id	title	keywords	abstract	entities	authors	year	journal	doi	fos	area	x	y	ix
4337487667069bd83d645788068587567fe46762	towards a platform-independent cooperative human-robot interaction system: ii. perception, execution and imitation of goal directed actions	robot sensing systems;image motion analysis;executable specification;action representation;human robot interaction;learning systems;motion capture;robot vision;learning by example;adaptive systems;human motion;cognition;sparks;robot vision adaptive systems gesture recognition human robot interaction image motion analysis learning by example learning systems;visual perception;humans;goal directed action imitation platform independent cooperative human robot interaction system robot learning adaptive robot platform independent perceptual system human action recognition action learning action perception human understanding teleological reasoning action primitive composition compositional action execution specification icub robot jido robot agency attribution kinect motion capture system human motion tracking action representation spoken language understanding visual perception physical state change;humans robot kinematics context robot sensing systems sparks cognition;gesture recognition;context;robot kinematics;spoken language understanding	If robots are to cooperate with humans in an increasingly human-like manner, then significant progress must be made in their abilities to observe and learn to perform novel goal directed actions in a flexible and adaptive manner. The current research addresses this challenge. In CHRIS.I [1], we developed a platform-independent perceptual system that learns from observation to recognize human actions in a way which abstracted from the specifics of the robotic platform, learning actions including “put X on Y” and “take X”. In the current research, we extend this system from action perception to execution, consistent with current developmental research in human understanding of goal directed action and teleological reasoning. We demonstrate the platform independence with experiments on three different robots. In Experiments 1 and 2 we complete our previous study of perception of actions “put” and “take” demonstrating how the system learns to execute these same actions, along with new related actions “cover” and “uncover” based on the composition of action primitives “grasp X” and “release X at Y”. Significantly, these compositional action execution specifications learned on one iCub robot are then executed on another, based on the abstraction layer of motor primitives. Experiment 3 further validates the platform-independence of the system, as a new action that is learned on the iCub in Lyon is then executed on the Jido robot in Toulouse. In Experiment 4 we extended the definition of action perception to include the notion of agency, again inspired by developmental studies of agency attribution, exploiting the Kinect motion capture system for tracking human motion. Finally in Experiment 5 we demonstrate how the combined representation of action in terms of perception and execution provides the basis for imitation. This provides the basis for an open ended cooperation capability where new actions can be learned and integrated into shared plans for cooperation. Part of the novelty of this research is the robots' use of spoken language understanding and visual perception to generate action representations in a platform independent manner based on physical state changes. This provides a flexible capability for goal-directed action imitation.	abstraction layer;experiment;human–robot interaction;icub;kinect;kinesiology;motion capture;natural language understanding;robot	Stéphane Lallée;Ugo Pattacini;Jean-David Boucher;Séverin Lemaignan;Alexander Lenz;Chris Melhuish;Lorenzo Natale;Sergey Skachek;Katharina Hamann;Jasmin Steinwender;Emrah Akin Sisbot;Giorgio Metta;Rachid Alami;Matthieu Warnier;Julien Guitton;Felix Warneken;Peter Ford Dominey	2011	2011 IEEE/RSJ International Conference on Intelligent Robots and Systems	10.1109/IROS.2011.6094744	computer vision;motion capture;cognition;visual perception;computer science;artificial intelligence;gesture recognition;robot kinematics	Robotics	-32.73850449100934	-40.02342176543091	14292
31dc88bee63cf32a2ac29ed8b221abb1a22f2bd1	characterizing super spreading in microblog: an epidemic-based model	silicon;sina weibo;social networking online information dissemination;predictive models silicon sociology statistics twitter;information propagation regularity;super spreading;epidemiology sina weibo information propagation regularity super spreading compartment model;epidemiology;statistics;predictive models;compartment model;twitter;sair model microblog epidemic based model online social communications information spreading platform super spreading events message transmission information diffusion process hot topic detection information propagation information monitoring contagious disease spread parameterized model epidemic models tweet message diffusion fitting process parameter settings;sociology	"""Microblogs play an important role in online social communications. Different from ordinary pieces of information, some hot topics and emerging news will become much more popular in a very short time with the help of this information spreading platform of microblogs. In these """"super spreading events"""", messages are transmitted to a vast range of individuals through a small portion of users engaged in the information diffusion process, a.k.a. super spreaders. Gaining an awareness of super spreading phenomena and an understanding of patterns of vast-ranged information diffusion process is worthy for several tasks such as hot topic detection, predictions of information propagation, harmful information monitoring and intervention. In this paper, inspired by the analogous patterns of super spreading in both information diffusion and spread of a contagious disease, we build a parameterized model based on well-known epidemic models to characterize super spreading phenomenon of tweet message diffusion accompanied with super spreaders. Through a fitting process, parameter settings under different scenarios are obtained and the corresponding basic reproduction number is also analyzed, which indicates the degree super spreader will affect the spreading. With the help of the SAIR model, some feasible applications can be exploited."""	daylight;multi-compartment model;social network;software propagation	Yu Liu;Bin Wu;Bai Wang	2015	2015 IEEE International Conference on Big Data (Big Data)	10.1109/BigData.2015.7364020	simulation;geography;advertising;communication	DB	-19.66891328405395	-42.714983049815174	14306
1eeb67b12dcc9b967bc65c3c4ff22cad57478a56	extracting share frequent itemsets with infrequent subsets	heuristic data mining;share frequent itemsets;heuristic method;association rules;data mining;association rule mining;share measure;frequent itemset;machine learning;association rule;frequent itemsets;quantitative itemsets	Itemset share has been proposed as an additional measure of the importance of itemsets in association rule mining (Carter et al., 1997). We compare the share and support measures to illustrate that the share measure can provide useful information about numerical values that are typically associated with transaction items, which the support measure cannot. We define the problem of finding share frequent itemsets, and show that share frequency does not have the property of downward closure when it is defined in terms of the itemset as a whole. We present algorithms that do not rely on the property of downward closure, and thus are able to find share frequent itemsets that have infrequent subsets. The algorithms use heuristic methods to generate candidate itemsets. They supplement the information contained in the set of frequent itemsets from a previous pass, with other information that is available at no additional processing cost. They count only those generated itemsets that are predicted to be frequent. The algorithms are applied to a large commercial database and their effectiveness is examined using principles of classifier evaluation from machine learning.	algorithm;association rule learning;heuristic;machine learning;numerical analysis	Brock Barber;Howard J. Hamilton	2003	Data Mining and Knowledge Discovery	10.1023/A:1022419032620	association rule learning;computer science;machine learning;pattern recognition;data mining;database	ML	-5.730390641992736	-35.98273074399933	14326
511a8cb69af8b1eed06b9dff2fcd21cfcda9d13f	sensing healthy lifestyle in urban and rural environments		An extended framework for Android smartphones is employed to obtain objective and subjective measures of relevant lifestyle parameters. Participants were recruited from two very dissimilar environments: the city of Istanbul as one of the largest mega cities worldwide and the rural district of Mersin in the south-eastern part of Turkey. Correlation analysis between subjective ratings and objective sensor data features is performed to illustrate the potential of an automatic detection of health-relevant lifestyle parameters.		Bert Arnrich;Naime Seyma Erdem;Hasan Faik Alan;Cem Ersoy	2014			simulation;geography;environmental protection;cartography	HCI	-20.171727091265296	-32.95731333920589	14366
ffa111d29d9aeddd78040b96226629d01c66553a	next-app prediction by fusing semantic information with sequential behavior		Next-app prediction is the task of predicting the next app that a user will choose to use on the smartphone. It helps to establish a variety of intelligent personalized services, such as fast-launch UI app, intelligent user-phone interactions, and so on. Since app names only provide limited semantic information, the intrinsic relation among apps cannot be fully exploited. Meanwhile, next-app to be used is largely determined by a sequence of apps that a user used recently. To address these challenging problems, this paper first enriches the semantic information of apps by extracting descriptive text of each app from the app store and thus proposes a topic model to transform apps as well as user preferences into latent vectors. Then, a set of nearest neighbors can be constructed based on the similarity of latent vectors and it is employed for training the prediction model. Furthermore, our prediction scheme is built on the temporal sequential data and is modeled by using the chain-augmented Naive Bayes model. Experimental results with a real smartphone application log data have demonstrated that our method achieves higher recall and DCG values compared with several baseline next-app prediction methods.		Changjian Fang;Youquan Wang;Dejun Mu;Zhiang Wu	2018	IEEE Access	10.1109/ACCESS.2018.2883377	topic model;naive bayes classifier;machine learning;semantics;distributed computing;app store;computer science;recall;data modeling;artificial intelligence	ML	-21.746535680550966	-45.657709768892055	14367
ce2e645aacb0290c03a82d5fd24718f908853813	study on covert networks of terroristic organizations based on text analysis	terroristic organizations;domestic terrorist organization;social organization structure;data mining tools;barium;text analysis;organizations algorithm design and analysis artificial neural networks world wide web barium;social network analytical method;data mining;artificial neural networks;terroristic activities;domestic mainstream network;social networking online;social network structure;network analysis tools;text information;social network analysis;network text analysis;world wide web;terroristic network;organizations;data mining network text analysis social network analysis terroristic network;text analysis data mining social networking online terrorism;algorithm design;algorithm design and analysis;text data mining;social network analytical method terroristic organizations text analysis text information domestic mainstream network domestic terrorist organization social network structure social organization structure network analysis tools terroristic activities text data mining data mining tools;artificial neural network;terrorism	Text information on typical domestic terrorist organization released by domestic mainstream network media is collected, and network text analysis tools are adopted to extract the entities that reflect the social network structure of terroristic organizations and the associated data from text information, to construct the covert networks for social organization structure of terrorists. Network analysis tools are adopted to carry out a social network quantitative analysis to the terroristic network characteristics in both individual level and organizational level. The study shows, that text information on terroristic activities from various network media can be effectively processed by text data mining, and visual network models that reflect social organization structure of terrorists can be made accordingly, and this demonstrates that to combine data mining tools with social network analytical method is an effective approach to study the covert networks of terroristic organizations.	covert channel	Duoyong Sun;Shu-Quan Guo;Hai Zhang;Ben-xian Li	2011		10.1109/ISI.2011.5984117	organizational network analysis;algorithm design;computer science;data science;machine learning;data mining;world wide web;artificial neural network	NLP	-22.5307842256109	-51.97416277215297	14479
86a2553f1155782164aad34e472651d0ba1d7be1	characterizing information propagation patterns in emergencies: a case study with yiliang earthquake			software propagation	Lifang Li;Qingpeng Zhang;Jun Tian;Haolin Wang	2018	Int J. Information Management	10.1016/j.ijinfomgt.2017.08.008		HCI	-15.486186420392082	-25.29554709343398	14490
e88a7d49ae81656054d3cecd268a205b5d021cce	on finding the maximum edge biclique in a bipartite graph: a subspace clustering approach.		Bipartite graphs have been proven useful in modeling a wide range of relationship networks. Finding the maximum edge biclique within a bipartite graph is a well-known problem in graph theory and data mining, with numerous realworld applications across different domains. We propose a probabilistic algorithm for finding the maximum edge biclique using a Monte Carlo subspace clustering approach. Extensive experimentation with both artificial and real-world datasets shows that the algorithm is significantly better than the state-of-the-art technique. We prove that there are solid theoretical reasons for the algorithm’s efficacy that manifest in a polynomial complexity of time and space. Keywords—Maximum edge bipartite subgraph; Biclique; Subspace clustering; Data mining; Graph mining	cluster analysis;clustering high-dimensional data;data mining;graph theory;maximum cut;monte carlo method;polynomial;randomized algorithm;structure mining;time complexity	Eran Shaham;Honghai Yu;Xiaoli Li	2016		10.1137/1.9781611974348.36	edge-transitive graph;complete bipartite graph;bipartite graph;simplex graph;biregular graph;matching	ML	-10.287168403072117	-39.92306209462275	14543
6501360921e75069e89c56f3243ab4e9d924accd	a framework to mine high-level emerging patterns by attribute-oriented induction	high level;algorithm;emerging pattern;attribute oriented;rulesets	This paper presents a framework to mine summary emerging patterns in contrast to the familiar low-level patterns. Generally, growth rate based on low-level data and simple supports are used to measure emerging patterns (EP) from one dataset to another. This consequently leads to numerous EPs because of the large numbers of items. We propose an approach that uses high-level data: high-level data captures the data semantics of a collection of attributes values by using taxonomies, and always has larger support than low-level data. We apply a well known algorithm, attribute-oriented induction (AOI), that generalises attributes using taxonomies and investigate properties of the rule sets obtained by generalisation algorithms.		Maybin K. Muyeba;Muhammad Saad Khan;Spits Warnars;John A. Keane	2011		10.1007/978-3-642-23878-9_21	high- and low-level;computer science;artificial intelligence;data science;machine learning;data mining;database	ML	-7.632017821343783	-44.14846433424948	14554
c2d5b06dc569344c623cf3285d8f3447b9cf1116	hybrid simulation algorithms for an agent-based model of the immune response	celada seiden model;agent based model;immune system;computational biology;cellular automata;hybrid simulation;immune response	The immune system is of central interest for the life sciences, but its high complexity makes it a challenging system to study. Computational models of the immune system can help to improve our understanding of its fundamental principles. In this paper, we analyze and extend the Celada-Seiden model, a simple and elegant agent-based model of the entire immune response, which, however, lacks biophysically sound simulation methodology. We extend the stochastic model to a stochastic-deterministic hybrid, and link the deterministic version to continuous physical and chemical laws. This gives precise meanings to all simulation processes, and helps to increase performance. To demonstrate an application for the model, we implement and study two different hypotheses about T cell-mediated immune memory.	agent-based model;algorithm;computation;computational model;simulation	Johannes Textor;Björn Hansen	2009	Cybernetics and Systems	10.1080/01969720902922384	cellular automaton;simulation;immune system;computer science;artificial intelligence;artificial immune system	AI	-5.641221228583367	-49.60173512522582	14574
d82e2f7df98f9626c723835343a2ba6bfe85cef8	prediction of indoor movements using bayesian networks	sensibilidad contexto;prediction method;duracion;bayesian network;pistage;context aware;criterio resultado;office building;pervasive computing;multilayer perceptrons;localization;rastreo;performance requirement;critere performance;localizacion;duration;informatica difusa;perceptron multicouche;reseau bayes;red multinivel;localisation;red bayes;informatique diffuse;dynamic bayesian network;prediction accuracy;bayes network;multi layer perceptron;multilayer network;sensibilite contexte;reseau multicouche;reseau neuronal;indoor installation;instalacion interior;installation interieure;red neuronal;tracking;duree;neural network	This paper investigates the efficiency of in-door next location prediction by comparing several prediction methods. The scenario concerns people in an office building visiting offices in a regular fashion over some period of time. We model the scenario by a dynamic Bayesian network and evaluate accuracy of next room prediction and of duration of stay, training and retraining performance, as well as memory and performance requirements of a Bayesian network predictor. The results are compared with further context predictor approaches a state predictor and a multi-layer perceptron predictor using exactly the same evaluation set-up and benchmarks. The publicly available Augsburg Indoor Location Tracking Benchmarks are applied as predictor loads. Our results show that the Bayesian network predictor reaches a next location prediction accuracy of up to 90% and a duration prediction accuracy of up to 87% with variations depending on the person and specific predictor set-up. The Bayesian network predictor performs in the same accuracy range as the neural network and the state predictor.	artificial neural network;dynamic bayesian network;kerrison predictor;multilayer perceptron;requirement	Jan Petzold;Andreas Pietzowski;Faruk Bagci;Wolfgang Trumler;Theo Ungerer	2005		10.1007/11426646_20	simulation;computer science;artificial intelligence;machine learning;bayesian network;ubiquitous computing;artificial neural network	Mobile	-12.756919202943907	-31.3961822992416	14685
e35d52da6788bbb9c9cad37d8bf33f5d6579d6a8	a brief tour of theoretical tile self-assembly		The author gives a brief historical tour of theoretical tile selfassembly via chronological sequence of reports on selected topics in the field. The goal is to provide context and motivation for the these results and the field more broadly. Introduction. This tour covers only a subset of the research topics in theoretical tile self-assembly, listed chronologically according to the most intense interval of study. It is intended for readers who are familiar with the basics of the field and wish to obtain a better understanding of how the multitude of models, problems, and results relate. As such, it is neither a survey nor an introduction; for these, the reader is referred to the excellent works of Doty [18], Patitz [37], Woods [50], and Winfree [47]. Moreover, it does not cover work in experimental DNA tile self-assembly. The aTAM of Winfree (1990s). It is common for work on theoretical tile self-assembly (hereafter tile assembly), to begin “In his Ph.D. thesis, Winfree [47] introduced the abstract tile assembly model (aTAM) . . . ”. The ubiquity of this opener matches the importance this work plays in the field: it is the point of conception, and nearly 20 years later, its reading connotes initiation to the area. Moreover, the sustained popularity of tile assembly is due in large part to the elegance and hidden deoth of this original model. Such intricacy is perhaps most crystallized in a simple yet devious question: is universal computation possible in the aTAM at temperature 1? As with any research, the conception of the aTAM and corresponding experimental implementations were did not occur in isolation. Several other models of (linear) DNA-based computation also introduced around this time,	computation;self-assembly	Andrew Winslow	2016		10.1007/978-3-319-39300-1_3	tile;theoretical computer science;distributed computing;computer science	Theory	-7.898225003916996	-48.27344330519737	14692
cc5b4c535d02c3a0d4b9e0669cdc70c926b7d668	biometric information fusion for web user navigation and preferences analysis: an overview		Extracting knowledge of web users interests, navigational actions and preferences from web and biometric dataBiometric tools for measuring actual responses to the stimuli presented via websitesSurvey of biometric information fusion applied to the web usage mining field. Throughout the years having knowledge of Web users interests, navigational actions and preferences has gained importance due to the objectives of organizations and companies. Traditionally this field has been studied from the Web Mining perspective, particularly through the Web Usage Mining (WUM) concept, which consists of the application of machine learning techniques over data originated in the Web (Web data) for automatic extraction of behavioral patterns from Web users. WUM makes use of data sources that approximate users behavior, such as weblogs or clickstreams among others; however these sources imply a considerable degree of subjectivity to interpret. For that reason, the application of biometric tools with the possibility of measuring actual responses to the stimuli presented via websites has become of interest in this field. Instead of doing separate analyses, information fusion (IF) tries to improve results by developing efficient methods for transforming information from different sources into a single representation, which then could be used to guide biometric data fusion to complement the traditional WUM studies and obtain better results. This paper presents a survey of Biometric IF applied to the WUM field, by first defining WUM and its main applications, later explaining how the Biometric IF could be applied and finally reviewing several studies that apply this concept to WUM.	biometrics	Gino Slanzi;Gaspar Pizarro;Juan D. Velásquez	2017	Information Fusion	10.1016/j.inffus.2017.02.006	web mining;artificial intelligence;machine learning;fusion;data mining;information retrieval;sensor fusion;biometrics;behavioral pattern;computer science	NLP	-25.321758407626824	-49.24792635629909	14699
14e380d5663da189f17450013fdcd3cd19326434	practical recommendations on crawling online social networks	social network services;convergence;tree searching random processes sampling methods social networking online;social networking services;metropolis hastings;data collection;indexing terms;random walks;topological properties;facebook peer to peer computing privacy convergence markov processes context;random walk;random processes;social networking online;facebook;ground truth;graph sampling sampling methods social network services facebook random walks convergence measurements;measurements;markov processes;online social network;peer to peer computing;tree searching;sampling methods;facebook online social network crawling social graph metropolis hasting random walk re weighted random walk mhrw rwrw breadth first search unadjusted random walk online formal convergence diagnostics data collection process;breadth first search;context;graph sampling;privacy;performance assessment	"""Our goal in this paper is to develop a practical framework for obtaining a uniform sample of users in an online social network (OSN) by crawling its social graph. Such a sample allows to estimate any user property and some topological properties as well. To this end, first, we consider and compare several candidate crawling techniques. Two approaches that can produce approximately uniform samples are the Metropolis-Hasting random walk (MHRW) and a re-weighted random walk (RWRW). Both have pros and cons, which we demonstrate through a comparison to each other as well as to the """"ground truth."""" In contrast, using Breadth-First-Search (BFS) or an unadjusted Random Walk (RW) leads to substantially biased results. Second, and in addition to offline performance assessment, we introduce online formal convergence diagnostics to assess sample quality during the data collection process. We show how these diagnostics can be used to effectively determine when a random walk sample is of adequate size and quality. Third, as a case study, we apply the above methods to Facebook and we collect the first, to the best of our knowledge, representative sample of Facebook users. We make it publicly available and employ it to characterize several key properties of Facebook."""	ground truth;metropolis;online and offline;read-write memory;recommender system;social graph;social network	Minas Gjoka;Maciej Kurant;Carter T. Butts;Athina Markopoulou	2011	IEEE Journal on Selected Areas in Communications	10.1109/JSAC.2011.111011	stochastic process;computer science;data mining;internet privacy;world wide web;random walk;statistics	Web+IR	-10.916445910781844	-43.5748895638539	14770
36fe5b7793f342f5480c4ed34a035d35730a4718	nani: an efficient community detection algorithm based on nested aggregation of node influence		Most traditional community detection algorithms were developed based on the similarity evaluation of topological features. None of them have concerned about the rules during the information dissemination from the dynamic aspect, and therefore, they cannot discover communities that best serve the purpose of information diffusion. In addition, since traditional algorithms have not considered the information interacting structure and mechanism with-between network nodes, the community center and backbone nodes identified may not even be effective in the actual information dissemination process. To deal with this problem, this paper explored the community detection issue from a different angle of dynamic information diffusion and did the following contributions: (1) proposing a novel model, called NI (Node Influence) to evaluate the influence between nodes and intermediate communities, (2) proposing a novel algorithm, NANI (Nested Aggregation of Node Influences) to merge the nodes or intermediate communities on the way upwards based on NI model, (3) conducting extensive experiments on all existing 9 kinds of similarity measures. Experiments showed that the NANI algorithm outperforms all the related methods at most cases, especially when the data volume scale is considerably huge.	algorithm;experiment;interaction;internet backbone;non-maskable interrupt	Chuan Li;Zhiheng Jiang;Yijie Li;Yangfan Miao;Daiyan Hu;Guang Ming Liu;Yijing Liu	2017		10.1145/3063955.3063980	merge (version control);node (networking);algorithm;information dissemination;geography	DB	-14.632667364410734	-42.99080304855087	14773
80a07e2811fdd6e79fc098d2aa99dbb9bf087a6b	gentlemen, stop your engines!	endnotes;pubications	For fifty years, computer chess has pursued an original goal of Artificial Intelligence, to produce a chess-engine to compete at the highest level. The goal has arguably been achieved, but that success has made it harder to answer questions about the relative playing strengths of man and machine. The proposal here is to approach such questions in a counter-intuitive way, handicapping or stopping-down chess engines so that they play less well. The intrinsic lack of man-machine games may be side-stepped by analysing existing games to place computerengines as accurately as possible on the FIDE ELO scale of human play. Move-sequences may also be assessed for likelihood if computer-assisted cheating is suspected.	artificial intelligence;chess engine;computer chess	Guy Haworth	2007	ICGA Journal		simulation;computer science;artificial intelligence	AI	-25.26597801765007	-25.943383537082084	14832
69292f84ca39682a309d71966b16cf4a18462da7	using hybrid similarity-based collaborative filtering method for compound activity prediction		It is important for researchers to predict compound activity to the targets quickly and effectively in the field of drug design. In the paper, the problem of compound activity prediction is converted to the recommendations in the field of e-commerce, compounds are viewed as users, and protein targets are viewed as items. A rating matrix is extracted by IC50 of each compound to targets, there are four filtering recommendation algorithms could be used for predicting compound activity. In order to improve the accuracy of prediction, the hybrid similarity-based Collaborative Filtering (HybridSimCF) Method is proposed, the method will combine the similarity of the compound structure and the similarity based on the rating matrix to predict the activity. Through compared with other three collaborative filtering methods, HybridSimCF has better results. It not only improves the values of RMSE and MAE, but also effectively solves the cold start problem. The method can quickly and effectively solve the prediction of compound activity.	collaborative filtering	Jun Ma;Ruisheng Zhang;Yongna Yuan;Zhili Zhao	2018		10.1007/978-3-319-95933-7_67	pattern recognition;collaborative filtering;cold start;machine learning;filter (signal processing);computer science;artificial intelligence;quantitative structure–activity relationship;matrix (mathematics)	ECom	-21.1432078035184	-48.77900011852489	14851
99ad43c711f3668a49c68c6e1a54b8581267228c	adapting models of visual aesthetics for personalized content creation	constrained optimization;optimisation;art;evolutionary computation;experience driven procedural content generation edpcg;visualization games optimization computational modeling art shape adaptation models;interactive evolution experiment visual aesthetics model adaptation personalized content creation search based approach personalized content generation two step adaptation procedure personalized evaluation function fitness functions visual perception 2d game spaceships neuroevolutionary constrained optimization;optimisation computer games evolutionary computation interactive systems;visualization;computational modeling;shape;games;computational aesthetics;optimization;interactive evolution;computer games;adaptation models;interactive evolution computational aesthetics constrained optimization experience driven procedural content generation edpcg;interactive systems	This paper introduces a search-based approach to personalized content generation with respect to visual aesthetics. The approach is based on a two-step adaptation procedure where: 1) the evaluation function that characterizes the content is adjusted to match the visual aesthetics of users; and 2) the content itself is optimized based on the personalized evaluation function. To test the efficacy of the approach, we design fitness functions based on universal properties of visual perception, inspired by psychological and neurobiological research. Using these visual properties, we generate aesthetically pleasing 2-D game spaceships via neuroevolutionary constrained optimization and evaluate the impact of the designed visual properties on the generated spaceships. The offline generated spaceships are used as the initial population of an interactive evolution experiment in which players are asked to choose spaceships according to their visual taste: the impact of the various visual properties is adjusted based on player preferences and new content is generated online based on the updated computational model of visual aesthetics of the player. Results are presented that show the potential of the approach in generating content which is based on subjective criteria of visual aesthetics.	computational model;constrained optimization;evaluation function;experiment;fitness function;game engine;hall-effect thruster;interactive evolutionary computation;mathematical optimization;online and offline;personalization;procedural generation;spaceship (cellular automaton);weight function	Antonios Liapis;Georgios N. Yannakakis;Julian Togelius	2012	IEEE Transactions on Computational Intelligence and AI in Games	10.1109/TCIAIG.2012.2192438	games;constrained optimization;simulation;visualization;shape;computer science;artificial intelligence;machine learning;multimedia;computational model;evolutionary computation	HCI	-27.86371919166324	-26.03004839708639	14892
5901af2236144488a965a7b988719ad10eece96d	combining dynamic a/b experimentation and recommender systems in moocs		We consider how dynamic A/B experiments – used to discover and deploy policies for personalizing items – can be interpreted from the perspective of a recommendation problem, where no prior data is available. We present an illustrative data set we collected, to evaluate algorithms for recommending emails (that vary along dimensions like subject lines) that will maximize response rate, from different subgroups of online learners. This problem is formalized as a contextual bandit, and we do an offline regret comparison of how standard bandit algorithms would perform in optimizing response rate. We report a system that provides an API for real–time data exchange and recommendation policy updates from algorithms from external machine learning researchers, and compare our best-performing offline algorithm – Thompson Sampling – against a randomized policy.	a/b testing;application programming interface;email;experiment;gibbs sampling;machine learning;massive open online course;online algorithm;online and offline;randomized algorithm;real-time operating system;recommender system;thompson sampling	Joseph Jay Williams;Luong Hoang	2016			recommender system;data mining;computer science	ML	-17.986938767848972	-48.50448613695535	14902
9ceff50f0023d6c872e82c9d76a64877ec8ba6bb	experimental identification of pilot response using measured data from a flight simulator		This paper describes the measuring of pilot respon e time to a sudden change in a controlled parameter whilst flying an a ircr ft. The authors of this paper created an analytical model of human behavior from the basic data of an automated regulation. The measurements have been do ne on a Cessna 152 simulator at the University of Hertfordshire, Hatfi eld. The tested pilots were pilot students with several tens of flight hours in real planes. The pilot’s response to a sudden aircraft altitude change was m easured. For analysis of the measured results a mathematical identification mode l in MATLAB® environment was used. The results obtained from MAT LAB® confirm that the experimental measurements were successful.	algorithm;behavior model;flight simulator;matlab;planning;response time (technology);simulation;stereotype (uml);transfer function;while	Jan Boril;Rudolf Jalovecky	2012		10.1007/978-3-642-33409-2_14	simulation	Robotics	-22.602526513950345	-25.607307179626595	14926
c566a5cd0a737c46ba928284fc2e8c23f041218b	empirical evaluation of an automated intraday stock recommendation system incorporating both market data and textual news	data mining;investment decisions;stock returns;recommendation;prediction	In this study we evaluate the effectiveness of augmenting numerical market data with textual-news data, using data mining methods, for forecasting stock returns in intraday trading. Integrating these two sources of data not only enriches the information available for the forecasting model, but it can potentially capture joint patterns that may not otherwise be identified when each data source is employed separately. We start with market data and then gradually add various textual data representations, going from simple representations, such as word counts, to more advanced representations involving sentiment analysis. To find the incremental value of each data representation, we build an end-to-end recommendation process including data preprocessing, modeling, validation, trade recommendations and economic evaluation. Each component of the modeling process is optimized to remove human bias and to allow us to impartially compare the results of the various models. Additionally, we experiment with several forecasting algorithms to find the one that yields the ''best'' results according to a variety of performance criteria. We employ data representation procedures and modeling improvements beyond those used in previous related studies. The economic evaluation of the results is conducted using a simulation procedure that inherently accounts for transaction costs and eliminates biases that have potentially affected previous related data-mining studies. This research is one of the largest-scale data-mining studies for evaluating the effectiveness of integrating market data with textual news data for the purpose of stock investment recommendations. The results of our study are promising in that they show that augmenting market data with advanced textual data representation significantly improves stock purchase decisions. Best results are achieved when the approach is implemented with a nonlinear neural network forecasting algorithm.	recommender system	Tomer Geva;Jacob Zahavi	2014	Decision Support Systems	10.1016/j.dss.2013.09.013	prediction;marketing;machine learning;data mining;database;world wide web;statistics;commerce	Web+IR	-20.490310522401856	-50.76965568388729	14948
443efce5306421a8ef0b4a310de5c08eda0807aa	personalized recommendation for weibo comic users		Recommendation system, as one of cost effective solutions dealing with the information-overwhelming problem, has been adopted by many internet e-commerce platforms, such as Amazon, eBay, Asos, etc. User-based or item-based collaborative filtering, as one of the classic recommendation algorithms, suffers greatly from high computational consumption and matrix complexity when big data is involved. While neural network architecture based deep learning technique, on the other hand, performs outstandingly as an alternative solution solving regression and classification problems, especially with sparse inputs. Furthermore, deep learning alleviates the cold start problem to a certain extent which is an unavoidable flaw in collaborative filtering (CF) approach based recommendation algorithms. This paper proposes a deep learning network structure which utilizes the Restricted Boltzmann Machine and the artificial neural network for Weibo Users. The proposed structure is trained and tested through the actual dataset provided by VComic, who is an online comic book provider and shares the information with China's biggest social network — Weibo.com. The offline experiment shows that the proposed system outperforms the user-based collaborative filtering algorithm in the metrics of precision and coverage. Specifically, the proposed mechanism demonstrates the ability to mine the long tail under the premise of accuracy guarantee, as well as to reduce the system's complexity dramatically.	algorithm;artificial neural network;big data;cold start;collaborative filtering;deep learning;e-commerce;flaw hypothesis methodology;long tail;network architecture;online and offline;recommender system;restricted boltzmann machine;social network;sparse matrix;webcomic	Yan Lindsay Sun;Haoran Lv;Xu Liu;Peng Xu;Yun Huang;Yuqian Sun	2018	2018 Wireless Telecommunications Symposium (WTS)	10.1109/WTS.2018.8363939	collaborative filtering;recommender system;real-time computing;architecture;computer science;cold start;big data;machine learning;deep learning;artificial neural network;artificial intelligence;restricted boltzmann machine	AI	-19.20748391495119	-50.17922748488372	15074
52f05a598e87b1f8bb5b60ca4c6eca748d832be0	gaze guidance reduces the number of vehicle-pedestrian collisions in a driving simulator	gaze guidance;vision system;traffic accident;driving simulator;eye movements;eye movement;visual perception;national highway traffic safety administration;driving safety	Driving and visual perception are tightly linked. Every moment, a multitude of visual stimuli compete for the driver's limited attentional resources. Despite modern safety measures, traffic accidents still remain a major source of fatalities. A large part of these casualties occur in accidents for which driver distraction was cited as the main cause [National Highway Traffic Safety Administration September 2010]. We propose to help drivers by building an augmented vision system that can guide eye movements towards regions which may constitute a source of danger. In a first study, we have already shown that largely unobtrusive gaze guidance techniques used in a driving simulator help drivers better distribute their attentional resources and drive more safely [Pomarjanschi et al. 2011]. Current experiments investigate the efficiency of more general cues, that only signal the direction in which a critical event might occur. Results of these experiments will be reported at the conference.	driving simulator;experiment;simulation	Laura Pomârjanschi;Michael Dorr;Erhardt Barth	2011		10.1145/2077451.2077482	computer vision;simulation;machine vision;computer security;eye movement	Vision	-19.415631502306933	-27.22505409850685	15121
af6a05402e32c887b47a24e9903680475a283a55	trending words in digital library for term cloud-based navigation	keywords;history;digital libraries;navigation;annotation web based system digital library term cloud based navigation navigation history metadata source personalized navigation annota book marking;digital libraries tags keywords navigation history term cloud;term cloud;meta data;meta data cloud computing digital libraries;tags;navigation history image color analysis tag clouds cloud computing libraries visualization;cloud computing	The clouds consisting of tags or keywords provide an alternative and often more readable navigation interface by exploiting visual features of words placed in a cloud and augmenting their information value with different font size and color. However, existing approaches for cloud navigation rely mostly on frequency of terms and do not adapt to the users' needs. In the paper, we propose a method for term cloud navigation which exploits navigation history as a source of metadata for personalized navigation. We consider trending words in users' navigation history as a relevant factor determining users' interests while navigating. In addition, we recognize a position of a word in a query to have an important role and rank the list of the documents accordingly. We focus on the domain of digital libraries and provide an evaluation of our method in Annota, book marking and annotation web-based system.	cloud computing;digital library;gps navigation device;human-readable medium;item unique identification;library (computing);personalization;web application	Samuel Molnar;Róbert Móro;Mária Bieliková	2013	2013 8th International Workshop on Semantic and Social Media Adaptation and Personalization	10.1109/SMAP.2013.23	computer science;multimedia;world wide web;information retrieval	HCI	-28.45947744135573	-51.31060681978147	15148
c9fb80debc65f219b0e77afae56f56e0cf2ba98b	multi-agent diffusion of decision experiences	recognition;cognitive agent;diffusion distance	Diffusion geometry offers a general framework for multiscale analysis of massive data sets on manifold. However, its applicability is greatly limited due to the lack of work on distributed diffusion computing, as a data set expands over time, it can quickly exceed the processing capacity of a single agent. In this paper, we propose a multi-agent diffusion approach where a massive data set can be split into several subsets and each diffusion agent only needs to work with one subset in diffusion computation. We conduct an experiment by applying various splitting strategies to a large set of human decision-making experiences. The result indicates that the multi-agent diffusion approach is promising, and it is possible to benefit from using a large group of diffusion agents if their diffusion maps were constructed from subsets with shared data points (experiences). This study encourages the application of multi-agent diffusion approach to systems that rely on massive data analysis, and will stimulate further investigations on distributed diffusion computing.	agent-based model;computation;data point;data security;decision support system;diffusion map;experiment;influence diagram;multi-agent system;network-centric warfare;serializability	Xiaocong Fan;Meng Su	2011	2011 IEEE 23rd International Conference on Tools with Artificial Intelligence	10.1142/S0218213013600014	mathematical optimization;simulation;artificial intelligence;management science	Vision	-12.556192808346582	-37.684469450851964	15156
8859f4b7f3d826bcae4eff2735a073030be23e8a	mr-tree: an efficient index for mapreduce	mapreduce;multidimensional index	Nowadays, big data becomes more and more popular, because it widely exists in many applications, such as social network and astronomy. Although building indexes to improve the query processing performance is common in DBMS field, it is infeasible to apply traditional indexing techniques to the MapReduce framework efficiently. Thus, how to process such data efficiently is challenging. In this paper, we study the problem of how to build an index for multidimensional data in MapReduce platform. The experimental results show that the proposed method can run efficiently. Copyright © 2013 John Wiley & Sons, Ltd.	big data;database;john d. wiley;k-nearest neighbors algorithm;mapreduce;range query (database);search algorithm;social network	Chunsheng Li;Jie Chen;Cheqing Jin;Rong Zhang;Aoying Zhou	2014	Int. J. Communication Systems	10.1002/dac.2619	computer science;data science;operating system;data mining;database	DB	-4.678264452012447	-39.9225280799483	15158
365f21f21485bcdfe049a473627a32076fef0392	graph-based ranking algorithms for e-mail expertise analysis	expert finding;ranking algorithm;social network analysis;digraph node ranking;ordered list distance	In this paper we study graph--based ranking measures for the purpose of using them to rank email correspondents according to their degree of expertise on subjects of interest. While this complete expertise analysis consists of several steps, in this paper we focus on the analysis of digraphs whose nodes correspond to correspondents (people), whose edges correspond to the existence of email correspondence between the people corresponding to the nodes they connect and whose edge directions point from the member of the pair whose relative expertise has been estimated to be higher. We perform our analysis on both synthetic and real data and we introduce a new error measure for comparing ranked lists.	algorithm;directed graph;email;synthetic intelligence	Byron Dom;Iris Eiron;Alex Cozzi;Yi Zhang	2003		10.1145/882082.882093	social network analysis;machine learning;data mining	ML	-14.59709863300217	-41.071205138368335	15191
e41019de55bb3f439497f8f9c85252a30c8ea7c4	the classification of multi-modal data with hidden conditional random field	hidden conditional random field;multi modal classification;latent structure	The classification of multi-modal data has been an active research topic in recent years. It has been used in many applications where the processing of multi-modal data is involved. Motivated by the assumption that different modalities in multi-modal data share latent structure (topics), this paper attempts to learn the shared structure by exploiting the symbiosis of multiple-modality and therefore boost the classification of multi-modal data, we call it Multi-modal Hidden Conditional Random Field (M-HCRF). M-HCRF represents the intrinsical structure shared by different modalities as hidden variables in a undirected general graphical model. When learning the latent shared structure of the multi-modal data, M-HCRF can discover the interactions among the hidden structure and the supervised category information. The experimental results show the effectiveness of our proposed M-HCRF when applied to the classification of multi-modal data.	conditional random field;modal logic	Xinyang Jiang;Fei Wu;Yin Zhang;Siliang Tang;Weiming Lu;Yueting Zhuang	2015	Pattern Recognition Letters	10.1016/j.patrec.2014.08.005	computer science;machine learning;pattern recognition;data mining	Vision	-14.940501766496109	-47.54841403533513	15193
bf87dcc79a0afc0e3d238c1156c6d07c5186beec	quantifying the invariance and robustness of permutation-based indexing schemes		Providing a fast and accurate (exact or approximate) access to large-scale multidimensional data is a ubiquitous problem and dates back to the early days of large-scale Information Systems. Similarity search, requiring to resolve nearest neighbor (NN) searches, is a fundamental tool for structuring information space. Permutation-based Indexing (PBI) is a reference-based indexing scheme that accelerates NN search by combining the use of landmark points and ranking in place of distance calculation. In this paper, we are interested in understanding the approximation made by the PBI scheme. The aim is to understand the robustness of the scheme created by modeling and studying by quantifying its invariance properties. After discussing the geometry of PBI, in relation to the study of ranking, from empirical evidence, we make proposals to cater for the inconsistencies of this structure.	approximation algorithm;computational geometry;experiment;feature vector;information system;k-nearest neighbors algorithm;landmark point;mathematical model;similarity search	Stéphane Marchand-Maillet;Edgar Roman-Rangel;Hisham Mohamed;Frank Nielsen	2016		10.1007/978-3-319-46759-7_6	artificial intelligence;machine learning;robustness (computer science);permutation;search engine indexing;computer science;information system;information space;k-nearest neighbors algorithm;ranking;nearest neighbor search	DB	-5.7190240159280785	-41.94666979923364	15200
579eb8d73a0b9739b48e34c477c097ebe72d6311	angular brushing of extended parallel coordinates	histograms;cfd data visualization;data dimensions;prototypes;angular brushing;information visualization;brushing;extended parallel coordinates;computational fluid dynamics;linear correlations;data visualisation;data analysis;navigation;computational modeling;cfd data visualization angular brushing extended parallel coordinates rational data properties data dimensions;data visualization;rational data properties;writing;data exploration;focus context visualization;data visualization computational fluid dynamics brushes navigation histograms data analysis prototypes writing multidimensional systems computational modeling;high light;multidimensional systems;parallel coordinates;brushes	In this paper we present angularbrushingfor parallel coordinates (PC) as a new approach to high-light rational dataproperties, i.e., features which depend on two data dimensions (instead of one). We also demonstrate smoothbrushing of PC as an intuitive tool to specify non-binary degreeof-interest functions (then used for F+C visualization). We also shortly describe our implementation as well as its application to the visualization of CFD data.	brushing and linking;computational fluid dynamics;parallel coordinates	Helwig Hauser;Florian Ledermann;Helmut Doleisch	2002		10.1109/INFVIS.2002.1173157	computer vision;navigation;parallel coordinates;multidimensional systems;interactive visual analysis;computational fluid dynamics;computer science;theoretical computer science;data mining;histogram;prototype;data analysis;computational model;writing;data visualization;statistics;computer graphics (images)	Visualization	-28.424091830084706	-33.082621968112974	15244
ee90828f6fb64526a4243e986d21c02f20137990	a task-oriented view of information visualization	pilot study;data collection;information visualization;data analysis;complex data;task analysis;data visualization;exploratory data visualizer;data exploration;data analysis process	Much of the research in information visualization has primarily focused on providing new views and frameworks to aid users in exploring or accessing data. Very little work has been done to support users through their full analysis process--from transforming their raw data into a set of polished final results. In this pilot study, we conducted a task analysis on five experts' use of an existing information visualization system when analyzing a complex data set. Our preliminary results indicate that users conduct several tasks outside of data exploration--tasks such as preparing the data, collecting results, and gathering evidence for a presentation. In addition, they give these other tasks high importance ratings with respect to the analysis process.	information visualization;task analysis	Stacie Hibino	1999		10.1145/632716.632829	data modeling;information visualization;computer science;data science;data mining;task analysis;database;data analysis;data visualization;complex data type;data collection	HCI	-27.083516778327315	-34.11399543845541	15246
a26eff4c4ad763c54c663b495fa19c069514916e	modeling the effects of information quality on process performance in operating rooms	analytical models;operating room;decision support;patient care hospitals medical information systems;theoretical framework;sorting;queue length;simulation;hospitals;patient care;operating rooms;hospitals information analysis analytical models surgery quality management computational modeling computer simulation cost function throughput queueing analysis;connectors;computational modeling;quality indicators;medical information systems;waiting time;information quality;surgery;patient satisfaction;quality indicators information quality process performance operating rooms hospital facility patient satisfaction quantitative information;quantitative information;process performance;simulation information quality operating room process performance;hospital facility	Operating rooms are regarded as the most costly hospital facilities. Due to rising costs and risks, it is necessary to optimize performance of the operating rooms. High quality information has a significant effect on improving process performance and patient satisfaction, as well as resolving patient disputes. Based on the analysis of the operation process, information quality (IQ) is considered as an important contributory factor in improving patient throughput. In this paper, a theoretical framework and main content are presented. Through the establishment of quantitative information, quality indicators such as Trace-ability, Believability and Reputation, and the effect on process performance (registered queue length, waiting time, utilization of hospital facilities), together with the cost of the operating process, are analyzed from the theoretical aspect and then verified by simulation technology. Finally, the results of our studies provide evidence that simulation can provide effective decision support to drive performance in operating rooms in several phases of the IQ improvement.	decision support system;experiment;information quality;operating system;simulation;throughput	Ying Su;Ningqiao Shen	2010	2010 12th International Conference on Computer Modelling and Simulation	10.1109/UKSIM.2010.39	simulation;medicine;operations management;management science	HPC	-16.662460040822303	-24.60778169200771	15294
d30a7a4b9f56a56ddbb3af43f1d3ef325261cbb5	salience indicators for landmark extraction at large spatial scales based on spatial analysis methods	spatial context;spatial cognition;urban landmark extraction;scale effect of cognition;address description	Urban landmarks are frequently used in way-finding and representations of spatial knowledge. However, assessing the salience of urban landmarks is difficult. Moreover, no method exists to rapidly extract urban landmarks from basic geographic information databases. The goal of this paper is to solve these problems from the dual aspects of spatial knowledge representation and public spatial cognition rules. A clear and systematic definition for multiple-scale urban landmarks is proposed, together with a category reference for extracting smalland medium-scale urban landmarks and a model for the large-scale automatic extraction of urban landmarks. In this large-scale automatic urban landmark extraction model, the salience is expressed by two weighted parameters: the check-in totals and local accessibility. The extraction threshold is set according to a predefined number of landmarks to be extracted. Experiments show that the extraction results match the reference data well.	accessibility;cognition;database;experiment;geographic information system;knowledge representation and reasoning;spatial analysis	Min Weng;Qin Xiong;Mengjun Kang	2017	ISPRS Int. J. Geo-Information	10.3390/ijgi6030072	computer vision;geography;data mining;communication	Web+IR	-23.070195252506796	-31.453755494969247	15366
b4aa957b3e9b4f79f3c01e31afb5ec5815ba1b32	the 'mental map' versus 'static aesthetic' compromise in dynamic graphs : a user study		The design of automatic layout algorithms for singl e graphs is a well established field, and some recent studies show how these algorithms affect human understandin g. By contrast, layout algorithms for graphs that chan ge over time are relatively immature, and few studies exist to evaluate their effectiveness empirically. This pape r presents two new dynamic graph layout algorithms an d empirical investigations of how effective these alg orithms are with respect to human understanding. Central to each algorithm is the “mental map”: the degree to which the layout supports continuous understanding. This work aims to evaluate the importance of the mental map, alongside traditional static graph aesthetics, in a nswering questions about dynamic graphs. We discover that a simple concept of the mental map is not sufficient for increasing understanding of the graph.	algorithm;automatic layout;eve;expectation propagation;force-directed graph drawing;mental mapping;preemption (computing);wilhelm pape	Peter Saffrey;Helen C. Purchase	2008				HCI	-30.096294573786224	-36.68271555843086	15409
de8c3378a1ede7c445dbb5efb549bdd7978b3065	hmm-based fast detection of false data injections in advanced metering infrastructure		"""Smart grids not only provide """"intelligence"""" to the next generation power systems, but also potentially introduce vital security and privacy issues. Particularly, as a core part of the smart grids, advanced metering infrastructure (AMI) is suffering widespread disputes in terms of security and privacy concerns. This paper proposes a novel hidden Markov model (HMM) based method to detect false data injection attacks in AMI. In this method, a global-state HMM of the whole-house appliances is built and trained by sufficient historical meter data in an offline mode. Then, a new fast Viterbi algorithm is devised to decode the hidden states of the HMM. The decoded states are then verified via the partial sub-meter data in an online mode, by which false data can be detected. The effectiveness and efficiency of our method are verified by a public dataset AMPds with one- year real-time meter data."""	airplane mode;experiment;hidden markov model;ibm power systems;markov chain;online and offline;privacy;real-time clock;smart meter;viterbi algorithm	Beibei Li;Rongxing Lu;Gaoxi Xiao	2017	GLOBECOM 2017 - 2017 IEEE Global Communications Conference	10.1109/GLOCOM.2017.8254498	viterbi algorithm;electric power system;real-time computing;smart grid;hidden markov model;metering mode;metre (music);computer science	Security	-15.828847293393977	-29.15981110143272	15473
35cfbc5310efec22021607ef7aa948b8c7f6ebda	ranking causal anomalies for system fault diagnosis via temporal and dynamical analysis on vanishing correlations		Detecting system anomalies is an important problem in many fields such as security, fault management, and industrial optimization. Recently, invariant network has shown to be powerful in characterizing complex system behaviours. In the invariant network, a node represents a system component and an edge indicates a stable, significant interaction between two components. Structures and evolutions of the invariance network, in particular the vanishing correlations, can shed important light on locating causal anomalies and performing diagnosis. However, existing approaches to detect causal anomalies with the invariant network often use the percentage of vanishing correlations to rank possible casual components, which have several limitations: (1) fault propagation in the network is ignored, (2) the root casual anomalies may not always be the nodes with a high percentage of vanishing correlations, (3) temporal patterns of vanishing correlations are not exploited for robust detection, and (4) prior knowledge on anomalous nodes are not exploited for (semi-)supervised detection. To address these limitations, in this article we propose a network diffusion based framework to identify significant causal anomalies and rank them. Our approach can effectively model fault propagation over the entire invariant network and can perform joint inference on both the structural and the time-evolving broken invariance patterns. As a result, it can locate high-confidence anomalies that are truly responsible for the vanishing correlations and can compensate for unstructured measurement noise in the system. Moreover, when the prior knowledge on the anomalous status of some nodes are available at certain time points, our approach is able to leverage them to further enhance the anomaly inference accuracy. When the prior knowledge is noisy, our approach also automatically learns reliable information and reduces impacts from noises. By performing extensive experiments on synthetic datasets, bank information system datasets, and coal plant cyber-physical system datasets, we demonstrate the effectiveness of our approach.	anomaly detection;causal filter;complex system;computer security;cyber-physical system;data mining;distributed computing;dynamical system;experiment;information system;mathematical optimization;real life;scalability;sensor;software propagation;synthetic intelligence;type signature	Wei Cheng;Jingchao Ni;Kai Zhang;Haifeng Chen;Guofei Jiang;Yu Shi;Xiang Zhang;Wei Wang	2017	TKDD	10.1145/3046946	invariant (physics);machine learning;artificial intelligence;data mining;complex system;fault management;invariant (mathematics);inference;mathematics;ranking;non-negative matrix factorization	ML	-14.82321827781753	-41.6011761103854	15545
626c51027bf9d36509c3fd97b66319ce0d9b945b	the playmate system		Research in CoSy was scenario driven. Two scenarios were created, the PlayMate and the Explorer. One of the integration goals of the project was to build integrated systems that addressed the tasks in these two scenarios. This chapter concerns the integrated system for the PlayMate scenario. The work described here on the PlayMate scenario is concerned with understanding, at a systems level, the problems that an intelligent system must face if it must interact with humans in an object rich environment. In particular the goal is to understand how a robot can interact with a human in a space in which they both manipulate objects, and in which they can talk about those objects. This requires many abilities. The robot must be able to understand and generate references to objects, actions with them, their properties and spatial relationships. It must understand how actions alter the relationships between objects, be able to recognise actions the human performs with objects, and it must be able to learn about the effects of actions on objects, both by discovery and by watching others. If there are several opportunities for action it must choose between a number of potential goals at any one time.	artificial intelligence;cosy (computer conferencing system);integrated development environment;robot	Nick Hawes;Jeremy L. Wyatt;Mohan Sridharan;Marek Sewer Kopicki;Somboon Hongeng;Ian Calvert;Aaron Sloman;Geert-Jan M. Kruijff;Henrik Jacobsson;Michael Brenner;Danijel Skocaj;Alen Vrecko;Nikodem Majer;Michael Zillich	2010		10.1007/978-3-642-11694-0_9	simulation;question answering;computer science	Robotics	-33.19725593687641	-40.85470197986795	15547
47c9fc9040e4d8252a53cca32fa74de5423014f4	segmenting customer transactions using a pattern-based clustering approach	cluster algorithm;pattern clustering;customer relationship management;customer loyalty;data mining;transaction data;data analysis data mining information management clustering algorithms itemsets credit cards cellular phones pricing postal services advertising;internet;mixture model;internet customer transactions segmentation pattern based clustering marketing data mining user centric web usage data yaca technique;transaction processing;data mining transaction processing customer relationship management pattern clustering internet	"""Grouping customer transactions into categories helps understand customers better. The marketing literature has concentrated on identifying important segmentation variables (e.g. customer loyalty) and on using clustering and mixture models for segmentation. The data mining literature has provided various clustering algorithms for segmentation. We investigate using """"pattern-based"""" clustering approaches to grouping customer transactions. We argue that there are clusters in transaction data based on natural behavioral patterns, and present a new technique, YACA, that groups transactions such that itemsets generated from each cluster, while similar to each other, are different from ones generated from others. We present experimental results from user-centric Web usage data that demonstrates that YACA generates a highly effective clustering of transactions."""		Yinghui Yang;Balaji Padmanabhan	2003		10.1109/ICDM.2003.1250947	customer relationship management;the internet;transaction processing;loyalty business model;computer science;transaction data;mixture model;data mining;database;customer intelligence	ML	-4.5790375483130275	-33.694470888877596	15559
bf8dc2f780032f5192738890d252ad89a8a9777b	identifying and characterizing truck stops from gps data		Information about truck stops in highways is essential for trip planning, monitoring and other applications. GPS data of truck movement can be very useful to extract information that helps us understand our highway network better. In this paper, we present a method to identify truck stops on highways from GPS data, and subsequently characterize the truck stops into clusters that reflects their functionality. In the procedure, we extract the truck stoppage locations from the GPS data and cluster the stoppage points of multiple trips to obtain truck stops. We construct arrival time distribution and duration distribution to identify the functional nature of the stops. Subsequently, we cluster the truck stops using the above two distributions as attributes. The resultant clusters are found to be representative of different types of truck stops. The characterized truck stoppages can be useful for dynamic trip planning, behavior modeling of drivers and traffic incident detection.	global positioning system	Russel Aziz;Manav Kedia;Soham Dan;Sayantan Basu;Sudeshna Sarkar;Sudeshna Mitra;Pabitra Mitra	2016		10.1007/978-3-319-41561-1_13	real-time computing;trips architecture;truck;global positioning system;cluster analysis;data analysis;business	ML	-17.508969768008804	-32.03195860266188	15581
1af08944ccddf031bcbec9befb251cb62a30b162	designing pixel-oriented visualization techniques: theory and applications	journal_article;visualizing large data sets;spatial data;multidimensional data;information visualization;visualizing multidimensional and multivariate data;subwindows pixel oriented visualization techniques multidimensional information very large multidimensional data sets data objects visual data exploration optimization problems colors;optimization problem;data visualisation;visualization technique;visual data mining;data visualization multidimensional systems design optimization data mining information analysis shape data analysis statistical analysis machine learning artificial intelligence;visual data exploration	ÐVisualization techniques are of increasing importance in exploring and analyzing large amounts of multidimensional information. One important class of visualization techniques which is particularly interesting for visualizing very large multidimensional data sets is the class of pixel-oriented techniques. The basic idea of pixel-oriented visualization techniques is to represent as many data objects as possible on the screen at the same time by mapping each data value to a pixel of the screen and arranging the pixels adequately. A number of different pixel-oriented visualization techniques have been proposed in recent years and it has been shown that the techniques are useful for visual data exploration in a number of different application contexts. In this paper, we discuss a number of issues which are of high importance in developing pixel-oriented visualization techniques. The major goal of this article is to provide a formal basis of pixel-oriented visualization techniques and show that the design decisions in developing them can be seen as solutions of well-defined optimization problems. This is true for the mapping of the data values to colors, the arrangement of pixels inside the subwindows, the shape of the subwindows, and the ordering of the dimension subwindows. The paper also discusses the design issues of special variants of pixel-oriented techniques for visualizing large spatial data sets. The optimization functions for the mentioned design decisions are important for the effectiveness of the resulting visualizations. We show this by evaluating the optimization functions and comparing the results to the visualizations obtained in a number of different application. Index TermsÐInformation visualization, visualizing large data sets, visualizing multidimensional and multivariate data, visual data exploration, visual data mining.	algorithm;color;column (database);complete (complexity);computational complexity theory;dspace;data mining;database;decision problem;hoc (programming language);karp's 21 np-complete problems;linear programming;mathematical optimization;np (complexity);np-completeness;ntime;optimization problem;pspace;pixel;polynomial;polynomial-time reduction;precondition;similarity measure;time complexity;travelling salesman problem	Daniel A. Keim	2000	IEEE Trans. Vis. Comput. Graph.	10.1109/2945.841121	optimization problem;visual analytics;information visualization;interactive visual analysis;computer science;data science;theoretical computer science;data mining;mathematics;spatial analysis;data visualization;statistics	Visualization	-7.570290813694572	-38.36236402830017	15610
a556224050531953bdaf481ff378c50942874517	cgdk: an extensible coreldraw vba program for geological drafting	software;excel;coreldraw;cgdk;vba;geological drafting	Corel Geological Drafting Kit (CGDK), a program written in VBA, has been designed to assist geologists and geochemists with their drafting work. It obtains geological data from a running Excel application directly, and uses the data to plot geochemical diagrams and to construct stratigraphic columns. The software also contains functions for creating stereographic projections and rose diagrams, which can be used for spatial analysis, on a calibrated geological map. The user-friendly program has been tested to work with CorelDRAW 13–14–15 and Excel 2003–2007. & 2012 Elsevier Ltd. All rights reserved.	column (database);coreldraw;map projection;spatial analysis;state diagram;stereoscopy;usability;visual basic for applications	Jun-Ting Qiu;Wan-Jiao Song;Cheng-Xin Jiang;Han Wu;Raymond M. Dong	2013	Computers & Geosciences	10.1016/j.cageo.2012.07.020	simulation;visual basic for applications;computer science;computer graphics (images)	HCI	-27.941788688564397	-29.06293586564021	15653
18bb1914c8710cb178b05e95a6559d7be24b574b	multi-objective community detection method by integrating users' behavior attributes	community detection;attribute categorization;structure clustering;multi objective optimization;behavior analysis	Social networks usually have abundant attributes associated with users to describe their features. Behavior attribute is one of the most important types of attribute which can better reflect users' intrinsic interests. In practice, many network applications prefer communities that not only are densely intraconnected, but also have homogeneous attribute value on specific behavior attributes. Structure clustering and attribute categorization are two types of method which can take full advantage of structure information and attribute information to partition the network, respectively. In this paper, we propose a novel community detection method by realizing structure clustering technology and attribute categorization technology simultaneously. Specifically, structure clustering is realized by optimizing modularity which captures densely intra-connected nature of communities. As for attribute categorization, a new metric named as homogeneity is defined to achieve the goal that nodes within each community have homogeneous attribute value, while in different communities have diverse attribute values. A multiobjective optimization evolutionary mechanism is adopted to optimize modularity and homogeneity simultaneously. Extensive experiments on several real-world networks demonstrate that our method can get a set of community structures corresponding to different trade-offs between structure clustering and attribute categorization. & 2016 Elsevier B.V. All rights reserved.	attribute grammar;categorization;cluster analysis;computation;entropy (information theory);evolutionary algorithm;experiment;mathematical optimization;maxima and minima;multi-objective optimization;parallel computing;shannon (unit);time complexity	Peng Wu;Li Pan	2016	Neurocomputing	10.1016/j.neucom.2015.11.128	variable and attribute;computer science;multi-objective optimization;machine learning;pattern recognition;data mining	DB	-13.96925067054556	-43.926846029713616	15660
d2de2eb8eabeb6d9afd2ffd7470e4154a6bd4477	system dynamics modeling of environmental systems			environment (systems);system dynamics	Andrew Ford	2007		10.1201/9781420010855.ch27	environmental science;system dynamics;control engineering	Robotics	-11.649939032857507	-26.30590983802102	15817
11256a3695e1313bc0989935a94ee80342e25cd1	automatically synthesizing sql queries from input-output examples	query processing;sql;database textbook exercises automatic sql query synthesis input output examples computer end users database query programming by example technique sqlsynthesizer tool forum questions sql query writing;sql query processing;databases skeleton aggregates writing standards syntactics graphical user interfaces	Many computer end-users, such as research scientists and business analysts, need to frequently query a database, yet lack enough programming knowledge to write a correct SQL query. To alleviate this problem, we present a programming by example technique (and its tool implementation, called SQLSynthesizer) to help end-users automate such query tasks. SQLSynthesizer takes from users an example input and output of how the database should be queried, and then synthesizes a SQL query that reproduces the example output from the example input. If the synthesized SQL query is applied to another, potentially larger, database with a similar schema, the synthesized SQL query produces a corresponding result that is similar to the example output. We evaluated SQLSynthesizer on 23 exercises from a classic database textbook and 5 forum questions about writing SQL queries. SQLSynthesizer synthesized correct answers for 15 textbook exercises and all 5 forum questions, and it did so from relatively small examples.	ibm notes;input/output;programming by example;sql;test automation;usability testing	Sai Zhang;Yuyin Sun	2013	2013 28th IEEE/ACM International Conference on Automated Software Engineering (ASE)	10.1109/ASE.2013.6693082	materialized view;sargable;data definition language;query optimization;sql;.ql;web query classification;sql injection;stored procedure;computer science;query by example;user-defined function;data mining;autocommit;database;sql/psm;temporal database;language integrated query;programming language;web search query;view;information retrieval;null;query language;object query language;spatial query	DB	-31.73482907296393	-30.379256098401378	15860
75cdf9cd279d6ff4d60e1e3c2d7120c4060e435b	efficient and effective similarity search on complex objects	ddc 500;fakultat fur mathematik informatik und statistik;ddc 510	Due to the rapid development of computer technology and new methods for the extraction of data in the last few years, more and more applications of databases have emerged, for which an efficient and effective similarity search is of great importance. Application areas of similarity search include multimedia, computer aided engineering, marketing, image processing and many more. Special interest adheres to the task of finding similar objects in large amounts of data having complex representations. For example, setvalued objects as well as tree or graph structured objects are among these complex object representations. The grouping of similar objects, the socalled clustering, is a fundamental analysis technique, which allows to search through extensive data sets. The goal of this dissertation is to develop new efficient and effective methods for similarity search in large quantities of complex objects. Furthermore, the efficiency of existing density-based clustering algorithms is to be improved when applied to complex objects. The first part of this work motivates the use of vector sets for similarity modeling. For this purpose, a metric distance function is defined, which is suitable for various application ranges, but time-consuming to compute. Therefore, a filter refinement technology is suggested to efficiently process range queries and k-nearest neighbor queries, two basic query types within the field of similarity search. Several filter distances are presented, which approximate the exact object distance and can be computed efficiently. Moreover, a multi-step query processing approach is described, which can be directly integrated into the well-known density-based clustering algorithms	approximation algorithm;cluster analysis;computer;database;image processing;k-nearest neighbors algorithm;range query (data structures);refinement (computing);similarity search;whole earth 'lectronic link	Stefan Brecheisen	2007			computer science;theoretical computer science;machine learning;consensus clustering;data mining;cluster analysis	DB	-5.717170213910058	-39.9562393953055	15888
995d56f8c9bfde9b8bdc1d0220279367d67ea0c3	study on an assistive robot for improving imitation skill of children with autism	humanoid robot;executable specification;real time;human robot interaction;principal component analysis;robot mimicking;expectation maximization algorithm;motion planning;children with autism;imitation skill	In this paper, we report the effectiveness of a therapeutic humanoid robot for children with autism to improve his/her imitation skill. In order to realize this system, a robot has to provide two functions: mimicking and evaluating the child's motion in real time. The former function is achieved by selecting key frames using the Q-Learning approach to remove noisy camera data. The latter is established via a cluster-based framework on Mixture Gaussian and Expectation-Maximization algorithm using parameters which are converted by Principal Component Analysis. Practical experiments are shown in which autistic children interact with a robot and are trained by executing specific tasks for improving imitation skill.	assistive technology;robot	Isao Fujimoto;Tohru Matsumoto;P. Ravindra De Silva;Masakazu Kobayashi;Masatake Higashi	2010		10.1007/978-3-642-17248-9_24	simulation;computer science;artificial intelligence;social robot;communication	Robotics	-31.37175580386779	-40.583360693485496	16042
e6f295b270c87e722866d9cd0495aa2450c3a20b	the dynamics of repeat consumption	repeat consumption;recency;quality;copying process	We study the patterns by which a user consumes the same item repeatedly over time, in a wide variety domains ranging from check-ins at the same business location to re-watches of the same video. We find that recency of consumption is the strongest predictor of repeat consumption. Based on this, we develop a model by which the item from $t$ timesteps ago is reconsumed with a probability proportional to a function of t. We study theoretical properties of this model, develop algorithms to learn reconsumption likelihood as a function of t, and show a strong fit of the resulting inferred function via a power law with exponential cutoff. We then introduce a notion of item quality, show that it alone underperforms our recency-based model, and develop a hybrid model that predicts user choice based on a combination of recency and quality. We show how the parameters of this model may be jointly estimated, and show that the resulting scheme outperforms other alternatives.	additive model;algorithm;kerrison predictor;time complexity	Ashton Anderson;Ravi Kumar;Andrew Tomkins;Sergei Vassilvitskii	2014		10.1145/2566486.2568018	simulation	Web+IR	-18.84120820377106	-39.15720057863843	16071
b236fb5bfdc7efcc7de8f1f372c1aff7f92603b9	safe driving in la: report from the greatest intervehicular accident detection test ever	road accidents;vehicular and wireless technologies design for experiments prototypes vehicle safety vehicular ad hoc network vanet testbed;highway pileups safe driving intervehicular accident detection test sensor technology communication technology vehicular ad hoc network accident warning system algorithm bandwidth usage;vehicular ad hoc networks;vehicular ad hoc networks road accidents road safety;vehicles accidents relays alarm systems roads;road safety	The UN Economic Commission's Statistics of Road Traffic Accidents report of 2011 shows that every year, about 150 000 human beings lose their lives on the roads of the western world. Although it is a common belief that this figure could shrink with the use of new sensor and communication technologies, unfortunately, none such systems have hit the road to date. Ideally, if such technologies were put into place, vehicles could be part of a vehicular ad hoc network (VANET) capable of spreading relevant information about dangerous events (e.g., car accidents) to all approaching drivers. However, all this is mainly supported by simulation studies, as no practical results have been published to date, revealing the effective performances of such systems at work. In this paper, we fill this gap, presenting a detailed description of the greatest experiments (a few thousand throughout the streets of Los Angeles), to date, ever performed with an accident warning system specifically devised for highway scenarios. In particular, among all the possible candidate schemes, we ran a few thousand experiments with the accident warning system algorithm that was proven to be optimal in terms of bandwidth usage and covered distance in realistic scenarios. Our experiments confirm what has been observed before in theory and simulation, i.e., the use of such a system can reduce, by as much as 40%, the amount of vehicles involved in highway pileups.	algorithm;device driver;experiment;hoc (programming language);nicoll highway collapse;performance;simulation;systems theory	Gustavo Marfia;Marco Roccetti;Alessandro Amoroso;Giovanni Pau	2013	IEEE Transactions on Vehicular Technology	10.1109/TVT.2012.2226484	simulation;engineering;transport engineering;computer security;computer network	Mobile	-18.526546096662265	-27.82014948770682	16076
07760a9491f2e0f7a7aa96ab72b7394fc8c690bc	a review of the use of examples for automating architectural design tasks		Abstract Recent Artificial Intelligence studies have achieved substantial improvements in practical tasks by using extensive amounts of data. We assume that a substantial part of the data to guide artificial design technologies resides in existing design examples. Developing ways to use this data may enable improvements in intelligent design tools, with the hope that these may provide more effective design workflows and more productive design practices. Such improvements may result in more in-depth evaluations of potentials and alternatives for design situations; hence better planning for the spatial environment. Various approaches have been developed to use representations of architectural examples for artificially tackling architectural design tasks. This study presents a review of the historical development of these approaches, with an overall aim to investigate where and how design examples have been used for practical computational design applications. The review encompasses traditional and recent Shape Grammar and Procedural Modeling studies, Case-Based Design, Similarity-Based Evaluation and Design, and recent studies on the architectural uses of Machine Vision, Semantic Modeling, Machine Learning, and Classification. The emphasis of the review is on the studies that aim at designing or generating new design examples, particularly for building layouts, facades, envelopes, and massing. For a comparative evaluation of the current capabilities of the examined lineages of studies, we propose a minimum set of design capabilities, and assess each study through this framework. This reveals the overall patterns of already covered requirements. The review shows that initial hand-operated SGs gave way to automatic generation, which in turn developed into automated SG extraction, through increasing levels of computational capabilities. Case-Based Design has been neglected; however, it can be reinvigorated through novel AI techniques. On the other hand, Similarity-Based Evaluation may complement and balance the orientation towards technical performance. Machine Learning and Computer Vision appear as potential intermediaries for connecting these threads. There are example-based studies towards almost all aspects of artificial design; yet, these have not been tackled adequately or definitively. In particular, dynamic process control is still only a future potential. On the other hand, the examined research lineages have the potential to assume complementary roles for more capable and multifaceted design systems. As an overall result, example-based research perspectives raise important possibilities for intelligent design systems.		Onur Nizam Sonmez	2018	Computer-Aided Design	10.1016/j.cad.2017.10.005	computer-automated design;probabilistic design;systems engineering;environmental graphic design;high-level design;conceptual design;design technology;design language;generative design;computer science	EDA	-29.05649272761018	-27.668260723844536	16077
3be2609d565f436611090bf5201f73543b3d0610	learning hierarchical representation model for nextbasket recommendation	会议论文;sequential behavior;next basket recommendation;hierarchical representation model;general taste	Next basket recommendation is a crucial task in market basket analysis. Given a user's purchase history, usually a sequence of transaction data, one attempts to build a recommender that can predict the next few items that the user most probably would like. Ideally, a good recommender should be able to explore the sequential behavior (i.e., buying one item leads to buying another next), as well as account for users' general taste (i.e., what items a user is typically interested in) for recommendation. Moreover, these two factors may interact with each other to influence users' next purchase. To tackle the above problems, in this paper, we introduce a novel recommendation approach, namely hierarchical representation model (HRM). HRM can well capture both sequential behavior and users' general taste by involving transaction and user representations in prediction. Meanwhile, the flexibility of applying different aggregation operations, especially nonlinear operations, on representations allows us to model complicated interactions among different factors. Theoretically, we show that our model subsumes several existing methods when choosing proper aggregation operations. Empirically, we demonstrate that our model can consistently outperform the state-of-the-art baselines under different evaluation metrics on real-world transaction data.	affinity analysis;baseline (configuration management);human race machine;interaction;nonlinear system;recommender system;transaction data	Pengfei Wang;Jiafeng Guo;Yanyan Lan;Jun Xu;Shengxian Wan;Xueqi Cheng	2015		10.1145/2766462.2767694	computer science;machine learning;data mining;world wide web	Web+IR	-18.78018531775955	-47.76074024472712	16084
c85bcb66571351e29872eca4458b983699ae0339	balanced graph partitioning with apache spark	approximated algorithm;graph partitioning;distributed algorithm	A significant part of the data produced every day by online services is structured as a graph. Therefore, there is the need for efficient processing and analysis solutions for large scale graphs. Among the others, the balanced graph partitioning is a well known NP-complete problem with a wide range of applications. Several solutions have been proposed so far, however most of the existing state-of-the-art algorithms are not directly applicable in very large-scale distributed scenarios. A recently proposed promising alternative exploits a vertex-center heuristics to solve the balance graph partitioning problem. Their algorithm is massively parallel: there is no central coordination, and each node is processed independently. Unfortunately, we found such algorithm to be not directly exploitable in current BSP-like distributed programming frameworks. In this paper we present the adaptations we applied to the original algorithm while implementing it on Spark, a state-of-the-art distributed framework for data processing.	algorithm;apache spark;consistency model;distributed computing;e-services;experiment;graph (discrete mathematics);graph partition;heuristic (computer science);np-completeness;order of approximation;partition problem;performance;requirement;simulation	Emanuele Carlini;Patrizio Dazzi;Andrea Esposito;Alessandro Lulli;Laura Ricci	2014		10.1007/978-3-319-14325-5_12	distributed algorithm;parallel computing;graph bandwidth;computer science;graph partition;theoretical computer science;machine learning;database;distributed computing;moral graph;reverse-delete algorithm	ML	-10.755963777650532	-40.710261765241015	16153
87d1c1e1f7687919cb5a4d96ccbab49267eae99d	identification of substructures in complex networks using formal concept analysis		PurposernrnrnrnrnIn recent years, the increasing complexity of the hyper-connected world demands new approaches for social network analysis. The main challenges are to find new computational methods that allow the representation, characterization and analysis of these social networks. Nowadays, formal concept analysis (FCA) is considered an alternative to identifying conceptual structures in a social network. In this FCA-based work, this paper aims to show the potential of building computational models based on implications to represent and analyze two-mode networks.rnrnrnrnrnDesign/methodology/approachrnrnrnrnrnThis study proposes an approach to find three important substructures in social networks such as conservative access patterns, minimum behavior patterns and canonical access patterns. The present study approach considered as a case study a database containing the access logs of a cable internet service provider.rnrnrnrnrnFindingsrnrnrnrnrnThe result allows us to uncover access patterns, conservative access patterns and minimum access behavior patterns. Furthermore, through the use of implications sets, the relationships between event-type elements (websites) in two-mode networks are analyzed. This paper discusses, in a generic form, the adopted procedures that can be extended to other social networks.rnrnrnrnrnOriginality/valuernrnrnrnrnA new approach is proposed for the identification of conservative behavior in two-mode networks. The proper implications needed to handle minimum behavior pattern in two-mode networks is also proposed to be analyzed. The one-item conclusion implications are easy to understand and can be more relevant to anyone looking for one particular website access pattern. Finally, a method for a canonical behavior representation in two-mode networks using a canonical set of implications (steam base), which present a minimal set of implications without loss of information, is proposed.		Sebastião M. Neto;Sérgio Dias;Rokia Missaoui;Luis E. Zárate;Mark A. J. Song	2018	IJWIS	10.1108/IJWIS-10-2017-0067	cable internet access;service provider;data mining;social network analysis;complex network;computer science;computational model;social network;formal concept analysis;behavioral pattern	AI	-21.93020408462743	-43.84900740720161	16177
d3fc943845b2fe6441439b8d21f5e3d18116266d	predictive analysis of engine health for decision support	estimation;statistical techniques	Data mining, the discovery of knowledge from data, bridges several disciplines such as database management, artificial intelligence, statistics, visualization and the domain of the data, e.g., biology or engineering. Knowledge discovered by mining the data can be used for various purposes such as developing decision support systems and intelligent tutors. In this paper we present such a data mining problem in the mechanical engineering domain where knowledge discovery from the data is performed using statistical approaches, to conduct predictive analysis for decision support. More specifically, we focus on the engine health problem which consists of using existing data on the behavior of an engine in order to predict whether the engine is capable of functioning well (i.e., it is healthy) and to offer suggestions on preventive maintenance. The data we use for this predictive analysis consists of graphs that plot process parameters such as the vibration and temperature of the engine with respect to time. In this paper we define the problem in detail, propose a solution based on statistical inference techniques, summarize our experimental evaluation and discuss the applications of this work in various fields from a decision support angle.	artificial intelligence;data mining;decision support system	Shubhabrata Mukherjee;Aparna S. Varde;Giti Javidi;Ehsan Sheybani	2013	SIGKDD Explorations	10.1145/2641190.2641197	estimation;simulation;intelligent decision support system;computer science;data science;machine learning;data mining;statistics	DB	-10.659104953420723	-47.90316964485716	16179
09ab6d159924d8311eb9cd162f3bdec26bda1f13	collection and analysis of multi-dimensional network data for opportunistic networking research	complex networks;opportunistic networks;human mobility;multi dimensional network analysis;eurecom ecole d ingenieur telecommunication centre de recherche graduate school research center communication systems;online social networks;facebook;twitter;gowalla	Opportunistic networks use human mobility and consequent wireless contacts between mobile devices to disseminate data in a peer-to-peer manner. Designing appropriate algorithms and protocols for such networks is challenging as it requires understanding patterns of (1) mobility (who meets whom), (2) social relations (who knows whom) and (3), communication (who communicates with whom). To date, apart from few small test setups, there are no operational opportunistic networks where measurements could reveal the complex correlation of these features of human relationships. Hence, opportunistic networking research is largely based on insights from measurements of either contacts, social networks, or communication, but not all three combined. In this paper we analyze two datasets comprising social, mobility and communication ties. The first dataset we have collected with Stumbl, a Facebook application that lets participating users report their daily face-to-face meetings with other Facebook friends. It also logs user interactions on Facebook (e.g. comments, wall posts, likes). For the second dataset, we use data from two online social networks (Twitter and Gowalla) on the same set of nodes to infer social, communication and mobility ties. We look at the interplay of the different dimensions of relationships on a pairwise level and analyze how the network structures compare to each other. 2012 Elsevier B.V. All rights reserved.	algorithm;application programming interface;cluster analysis;complex network;facebook platform;interaction;level of detail;link-state routing protocol;mobile device;peer-to-peer;small-world experiment;social network;video game developer	Theus Hossmann;George Nomikos;Thrasyvoulos Spyropoulos;Franck Legendre	2012	Computer Communications	10.1016/j.comcom.2012.05.003	telecommunications;computer science;data mining;internet privacy;world wide web;computer security;complex network;computer network	Metrics	-20.216983992389647	-41.6685311651987	16225
62fea01d9eb6442e7c812540a14ed8b4a8a00e1f	a contextual random walk model for automated playlist generation		In this paper, we propose new methods for generating playlists with a single graph, which represents multiple types of relations in a playlist. Although current users are familiar with online music services, they have difficulty in deciding which tracks to listen to because there are millions of tracks available on such services. Automated playlist generation is one of the best solutions to solving this costly task of finding interesting tracks from the enormous tracks. Accordingly, one playlist-generation task, namely, hit rate, in which several tracks are given as a user query, is focused on in this study. There are four types of context objects (playlists, tracks, artists, and users) in the basic information on playlists, and three types of relations (playlists contain tracks and artists, users create playlists and artists play and/or sing tracks) in playlists. First, different types of relations in playlists are combined, and a single graph linking different context objects is generated. Next, a random walk is applied to the graph, and the expected values of track nodes are calculated on the basis of the transition probabilities of nodes in the graph. Finally, tracks are recommended in order of the expected values. The results of an experimental evaluation of the proposed methods in comparison with conventional methods revealed that one of the proposed methods (RW-hybrid) improved effectiveness by up to 21%. Moreover, this method reduces execution time as much as the fastest existing methods.		Seiji Ueda;Atsushi Keyaki;Jun Miyazaki	2018	2018 IEEE/WIC/ACM International Conference on Web Intelligence (WI)	10.1109/WI.2018.00-66	random walk;data mining;information retrieval;task analysis;computer science;hit rate;context model;graph	Web+IR	-27.731315539725802	-48.832673323773086	16226
a0cc3363f718aa560e6eb7dd7f80101e638c3c62	efficient recompression techniques for dynamic full-text retrieval systems	information retrieval system;information retrieval;text retrieval;on the fly;optimal algorithm	An efficient variant of an optimal algorithm is presented, which, in the context of a large dynamic fulltext information retrieval system, reorganizes data that has been compressed by an on-the-fly compression method based on LZ77, into a more compact form, without changing the decoding procedure. The algorithm accelerates a known technique based on a reduction to a graph-theoretic problem, by reducing the size of the graph, without affecting the optimality of the solution. The new method can thus effectively improve any dictionary compression scheme using a static encoding method.	algorithm;dictionary coder;document retrieval;graph theory;information retrieval;lz77 and lz78	Shmuel Tomi Klein	1995		10.1145/215206.215330	computer science;concept search;data mining;database;adversarial information retrieval;information retrieval	Web+IR	-7.182525919519112	-42.502199661403374	16251
87e10066aa50ed0f6d2d4ca5d34f8c31757e7778	a crowd-sourced approach for monitoring asian elephants outside protected areas	geographic information systems;mobile handsets computerised monitoring geographic information systems mobile computing;mobile handsets;elephant movement prediction asian elephants monitoring protected areas nature conservation mobile phone based system crowd sourced elephant tracking system geo referenced grid;computerised monitoring;mobile computing;hardware tracking databases electrocardiography	Although nature conservation has traditionally relied on the creation of vast human free areas, the focus is now widening to also include `buffer' and `corridor' areas that also include human dominated landscapes. This is especially true for a country like India, with a high population density of over 400 people per sq km, while also being home to two thirds of the world's Asian elephants. Human-Wildlife Conflict is now one of the biggest challenges, as a few hundred people are killed every year in India by elephants alone, almost all in accidental encounters. Given that most of these forest areas are now covered by mobile phone networks and that many local people as well as forest guards have mobile phones, it is feasible to conceive of a mobile phone-based system to alert people of approaching elephants. The crowd-sourced elephant tracking system proposed here automatically consolidates information received from multiple contributors through mobile phones into a single geo-referenced grid which can be used by human experts to predict elephant movements and alert villages in their projected path, thus avoiding deaths and injury while also providing valuable previously undocumented information on how elephants use human dominated landscapes.	crowdsourcing;error-tolerant design;mobile phone;tracking system;undocumented feature	Satish Babu;Tarsh Thekaekara	2013	2013 IEEE Global Humanitarian Technology Conference (GHTC)	10.1109/GHTC.2013.6713715	simulation;geography;cartography	HCI	-20.699396602422524	-30.653155104402686	16357
0cf1de5865eca666d4c299cb290b8afcb53ca64e	research on news topic-driven market flucatuation and predication		In order to forecast the price movement of stock with the correlated news events, an enhanced Topic-driven model with the positional weight of feature words and label of stocks, named LP-LDA model, is proposed to represent and analyze the intrinsic mechanism in financial market. The experiment results show that LP-LDA has a better performance than traditional LDA model. Especially, when the number of topics are increasing, the running time of LP-LDA model are 0.69s, 0.78 s and 1.15s at 100, 200 and 300 topics, respectively, which are better than LDA. Furthermore, Degree of Influence (DoI) is defined to describe the considerable influence about the news events on the price movement of certain stock, which provides a new mechanism to measure the fluctuating price. The experiment results shown that the coefficient of correlation between news topic and return rate of stock is 0.9137, which is much higher than other results of experiment.	coefficient;lp-type problem;time complexity	Yuan Rao;Xuhui Zhong;Shumin Lu	2016	2016 International Conference on Identification, Information and Knowledge in the Internet of Things (IIKI)	10.1109/IIKI.2016.93	financial economics;instrumental and intrinsic value;probability distribution;computer network;financial market;stock (geology);computer science;rate of return;statistical classification;data processing	ML	-8.998320174665825	-30.827086324972615	16387
f6b77297c4dd2da32f994203408f0f87de1263dc	computing through scientific abstractions in sysbiopse	system biology problem solving environment scientific computing biologists bioinformaticists scientific abstractions cognitive computational framework;computers;scientific abstractions;biology computing;cybernetics;general and miscellaneous mathematics computing and information science;information systems;bioinformaticists;biology computing bioinformatics problem solving scientific computing computational biology biological system modeling systems biology genomics pervasive computing cells biology;availability;scientific data;scientific workflow;abstract data types;cognitive computational framework;information dissemination problem solving environments;biologists;biology;research and development;visual modeling;system biology;scientific computing;evaluation;computational biology;problem solving environment;system biology problem solving environment;biomedical computing;scientific information systems;problem solving;scientific information systems abstract data types biology computing problem solving;pacific northwest	At Pacific Northwest National Laboratory, we are researching and developing scientific computing environments for biologists and bioinformaticists. Important issues for us are how to motivate biologists to use new computational technologies and how to best incorporate and integrate disparate computational resources into computational biology research. In recent efforts, we have focused on the development of tools that support specific scientific abstractions or models that may be used as cognitive computational frameworks for biologists. The specific tools allow biologists to view and organize their computational work along the scientific concepts and theories that are under investigation, the experimental processes that are being carried out, and the logical structures and properties of the scientific data being examined and explored. This collection of tools and their underlying framework comprise a system known as SysBioPSE (system biology problem solving environment)	computational biology;computational resource;computational science;problem solving environment;systems biology;theory	George Chin;Eric G. Stephan;Deborah K. Gracio	2004	2004 IEEE International Conference on Systems, Man and Cybernetics (IEEE Cat. No.04CH37583)	10.1109/ICSMC.2004.1398275	computational biology;computational science;availability;cybernetics;computer science;artificial intelligence;evaluation;abstract data type;information system;data	HPC	-5.712762744001361	-51.01091721686226	16403
672311a4e4c891133e4b2663f6307287a42a731a	zipnet-gan: inferring fine-grained mobile traffic patterns via a generative adversarial neural network		Large-scale mobile traffic analytics is becoming essential to digital infrastructure provisioning, public transportation, events planning, and other domains. Monitoring city-wide mobile traffic is however a complex and costly process that relies on dedicated probes. Some of these probes have limited precision or coverage, others gather tens of gigabytes of logs daily, which independently offer limited insights. Extracting fine-grained patterns involves expensive spatial aggregation of measurements, storage, and post-processing. In this paper, we propose a mobile traffic super-resolution technique that overcomes these problems by inferring narrowly localised traffic consumption from coarse measurements. We draw inspiration from image processing and design a deep-learning architecture tailored to mobile networking, which combines Zipper Network (ZipNet) and Generative Adversarial neural Network (GAN) models. This enables to uniquely capture spatio-temporal relations between traffic volume snapshots routinely monitored over broad coverage areas (u0027low-resolutionu0027) and the corresponding consumption at 0.05 km2 level (u0027high-resolutionu0027) usually obtained after intensive computation. Experiments we conduct with a real-world data set demonstrate that the proposed ZipNet(-GAN) infers traffic consumption with remarkable accuracy and up to 100X higher granularity as compared to standard probing, while outperforming existing data interpolation techniques. To our knowledge, this is the first time super-resolution concepts are applied to large-scale mobile traffic analysis and our solution is the first to infer fine-grained urban traffic patterns from coarse aggregates.	artificial neural network;computation;deep learning;experiment;gigabyte;image processing;image resolution;interpolation;marco dorigo;peak signal-to-noise ratio;provisioning;requirement;shadow copy;structural similarity;super-resolution imaging;traffic analysis;video post-processing	Chaoyun Zhang;Xi Ouyang;Paul Patras	2017		10.1145/3143361.3143393	image processing;traffic analysis;distributed computing;artificial neural network;granularity;architecture;deep learning;computer science;provisioning;analytics;artificial intelligence	ML	-15.14344978225884	-30.275246867133937	16489
a298f2cccefa4c69be7d62ea72fdb24259018359	recommendations beyond the ratings matrix	data driven innovation;social data;big data;information hunting;recommendation systems	Recommender systems have become indispensable for several Web sites, such as Amazon, Netflix and Google News, helping users navigate through the abundance of available choices. Although the field has advanced impressively in the last years with respect to models, usage of heterogeneous information, such as ratings and text reviews, and recommendations for modern applications beyond purchases, almost all of the approaches rely on the data that exist within the recommender and on user explicit input. In a rapidly connected world, though, information is not isolated and does not necessarily lie in the database of a single recommender. Rather, Web offers tremendous amount of information on almost everything, from items to users and their tendency to certain items, but also information on general trends and demographics. We envision an out-of-the-box recommender system that exploits the existing information in a recommender, namely, items, users and ratings, but also explores new sources of information out of the database, like user online traces and online discussions about data items, and exploits them for better and innovative recommendations. We discuss the challenges that such an out-of-the-box approach effects and how it reshapes the field of recommenders.	google news;out of the box (feature);purchasing;recommender system;tracing (software);world wide web	Eirini Ntoutsi;Kostas Stefanidis	2016		10.1145/2911187.2914580	computer science;marketing;data mining;world wide web	Web+IR	-25.96273425901257	-46.79582328079759	16511
99531454d166b9c29ac375c06b7f13ca8bc29e70	path selection: a novel interaction technique for mapping applications	cell phone;path selection;routing;location based reminder;individual object;route selection;lists;pim;bubble targets;ubiquitous computing;bubble cursors;h 5 2 information interfaces and presentation graphical user interfaces gui;selection techniques;location based information delivery;user satisfaction;interaction technique	Many online mapping applications let users define routes, perhaps for sharing a favorite bicycle commuting route or rating several contiguous city blocks. At the UI level, defining a route amounts to selecting a fairly large number of objects - the individual segments of roads and trails that make up the route. We present a novel interaction technique for this task called path selection. We implemented the technique and evaluated it experimentally, finding that adding path selection to a state-of-the-art technique for selecting individual objects reduced route definition time by about a factor of 2, reduced errors, and improved user satisfaction. Detailed analysis of the results showed path selection is most advantageous (a) for routes with long straight segments and (b) when objects that are optimal click targets also are visually attractive.	computation;computer user satisfaction;emoticon;experiment;feedback;grouplens research;ibm notes;interaction technique;shortest path problem;user interface;web mapping	Michael Ludwig;Reid Priedhorsky;Loren G. Terveen	2009		10.1145/1518701.1519055	routing;simulation;human–computer interaction;computer science;theoretical computer science;operating system;world wide web;ubiquitous computing;personal information manager;interaction technique	HCI	-30.944512977358254	-35.70943167774076	16576
7ad38acc6a5f6b79a6cdaa92426db09bf5d29ed5	a method for community recommendation for social networks	online social networks community recommendation user centric community user interest topic socio psychological issues information propagation;measurement;twitter tagging man machine systems image edge detection measurement informatics;image edge detection;informatics;community recommendation social network twitter data;user interfaces psychology recommender systems social networking online;twitter;man machine systems;tagging	The increasing use of social networks has been beneficial in our daily lives. In this paper we consider the problem of recommending a user centric community based on a user's interest topic, location, and relationship network. Our framework can address some significant socio-psychological issues and also allows to understand information propagation. We consider a user's network structure to calculate the proximity between any two users. We suggest a community recommendation procedure that recommends only the users who are interested in socialization based on several features of a user profile. The recommendation set prunes out bots and cyborgs and it consists of human users only. We have used several properties to analyze a user. We have shown that these properties can be leveraged to improve the performance of the approach in online social networks. We have conducted several experiments using Twitter data. The experimental results illustrate the effectiveness of our approach.	cyborg;experiment;social network;socialization;software propagation;user profile	Soumyajyoti Banerjee;Rajdeep Niyogi	2015	2015 International Conference on Advances in Computing, Communications and Informatics (ICACCI)	10.1109/ICACCI.2015.7275968	computer science;mathematics;multimedia;internet privacy;informatics;world wide web;quantum mechanics;measurement;statistics	DB	-21.123115493747445	-44.94673238035391	16616
2643175087bece90215e7131a48fad0f8a5dce5f	geographic prevalence and mix of regional cuisines in chinese cities		Previous research on the geographies of food put a considerable focus on analyzing how different types of food or ingredients are consumed across different places. Little is known, however, about how food culture is manifested through various cooking traditions as well as people’s perceptions over different culinary styles. Using a data set captured from one of the largest online review sites in China (www.dianping.com), this study demonstrates how geo-referenced social review data can be leveraged to better understand the geographic prevalence and mix of regional cuisines in Chinese cities. Based on information of millions of restaurants obtained in selected cities (i.e., provincial capitals and municipalities under direct supervision of the Chinese central government), we first measure by each city the diversity of restaurants that serve regional Chinese cuisines using the Shannon entropy, and analyze how cities with different characteristics are geographically distributed. A hierarchical clustering algorithm is then used to further explore the similarities of consumers’ dining options among these cities. By associating each regional Chinese cuisine to its origin, we then develop a weighted distance measure to quantify the geographic prevalence of each cuisine type. Finally, a popularity index (POPU) is introduced to quantify consumers’ preferences for different regional cuisines. We find that: (1) diversity of restaurants among the cities shows an “east–west” contrast that is in general agreement with the socioeconomic divide in China; (2) most of the cities have their own unique characteristics, which are mainly driven by a large market share of the corresponding local cuisine; (3) there exists great heterogeneity of the geographic prevalence of different Chinese cuisines. In particular, Chuan and Xiang, which are famous for their spicy taste, are widely distributed across the mainland China and (4) among the top-tier restaurants ranked by the consumers in a city, the local cuisine is not usually favored, while other cuisines are favored by consumers in many different cities. This study demonstrates the use of social review data as a cost-effective approach of studying urban gastronomy and its relationship with human activities.	algorithm;cluster analysis;entropy (information theory);hierarchical clustering;multitier architecture;shannon (unit)	Jingwei Zhu;Yang Xu;Zhixiang Fang;Shih-Lung Shaw;Xingjian Liu	2018	ISPRS Int. J. Geo-Information	10.3390/ijgi7050183	mainland china;regional cuisine;central government;marketing;spatial analysis;china;socioeconomic status;gastronomy;market share;business	Web+IR	-20.78339914467463	-34.71158604798215	16625
3b1cd78a7b49711729f3c58ec6d69bac9bf6e51e	anatomy of a web-scale resale market: a data mining approach	behavioral analysis;e commerce;resale market;big data;ebay;mapreduce;prediction;reseller	"""Reuse and remarketing of content and products is an integral part of the internet. As E-commerce has grown, online resale and secondary markets form a significant part of the commerce space. The intentions and methods for reselling are diverse. In this paper, we study an instance of such markets that affords interesting data at large scale for mining purposes to understand the properties and patterns of this online market.As part of knowledge discovery of such a market, we first formally propose criteria to reveal unseen resale behaviors by elastic matching identification (EMI) based on the account transfer and item similarity properties of transactions. Then, we present a large-scale system that leverages MapReduce paradigm to mine millions of online resale activities from petabyte scale heterogeneous e-commerce data. With the collected data, we show that the number of resale activities leads to a power law distribution with a 'long tail', where a significant share of users only resell in very low numbers and a large portion of resales come from a small number of highly active resellers. We further conduct a comprehensive empirical study from different aspects of resales, including the temporal, spatial patterns, user demographics, reputation and the content of sale postings. Based on these observations, we explore the features related to """"successful"""" resale transactions and evaluate if they can be predictable. We also discuss uses of this information mining for business insights and user experience on a real-world online marketplace."""	data mining;e-commerce;emi;elastic matching;floor and ceiling functions;long tail;mapreduce;online marketplace;petabyte;programming paradigm;user experience;world online	Yuchen Zhao;Neel Sundaresan;Zeqian Shen;Philip S. Yu	2013		10.1145/2488388.2488522	e-commerce;big data;prediction;computer science;database;world wide web;statistics	Web+IR	-20.935953742936576	-44.43406914421946	16676
7156530b0e6105f62b4da602534f1f9f47788d6c	a note on actor network utilities and network evolution	dynamique sociale;reseau social;network evolution;network utilities;social dynamic;dynamic social networks;social network;networks structure;theoreme;network structure;structure	The corrections provided by Xie and Cui [Xie, F., Cui, W., in press. Cost range and network structures. Social Networks, 30] to one of the heorems provided by Doreian [Doreian, P., 2006. Actor network utilities and network evolution. Social Networks, 28, 137–164] are both necessary nd helpful. Accepting these corrections, and linking them more closely to the work of Hummon [Hummon, N.P., 2000. Utility and dynamic social etworks. Social Networks, 22, 221–249], leads to some additional suggestions which, together with a restatement of some earlier results, help set he foundations for future work in this area. 2007 Elsevier B.V. All rights reserved.	network utility;p (complexity);social network;x image extension	Patrick Doreian	2008	Social Networks	10.1016/j.socnet.2007.07.006	organizational network analysis;network science;structure;social dynamics;social science;evolving networks;network formation;dynamic network analysis;artificial intelligence;sociology;operations research;social network	AI	-18.003776126124144	-38.970859827787244	16714
f365b08f9e6b4637ea991f0feeb95c5b53271468	deep learning based recommender systems		Recommender Systems (RSs) are valuable and practical tools that help users to find interesting products in a large space of possible options. Many hybrid recommender systems combine collaborative filtering and content-based approach to build a more robust system. This paper aims to propose a new deep learning based recommender system to enhance recommendation performance and to overcome the limitations of existing approaches, especially when dealing with the cold start problem. So, a hybrid model based on Deep Belief Networks and item-based collaborative filtering is proposed. We conducted experiments on MovieLens 100K dataset. The results showed that our method outperforms existing hybrid recommender systems.		Brahim Ouhbi;Bouchra Frikh;El Moukhtar Zemmouri;Abdellwahed Abbad	2018	2018 IEEE 5th International Congress on Information Science and Technology (CiSt)	10.1109/CIST.2018.8596492	recommender system;deep learning;python (programming language);deep belief network;boltzmann machine;unsupervised learning;machine learning;computer science;artificial intelligence	Web+IR	-18.74114580767153	-50.15388315807567	16733
45b321f73129f712fb70a4b8a87dfe5db32967ea	cave-som: immersive visual data mining using 3d self-organizing maps	neurons three dimensional displays data mining data visualization visualization iris humans;3d visualization;benchmark problem;knowledge extraction;self organising feature maps data mining data visualisation;data mining;multi dimensional;machine learning immersive visual data mining 3d self organizing maps human observer human perception knowledge extraction dimensionality reduction 3d visual data mining framework self organizing map algorithm immersive cave automated virtual environment multidimensional datasets immersive visualization data histogram u matrix input space view wind power generation data decision making;data visualisation;machine learning;self organising feature maps;design and implementation;visual data mining;self organized map;wind power generation;virtual environment;dimensional reduction;human perception	Data mining techniques are becoming indispensable as the amount and complexity of available data is rapidly growing. Visual data mining techniques attempt to include a human observer in the loop and leverage human perception for knowledge extraction. This is commonly allowed by performing a dimensionality reduction into a visually easy-to-perceive 2D space, which might result in significant loss of important spatial and topological information. To address this issue, this paper presents the design and implementation of a unique 3D visual data mining framework - CAVE-SOM. The CAVE-SOM system couples the Self-Organizing Map (SOM) algorithm with the immersive Cave Automated Virtual Environment (CAVE). The main advantages of the CAVE-SOM system are: i) utilizing a 3D SOM to perform dimensionality reduction of large multi-dimensional datasets, ii) immersive visualization of the trained 3D SOM, iii) ability to explore and interact with the multi-dimensional data in an intuitive and natural way. The CAVE-SOM system uses multiple visualization modes to guide the visual data mining process, for instance the data histograms, U-matrix, connections, separations, uniqueness and the input space view. The implemented CAVE-SOM framework was validated on several benchmark problems and then successfully applied to analysis of wind-power generation data. The knowledge extracted using the CAVE-SOM system can be used for further informed decision making and machine learning.	algorithm;benchmark (computing);cave story;cave automatic virtual environment;cluster analysis;data mining;dimensionality reduction;machine learning;organizing (structure);self-organizing map;u-matrix	Dumidu Wijayasekara;Ondrej Linda;Milos Manic	2011	The 2011 International Joint Conference on Neural Networks	10.1109/IJCNN.2011.6033540	computer vision;visualization;computer science;virtual machine;data science;machine learning;data mining;knowledge extraction;data stream mining;perception	ML	-27.371474489876253	-32.06780424718956	16760
caad1cece248ae80b038d3b25c7d417a5419dbb9	effective user interactions for visual analytics tools		In the last few decades, there has formed a layer of traditions in the information processing from different fields of science and technology, which includes a variety of standards, techniques and approaches for visual analysis of diverse types and structures of data. Every year, the advanced technologies of human-computer interaction and computer graphics are becoming closer to information-based areas of activity, providing flexible and adaptive solutions in the implementation of user interfaces for information management and decision-making systems that involving the human-analyst. Taking into account the fact that the resulting quality of activity in various areas of high-tech depends on the ability of studying and mastering of complexly structured storages of multidimensional data, the issue of developing effective user interactions for visual analytics tools is becoming increasingly important. This paper pays attention to the problems and possible solutions of effective visual representation and management of static and dynamic graph-based datasets. Particular attention given to ergonomic approaches of data visualization and concepts of its gesture-based handling and control.	bus mastering;computer graphics;data visualization;human factors and ergonomics;human–computer interaction;information management;information processing;learnability;software framework;user interface;visual analytics	Vladimir Guchev	2017			software analytics;interactive visual analysis;semantic analytics;visual analytics;data science;web analytics;analytics;computer science	Visualization	-29.10963763428288	-31.026279759091857	16774
a9931e6b1655f8d4e325982eb84c118c780928e6	rare association rule mining: a systematic review		One of the indispensable tasks of data mining is the extraction of significant and meaningful association rules. Whereas the extraction of frequent patterns using association rule mining is an imperative field of research, the idea of generating patterns that do not appear frequently in a database has grabbed the attention of researchers in recent years. The infrequent items or more commonly known as the rare items represent unknown or unpredictable associations and are therefore more interesting than the frequent ones. This study aims to provide a broad systematic review of the area of rare association rule mining. In this paper, a methodical analysis of the rare itemset and rare rule generation techniques in static and dynamic environment is presented. This paper also attempts to feature the current status and future perspectives of rare association rule mining along with some major research challenges.	association rule learning;systematic review	Anindita Borah;Bhabesh Nath	2017	IJKEDM	10.1504/IJKEDM.2017.10007846	data mining;association rule learning;computer science	ML	-10.281969860732124	-34.67081540011254	16828
e5785180952a370be81fc1f4cbf444992c13c82b	correlation consistency constrained probabilistic matrix factorization for social tag refinement	matrix factorization;期刊论文;social image;tag refinement;correlation consistency	With the permeation of Web 2.0, large-scale user contributed images with tags are easily available on social websites. However, the noisy or incomplete correspondence between images and tags prohibit us from precise image retrieval and effective management. To tackle this, we propose a social tag refinement method, named as Correlation Consistency constrained Probabilistic Matrix Factorization (CCPMF), to jointly model the interand intra-correlations among images and tags, and further to precisely reconstruct the image–tag correlation as a result. For CCPMF, we attempt to derive two lowrank factors by conducting a joint factorization upon the image–tag correlation matrix. Besides, two types of correlation consistency, i.e., the image–bias correlation consistency (from image similarity to tag relevance) and the tag–bias correlation consistency (from tag relevance to image similarity), are formulated as constraints in the factorization process. Finally, each untagged or noisily tagged image can be retagged according to the reconstructed image–tag correlations with the both derived latent factors. Experimental results on the NUS-WIDE dataset show the encouraging performance of our proposed algorithm over the state-of-the-arts. & 2013 Elsevier B.V. All rights reserved.	algorithm;experiment;folksonomy;image retrieval;information;latent variable;refinement (computing);relevance;tag cloud;web 2.0	Yifan Zhang;Zechao Li;Hanqing Lu	2013	Neurocomputing	10.1016/j.neucom.2012.02.052	pattern recognition;data mining;mathematics;matrix decomposition;information retrieval	AI	-19.17527164626636	-47.24718122819325	16869
854370631d985189927e512929b72306eab3884a	using extended hazard regression model to assess the probability of aviation event	aviation safety;extended hazard regression;proportional hazards;risk assessment	Flight safety has always been the major attention subject in civil aviation in view of the rapid and continuous growth in air transportation traffic volume. The Airline Safety Assessment System, which is currently under development by the Taiwan Civil Aeronautics Administration (CAA), will contain indicators of airline safety performance that can identify potential problem areas for inspectors. The objective of this research is to develop an analytic method that uses data on both accident and performance measures to analyze potential aviation event. The extended hazard regression (EHR) model was conducted to assess the probability of aviation event and analyze how the probability may be affected by airline safety performance. We investigated and demonstrated its applicability in a practical case study.		Huan-Jyh Shyur;Hwa Keng;I Ia-Ka;Cheng-Lung Huang	2012	Applied Mathematics and Computation	10.1016/j.amc.2012.04.029	risk assessment;simulation;aviation safety	Vision	-15.304085044102743	-27.454800346882923	16890
843a50d7e6ef5fac86fea49bf85828a3c29b7d8b	design and exploration of braiding swarms in vr		Swarm-based braiding of structures represents a novel research direction in the domain of building architecture. The idea is that autonomous agents, for instance robots that unroll threads or plants that grow, are programmed or influenced to braid. It is an aspect of biohybrid systems where organisms and robots join forces. In order to harness this idea, we have developed a swarm-based model that allows architects to explore the resulting design spaces in virtual reality. In this paper, we present (1) the model of our swarm-based simulation that aims at growing braided structures, (2) the design elements to guide the otherwise self-organising virtual agents, and (3) the user interface that allows the user to configure, place and grow the swarms of braiding agents. We also present results of a first user study with students and faculty from architecture, in which we tried to capture the usability of our first prototype based on a survey and an analysis of the built results.	autonomous robot;braid;prototype;self-organization;simulation;swarm intelligence;usability testing;user interface;virtual reality	Daniel Wagner;Christian Hofmann;Heiko Hamann;Sebastian von Mammen	2017		10.1145/3139131.3139169	simulation;architecture;autonomous agent;swarm behaviour;robot;usability;computer science;virtual reality;thread (computing);user interface	HCI	-30.571382114480983	-27.210922946113282	16984
cc97b575e3c809b620fe65cddc523b91300d0be6	situation assessment for human-robot interactive object manipulation	ontology human robot interactive object manipulation spatial reasoning interactive robot situation assessment reasoner symbolic knowledge;manipulators;human interaction;spatial reasoning;computer model;spatial reasoning control engineering computing human robot interaction manipulators ontologies artificial intelligence;human robot interaction;natural interaction;three dimensional;ontologies artificial intelligence;computational modeling;three dimensional displays;object manipulation;perspective taking;face;control engineering computing;humans;situation assessment;cameras;humans robot kinematics computational modeling three dimensional displays cameras face;robot kinematics	In daily human interactions spatial reasoning occupies an important place. With this ability we can build relations between objects and people, and we can predict the capabilities and the knowledge of the people around us. An interactive robot is also expected to have these abilities in order to establish an efficient and natural interaction. In this paper we present a situation assessment reasoner, based on spatial reasoning and perspective taking, which generates on-line relations between objects and agents in the environment. Being fully integrated to a complete architecture, this reasoner sends the generated symbolic knowledge to a fact data base which is built on the basis on an ontology and which is accessible to the entire system. This work is also part of a broader effort to develop a complete decisional framework for human-robot interactive task achievement.	automated planning and scheduling;database;interaction;interactive storytelling;online and offline;ontology (information science);robot;semantic reasoner;spatial–temporal reasoning;dialog	Emrah Akin Sisbot;Raquel Ros;Rachid Alami	2011	2011 RO-MAN	10.1109/ROMAN.2011.6005258	human–robot interaction;face;three-dimensional space;computer vision;interpersonal relationship;simulation;computer science;artificial intelligence;spatial intelligence;situation analysis;computational model;robot kinematics	AI	-33.42082343565217	-39.079269380063145	16992
3538d1ed7ae71a8792371c760b896cc8fadaa14a	visualisation of overlapping sets and clusters with euler diagrams. (diagrammes d'euler pour la visualisation de communautés et d'ensembles chevauchants)		In this thesis, we propose a method for the visualisation of overlapping sets and of fuzzy graph clusterings based on Euler diagrams. Euler diagrams are probably the most intuitive and most used method to depict sets in which elements can be shared. Such a powerful visualisation metaphor could be an invaluable visualisation tool, but the automatic generation of Euler diagrams still presents many challenging problems. First, not all instances can be drawn using standard Euler diagrams. Second, most existing algorithms focus on diagrams of modest dimensions while real-world applications typically features much larger data. Third, the generation process must be reliable and reasonably fast. In this thesis, we describe an extended version of Euler diagrams that can be produced for every input instance. We then propose an automatic procedure for the generation of such diagrams that specifically target large input instances. Finally, we present a software implementation of this method and we describe some output examples generated on real-world data.	algorithm;desktop metaphor;diagram;euler characteristic;euler method;euler–lagrange equation;linear algebra	Paolo Simonetto	2011				Graphics	-30.409829436712155	-30.899430051223348	17090
391eb4c999a92345744edd02758531480eea0bf0	a graph-based profile similarity calculation method for collaborative information retrieval	dynamic community;evaluation method;user profile;profile similarity;collaborative information retrieval cir;user interaction;collaborative information retrieval	Collaborative Information Retrieval (CIR) is one of the popular social-based IR approaches. A CIR system registers the previous user interactions to response to the subsequent user queries more efficiently. But CIR suffers from the personalization problem because the goals and the characteristics of two users may be different; so when they send the same query to a CIR system, they may be interested in two different lists of documents. We have developed a personalized CIR system, called PERCIRS, to solve this problem. Selecting an efficient method to calculate the similarity between user profiles is a key factor for enhancing PERCIRS's efficiency. In this paper, we propose a new graph-based method for user profile similarity calculation. Finally, by introducing an evaluation method, we will show that this new method is more efficient than the previous methods.	committed information rate;information retrieval;interaction;lazy evaluation;personalization;user profile	Hassan Naderi;Béatrice Rumpler;Jean-Marie Pinon	2008		10.1145/1363686.1363948	computer science;data mining;database;world wide web;information retrieval	Web+IR	-22.57972031570877	-47.23579330060226	17097
c4ecadfdeb9eeca21c5a222f52dc251c1f94cbe5	botdcat-ap: an extension of the dcat application profile for describing datasets for chatbot systems		Although it is still an emerging technology, the increasing usage of chatbots (also known as bots) has opened a promising touchpoint for citizen and customer engagement. A chatbot consists of a computer program aimed at simulating a conversation between humans and machines through the formulation of appropriate answers making use of external knowledge. Therefore, managing external knowledge is a crucial task for the design and development of chatbots. To facilitate the reuse of existing data sources in chatbot applications, in this paper we propose BotDCAT-AP, an extension of the Data Catalogue (DCAT) Application Profile for describing datasets for chatbots. BotDCAT-AP enables the description of intents (i.e., the actions users want to accomplish by interacting with a chatbot) and entities (i.e., individual information units associated to an intent) supported by a dataset and the method to access it. A practical usage of BotDCAT-AP is shown to demonstrate the value of its adoption.	computer program;entity;interaction;simulation;software agent	Paolo Cappello;Marco Comerio;Irene Celino	2017			chatbot;information retrieval;application profile;computer science	AI	-32.46205398593958	-26.716690176477996	17142
ddf5ad4d482e1685ba5a85ca5d89e9726267b825	som-based data visualization methods	data mining;visualization;vector quantization;projection;data visualization;self organizing map;self organized map;vector quantizer	The self-organizing map SOM is an efficient tool for visualization of multidimensional numerical data. In this paper, an overview and categorization of both old and new methods for the visualization of SOM is presented. The purpose is to give an idea of what kind of information can be acquired from different presentations and how the SOM can best be utilized in exploratory data visualization. Most of the presented methods can also be applied in the more general case of first making a vector quantization e.g. k-means and then a vector projection e.g. Sammon's mapping.	data visualization	Juha Vesanto	1999	Intell. Data Anal.	10.1016/S1088-467X(99)00013-X	computer vision;information visualization;visualization;self-organizing map;projection;computer science;machine learning;data mining;vector quantization;data visualization	Visualization	-27.46334418652772	-32.14808015060304	17149
390aa27c800ea7c1ff97aeb67cff19198df0a340	large-scale multimedia retrieval and mining [guest editors' introduction]	ieee multimedia web event detection landmark detection image annotation musical content mining and cloud computing guest editors introduction;special issues and sections information retrieval data mining large scale systems;multimedia retrieval;special issues and sections;information retrieval;ieee multimedia;event detection;image annotation;data mining;guest editors introduction;landmark detection;large scale;and cloud computing;musical content mining;eurecom ecole d ingenieur telecommunication centre de recherche graduate school research center communication systems;guest editors introduction ieee multimedia web event detection cloud computing image annotation landmark detection musical content mining;web event detection;large scale systems;cloud computing	Rahul Sukthankar Intel Labs and Carnegie Mellon University R ecent years have witnessed an explosive growth of multimedia data due to higher processor speeds, faster networks, wider availability of high-capacity mass-storage devices, and the advent of cloud computing. Stimulated by current work in scalable machine learning, feature indexing and multimodal analysis techniques, researchers are increasingly interested in exploring challenges and new opportunities for developing scalable approaches for multimedia retrieval and mining. The enormous scale of multimedia data is reflected in the following statistics: approximately 120 million digital still cameras were sold in 2010; video already accounts for more than half of all Internet traffic, with YouTube attracting more than 2 billion views per day and 24 hours of video uploaded every minute. This explosion of the amount of data, number of users, and availability of new resources has led to greater expectations for multimedia retrieval and mining in terms of effectiveness and efficiency, for which existing analysis approaches and systems typically don’t suffice. Scalability to large data collections poses a particularly significant challenge for current multimedia processing methods. For instance, only about one-third of the papers appearing in ACM Multimedia 2008’s content track are applicable to this scale of data collections. Meanwhile, the research interest in processing large-scale image, audio, and video collections continues to grow rapidly, given the increasing availability of Web 2.0 websites, surveillance videos, and both personal and enterprise multimedia archives. We believe the tipping point for largescale multimedia analysis is quickly approaching. This special issue samples the state of the art in large-scale multimedia analysis techniques and explores how advanced multimedia analysis can be leveraged to address the challenges in large-scale data collections. In particular, from a total of 20 submissions, we selected five representative articles, that investigate large-scale multimedia analysis theory and systems across multiple application domains, such as Web event detection, landmark detection, image annotation, musical content mining, and cloud computing.	anomaly detection;archive;automatic image annotation;cloud computing;internet;machine learning;multimodal interaction;scalability;web 2.0	Rong Yan;Benoit Huet;Rahul Sukthankar	2011	IEEE MultiMedia	10.1109/MMUL.2011.11	cloud computing;computer science;data science;operating system;multimedia;automatic image annotation;world wide web;information retrieval	Web+IR	-14.041940071068566	-51.5599764332572	17184
d1543882d0a02b5a565e7c0d8cde45b6702fc961	link prediction in social network using co-clustering based approach	graph theory;cluster algorithm;pattern clustering;probability;link prediction probability;graph clustering;prediction algorithms;link prediction;spectral graph clustering algorithm;bigraph spectral co clustering;dblp dataset;clustering algorithms partitioning algorithms mathematical model equations algorithm design and analysis prediction algorithms bipartite graph;social network;spectral co clustering approach;spectral graph clustering;spectral analysis graph theory pattern clustering probability;mathematical model;clustering algorithms;spectral co clustering approach link prediction probability social network dblp dataset spectral graph clustering algorithm bipartite graph;spectral analysis;bipartite graph;algorithm design;algorithm design and analysis;link prediction spectral graph clustering bigraph spectral co clustering;partitioning algorithms	This paper introduces an approach to derive whether an individual is related to an item or not. In our approach, the well-known DBLP dataset is used and we try to find some skills that are related to an author that we were not aware of before. To realize our objective, we cluster authors and skills using Spectral Graph Clustering algorithm, then simultaneously obtain user and movie clusters via Bipartite Graph (Bigraph) Spectral Co-clustering approach, and then generate predictions based on the outputs of clustering and co-clustering steps. Accordingly, we utilize clustering and co-clustering advantages to predict the probability of link existing between an author and a skill. Experimental results on DBLP dataset show that our approach works well in the specified task.	algorithm;biclustering;bigraph;cluster analysis;computer cluster;dbl-browser;social network;whole earth 'lectronic link	Elham Hoseini;Sattar Hashemi;Ali Hamzeh	2012	2012 26th International Conference on Advanced Information Networking and Applications Workshops	10.1109/WAINA.2012.189	algorithm design;computer science;graph theory;machine learning;pattern recognition;data mining;statistics	ML	-14.028413546989768	-42.07761606104637	17235
ba58439e77e4ed8d6705cd2b5b83ee7decab2247	collaborative filtering model of book recommendation system	book recommendations;user evaluation;regression prediction;collaborative filtering;principal component analysis;pca;recommender systems;book recommendation systems	With the rapid development of information technology and internet, people from an era of scarcity gradually entered the era of information overload. For information-consumers, finding themselves interested in information from a large amount of information is a very difficult task. As regard to information producers, letting the production information stand out and getting the attention of the masses of users is also a very difficult task. To solve this contradiction, first, we establish a decorrelation principal component analysis model based on the correlation theory to obtain the main factors affecting the user evaluation of books. Secondly, we establish a predictive scoring system based on linear regression theory which can predict book ratings. Finally, we establish a collaborative filtering model of book recommendation.	collaborative filtering;recommender system	Xiaoqiang Guo;Lichao Feng;Yalou Liu;Xiuli Han	2016	IJAMC	10.1504/IJAMC.2016.10001902	computer science;artificial intelligence;data science;collaborative filtering;information filtering system;machine learning;data mining;world wide web;computer security;recommender system;principal component analysis	Web+IR	-21.69908062071723	-49.62936024965589	17262
ed721bdc8b1f0f6b72b8093e0e4c4edfd47d1c03	inverted linear quadtree: efficient top k spatial keyword search	keyword;smart phones;keyword search spatial indexes partitioning algorithms business search problems smart phones;batch spatial keyword;spatial indexes;keyword search;business;batch;geo positioning technologies il quadtree technique filtering capability keyword based pruning techniques inverted linear quadtree index structure linear quadtree inverted index topk sk queries batch processing query keywords query location spatio textual objects btopk sk batch top k spatial keyword search spatial keyword queries textual description spatio textual objects geo location services;text analysis batch processing computers quadtrees query processing search engines;search problems;partitioning algorithms;spatial	With advances in geo-positioning technologies and geo-location services, there are a rapidly growing amount of  spatio-textual  objects collected in many applications such as location based services and social networks, in which an object is described by its spatial location and a set of keywords (terms). Consequently, the study of spatial keyword search which explores both location and textual description of the objects has attracted great attention from the commercial organizations and research communities. In the paper, we study two fundamental problems in the spatial keyword queries: top   $k$      spatial keyword search (TOPK-SK), and batch top   $k$      spatial keyword search (BTOPK-SK). Given a set of  spatio-textual  objects, a query location and a set of query keywords, the TOPK-SK retrieves the closest   $k$      objects each of which contains all keywords in the query. BTOPK-SK is the batch processing of sets of TOPK-SK queries. Based on the inverted index and the linear quadtree, we propose a novel index structure, called inverted linear quadtree (IL-Quadtree), which is carefully designed to exploit both spatial and keyword based pruning techniques to effectively reduce the search space. An efficient algorithm is then developed to tackle top   $k$      spatial keyword search. To further enhance the filtering capability of the signature of linear quadtree, we propose a partition based method. In addition, to deal with BTOPK-SK, we design a new computing paradigm which partition the queries into groups based on both spatial proximity and the textual relevance between queries. We show that the IL-Quadtree technique can also efficiently support BTOPK-SK. Comprehensive experiments on real and synthetic data clearly demonstrate the efficiency of our methods.	quadtree	Chengyuan Zhang;Wenjie Zhang;Xuemin Lin	2016	IEEE Trans. Knowl. Data Eng.	10.1109/TKDE.2016.2530060	computer science;data mining;database;batch file;information retrieval;spatial query	DB	-14.89838708734538	-36.842868256243214	17305
d54d3489028e0bfd3ddc954deb854731db3d584e	novel spatial query processing techniques for scaling location based services	location based services;mobile;cq;range query;road network;continuous query;simulation;dissertation;lbs;query	Location based services (LBS) are gaining widespread user acceptance and increased daily usage. GPS based mobile navigation systems (Garmin), location-related social network updates and check-ins (Facebook), location-based games (Nokia), friend queries (Foursquare) and ads (Google) are some of the popular LBSs available to mobile users today. Despite these successes, current user services fall short of a vision where mobile users could ask for continuous location-based services with always-up-to-date information around them, such as the list of friends or favorite restaurants within 15 minutes of driving. Providing such a location based service in real time faces a number of technical challenges. #R##N#In this dissertation research, we propose a suite of novel techniques and system architectures to address some known technical challenges of continuous location queries and updates. Our solution approaches enable the creation of new, practical and scalable location based services with better energy efficiency on mobile clients and higher throughput at the location servers. Our first contribution is the development of RoadTrack, a road network aware and query-aware location update framework and a suite of algorithms. A unique characteristic of RoadTrack is the innovative design of encounter points and system-defined precincts to manage the desired spatial resolution of location updates for different mobile clients while reducing the complexity and energy consumption of location update strategies. The second novelty of this dissertation research is the technical development of Dandelion data structures and algorithms that can deliver superior performance for the periodic re-evaluation of continuous road-network distance based location queries, when compared with the alternative of repeatedly performing a network expansion along a mobile users trajectory. The third contribution of this dissertation research is the FastExpand algorithm that can speed up the computation of single-issue shortest-distance road network queries. Finally, we have developed the open source GT MobiSim mobility simulator, a discrete event simulation platform to generate realistic driving trajectories for real road maps. It has been downloaded and utilized by many to evaluate the efficiency and effectiveness of the location query and location update algorithms, including the research efforts in this dissertation.	database;image scaling;location-based service;spatial query	Péter Pesti	2012			simulation;computer science;location-based service;data mining;world wide web	DB	-16.080278657481703	-34.53580186410634	17392
8733a087e7bb2d337f23aad5249f6808cf1063de	an online fuzzy approach to the structural analysis of handwritten mathematical expressions	user interfaces fuzzy logic fuzzy set theory handwriting recognition trees mathematics;handwriting recognition;pen based interface;expression tree;expression recognition system;fuzzy rules;spatial relationship;trees mathematics;fuzzy set theory;fuzzy logic;handwriting recognition feature extraction computer science informatics educational institutions computer interfaces handheld computers fuzzy sets data processing writing;online fuzzy approach;fuzzy logic online fuzzy approach structural analysis handwritten mathematical expressions spatial relationship expression recognition system pen based interface expression tree;spatial relationships;handwritten mathematical expressions;structural analysis;user interfaces;structure analysis	This paper discusses the importance of the structural analysis of mathematical expressions and the significance of identifying the spatial relationships between symbols to determine the nature of an expression. It describes a recognition system based on a pen-based interface that can be used to analyse the structure of a mathematical expression by identifying these relationships. The solution is represented by an expression tree. When a new symbol is added to an expression, fuzzy rules are used to establish what relationships exist between the new symbol and the existing symbols. Once the best relationship has been identified, the expression tree is immediately updated.	binary expression tree;fuzzy logic;fuzzy rule;structural analysis	Ray Genoe;John A. Fitzgerald;M. Tahar Kechadi	2006	2006 IEEE International Conference on Fuzzy Systems	10.1109/FUZZY.2006.1681721	spatial relation;computer science;artificial intelligence;expression;theoretical computer science;machine learning;pattern recognition;structural analysis;handwriting recognition	Robotics	-32.05889043370463	-43.84413788954742	17502
3e3f8b58a10ba8fdc40f1fe325ecf8080f07663c	conflict detection and resolution model for low altitude flights	nextgen conflict detection resolution model low altitude flights general aviation small aircraft transportation system broaden air transportation services national airspace system unmanned aerial vehicle uav low altitude airspace collision avoidance conflict resolution ads r;aircraft atmospheric modeling turning mathematical model clocks collision avoidance data models;turning;clocks;advisories conflict detection and resolution cd r automatic dependent surveillance rebroadcast ads r traffic alert and collision avoidance system tcas general aviation ga unmanned aerial vehicle uav;collision avoidance aircraft autonomous aerial vehicles;mathematical model;collision avoidance;atmospheric modeling;aircraft;data models	General aviation has been promoted by Small Aircraft Transportation System (SATS) to broaden air transportation services. Under such development, the National Airspace System (NAS) will change dramatically in congested airspace. In this decade, the unmanned aerial vehicle (UAV) has rapidly growing into civilian applications. Low altitude airspace becomes more crowded. As a result, collision avoidance for low altitude flights will become a serious concern to aviation safety. Varieties of conflict detection and resolution (CD&R) were required under multiple maneuvering dimensions for GA and UAV. This paper focuses on efficient collision avoidance logic for GA and UAV based on ADS-R for NextGen. Heading change of horizontal resolution is more suitable for small GA or UAV flying in low altitude in the proposed CD&R model. Simulations using real ultralight flight data are tested to verify the performance of the proposed CD&R.	advanced transportation controller;aerial photography;algorithm;computer simulation;file synchronization;flying ice cube;image resolution;r.o.t.o.r.;sl (complexity);software release life cycle;traffic collision avoidance system;unmanned aerial vehicle	Chin E. Lin;Chia-Jung Lee	2015	2015 20th International Conference on Methods and Models in Automation and Robotics (MMAR)	10.1109/MMAR.2015.7283910	simulation;traffic collision avoidance system;geography;aerospace engineering;aeronautics;airborne collision avoidance system	Robotics	-18.006826545918482	-27.405745872037915	17530
f45cfe62446fc2d1b5ad9c351a2438faaa9c6553	unbiased learning to rank with unbiased propensity estimation		Learning to rank with biased click data is a well-known challenge. A variety of methods has been explored to debias click data for learning to rank such as click models, result interleaving and, more recently, the unbiased learning-to-rank framework based on inverse propensity weighting. Despite their differences, most existing studies separate the estimation of click bias (namely the propensity model ) from the learning of ranking algorithms. To estimate click propensities, they either conduct online result randomization, which can negatively affect the user experience, or offline parameter estimation, which has special requirements for click data and is optimized for objectives (e.g. click likelihood) that are not directly related to the ranking performance of the system. In this work, we address those problems by unifying the learning of propensity models and ranking models. We find that the problem of estimating a propensity model from click data is a dual problem of unbiased learning to rank. Based on this observation, we propose a Dual Learning Algorithm (DLA) that jointly learns an unbiased ranker and an unbiased propensity model. DLA is an automatic unbiased learning-to-rank framework as it directly learns unbiased ranking models from biased click data without any preprocessing. It can adapt to the change of bias distributions and is applicable to online learning. Our empirical experiments with synthetic and real-world data show that the models trained with DLA significantly outperformed the unbiased learning-to-rank algorithms based on result randomization and the models trained with relevance signals extracted by click models.	algorithm;algorithmic learning theory;clickstream;consistency model;drive letter assignment;duality (optimization);estimation theory;experiment;forward error correction;learning to rank;online and offline;preprocessor;ranking (information retrieval);relevance;requirement;synthetic intelligence;user experience	Qingyao Ai;Keping Bi;Cheng Luo;Jiafeng Guo;W. Bruce Croft	2018		10.1145/3209978.3209986	computer science;data mining;learning to rank;duality (optimization);randomization;user experience design;ranking;estimation theory;artificial intelligence;pattern recognition;weighting	Web+IR	-17.95515300299515	-49.01781435537261	17558
56f8ec864afdce5b687dabdb7223eb9308db1056	a cross-modal multi-task learning framework for image annotation	image annotation;semi supervised learning;multi task learning;cross modal learning	With the advance of internet, multi-modal data can be easily collected from many social websites such as Wikipedia, Flickr, YouTube, etc. Images shared on the web are usually associated with social tags or other textual information. Although existing multi-modal methods can make use of associated text to improve image annotation, the disadvantages of them are that associated text is also required for a new image to be predicted. In this paper, we propose the cross-modal multi-task learning (CMMTL) framework for image annotation. Labeled and unlabeled multi-modal data are both levaraged for training in CMMTL, and it finally obtains visual classifiers which can predict concepts for a single image without any associated information. CMMTL integrates graph learning, multi-task learning and cross-modal learning into a joint framework, where a shared subspace is learned to preserve both cross-modal correlation and concept correlation. The optimal solution of the proposed framework can be obtained by solving a generalized eigenvalue problem. We conduct comprehensive experiments on two real world image datasets: MIR Flickr and NUS-WIDE, to evaluate the performance of the proposed framework. Experimental results demonstrate that CMMTL obtains a significant improvement over several representative methods for cross-modal image annotation.	automatic image annotation;autostereogram;computer multitasking;experiment;flickr;modal logic;multi-task learning;wikipedia;world file	Liang Xie;Peng Pan;Yansheng Lu;Shixun Wang	2014		10.1145/2661829.2662023	semi-supervised learning;multi-task learning;image retrieval;computer science;machine learning;data mining;database;automatic image annotation;world wide web;information retrieval	AI	-17.662001968703255	-47.55231112093852	17657
03efd5e625bbc0f4f667e6a67f8185f422039a8d	smart multi-agent traffic coordinator for autonomous vehicles at intersections		Intersections are not only a scene to daily car accidents (rear-end collisions and side impacts…) but also a big cause for anger and frustration to many drivers, making the driving task difficult and dangerous. In this research, we proposed a smart multi-agent system to coordinate traffic in intersections for autonomous vehicles using reinforced learning and deep neural networks, this system will offer the possibility for a safe and fast passage through intersections without the need for human control.	artificial neural network;autonomous robot;deep learning;multi-agent system;network congestion;reinforcement learning;vehicle routing problem	Imad Lamouik;Ali Yahyaouy;My Abdelouahed Sabri	2017	2017 International Conference on Advanced Technologies for Signal and Image Processing (ATSIP)	10.1109/ATSIP.2017.8075564	simulation;artificial neural network;reinforcement learning;frustration;computer science	Robotics	-20.293240054950004	-26.54361468510045	17731
0d8b600ef0f379040861ca8b8092959be2a968dd	influence of social communication on content-based recommendation		One of basic divisions of information retrieval systems is content-based and collaborative filtering. Some hybrid methods exist combining both of them, but certain aspects still remain unexplored. In this paper we explore one: the influence of users communicating via social media on content-based recommendation systems. While in the system users do not know each other, outside they may make their own preferences known (e.g. tweeting recommendations), thus influencing the preferences of other users. Here we simulate several different types of such communication and its influence on content-based recommendation system. We intend to use this results for improving the quality of such systems.	collaborative filtering;information retrieval;interaction;recommender system;serial ata;simulation;social media	Bernadetta Maleszka;Marcin Maleszka	2017	2017 IEEE International Conference on INnovations in Intelligent SysTems and Applications (INISTA)	10.1109/INISTA.2017.8001147	recommender system;collaborative filtering;social media;knowledge management;multi-agent system;computer science	DB	-27.270543593971674	-50.02055098547858	17754
ab91a42d1e465b177ea738f9c87062d1a04385ef	a visualization pipeline for large-scale tractography data	measurement data visualization neurons image reconstruction diffusion tensor imaging probabilistic logic;clustering tractography neuroscience visualization;neuroscience;visualization;clustering;large scale tractography data novel clustering methodology standard visualization techniques three dimensional histogram;pattern clustering data visualisation;tractography	We present a novel methodology for clustering and visualizing large-scale tractography data sets. Tractography data sets contain hundreds of millions of line segments, making visualizing and understanding this data very difficult. Our method reduces and simplifies this data to create coherent groupings and visualizations. Our input is a collection of tracts, from which we derive metrics and perform clustering. Using the clustered data, we create a three-dimensional histogram that contains the counts of the number of tracts that intersect each bin. With these new data sets, we can perform standard visualization techniques. Our contribution is the visualization pipeline itself, as well as a study and evaluation schema. Our study utilizes our evaluation schema to identify the best and most influential clustering metrics, and an optimal number of clusters under varying user requirements.	cluster analysis;coherence (physics);database schema;requirement;user requirements document	James Kress;Erik Anderson;Hank Childs	2015	2015 IEEE 5th Symposium on Large Data Analysis and Visualization (LDAV)	10.1109/LDAV.2015.7348079	computer vision;computer science;machine learning;data mining;cluster analysis	Visualization	-28.004907987414317	-32.89778661169761	17758
2ac5dd61188ff26087dc04280e6761b587e6322a	task taxonomy for graph visualization	task performance;controlled experiment;task taxonomy;evaluation;graph visualization	Our goal is to define a list of tasks for graph visualization that has enough detail and specificity to be useful to: 1) designers who want to improve their system and 2) to evaluators who want to compare graph visualization systems. In this paper, we suggest a list of tasks we believe are commonly encountered while analyzing graph data. We define graph specific objects and demonstrate how all complex tasks could be seen as a series of low-level tasks performed on those objects. We believe that our taxonomy, associated with benchmark datasets and specific tasks, would help evaluators generalize results collected through a series of controlled experiments.	benchmark (computing);experiment;graph drawing;high- and low-level;sensitivity and specificity;taxonomy (general)	Bongshin Lee;Catherine Plaisant;Cynthia Sims Parr;Jean-Daniel Fekete;Nathalie Henry Riche	2006		10.1145/1168149.1168168	computer science;theoretical computer science;evaluation;data mining;distributed computing;graph drawing	Visualization	-30.323268432927303	-36.613274708889755	17786
34f80305c84680ea677a0d8ebd41057570d2854b	recommetz: a context-aware knowledge-based mobile recommender system for movie showtimes	ontology reasoning;knowledge based recommender systems;semantic web;context aware systems	Recommender systems are used to provide filtered information from a large amount of elements. They provide personalized recommendations on products or services to users. The recommendations are intended to provide interesting elements to users. Recommender systems can be developed using different techniques and algorithms where the selection of these techniques depends on the area in which they will be applied. This paper proposes a recommender system in the leisure domain, specifically in the movie showtimes domain. The system proposed is called RecomMetz, and it is a context-aware mobile recommender system based on Semantic Web technologies. In detail, a domain ontology primarily serving a semantic similarity metric adjusted to the concept of ‘‘packages of single items’’ was developed in this research. In addition, location, crowd and time were considered as three different kinds of contextual information in RecomMetz. In a nutshell, RecomMetz has unique features: (1) the items to be recommended have a composite structure (movie theater + movie + showtime), (2) the integration of the time and crowd factors into a context-aware model, (3) the implementation of an ontology-based context modeling approach and (4) the development of a multi-platform native mobile user interface intended to leverage the hardware capabilities (sensors) of mobile devices. The evaluation results show the efficiency and effectiveness of the recommendation mechanism implemented by RecomMetz in both a cold-start scenario and a no cold-start scenario. 2014 Elsevier Ltd. All rights reserved.	algorithm;cold start;mobile device;ontology (information science);personalization;recommender system;semantic web;semantic similarity;sensor;user interface	Luis Omar Colombo-Mendoza;Rafael Valencia-García;Alejandro Rodríguez González;Giner Alor-Hernández;José Javier Samper Zapater	2015	Expert Syst. Appl.	10.1016/j.eswa.2014.09.016	computer science;artificial intelligence;semantic web;data mining;multimedia;world wide web	AI	-29.33423326415815	-47.57553044897548	17795
758f2922bc133893ab1123c93f5ffc1b56afe8bb	efficient algorithms for managing the history of evolving databases	theoretical framework;efficient algorithm;space use;lower bound	We propose a novel method for representing evolving databases by “evolving sets”, which is particularly useful when we are interested in reconstructing any past state of a database. This theoretical framework therefore reduces the problem concerning the history management of databases to the problem of efficiently managing the history of a set evolving in time. We present a dynamic algorithm that reconstructs the state of the set at a given time t in the past in O(|s(t)| + loglogT) time, where |s(t)| is the size of the answer and T is the maximal size of the time interval (t ≤ T). The space used is linear to the number of changes that occurred during the set's evolution. The resulting algorithm is thereby more efficient than all previous methods dealing with the history management of evolving databases. In fact the proposed algorithm is optimal within a constant factor, because a lower bound of O(|s(t)| + loglogT) is also proved. Furthermore, if a total of O((logT)1/c) parallel processors is available, where c is a positive constant (c ≥ 1), the above bound is reduced to O(|s(t)|).	algorithm;database	Vassilis J. Tsotras;B. Gopinath	1990		10.1007/3-540-53507-1_75	computer science;theoretical computer science;data mining;k-approximation of k-hitting set;upper and lower bounds;algorithm	DB	-6.774736353729063	-36.32488653880949	17843
07fc3438cd4d77518c6bd2c02815972acde9abde	mining generalized graph patterns based on user examples	graph theory;web pages;logical documents;patterns structure;generalization rules;pattern generation;data mining;chemical compound classification task;machine learning;science learning;generalized patterns;web sites;computer science chemical compounds web pages evolution biology chemical technology machine learning algorithms biology computing proteins html data mining;graph patterns mining;synthetic data;learning artificial intelligence;learning artificial intelligence data mining graph theory;data structure;molecular structure;machine learning graph patterns mining patterns structure chemical compound classification task web sites web pages logical documents generalization rules generalized patterns	"""There has been a lot of recent interest in mining patterns from graphs. Often, the exact structure of the patterns of interest is not known. This happens, for example, when molecular structures are mined to discover fragments useful as features in chemical compound classification task, or when web sites are mined to discover sets of web pages representing logical documents. Such patterns are often generated from a few small subgraphs (cores), according to certain generalization rules (GRs). We call such patterns """"generalized patterns """"(GPs). While being structurally different, GPs often perform the same function in the network. Previously proposed approaches to mining GPs either assumed that the cores and the GRs are given, or that all interesting GPs are frequent. These are strong assumptions, which often do not hold in practical applications. In this paper, we propose an approach to mining GPs that is free from the above assumptions. Given a small number of GPs selected by the user, our algorithm discovers all GPs similar to the user examples. First, a machine learning-style approach is used to find the cores. Second, generalizations of the cores in the graph are computed to identify GPs. Evaluation on synthetic data, generated using real cores and GRs from biological and web domains, demonstrates effectiveness of our approach."""	algorithm;graph (discrete mathematics);machine learning;mined;synthetic data;universal generalization;web page	Pavel Dmitriev;Carl Lagoze	2006	Sixth International Conference on Data Mining (ICDM'06)	10.1109/ICDM.2006.108	combinatorics;data structure;molecule;computer science;graph theory;data science;machine learning;web page;data mining;programming language;algorithm;synthetic data	ML	-10.89643320653605	-45.884962629188024	17858
6ddba3533f9cb1db9ecd7a0c39027e931dd423fd	using interactions and dynamics for mining groups of moving objects from trajectory data		ABSTRACTAdvances in tracking technology enable the gathering of spatio-temporal data in the form of trajectories, which when analysed can convey useful knowledge. In particular, discovering groups of moving objects is a valuable means for a wide class of problems related to mobility. The task of group mining has been investigated by considering mostly the spatial closeness and similarity of the trajectories, while little attention has been paid to the relationships between the trajectories and time-changing nature of the trajectories. The relationships may provide evidence of interactions between the moving objects. The time-changing nature may provide evidence of dynamics of the movements. Therefore, interactions and dynamics can be sources of information to be considered in order to discover new forms of groups.  Motivated by this, we introduce the concept of crews and propose a method to discover crews. A crew gathers moving objects with similar interactions and similar dynamics. The proposed method re...	interaction	Corrado Loglisci	2018	International Journal of Geographical Information Science	10.1080/13658816.2017.1416473	machine learning;computer science;artificial intelligence;data mining;information system;crew;closeness;trajectory	DB	-23.09514965169789	-34.759800296075504	17863
09cebbd99b5bf358b763770a798fc0f099878883	discovering graph temporal association rules		Detecting regularities between complex events in temporal graphs is critical for emerging applications. This paper proposes graph temporal association rules (GTAR). A GTAR extends traditional association rules to discover temporal associations for complex events captured by a class of temporal pattern queries. We introduce notions of support and confidence for GTARS and formalize the discovery problem for GTARS. We show that despite the enhanced expressive power, GTARS discovery is feasible over large temporal graphs. We develop an effective rule discovery algorithm, which integrates event mining and rule discovery as a single process, and reduces the redundant computation by leveraging their interaction. Using real-life and synthetic data, we experimentally verify the effectiveness and scalability of the algorithms. Our case study also verifies that GTARS demonstrate highly interpretable associations in real-world networks.	algorithm;association rule learning;computation;experiment;expressive power (computer science);real life;scalability;synthetic data	Mohammad Hossein Namaki;Yinghui Wu;Qi Song;Peng Lin;Tingjian Ge	2017		10.1145/3132847.3133014	expressive power;data mining;scalability;computer science;computation;association rule learning;machine learning;synthetic data;artificial intelligence;graph	DB	-9.747965402415991	-37.67850056353659	17870
122c80f08c46402a77ceea87b48d7a2ff172f3b7	towards the adaptation of sdc methods to stream mining		Abstract Most of the existing statistical disclosure control (SDC) standards, such as k -anonymity or l -diversity, were initially designed for static data. Therefore, they cannot be directly applied to stream data which is continuous, transient, and usually unbounded. Moreover, in streaming applications, there is a need to offer strong guarantees on the maximum allowed delay between incoming data and its corresponding anonymous output. In order to full-fill with these requirements, in this paper, we present a set of modifications to the most standard SDC methods, efficiently implemented within the Massive Online Analysis (MOA) stream mining framework. Besides, we have also developed a set of performance metrics to evaluate Information Loss and Disclosure Risk values continuously. Finally, we also show the efficiency of our new methods with a large set of experiments.		David Martínez Rodríguez;Jordi Nin;Miguel Núñez-del-Prado	2017	Computers & Security	10.1016/j.cose.2017.08.011	computer security;anonymity;data mining;statistical disclosure control;data stream mining;computer science	ML	-9.030386575588928	-34.8549158423806	17885
827850470b8633b5c78dd318d91c2b39c82d8124	visual analytics methods for categoric spatio-temporal data	data visualization visualization algorithm design and analysis image color analysis time series analysis electronic mail data analysis;electronic mail;data visualisation;data analysis;visualization;meteorologic areas visual analytics methods spatiotemporal data categoric space referenced categorical data analysis time referenced categorical data analysis spatial geographical objects spatial geographical locations location analysis time analysis categorical change visualization spatial data computational techniques task oriented selection movement tracking;time series analysis;geographic information systems;image color analysis;data visualization;spatiotemporal phenomena;interactive systems;meteorology;algorithm design and analysis;spatiotemporal phenomena data visualisation geographic information systems interactive systems meteorology	We focus on visual analysis of space- and time-referenced categorical data, which describe possible states of spatial (geographical) objects or locations and their changes over time. The analysis of these data is difficult as there are only limited possibilities to analyze the three aspects (location, time and category) simultaneously. We present a new approach which interactively combines (a) visualization of categorical changes over time; (b) various spatial data displays; (c) computational techniques for task-oriented selection of time steps. They provide an expressive visualization with regard to either the overall evolution over time or unusual changes. We apply our approach on two use cases demonstrating its usefulness for a wide variety of tasks. We analyze data from movement tracking and meteorologic areas. Using our approach, expected events could be detected and new insights were gained.	algorithm;categorical variable;category theory;computation;electronic billing;emoticon;expert system;interactivity;medical imaging;mobile phone;self-propelled particles;usability testing;visual analytics	Tatiana von Landesberger;Sebastian Bremm;Natalia V. Andrienko;Gennady L. Andrienko;Maria Tekusova	2012	2012 IEEE Conference on Visual Analytics Science and Technology (VAST)	10.1109/VAST.2012.6400553	algorithm design;computer vision;visual analytics;information visualization;visualization;interactive visual analysis;computer science;data science;time series;data mining;data analysis;data visualization;statistics	Visualization	-26.088636824481824	-33.34863560691158	17906
828658bd92d59035573ff736ac27e5e98f9d1500	large-scale multidimensional data visualization: a web service for data mining	parallel computing;web service;data mining;visualization;large scale multidimensional data	In this paper, we present an approach of the Web application (as a service) for data mining oriented to the multidimensional data visualization. The stress is put on visualization methods as a tool for the visual presentation of large-scale multidimensional data sets. The proposed implementation includes five visualization methods: MDS SMACOF algorithm, Relative MDS, Diagonal majorization algorithm, Relational perspective map, SAMANN. A cluster for parallel computation is used by Web service for the visual data mining. The service is of free access to the user community for data visualization.	algorithm;computation;data mining;data visualization;parallel computing;virtual community;web application;web service;world wide web	Gintautas Dzemyda;Virginijus Marcinkevicius;Viktor Medvedev	2011		10.1007/978-3-642-24755-2_2	information visualization;computer science;data mining;database;world wide web	Visualization	-28.809147341990037	-32.991224793672416	17942
36a49b9ee09a3d06bd2da6dc605bfddc10fddf78	community detection by popularity based models for authored networked data	distributed algorithms;community detection;probability;graph clustering;data mining;data mining popularity based models authored networked data networked data community detection authorship information entities communities probabilistic models popularity link model community memberships author topic model discriminative approach;social networking online;communities computational modeling mathematical model data models social network services analytical models conferences;social networking online data mining probability;mapreduce	Community detection has emerged as an attractive topic due to the increasing need to understand and manage the networked data of tremendous magnitude. Networked data usually consists of links between the entities and the attributes for describing the entities. Various approaches have been proposed for detecting communities by utilizing the link information and/or attribute information. In this work, we study the problem of community detection for networked data with additional authorship information. By authorship, each entity in the network is authored by another type of entities (e.g., wiki pages are edited by users, products are purchased by customers), to which we refer as authors. Communities of entities are affected by their authors, e.g., two entities that are associated with the same author tend to belong to the same community. Therefore leveraging the authorship information would help us better detect the communities in the networked data. However, it also brings new challenges to community detection. The foremost question is how to model the correlation between communities and authorships. In this work, we address this question by proposing probabilistic models based on the popularity link model [1], which is demonstrated to yield encouraging results for community detection. We employ two methods for modeling the authorships: (i) the first one generates the authorships independently from links by community memberships and popularities of authors by analogy of the popularity link model; (ii) the second one models the links between entities based on authorships together with community memberships and popularities of nodes, which is an analog of previous author-topic model. Upon the basic models, we explore several extensions including (i) we model the community memberships of authors by that of their authored entities to reduce the number of redundant parameters; and (ii) we model the communities memberships of entities and/or authors by their attributes using a discriminative approach. We demonstrate the effectiveness of the proposed models by empirical studies.	entity;foremost;sensor;topic model;wiki	Tianbao Yang;Prakash Mandayam Comar;Linli Xu	2013	2013 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining (ASONAM 2013)	10.1145/2492517.2492520	distributed algorithm;computer science;artificial intelligence;data science;machine learning;probability;data mining;clustering coefficient;mathematics;world wide web;statistics	DB	-19.141314579098488	-44.60002903591762	17979
ff111f4f79a9587a87a83e5968ec8ff73c8bb1c1	a learning system with the ability to grasp its situation	learning process;biological system modeling;manganese;optimal control;learning systems;learning system;brain modeling;computational modeling;organizing;stability analysis;pattern recognition;associative memory;learning systems pattern recognition organizing brain modeling context modeling concrete stability analysis computational modeling computer simulation associative memory;couplings;machine model;context modeling;computer simulation;context;concrete	This paper reports a machine that is able to respond correctly to inputs having multiple meanings by grasping its situation. Unlike the conventional learning systems, the machine models the context relation between input patterns by a learning process. The machine can grasp its situation by the use of the modeled context relation, and hence it can respond correctly. To be concrete, the machine can correctly recognize patterns having multiple meanings such as 0 (``oh'' or ``zero'') as the situation may demand. The machine is composed of the backward coupling of the same kind of neuronlike elements called basic computational elements. The context relation between two input patterns is given by the coupling coefficient of the two basic computational elements correlated to the two patterns, respectively. Coupling coefficients make potentials of the elements correlated to the present inputs higher than the other elements. These higher potentials enable the machine to grasp the situation. Stability analysis is also made, and conditions for the machine to operate correctly are definitely shown under some assumptions. The machine was simulated on a computer, and several input patterns each of which had two meanings were recognized correctly.	coefficient;computer;loose coupling;the machine	Takashi Nagano	1975	IEEE Transactions on Systems, Man, and Cybernetics	10.1109/TSMC.1975.5409157	computer simulation;concrete;optimal control;computer science;artificial intelligence;manganese;machine learning	Arch	-7.988678379752966	-45.90675031366846	17996
5381f37735a332288b0d8d27684abf8bdde83adc	evaluation of epl mutation operators with the muepl mutation system		Abstract The expert systems (ESs) have been developed to facilitate the users their tasks, to enhance the productivity and reduce losses. In order to replicate the behaviour of a human expert, they generate output using their stored knowledge base. In a ES, the accumulation of knowledge from different sources is a very important factor. Nowadays, we are living in a world where two crucial processes need to be perform quickly: decision-making and problem solving. The complexity of the decisions and problems lays on the different factors, situations and data that are involved. The Internet of Things (IoT) has been created to address these situations and helps the users to make correct decisions in real time according to the received data. In the concept of IoT, daily life objects are connected to each other so they can transfer data over the internet without a human to human interaction. The combination of IoT and ESs is a step further for the decision making problem, the received data from the IoT system will be sent to the ES, then the ES will process the information and send the results or decisions to the user. Given that correct decisions-making and problem solving are critical processed, these complex systems need to be tested. Mutation testing, which is a technique used in fault testing, has been examined in a range of studies where different programming languages have been used as well as in IoT expert systems evaluations. However, this technique has not been applied to an IoT programming language, which is noteworthy in the case of event processing languages (EPLs), that have been designed to address the main problems of IoT systems. Among the existing EPLs, the EPL of EsperTech is used the most often. In this paper, we apply mutation testing using MuEPL to EPL of EsperTech programs in order to simulate the common errors of the developers and to avoid the wrong decisions before moving out to ES in the IoT network.	esoteric programming language	Lorena Gutiérrez-Madronal;Inmaculada Medina-Bulo;Juan José Domínguez-Jiménez	2019	Expert Syst. Appl.	10.1016/j.eswa.2018.09.003	data mining;the internet;replicate;knowledge base;complex system;operator (computer programming);complex event processing;expert system;mutation testing;computer science	DB	-14.425635788539088	-29.630851279296213	17999
a4345f2b3954ddfe20eaf6133ef84cad97c591b5	spatial distribution pattern of the customer count and satisfaction of commercial facilities based on social network review data in beijing, china		Abstract In cities, commercial facilities play a very important role in economic growth and urban development. Current studies often discuss the spatial distribution of commercial facilities. The spatial distribution and relevant influencing factors of the customer count and satisfaction of commercial facilities, however, has rarely been considered. In this paper, a Weighted Network-constrained Kernel Density Estimation is applied to social network review data to analyze the spatial distribution of customer count and satisfaction of commercial facilities. We found differences in the spatial distribution of customer count, satisfaction, and the location of commercial facilities. To analyze these spatial differences, we present a new method for quantitative analysis using the Network-constrained Local Getis-Ordu0027s General G* as an indicator. Road segments with high-value spatial clustering or low-value spatial clustering were detected, reflecting the spatial distribution pattern of the customer count and satisfaction of commercial facilities. The Network-constrained K-Function was used to explore the spatial clustering pattern of commercial facilities as well as the correlation between the spatial distribution of commercial facilities and other POI data, such as subway stations or business centers. The results of these analyses provide a quantitative reference when deciding locations for commercial facilities, and can help us to identify problems in commercial facility services to improve the quality of life among urban residents.	social network	Teng Wang;Yandong Wang;Xiaoming Zhao;Xiao-kang Fu	2018	Computers, Environment and Urban Systems	10.1016/j.compenvurbsys.2018.04.005	geography;data mining;spatial distribution;china;cluster analysis;social network;beijing;kernel density estimation;quality of life;urban planning	HPC	-18.254974739302963	-32.666145518043024	18019
bc4da91b280a8b923670d77b2c950b850542f5a9	using crowdsourced trajectories for automated osm data entry approach	trajectory data mining;spatial data quality;openstreetmap;completeness;crowdsourcing	The concept of crowdsourcing is nowadays extensively used to refer to the collection of data and the generation of information by large groups of users/contributors. OpenStreetMap (OSM) is a very successful example of a crowd-sourced geospatial data project. Unfortunately, it is often the case that OSM contributor inputs (including geometry and attribute data inserts, deletions and updates) have been found to be inaccurate, incomplete, inconsistent or vague. This is due to several reasons which include: (1) many contributors with little experience or training in mapping and Geographic Information Systems (GIS); (2) not enough contributors familiar with the areas being mapped; (3) contributors having different interpretations of the attributes (tags) for specific features; (4) different levels of enthusiasm between mappers resulting in different number of tags for similar features and (5) the user-friendliness of the online user-interface where the underlying map can be viewed and edited. This paper suggests an automatic mechanism, which uses raw spatial data (trajectories of movements contributed by contributors to OSM) to minimise the uncertainty and impact of the above-mentioned issues. This approach takes the raw trajectory datasets as input and analyses them using data mining techniques. In addition, we extract some patterns and rules about the geometry and attributes of the recognised features for the purpose of insertion or editing of features in the OSM database. The underlying idea is that certain characteristics of user trajectories are directly linked to the geometry and the attributes of geographic features. Using these rules successfully results in the generation of new features with higher spatial quality which are subsequently automatically inserted into the OSM database.	arcgis;clinical act of insertion;crowdsourcing;data mining;geographic information systems;geographic information system;inference engine;insertion mutation;interface device component;interpretation process;movement;openstreetmap;partial;plug-in (computing);providing (action);raw image format;registration;rule (guideline);sensor;statistical classification;usability;user interface;vagueness	Anahid Bassiri;Pouria Amirian;Peter Mooney	2016		10.3390/s16091510	completeness;data science;data mining;database;crowdsourcing;statistics	ML	-31.383805285434466	-34.66809863092814	18026
5cbae2c950ae1b64971ab0bb12bc5327987eacc3	dynamics of group cohesion in homophilic networks		Understanding cohesion and homophily in empirical networks allows us build better personalization and recommendation systems. This paper proposes a network model that explains the emergence of cohesion and homophily as an aggregate outcome at the group- and network-level. We introduce two simple mechanisms that capture the underlying tendencies of nodes to connect with similar and different others. Our main theoretical result presents conditions on the network under which it reaches high degrees of cohesion and homophily.	aggregate data;cohesion (computer science);emergence;group cohesiveness;network model;personalization;recommender system	Katerine Guerrero;Jorge Finke	2017	2017 IEEE 56th Annual Conference on Decision and Control (CDC)	10.1109/CDC.2017.8263988	recommender system;personalization;management science;mathematical optimization;homophily;computer science;cohesion (chemistry);network model;group cohesiveness	DB	-19.264504611588958	-41.74043268914008	18095
1eddb4f504a47410cc411893086dbc1b3956ac00	a phase transition induces chaos in a predator-prey ecosystem with a dynamic fitness landscape		"""In many ecosystems, natural selection can occur quickly enough to influence the population dynamics and thus future selection. This suggests the importance of extending classical population dynamics models to include such eco-evolutionary processes. Here, we describe a predator-prey model in which the prey population growth depends on a prey density-dependent fitness landscape. We show that this two-species ecosystem is capable of exhibiting chaos even in the absence of external environmental variation or noise, and that the onset of chaotic dynamics is the result of the fitness landscape reversibly alternating between epochs of stabilizing and disruptive selection. We draw an analogy between the fitness function and the free energy in statistical mechanics, allowing us to use the physical theory of first-order phase transitions to understand the onset of rapid cycling in the chaotic predator-prey dynamics. We use quantitative techniques to study the relevance of our model to observational studies of complex ecosystems, finding that the evolution-driven chaotic dynamics confer community stability at the """"edge of chaos"""" while creating a wide distribution of opportunities for speciation during epochs of disruptive selection-a potential observable signature of chaotic eco-evolutionary dynamics in experimental studies."""	chaos theory;ecosystem;edge of chaos;exhibits as topic;first-order reduction;fitness function;lotka–volterra equations;observable;onset (audio);phase transition;population growth;population dynamics;prey;relevance;statistical mechanics;free energy	William Gilpin;Marcus W. Feldman	2017		10.1371/journal.pcbi.1005644	statistical physics;statistical mechanics;fitness landscape;edge of chaos;genetics;biology;ecology;chaotic;disruptive selection;population;natural selection;fitness function	ML	-4.8605037976039	-47.27688986738527	18127
27863f7c61f5754ffb03c0502d38f32b9cbd030f	binscroll: a rapid selection technique for alphanumeric lists	selection technique;alphanumeric list;search algorithm;mobile computer;binary search;mobile computing	We present a new, efficient technique to find an alphanumeric item in a sorted list. Our technique, called BinScroll, is based on binary search, the well-known computer science search algorithm. BinScroll can be used with a minimum of four buttons, making it ideal for keyboardless mobile use. It can also be implemented with a minimum of three lines of text, making it suitable for devices with limited screen space. Our initial evaluation showed that after 15 minutes of training, a novel user is able to locate any item from a list of 10 000 movie names in 14 seconds on average.	binary search algorithm;computer science;glossary of computer graphics;sorting algorithm;whole earth 'lectronic link	Juha Lehikoinen;Mika Röykkee	2000		10.1145/633292.633445	linear search;computer science;operating system;jump search;data mining;mobile computing;world wide web;information retrieval;binary search algorithm;search algorithm	HCI	-33.58507306683559	-46.80693801486495	18203
21f304dfe8751045b59ece385708751aee8f5e6b	on the importance of subtext in recommender systems			recommender system;subtext	Peter Grasch;Alexander Felfernig	2015	i-com		sentiment analysis;recommender system;paralanguage;computer science;human–computer interaction;interaction styles;natural language;subtext	ECom	-31.444682724181757	-48.13009637160136	18211
156a979a4214c6684e6f9ba77c0ca5fcf410e5ff	short-term multiagent simulation-based prediction in mass gatherings decision support		Mass gatherings emerging both for specific occasions and spontaneously, are naturally associated with the risk of stampedes and crowd clashes that may trigger dramatic consequences in shorter or longer term perspectives. In order to address such issues the present paper suggests the application of the agentbased modeling approach to short-term predictions of future states of large congregates of people. The latter is of prime value for practitioners who seek to identify the potentially dangerous areas where the risk of stampede-induced injuries is assumed the highest based on the estimations of the crowd pressure at a given spot. In this paper, we outline the algorithm for generating forecasts and on its basis, propose a system of decision support. The test of system applicability has been performed based on the 2018 World Football Championship stadium use case. The object under investigation is expected to be put into operation in 2018.	agent-based model;algorithm;crowdsourcing;decision support system;simulation	Vladislav A. Karbovskii;Andrey Karsakov;Dmitry Rybokonenko;Daniil V. Voloshin	2016		10.1016/j.procs.2016.05.531	simulation;artificial intelligence;data mining;operations research	AI	-17.997495227735225	-24.80902181392338	18229
0ea3009bf73e5615af5b4c0052d394ed3f90b144	permu-pattern: discovery of mutable permutation patterns with proximity constraint	text mining;gene cluster;proximity pattern;pattern discovery;synthetic data;sequential pattern;computational biology;permutation pattern	Pattern discovery in sequences is an important problem in many applications, especially in computational biology and text mining. However, due to the noisy nature of data, the traditional sequential pattern model may fail to reflect the underlying characteristics of sequence data in these applications. There are two challenges: First, the mutation noise exists in the data, and therefore symbols may be misrepresented by other symbols; Secondly, the order of symbols in sequences could be permutated. To address the above problems, in this paper we propose a new sequential pattern model called mutable permutation patterns. Since the Apriori property does not hold for our permutation pattern model, a novel Permu-pattern algorithm is devised to mine frequent mutable permutation patterns from sequence databases. A reachability property is identified to prune the candidate set. Last but not least, we apply the permutation pattern model to a real genome dataset to discover gene clusters, which shows the effectiveness of the model. A large amount of synthetic data is also utilized to demonstrate the efficiency of the Permu-pattern algorithm.	algorithm;bioinformatics;computation;computational biology;database;immutable object;pattern language;permutation pattern;reachability;synthetic data;text mining	Meng Hu;Jiong Yang;Wei Su	2008		10.1145/1401890.1401932	text mining;gene cluster;computer science;bioinformatics;data mining;mathematics;k-optimal pattern discovery;algorithm;synthetic data	DB	-6.758118016107627	-37.867982416864855	18244
2c9e38000575256b005df00d67cc049259ae256c	enhancing the envision interface for digital libraries	digital library;envision;information visualization;aggregation;variable width;user interaction	To enhance the ENVISION interface and facilitate user interaction, various techniques were considered for better rendering of search results with improved scalability. In this paper we discuss the challenges we encountered and our solutions to those problems.	digital library;library (computing);scalability	Abhishek Agrawal;Anil Bazaza;Supriya Angle;Edward A. Fox;Chris North	2002		10.1145/544220.544279	digital library;information visualization;delegation;human–computer interaction;computer science;multimedia;world wide web	HCI	-31.926323879107454	-33.83279067960394	18252
328e22e79f80d6d9d4a088ffceb76b3c6d0bd0ba	big data clustering via community detection and hyperbolic network embedding in iot applications	girvan–newman algorithm;rigel embedding;community detection;data clustering;edge-betweenness centrality;hyperbolic network embedding;smart-cities/buildings	In this paper, we present a novel data clustering framework for big sensory data produced by IoT applications. Based on a network representation of the relations among multi-dimensional data, data clustering is mapped to node clustering over the produced data graphs. To address the potential very large scale of such datasets/graphs that test the limits of state-of-the-art approaches, we map the problem of data clustering to a community detection one over the corresponding data graphs. Specifically, we propose a novel computational approach for enhancing the traditional Girvan-Newman (GN) community detection algorithm via hyperbolic network embedding. The data dependency graph is embedded in the hyperbolic space via Rigel embedding, allowing more efficient computation of edge-betweenness centrality needed in the GN algorithm. This allows for more efficient clustering of the nodes of the data graph in terms of modularity, without sacrificing considerable accuracy. In order to study the operation of our approach with respect to enhancing GN community detection, we employ various representative types of artificial complex networks, such as scale-free, small-world and random geometric topologies, and frequently-employed benchmark datasets for demonstrating its efficacy in terms of data clustering via community detection. Furthermore, we provide a proof-of-concept evaluation by applying the proposed framework over multi-dimensional datasets obtained from an operational smart-city/building IoT infrastructure provided by the Federated Interoperable Semantic IoT/cloud Testbeds and Applications (FIESTA-IoT) testbed federation. It is shown that the proposed framework can be indeed used for community detection/data clustering and exploited in various other IoT applications, such as performing more energy-efficient smart-city/building sensing.	benchmark (computing);betweenness centrality;big data;cluster analysis;complex network;computation (action);data dependency;embedding;girvan–newman algorithm;graph - visual representation;grid north;image scaling;mathematical optimization;mycobacterium phage newman;node - plant part;numerous;relevance;synthetic intelligence;testbed;emotional dependency;sensor (device);statistical cluster	Vasileios Karyotis;Konstantinos Tsitseklis;Konstantinos Sotiropoulos;Symeon Papavassiliou	2018		10.3390/s18041205	complex network;data dependency;electronic engineering;network topology;engineering;big data;machine learning;cloud computing;cluster analysis;centrality;girvan–newman algorithm;artificial intelligence	ML	-12.12228691804843	-41.74080857449444	18255
9075869c996d0c8f2e7da05bae8b6d6ed8001246	what's in a name? data linkage, demography and visual analytics		This work explores the development of a visual analytics tool for geodemographic exploration in an online environment. We mine 78 million records from the United States public telephone directories, link the location data to demographic data (specifically income) from the United States Census Bureau, and allow users to interactively compare distributions of names with regards to spatial location similarity and income. In order to enable interactive similarity exploration, we explore methods of pre-processing the data as well as on-the-fly lookups. As data becomes larger and more complex, the development of appropriate data storage and analytics solutions has become even more critical when enabling online visualization. We discuss problems faced in implementation, design decisions and directions for future work.	computer data storage;interactivity;linkage (software);preprocessor;visual analytics	Feng Wang;José Tomás Ibarra;Adnan Muhammed;Paul Longley;Ross Maciejewski	2014		10.2312/eurova.20141143	analytics;computer science;data science;data mining;cultural analytics;world wide web	HCI	-26.707549529430462	-31.72300006931502	18310
2ffc826ea46d23b77646ed8cb95ea70e954e2ceb	a behavioral investigation of dimensionality reduction		A cornucopia of dimensionality reduction techniques have emerged over the past decade, leaving data analysts with a wide variety of choices for reducing their data. Means of evaluating and comparing low-dimensional embeddings useful for visualization, however, are very limited. When proposing a new technique it is common to simply show rival embeddings side-by-side and let human judgment determine which embedding is superior. This study investigates whether such human embedding evaluations are reliable, i.e., whether humans tend to agree on the quality of an embedding. We also investigate what types of embedding structures humans appreciate a priori. Our results reveal that, although experts are reasonably consistent in their evaluation of embeddings, novices generally disagree on the quality of an embedding. We discuss the impact of this result on the way dimensionality reduction researchers should present their results, and on applicability of dimensionality reduction outside of machine learning.	dimensionality reduction;machine learning	Joshua M. Lewis;Laurens van der Maaten;Virginia R. de Sa	2012			topic model;social psychology;eval;unsupervised learning;curse of dimensionality;parametric statistics;data mining;dimensionality reduction;machine learning;data structure;artificial intelligence;image segmentation;computer science	ML	-25.915106273348588	-36.14446077773223	18317
1845d6be7e7f37943393e7517f7359bc8487ff42	a comparison of analytic and experimental goal regression for machine learning	satisfiability;machine learning	Recent research demonstrates the use of goal regression as an analytic technique for learning search heuris-tics. This paper critically examines this research and identifies essential applicability conditions for the technique. The conditions that operators be invertible and that the domain be closed with respect to the inverse operators severely limit the use of analytic goal regression. In those restricted domains which satisfy the applicability conditions , analytic goal regression only discovers required preconditions for operator application. Discovering pragmatic preconditions is beyond the capability of the technique. An alternative, called experimental goal regression, is defined which approximates the results of analytic goal regression without suffering from these limitations.	approximation algorithm;machine learning;precondition;race condition	Bruce W. Porter;Dennis F. Kibler	1985			mathematical optimization;computer science;artificial intelligence;machine learning;mathematics;statistics;satisfiability	ML	-6.96359063859856	-26.386026480791745	18336
a9f7caf8394de3f2cd954ad7a83b45171c481f7a	the designing of a web page recommendation system for esl	article summary technique;web pages;reading material;search engines;computer aided instruction;article summary;search method;search engines computer aided instruction internet metacomputing;learning environment;english as a second language;recommender system;internet;meta search api;article summary web page recommendation system english as a second language meta search api;second language;english learning web page recommendation system meta search article summary technique reading material article searching mechanism;meta search;web pages search engines metasearch internet information filtering information filters databases search methods natural languages education;metacomputing;english learning;english as a;web page recommendation system;article searching mechanism	In this paper, a webpage reading recommendation system is constructed through the concept of meta search and article summary technique. The designed system recommends webpages that are related to the current webpage, to provide the user with further reading material. Using article-searching mechanism, the ESL student can avoid using keyword-based search method, thereby greatly decreasing the time spent to look for related articles. The system provides related articles as well as information such as the difficulty of the articles, which would assist English learning, and harbor a more user friendly English learning environment. This in turn increases learning efficiency. A designed toolbar serves as the main medium of communication with the user. All the user has to do is install the toolbar on the browser to gain the assistance from the system.	recommender system;usability;web page	Chen-Chung Chi;Chin-Hwa Kuo;Chia-Chun Peng	2007	Seventh IEEE International Conference on Advanced Learning Technologies (ICALT 2007)	10.1109/ICALT.2007.241	the internet;computer science;web page;database;multimedia;world wide web;information retrieval;search engine;recommender system	Robotics	-32.82110614919912	-48.76288383126283	18355
0da99daf9df75e4640eafac6ebe61d8fddf011b5	frequent itemset mining using cellular learning automata	parallel frequent itemset mining;association rules;data mining;frequent itemset mining;cellular automata	A core issue of the association rule extracting process in the data mining field is to find the frequent patterns in the database of operational transactions. If these patterns discovered, the decision making process and determining strategies in organizations will be accomplished with greater precision. Frequent pattern is a pattern seen in a significant number of transactions. Due to the properties of these data models which are unlimited and high-speed production, these data could not be stored in memory and for this reason it is necessary to develop techniques that enable them to be processed online and find repetitive patterns. Several mining methods have been proposed in the literature which attempt to efficiently extract a complete or a closed set of different types of frequent patterns from a dataset. In this paper, a method underpinned upon Cellular Learning Automata (CLA) is presented for mining frequent itemsets. The proposed method is compared with Apriori, FP-Growth and BitTable methods and it is ultimately concluded that the frequent itemset mining could be achieved in less running time. The experiments are conducted on several experimental data sets with different amounts of minsup for all the algorithms as well as the presented method individually. Eventually the results prod to the effectiveness of the proposed method.	association rule learning;automata theory;learning automata	Mohammad Karim Sohrabi;Reza Roshani	2017	Computers in Human Behavior	10.1016/j.chb.2016.11.036	cellular automaton;association rule learning;computer science;data science;data mining;database;k-optimal pattern discovery	ML	-5.285825372716585	-35.04980763304804	18390
3e760ab9e6e08a762253c08304bdfe2bd1bd1826	from black and white to full color: extending redescription mining outside the boolean world	bioclimatic niche finding;data mining;numerical data;redescription mining;missing data	Redescription mining is a powerful data analysis tool that is used to find multiple descriptions of the same entities. Consider geographical regions as an example. They can be characterized by the fauna that inhabits them on one hand and by their meteorological conditions on the other hand. Finding such redescriptors, a task known as niche-finding, is of much importance in biology. But current redescription mining methods cannot handle other than Boolean data. This restricts the range of possible applications or makes discretization a prerequisite, entailing a possibly harmful loss of information. In nichefinding, while the fauna can be naturally represented using a Boolean presence/absence data, the weather cannot. In this paper, we extend redescription mining to realvalued data using a surprisingly simple and efficient approach. We provide extensive experimental evaluation to study the behaviour of the proposed algorithm. Furthermore, we show the statistical significance of our results using recent innovations on randomization methods.	beam search;discretization;entity;experiment;niche blogging;preprocessor;randomized algorithm;synthetic intelligence	Esther Galbrun;Pauli Miettinen	2012	Statistical Analysis and Data Mining	10.1002/sam.11145	missing data;data science;data mining;mathematics;statistics	ML	-9.706018770812985	-36.93228753364821	18396
2291ce8b9e6a4e7792cab704f2259c3ac9de14d4	the influence of investor attention on return and volatility of stock market	search engines;industries;companies;stock markets;indexes;internet;estimation	Applying internet data to investor attention research is a trend now. This paper propose a new method to measure positive and negative investor attention paid to a certain industry by using of search data from search engine. We select keywords from a corpus of energy industry by text-analysis technique including TextRank algorithm instead of taking company names or stock tickers as keywords in previous studies. After selecting keywords, we calculating two indices by PCA method. The empirical analysis demonstrates that the positive index has significantly negative effect on stock index volatility. However, the negative index has significant influence on volatility. These results shows the rationality of our indices construction.	algorithm;internet;principal component analysis;rationality;text corpus;volatility;web search engine	Wen Long;Bin Wang;Lingxiao Cui	2016	2016 IEEE/WIC/ACM International Conference on Web Intelligence Workshops (WIW)	10.1109/WIW.2016.027	capitalization-weighted index;database index;estimation;the internet;computer science;statistics	DB	-9.162444817445532	-30.63220997734578	18465
3cabbac2a601a82825173122f2f6182edcd6c271	generalized markov models of infectious disease spread: a novel framework for developing dynamic health policies	health research;dynamic programming;uk clinical guidelines;biological patents;infectious disease models dynamic health policy discrete time markov chain dynamic programming epidemiology;europe pubmed central;citation search;epidemiology;infectious disease models;discrete time markov chain;uk phd theses thesis;life sciences;dynamic health policy;uk research reports;medical journals;europe pmc;biomedical research;bioinformatics	We propose a class of mathematical models for the transmission of infectious diseases in large populations. This class of models, which generalizes the existing discrete-time Markov chain models of infectious diseases, is compatible with efficient dynamic optimization techniques to assist real-time selection and modification of public health interventions in response to evolving epidemiological situations and changing availability of information and medical resources. While retaining the strength of existing classes of mathematical models in their ability to represent the within-host natural history of disease and between-host transmission dynamics, the proposed models possess two advantages over previous models: (1) these models can be used to generate optimal dynamic health policies for controlling spreads of infectious diseases, and (2) these models are able to approximate the spread of the disease in relatively large populations with a limited state space size and computation time.	approximation algorithm;class;communicable diseases;computation;dynamic programming;epidemiology;health policy;markov chain;markov model;mathematical model;mathematical optimization;mathematics;natural history;population;real-time transcription;state space;time complexity	Reza Yaesoubi;Ted Cohen	2011	European journal of operational research	10.1016/j.ejor.2011.07.016	epidemiology;marketing;operations management;dynamic programming;management science;operations research	ML	-8.860478104490513	-50.19437014478932	18569
f7a7c889155cdcae467d5f22e440a447d773fcf2	noun retrieval effect on text summarization and delivery of personalized news articles to the user's desktop	news personalization;noun;information retrieval;text summarization;web based information;part of speech tagging;indexation;keyword extraction;noun retrieval;knowledge discovery	Text summarization and categorization, as well as personalization of the results, have always been some of the most demanding information retrieval tasks. Deploying a generalized, multi-functional mechanism that produces good results for the aforementioned tasks seems to be a panacea for most of the text-based, information retrieval needs. In this article, we present the keyword extraction techniques, exploring the effects that part of speech tagging has on the summarization procedure of an existing system. Moreover, we describe the profiling features that are used as an extension to an already constructed news indexing system, PeRSSonal. We are thus enhancing the personalization algorithm that the system utilizes with various features derived from the user’s profile, such as the list of viewed articles and the time spent on them. In addition, we analyze the system’s interconnection channels that are used with the client-side desktop application that was developed and we evaluate the approaches that we propose. 2010 Elsevier B.V. All rights reserved.	algorithm;automatic summarization;categorization;channel (communications);client-side;collaborative filtering;desktop computer;information retrieval;interactivity;interconnection;keyword extraction;part-of-speech tagging;personalization;text-based (computing);user profile;web 2.0;world wide web	Christos Bouras;Vassilis Tsogkas	2010	Data Knowl. Eng.	10.1016/j.datak.2010.02.005	noun;multi-document summarization;computer science;automatic summarization;data mining;database;knowledge extraction;world wide web;information retrieval	AI	-27.819586244668542	-51.74194093825624	18571
893b6cd7c7b191160bfd49c0bb0945a881ccf710	cbs: a concept-based sequencer for soundtrack composition	concept mappings concept based sequencer soundtrack music composition probability based techniques grammatical generation methods temporal media semantic markup genetic algorithms web based repository;internet;general methods;concept map;xml;genetic algorithm;genetic algorithms;markov processes music genetic algorithms xml internet;markov processes;music;genetic algorithms stochastic processes computer science genetic mutations couplings focusing layout knowledge based systems guidelines stochastic systems	Existing methods of music composition vary from probability-based techniques to grammatical generation methods, yet the majority focus on the creation of independent pieces with no ties to other media. Our Concept-Based Sequencer (CBS) aims to use semantic markup of temporal media in combination with Genetic Algorithms to generate music that can fit scripted content such as film and radio. Genetic Algorithms offer an evolutionary approach which allows mutation but within a specified context. The concept here allows for linkage between media. This paper describes the techniques behind the CBS, and the construction of a web-based repository for concept mappings.	genetic algorithm;iterative and incremental development;linkage (software);markup language;microsequencer;semantic html;soundtrack pro;web application;while	Michael O. Jewell;Mark S. Nixon;Adam Prügel-Bennett	2003		10.1109/WDM.2003.1233882	natural language processing;computer science;theoretical computer science;multimedia	AI	-31.979743625145737	-47.288553130527134	18643
59e9006b0e763f5e23fd66eb6b778ab631653650	a fast algorithm for mining share-frequent itemsets	satisfiability;frequent itemset;association rule;fast algorithm;profitability	Itemset share has been proposed as a measure of the importance of itemsets for mining association rules. The value of the itemset share can provide useful information such as total profit or total customer purchased quantity associated with an itemset in database. The discovery of share-frequent itemsets does not have the downward closure property. Existing algorithms for discovering share-frequent itemsets are inefficient or do not find all share-frequent itemsets. Therefore, this study proposes a novel Fast Share Measure (FSM) algorithm to efficiently generate all share-frequent itemsets. Instead of the downward closure property, FSM satisfies the level closure property. Simulation results reveal that the performance of the FSM algorithm is superior to the ZSP algorithm two to three orders of magnitude between 0.2% and 2% minimum share thresholds.	algorithm;association rule learning;data mining;simulation;social inequality	Yu-Chiang Li;Jieh-Shan Yeh;Chin-Chen Chang	2005		10.1007/978-3-540-31849-1_41	association rule learning;computer science;data mining;database;algorithm;profitability index;satisfiability	DB	-5.901235387537203	-36.213124895487965	18667
48da736f5adecb26cd743d1704575f484efa7d52	representing and parsing sketched symbols using adjacency grammars and a grid-directed parser	user interface;pen computing;syntactic pattern recognition;pen input;topological relation	While much work has been done in Structural and Syntactical Pattern Recognition applied to drawings, most approaches are non-interactive. However, the recent emergence of viable pen-computers makes it desirable to handle pen-input such as sketches and drawings interactively. This paper presents a syntax-directed approach to parse sketches based on Relational Adjacency Grammars, which describe spatial and topological relations among parts of a sketch. Our approach uses a 2D grid to avoid re-scanning all the previous input whenever new strokes entered into the system, thus speeding up parsing considerably. To evaluate the performance of our approach we have tested the system using non-trivial inputs analyzed with two different grammars, one to design user interfaces and the other to describe floor-plans. The results clearly show the effectiveness of our approach and demonstrate good scalability to larger drawings.	parser;parsing	Joan Mas Romeu;Joaquim A. Jorge;Gemma Sánchez;Josep Lladós	2007		10.1007/978-3-540-88188-9_17	natural language processing;l-attributed grammar;computer science;theoretical computer science;machine learning;programming language;user interface	NLP	-30.293017855547	-36.22239633314979	18705
9e8d87dc5d8a6dd832716a3f358c1cdbfa97074c	what makes an image popular?	popularity;flickr;regression;deep learning;images	Hundreds of thousands of photographs are uploaded to the internet every minute through various social networking and photo sharing platforms. While some images get millions of views, others are completely ignored. Even from the same users, different photographs receive different number of views. This begs the question: What makes a photograph popular? Can we predict the number of views a photograph will receive even before it is uploaded? These are some of the questions we address in this work. We investigate two key components of an image that affect its popularity, namely the image content and social context. Using a dataset of about 2.3 million images from Flickr, we demonstrate that we can reliably predict the normalized view count of images with a rank correlation of 0.81 using both image content and social cues. In this paper, we show the importance of image cues such as color, gradients, deep learning features and the set of objects present, as well as the importance of various social cues such as number of friends or number of photos uploaded that lead to high or low popularity of images.	deep learning;flickr;gradient	Aditya Khosla;Atish Das Sarma;Raffay Hamid	2014		10.1145/2566486.2567996	regression;computer science;machine learning;deep learning;multimedia;internet privacy;world wide web	Vision	-18.64274486826116	-50.98805075641632	18776
2ab0fe3d41e2bff65bec4fb05ff273ab5f86e92a	on-line imitative interaction with a humanoid robot using a dynamic neural network model of a mirror system	robot learning;humanoid robot;system approach;mirror system;entertainment robot;movement pattern;dynamic neural network;dynamical systems approach;recurrent neural network;imitation learning;robot dynamics;joint attention	This study presents experiments on the imitative interactions between a small humanoid robot and a user. A dynamic neural network model of a mirror system was implemented in a humanoid robot, based on the recurrent neural network model with parametric bias (RNNPB). The experiments showed that after the robot learns multiple cyclic movement patterns as embedded in the RNNPB, it can regenerate each pattern synchronously with the movements of a human who is demonstrating the corresponding movement pattern in front of the robot. Further, the robot exhibits diverse interactive responses when the user demonstrates novel cyclic movement patterns. Those responses were analyzed and categorized. We propose that the dynamics of coherence and incoherence between the robot’s and the user’s movements could enhance close interactions between them, and also that they could explain the essential psychological mechanism of joint attention. keywords entertainment robot, imitation learning, mirror system, recurrent neural network, dynamical systems approach	artificial neural network;autonomous robot;categorization;coherence (physics);dynamical system;embedded system;entertainment robot;experiment;humanoid robot;interaction;network model;neuron;nonlinear system;random neural network;recurrent neural network;synthetic intelligence	Masato Ito;Jun Tani	2004	Adaptive Behaviour	10.1177/105971230401200202	robot learning;joint attention;computer vision;simulation;computer science;humanoid robot;artificial intelligence;recurrent neural network;social robot;robot control;mirror neuron;communication	Robotics	-29.25341419004513	-39.63955927040234	18804
288f4f222fbb7c9fdc04b03a9764ac7611c77912	on a probabilistic combination of prediction sources	prediction method;theoretical framework;personalization;data mining;recommender system;collaborative filtering;recommender systems;production rule	Recommender Systems (RS) are applications that provide personalized advice to users about products or services they might be interested in. To improve recommendation quality, many hybridization techniques have been proposed. Among all hybrids, the weighted recommenders have the main benefit that all of the system’s constituents operate independently and stand in a straightforward way over the recommendation process. However, the hybrids proposed so far consist of a linear combination of the final scores resulting from all recommendation techniques available. Thus, they fail to provide explanations of predictions or further insights into the data. In this work, we propose a theoretical framework to combine information using the two basic probabilistic schemes: the sum and product rule. Extensive experiments have shown that our purely probabilistic schemes provide better quality recommendations compared to other methods that combine numerical scores derived from each prediction method individually.	experiment;numerical analysis;personalization;recommender system	Ioannis Rousidis;George Tzagkarakis;Dimitris Plexousakis;Yannis Tzitzikas	2008		10.1007/978-3-540-68123-6_58	computer science;artificial intelligence;collaborative filtering;machine learning;data mining;personalization;database;recommender system	ML	-21.13824272368206	-47.46120153520578	18809
cd27fd2905d17e04aa863317bb38bdaaedc5f082	who's driving my car? a machine learning based approach to driver identification		Despite the development of new technologies, in order to prevent the stealing of cars, the number of car thefts is sharply increasing. With the advent of electronics, new ways to steal cars were found. To avoid auto-theft attacks, in this paper we propose a machine leaning based method to silently e continuously profile the driver by analyzing built-in vehicle sensors. We evaluate the efficiency of the proposed method in driver identification using 10 different drivers. Results are promising, as a matter of fact we obtain a high precision and a recall evaluating a dataset containing data extracted from real vehicle.	autonomous car;canonical account;machine learning;sensor	Fabio Martinelli;Francesco Mercaldo;Vittoria Nardone;Albina Orlando;Antonella Santone	2018		10.5220/0006633403670372	computer science;machine learning;artificial intelligence	AI	-20.305706166059082	-29.869564550552383	18875
d83b47d947dce5081fa47cf6a34a33c062785a02	a sequential pattern mining algorithm based on improved fp-tree	databases;tree data structures data mining database management systems;sequential database;machine learning algorithms;itemsets;sequential pattern mining algorithm;pediatrics;database management systems;association rules;tree data structures;data mining;sequential database sequential pattern mining algorithm data mining stmfp algorithm fp tree structure;tree structure;itemsets databases data mining pediatrics algorithm design and analysis association rules machine learning algorithms;fp tree structure;sequential pattern mining;stmfp algorithm;sequential pattern;algorithm design and analysis	Sequential pattern mining is an important data mining problem with broad application. Most of the previously developed sequential pattern mining methods need to scan the database many times. In this study, STMFP algorithm based on improved FP-tree is presented for sequential pattern mining. By improving the FP-tree structure, every node of the tree can store a set of items instead of one item. After scanning the sequential database once time, the tree can store all the sequences. In addition, a novel mining method, combining nodes from leaf to root which helps mining sequential patterns, is proposed. The cost of mining pattern sequence is divided into two parts. One is to construct STMFP Tree. The cost of this part associates with the size of sequential database. Another one is to find random assembled nodes from leaf to root in every path of STMFP tree. Because the maximal length of path is bounded by the maximal length of one transaction, and there are exiting common nodes which help reduce the number of leaf nodes, so the cost of this part must be much less than the size of the database. Compared with other methods which need to scan the sequential database many times, the cost of our method must be less than two passes of the database. Through the whole mining process, it only needs scan the database once time.	abstract syntax tree;algorithm;data mining;maximal set;pattern matching;sequential pattern mining;tree (data structure);tree structure	Yi Sui;Fengjing Shao;Rencheng Sun;Jinlong Wang	2008	2008 Ninth ACIS International Conference on Software Engineering, Artificial Intelligence, Networking, and Parallel/Distributed Computing	10.1109/SNPD.2008.161	sequential pattern mining;algorithm design;gsp algorithm;association rule learning;computer science;pattern recognition;data mining;database;tree structure;tree	DB	-4.874606650907411	-36.83122379814488	18891
9640baa88586f069e1dbc505c613694b61ec94d7	performance evaluation of automatic name placement functions for geographical database systems	performance evaluation;geographic database	Geographical information systems have been studied and actively developed in various field. One of their characteristics that distinguishes them from paper-based maps is their ability to retrieve various kinds of geographical information, compose the information, and display it on maps. In addition, these operations must be done very quickly. The system is required to provide a visual and high-level user interface. When retrieved data are composed on maps, one of the major problems is to deal with character information, which is to place names appropriately so that each of them is easily associated with its feature. We must take into account the fact that the displayed map, since it is a form of visualized representation of data, may not be a complete map. For this reason, the output maps are desirable to be displayed in realtime, and also they must be legible. In this paper, we describe our automatic name placement functions and discuss their performances.	automatic label placement;geographic information system;high- and low-level;map;norm (social);performance evaluation;real-time computing;user interface	Nobuhiko Kojiro;Ken'ichi Miura;Hiroshi Imai;Yahiko Kambayashi	1991			computer science;data mining;database;information retrieval;database design	Graphics	-33.317895516987086	-34.90428939111309	18935
8d18855d9ede195f128fb12160bc2ea84e699565	low-cost system for detecting traffic offences		This paper describes the implementation of a prototype installation for automatic detection of traffic offences with the use of video camera real time analysis. In this paper, we focus on the technical aspect of the installation as well as on the possibilities to implement algorithms to detect offenders. The project of the installation assumed the use of low-cost series of components and reducing infrastructure requirements in the place of assembly of the equipment.	algorithm;prototype;requirement;sensor	Lukasz Kaminski;Michal Lyczek;Michal Poplawski	2010		10.7148/2010-0122-0125	real-time computing;computer science;video camera	OS	-21.81646988333415	-29.54146301199733	18967
1998209322ab5aed99d44c83fddaa77ab423a00f	snow phenomena modeling through online public media	pipeline structure snow phenomena modeling online public media environmental monitoring publicly available media user generated content ugc snow cover social media data geo tagged photographs public webcams data crawling automatic relevance classification image content analysis environmental models snow covered area;scene classification;ugc;snow webcams clouds media pipelines estimation monitoring;scene classification ugc environmental modeling virtual sensors object identification;virtual sensors;object identification;environmental modeling;social networking online cameras geophysical image processing pattern classification pipeline processing snow	We propose a method for the environmental monitoring through the publicly available media User Generated Content (UGC). In particular we address the problem of the snow cover and level estimation by analyzing the social media data such as geotagged photographs and public webcams installed in mountain regions. The entire pipeline of the process is presented to the audience: from the data crawling and automatic relevance classification (does or does not the photograph contain a significant mountain profile) to the image content analysis and environmental models (identification of the snow covered area on the photograph). Each presented component is self-contained and can be inspected individually, the connections between the components however are strongly highlighted allowing the viewer to understand intuitively the entire pipeline structure.	geotagging;relevance;social media;webcam	Roman Fedorov;Piero Fraternali;Marco Tagliasacchi	2014	2014 IEEE International Conference on Image Processing (ICIP)	10.1109/ICIP.2014.7025438	simulation;computer science;internet privacy;user-generated content	Robotics	-24.91377968075648	-51.97512332170678	19028
c73b92edd1f657a158672c6d32c5742af40e93ff	the research on knowledge diffusion based on small world network	expert;knowledge diffusion;small world	Small world is a sort of network between regular and random network that has the feature of both shorter characteristic path length and higher clustering coefficient, which is an appropriate model for the research of knowledge diffusion. There is simulation in this paper to certificate the validity of small world network in knowledge diffusion. In order to reflect the real world the model is completed by including expert as one influence factor and currency as the other to reflect knowledge transaction. Simulation results show that small world network do exist in knowledge diffusion.		Xinxin Feng;Baojiang Chen;Huanzhi Zhu	2013		10.1007/978-3-642-39137-8_23	knowledge management;data science;management science	Vision	-19.451552020643753	-40.35899383307504	19153
4d1f39001282d5e77be6a2038673ab92389df62c	dimscanner: a relation-based visual exploration approach towards data dimension inspection	measurement;two dimensional displays;layout;inspection;visualization;data visualization;correlation	Exploring multi-dimensional datasets can be cumbersome if data analysts have little knowledge about the data. Various dimension relation inspection tools and dimension exploration tools have been proposed for efficient data examining and understanding. However, the needed workload varies largely with respect to data complexity and user expertise, which can only be reduced with rich background knowledge over the data. In this paper we address the workload challenge with a data structuring and exploration scheme that affords dimension relation detection and that serves as the background knowledge for further investigation. We contribute a novel data structuring scheme that leverages an information-theoretic view structuring algorithm to uncover information-aware relations among different data views, and thereby discloses redundancy and other relation patterns among dimensions. The integrated system, DimScanner, empowers analysts with rich user controls and assistance widgets to interactively detect the relations of multi-dimensional data.	algorithm;categorization;cognitive science;computation;data structure;in-memory database;information theory;interactivity;parallel computing	Jing Xia;Wei Chen;Yumeng Hou;Wanqi Hu;Xinxin Huang;David S. Ebert	2016	2016 IEEE Conference on Visual Analytics Science and Technology (VAST)	10.1109/VAST.2016.7883514	layout;computer vision;visualization;inspection;computer science;data science;data mining;correlation;data visualization;measurement;statistics	Visualization	-27.207062758903227	-33.913522778095974	19181
f08442949154afe3311070d3ee0af969ed7854dc	detecting system anomalies in multivariate time series with information transfer and random walk		Detecting major system anomalies with observed multivariate time series requires not only the characteristics of each time series but also the status of the entire time series dynamics. Therefore, we propose a method that can detect substantial anomalies by generating a transfer network and an influence network from a multivariate time series. To form a transfer network, each vertex represents a single time series. Each edge indicates the strength of the information flow between each pair of time series using transfer entropy. With the transfer network, we exploit the random walk approach to calculate the affinity score between two vertices and create an influence network that reflects both the direct and indirect influences. In our experiment, we show the efficacy of the proposed method using simple synthetic time series networks and the real data set such as world stock indices and key performance indicators of the SAP HANA in-memory database system.		Jongsun Lee;Hyun-Soo Choi;Yongkweon Jeon;Yongsik Kwon;Donghun Lee;Sungroh Yoon	2018	2018 IEEE/ACM 5th International Conference on Big Data Computing Applications and Technologies (BDCAT)	10.1109/BDCAT.2018.00017	performance indicator;data mining;random walk;computer science;transfer entropy;sap hana;information flow (information theory);multivariate statistics;anomaly detection;information transfer	DB	-19.178142430938564	-38.58248204643501	19199
2d1546e72bc294f83570346c6ef1289dd7be9b41	effective and effortless features for popularity prediction in microblogging network	temporal features;popularity prediction;classification;social network;microblogging	Predicting popularity of online contents is of remarkable practical value in various business and administrative applications. Existing studies mainly focus on finding the most effective features for prediction. However, some effective features, such as structural features which are extracted from the underlying user network, are hard to access. In this paper, we aim to identify features that are both effective and effortless (easy to obtain or compute). Experiments on Sina Weibo show the effectiveness and effortlessness of the temporal features and satisfying prediction performance can be obtained based on only the temporal features of first 10 retweets.		Shuai Gao;Jun Ma;Zhumin Chen	2014		10.1145/2567948.2577312	biological classification;computer science;microblogging;data mining;internet privacy;world wide web;social network	Web+IR	-22.7956575996478	-48.107227526844	19220
e8caddea902a45f1c38ca5e6d78b43ef32a8588c	comparison of four subjective methods for image quality assessment	subjective metrics;single stimulus;pairwise comparison;quality metrics;user studies;double stimulus;i 3 6 computer graphics methodology and techniques;ranking;image quality;similarity judgements	To provide a convincing proof that a new method is better than the state-of-th e-ar , computer graphics projects are often accompanied by user studies, in which a group of observers r ank or rate results of several algorithms. Such user studies, known as subjective image quality assessment exper im nts, can be very time consuming and do not guarantee to produce conclusive results. This paper is intended to he lp design efficient and rigorous quality assessment experiments and emphasise the key aspects of the results a nalysi . To promote good standards of data analysis, we review the major methods for data analysis, such as establishin g confidence intervals, statistical testing and retrospective power analysis. Two methods of visualising rank ing results together with the meaningful information about the statistical and practical significance are explored. F inally, we compare four most prominent subjective quality assessment methods: single-stimulus, double-stimulus, forced-choice pairwise comparison, and similarity judgements. We conclude that the forced-choice pairwise compar ison method results in the smallest measurement variance and thus produces the most accurate results. This method is also the most time-efficient, assuming a moderate number of compared conditions.	blackwell (series);computer graphics;distortion;eurographics;expectation propagation;experiment;image quality;sorting algorithm;usability testing	Rafal Mantiuk;Anna Lewandowska;Radoslaw Mantiuk	2012	Comput. Graph. Forum	10.1111/j.1467-8659.2012.03188.x	image quality;pairwise comparison;ranking;computer science;data science;data mining;mathematics;statistics	Graphics	-26.330783202695805	-37.584488866148334	19234
7ff9bac5114e63b968946aedb2e41cab549e311a	learning user preferences by observing user-items interactions in an iot augmented space		Recommender systems generate recommendations by analysing which items the user consumes or likes. Moreover, in many scenarios, e.g., when a user is visiting an exhibition or a city, users are faced with a sequence of decisions, and the recommender should therefore suggest, at each decision step, a set of viable recommendations (attractions). In these scenarios the order and the context of the past user choices is a valuable source of data, and the recommender has to effectively exploit this information for understanding the user preferences in order to recommend compelling items.  For addressing these scenarios, this paper proposes a novel preference learning model that takes into account the sequential nature of item consumption. The model is based on Inverse Reinforcement Learning, which enables to exploit observations of users' behaviours, when they are making decisions and taking actions, i.e., choosing the items to consume. The results of a proof of concept experiment show that the proposed model can effectively capture the user preferences, the rationale of users decision making process when consuming items in a sequential manner, and can replicate the observed user behaviours.	autonomous robot;design rationale;experiment;high- and low-level;human–computer interaction;integrated development environment;machine learning;pc bruno;preference learning;recommender system;reinforcement learning;scalability;self-replicating machine;state space;user (computing);web application	David Massimo;Mehdi Elahi;Francesco Ricci	2017		10.1145/3099023.3099070	data mining;user modeling;replicate;recommender system;proof of concept;decision-making;reinforcement learning;machine learning;exploit;artificial intelligence;preference learning;computer science	AI	-25.424298215345868	-42.200262324826426	19304
842e398edd5382de0a45cc4e040a936ea334c69f	consumsense: a framework for physical consuming behavior prediction on smartphones	consuming activity;easy card;consuming behavior;prediction accuracy;consumer behavior;online consuming behavior;proposed framework;physical consuming behavior prediction;smartphones;physical store;context awareness;smartphone system;daily life;consumsense;consumer behaviour;android;smart phones;physical consuming behavior;3-week experiment;mobile computing;android (operating system);learning and prediction	Automatic track and prediction of consumer behaviors involve huge commercial interests and have been studied extensively in the past. We have seen very successful application of such techniques on online consuming behaviors. However, it is still very challenging to predict consumer behaviors in physical stores, because many operations in the middle are not digitized. As smartphones are becoming indispensible in our daily life, we propose to build a framework, called ConsumSense, into the smartphones that observes in close-up the physical consuming behavior of the user and predicts his/her future purchases. Our framework addresses two difficult issues: (1) how to use the limited number of sensors on a smart phone to observe and predict the consuming behavior of its user? (2) how to verify and correlate the purchases? To demonstrate the feasibility of the proposed framework, we have developed the framework on Android and evaluated it by asking 14 participants to conduct a 3-week experiment by using Easy card during their daily life. The results show that time and location are the most important contexts for predicting consuming activities and our framework can achieve a 76% prediction accuracy.	android;bayesian network;digital wallet;near field communication;network model;overhead (computing);privacy;purchasing;sensor;smartphone	Guanzhong Ding;Chung-Ta King;Yi-Fan Chung	2013	2013 International Conference on Parallel and Distributed Systems	10.1109/ICPADS.2013.36	embedded system;mobile telephony;computer science;sensor;operating system;semantics;context model;internet privacy;mobile computing;computer security	HCI	-24.20810442773264	-45.01630308134696	19438
979fb6523f7fba01cec1e14b043ca005835fcb33	towards a unified planner for socially-aware navigation		This paper presents a novel architecture to attain a Unified Socially-Aware Navigation (USAN) and explains its need in Socially Assistive Robotics (SAR) applications. Our approach emphasize interpersonal distance and how spatial communication can be used to build a unified planner for a human-robot collaborative environment. Socially-Aware Navigation (SAN) is vital to make humans feel comfortable and safe around robots; HRI studies have shown the importance of SAN transcendents safety and comfort. SAN plays a crucial role in perceived intelligence, sociability and social capacity of the robot, thereby increasing the acceptance of the robots in public places. Human environments are very dynamic and pose serious social challenges to robots intended for interactions with people. For the robots to cope with the changing dynamics of a situation, there is a need to infer intent and detect changes in the interaction context. SAN has gained immense interest in the social robotics community; to the best of our knowledge, however, there is no planner that can adapt to different interaction contexts spontaneously after autonomously sensing the context. Most of the recent efforts involve social path planning for a single context. In this work, we propose a novel approach for a unified architecture to SAN that can plan and execute trajectories which are humanfriendly for an autonomously sensed interaction context. Our approach augments the navigation stack of the Robot Operating System (ROS) utilizing machine learning and optimization tools. We modified the ROS navigation stack using a machine learning-based context classifier and a PaCcET based local planner for us to achieve the goals of USAN. We discuss our preliminary results and concrete plans on putting the pieces together in achieving USAN.	artificial neural network;google map maker;humans;human–robot interaction;machine learning;mathematical optimization;motion planning;multi-objective optimization;optimization problem;robot operating system;robotics;social robot;software feature;storage area network	Santosh Balajee Banisetty;David Feil-Seifer	2018	CoRR		architecture;engineering;simulation;planner;social robot;motion planning;robot;robotics;artificial intelligence;interpersonal communication	Robotics	-32.03859844682895	-40.61919036786757	19440
c4416c828a9b11b306a932bbba26e76f2b5a253f	using uncertainty of bayesian theorem to predict mortality of tree in forest growth simulation system		Researchers have done a lot of methods to link between growth rate and mortality. However, very little information about the uncertainty involve in tree mortality process. In this study, we presented the mortality prediction in forest simulation system by using uncertainty technique of Bayesian approach based on individual tree. The prediction will take account the overlapping of tree crowns, whether the species are shade tolerance or intolerance and the number of years the tree is under shade of suppression. The system will display the end status of the tree. The decision of the end status of the tree for dead tree is based on the ranking of the tree. The tree has higher potential to be dead if it is under suppression for several cycles. This new approach appears practicable particularly on its ability to project the mortality trees in their respective location. In addition, this approach will improve the decision-making process of the sustainable management of tropical forest as well as to improve its information database system.	cycle (graph theory);database;simulation;zero suppression	Yasmin Yahya;Roslan Ismail	2018		10.1145/3164541.3164622	sustainable management;real-time computing;tropical forest;computer science;shade tolerance;bayes' theorem;artificial intelligence;ranking;bayesian probability;pattern recognition	AI	-10.220076568881117	-25.13119876641688	19471
ed31c96f2b2a3f17982e1b7df90cc162940fade4	second chance: a hybrid approach for dynamic result caching and prefetching in search engines	dynamic result caching;result prefetching;web search engines	Web search engines are known to cache the results of previously issued queries. The stored results typically contain the document summaries and some data that is used to construct the final search result page returned to the user. An alternative strategy is to store in the cache only the result document IDs, which take much less space, allowing results of more queries to be cached. These two strategies lead to an interesting trade-off between the hit rate and the average query response latency. In this work, in order to exploit this trade-off, we propose a hybrid result caching strategy where a dynamic result cache is split into two sections: an HTML cache and a docID cache. Moreover, using a realistic cost model, we evaluate the performance of different result prefetching strategies for the proposed hybrid cache and the baseline HTML-only cache. Finally, we propose a machine learning approach to predict singleton queries, which occur only once in the query stream. We show that when the proposed hybrid result caching strategy is coupled with the singleton query predictor, the hit rate is further improved.	analysis of algorithms;baseline (configuration management);cpu cache;cache (computing);document;html;kerrison predictor;link prefetching;machine learning;web search engine	Rifat Ozcan;Ismail Sengör Altingövde;Berkant Barla Cambazoglu;Özgür Ulusoy	2013	TWEB	10.1145/2536777	cache-oblivious algorithm;real-time computing;cache coloring;page cache;cache;computer science;cache invalidation;database;smart cache;cache algorithms;cache pollution;world wide web	Web+IR	-15.80592025018214	-37.485965822789744	19485
ae3c40f6769350b69aae46fe8e6d095bc3df9e7b	hup-me: inferring and reconciling a timeline of user activity from rich smartphone data	dynamic bayesian networks;smartphone sensors;multimodal transport networks;itinerary recognition;activity recognition	We designed a system to infer multimodal itineraries traveled by a user from a combination of smartphone sensor data (e.g., GPS, Wi-Fi, accelerometer) and knowledge of the transport network infrastructure (e.g., road and rail maps, public transportation timetables). The system uses a Transportation network that captures the set of possible paths of this network for the modes, e.g., foot, bicycle, road_vehicle, and rail. This Transportation network is constructed from OpenStreetMap data and public transportation routes published online by transportation agencies in GTFS format. The system infers itineraries from a sequence of smartphone observations in two phases. The first phase uses a dynamic Bayesian network that models the probabilistic relationship between paths in Transportation network and sensor data. The second phase attempts to match portions recognized as road_vehicle or rail with possible public transportation routes of type bus, train, metro, or tram extracted from the GTFS source. We evaluated the performance of our system with data from users traveling over the Paris area who were asked to record data for different trips via an Android application. Itineraries were annotated with modes and public transportation routes taken and we report on the results of the recognition.	android;dynamic bayesian network;general transit feed specification;global positioning system;map;multimodal interaction;openstreetmap;schedule;smartphone;timeline	David Montoya;Serge Abiteboul;Pierre Senellart	2015		10.1145/2820783.2820852	simulation;computer science;machine learning;computer security;dynamic bayesian network;activity recognition	Mobile	-19.20136474536341	-31.59839273907774	19511
01d711358705c09656c4deb5cd46907a12862637	adaptive web sites: conceptual cluster mining	cluster algorithm;conceptual clustering;indexation;concept learning;user interface design;adaptive web site	The creation of a complex web site is a thorny problem in. user interface design. In I J C A I '97, we challenged the AI community to address this problem by creating adaptive web sites. In response, we investigate the problem of index page synthesis — the automatic creation of pages that facil itate a visitor's navigation of a Web site. Previous work has employed statisti­ cal methods to generate candidate index pages that are of l imited value because they do not correspond to concepts or topics that are in­ tuit ive to people. In this paper we formalize index page synthesis as a conceptual clustering problem and introduce a novel approach which we call conceptual cluster mining: we search for a small number of cohesive clusters that corre­ spond to concepts in a given concept descrip­ t ion language L. Next, we present SGML, an algorithm schema that combines a statistical clustering algorithm with a concept learning algorithm. The clus­ tering algorithm is used to generate seed clus­ ters, and the concept learning algorithm to de­ scribe these seed clusters using expressions in L. Finally, we offer preliminary experimental evidence that instantiations of SGML outper­ form existing algorithms (e.g., COBWEB) in this domain.	algorithm;cluster analysis;concept learning;conceptual clustering;home page;standard generalized markup language;user interface design	Mike Perkowitz;Oren Etzioni	1999			user interface design;concept learning;computer science;artificial intelligence;data science;machine learning;data mining;cluster analysis;world wide web;conceptual clustering	AI	-31.952666525525313	-47.422790122130685	19566
1bbcd03fe7cc0140bb818c3689640aa4d2de2a6b	energy-based clustering of graphs with nonuniform degrees	modelizacion;graph theory;estimacion sesgada;reseau social;analyse amas;teoria grafo;lien hypertexte;subgrafo;grado grafo;graph drawing;enlace hipertexto;metodo energetico;dependence graph;error sistematico;semantics;energy method;hyperlink;semantica;semantique;classification;theorie graphe;modelisation;social network;representacion de grafos;cluster analysis;bias;sous graphe;estructura social;methode energetique;analisis cluster;degre graphe;subgraph;social structure;semantic relations;modeling;biased estimation;estimation biaisee;clasificacion;red social;graph degree;trace de graphes;normalized cut;erreur systematique;structure sociale	Widely varying node degrees occur in software dependency graphs, hyperlink structures, social networks, and many other real-world graphs. Finding dense subgraphs in such graphs is of great practical interest, as these clusters may correspond to cohesive software modules, semantically related documents, and groups of friends or collaborators. Many existing clustering criteria and energy models are biased towards clustering together nodes with high degrees. In this paper, we introduce a clustering criterion based on normalizing cuts with edge numbers (instead of node numbers), and a corresponding energy model based on edge repulsion (instead of node repulsion) that reveal clusters without this bias.	cluster analysis;coupling (computer programming);edge enhancement;hyperlink;social network	Andreas Noack	2005		10.1007/11618058_28	correlation clustering;combinatorics;systems modeling;biological classification;artificial intelligence;graph theory;bias;social structure;mathematics;semantics;hyperlink;cluster analysis;graph drawing;algorithm;social network	DB	-9.106744006903396	-44.279385933052744	19597
b36368a9e34d3e557af7a647237c1190b522f7d3	file diffusion in a dynamic peer-to-peer network	peer to peer network;edonkey;social network;file diffusion;peer to peer;diffusion model;dynamic networks	Many studies have been made on diffusion in the field of epidemiology, and in the last few years, the development of social networking has induced new types of diffusion. In this paper, we focus on file diffusion on a peer-to-peer dynamic network using eDonkey protocol. On this network, we observe a linear behavior of the actual file diffusion. This result is interesting, because most diffusion models exhibit exponential behaviors. In this paper, we propose a new model of diffusion, based on the SI (Susceptible / Infected) model, which produces results close to the linear behavior of the observed diffusion. We then justify the linearity of this model, and we study its behavior in more details.	edonkey network;peer-to-peer;time complexity	Alice Albano;Jean-Loup Guillaume;Bénédicte Le Grand	2012		10.1145/2187980.2188257	simulation;computer science;diffusion;distributed computing;computer network;social network	Metrics	-19.22937112919023	-42.087339042751665	19647
7d0fd29d7949401b582bc758b9574e2c7e6c037a	inferring distant-time location in low-sampling-rate trajectories	reachability;sparsity;location prediction	With the growth of location-based services and social services, low- sampling-rate trajectories from check-in data or photos with geo- tag information becomes ubiquitous. In general, most detailed mov- ing information in low-sampling-rate trajectories are lost. Prior works have elaborated on distant-time location prediction in high- sampling-rate trajectories. However, existing prediction models are pattern-based and thus not applicable due to the sparsity of data points in low-sampling-rate trajectories. To address the sparsity in low-sampling-rate trajectories, we develop a Reachability-based prediction model on Time-constrained Mobility Graph (RTMG) to predict locations for distant-time queries. Specifically, we de- sign an adaptive temporal exploration approach to extract effective supporting trajectories that are temporally close to the query time. Based on the supporting trajectories, a Time-constrained mobility Graph (TG) is constructed to capture mobility information at the given query time. In light of TG, we further derive the reacha- bility probabilities among locations in TG. Thus, a location with maximum reachability from the current location among all possi- ble locations in supporting trajectories is considered as the predic- tion result. To efficiently process queries, we proposed the index structure Sorted Interval-Tree (SOIT) to organize location records. Extensive experiments with real data demonstrated the effective- ness and efficiency of RTMG. First, RTMG with adaptive tempo- ral exploration significantly outperforms the existing pattern-based prediction model HPM [2] over varying data sparsity in terms of higher accuracy and higher coverage. Also, the proposed index structure SOIT can efficiently speedup RTMG in large-scale trajec- tory dataset. In the future, we could extend RTMG by considering more factors (e.g., staying durations in locations, application us- ages in smart phones) to further improve the prediction accuracy.	data point;earthbound;effective-;experiment;geotagging;interval tree;location-based service;reachability;sampling (signal processing);smartphone;sparse matrix;speedup	Meng-Fen Chiang;Yung-Hsiang Lin;Wen-Chih Peng;Philip S. Yu	2013		10.1145/2487575.2487707	simulation;computer science;machine learning;data mining;reachability;sparsity-of-effects principle	AI	-16.807304208927146	-35.338612660043296	19712
8a22936b55f8104244728c73205ca487416dbf9c	the emergence of canalization and evolvability in an open-ended, interactive evolutionary system	generative encoding;canalization;divergent search;interactive evolutionary computation;structural organization	Many believe that an essential component for the discovery of the tremendous diversity in natural organisms was the evolution of evolvability, whereby evolution speeds up its ability to innovate by generating a more adaptive pool of offspring. One hypothesized mechanism for evolvability is developmental canalization, wherein certain dimensions of variation become more likely to be traversed and others are prevented from being explored (e.g., offspring tend to have similar-size legs, and mutations affect the length of both legs, not each leg individually). While ubiquitous in nature, canalization is rarely reported in computational simulations of evolution, which deprives us of in silico examples of canalization to study and raises the question of which conditions give rise to this form of evolvability. Answering this question would shed light on why such evolvability emerged naturally, and it could accelerate engineering efforts to harness evolution to solve important engineering challenges. In this article, we reveal a unique system in which canalization did emerge in computational evolution. We document that genomes entrench certain dimensions of variation that were frequently explored during their evolutionary history. The genetic representation of these organisms also evolved to be more modular and hierarchical than expected by chance, and we show that these organizational properties correlate with increased fitness. Interestingly, the type of computational evolutionary experiment that produced this evolvability was very different from traditional digital evolution in that there was no objective, suggesting that open-ended, divergent evolutionary processes may be necessary for the evolution of evolvability.	computation;computer simulation;developmental robotics;dimensions;emergence;evolution;genetic representation;genome;interactive evolutionary computation;interactivity;leg;morphogenesis;mutation;nonlinear gameplay;organism;randomness;reproduction;spontaneous order;trait;web site	Joost Huizinga;Kenneth O. Stanley;Jeff Clune	2018	Artificial Life	10.1162/artl_a_00263	artificial intelligence;interactive evolutionary computation;computer science;evolvability;canalisation	Web+IR	-4.6690119930279534	-47.141588043051534	19718
5554a4dcbcd9e6e174a417aba0a42be6a62a65b2	on real-time detecting passenger flow anomalies		In large and medium-sized cities, detecting unusual changes of crowds of people on the streets is needed for public security, transportation management, emergency control, and terrorism prevention. As public transportation has the capability to bring a large number of people to an area in a short amount of time, real-time discovery of anomalies in passenger numbers is an effective way to detect crowd anomalies. In this paper, we devise an approach called Kochab. Kochab adopts a generative model and combines the prior knowledge about passenger flows. Hence, it can detect anomalies in the numbers of incoming and outgoing passengers within a certain time and spatial area, including anomalous events along with their durations and severities. Through well-designed inference algorithms, Kochab requires only a moderate amount of historical data to be sample data. As such, Kochab shows good performance in real time and makes prompt responses to user' s interactive analysis requests. In particular, based on the recognized anomalous events, we capture event patterns which give us hints to link to activities or status in cities. In addition, for the convenience of method evaluation and comparison, we create an open Stream Anomaly Benchmark on the basis of large-scale real-world data. This benchmark will prove useful for other researchers too. Using this benchmark, we compare Kochab with four other methods. The experimental results show that Kochab is sensitive to population flow anomalies and has superior accuracy in detecting anomalies in terms of precision, recall and the F1 score.	algorithm;anomaly detection;benchmark (computing);f1 score;generative model;graphical user interface;real-time locating system;real-time transcription;sensor;smart city	Bo Tang;Hongyin Tang;Xinzhou Dong;Beihong Jin;Tingjian Ge	2018		10.1145/3269206.3271754	data stream;anomaly detection;data mining;time series;generative model;crowds;f1 score;computer science;inference;population	ML	-16.14494393594129	-31.698477800571464	19770
0953e6820f9dda6bb671297d6e1056eb905cf9f2	official statistics data integration for enhanced information quality	official statistics;information quality infoq;administrative data;data integration;bayesian networks	This work is about integrated analysis of data collected as official statistics with administrative data from operational systems in order to increase the quality of information. Information quality, or InfoQ, is ‘the potential of a data set to achieve a specific goal by using a given empirical analysis method’. InfoQ is based on the identification of four interacting components: the analysis goal, the data, the data analysis and the utility, and it is assessed through eight dimensions: data resolution, data structure, data integration, temporal relevance, generalizability, chronology of data and goal, construct operationalization and communication. The paper illustrates, through case studies, a novel strategy to increase InfoQ based on the integration of official statistics with administrative data using copulas and Bayesian Networks. Official statistics are extraordinary sources of information. However, because of temporal relevance and chronology of data and goals, these fundamental sources of information are often not properly leveraged resulting in a poor level of InfoQ in the use of official statistics. This leads to low valued statistical analyses and to the lack of sufficiently informative results. By improving temporal relevance and chronology of data and goals, the use of Bayesian Networks allows us to calibrate official with administrative data, thus strengthening the quality of the information derived from official surveys, and, overall, enhancing InfoQ. We show, with examples, how to design and implement such a calibration strategy. Copyright © 2015 John Wiley u0026 Sons, Ltd.	information quality	Luciana Dalla Valle;Ron S. Kenett	2015	Quality and Reliability Eng. Int.	10.1002/qre.1859	official statistics;computer science;data science;data integration;bayesian network;data mining;database;mathematics;statistics	DB	-22.488996817820325	-32.0106566439313	19840
27d69faa5f65d9b70555a8a34827e439ddd043b7	gallop: global feature fused location prediction for different check-in scenarios		Location prediction is widely used to forecast users’ next place to visit based on his/her mobility logs. It is an essential problem in location data processing, invaluable for surveillance, business, and personal applications. It is very challenging due to the sparsity issues of check-in data. An often ignored problem in recent studies is the variety across different check-in scenarios, which is becoming more urgent due to the increasing availability of more location check-in applications. In this paper, we propose a new feature fusion based prediction approach, GALLOP, i.e., GlobAL feature fused LOcation Prediction for different check-in scenarios. Based on the carefully designed feature extraction methods, we utilize a novel combined prediction framework. Specifically, we set out to utilize the density estimation model to profile geographical features, i.e., context information, the factorization method to extract collaborative information, and a graph structure to extract location transition patterns of users’ temporal check-in sequence, i.e., content information. An empirical study on three different check-in datasets demonstrates impressive robustness and improvement of the proposed approach.	feature extraction;feature vector;preprocessor;robustness (computer science);sparse matrix	Yuxing Han;Junjie Yao;Xuemin Lin;Liping Wang	2017	IEEE Transactions on Knowledge and Data Engineering	10.1109/TKDE.2017.2705083	robustness (computer science);machine learning;check-in;artificial intelligence;data mining;computer science;empirical research;feature extraction;density estimation;graph;data processing	DB	-17.201443472429006	-35.11106933444035	19902
7315c2d9b8fee8ce7ea914d53d67896eb9f6f38f	mining bipartite graphs to improve semantic pedophile activity detection	topological measures bipartite graph mining semantic pedophile activity detection p2p networks peer to peer networks internet pedophile exchange keywords sequence social network analysis pedophile queries;paedophile activity classification bipartite graphs;social networking online behavioural sciences computing data mining information analysis peer to peer computing query processing;communities semantics bipartite graph social network services peer to peer computing data mining ip networks	Peer-to-peer (P2P) networks are popular to exchange large volumes of data through the Internet. Pedophile activity is a very important topic for our society and some works have recently attempted to gauge the extent of pedophile exchanges on P2P networks. A key issue is to obtain an efficient detection tool, which may decide if a sequence of keywords is related to the topic or not. We propose to use social network analysis in a large dataset from a P2P network to improve a state-of-the-art filter for pedophile queries. We obtain queries and thus combinations of words which are not tagged by the filter but should be. We also perform some experiments to explore if the original four categories of paedophile queries were to be found by topological measures only.	experiment;peer-to-peer;social network analysis	Raphaël Fournier-S'niehotta;Maximilien Danisch	2014	2014 IEEE Eighth International Conference on Research Challenges in Information Science (RCIS)	10.1109/RCIS.2014.6861035	computer science;data mining;database;world wide web	DB	-24.348091599961016	-50.913845099227494	19990
8cea053b6f1c67eab4a0e15885a384932cfa1bfc	comparison of algorithms for automatically building example-tracing tutor models		In our recent work, we have proposed that multiple behavior demonstrations can be automatically combined to generate an Example-Tracing Tutor model. In this paper, we compare four algorithms for this problem using a number of different metrics for two different datasets, one of which is publicly available. Our experiments show that these four algorithms are complementary to each other in terms of their performance along the different metrics. These findings make a case for incorporating multiple algorithms for building behavior graphs into authoring tools for Intelligent Tutoring Systems (ITS) that use behavior graphs.	algorithm;experiment	Rohit Kumar;Matthew E. Roy;R. Bruce Roberts;John Makhoul	2014			machine learning;computer science;natural language processing;tracing;artificial intelligence;tutor	NLP	-32.49914046875483	-51.066167093215014	20011
d4a73ba3af34744e69482437862208520563aaf4	false discovery rate control and statistical quality assessment of annotators in crowdsourced ranking		With the rapid growth of crowdsourcing platforms it has become easy and relatively inexpensive to collect a dataset labeled by multiple annotators in a short time. However due to the lack of control over the quality of the annotators, some abnormal annotators may be affected by position bias which can potentially degrade the quality of the final consensus labels. In this paper we introduce a statistical framework to model and detect annotator’s position bias in order to control the false discovery rate (FDR) without a prior knowledge on the amount of biased annotators – the expected fraction of false discoveries among all discoveries being not too high, in order to assure that most of the discoveries are indeed true and replicable. The key technical development relies on some new knockoff filters adapted to our problem and new algorithms based on the Inverse Scale Space dynamics whose discretization is potentially suitable for large scale crowdsourcing data analysis. Our studies are supported by experiments with both simulated examples and real-world data. The proposed framework provides us a useful tool for quantitatively studying annotator’s abnormal behavior in crowdsourcing. Proceedings of the 33 rd International Conference on Machine Learning, New York, NY, USA, 2016. JMLR: W&CP volume 48. Copyright 2016 by the author(s).	abnormal end;academy;algorithm;counterfeit consumer goods;crowdsourcing;discretization;experiment;international conference on machine learning;journal of machine learning research;least squares;microsoft research;scalability;scale space;simulation;sparse matrix;statistical model;yao graph	Qianqian Xu;Jiechao Xiong;Xiaochun Cao;Yuan Yao	2016			computer science;data science;machine learning;data mining;statistics	ML	-10.546083845294165	-43.99903509538886	20016
fc2971cd70026622c50591276fcdafa77a0a1d65	a grocery recommendation for off-line shoppers		PurposernrnrnrnrnMany off-line retailers have experienced a slump in sales and have the potential risk of overstock or understock. To overcome these problems, retailers have applied data mining techniques, such as association rule mining or sequential association rule mining, to increase sales and predict product demand. However, because these techniques cannot generate shopper-centric rules, many off-line shoppers are often inconvenienced after writing their shopping lists carefully and comprehensively. Therefore, the purpose of this paper is to propose a personalized recommendation methodology for off-line grocery shoppers.rnrnrnrnrnDesign/methodology/approachrnrnrnrnrnThis paper employs a Markov chain model to generate recommendations for the shopper’s next shopping basket. The proposed methodology is based on the knowledge of both purchased products and purchase sequences. This paper compares the proposed methodology with a traditional collaborative filtering (CF)-based system, a bestseller-based system and a Markov-chain-based system as benchmark systems.rnrnrnrnrnFindingsrnrnrnrnrnThe proposed methodology achieves improvements of 15.87, 14.06 and 37.74 percent with respect to the CF-, Markov chain-, and best-seller-based benchmark systems, respectively, meaning that not only the purchased products but also the purchase sequences are important elements in the personalization of grocery recommendations.rnrnrnrnrnOriginality/valuernrnrnrnrnMost of the previous studies on this topic have proposed on-line recommendation methodologies. However, because off-line stores collect transaction data from point-of-sale devices, this research proposes a methodology based on purchased products and purchase patterns for off-line grocery recommendations. In practice, this study implies that both purchased products and purchase sequences are viable elements in off-line grocery recommendations.	online and offline	Jae Kyeong Kim;Hyun Sil Moon;Byong Ju An;Il Young Choi	2018	Online Information Review	10.1108/OIR-04-2016-0104	information retrieval;collaborative filtering;overstock;personalization;computer science;transaction data;association rule learning;originality;markov chain	ECom	-20.779588345946596	-50.9118301140903	20022
3af0298078aee3457e545f61b2ff019ec2955f08	a hybrid recommendation system based on density-based clustering		Collaborative filtering recommenders leverage past user-item ratings in order to predict ratings for new items. One of the most critical steps in such methods corresponds to the formation of the neighbourhood that contains the most similar users or items, so that the ratings associated with them can be employed for predicting new ratings. This work proposes to perform the combination of content-based and ratings-based evidence during the neighbourhood formation step and thus identify the most similar neighbours in a hybrid manner. To this end, DBSCAN, a density-based clustering approach, is applied for identifying the most similar users or items by considering the ratings-based and the content-based similarities, both individually and in combination. The resulting hybrid cluster-based CF recommendation scheme is then evaluated on the latest small MovieLens100k dataset and the experimental results indicate the potential of the proposed approach.	recommender system	Theodora Tsikrika;Spyridon Symeonidis;Ilias Gialampoukidis;Anna Satsiou;Stefanos Vrochidis;Yiannis Kompatsiaris	2017		10.1007/978-3-319-77547-0_5	collaborative filtering;recommender system;cluster analysis;dbscan;neighbourhood (mathematics);pattern recognition;computer science;artificial intelligence	ML	-20.993937449032412	-48.064271059721776	20049
cc2ddca2ad0c6a4543eee847a89f2debddadfbae	origin-destination estimator based on hidden markov models for adaptive traffic control		Knowledge of the origin-destination (O-D) matrix of a traffic network is useful for various planning and operations tasks. The matrix gives the traffic flow between a specific origin and a specific destination. In this paper, we consider the traffic flow on a specific intersection and we estimate the traffic flow in the next intersection based on Hidden Markov Model (HMM). In this concept each street has two lanes. We observe the traffic flow on each lane individually. Finally, we evaluate the proposed model using a real scenario with two different intersections.	algorithm;automated planning and scheduling;embedded system;hidden markov model;markov chain;real-time clock;real-time computing;simulation;the matrix;vissim	Fadi Al Machot;Alireza Fasih;Fidaa Al Machot;Kyandoghere Kyamakya;Ahmad Haj Mosa	2012		10.3182/20120403-3-DE-3010.00073	traffic generation model;simulation;geography;traffic congestion reconstruction with kerner's three-phase theory;machine learning;transport engineering	AI	-16.653960884920917	-30.643929443105502	20076
061c58f70ea5d28874f58a9827cd8278cde9903c	interactive visual analysis of families of function graphs	passenger car;graph theory;time series data interactive visual analysis function graph multidimensional data analysis multivariate data analysis data visualization internal data structure visual exploration interactive brushing histogram scatterplot composite brush optimization fuel injection system diesel engine passenger car;algorithms computer graphics computer simulation data interpretation statistical information storage and retrieval models statistical multivariate analysis pattern recognition automated user computer interface;internal data structure;linked views;interactive visualization;composite brushing;fuel injection system;fuel injection system visual exploration composite brushing linked views time series data;multiple views;function graph;diesel engine;interactive visual analysis;data visualisation;data analysis;histogram;data visualization multidimensional systems data structures data analysis histograms scattering brushes visual analytics fuels diesel engines;multivariate data analysis;scatterplot;visual exploration;data structures;graph theory data analysis data structures data visualisation;indexation;visual analysis;data visualization;time series data;optimization;composite brush;visual analytics;interactive brushing;data structure;multivariate data;multidimensional data analysis;parallel coordinates	The analysis and exploration of multidimensional and multivariate data is still one of the most challenging areas in the field of visualization. In this paper, we describe an approach to visual analysis of an especially challenging set of problems that exhibit a complex internal data structure. We describe the interactive visual exploration and analysis of data that includes several (usually large) families of function graphs fi(x, t). We describe analysis procedures and practical aspects of the interactive visual analysis specific to this type of data (with emphasis on the function graph characteristic of the data). We adopted the well-proven approach of multiple, linked views with advanced interactive brushing to assess the data. Standard views such as histograms, scatterplots, and parallel coordinates are used to jointly visualize data. We support iterative visual analysis by providing means to create complex, composite brushes that span multiple views and that are constructed using different combination schemes. We demonstrate that engineering applications represent a challenging but very applicable area for visual analytics. As a case study, we describe the optimization of a fuel injection system in diesel engines of passenger cars	application domain;brushing and linking;color gradient;convex function;data drilling;data model;data structure;dataspaces;diesel;entity name part qualifier - adopted;graph - visual representation;graph of a function;hl7publishingsubsection <operations>;imagery;injection system device component;interactive visual analysis;iteration;iterative method;iterative refinement;linked list;mathematical optimization;parallel coordinates;refinement (computing);scientific visualization;sensor;time series;usability;visual analytics;whole earth 'lectronic link	Zoltan Konyha;Kresimir Matkovic;Denis Gracanin;Mario Jelovic;Helwig Hauser	2006	IEEE Transactions on Visualization and Computer Graphics	10.1109/TVCG.2006.99	scatter plot;multidimensional analysis;computer vision;multivariate statistics;visual analytics;simulation;parallel coordinates;data structure;interactive visual analysis;fuel injection;computer science;data science;time series;data mining;histogram;mathematics;multivariate analysis;data analysis;graph of a function;data visualization;statistics	Visualization	-27.625918528485116	-33.508703458620865	20097
6f958be6f1ae1f7eaf5905f6aaf3da3915eb5bac	data mining on social interaction networks	computer science databases;computer science social and information networks;physics physics and society	Social media and social networks have already woven themselves into the very fabric of everyday life. This results in a dramatic increase of social data capturing various relations between the users and their associated artifacts. In such settings, data mining and analysis plays a central role: Predictive data mining targets the acquisition and learning of specific models in order to support the users, e. g., for classification or inference of parameters for future cases. Furthermore, descriptive data mining aims at obtaining patterns which summarize and characterize the data. From an application perspective, there is a variety of computational social systems – with an increasing use of mobile and ubiquitous technologies. The various direct and indirect interactions between the users in the online networks as well as the realworld human interactions using ubiquitous devices can then be represented using social interaction networks. In this article, we consider social interaction networks from a data mining perspective – also with a special focus on real-world face-to-face contact networks: We combine data mining and social network analysis techniques for examining the networks in order to improve our understanding of the data, the modeled behavior, and its underlying emergent processes. Furthermore, we adapt, extend and apply known predictive data mining algorithms on social interaction networks. Additionally, we present novel methods for descriptive data mining for uncovering and extracting relations and patterns for hypothesis generation and exploration by the user, in order to provide characteristic information about the data and networks. The presented approaches and methods aim at extracting valuable knowledge for enhancing the understanding of the respective data, and for supporting the users of the respective systems. We consider data from several social systems, like the social bookmarking system BibSonomy, the social resource sharing system flickr, and ubiquitous social systems: Specifically, we focus on data from the social conference guidance system Conferator and the social group interaction system MyGroup. This work first gives a short introduction into social interaction networks, before we describe several analysis results in the context of online social networks, as well as real-world face-to-face contact networks. Next, we present predictive data mining methods making use of the social interactions, i. e., for localization, recommendation and link prediction. After that, we present novel descriptive data mining methods for mining communities and patterns on social interaction networks. ar X iv :1 31 2. 66 75 v2 [ cs .S I] 1 5 M ar 2 01 4	algorithm;automatic identification and data capture;big data;collective intelligence;computation;data mining;emergence;flickr;guidance system;interaction network;microsoft outlook for mac;pervasive informatics;sensor;social media;social network analysis;social system	Martin Atzmüller	2014	JDMDH		computer science;dynamic network analysis;data science;machine learning;data mining;world wide web;social computing	ML	-22.637385419868668	-42.387587697122406	20116
a4c6515f8f00a2b1243c2795204aa866f881b297	streaming data analysis framework for cyber-physical system of metal machining processes		Online monitoring and offline batch analyzing the data stream obtained from computer numeric control (CNC) machines and sensors deployed on manufacturing site are the core technology of Cyber-Physical System (CPS). In order to analyze data stream collected continually, in this research, the data analysis framework consist of supervisory control and data acquisition (SCADA), edge computing and cloud computing is proposed. By integrating signal smoothing and anomaly pattern detection techniques, the significant unique patterns of data stream can be discovered and stored for further usage in CPS application.	anomaly detection;cloud computing;computation;cyber-physical system;data acquisition;edge computing;factor analysis;machine learning;mean time between failures;online and offline;pattern recognition;predictive modelling;sensor;smoothing;stream (computing);streaming media;time series	Chao-Lung Yang;Hendri Sutrisno;Nai-Wei Lo;Zhi-Xuan Chen;Ching-Chih Wei;Han-Wei Zhang;Chin-Teng Lin;Chen-Lung Wei;Shang-Heng Hsieh	2018	2018 IEEE Industrial Cyber-Physical Systems (ICPS)	10.1109/ICPHYS.2018.8390764	data stream;machining;control engineering;real-time computing;time series;smoothing;cloud computing;cyber-physical system;engineering;edge computing;scada	Embedded	-7.9828916875559495	-28.52428187615961	20173
4c133c6cb33edca936ce90a6c4dd68197b2c32e8	defragging subgraph features for graph classification	graph classification;feature selection;conference proceeding;subgraph join	Graph classification is an important tool for analysing structured and semi-structured data, where subgraphs are commonly used as the feature representation. However, the number and size of subgraph features crucially depend on the threshold parameters of frequent subgraph mining algorithms. Any improper setting of the parameters will generate many trivial short-pattern subgraph fragments which dominate the feature space, distort graph classifiers and bury interesting long-pattern subgraphs. In this paper, we propose a new Subgraph Join Feature Selection (SJFS) algorithm. The SJFS algorithm, by forcing graph classifiers to join short-pattern subgraph fragments, can defrag trivial subgraph features and deliver long-pattern interesting subgraphs. Experimental results on both synthetic and real-world social network graph data demonstrate the performance of the proposed method.	algorithm;collaboration graph;distortion;feature selection;feature vector;semi-structured data;semiconductor industry;social network;synthetic data	Haishuai Wang;Peng Zhang;Ivor W. Tsang;Ling Chen;Chengqi Zhang	2015		10.1145/2806416.2806585	degeneracy;rook's graph;claw-free graph;graph power;factor-critical graph;cograph;universal graph;connected component;planarity testing;computer science;forbidden graph characterization;machine learning;reconstruction conjecture;pattern recognition;subgraph isomorphism problem;graph factorization;color-coding;distance-hereditary graph;induced subgraph isomorphism problem;maximum common subgraph isomorphism problem;butterfly graph;feature selection;line graph	ML	-10.067253647348725	-39.826734884220755	20210
77f1545aeecbfe038055581dd2defb1db14822ad	evaluating the dynamic properties of recommendation algorithms	evaluation method;recommender system;user experience;temporal properties;evaluation;recommender systems;leave one out;dynamic properties	"""Collaborative recommendation algorithms are typically evaluated on a static matrix of user rating data. However, when users experience a recommender system, it is dynamic, constantly evolving as new items and new users arrive. The dynamic properties of collaborative recommendation have become important as prediction algorithms based on the interactions of rating histories have been proposed, and as researchers seek to understand problems of robustness and maintenance in rating databases.  This paper proposes a new evaluation method for the dynamic aspects of collaborative algorithms, the """"temporal leave-one-out"""" approach, which can provide insight into both user-specific and system-level evolution of recommendation behavior. As a case study, the methodology is applied to the Influence Limiter algorithm [12], showing that its robustness to attack comes at a high accuracy cost."""	algorithm;database;interaction;limiter;recommender system	Robin D. Burke	2010		10.1145/1864708.1864753	computer science;evaluation;machine learning;data mining;database;world wide web;recommender system	Web+IR	-22.439742537475272	-46.75961924382336	20220
d6899e1478f846c67fbd26c1f3ec4cf2955a1847	development of a deceleration-based surrogate safety measure for rear-end collision risk	rear end crashes;road vehicles collision avoidance intelligent transportation systems risk management road accidents road safety road traffic;vehicles acceleration safety decision support systems accidents vehicle crash testing roads;intelligent transportation systems;crash avoidance systems;acceleration;driving assistance collision avoidance safety warning surrogate safety measure its;accidents;roads;decision support systems;safety;vehicle crash testing;vehicles;behavior;deceleration;intelligent transportation system deceleration based surrogate safety measure development hazardous roadway events safety risk driving environment vehicles dssm safety indicator rear end collision risk evaluation safety conditions decision making process human driving acceleration phases deceleration phases surrogate safety model severe deceleration behavior driver critical behavior high risk situations microscopic vehicle trajectory data crash potential collision warning systems collision avoidance systems;driver support systems	A surrogate safety measure can be used for preventing hazardous roadway events by evaluating the potential safety risk by using information on the driving environment gathered from vehicles. In this paper, the deceleration-based surrogate safety measure (DSSM) is proposed as a safety indicator for rear-end collision risk evaluation based on the safety conditions and the decision-making process during human driving. The DSSM shows how drivers deal with collision risk differently in acceleration and deceleration phases. The proposed surrogate safety model has been validated for severe deceleration behavior, which is a driver-critical behavior in high-risk situations of collision based on microscopic vehicle trajectory data. The results indicate that there is a strong relationship between the proposed surrogate safety measures and crash potential. The measure could be used for collision warning and collision avoidance systems. It has a merit in that it reflects the characteristics of both vehicle (e.g., mechanical braking capability) and driver (e.g., preference for certain acceleration rates).	chrome web store;control system;definition;device driver;feedback;on-board data handling;performance;risk assessment;smartphone	Sehyun Tak;Sunghoon Kim;Hwasoo Yeo	2015	IEEE Transactions on Intelligent Transportation Systems	10.1109/TITS.2015.2409374	acceleration;decision support system;computer science;engineering;automotive engineering;transport engineering;computer security;quantum mechanics	Mobile	-19.123596109783442	-26.77891249243124	20232
3a26bf4a877ab38e274e88683433f5ac031ac960	simulation and visual analysis of neuromusculoskeletal models and data	neuromusculoskeletal simulation;forward simulation;big data;inverse simulation	This work presents a novel medical decision support system for diseases related to the upper body neuromusculature. The backbone of the system is a simulation engine able to perform both forward and inverse simulation of upper limb motions. In forward mode neural signals are fed to the muscles that perform the corresponding motion. In the inverse mode, a specified motion trajectory is used as input and the neural signals that are the root cause of this particular motion are estimated and investigated. Due to the vast amount of information that results from even simple simulations, the results are presented to the expert using visual analytics metaphors and in particular both embodied and symbolic visualizations. Several use cases are presented so as to demonstrate the analytics potential of the proposed system.	simulation	Konstantinos Moustakas;Panagiotis Moschonas;Konstantinos Votis;Dimitrios Tzovaras;Konstantinos Moustakas	2015		10.1007/978-3-319-23868-5_29	computer vision;simulation;big data;computer science;artificial intelligence;machine learning	HCI	-10.691242770331082	-47.906942590125475	20243
8d203a3ae6166243252251eb5d75404d453d500f	approximate analysis of binary topological relations between geographic regions with indeterminate boundaries	fuzzy set;geographic information system;spatial reasoning;image understanding;spatial relation;topological relation	The development of formal models of spatial relations is a topic of great importance in spatial reasoning, geographic information systems (GIS) and computer vision, and has gained much attention from researchers across these research areas during the past two decades. In recent years significant achievements have been made on the development of models of spatial relations between spatial objects with precisely defined boundaries. However, these models cannot be directly applied to spatial objects with indeterminate boundaries which are found in many applications in geographic analysis and image understanding. This article develops a method for approximately analyzing binary topological relations between geographic regions with indeterminate boundaries based upon previous work on topological spatial relations and fuzzy sets. In addition, examples are given to demonstrate the method and related concepts. It is shown that the eight binary topological relations between regions in a two-dimensional space can be easily determined by the method.	indeterminacy in concurrent computation	F. Benjamin Zhan	1998	Soft Comput.	10.1007/s005000050032	spatial relation;discrete mathematics;computer science;mathematics;geometry;spatial analysis;geographic information system;fuzzy set;spatial intelligence	NLP	-6.205346774904531	-27.494641819442776	20268
36aed180d5f64061b3ff00388aea89900e172cce	arbitrarily distributed data-based recommendations with privacy	data mining;accuracy;collaborative filtering;arbitrarily distributed data;privacy	Article history: Received 5 January 2011 Received in revised form 3 November 2011 Accepted 4 November 2011 Available online 12 November 2011 Collaborative filtering (CF) systems use customers' preferences about various products to offer recommendations. Providing accurate and reliable predictions is vital for both e-commerce companies and their customers. To offer such referrals, CF systems should have sufficient data. When data collected for CF purposes held by a central server, it is an easy task to provide recommendations. However, customers' preferences represented as ratingsmight be partitioned between two vendors. To supply trustworthy and correct predictions, such companies might desire to collaborate. Due to privacy concerns, financial fears, and legal issues; however, the parties may not want to disclose their data to each other. In this study, we scrutinize how to estimate item-based predictions on arbitrarily distributed data (ADD) between two e-commerce sites without deeply jeopardizing their privacy. We analyze our proposed scheme in terms of privacy; and demonstrate that the method does not intensely violate data owners' confidentiality. We conduct experiments using real data sets to show how coverage and quality of the predictions improve due to collaboration. We also investigate our scheme in terms of online performance; and demonstrate that supplementary online costs caused by privacy measures are negligible. Moreover, we perform trials to show how privacy concerns affect accuracy. Our results show that accuracy and coverage improve due to collaboration; and the proposed scheme is still able to offer truthful predictions with privacy concerns. © 2011 Elsevier B.V. All rights reserved.	collaborative filtering;confidentiality;e-commerce;experiment;privacy;server (computing)	Ibrahim Yakut;Huseyin Polat	2012	Data Knowl. Eng.	10.1016/j.datak.2011.11.002	privacy software;privacy by design;computer science;collaborative filtering;data mining;database;accuracy and precision;internet privacy;privacy;computer security	AI	-20.95653278730989	-50.0258914876388	20312
65787fe1b6c7962b8a355a2e4503bd72f1dd7fcb	an efficient algorithm of frequent connected subgraph extraction	extraction information;graph theory;frequent pattern;teoria grafo;subgrafo;analisis datos;information extraction;efficient algorithm;data mining;theorie graphe;data analysis;regle association;association rule;fouille donnee;sous graphe;close relationships;analyse donnee;subgraph;busca dato;extraccion informacion	Mining frequent patterns from datasets is one of the key success stories of data mining research. Currently, most of the works focus on independent data, such as the items in the marketing basket. However, the objects in the real world often have close relationship with each other. How to extract frequent patterns from these relations is the objective in this paper. We use graphs to model the relations, and select a simple type for analysis. Combining the graph theory and algorithms to generate frequent patterns, a new algorithm Topology, which can mine these graphs efficiently, has been proposed. We evaluate the performance of the algorithm by doing experiments with synthetic datasets and real data. The experimental results show that Topology can do the job well. At the end of this paper, the potential improvement is mentioned.	algorithm	Mingsheng Hong;Haofeng Zhou;Wei Wang;Baile Shi	2003		10.1007/3-540-36175-8_5	association rule learning;computer science;graph theory;machine learning;data mining;mathematics;data analysis;information extraction;algorithm	NLP	-8.729333792487584	-38.62127403823834	20325
b2e1f542f53ef5bb2ccfc281c486815263f399c1	passenger segmentation using smart card data	pattern clustering public transport smart cards strategic planning traffic engineering computing;automated fare collection afc system market segmentation public transport smart cards scs transit passenger;transit passenger automated fare collection afc system market segmentation public transport smart cards scs;data mining;transit passenger market segmentation transit operators transit users operational planning strategic planning smart card data automated fare collection system multiday travel pattern sc data sc transactions density based spatial clustering of application with noise algorithm dbscan algorithm travel pattern oriented information;clustering algorithms pattern analysis australia noise algorithm design and analysis intelligent transportation systems smart cards;smart cards;public transit;algorithms;travel patterns;methodology;traffic engineering computing pattern clustering public transport smart cards strategic planning;oriented information transit passenger market segmentation transit operators transit users operational planning strategic planning smart card data automated fare collection system multiday travel pattern sc data sc transactions density based spatial clustering of application with noise algorithm dbscan algorithm travel pattern;market segmentation;passengers	Transit passenger market segmentation enables transit operators to target different classes of transit users for targeted surveys and various operational and strategic planning improvements. However, the existing market segmentation studies in the literature have been generally done using passenger surveys, which have various limitations. The smart card (SC) data from an automated fare collection system facilitate the understanding of the multiday travel pattern of transit passengers and can be used to segment them into identifiable types of similar behaviors and needs. This paper proposes a comprehensive methodology for passenger segmentation solely using SC data. After reconstructing the travel itineraries from SC transactions, this paper adopts the density-based spatial clustering of application with noise (DBSCAN) algorithm to mine the travel pattern of each SC user. An a priori market segmentation approach then segments transit passengers into four identifiable types. The methodology proposed in this paper assists transit operators to understand their passengers and provides them oriented information and services.	algorithm;cluster analysis;dbscan;passenger name record;smart card	Le Minh Kieu;Ashish Bhaskar;Edward Chung	2015	IEEE Transactions on Intelligent Transportation Systems	10.1109/TITS.2014.2368998	embedded system;smart card;computer science;engineering;methodology;transport engineering;computer security;market segmentation	Robotics	-18.013766301192547	-32.34920374158232	20335
b3ec581b232e2bfb6020b9a995dccc996f03ac19	peculiarities of the correlation between local and global news popularity of electronic mass media	mass media;detrended fluctuation analysis;information flow;information theory	One of the approaches to the solution of the navigation problem in current information flows is ranking the documents according to their popularity level. The definition of local and global news popularity which is based on the number of similar-in-content documents, published within local and global time interval, was suggested. Mutual behavior of the documents of local and global popularity levels was studied. The algorithm of detecting the documents which received great popularity before new topics appeared was suggested.	algorithm;motion planning;sensor	D. V. Lande;S. M. Braichevskii;A. T. Darmokhval;A. A. Snarskii	2008	CoRR		information flow;information theory;detrended fluctuation analysis;data mining;mathematics;world wide web;information retrieval;statistics;mass media	Web+IR	-23.829200862107577	-51.93164178823405	20443
2adf38940df4bee204e0e09a543bd8e6f4179388	data classification for artificial intelligence construct training to aid in network incident identification using network telescope data	paper;ai;trend analysis;artificial intelligent;building simulation;artificial intelligence;network telescope;astrophysics;computer science;security;data classification	This paper considers the complexities involved in obtaining training data for use by artificial intelligence constructs to identify potential network incidents using passive network telescope data. While a large amount of data obtained from network telescopes exists, this data is not currently marked for known incidents. Problems related to this marking process include the accuracy of the markings, the validity of the original data and the time involved. In an attempt to solve these issues two methods of training data generation are considered namely; manual identification and automated generation. The manual technique considers heuristics for finding network incidents while the automated technique considers building simulated data sets using existing models of virus propagation and malicious activity. An example artificial intelligence system is then constructed using these marked datasets.	artificial intelligence system;heuristic (computer science);item unique identification;network telescope;software propagation	Bradley Cowie;Barry Irwin	2010		10.1145/1899503.1899544	marketing and artificial intelligence;engineering;artificial intelligence;data science;data mining	AI	-12.410322736627863	-29.88172109422302	20479
dc20f66f7a5b1c5b98f237e6adbb44c3e420cb2b	finding interesting rare association rules using rare pattern tree		Most association rule mining techniques concentrate on finding frequent rules. However, rare association rules are in some cases more interesting than frequent association rules since rare rules represent unexpected or unknown associations. All current algorithms for rare association rule mining use an Apriori level-wise approach which has computationally expensive candidate generation and pruning steps. We propose RP-Tree, a method for mining a subset of rare association rules using a tree structure, and an information gain component that helps to identify the more interesting association rules. Empirical evaluation using a range of real world datasets shows that RP-Tree itemset and rule generation is more time efficient than modified versions of FP-Growth and ARIMA, and discovers 92-100% of all the interesting rare association rules. Additional evaluation using synthetic datasets also shows that RP-Tree is more efficient, in addtion to showing how the execution time of RP-Tree changes with transaction length and rare-item itemset size.		Sidney Tsang;Yun Sing Koh;Gillian Dobbie	2013	Trans. Large-Scale Data- and Knowledge-Centered Systems	10.1007/978-3-642-37574-3_7	artificial intelligence;autoregressive integrated moving average;association rule learning;tree structure;pattern recognition;database transaction;computer science	DB	-5.500826481018399	-36.41863252300587	20609
da18a48bf6b9b8555518b663c4b8eb770a607a10	comparing community-based information adoption and diffusion across different microblogging sites	information comparison;information diffusion;social media	The proliferation of social media is bringing about significant changes in how people make sense of their world and adopt new information. However, social, cultural and political divisions continue to separate users and information into different social media systems. Twitter and Facebook, for example, are strictly forbidden in mainland China. As a result, 21.97% of all world-wide Internet users are thus excluded from participating in these platforms. In this study, we investigate whether the dynamics of information diffusion, modeled as the adoption patterns of topical hashtags, differ between the communities of the mentioned social media sites as a result of this separation. Specifically, we compare Weibo and Twitter, the two largest micro-blogging sites serving respectively the Chinese population and the rest of the world, by exploring the similarities and differences of how their respective users adopt new information. By leveraging sophisticated community detection algorithms and heterogeneous graph mining methods, we investigate and compare how the different characteristics of these communities influence information diffusion and adoption. Experimental results show that while community-specific information influences topic diffusion and adoption in both environments, novel features, extracted from heterogeneous graph based communities, have a greater effect on Weibo information adoption than Twitter. We also find that users sharing hashtags is an important factor in information diffusion on both Twitter and Weibo, whereas user mentions are important for Weibo, but less so for Twitter. Overall, we conclude that Weibo and Twitter differ sharply in how their users adopt information in response to similar factors.	algorithm;blog;hashtag;internet;social media;structure mining	Xiaozhong Liu;Xing Yu;Zheng Gao;Tian Xia;Johan Bollen	2016		10.1145/2914586.2914665	social media;computer science;microblogging;internet privacy;world wide web	Web+IR	-20.715574249363534	-43.09929476351399	20631
38c8568f594b40d13ae0172491bfeb22ac6884f1	browsing large digital library collections using classification hierarchies	digital library;digital libraries;browsing;classification;aggregation;searching;summarization;data analysis;interaction technique	Summarization of intermediary query result sets plays an important role when users browse through digital library collections. Summarization enables users to quickly digest the results of their queries, and provides users with important information they can use to narrow their search interactively. Techniques from the field of data analysis may be applied to the problem of generating summaries of query results efficiently. Such techniques should permit the incorporation of classification hierarchies in order to provide powerful browsing environments for digital library users.	browsing;cryptographic hash function;data cube;digital library;interactivity;library (computing);olap cube;refinement (computing)	Steven Geffner;Divyakant Agrawal;Amr El Abbadi;Terence R. Smith	1999		10.1145/319950.319978	digital library;multi-document summarization;biological classification;computer science;automatic summarization;database;data analysis;world wide web;information retrieval;interaction technique	DB	-30.608672171858576	-33.93523640089217	20645
a4b5fa99db7ae57c87c71df9fa4ebffea1a8a308	integrating collaborative filtering and matching-based search for product recommendations	tecnologia electronica telecomunicaciones;recommend er systems;product search;personalization;user profiling;grupo c;collaborative filtering;tecnologias;recommender systems;product recommendation	Currently, recommender systems (RS) have been widely applied in many commercial e-commerce sites to help users deal with the information overload problem. Recommender systems provide personalized recommendations to users and, thus, help in making good decisions about which product to buy from the vast amount of product choices. Many of the current recommender systems are developed for simple and frequently purchased products like books and videos, by using collaborative-filtering and content-based approaches. These approaches are not directly applicable for recommending infrequently purchased products such as cars and houses as it is difficult to collect a large number of ratings data from users for such products. Many of the ecommerce sites for infrequently purchased products are still using basic search-based techniques whereby the products that match with the attributes given in the target user’s query are retrieved and recommended. However, search-based recommenders cannot provide personalized recommendations. For different users, the recommendations will be the same if they provide the same query regardless of any difference in their interest. In this article, a simple user profiling approach is proposed to generate user’s preferences to product attributes (i.e., user profiles) based on user product click stream data. The user profiles can be used to find similarminded users (i.e., neighbours) accurately. Two recommendation approaches are proposed, namely RoundRobin fusion algorithm (CFRRobin) and Collaborative Filtering-based Aggregated Query algorithm (CFAgQuery), to generate personalized recommendations based on the user profiles. Instead of using the target user’s query to search for products as normal search based systems do, the CFRRobin technique uses the attributes of the products in which the target user’s neighbours have shown interest as queries to retrieve relevant products, and then recommends to the target user a list of products by merging and ranking the returned products using the Round Robin method. The CFAgQuery technique uses the attributes of the products that the user’s neighbours have shown interest in to derive an aggregated query, which is then used to retrieve products to recommend to the target user. Experiments conducted on a real e-commerce dataset show that both the proposed techniques CFRRobin and CFAgQuery perform better than the standard Collaborative Filtering and the Basic Search approaches, which are widely applied by the current e-commerce applications.	algorithm;book;clickstream;collaborative filtering;e-commerce;experiment;information overload;international standard serial number;personalization;probabilistic latent semantic analysis;recommender system;shlomo moran;user profile	Noraswaliza Abdullah;Yue Xu;Shlomo Geva	2013	JTAER	10.4067/S0718-18762013000200004	user modeling;computer science;marketing;collaborative filtering;data mining;personalization;world wide web;information retrieval;recommender system	Web+IR	-21.640922721339066	-49.22906920575203	20769
02b6a69d3e51fa3e6086eee2e28090d08cd15468	visualization of personal stories		The system has three view modes which the user can select from depending on the purpose. Transition between view modes occurs smoothly. 1) Relation view mode (network-diagram) This mode provides an understanding of the interrelation among people. The relationships of a person are displayed using star-like diagrams (Fig.3 (A)). 2) Timeline view mode This mode is useful for analysis of temporal relations. The timeline is configured to display the past as down and the future as up (Fig.3 (B)). 3) Exocentric view mode Both temporal and inter-personal relationships can be observed from an exocentric viewpoint (Fig.1). With this mode, the user can visually understand the overall story outline.	diagram;smoothing;timeline	Yuya Nomata;Junichi Hoshino	2005		10.1145/1186954.1186969	computer vision;computer graphics (images);artificial intelligence;visualization;computer science	HCI	-28.38580131393167	-41.27121352766175	20774
4eb7640fceb0c692aaae598a65f6cca39e73f110	benchmarking data mining algorithms	benchmarking;decision support;data mining;machine learning;computer experiment;statistical algorithms;data mining algorithm;data mining algorithms;data structure;knowledge discovery	Data mining is the process of sifting through the mass of organizational (internal and external) data to identify patterns critical for decision support. Successful implementation of the data mining effort requires a careful assessment of the various tools and algorithms available. The basic premise of this study is that machine-learning algorithms, which are assumption free, should outperform their traditional counterparts when mining business databases. The objective of this study is to test this proposition by investigating the performance of the algorithms for several scenarios. The scenarios are based on simulations designed to reflect the extent to which typical statistical assumptions are violated in the business domain. The results of the computational experiments support the proposition that machine learning algorithms generally outperform their statistical counterparts under certain conditions. These can be used as prescriptive guidelines for the applicability of data mining techniques.	algorithm;business domain;data mining;database;decision support system;experiment;machine learning;simulation	Balaji Rajagopalan;Ravindra Krovi	2002	J. Database Manag.	10.4018/jdm.2002010103	concept mining;text mining;computer experiment;data structure;computer science;data science;machine learning;data mining;database;data stream mining;benchmarking	ML	-5.787885861043621	-30.245435825111148	20824
14c6bffb0469939cd29c019ee8fbc1962fc03fcd	ndlib: studying network diffusion dynamics		Nowadays the analysis of diffusive phenomena occurring on top of complex networks represents a hot topic in the Social Network Analysis playground. In order to support students, teachers, developers and researchers in this work we introduce a novel simulation framework, NDlib. NDlib is designed to be a multi-level ecosystem that can be fruitfully used by different user segments. Upon the diffusion library, we designed a simulation server that allows remote execution of experiments and an online visualization tool that abstract the programmatic interface and makes available the simulation platform to non-technicians.	complex network;ecosystem;experiment;server (computing);simulation;social network analysis	Giulio Rossetti;Letizia Milli;Salvatore Rinzivillo;Alina Sîrbu;Dino Pedreschi;Fosca Giannotti	2017	2017 IEEE International Conference on Data Science and Advanced Analytics (DSAA)	10.1109/DSAA.2017.6	social network analysis;visualization;complex network;distributed computing;computer science	Visualization	-30.688665010596512	-28.189702654207572	20826
aaa89fea5fb98ebadab0dd9952ce102990f9c8a4	hybrid ensemble learning for triggering of gps in long-term tracking applications			ensemble learning;global positioning system	Llewyn Salt;Raja Jurdak;Erin Oliver;Branislav Kusy	2016	Int. J. Hybrid Intell. Syst.	10.3233/HIS-160235	machine learning	AI	-14.97031121187788	-32.04502329030365	20829
62d509542eda9364584088ca7b848bcb8da81cf8	mining frequent route patterns based on personal trajectory abstraction		Frequent route pattern mining from personal trajectory data is the basis of location awareness and location services. However, because personal trajectory data is highly uncertain, most existing approaches are only capable of finding short and incomplete route patterns. In this paper, a novel approach is proposed for the discovery of frequent route patterns based on trajectory abstraction. First, trajectory partition, location extraction, data simplification, and common segment discovery are used to abstract trajectory data, convert these trajectories into common segment temporal sequences (STS) and generate 1-frequent itemsets. Then, a pattern mining algorithm is proposed based on the spatial-temporal adjacency relationship. This algorithm uses the constraint mechanism and bidirectional projected database to mine frequent route patterns from STS. Based on the real GeoLife trajectory data, the experimental results indicate that the proposed method has better performance and can find longer route patterns than other currently available methods.	algorithm;data mining;level of detail;location awareness	Zhongliang Fu;Zongshun Tian;Yanqing Xu;Kaichun Zhou	2017	IEEE Access	10.1109/ACCESS.2017.2712703	computer science;adjacency list;location awareness;location-based service;algorithm design;artificial intelligence;trajectory;machine learning;abstraction	ML	-15.965424653392095	-35.52192382989103	20946
21d97b7ac1bb11cc9a3fa9afe8af6d060fde492e	research on integrated monitoring and early warning platform for safe high speed railway operation	safety	"""With the characteristics of high speed, heavy density and strong dependence on control equipment, safe high-speed railway operation are affected by various factors whose interaction relationships resulted in the complexity and high risks of high-speed railway. To adopt ‘basic theory, key technology and simulation experiment’ method, based on the """"proactive safety"""" concept, a visual, intelligent and integrated monitoring and early-warning platform for safe high-speed railway operation was proposed in this paper, and was described from objectives, architecture and functions, to achieve comprehensive monitoring, safety warning, decision support and information transfer and sharing in the whole operation."""	decision support system;simulation	Xue-mei Xiao;Yanhui Wang;Limin Jia	2012		10.1117/12.945966	simulation;engineering;transport engineering;computer security	EDA	-18.90349047901273	-26.23013079045862	21023
fd0def2f886235089bd1360533a64f0e0c7af708	information fusion for multi-source fuzzy information system with the same structure	fuzzy information fusion;fuzzy rough accuracy;same structure;fuzzy information fusion multisource fuzzy information system information service information box information table;会议论文;fuzzy rough accuracy fuzzy information fusion same structure information box;information box;information services fuzzy set theory	Information fusion technologies have become more important in the field of information service in the age of information. The main goal of information fusion is to combine information from different sources to obtain a single composite solution. Multiple information sources form an information box if they have the same structure, i.e. the same object set and the same attribute set The information fusion is a process to map an information box to an information table. In this paper, we propose two approaches for fuzzy information fusion in multi-source environment with the same structure. Furthermore, a case study of expert evaluation is carried out to verify the proposed fusion method and the fuzzy rough accuracy is used to test different fusion approaches.	attribute-value system;information system;multi-source	Jianhang Yu;Weihua Xu	2015	2015 International Conference on Machine Learning and Cybernetics (ICMLC)	10.1109/ICMLC.2015.7340917	fuzzy classification;computer science;fuzzy number;information integration;information filtering system;machine learning;data mining;fuzzy set operations;information retrieval	Robotics	-6.1187951681261525	-26.645798290137353	21074
4b3e55c32aa24267d2993311fe9c403fb954be39	service recommendation system for big data analysis	generators;data mining;recommendation system;data analysis;engines;big data;data visualization;algorithm design and analysis	The present paper allows to recommend data corresponding to a user requirement and an analysis algorithm which is able to analyze the data and let an analysis service selected by the user among a plurality of analysis services be automatically performed in a big data platform.	algorithm;big data;recommender system;user requirements document	Tai-Yeon Ku;Hee-Sun Won;Hoon Choi	2016	2016 International Conference on Information Networking (ICOIN)	10.1109/ICOIN.2016.7427122	algorithm design;big data;computer science;data mining;data analysis;world wide web;information retrieval;data visualization	Robotics	-29.501744310994862	-50.293729755460234	21135
7322c98f28e250460258e91835c23e3b6ac68769	graph sampling: estimation of degree distributions	random walk sampling graph sampling degree distribution estimation online social networks world wide web network sampling biased degree distribution wireless subscriber network kolmogorov smirnov statistic pareto optimal sample;pareto optimisation;subscriber loops internet pareto optimisation signal sampling social networking online;sampling methods measurement knee maximum likelihood estimation pareto optimization educational institutions;signal sampling;internet;subscriber loops;social networking online;large scale networks graph sampling markov chain monte carlo mcmc sampling pareto optimality	Online social networks and the World Wide Web lead to large underlying graphs that might not be completely known because of their size. To compute reliable statistics, we have to resort to sampling the network. In this paper, we investigate four network sampling methods to estimate the network degree distribution and the so-called biased degree distribution of a 3.7 million wireless subscriber network. We measure the quality of our estimates of the degree distributions by using the Kolmogorov-Smirnov statistic. Among all four sampling methods, node sampling yields Pareto optimal sample sizes in terms of the Kolomogorov-Smirnov statistic for the degree distribution, while node-by-edge sampling yields optimal sample sizes for the biased distribution. We also find that random walk sampling performs better than the Metropolis-Hastings random walk.	degree distribution;metropolis;metropolis–hastings algorithm;pareto efficiency;sampling (signal processing);social network;world wide web	Joya A. Deri;José M. F. Moura	2013	2013 IEEE International Conference on Acoustics, Speech and Signal Processing	10.1109/ICASSP.2013.6638918	metropolis–hastings algorithm;sampling;econometrics;mathematical optimization;simple random sample;sampling design;the internet;degree distribution;importance sampling;slice sampling;mathematics;sampling distribution;pareto interpolation;statistics	DB	-10.887620796960915	-43.512393288163246	21145
f6855346b49eec7c6f32fad8ab7257b567cbf928	promoting creative design in interactive evolutionary computation	art;human computer interaction;interactive evolution artificial ecosystem computational creativity electronic art;multi agent systems art genetic algorithms human computer interaction human factors interactive systems;multi agent systems;human factors;agent based pixel level system creative design interactive evolutionary computation interactive evolutionary art task natural language usage tractable creativity definition generative ecosystemic art system evoeco image generation phenotypic distance measurement random search creativity measure enhanced version genetic representation pattern space traversal human computer interface interactive genetic algorithms evolutionary search;genetic algorithms;interactive systems;art reliability image color analysis humans evolutionary computation ecosystems genomics	We use a new measure of creativity as a guide in an interactive evolutionary art task and tie the results to natural language usage of the term “creative.” Following previous work, we explore a tractable definition of creativity, one emphasizing the novelty of systems, and its addition to an interactive application. We next introduce a generative ecosystemic art system, EvoEco, an agent-based pixel-level means of generating images. EvoEco is used as a component of an online survey which asks users to evolve a pleasing image and then rank the success of the process and its output. Evolutionary search is augmented with the creativity measure, and compared with control groups augmented with either random search or a measure of phenotypic distance. We show that users consistently rate the creativity measure-enhanced version as more “creative” and “novel” than other search techniques. We further derive additional insights into appropriate forms of genetic representation and pattern space-traversal in an interactive evolutionary algorithm.	agent-based model;cobham's thesis;evolutionary algorithm;evolutionary art;genetic representation;interactive evolutionary computation;natural language;pixel;random search;sed	Taras Kowaliw;Alan Dorin;Jon McCormack	2012	IEEE Transactions on Evolutionary Computation	10.1109/TEVC.2011.2166764	evolutionary music;simulation;genetic algorithm;interactive evolutionary computation;human-based evolutionary computation;computer science;artificial intelligence;human factors and ergonomics;machine learning;genetic representation;multi-agent system;multimedia;algorithm	Vision	-27.913613270731563	-26.10533990688797	21150
ee3a62d11a94aa45291235982ceef3ee724cb45c	drawing large weighted graphs using clustered force-directed algorithm	graph theory;sc2;lc;pattern clustering;sc1;convergence;electronic mail;graph drawing;scalability problem;short convergences;clustering algorithms layout convergence data visualization electronic mail clustering methods educational institutions;force directed graph drawing;large graph visualization;information visualization;layout;long convergence;pattern clustering computational complexity data visualisation graph theory;weighted graph graph visualization graph drawing data analytics information visualization force directed graph drawing clustered graph drawing;data visualisation;computational complexity;large weighted graphs;clustered force directed algorithm;data visualization;clustering algorithms;data analytics;clustered graph drawing;weighted graph;graph visualization aesthetics;convergence time;graph visualization aesthetics large weighted graphs clustered force directed algorithm clustered graph drawing scalability problem large graph visualization convergence time computational complexity long convergence lc short convergences sc1 sc2;clustering methods;graph visualization;conference proceeding	Clustered graph drawing is widely considered as a good method to overcome the scalability problem when visualizing large (or huge) graphs. Force-directed algorithm is a popular approach for laying graphs yet small to medium size datasets due to its slow convergence time. This paper proposes a new method which combines clustering and a force-directed algorithm, to reduce the computational complexity and time. It works by dividing a Long Convergence: LC into two Short Convergences: SC1, SC2, where SC1+SC2 <; LC. We also apply our work on weighted graphs. Our experiments show that the new method improves the aesthetics in graph visualization by providing clearer views for connectivity and edge weights.	algorithm;cluster analysis;computation;computational complexity theory;experiment;force-directed graph drawing;reduction (complexity);scalability;time complexity;usability testing	Jie Hua;Mao Lin Huang;Quang Vinh Nguyen	2014	2014 18th International Conference on Information Visualisation	10.1109/IV.2014.24	combinatorics;computer science;theoretical computer science;machine learning	Robotics	-12.438621690707292	-42.933628689992766	21152
586fcc19071f74d16a75a38da57d67c909ee5e60	link label prediction in signed social networks	social network;slashdot data;online social network;matrix factorization;logistic regression;positive interaction;negative interaction;link label prediction problem;certain link	Online social networks continue to witness a tremendous growth both in terms of the number of registered users and their mutual interactions. In this paper, we focus on online signed social networks where positive interactions among the users signify friendship or approval, whereas negative interactions indicate antagonism or disapproval. We introduce a novel problem which we call the link label prediction problem: Given the information about signs of certain links in a social network, we want to learn the nature of relationships that exist among the users by predicting the sign, positive or negative, of the remaining links. We propose a matrix factorization based technique MF-LiSP that exhibits strong generalization guarantees. We also investigate the applicability of logistic regression [8] in this setting. Our experiments on Wiki-Vote, Epinions and Slashdot data sets strongly corroborate the efficacy of these approaches.	anchor text;experiment;heuristic (computer science);interaction;logistic regression;provable security;recommender system;slashdot;social network;synthetic data;wiki	Priyanka Agrawal;Vikas K. Garg;Ramasuri Narayanam	2013			artificial intelligence;machine learning;mathematics	ML	-19.71590094147766	-45.850544799166215	21167
0357f72051b51512da3487c40fb6f464d97028e8	automatic extraction of destinations, origins and route parts from human generated route directions	cognitive systems;geographic information;origin destination;large scale;machine learning;movement pattern;spatial language;geographic information extraction;destination name identification;driving directions;route component classification;spatial organization;spatial information	Researchers from the cognitive and spatial sciences are studying text descriptions of movement patterns in order to examine how humans communicate and understand spatial information. In particular, route directions offer a rich source of information on how cognitive systems conceptualize movement patterns by segmenting them into meaningful parts. Route directions are composed using a plethora of cognitive spatial organization principles: changing levels of granularity, hierarchical organization, incorporation of cognitively and perceptually salient elements, and so forth. Identifying such information in text documents automatically is crucial for enabling machine-understanding of human spatial language. The benefits are: a) creating opportunities for large-scale studies of human linguistic behavior; b) extracting and georeferencing salient entities (landmarks) that are used by human route direction providers; c) developing methods to translate route directions to sketches and maps; and d) enabling queries on large corpora of crawled/analyzed movement data. In this paper, we introduce our approach and implementations that bring us closer to the goal of automatically processing linguistic route directions. We report on research directed at one part of the larger problem, that is, extracting the three most critical parts of route directions and movement patterns in general: origin, destination, and route parts. We use machine-learning based algorithms to extract these parts of routes, including, for example, destination names and types. We prove the effectiveness of our approach in several experiments using hand-tagged corpora.	algorithm;apple maps;artificial intelligence;cognition;database;emoticon;entity;experiment;geographic information system;geomatics;information source;machine learning;map;next-generation access;ontology (information science);refinement (computing);spatial organization;text corpus;web page;web search engine;word-sense disambiguation	Xiao Zhang;Prasenjit Mitra;Alexander Klippel;Alan M. MacEachren	2010		10.1007/978-3-642-15300-6_20	computer science;artificial intelligence;data mining;spatial analysis;spatial organization;cartography	ML	-25.999564810272627	-51.525138537068536	21197
2c10a7e5e9c9447b3e54a50e720373bcdadfc929	a unified music recommender system using listening habits and semantics of tags	emotion ontology;tag ontology;listening habits;music recommendation;intelligent information and database systems	In this paper, we propose a unified music recommender system using both listening habits and semantics of tags in a social music site. Most commercial music recommender systems recommend music items based on the number of plays, or explicit ratings of a song. However, these approaches have some difficulties in recommending new items with only a few ratings, or recommending items to new users with little information. To resolve the problem, UniTag ontology is developed, which defines the meaning and the weighted score of tags. User profiles are created by combining the score of tags and the number of plays, and a collaborative filtering algorithm is executed. For performance evaluation, precisions, recalls, and F-measures are measured using the listening habits-based recommendation, the tag score-based recommendation, and the unified recommendation, respectively. Our experiments show that the proposed approach outperforms the other two approaches in terms of all the evaluation metrics.	recommender system	Hyon Hee Kim;Donggeon Kim;Jinnam Jo	2014	IJIIDS	10.1504/IJIIDS.2014.060460	computer science;data mining;multimedia;world wide web;information retrieval	AI	-27.089177473981284	-51.2199969672822	21216
78467280e0fdffddd44d3e89ca96129a1d4b2b09	c-3po: click-sequence-aware deep neural network (dnn)-based pop-ups recommendation		"""With the emergence of mobile and wearable devices, push notification becomes a powerful tool to connect and maintain the relationship with App users, but sending inappropriate or too many messages at the wrong time may result in the App being removed by the users. In order to maintain the retention rate and the delivery rate of advertisement, we adopt Deep Neural Network (DNN) to develop a pop-up recommendation system """"C licksequence-aware deeP neural network (DNN)-based Pop-uPs recOmmendation (C-3PO)"""" enabled by collaborative filteringbased hybrid user behavioral analysis. We further verified the system with real data collected from the product Security Master, Clean Master and CM Browser, supported by Leopard Mobile Inc. (Cheetah Mobile Taiwan Agency). In this way, we can know precisely about users’ preference and frequency to click on the push notification/pop-ups, decrease the troublesome to users efficiently, and meanwhile increase the click through rate of push notifications/pop-ups."""		TonTon Hsien-De Huang;Hung-Yu Kao	2018	CoRR		recommender system;multimedia;collaborative filtering;data mining;wearable technology;deep learning;push technology;artificial neural network;computer science;artificial intelligence	Mobile	-25.129986141931145	-43.005856717746894	21248
27d3e9476090afe068da68fdd3ca41c920d7f9f8	legible action selection in human-robot collaboration		Humans are error-prone in the presence of multiple similar tasks. While Human-Robot Collaboration (HRC) brings the advantage of combining the superiority of both humans and robots in their respective talents, it also requires the robot to communicate the task goal clearly to the human collaborator. We formalize such problems in interactive assembly tasks with hidden goal Markov decision processes (HGMDPs) to enable the symbiosis of human intention recognition and robot intention expression. In order to avoid the prohibitive computational requirements, we provide a myopic heuristic along with a feature-based state abstraction method for assembly tasks to approximate the solution of the resulting HGMDP. A user study with human subjects in round-based LEGO assembly tasks shows that our algorithm improves HRC and helps the human collaborators when the task goal is unclear to them.	action selection;approximation algorithm;cognitive dimensions of notations;dyadic transformation;experiment;feedback;heuristic;hidden markov model;humans;human–robot interaction;markov chain;markov decision process;motion planning;observable variable;online and offline;pspace;pspace-complete;partially observable system;requirement;robot;smt placement equipment;usability testing	Huaijiang Zhu;Volker Gabler;Dirk Wollherr	2017	2017 26th IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN)	10.1109/ROMAN.2017.8172326	simulation;machine learning;robot;computer science;abstraction;markov decision process;markov process;action selection;artificial intelligence;heuristic;human–robot interaction	Robotics	-31.71706870026627	-41.130336320782504	21253
8b93fe57ae1d5ff3eb13d76f5ff69cfa4255d738	exploring spatial scale in geography			spatial scale	David O'Sullivan	2015	International Journal of Geographical Information Science	10.1080/13658816.2015.1053890	data mining;spatial ecology;geography	DB	-12.286955533146967	-26.8886299519068	21274
1380c4a283789b5b3af4215d314dc11a4a8e9e3d	efficient mining of statistical dependencies	search space;upper bound;multivariate time series;empirical evaluation;categorical data	The Multi-Stream Dependency Detection algorithm finds rules that capture statistical dependencies between patterns in multivariate time series of categorical data [Oates and Cohen, 1996c]. Rule strength is measured by the G statistic [Wickens, 1989], and an upper bound on the value of G for the descendants of a node allows MSDD'S search space to be pruned. However, in the worst case, the algorithm wil l explore exponentially many rules. This paper presents and empirically evaluates two ways of addressing this problem. The first is a set of three methods for reducing the size of MSDD'S search space based on information collected during the search process. Second, we discuss an implementation of MSDD that distributes its computations over multiple machines on a network.	algorithm;best, worst and average case;categorical variable;computation;rule 90;time series	Tim Oates;Matthew D. Schmill;Paul R. Cohen	1999			categorical variable;artificial intelligence;machine learning;data mining;mathematics;upper and lower bounds;statistics	AI	-5.393957726623805	-36.04365855308917	21356
d40f814c44386b7a087b3311c7db29a4ca243ff5	version-aware rating prediction for mobile app recommendation		With the great popularity of mobile devices, the amount of mobile apps has grown at a more dramatic rate than ever expected. A technical challenge is how to recommend suitable apps to mobile users. In this work, we identify and focus on a unique characteristic that exists in mobile app recommendation—that is, an app usually corresponds to multiple release versions. Based on this characteristic, we propose a fine-grain version-aware app recommendation problem. Instead of directly learning the users’ preferences over the apps, we aim to infer the ratings of users on a specific version of an app. However, the user-version rating matrix will be sparser than the corresponding user-app rating matrix, making existing recommendation methods less effective. In view of this, our approach has made two major extensions. First, we leverage the review text that is associated with each rating record; more importantly, we consider two types of version-based correlations. The first type is to capture the temporal correlations between multiple versions within the same app, and the second type of correlation is to capture the aggregation correlations between similar apps. Experimental results on a large dataset demonstrate the superiority of our approach over several competitive methods.	aggregate data;algorithm;complexity;experiment;interactivity;mobile app;mobile device;scalability;sparse matrix;unified model	Yuan Yao;Wayne Xin Zhao;Yaojing Wang;Hanghang Tong;Feng Xu;Jian Lu	2017	ACM Trans. Inf. Syst.	10.1145/3015458	leverage (finance);information retrieval;recommender system;data mining;computer science;mobile device;popularity	Web+IR	-19.88097758500342	-47.78238363853448	21419
2a4485189e9f03dcb7f803ef274601059a9d0843	mining user's location intention from mobile search log	query classification;location intention;feature selection	Much attention has been paid to web search personalization and query optimization over the past decade. With the prevalence of smart phones, the mobile search results for the same query may vary in regard to the user’s location. In order to provide more precise results for users, it’s essential to take geographic location into account along with the user’s input query. In this paper, we try to identify queries that have location intentions. For example, query “weather forecast” has a location intention of local city while “The Statue of Liberty” has a location intention of “New York city”. To identify the location intention behind a query, we propose a novel method to extract a set of features and use neural network to classify queries. In the classification of queries without explicit location names, our experiment shows that our approach achieves 82.5% at F1 measure and outperforms baselines by 4.2%.	artificial neural network;baseline (configuration management);collocation;experiment;f1 score;feature selection;geographic coordinate system;mathematical optimization;personalization;query optimization;smartphone;web search engine;web search query;wisdom of the crowd	Yifan Sun;Xin Li;Lin Li;Qi Feng Liu;Enhong Chen;Haiping Ma	2015		10.1007/978-3-319-25159-2_37	query optimization;query expansion;web query classification;computer science;machine learning;data mining;web search query;feature selection;world wide web;information retrieval	Web+IR	-23.60576368344194	-45.125989814780056	21458
2f293f02a4bea4333ac83f95d5e2758f07897a41	ranking tagged resources using social semantic relevance	domain ontology;test collection;web page;graded relevance;web resource;social semantic relevance;ranking tagged resources;keyword matching;experimental study;relevance ranking;social bookmarking site	The WWW today is overwhelmed with information on almost every topic. Therefore, relevance ranking of web pages to a user’s expectations is a challenge, rather than retrieving a collection of thousands of web pages selected by keyword matching. This paper presents an approach to rank tagged web pages retrieved from a Social Bookmarking Site for a learner who needs web resources containing content on a given topic. Besides the popularity of the web page in the community, the relevance of a web page for ranking is computed based on the semantic distance between tags and a given topic using domain ontology. An experimental study has been conducted to evaluate the ranks generated by the proposed approach. The test collection was created using a questionnaire which was designed to judge the crawled web pages for their graded relevance on a topic.	experiment;ontology (information science);paging;relevance;turing test;www;web page;web resource	Anjali Thukral;Hema Banati;Punam Bedi	2011	IJIRR		static web page;site map;data web;web mapping;web search engine;web standards;computer science;semantic web;social semantic web;web page;data mining;semantic web stack;web 2.0;world wide web;website parse template;information retrieval	Web+IR	-28.744579731105052	-51.96684370366049	21636
359408564930a75e5a630cba4760a35129def16b	vizrec: a framework for secure data exploration via visual representation		Visual representations of data (visualizations) are tools of great importance and widespread use in data analytics as they provide users visual insight to patterns in the observed data in a simple and effective way. However, since visualizations tools are applied to sample data, there is a a risk of visualizing random fluctuations in the sample rather than a true pattern in the data. This problem is even more significant when visualization is used to identify interesting patterns among many possible possibilities, or to identify an interesting deviation in a pair of observations among many possible pairs, as commonly done in visual recommendation systems. We present VizRec, a framework for improving the performance of visual recommendation systems by quantifying the statistical significance of recommended visualizations. The proposed methodology allows to control the probability of misleading visual recommendations using both classical statistical testing procedures and a novel application of the Vapnik Chervonenkis (VC) dimension method which is a fundamental concept in statistical learning theory.	alexey chervonenkis;machine learning;recommender system;statistical learning theory;vc dimension;vapnik–chervonenkis theory	Lorenzo De Stefani;Leonhard F. Spiegelberg;Tim Kraska;Eli Upfal	2018	CoRR			ML	-26.043421321469307	-35.49545581061689	21643
abec9c742c593097fd1b77166a21f9c7f1438a7d	complexity at large - 19.2		THE ORIGINS OF SCALING IN CITIES The following news item is taken in part from the 2013-06-21 issue of Science titled ‘‘The Origins of Scaling in Cities,’’ by Lu ıs M. A. Bettencourt. Despite the increasing importance of cities in human societies, our ability to understand them scientifically and manage them in practice has remained limited. The greatest difficulties to any scientific approach to cities have resulted from their many interdependent facets, as social, economic, infrastructural, and spatial complex systems that exist in similar but changing forms over a huge range of scales. Here, I show how all cities may evolve according to a small set of basic principles that operate locally. A theoretical framework was developed to predict the average social, spatial, and infrastructural properties of cities as a set of scaling relations that apply to all urban systems. Confirmation of these predictions was observed for thousands of cities worldwide, from many urban systems at different levels of development. Measures of urban efficiency, capturing the balance between socioeconomic outputs and infrastructural costs, were shown to be independent of city size and might be a useful means to evaluate urban planning strategies. A link to this article can be found at http://dx.doi.org/10.1126/science.1235823.	complex systems;complexity;image scaling;interdependence;lu decomposition;scalability	Carlos Gershenson	2013	Complexity	10.1002/cplx.21475	worst-case complexity	ML	-20.95529529269151	-35.33380875703919	21677
11e5aa7f4988c632c2974d990c44628a7d7d820c	how users employ various popular tags to annotate resources in social tagging: an empirical study	information use;期刊论文;web content management;organization of information	This paper focuses on exploring the usage patterns and regularities of co-employment of various popular tags and their relationships with the activeness of users and the interest level of resources in social tagging. A hypernetwork for social tagging is constructed in which a tagging action is expressed as a hyperedge and the user, resource, and tag are expressed as nodes. Quantitative measures for the constructed hypernetwork are defined, including the hyperdegree and its distribution, the excess average hyperdegree, and the hyperdegree conditional probability distribution. Using the data set from Delicious, an empirical study was conducted. The empirical results show that multiple individual tags and one or very few popular tags are generally employed together in one tagging action, and the usage patterns and regularities of tags with varying popularity are correlated to both user activity and resource interest. The empirical results are further discussed and explained from the perspectives of tag functions and motivations. Finally, suggestions regarding the usage of various popular tags for both tagging users and service providers of social tagging are given.	folksonomy	Xuwei Pan;Shenglan He;Xiyong Zhu;Qingmiao Fu	2016	JASIST	10.1002/asi.23478	computer science;data mining;world wide web;information retrieval	HCI	-21.339993253663305	-46.37796275618609	21686
0e91bf8bae9adbd85a753cba722334d8c1130fab	lda topic model for microblog recommendation	radio frequency knowledge engineering real time systems;会议论文;recommendation system;comparative analysis lda topic model microblog recommendation browser based platform web user information sharing latent dirichlet allocation topic model user interest indirect recommendation algorithms direct recommendation algorithms;lda;radio frequency;lda model social media recommendation system;web sites internet;social media;real time systems;knowledge engineering	Microblog is a browser-based platform for web user's information sharing and communication. With the rapidly increasing of microblog population, its effective recommendation function becomes necessary. This paper proposes the recommendation by the Latent Dirichlet Allocation topic model, which combines the user interest to meet their needs. It also conducts a comparative analysis between indirect and direct recommendation algorithms. The experimental results show that the indirect recommendation is more effective for the micro-blog recommendation.	algorithm;blog;latent dirichlet allocation;linear discriminant analysis;local-density approximation;qualitative comparative analysis;recommender system;topic model;web application	Jianyong Duan;Yamin Ai;Xia Li	2015	2015 International Conference on Asian Language Processing (IALP)	10.1109/IALP.2015.7451562	social media;computer science;knowledge engineering;data mining;world wide web;radio frequency;information retrieval	DB	-22.853772917040203	-49.335161441377856	21701
8ee11d5f9df0a120859f286ddad65f299244c26c	“pedestrian in the loop”: an approach using virtual reality		A large number of testing procedures have been developed to ensure vehicle safety in common and extreme driving situations. However, these conventional testing procedures are insufficient for testing autonomous vehicles. They have to handle unexpected scenarios with the same or less risk a human driver would take. Currently, safety related systems are not adequately tested, e.g. in collision avoidance scenarios with pedestrians. Examples are the change of pedestrian behaviour caused by interaction, environmental influences and personal aspects, which cannot be tested in real environments. It is proposed to use Virtual Reality techniques. This method can be seen as a new Pedestrian in the Loop testing procedure.	autonomous robot;cloud computing;collision detection;device driver;die (integrated circuit);motion capture;motion planning;randomized algorithm;smartphone;software performance testing;software release life cycle;virtual reality;wearable computer;webcam;world wide web	Michael Hartmann;Marco Viehweger;Wim Desmet;Michael Stolz;Daniel Watzenig	2017	2017 XXVI International Conference on Information, Communication and Automation Technologies (ICAT)	10.1109/ICAT.2017.8171601	collision;simulation;virtual reality;vehicle dynamics;pedestrian;computer science	Visualization	-20.43928905610532	-27.705043669189035	21752
41f15043d055692650ab8272e49c4bd905974763	the continuous configuration model: a null for community detection on weighted networks		Community detection is the process of grouping strongly connected nodes in a network. Many community detection methods for un-weighted networks have a theoretical basis in a null model, which provides an interpretation of resulting communities in terms of statistical significance. In this paper, we introduce a null for sparse weighted networks called the continuous configuration model. We prove a Central Limit Theorem for sums of edge weights under the model, and propose a community extraction method called CCME which combines this result with an iterative multiple testing framework. To benchmark the method, we provide a simulation framework that incorporates the continuous configuration model as a way to plant null or “background” nodes in weighted networks with communities. We show CCME to be competitive with existing methods in accurately identifying both disjoint and overlapping communities, while being particularly effective in ignoring background nodes when they exist. We present two real-world data sets with potential background nodes and analyze them with CCME, yielding results that correspond to known features of the data.	benchmark (computing);iterative method;null model;simulation;sparse matrix;strongly connected component;weighted network	John Palowitch;Shankar Bhamidi;Andrew B. Nobel	2016	CoRR		combinatorics;machine learning;data mining;mathematics;statistics	AI	-14.312425602499498	-41.64378316662674	21866
6f7e96859d0b0b10cf63c88cfc3a8eab135fd1dc	using triangles and latent factor cosine similarity prior to improve community detection in multi-relational social networks			cosine similarity;social network	Jianzhou Zhan;Mei Sun;Huidan Wu;Haojun Sun	2018	Concurrency and Computation: Practice and Experience	10.1002/cpe.4453	distributed computing;computer science;machine learning;social network;cosine similarity;artificial intelligence	Web+IR	-15.736371965874042	-44.88341767430665	21889
9789a533266e2a04eff1f9a507b59282775e343e	linking collaborative filtering and social networks: who are my mentors?	social network services;community detection;groupware;measurement;community detection algorithm;detection algorithms;motion pictures;social networking online groupware information filtering recommender systems;information filtering;collaboration;social network;democratic voting rules mentor selection memory based collaborative filtering community detection algorithm social networks;memory based collaborative filtering;local community detection;local community;collaborative filtering;social networks;social networking online;voting rule;local community detection mentor detection collaborative filtering;mentor detection;communities;mentor selection;communities social network services collaboration detection algorithms recommender systems measurement motion pictures;recommender systems;democratic voting rules	This paper proposes a new approach of mentor selection in memory-based collaborative filtering when no rating is available. Users are represented under the form of a social network. The selection of mentors is performed through the use of a community detection algorithm used in the frame of social networks. It allows to recommend items to a given user, by applying democratic voting rules within his community.	algorithm;collaborative filtering;social network	Armelle Brun;Anne Boyer	2010	2010 International Conference on Advances in Social Networks Analysis and Mining	10.1109/ASONAM.2010.41	social science;computer science;knowledge management;collaborative filtering;world wide web;recommender system;social network	ML	-23.556903969066298	-42.538798387288324	21891
2d5f52c2d1698ef0378790c24cb233db0bd6f46a	on locality-sensitive indexing in generic metric spaces	generalized metric space;metric space;locality sensitive hashing;euclidean distance;approximation;sensitivity index;indexation;high dimensional data;hash function;scalability;similarity search	"""The concept of Locality-sensitive Hashing (LSH) has been successfully used for searching in high-dimensional data and a number of locality-preserving hash functions have been introduced. In order to extend the applicability of the LSH approach to a general metric space, we focus on a recently presented Metric Index (M-Index), we redefine its hashing and searching process in the terms of LSH, and perform extensive measurements on two datasets to verify that the M-Index fulfills the conditions of the LSH concept. We widely discuss """"optimal"""" properties of LSH functions and the efficiency of a given LSH function with respect to kNN queries. The results also indicate that the M-Index hashing and searching is more efficient than the tested standard LSH approach for Euclidean distance."""	cryptographic hash function;euclidean distance;locality of reference;locality-sensitive hashing;lsh	David Novak;Martin Kyselak;Pavel Zezula	2010		10.1145/1862344.1862354	discrete mathematics;scalability;hash function;topology;metric space;computer science;theoretical computer science;machine learning;approximation;euclidean distance;mathematics;k-independent hashing;locality-sensitive hashing;clustering high-dimensional data	DB	-5.731886833142714	-42.607326552390674	21962
bd59160844386d36499660b3ce35dcabae81a57b	using indirect communications to improve relationship strength estimation		The estimation of relationship strength based on phone communication data has drawn great interests from amounts of researches. This paper focuses on combining indirect communications with direct communications to improve relationship strength estimation. Firstly, algorithms for finding one-jump and two-jump indirect communications are proposed to make preparations for feature extraction. Then features from direct and indirect communications are extracted and aggregated to be used for classification. Experiment results on MIT Social Relationship dataset indicate that our method combining direct and indirect communications performs better than existing method. Especially, our method improves the performance of estimating relationship strength on pairs with no direct communications.	algorithm;experiment;feature extraction	Zeng Chen;Keren Wang	2017	2017 13th International Conference on Semantics, Knowledge and Grids (SKG)	10.1109/SKG.2017.00047	data mining;feature extraction;mobile telephony;computer science	Robotics	-14.690482112975404	-49.32383690235852	22047
995328f2d7a1e45dbbc63c6f34841c6f5a847ced	visual analytics in urban computing: an overview	social network services;town and country planning data analysis data mining data visualisation learning artificial intelligence;multivariate;sensors;data visualization visual analytics roads urban areas social network services public transportation sensors;public transportation;artificial intelligence urban computing urban visual analytics data types data exploration pattern interpretation visual learning machine learning data mining process;visualization;urban areas;roads;visual learning;spatio temporal;data visualization;visual analytics;urban computing;multivariate urban computing visual analytics visualization visual learning spatio temporal	Nowadays, various data collected in urban context provide unprecedented opportunities for building a smarter city through urban computing. However, due to heterogeneity, high complexity and large volumes of these urban data, analyzing them is not an easy task, which often requires integrating human perception in analytical process, triggering a broad use of visualization. In this survey, we first summarize frequently used data types in urban visual analytics, and then elaborate on existing visualization techniques for time, locations and other properties of urban data. Furthermore, we discuss how visualization can be combined with automated analytical approaches. Existing work on urban visual analytics is categorized into two classes based on different outputs of such combinations: 1) For data exploration and pattern interpretation, we describe representative visual analytics tools designed for better insights of different types of urban data. 2) For visual learning, we discuss how visualization can help in three major steps of automated analytical approaches (i.e., cohort construction; feature selection & model construction; result evaluation & tuning) for a more effective machine learning or data mining process, leading to sort of artificial intelligence, such as a classifier, a predictor or a regression model. Finally, we outlook the future of urban visual analytics, and conclude the survey with potential research directions.	artificial intelligence;categorization;data mining;feature selection;kerrison predictor;machine learning;microsoft outlook for mac;statistical classification;urban computing;visual analytics;visual learning	Yixian Zheng;Wenchao Wu;Yuanzhe Chen;Huamin Qu;Lionel M. Ni	2016	IEEE Transactions on Big Data	10.1109/TBDATA.2016.2586447	computer vision;multivariate statistics;analytics;visual analytics;visualization;interactive visual analysis;computer science;sensor;data science;machine learning;data mining;business intelligence;cultural analytics;data visualization;statistics	Visualization	-25.682319798747997	-33.28216147287586	22112
a275f2e251d6560e4bb3ca8d0e9eef40dbe37fda	scalemine: scalable parallel frequent subgraph mining in a single large graph		Frequent Subgraph Mining is an essential operation for graph analytics and knowledge extraction. Due to its high computational cost, parallel solutions are necessary. Existing approaches either suffer from load imbalance, or high communication and synchronization overheads. In this paper we propose ScaleMine; a novel parallel frequent subgraph mining system for a single large graph. ScaleMine introduces a novel two-phase approach. The first phase is approximate; it quickly identifies subgraphs that are frequent with high probability, while collecting various statistics. The second phase computes the exact solution by employing the results of the approximation to achieve good load balance; prune the search space; generate efficient execution plans; and guide intra-task parallelism. Our experiments show that ScaleMine scales to 8,192 cores on a Cray XC40 (12× more than competitors); supports graphs with one billion edges (10× larger than competitors), and is at least an order of magnitude faster than existing solutions.	acm/ieee supercomputing conference;algorithmic efficiency;approximation algorithm;cray xc40;experiment;f1 score;graph partition;image scaling;in-memory database;load balancing (computing);overhead (computing);parallel computing;prototype;scalability;task parallelism;two-phase commit protocol;with high probability	Ehab Abdelhamid;Ibrahim Abdelaziz;Panos Kalnis;Zuhair Khayyat;Fuad Jamour	2016	SC16: International Conference for High Performance Computing, Networking, Storage and Analysis		parallel processing;parallel computing;scalability;computer science;theoretical computer science;operating system;machine learning;analysis;distributed computing;scheduling;measurement	HPC	-8.711141648847548	-40.96750332688395	22133
77f4314e33722556690d559f9d6a54782f3f8953	an algorithm of propagation in weighted directed graphs with applications to economics and finance	directed graph	This paper puts forward an algorithm that computes the diffusion of events and actions across networks of economic agents, an algorithm that is applicable when such networks can be represented as weighted directed graphs. The functioning of the algorithm is shown in three applications. First, the algorithm is applied to a model of diffusion of innovation driven by the agents' imitation of their neighbors' behavior. Second, a graph-theoretic model of financial networks is introduced, and the corresponding algorithm is used to compute the so called domino effect, i.e., the diffusion of losses and insolvencies caused by the initial default of one or more agents. Finally, the algorithm is applied to the transfer of deposits operated by interbank liquidity networks. © 2010 Wiley Periodicals, Inc.	algorithm;directed graph;software propagation	Mario Eboli	2010	Int. J. Intell. Syst.	10.1002/int.20399	suurballe's algorithm;directed graph;floyd–warshall algorithm;computer science;artificial intelligence;machine learning;mathematics;mathematical economics;statistics	Theory	-15.938023623341945	-39.47505811517718	22139
310abcfe375a4e498b76bc796c610d7555cafcff	privacy-enhancing personalized web search	search engine;privacy protection;personalized search;hierarchical user profile;user profile;web search;profitability;privacy	Personalized web search is a promising way to improve search quality by customizing search results for people with individual information goals. However, users are uncomfortable with exposing private preference information to search engines. On the other hand, privacy is not absolute, and often can be compromised if there is a gain in service or profitability to the user. Thus, a balance must be struck between search quality and privacy protection. This paper presents a scalable way for users to automatically build rich user profiles. These profiles summarize a user.s interests into a hierarchical organization according to specific interests. Two parameters for specifying privacy requirements are proposed to help the user to choose the content and degree of detail of the profile information that is exposed to the search engine. Experiments showed that the user profile improved search quality when compared to standard MSN rankings. More importantly, results verified our hypothesis that a significant improvement on search quality can be achieved by only sharing some higher-level user profile information, which is potentially less sensitive than detailed personal information.	personalization;personally identifiable information;privacy;requirement;scalability;user profile;web search engine	Yabo Xu;Ke Wang;Benyu Zhang;Zheng Chen	2007		10.1145/1242572.1242652	metasearch engine;semantic search;computer science;data mining;database;internet privacy;search analytics;privacy;world wide web;search engine;profitability index	Web+IR	-28.682346167242528	-46.677838973376566	22144
67dda94dcbc09e96a6758cb073799043529def9e	a captcha design based on visual reasoning		CAPTCHA is a reverse Turing test to distinguish humans from machines. It is widely used in the internet industry for cyber security. A good CAPTCHA is supposed to be easy for humans but difficult for machines. Many existing CAPTCHA implementations leverage the inability of automatic visual recognition, e.g., recognizing the text or other objects in an image. These CAPTCHAs are becoming more and more vulnerable recently, due to the rapid development of visual recognition techniques. This paper presents our study of using visual reasoning in CAPTCHA design. This CAPTCHA asks the users to find specific object(s) in an image according to a given text query. It is generally easy for humans to understand the text query and make sophisticated reasoning about the image, but still remains difficult and computationally expensive for machines. We describe the CAPTCHA design, provide usability analysis and present security experiments. Moreover, we show that the security can be further improved by the use of neural style transfer.	analysis of algorithms;captcha;computer security;experiment;online service provider;reverse turing test;usability	Haipeng Wang;Feng Zheng;Zhuoming Chen;Yi Lu;Jing Gao;Renjia Wei	2018	2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)	10.1109/ICASSP.2018.8461764	implementation;visual reasoning;the internet;reverse turing test;theoretical computer science;visualization;artificial intelligence;usability;captcha;pattern recognition;computer science;cognition	Robotics	-25.376103146615325	-26.253043847093902	22151
3b8af7ef79651da9be55ec2f93cf11a1eb13de43	temporal sketch recognition in interspersed drawings	pen based interface;sketch recognition;temporal information;categories and subject descriptors according to acm ccs i 5 4 pattern recognition applications;dynamic bayesian network;temporal pattern	Sketch recognition has been recognized as an enabling technology for pen-based interfaces. Previous work in the field has shown that in certain domains the stroke orderings used when drawing objects contain temporal patterns that can aid recognition. So far, systems that use temporal information for recognition have assumed that objects are drawn one at a time. This paper shows how this assumption can be relaxed to permit temporal interspersing of strokes from different objects. We describe a statistical framework based on Dynamic Bayesian Networks that explicitly models the fact that objects can be drawn interspersed. We present recognition results for hand-drawn electronic circuit diagrams. The results show that handling interspersed drawing provides a significant increase in accuracy.	diagram;dynamic bayesian network;electronic circuit;sketch recognition	T. Metin Sezgin;Randall Davis	2007		10.1145/1384429.1384436	computer vision;computer science;communication;engineering drawing;sketch recognition	HCI	-30.612665479689056	-38.20028140923792	22175
89b089e80991e4a9fe31c473e76e887039a5470e	sketching landscapes of page farms	web spam;web pages;social network;power law distribution;greedy algorithm	The Web is a very large social network. It is important and interesting to understand the “ecology” of the Web: the general relations of Web pages to their environment. The understanding of such relations has a few important applications, including Web community identification and analysis, and Web spam detection. In this paper, we propose the notion of page farm, which is the set of pages contributing to (a major portion of) the PageRank score of a target page. We try to understand the “landscapes” of page farms in general: how are farms of Web pages similar to or different from each other? In order to sketch the landscapes of page farms, we need to extract page farms extensively. We show that computing page farms is NP-hard, and develop a simple greedy algorithm. Then, we analyze the farms of a large number of (over 3 million) pages randomly sampled from the Web, and report some interesting findings. Most importantly, the landscapes of page farms tend to also follow the power law distribution. Moreover, the landscapes of page farms strongly reflect the importance of the Web pages.	anti-spam techniques;ecology;greedy algorithm;home page;np-hardness;pagerank;randomness;set cover problem;social network;web page;webgraph;world wide web	Bin Zhou;Jian Pei	2007		10.1137/1.9781611972771.67	web page;computer science;web search engine;social semantic web;world wide web;site map;web analytics;data mining;spamdexing;data web;web 2.0	Metrics	-28.27062874289132	-51.820626575781716	22288
faca12a154083e2aa0405a4b1eaf5ce8c71207ed	application of agent-based personal web of trust to local document ranking	web documents;web of trust;agent based	Web is the boundless source of information and no one is able to process the vast amount of new documents published on the web every day, even with filtering out the documents the user is not interested in. However, most of the recent web documents are blog posts, news and other documents with the author information established. Each author who is also the receiver of web documents possesses their own personal agent that delivers trust information related to other authors as well as rank data for each new document. Trusts and ranks available for agents are exchanged between them and in this way new authors and new web documents can be easily assessed. Based on the general concept of Web of Trust the new idea of Personal Web of Trust and its application to local ranking method for web documents is proposed in the paper.	blog;collaborative filtering;content-control software;digital signature;encryption;foaf (ontology);information source;intelligent agent;multi-agent system;personalization;public key certificate;public key infrastructure;public-key cryptography;ranking (information retrieval);semiconductor industry;social network;web of trust;web page;xhtml friends network	Marek Kopel;Przemyslaw Kazienko	2007		10.1007/978-3-540-72830-6_30	web service;web application security;web of trust;web development;data web;web analytics;web mapping;web design;web standards;computer science;semantic web;web navigation;social semantic web;web page;data mining;web intelligence;web 2.0;world wide web;information retrieval;web server;mashup	Web+IR	-27.510775992348282	-49.7339778304288	22387
b4038b3bb3b8ef1f03eea1c0b108ad89c29e5a50	hierarchical structuring of layout problems in an interactive evolutionary layout system	automated layout design;evolutionary algorithms;hierarchical structuring	This paper focuses on computer-based generative methods for layout problems in architecture and urban planning with special regard for the hierarchical structuring of layout elements. The generation of layouts takes place using evolutionary algorithms, which are used to optimize the arrangement of elements in terms of overlapping within a given boundary and the topological relations between them. In this paper, the approach is extended by a data structure that facilitates the hierarchical organization of layout elements making it possible to structure and organize larger layout problems into subsets that can be solved in parallel. An important aspect for the applicability of such a system in the design process is an appropriate means of user interaction. This depends largely on the calculation speed of the system and the variety of viable solutions. These properties are evaluated for hierarchical as well as for nonhierarchical structured layout	constraint (mathematics);data structure;evolutionary algorithm;feasible region;interactivity;iterative method;microsoft outlook for mac;microsoft windows;point of view (computer hardware company);rate of convergence;requirement;scenario testing;software release life cycle	Reinhard König;Sven Schneider	2012	AI EDAM	10.1017/S0890060412000030	layout;simulation;computer science;artificial intelligence;machine learning;evolutionary algorithm;engineering drawing	AI	-29.72420642131541	-26.577416803367765	22592
07aa4c85c376e83e0f27e26b265bf53a77c6da2c	adaptive pairwise learning for personalized ranking with content and implicit feedback	convergence;pairwise learning personalized ranking adaptive sampling;training;collaboration;smart phones;personalized ranking;pairwise learning;bpr learning adaptive pairwise learning content feedback implicit feedback massive training pairs large scale training data stochastic gradient descent sampling strategy informative training data content aware adaptive bayesian personalized ranking ca bpr method;training data;ubiquitous computing belief networks feedback gradient methods learning artificial intelligence sampling methods stochastic processes;adaptive sampling;business process re engineering;recommender systems;business process re engineering training convergence training data recommender systems smart phones collaboration	Pairwise learning algorithms are a vital technique for personalized ranking with implicit feedback. They usually assume that each user is more interested in items which have been selected by the user than remaining ones. This pairwise assumption usually derives massive training pairs. To deal with such large-scale training data, the learning algorithms are usually based on stochastic gradient descent with uniformly drawn pairs. However, the uniformly sampling strategy often results in slow convergence. In this paper, we first uncover the reasons of slow convergence. Then, we associate contents of entities with characteristics of data sets to develop an adaptive item sampler for drawing informative training data. In this end, to devise a robust personalized ranking method, we accordingly embed our sampler into Bayesian Personalized Ranking (BPR) framework, and further propose a Content-aware and Adaptive Bayesian Personalized Ranking (CA-BPR) method, which can model both contents and implicit feedbacks in a unified learning process. The experimental results show that, our adaptive item sampler indeed can speed up BPR learning and CA-BPR definitively outperforms the state-of-the-art methods in personalized ranking.	adaptive sampling;algorithm;cold start;entity;experiment;feedback;information;latent variable;machine learning;personalization;sampling (signal processing);speedup;stochastic gradient descent	Weiyu Guo;Shu Wu;Liang Wang;Tieniu Tan	2015	2015 IEEE/WIC/ACM International Conference on Web Intelligence and Intelligent Agent Technology (WI-IAT)	10.1109/WI-IAT.2015.36	training set;convergence;computer science;artificial intelligence;data science;machine learning;data mining;world wide web;recommender system;collaboration	AI	-18.697815629187154	-48.37797362307462	22611
fba80b6b405a9ef5c82b92608c3a166fa6ef88b3	community influence analysis based on social network structures	social network services;analytical models;influence maximization problem social network community influence commrank algorithm;damping;approximation algorithms;community influence;influence maximization problem;social network;social sciences computing optimisation social networking online;social network structure influence maximization problem commrank community oriented influence analysis model online social network;tuning;commrank algorithm;computer science;social network services algorithm design and analysis approximation algorithms tuning damping computer science analytical models;algorithm design and analysis	Modeling and measuring social influence is a major problem in Social Network Analysis. Existing models and methods could handle individual influence analysis conveniently, but they rarely estimate the social influence of communities which are ubiquitous in social networks. Based on the structures of online social networks, a community oriented influence analysis model is proposed. Then, we provide an algorithm called CommRank for calculating the social influence of communities. Since the algorithm combines both internal structural information and external interaction data of communities, it estimates community influence more precisely on multiple datasets. Experimental results also demonstrate that, at the cost of a little gain loss, CommRank can dramatically improve the efficiency when dealing with the influence maximization problem.	algorithm;centrality;entropy maximization;norm (social);social network analysis	Yi Li;Xindong Wu;Lei Li	2015	2015 IEEE International Conference on Smart City/SocialCom/SustainCom (SmartCity)	10.1109/SmartCity.2015.79	organizational network analysis;computer science;dynamic network analysis;artificial intelligence;machine learning;management science	DB	-17.71233493824591	-43.15146463901285	22625
129b726a08f47529131b12089770849146b841ec	a self-organizing method for predictive modeling with highly-redundant variables	predictive models correlation clustering algorithms principal component analysis force big data self organizing networks;principal component analysis self organizing method predictive analytics big data data driven decision making clustering modelling predictive modelling nonlinear coupling force;principal component analysis big data data analysis decision making pattern clustering	Rapid advancement of sensing and information technology brings the big data, which presents a gold mine of the 21st century. However, big data also brings significant challenges for data-driven decision making. In particular, it is not uncommon that a large number of variables (or features) underlie the big data. Complex interdependence structures among variables challenge the traditional framework of predictive modeling. This paper presents a new methodology of self-organizing network for variable clustering and predictive modeling. Specifically, we developed a new approach, namely nonlinear coupling analysis to measure nonlinear interdependence structures among variables. Further, all the variables are embedded as nodes in a complex network. Nonlinear-coupling forces move these nodes to derive a self-organizing topology of network. As such, variables are clustered as sub-network communities in the space. Experimental results demonstrated that the proposed methodology not only outperforms traditional variable clustering algorithms such as hierarchical clustering and oblique principal component analysis, but also effectively identify interdependent structures among variables and further improves the performance of predictive modeling. The proposed new idea of self-organizing network is generally applicable for predictive modeling in many disciplines that involve a large number of highly-redundant variables.	algorithm;big data;cluster analysis;complex network;embedded system;granular computing;hierarchical clustering;interdependence;nonlinear system;oblique projection;organizing (structure);predictive modelling;principal component analysis;self-organization;subnetwork	Gang Liu;Hui Yang	2015	2015 IEEE International Conference on Automation Science and Engineering (CASE)	10.1109/CoASE.2015.7294243	computer science;data science;machine learning;data mining;cluster analysis	Robotics	-17.48999814288099	-41.68137505065082	22779
6c078768054e2f9303789f6adef2d363e182b683	salesexplorer: exploring sales opportunities from white-space customers in the enterprise market		In commercial sales and services, recommender systems have been widely adopted to predict customers’ purchase interests using their prior purchasing behaviors. Cold-start is a known challenge to existing recommendation techniques, e.g., the popular collaborative filtering method is not applicable to predict the interests of “white-space” customers since they have no prior purchasing history in the targeted product categories.#R##N##R##N#This paper presents SalesExplorer, a new recommendation algorithm to address “white-space” customer issue in the commercial sales and services segment. To predict the interests of customers who are new to a product category, we propose a statistical inference method using customers’ existing purchase records from other product categories, a Probabilistic Latent Semantic Analysis (PLSA)-based transfer learning method using customers’ business profile content, and a kernel logistic regression-based model which combines these two recommendations to produce the final results with higher accuracy. Experimental study using real-world enterprise sales data demonstrates that, comparing with a baseline and two state-of-the-art methods, the proposed combinatorial algorithm improves recommendation accuracy by 32.14%, 13.13% and 9.85%, respectively.		Dongsheng Li;Yaoping Ruan;Qin Lv;Li Shang	2016	Knowl.-Based Syst.	10.1016/j.knosys.2016.09.011	data mining	ECom	-20.030470104952553	-50.16267304012665	22782
029d739edbb3ccf70634fef2ef1d014827d5061a	selectivity estimation for hybrid queries over text-rich data graphs	data graph;hybrid query;selectivity estimation	Many databases today are text-rich, comprising not only structured, but also textual data. Querying such databases involves predicates matching structured data combined with string predicates featuring textual constraints. Based on selectivity estimates for these predicates, query processing as well as other tasks that can be solved through such queries can be optimized. Existing work on selectivity estimation focuses either on string or on structured query predicates alone. Further, probabilistic models proposed to incorporate dependencies between predicates are focused on the relational setting. In this work, we propose a template-based probabilistic model, which enables selectivity estimation for general graph-structured data. Our probabilistic model allows dependencies between structured data and its text-rich parts to be captured. With this general probabilistic solution, BN+, selectivity estimations can be obtained for queries over text-rich graph-structured data, which may contain structured and string predicates (hybrid queries). In our experiments on real-world data, we show that capturing dependencies between structured and textual data in this way greatly improves the accuracy of selectivity estimates without compromising the efficiency.	database;empty string;experiment;graph (abstract data type);graph theory;kernel density estimation;overhead (computing);relational database;selectivity (electronic);statistical model;text corpus	Andreas Wagner;Veli Bicer;Thanh Tran	2013		10.1145/2452376.2452421	computer science;theoretical computer science;data mining;database	DB	-8.883702682148664	-33.00408566761382	22795
1e32243ac288c100b4605a7764ccf088bd2d290f	formal peptide as a basic agent of immune networks: from natural prototype to mathematical theory and applications			prototype	Alexander O. Tarakanov	1999			theoretical computer science;mathematical theory;immune system;computer science	ECom	-6.12364787406514	-50.215107241740895	22808
4a51f97c621849977b243bb6fd6a5ce8b6ce632f	tums: twitter-based user modeling service	semantic enrichment;user modeling;service;twitter	Twitter is today’s most popular micro-blogging service on the Social Web. As people discuss various fresh topics, Twitter messages (tweets) can tell much about the current interests and concerns of a user. In this paper, we introduce TUMS, a Twitter-based User Modeling Service, that infers semantic user profiles from the messages people post on Twitter. It features topic detection and entity extraction for tweets and allows for further enrichment by linking tweets to news articles that describe the context of the tweets. TUMS is made publicly available as a Web application. It allows end-users to overview Twitter-based profiles in a structured way and allows them to see in which topics or entities a user was interested in a specific point in time. Furthermore, it provides Twitter-based user profiles in RDF format and allows applications to incorporate these profiles in order to adapt their functionality to the current interests of a user. TUMS is available via: http://wis.ewi.tudelft.nl/tums/	blog;communication endpoint;entity;experiment;gene ontology term enrichment;grapple;hashtag;named-entity recognition;personalization;recommender system;resource description framework;user (computing);user modeling;user profile;web application	Ke Tao;Fabian Abel;Qi Gao;Geert-Jan Houben	2011		10.1007/978-3-642-25953-1_22	user modeling;service;computer science;multimedia;internet privacy;world wide web	Web+IR	-26.833543850343002	-49.640621936805374	22849
426ccf15eee325e2d2e4595fcc6df7910df908c2	experimental examination and simulation analysis of standing-type personal mobility device sharing	tablet computers;multi agent systems;servers;urban areas;bicycles;robots	This study considers sharing of standing-type personal mobility devices. Such devices offer various advantages as a means of transportation, but they have been used only slightly for this purpose to date. Their cost makes sharing such devices more attractive than owning them. Sharing personal mobility devices is expected to introduce beneficial social influences such as a modal shift. For this study, we conducted small-scale experiments to assess their feasibility. Then we considered larger cases in simulations. The experiments employ four sharing stations and four personal mobility devices by more than 60 registered users. Larger scale simulations are based on a multi-agent model, presenting results for its usage compared with other means of transportation. Such a simulation is expected to provide a basis for future demand prediction and planning of personal mobility sharing.	experiment;modal logic;multi-agent system;shift jis;simulation	Kohji Tomita;Naohisa Hashimoto;Akiya Kamimura;Masashi Yokozuka;Osamu Matsumoto	2016	2016 19th Conference of Open Innovations Association (FRUCT)	10.23919/FRUCT.2016.7892208	simulation;engineering;multimedia;computer security	HCI	-19.84523544169522	-23.99636259300122	22985
75975cc1ab222a846c0a55f7561b5fb729e951ae	spatial support and spatial confidence for spatial association rules	confidence measure;spatio temporal data mining;satisfiability;data mining;association rule mining;spatial data mining;association rule;fuzzy association rules	In data mining, the quality of an association rule can be stated by its support and its confidence. This paper investigates support and confidence measures for spatial and spatio-temporal data mining. Using fixed thresholds to determine how many times a rule that uses proximity is satisfied seems too limited. It allows the traditional definitions of support and confidence, but does not allow to make the support stronger if the situation is “really close”, as compared to “fairly close”. We investigate how to define and compute proximity measures for several types of geographic objects—point, linear, areal—and we express whether or not objects are “close” as a score in the range [0, 1]. We then use the theory from so-called fuzzy association rules to determine the support and confidence of an association rule. The extension to spatiotemporal rules can be done along the same lines.	association rule learning;data mining;point-to-point protocol;proximity problems	Patrick Laube;Mark de Berg;Marc J. van Kreveld	2008		10.1007/978-3-540-68566-1_33	data science;pattern recognition;data mining	DB	-9.667154012980136	-35.29863903299088	23009
3950fbaaea773f4367ce08e66417d4024ea74e0f	using virtual human for an interactive customer-oriented constrained environment design	customer orientation;trajectory planning;evaluation method;virtual human;motion capture;industrial production;constrained environment design;optimization	For industrial product design, it is very important to take into account assembly/disassembly and maintenance operations during the conceptual and prototype design stage. For these operations or other similar operations in a constrained environment, trajectory planning is always a critical and difficult issue for evaluating the design or for the users' convenience. In this paper, a customer-oriented approach is proposed to partially solve ergonomic issues encountered during the design stage of a constrained environment. A single objective optimization based method is taken from the literature to generate the trajectory in a constrained environment automatically. A motion capture based method assists to guide the trajectory planning interactively if a local minimum is encountered within the single objective optimization. At last, a multi-objective evaluation method is proposed to evaluate the operations generated by the algorithm.	algorithm;disassembler;human factors and ergonomics;interactivity;mathematical optimization;maxima and minima;motion capture;prototype;virtual actor	Liang Ma;Ruina Ma;Damien Chablat;Fouad Bennis	2010	CoRR		industrial production;motion capture;simulation;computer science;engineering;engineering drawing	Robotics	-30.10642310813552	-26.62643019488194	23026
d3b74aba5fa5f406f9f231cf3c1130581aa0e690	interactive probabilistic post-mining of user-preferred spatial co-location patterns		Spatial co-location pattern mining is an important task in spatial data mining. However, traditional mining frameworks often produce too many prevalent patterns of which only a small proportion may be truly interesting to end users. To satisfy user preferences, this work proposes an interactive probabilistic post-mining method to discover user-preferred co-location patterns from the early-round of mined results by iteratively involving user's feedback and probabilistically refining preferred patterns. We first introduce a framework of interactively post-mining preferred co-location patterns, which enables a user to effectively discover the co-location patterns tailored to his/her specific preference. A probabilistic model is further introduced to measure the user feedback-based subjective preferences on resultant co-location patterns. This measure is used to not only select sample co-location patterns in the iterative user feedback process but also rank the results. The experimental results on real and synthetic data sets demonstrate the effectiveness of our approach.	data mining;interactivity;iterative method;mined;resultant;statistical model;synthetic data;user (computing)	Lizhen Wang;Xuguang Bao;Longbing Cao	2018	2018 IEEE 34th International Conference on Data Engineering (ICDE)	10.1109/ICDE.2018.00124	end user;data mining;spatial analysis;probabilistic logic;computer science;synthetic data;statistical model	DB	-26.444000051331056	-35.25028180558934	23078
5c2a6e1255888547864b0f2671a6d4b5ebaab6e1	estimating and predicting average likability on computer-generated artwork variants	media arts;gentic algorithms;software product lines	Computer assisted human creativity encodes human design decisions in algorithms allowing machines to produce artwork variants. Based on this automated production, one can leverage collective understanding of beauty to rank computer-generated artworks according to their average likability. We present the use of Software Product Line techniques for computer-generated art systems as a case study on leveraging the feedback of human perception within the boundaries of a variability model. Since it is not feasible to get feedback for all variants because of a combinatorial explosion of possible configurations, we propose an approach that is developed in two phases: 1) the creation of a data set using an interactive genetic algorithm and 2) the application of a data mining technique on this dataset to create a ranking enriched with confidence metrics.	aggregate data;algorithmic art;computer-generated holography;data mining;genetic algorithm;heart rate variability;interactive evolutionary computation;software product line	Jabier Martinez;Gabriele Rossi;Tewfik Ziadi;Tegawendé F. Bissyandé;Jacques Klein;Yves Le Traon	2015		10.1145/2739482.2764681	simulation;computer science;data science;data mining	HCI	-28.02886850884213	-26.367145051949578	23082
234fffb44a57e88c1f1a52f9dd69d84c0c8ad490	evolving effective micro behaviors in rts game	genetic algorithms artificial intelligence computer games;ai bots microbehaviors rts game real time strategy games genetic algorithms combat scenarios macromanagement micromanagement positioning micromanagement movement tactics influence maps ecslbot starcraft ai art bots ualbertabot nova skirmish scenarios;force;games artificial intelligence force genetic algorithms navigation biological cells sociology;navigation;biological cells;games;artificial intelligence;genetic algorithms;sociology	We investigate using genetic algorithms to generate high quality micro management in combat scenarios for real-time strategy games. Macro and micro management are two key aspects of real-time strategy games. While good macro helps a player collect more resources and build more units, good micro helps a player win skirmishes against equal numbers and types of opponent units or win even when outnumbered. In this paper, we use influence maps and potential fields to generate micro management positioning and movement tactics. Micro behaviors are compactly encoded into fourteen parameters and we use genetic algorithms to search for effective micro management tactics for the given units. We tested the performance of our ECSLBot (the evolved player), obtained in this way against the default StarCraft AI, and two other state of the art bots, UAlbertaBot and Nova on several skirmish scenarios. The results show that the ECSLBot tuned by genetic algorithms outperforms the UAlbertaBot and Nova in kiting efficiency, target selection, and knowing when to flee to survive. We believe our approach is easy to extend to other types of units and can be easily adopted by other AI bots.	binaural beats;common logic;data general nova;display resolution;experiment;genetic algorithm;hard coding;map;open research;real-time locating system;software release life cycle;starcraft;unit type	Siming Liu;Sushil J. Louis;Christopher A. Ballinger	2014	2014 IEEE Conference on Computational Intelligence and Games	10.1109/CIG.2014.6932904	games;navigation;simulation;genetic algorithm;computer science;artificial intelligence;machine learning;operations research;force	AI	-27.4182942066754	-25.303234734680693	23096
849ef7c69287abd51cf936f7bbed54eb067af839	efficiency and consistency study on carma	itemsets;lattices;interactive programming data flow computing data mining;association rules itemsets data mining algorithm design and analysis partitioning algorithms transaction databases statistical distributions lattices statistics information science;association rules;data mining;indexes;online association algorithm;association rule;data flow distribution;apriori;association rule algorithm;carma;online data flow;data flow computing;phase ii;data flow;algorithm design;algorithm design and analysis;carma association rule algorithm apriori;data flow distribution carma online association algorithm association rule online data flow;interactive programming	Carma is a type of online association algorithm, designed to facilitate association rule with online data flow and successively changing support thresholds. In this paper we study the factors that contribute to the efficiency of Carma and how data flow distribution give effects on the performance of Carma. We design several experiments with two kinds of data. In fixed support threshold situations, we compare Carma with that of Apriori. We find the sets generated by Carma are subsets of those generated by Apriori. We find that if the support threshold is reasonably defined, these two algorithms reach the same results. On the other hand, as the support threshold increases, Phase Ι generates less items and the number of deleted sets from Phase II first increases and then declines. Carma behaves consistently towards changing support. We notice the earlier the items enter into a lattice, the more accurate the estimations are. If base stone elements show up early in the transaction, the performance of Phase II is mainly influenced by the late-entered item sets. Based on the discussion with Carma, we propose a new procedure to improve Carma. Simulations reveal that the modified algorithm works well.	apriori algorithm;association rule learning;computer simulation;dataflow;emoticon;experiment;online algorithm	Yuan Huang;Xing Wang;Ben-Chang Shia	2009	2009 Fifth International Joint Conference on INC, IMS and IDC	10.1109/NCM.2009.241	algorithm design;association rule learning;computer science;machine learning;data mining;database;statistics	DB	-5.083461436637771	-36.33656722640801	23137
363985f1dc1aec83b9b7b85dcfa1460595bf1a66	effective texture models for three dimensional flow visualization	scientific visualisation;computational fluid dynamics;virtual environment	Visualizing three dimensional flow with geometry primitives is challenging due to inevitable clutter and occlusion. Our approach to tackling this problem is to utilize semi-transparent geometry as well as animation. Using semi-transparency, however, can make the visualization blurry and vague. We investigate perceptual limits and find specific guidelines on using semi-transparency for three dimensional flow visualization. We base our results on the user study that we conducted. The users were shown multiple semi-transparent overlapping layers of flow and were asked how many different flow directions they were able to discern. We utilized textured lines as geometric primitives; two general texture models were used to control opacity and create animation. We found that the number of high scoring textures is small compared to the total number of textures within our models. To test our findings, we utilized the high scoring textures to create visualizations of a variety of datasets.	clutter;hidden surface determination;semi-supervised learning;semiconductor industry;usability testing;vagueness	Oleg Mishchenko;Roger Crawfis	2012		10.1145/2448531.2448536	computer vision;scientific visualization;simulation;computational fluid dynamics;computer science;virtual machine;artificial intelligence;machine learning;computer graphics (images)	Visualization	-32.53660138985681	-36.61157604185941	23152
faa3a94d82008206ef72b247239e2c81f5103d46	supporting management of sensor networks through interactive visual analysis		With the increasing capabilities of measurement devices and computing machines, the amount of recorded data grows rapidly. It is so high that manual processing is no longer feasible. The Visual Analytics approach is powerful because it combines the strengths of human recognition and vision system with today’s computing power. Different, but strongly linked visualizations and views provide unique perspectives on the same data elements. The views are linked using position on the screen as well as color, which also plays a secondary role in indicating the degree of similarity. This enables the human recognition system to identify trends and anomalies in a network of measurement readings. As a result, the data analyst has the ability to approach more complex questions such as: are there anomalies in the measurement records? What does the network usually look like? In this work we propose a collection of Visual Analytics approaches to support the user in exploratory search and related tasks in graph data sets. One aspect is graph navigation, where we use the information of existing labels to support the user in analyzing with this data set. Another consideration is the preservation of the user’s mental map, which is supported by smooth transitions between individual keyframes. The later chapters focus on sensor networks, a type of graph data that additionally contains time series data on a per-node basis; this adds an extra dimension of complexity to the problem space. This thesis contributes several techniques to the scientific community in different domains and we summarize them as follows. We begin with an approach for network exploration. This forms the basis for subsequent contributions, as it to supports user in the orientation and the navigation in any kind of network structure. This is achieved by providing a showing only a small subset of the data (in other words: a local graph view). The user expresses interest in a certain area by selecting one of more focus nodes that define the visible subgraph. Visual cues in the form of pointing arrows indicate other areas of the graph that could be relevant for the user. Based on this network exploration paradigm, we present a combination of different techniques that stabilize the layout of such local graph views by reducing acting forces. As a result, the movement of nodes in the node-link diagram is reduced, which reduces the mental effort to track changes on the screen. However, up to this point the approach suffers from one of the most prominent shortcomings of force-directed graph layouts. Little changes in the initial setup, force parameters, or graph topology changes have a strong impact on the visual representation of the drawing. When the user explores the network, the set of visible nodes continuously changes and therefore the layout will look different when an area of the graph is visited a second time. This makes it difficult to identify differences or recognize different drawing as equal in terms of topology. We contribute an approach for the deterministic generation of layouts based on pre-computed layout patches that are stitched at runtime. This ensures that even force-directed layouts are deterministic, allowing the analyst to recognize previ-	computer;diagram;directed graph;exploratory search;force-directed graph drawing;interactive visual analysis;key frame;linked list;mental mapping;node (computer science);precomputation;problem domain;programming paradigm;run time (program lifecycle phase);time series;topological graph theory;visual analytics	Martin Steiger	2015			simulation;computer science;dynamic network analysis;artificial intelligence;data mining;geometric networks;visual sensor network	HCI	-28.603381075634616	-35.12185043812413	23291
a92bf23e4db4c42d3a0461e47d7af272b0813fee	rose: reoccurring structures detection in bpmn 2.0 process model collections		The detection of structural similarities of process models is frequently discussed in the literature. The state-of-the-art approaches for structural similarities of process models presume a known subgraph that is searched in a larger graph, and utilize behavioral and textual semantics to achieve their goal. In this paper we propose an approach to detect reoccurring structures in a collection of BPMN . process models, without the knowledge of a subgraph to be searched, and by focusing solely on the structural characteristics of the process models. The proposed approach deals with the problems of subgraph isomorphism, frequent pattern discovery and maximum common subgraph isomorphism, which are mentioned as NP-hard in the literature. In this work we present a formal model and a novel algorithm for the detection of reoccurring structures in a collection of BPMN . process models. We then apply the algorithm to a collection of , real-world process models and provide a quantitative and qualitative analysis of the results.	algorithm;beam propagation method;benchmark (computing);business process model and notation;control flow;duplicate code;executable;formal language;graph isomorphism;heuristic;induced subgraph;management system;model of computation;np-hardness;process modeling;scenario testing;subgraph isomorphism problem;synthetic intelligence;workflow pattern	Marigianna Skouradaki;Vasilios Andrikopoulos;Oliver Kopp;Frank Leymann	2016		10.1007/978-3-319-48472-3_15	computer science;data science;data mining;database	SE	-10.158425232838166	-37.844682423391646	23304
3e98e2a60e4bfec2d792bd77be247962d66fff4a	convergent drawing for mutually connected directed graphs		Abstract Directed graphs are used to represent a variety of datasets, including friendship on social networking services (SNS), pathways of genes, and citations of research papers. Graph drawing is useful in representing such datasets. At the international conference on Information Visualization (IV), we have presented a convergent edge drawing and a node layout technique for tightly and mutually connected directed graphs. The edge drawing technique in the IV paper includes three features: ordinary bundling of edges connecting pairs of node clusters, convergence of multiple bundles that connect to the same node cluster, and shape adjustment of two bundles connecting the same pair of node clusters. In this paper, we present improved node layout and edge drawing techniques, which make our edge bundling more effective. This paper also introduces a case study with a directed paper citation graph dataset.vvvvv	directed graph	Naoko Toeda;Rina Nakazawa;Takayuki Itoh;Takafumi Saito;Daniel W. Archambault	2017	J. Vis. Lang. Comput.	10.1016/j.jvlc.2017.09.004	force-directed graph drawing;feedback arc set;dominance drawing;edge contraction;directed graph;modular decomposition;citation graph;graph drawing;computer science;distributed computing	Theory	-16.534578779884068	-40.6955671994484	23311
fb7dfb6bf788e5d31a74b3ca4e6daf25f834a24c	song intersection by approximate nearest neighbor search	music similarity;high dimensions;nearest neigh- bors;audio shingling;nearest neighbor method;locality sensitive hashing;very large database;nearest neighbor	We present new methods for computing inter-song similarities using intersections between multiple audio pieces. Th e intersection contains portions that are similar, when one s g is a derivative work of the other for example, in two different musical recordings. To scale our search to large song databases we have developed an algorithm based on localitysensitive hashing (LSH) of sequences of audio features call ed audio shingles. LSH provides an efficient means to identify approximate nearest neighbors in a high-dimensional feature space. We combine these nearest neighbor estimates, each a match from a very large database of audio to a small portion of the query song, to form a measure of the approximate similarity. We demonstrate the utility of our methods on a derivative works retrieval experiment using both exact and approximate (LSH) methods. The results show that LSH is at least an order of magnitude faster than the exact nearest neighbor method and that accuracy is not impacted by the approximate method.	(1+ε)-approximate nearest neighbor search;approximation algorithm;database;feature vector;rendezvous hashing;lsh	Michael A. Casey;Malcolm Slaney	2006			machine learning;artificial intelligence;locality-sensitive hashing;cover tree;fixed-radius near neighbors;ball tree;k-nearest neighbors algorithm;best bin first;computer science;nearest neighbor graph;nearest neighbor search	DB	-5.160870328329342	-41.64147563001183	23372
b135ff4f8575fcf199647ddaa8a1bdd1b8912676	a hybrid user and item-based collaborative filtering with smoothing on sparse data	information filters information filtering;information filtering;null;recommender system;collaborative filtering;data sparsity hybrid user collaborative filtering item based collaborative filtering recommender system technology aggregating rating information hybrid predictive algorithm with smoothing data smoothing predictive model;prediction accuracy;collaboration smoothing methods recommender systems information filtering information filters clustering algorithms prediction algorithms predictive models robustness accuracy;sparse data;prediction model;information filters	Collaborative filtering, the most successful recommender system technology to date, helps people make choices based on the opinions of other people. Existing collaborative filtering methods, mainly user-based and item-based methods, predict new ratings by aggregating rating information from either similar users or items. However, a large amount of ratings of similar items or similar users may be unavailable because of the sparse characteristic inherent to the rating data. For this reason, we present a Hybrid Predictive Algorithm with Smoothing (HSPA). HSPA uses item-based methods to provide the basis for data smoothing and builds the predictive model based on both users' aspects and items' aspects in order to ensure robust to data sparsity and predictive accuracy. Moreover, HSPA utilizes the user clusters to achieve high scalability. Experimental results from real datasets show that HSPA effectively contributes to the improvement of prediction on sparse data	algorithm;collaborative filtering;predictive modelling;recommender system;scalability;smoothing;sparse matrix	Rong Hu;Yansheng Lu	2006	16th International Conference on Artificial Reality and Telexistence--Workshops (ICAT'06)	10.1109/ICAT.2006.12	computer science;data science;collaborative filtering;information filtering system;machine learning;data mining;recommender system	AI	-20.98499674241469	-48.861591272886436	23382
b419eadbc0a1aea2c25d8827551c4ed9f378de52	building a generic debugger for information extraction pipelines	information extraction;text processing;large scale;provenance;operational transformation	Complex information extraction (IE) pipelines are becoming an integral component of most text processing frameworks. We introduce a first system to help IE users analyze extraction pipeline semantics and operator transformations interactively while debugging. This allows the effort to be proportional to the need, and to focus on the portions of the pipeline under the greatest suspicion. We present a generic debugger for running post-execution analysis of any IE pipeline consisting of arbitrary types of operators. For this, we propose an effective provenance model for IE pipelines which captures a variety of operator types, ranging from those for which full to no specifications are available. We have evaluated our proposed algorithms and provenance model on large-scale real-world extraction pipelines.	algorithm;debugger;debugging;information extraction;interactivity;pipeline (computing)	Anish Das Sarma;Alpa Jain;Philip Bohannon	2011		10.1145/2063576.2063933	natural language processing;computer science;theoretical computer science;data mining;database;world wide web;information extraction	SE	-32.01076702624697	-29.105509645858614	23438
779c59df396a00e01b65e28d0995593e97c313d3	e-commerce and web technologies		To save customers’ time and efforts in searching the goods in the Internet, a customized recommender system is required. It is very important for a recommender system to predict accurately by analyzing customer’s preferences. A recommender system utilizes in general an information filtering technique called collaborative filtering, which is based on the ratings of other customers who have similar preferences. Because a recommender system using collaborative filtering predicts customer’s preferences based only on the items without useful information on the attributes of each item, it may not give high quality recommendation consistently to the customers. In this paper we show that exploiting the attributes of each item improves prediction quality. We analyze the dataset and retrieve the preferences for the attributes because they have not been rated by customers explicitly. In the experiment the MovieLens dataset of the GroupLens Research Center has been used. The results on various experiments using several neighbor selection methods which are quite popular techniques for recommender systems show that the recommender systems using the attributes provide better prediction qualities than the systems without using the attribute information. Each of the systems using the attributes has improved the prediction quality more than 9%, compared with its counterpart. And the clustering-based recommender systems using the attributes can solve the very large-scale dataset problem without deteriorating prediction quality.	cluster analysis;collaborative filtering;display resolution;e-commerce payment system;experiment;grouplens research;information filtering system;internet;movielens;recommender system	Kurt Bauknecht Martin Bichler;Birgit Pröll	2004		10.1007/b100074		Web+IR	-21.231422832259508	-48.74961794476748	23509
9869d8b04bff9f07516d3c952f4aeab2ce4a8750	snaf: observation filtering and location inference for event monitoring on twitter	twitter;social sensor;message filtering;location inference;event detection	Twitter has recently emerged as a popular microblogging service that has 284 million monthly active users around the world. A part of the 500 million tweets posted on Twitter everyday are personal observations of immediate environment. If provided with time and location information, these observations can be seen as sensory readings for monitoring and localizing objects and events of interests. Location information on Twitter, however, is scarce, with less than 1% of tweets have associated GPS coordinates. Current researches on Twitter location inference mostly focus on city-level or coarser inference, and cannot provide accurate results for fine-grained locations. We propose an event monitoring system for Twitter that emphasizes local events, called SNAF (Sense and Focus). The system filters personal observations posted on Twitter and infers location of each report. Our extensive experiments with real Twitter data show that, the proposed observation filtering approach can have about 22% improvement over existing filtering techniques, and our location inference approach can increase the location accuracy by up to 36% within the 3km error range. By aggregating the observation reports with location information, our prototype event monitoring system can detect real world events, in many case earlier than news reports.	event monitoring;experiment;filter (signal processing);global positioning system;internationalization and localization;location inference;prototype	Yihong Zhang;Claudia Szabo;Quan Z. Sheng;Xiu Susie Fang	2017	World Wide Web	10.1007/s11280-017-0453-1	data mining;filter (signal processing);microblogging;computer science;event monitoring;social media;inference	ML	-23.894735019883818	-44.57112030430297	23531
2a841b09fa714f98505bf5adc725ec8724f5c339	state-of-the-art in group recommendation and new approaches for automatic identification of groups		Recommender systems are important tools that provide information items to users, by adapting to their characteristics and preferences. Usually items are recommended to individuals, but there are contexts in which people operate in groups. To support the recommendation process in social activities, group recommender systems were developed. Since different types of groups exist, group recommendation should adapt to them, managing heterogeneity of groups. This chapter will present a survey of the state-of-the-art in group recommendation, focusing on the type of group each system aims to. A new approach for group recommendation is also presented, able to adapt to technological constraints (e.g., bandwidth limitations), by automatically identifying groups of users with similar interests.		Ludovico Boratto;Salvatore Carta	2011		10.1007/978-3-642-16089-9_1	geography;knowledge management;data mining;world wide web	Web+IR	-27.046399616622036	-43.9667959991659	23619
2eccdc7fde80799bec2d2b33df092ec55382eed0	creating ai characters for fighting games using genetic programming	games learning artificial intelligence genetic programming adaptation models real time systems genetic algorithms;institutional repository research archive oaister;fighting games genetic programming ai character	This paper proposes a character generation approach for the M.U.G.E.N. fighting game that can create engaging AI characters using a computationally cheap process without the intervention of the expert developer. The approach uses a genetic programming algorithm that refines randomly generated character strategies into better ones using tournament selection. The generated AI characters were tested by 27 human players and were rated according to results, perceived difficulty and how engaging the gameplay was. The main advantages of this procedure are that no prior knowledge of how to code the strategies of the AI character is needed and there is no need to interact with the internal code of the game. In addition, the procedure is capable of creating a wide diversity of players with different strategic skills, which could be potentially used as a starting point to a further adaptive process.		Giovanna Mart&#x00ED;nez-Arellano;Richard J. Cant;David Woods	2017	IEEE Transactions on Computational Intelligence and AI in Games	10.1109/TCIAIG.2016.2642158	simulation;computer science;applications of artificial intelligence;machine learning;tournament selection;genetic algorithm;artificial intelligence;genetic programming	AI	-26.917579530881888	-25.38581350547288	23628
22d65fed387d26e1ec8bc9198ed5a277ec2ed5fe	improving context-aware music recommender systems: beyond the pre-filtering approach		Over the last years, music consumption has changed fundamentally: people switch from private, mostly limited music collections to huge public music collections provided by music streaming platforms. Thus, the amount of available music has increased dramatically and music streaming platforms heavily rely on recommender systems to assist users in discovering music they like. Incorporating the context of users has been shown to improve the quality of recommendations. Previous approaches based on pre-filtering suffered from a split dataset. In this work, we present a context-aware recommender system based on factorization machines that extracts information about the user's context from the names of the user's playlists. Based on a dataset comprising 15,000 users and 1.8 million tracks we show that our proposed approach outperforms the pre-filtering approach substantially in terms of accuracy of the computed recommendations.	baseline (configuration management);computation;fm broadcasting;naruto shippuden: clash of ninja revolution 3;recommender system;streaming media	Martin Pichl;Eva Zangerle;Günther Specht	2017		10.1145/3078971.3078980	user modeling;recommender system;personalization;computer science;filter (signal processing);multimedia	Web+IR	-20.400429257067156	-49.402159802054626	23705
1ff65a8897aa598b6045c41516df9eb2057650b8	a journey to the core of the blogosphere	a list blogs blogosphere world wide web structural analyses blogroll based networks core periphery structures;social network services;analytical models;a list blogs;blogosphere;blogroll based networks;random networks;data mining;sna;internet;cohesion;cohesion sna blogosphere cores;web sites internet;lead;blogs instruments reliability theory;web sites;world wide web;cores;genetic algorithms;core periphery structures;structural analyses;blogs;data models	Blogs are popular communication instruments in today's web and altogether, they form the so-called blogosphere. This blogosphere has repeatedly been subject to structural analyses, and one of the findings has been the discovery of the A-List phenomenon, a cohesive group of influential blogs in the center of the blogosphere, whose exact identification remained an open issue. We use four language-specific subsets of the blogosphere, for which we aggregated the blogroll-based networks. We adapt core theory to analyse and compare the cohesion in these four data-sets, and provide a new scalable method for the identification of core-periphery structures in blog networks, which can contribute to identify A-List blogs more reliably.	blog;blogosphere;centralisation;glossary of blogging;scalability	Darko Obradovic;Stephan Baumann	2009	2009 International Conference on Advances in Social Network Analysis and Mining	10.1109/ASONAM.2009.29	multi-core processor;data modeling;lead;the internet;genetic algorithm;computer science;cohesion;data mining;internet privacy;world wide web	SE	-20.108228761332303	-43.50472585482726	23715
d8f769f57d9966eb623ca6a688b3d839db46faf7	similarity join size estimation using locality sensitive hashing	locality sensitive hashing;random sampling;similarity join;indexation;data structure	Similarity joins are important operations with a broad range of applications. In this paper, we study the problem of vector similarity join size estimation (VSJ). It is a generalization of the previously studied set similarity join size estimation (SSJ) problem and can handle more interesting cases such as TF-IDF vectors. One of the key challenges in similarity join size estimation is that the join size can change dramatically depending on the input similarity threshold. We propose a sampling based algorithm that uses LocalitySensitive-Hashing (LSH). The proposed algorithm LSH-SS uses an LSH index to enable effective sampling even at high thresholds. We compare the proposed technique with random sampling and the state-of-the-art technique for SSJ (adapted to VSJ) and demonstrate LSH-SS offers more accurate estimates throughout the similarity threshold range and small variance using real-world data sets.	algorithm;hash function;locality of reference;locality-sensitive hashing;monte carlo method;sampling (signal processing);tf–idf;zobrist hashing;lsh	Hongrae Lee;Raymond T. Ng;Kyuseok Shim	2011	PVLDB	10.14778/1978665.1978666	sampling;data structure;computer science;pattern recognition;data mining;database;mathematics;programming language;locality-sensitive hashing	DB	-5.468835961167293	-40.85153664442428	23730
2b3d55f96864776af27448586038b4152ff94b76	anonymizing social graphs via uncertainty semantics	uncertain graph;maximizing variance;uncertain adjacency matrix	Rather than anonymizing social graphs by generalizing them to super nodes/edges or adding/removing nodes and edges to satisfy given privacy parameters, recent methods exploit the semantics of uncertain graphs to achieve privacy protection of participating entities and their relationships. These techniques anonymize a deterministic graph by converting it into an uncertain form. In this paper, we propose a general obfuscation model based on uncertain adjacency matrices that keep expected node degrees equal to those in the unanonymized graph. We analyze two recently proposed schemes and their fitting into the model. We also point out disadvantages in each method and present several elegant techniques to fill the gap between them. Finally, to support fair comparisons, we develop a new tradeoff quantifying framework by leveraging the concept of incorrectness. Experiments on large social graphs demonstrate the effectiveness of our schemes.	adjacency matrix;anonymous web browsing;correctness (computer science);entity;social graph	Hiep H. Nguyen;Abdessamad Imine;Michaël Rusinowitch	2015		10.1145/2714576.2714584	adjacency list;combinatorics;discrete mathematics;theoretical computer science;machine learning;data mining;mathematics	ML	-11.69580983472536	-43.73148249242613	23747
d2372936635bc501f9d1a2d73e7282b5856cc67c	on the complexity of query result diversification	diversity;database queries;counting problems;data complexity;combined complexity;relevance;result diversification;recommender systems	Query result diversification is a bi-criteria optimization problem for ranking query results. Given a database  D , a query  Q , and a positive integer  k , it is to find a set of  k  tuples from  Q ( D ) such that the tuples are as relevant as possible to the query, and at the same time, as diverse as possible to each other. Subsets of  Q ( D ) are ranked by an objective function defined in terms of relevance and diversity. Query result diversification has found a variety of applications in databases, information retrieval, and operations research.   This article investigates the complexity of result diversification for relational queries. (1) We identify three problems in connection with query result diversification, to determine whether there exists a set of  k  tuples that is ranked above a bound with respect to relevance and diversity, to assess the rank of a given  k -element set, and to count how many  k -element sets are ranked above a given bound based on an objective function. (2) We study these problems for a variety of query languages and for the three objective functions proposed in Gollapudi and Sharma [2009]. We establish the upper and lower bounds of these problems,  all matching , for both combined complexity and data complexity. (3) We also investigate several special settings of these problems, identifying tractable cases. Moreover, (4) we reinvestigate these problems in the presence of compatibility constraints commonly found in practice, and provide their complexity in all these settings.	diversification (finance)	Ting Deng;Wenfei Fan	2014	ACM Trans. Database Syst.	10.1145/2602136	sargable;query optimization;counting problem;web query classification;ranking;relevance;boolean conjunctive query;computer science;theoretical computer science;data mining;database;range query;recommender system	DB	-11.483808200225186	-36.78411685787541	23804
de56773aad909d8a063450fc16c25305afae52a3	exploration and assessment of event data	database application;data mining h 5 2 information interfaces and presentation;h 2 8 database management;user interfaces	Event data is generated in many domains, like business process management, industry or healthcare. These datasets are often unstructured, exhibit variant behaviour, and may contain errors. Before applying automated analysis methods, such as process mining algorithms, the analyst needs to understand the dependency between events in order to decide which analysis method might fit the recorded events. We define a categorization scheme of event dependencies and describe a preliminary approach for exploring event data, combining visual exploration with pattern mining. Events of interest can be selected, grouped, and visually explored, using either a sequential or a temporal scale. We present two use cases with shopping event data and report expert feedback on our approach.	algorithm;business process;categorization;data mining;eurographics;filter (signal processing);interaction;visual analytics	Peter Bodesinsky;Bilal Alsallakh;Theresia Gschwandtner;Silvia Miksch	2015		10.2312/eurova.20151106	computer science;data science;complex event processing;data mining;database	ML	-25.78321180174993	-33.97739622615739	23842
f20a99245eb0c1a6bbddc794bc4efea0dc6b6038	user exploration of search space using tradeoffs		We describe a system for representing search results as an interactive graph, in contrast to the common static representation as an ordered list. The search terms are represented as Key-Nodes, and the results are represented as connected Record-Nodes. The user can then explore tradeoffs by assigning different importance values to Key-Nodes. We suggest algorithms for placement of Record-Nodes in the graph to ensure both smooth change of the representation in response to changes in user preferences, and clustering of results. The work was implemented using Haskell and a client-side Web interface.		Zachi Baharav;David S. Gladstein	2015		10.1007/978-3-319-21383-5_107	human–computer interaction;computer science;graph (abstract data type);theoretical computer science;haskell;cluster analysis;user interface;graph	SE	-30.573106948929357	-34.63959354805375	23858
57c18d115750541f115911fce6893500ade1c46e	annotation graphs: a graph-based visualization for meta-analysis of data based on user-authored annotations	manuals;graph based visualization externalization user authored annotation exploratory sequential data analysis;human computer interaction;externalization user authored annotation;user authored annotation;semantics;externalization;layout;exploratory sequential data analysis;data analysis;visualization;data visualization semantics layout visualization human computer interaction data analysis manuals;data visualization;graph based visualization	User-authored annotations of data can support analysts in the activity of hypothesis generation and sensemaking, where it is not only critical to document key observations, but also to communicate insights between analysts. We present annotation graphs, a dynamic graph visualization that enables meta-analysis of data based on user-authored annotations. The annotation graph topology encodes annotation semantics, which describe the content of and relations between data selections, comments, and tags. We present a mixed-initiative approach to graph layout that integrates an analyst's manual manipulations with an automatic method based on similarity inferred from the annotation semantics. Various visual graph layout styles reveal different perspectives on the annotation semantics. Annotation graphs are implemented within C8, a system that supports authoring annotations during exploratory analysis of a dataset. We apply principles of Exploratory Sequential Data Analysis (ESDA) in designing C8, and further link these to an existing task typology in the visualization literature. We develop and evaluate the system through an iterative user-centered design process with three experts, situated in the domain of analyzing HCI experiment data. The results suggest that annotation graphs are effective as a method of visually extending user-authored annotations to data meta-analysis for discovery and organization of ideas.	anatomy, regional;annotation;biological anthropology;exploratory testing;graph - visual representation;graph drawing;human–computer interaction;imagery;inference;iteration;sensemaking;silo (dataset);situated;topological graph theory;user-centered design	Jian Zhao;Michael Glueck;Simon Breslav;Fanny Chevalier;Azam Khan	2017	IEEE Transactions on Visualization and Computer Graphics	10.1109/TVCG.2016.2598543	layout;information visualization;visualization;computer science;data mining;semantics;data analysis;world wide web;information retrieval;data visualization;statistics	Visualization	-28.538045042834064	-34.065562904438764	23878
ebed0e9eb604fcf11f6ffc993500ffcc2e12f792	a linear time algorithm for influence maximization in large-scale social networks		Influence maximization is the problem of finding k seed nodes in a given network as information sources so that the influence cascade can be maximized. To solve this problem both efficiently and effectively, in this paper we propose LAIM: a linear time algorithm for influence maximization in large-scale social networks. Our LAIM algorithm consists of two parts: (1) influence computation; and (2) seed nodes selection. The first part approximates the influence of any node using its local influence, which can be efficiently computed with an iterative algorithm. The second part selects seed nodes in a greedy manner based on the results of the first part. We theoretically prove that the time and space complexities of our algorithm are proportional to the network size. Experimental results on six real-world datasets show that our approach significantly outperforms other state-of-the-art algorithms in terms of influence spread, running time and memory usage.	expectation–maximization algorithm;social network;time complexity	Hongchun Wu;Jiaxing Shang;Shangbo Zhou;Yong Feng	2017		10.1007/978-3-319-70139-4_76	spacetime;machine learning;time complexity;iterative method;artificial intelligence;computation;computational complexity theory;computer science;maximization;social network;algorithm;mathematical optimization;entropy maximization	ECom	-16.451487744142305	-43.62406956587847	23934
b90a90873fe0174c11907e797245a52baee23e9e	integer programming based crowd behavior analysis for world expo	content management;crowd behavior analysis;video surveillance;rivers;behavioural sciences computing;trajectory identification ti;integer programming ip;content management integer programming ip crowd behavior analysis trajectory identification ti;trajectory;vectors;integer programming;integer programming based trajectory identification algorithm;cognition;linear programming;tourist visiting pattern;ip networks;pattern analysis;integer programming based crowd behavior analysis;algorithm design and analysis;world expo data;object detection;video surveillance behavioural sciences computing cognition integer programming object detection;tourist visiting pattern integer programming based crowd behavior analysis world expo data trajectory estimation integer programming based trajectory identification algorithm;trajectory estimation;trajectory linear programming algorithm design and analysis ip networks pattern analysis rivers vectors	With the large-scale activities increasing gradually, crowd behavior analysis becomes more and more popular and important. Trajectory identification and estimation are key techniques in crowd behavior analysis. This paper develops an integer programming based trajectory identification algorithm. Shanghai World Expo 2010 is a typical example of large-scale activities and the proposed algorithm is implemented on World Expo data. The experimental results show that the tourists' visiting patterns are different in different days due to various attractive strategies of the Expo site; and the tourists' visiting patterns of different time periods in the same day are different as well.	adversary (cryptography);algorithm;integer programming;piaget's theory of cognitive development;routing	Yuting Hu;Rong Xie;Wenjun Zhang	2013	2013 IEEE International Symposium on Broadband Multimedia Systems and Broadcasting (BMSB)	10.1109/BMSB.2013.6621789	simulation;computer science;artificial intelligence;multimedia	Embedded	-18.37188582267858	-35.78440918595192	23941
7c1d33da52804b3ee975d0a10e6ee0c3146cdc8e	investigating aesthetic measures for unsupervised evolutionary art	evolutionary art;multi objective optimisation;evolutionary computation;genetic programming;computational aesthetics	We present an extensive study into aesthetic measures in unsupervised evolutionary art (EvoArt). In contrast to several mainstream EvoArt approaches we evolve images without human interaction, using one or more aesthetic measures as fitness functions. We perform a series of systematic experiments, comparing 7 di↵erent aesthetic measures through subjective criteria (‘style’) as well as by quantitative measures reflecting properties of the evolved images. Next, we investigate the correlation between aesthetic scores by aesthetic measures and calculate how aesthetic measures judge each others images. Furthermore, we run experiments in which two aesthetic measures are acting simultaneously using a Multi-Objective Evolutionary Algorithm. Hereby we gain insights in the joint e↵ects on the resulting images and the compatibility of di↵erent aesthetic measures.	evolutionary algorithm;evolutionary art;experiment;fitness function;unsupervised learning	Eelco den Heijer;A. E. Eiben	2014	Swarm and Evolutionary Computation	10.1016/j.swevo.2014.01.002	aesthetics;artificial intelligence;machine learning;mathematics	Web+IR	-27.837970207419293	-26.105967559676813	23942
4c7c60c52056dc7dfedf2da6963afd47399070fd	automated detection of influential patents using singular values	citation analysis;singular value decomposition;singular value decomposition citation analysis patents security of data;u s patents data automated detection influential patents centrality measures degree centrality citation network node similarity matrix singular value update technique;patents;patents matrix decomposition singular value decomposition approximation methods;security of data;social network acyclic directed networks centrality citation network singular value decomposition	Centrality measures such as degree centrality have been utilized to identify influential and important patents in a citation network. However, no existing centrality measures take into consideration information from the change of the similarity matrix. This paper presents a new centrality measure based on the change of a node similarity matrix. The proposed approach gives more intuitive understanding of the finding of the influential nodes. The present study starts off with the assumption that the change of matrix that may result from removing a given node would assess the importance of the node since each node make a contribution to the given similarity matrix between nodes. The various matrix norms using the singular values such as nuclear norm which is the sum of all singular values, are used for calculating the contribution of a given node to a node similarity matrix. In other words, we can obtain the change of matrix norms for a given node after we calculate the singular values for the case of the nonexistence and the case of existence of the node. Then, the node resulting in the largest change (i.e., decrease) of matrix norms can be considered as the most important node. Computation of singular values can be computationally intensive when the similarity matrix size is large. Therefore, the singular value update technique is also developed for the case of the network with large nodes. We compare the performance of our proposed approach with other widely used centrality measures using U.S. patents data in the area of information and security. Experimental results show that our proposed approach is competitive or even performs better compared to existing approaches.	adjacency matrix;centrality;citation network;computation;scalable video coding;sensor;similarity measure;singular value decomposition;social network;the matrix	Dohyun Kim;Bangrae Lee;Hyuck Jai Lee;Sang Pil Lee;Yeongho Moon;Myong Kee Jeong	2012	IEEE Transactions on Automation Science and Engineering	10.1109/TASE.2012.2210214	mathematical optimization;combinatorics;discrete mathematics;computer science;katz centrality;alpha centrality;data mining;mathematics;centrality;singular value decomposition;betweenness centrality;citation analysis;statistics	AI	-13.719994443277253	-41.473677245761	24070
6b90f8fb51736423d3d48cf34f0869bfefc845f0	hierarchical temporal patterns and interactive aggregated views for pixel-based visualizations	hierarchical temporal patterns;image resolution;image resolution data visualisation image colour analysis;interactive visualization;granular overview overlay;data mining;calendars;process design;data visualization data analysis personnel medical services pattern analysis visual analytics calendars process design web page design knowledge engineering;data visualisation;data analysis;visualization;medical services;interactive aggregated views;granular overview overlay hierarchical temporal patterns interactive aggregated views pixel based visualizations time oriented data users visual analysis processes groove;personnel;image color analysis;image colour analysis;pixel based visualizations;pixel;business;web page design;users visual analysis processes;temporal pattern;visual analysis;data visualization;groove time oriented data structures of time granularities pixel based visualizations;groove;granularities;pattern analysis;time oriented data;visual analytics;structures of time;switches;knowledge engineering	Many real-world problems involve time-oriented data. Time data is different from other kinds of data--explicitly harnessing the structures of time in visualizations can guide and support users’ visual analysis processes. State-of-the-art visualizations hardly take advantage of the structures of time to aid users in understanding and exploring the data. To bring more flexibility to the analysis process, we have developed interactive visual methods incorporating the structures of time within a pixel-based visualization called GROOVE (granular overview overlay). GROOVE uses different techniques to visualize time-oriented data by overlaying several time granularities in one visualization and provides interactive operators, which utilize the structures of time in different ways to capture and explore time-oriented data.	pixel	Tim Lammarsch;Wolfgang Aigner;Alessio Bertone;Johannes Gärtner;Eva Mayr;Silvia Miksch;Michael Smuc	2009	2009 13th International Conference Information Visualisation	10.1109/IV.2009.52	computer science;data mining;multimedia;world wide web	Visualization	-28.465530662636127	-31.65730819551078	24134
6790d0a3f90de2c28d05e6582d0796d8bd860eaf	community detection in social networks using hybrid merging of sub-communities	bottom up merging;social networks;network communities	Network vertices are often divided into groups or communities with dense connections within communities and sparse connections between communities. Community detection has recently attracted considerable attention in the field of data mining and social network analysis. Existing community detection methods require too much space and are very time consuming for moderate-to-large networks. We propose a bottom up community detection method in which starting with fine-grained communities we find real communities of a network. Merging preliminary small communities is done in a hybrid way to maximize two quality functions: modularity and NMI. We show that our way of community detection is better or as effective as the other community detection algorithms while it has better time and space complexity. & 2013 Elsevier Ltd. All rights reserved.	benchmark (computing);dspace;data mining;expectation–maximization algorithm;non-maskable interrupt;similarity measure;social network analysis;sparse matrix;time complexity;top-down and bottom-up design;vertex (graph theory)	Mohsen Arab;Mohsen Afsharchi	2014	J. Network and Computer Applications	10.1016/j.jnca.2013.08.008	machine learning;data mining;social network	AI	-14.05276712720997	-42.90037212476966	24174
cdc68bd1d9650ca93fa82fc62a573f5a736d70be	operator-centric design patterns for information visualization software	software;0705k;linked data;0130c;software systems;information visualization;multiple views;data analysis;visualization;visualisation;visualization technique;design pattern;data transformation;analyse donnee;multivariate visualization;interaction technique	Design patterns have proven to be a useful means to make the pr oc ss of designing, developing, and reusing software systems more efficient. In the area of information visualiza tion, researchers have proposed design patterns for differ ent functional components of the visualization pipeline. Sinc e many visualization techniques need to display derived dat a as well as raw data, the data transformation stage is very impor tant in the pipeline, yet existing design patterns are, in ge neral, not sufficient to implement these data transformation techn iques. In this paper, we propose two design patterns, operat orcentric transformation and data modifier, to facilitate the design of data transformations for information visualizat ion systems. The key idea is to use operators to describe the data deriv tion and introduce data modifiers to represent the derived data. We also show that many interaction techniques can be regarded as operators as defined here, thus these two design patterns could support a wide range of visualization techniques. In addition, we describe a third design pattern , modifier-based visual mapping, that can generate visual abs traction via linking data modifiers to visual attributes. We also present a framework based on these three design patterns tha t supports coordinated multiple views. Several examples of multivariate visualizations are discussed to show that our design patterns and framework can improve the reusability a nd extensibility of information visualization systems. Fina lly, we explain how we have ported an existing visualization t ol (XmdvTool) from its old data-centric structure to a new stru c ure based on the above design patterns and framework.	extensibility;information visualization;interaction technique;modifier key;sinc function;software design pattern;software system;traction teampage;visualization software	Zaixian Xie;Zhenyu Guo;Matthew O. Ward;Elke A. Rundensteiner	2010		10.1117/12.838451	software visualization;software design pattern;information visualization;visualization;behavioral pattern;computer science;data science;theoretical computer science;data mining;structural pattern	Visualization	-29.88599737832962	-31.09870595945257	24182
2998f7260564ccb218838081576b11c762172cb8	provenance filtering for multimedia phylogeny		Departing from traditional digital forensics modeling, which seeks to analyze single objects in isolation, multimedia phylogeny analyzes the evolutionary processes that influence digital objects and collections over time. One of its integral pieces is provenance filtering, which consists of searching a potentially large pool of objects for the most related ones with respect to a given query, in terms of possible ancestors (donors or contributors) and descendants. In this paper, we propose a two-tiered provenance filtering approach to find all the potential images that might have contributed to the creation process of a given query q. In our solution, the first (coarse) tier aims to find the most likely “host” images — the major donor or background — contributing to a composite/doctored image. The search is then refined in the second tier, in which we search for more specific (potentially small) parts of the query that might have been extracted from other images and spliced into the query image. Experimental results with a dataset containing more than a million images show that the two-tiered solution underpinned by the context of the query is highly useful for solving this difficult task.	multitier architecture;phylogenetics	Allan da Silva Pinto;Daniel M Moreira;Aparna Bharati;Joel Brogan;Kevin W. Bowyer;Patrick J. Flynn;Walter J. Scheirer;Anderson Rocha	2017	2017 IEEE International Conference on Image Processing (ICIP)	10.1109/ICIP.2017.8296532	task analysis;information retrieval;filter (signal processing);phylogenetics;web query classification;data mining;robustness (computer science);computer science;search engine indexing;multimedia;digital forensics;query optimization	Visualization	-12.661535451153275	-51.17280256502542	24214
26ba44567cc731525a0c91ba4bbac9b77200d5dc	sparse linear method based top-n course recommendation system with expert knowledge and l 0 regularization		In this paper, we propose an approach of course recommender system for the subject of information management speciality in China. We collect the data relative to the course enrollment for specific set of students. The sparse linear method (SLIM) is introduced in our approach to generate the top-N recommendations of courses for students. Furthermore, the L 0 regularization terms were presented in our proposed optimization method based on the observation of the entries in recommendation system matrix. Expert knowledge based comparing experiments between state-of-the-art methods and our method are conducted to evaluate the performance of our method. Experimental results show that our proposed method outperforms state-of-the-art methods both in accuracy and efficiency.	matrix regularization;recommender system;sparse	Jinjiao Lin;Haitao Pu;Yibin Li;Jian Lian	2017		10.1007/978-3-319-74521-3_15	information management;recommender system;machine learning;matrix (mathematics);regularization (mathematics);computer science;artificial intelligence	AI	-19.887629707530923	-48.07391546604218	24232
f0f86ae269b552d74882136f98b84a56233c0fe5	ecological monitoring and object-oriented simulation studies on stability and alternative stable states of coral reef communities			simulation	Tze Wai Tam	2006				DB	-11.457758564443917	-26.842175197945163	24270
d6194637109485c19e47cce408cdcb52f90cb29a	mining distinguishing customer focus sets from online customer reviews	distinguishing customer focus;decision support;data mining;68u35	With the development of e-commerce, online shopping becomes increasingly popular. Very often, online shopping customers read reviews written by other customers to compare similar items. However, the number of customer reviews is typically too large to look through in a reasonable amount of time. To extract information that can be used for online shopping decision support, this paper investigates a novel data mining problem of mining distinguishing customer focus sets from customer reviews. We demonstrate that this problem has many applications, and at the same time, is challenging. We present dFocus-Miner, a mining method with various techniques that makes the mined results interpretable and user-friendly. Moreover, we propose a visualization design to display the results of dFocus-Miner. Our experimental results on real world data sets verify the effectiveness and efficiency of our method.	algorithm;cluster analysis;data mining;decision support system;distributed computing;e-commerce;experiment;mined;online shopping;usability	Lei Duan;Lu Liu;Guozhu Dong;Jyrki Nummenmaa;Tingting Wang;Pan Qin;Hao Yang	2018	Computing	10.1007/s00607-018-0601-1	mathematical optimization;mathematics;decision support system;data mining;visualization;data set	ML	-21.155648854128035	-51.049847910178535	24437
d26c5e043f47fdc6cce833d1798e27f4f796f6ec	combining ratings and item descriptions in recommendation systems using fuzzy fingerprints		Memory-based Collaborative filtering solutions are dominant in the Recommendation Systems domain, due to their low implementation effort and service maintenance, when compared to Model-based approaches. Memory-based systems often rely on similarity metrics to compute similarities between items (or users) using ratings, in what is often named neighbor-based Collaborative filtering. This paper applies Fuzzy Fingerprints to create a novel similarity metric. In it, the Fuzzy Fingerprint of each item is described with a ranking of users ratings, combined with words obtained from the items' description. This allows the presented similarity metric to use fewer neighbors than other well-known metrics such as Cosine similarity or Pearson Correlation. Our proposal is able to reduce RMSE by at least 0.030 and improve NDCG@10 by at least 0.017 when compared with the best baseline here presented.	baseline (configuration management);collaborative filtering;cosine similarity;experiment;fingerprint;recommender system;social network;video synopsis	André Luiz da Costa Carvalho;Pável Calado;João Paulo Carvalho	2017	2017 IEEE International Conference on Fuzzy Systems (FUZZ-IEEE)	10.1109/FUZZ-IEEE.2017.8015604	collaborative filtering;recommender system;artificial intelligence;machine learning;fuzzy logic;pearson product-moment correlation coefficient;cosine similarity;information retrieval;computer science;ranking;mean squared error	Robotics	-21.077161391863076	-48.6455315643755	24555
8817646b26e981fa007af1967a794594acd3d825	st-hasset for volcanic hazard assessment: a python tool for evaluating the evolution of unrest indicators	short term volcanic hazard assessment;articulo;monitoring data;python;hasset;unrest	Short-term hazard assessment is an important part of the volcanic management cycle, above all at the onset of an episode of volcanic agitation (unrest). For this reason, one of the main tasks of modern volcanology is to use monitoring data to identify and analyse precursory signals and so determine where and when an eruption might occur. This work follows from Sobradelo and Marti Short-term volcanic hazard assessment through Bayesian inference: retrospective application to the Pinatubo 1991 volcanic crisis. Journal of Volcanology and Geothermal Research 290, 111, 2015 who defined the principle for a new methodology for conducting short-term hazard assessment in unrest volcanoes. Using the same case study, the eruption on Pinatubo (15 June 1991), this work introduces a new free Python tool, ST-HASSET, for implementing Sobradelo and Marti (2015) methodology in the time evolution of unrest indicators in the volcanic short-term hazard assessment. Moreover, this tool is designed for complementing long-term hazard assessment with continuous monitoring data when the volcano goes into unrest. It is based on Bayesian inference and transforms different pre-eruptive monitoring parameters into a common probabilistic scale for comparison among unrest episodes from the same volcano or from similar ones. This allows identifying common pre-eruptive behaviours and patterns. ST-HASSET is especially designed to assist experts and decision makers as a crisis unfolds, and allows detecting sudden changes in the activity of a volcano. Therefore, it makes an important contribution to the analysis and interpretation of relevant data for understanding the evolution of volcanic unrest. A new tool for transforming precursory information on volcano monitoring/unrest into a common probabilistic scale.Short-term hazard assessment tool to identify pre-eruptive behaviours and patterns of volcanoes.The short-term analysis in the context of the volcanic management cycle.ST-HASSET tool allows detecting sudden changes during a volcanic unrest episode.	python;unrest	Stefania Bartolini;Rosa Sobradelo;Joan Martí	2016	Computers & Geosciences	10.1016/j.cageo.2016.05.002	meteorology;seismology;python;computer science;programming language	NLP	-13.131194117832392	-26.89084653814232	24665
7b9eb4c47d6fe4501d4abe3ebc98b1a539313d44	community-based scholar recommendation modeling in academic social network sites		Academic social network sites (ASNSs) have experienced rapid growth in recent years. Large amounts of users hope to make friends with other users for potential academic collaborations in ASNSs. Though there are many scholar recommendation systems, they mainly consider the content similarity of users’ profiles. In fact, the communities of ASNSs can offer rich networking information to make recommendations. In this paper, we propose a community-based scholar recommendation model in ASNSs. We firstly construct research-fields-based graphs, detect communities in the graphs by Louvain method and then make scholar recommendation by calculating friendship scores. We also implement the model on a real world dataset from an academic social network site called SCHOLAT. And the experimental results demonstrate that our approach improves the recommendations of core network members and outperforms the content-based user recommendation method.	social network	Jiemin Chen;Yong Tang;Jianguo Li;Chengjie Mao;Jing Xiao	2013		10.1007/978-3-642-54370-8_28	knowledge management;data science	ECom	-23.040639712848215	-48.02883782142854	24705
b8cea5fe03191383bfa423151303f970af0a00bc	data filtering utilizing window indexing	database indexing;filtering;optimisation;query processing;approximation algorithms;database management systems;nested loops;information filtering;multi objective optimization;partitioning;block nested loop algorithm;iterated window indexing;data filtering;skyline;skyline query;iterative methods;hybrid method;vectors;indexing;indexation;partitioning and filtering method;indexing computer science database systems mathematics partitioning algorithms application software conferences information filtering information filters algorithm design and analysis;vectors database indexing information filtering iterative methods optimisation query processing;block nested loop algorithm data filtering skyline query database management systems maximum vector problem multiobjective optimization partitioning and filtering method iterated window indexing;multiobjective optimization;vector filtering indexing partitioning skyline spatial;vector;maximum vector problem;computational efficiency;bnl;database management system;algorithm design and analysis;data models;partitioning algorithms;spatial	Since its introduction in 2001, the Skyline Query has been a useful addition to database management systems (DBMS) by returning best-fit results to a user. The skyline query is also a relevant area of research in mathematics as the maximum vector problem and multi-objective optimization. In this paper, we analyze both the Partitioning and Filtering (P&F) method and a new proposed method called Iterated Window Indexing. Next, we also propose two new methods, comprising combinations of previous solutions and Window Indexing. We then show that our hybrid methods are suitable for many cases and perform up to 10 times better than P&F and up to 8 times better than the Block Nested Loop (BNL) algorithm for computing skyline points.	algorithm;anti-aliasing filter;block nested loop;curve fitting;database;iterated function;mathematical optimization;maxima and minima;multi-objective optimization;overhead (computing);pareto efficiency;query optimization;window function	Scott Loper;S. Kami Makki	2010	2010 IEEE 24th International Conference on Advanced Information Networking and Applications Workshops	10.1109/WAINA.2010.59	computer science;theoretical computer science;multi-objective optimization;data mining;database;approximation algorithm	DB	-5.160835561067295	-40.38520071884005	24713
53efaaba9fb1ce67ef62d519e2223ddffb31ad21	river information services	information service	River Information Services (RIS) represent the most substantial modernization of river infrastructure aiming at information services to support planning andmanaging of traffic and transportation operations onwaterways. The RIS concept is based on tracking and tracing of the vessel positioning and the monitoring of relevant vessel data. The innovative concept and the ongoing implementation are presented in this paper.	track and trace	Johannes Vallant;Bernhard Hofmann-Wellenhof	2008	Elektrotechnik und Informationstechnik	10.1007/s00502-008-0539-7	computer science;data mining	Robotics	-17.800872444886874	-28.448371421269577	24731
294f9a7d798b2310344ca2b13a346a7313e67e1d	twende-twende: a mobile application for traffic congestion awareness and routing	frugal innovation;traffic congestion;mobile application;land marking	According to the UN-HABITAT, the city of Nairobi loses half a million USD daily due to congestion on roads designed for a city 10 times smaller. Therefore, there is a great need for traffic management and awareness solutions. Many existing solutions are unsuitable for cities like Nairobi due to economic constraints, dynamic events, uncertainty, and poor infrastructure.   Recently, a novel approach called Frugal Innovation has been adopted at IBM Tokyo Research. The approach combines very low quality images (VLQI) captured by existing low-cost cameras with network flow algorithms to accurately estimate traffic flow. We extend their work to develop a mobile app, called Twende-Twende, that provides drivers with real-time traffic information and suggested routes. We incorporate locally relevant context (such as references to landmarks) to predict congestion and create traffic awareness. We deployed the app and evaluated its effectiveness, accuracy and usability. Our initial evaluation indicates that the app enhances the driving experience and can be deployed in other developing countries.	algorithm;flow network;landmark point;mobile app;network congestion;real-time transcription;routing;usability	Andrew Kinai;Reginald E. Bryant;Aisha Walcott-Bryant;Eric Mibuari;Komminist Weldemariam;Osamuyimen Stewart	2014		10.1145/2593902.2593926	simulation;engineering;transport engineering;computer security	Mobile	-18.508744771293212	-29.064777689077502	24785
c29ff1445cc26cdef97d16b253653f1d8cd747a4	automatic vehicle location and monitoring system based on data distribution service	automatic vehicle location;pedestrian safety;poison control;injury prevention;wireless lans;bluetooth technology;safety literature;traffic safety;injury control;home safety;injury research;safety abstracts;human factors;saudi arabia;monitoring;occupational safety;safety;safety research;middleware;accident prevention;violence prevention;bicycle safety;poisoning prevention;falls;ergonomics;suicide prevention;local area networks	This paper proposes a real time Automatic Vehicle Location (AVL) and Monitoring system for pilgrims road transport coming towards city of Makkah in Saudi Arabia based on Data Distribution Service (DDS). This service is a real time publish/subscribe middleware. Using this middleware approach, we are able to locate and track a huge number of mobile vehicles and identify pilgrims for an annual Islamic gathering in the Holy City of Makkah. Performance results are demonstrated for LAN, WLAN and Bluetooth over DDS. © 2014 The Authors. Published by Elsevier B.V. Peer-review under responsibility of the Program Chairs of EUSPN-2014.	avl tree;automatic vehicle location;bluetooth;data distribution service;middleware;publish–subscribe pattern	Basem Almadani;Shehryar Khan;Tarek R. Sheltami;Elhadi M. Shakshuki;Muhammad Musaddiq;Bilal Saeed	2014		10.1016/j.procs.2014.08.021	local area network;computer science;suicide prevention;human factors and ergonomics;injury prevention;automatic vehicle location;operating system;middleware;computer security	Embedded	-20.20973616658646	-28.96774978388757	24789
0a14b970373c8c8b239d3a8be4219fe7c3d8cd73	predicting the popularity of news based on competitive matrix		With the rapid development of network, more and more people share and comment on the web to express their mends. How to predict the popularity of topic happening recently is a hot topic and lots of people are trying to find out the law of information diffusion hidden in it. However, many models assume that information spreads with no external interference in social networks. The research on competitive diffusion is still at the primary stage. The main contribution is to solve the problem that there are few or no work for popularity prediction based on multi-information, and propose a predicting model based on competitive matrix. The goal of this paper is to accurately estimate the popularity for a given viral topic at final based on the observation of historical popularity of the topic. And this model is mainly based on the competitive matrix and gradient descent method. Also, the capability of this method provides a better performance in the popularity prediction according to an empirical study on Tencent News.	algorithm;gradient descent;interference (communication);social network;tencent qq;total correlation	Xiaomeng Wang;Binxing Fang;Hongli Zhang;XuanYu	2017	2017 IEEE Second International Conference on Data Science in Cyberspace (DSC)	10.1109/DSC.2017.88	empirical research;popularity;data mining;social network;matrix (mathematics);machine learning;artificial intelligence;computer science	DB	-18.954609185031927	-45.94445111114083	24807
864d8752f8b6f0797eab33bec1406ad9b8566630	sampling and meshing surfaces with guarantees. (échantillonnage et maillage de surfaces avec garanties)				Steve Oudot	2005				Robotics	-8.970807741476689	-28.02745259760906	24843
54f5b0d2d17a140d365d56a5e8c636858c4bb726	rapare: a generic strategy for cold-start rating prediction problem	recommender systems collaboration interviews optimization algorithm design and analysis calibration electronic mail;electronic mail;rating comparison strategy recommender systems cold start problem;collaboration;recommender systems cold start problem rating comparison strategy;interviews;optimization;calibration;recommender systems;algorithm design and analysis	In recent years, recommender system is one of indispensable components in many e-commerce websites. One of the major challenges that largely remains open is the cold-start problem, which can be viewed as a barrier that keeps the cold-start users/items away from the existing ones. In this paper, we aim to break through this barrier for cold-start users/items by the assistance of existing ones. In particular, inspired by the classic Elo Rating System, which has been widely adopted in chess tournaments, we propose a novel rating comparison strategy (RaPare ) to learn the latent profiles of cold-start users/items. The centerpiece of our RaPare is to provide a fine-grained calibration on the latent profiles of cold-start users/items by exploring the differences between cold-start and existing users/items. As a generic strategy, our proposed strategy can be instantiated into existing methods in recommender systems. To reveal the capability of RaPare strategy, we instantiate our strategy on two prevalent methods in recommender systems, i.e., the matrix factorization based and neighborhood based collaborative filtering. Experimental evaluations on five real data sets validate the superiority of our approach over the existing methods in cold-start scenario.	cold start;collaborative filtering;e-commerce;recommender system;the matrix	Jingwei Xu;Yuan Yao;Hanghang Tong;Xianping Tao;Jian Lu	2017	IEEE Transactions on Knowledge and Data Engineering	10.1109/TKDE.2016.2615039	algorithm design;calibration;simulation;interview;computer science;data mining;database;world wide web;recommender system;collaboration	AI	-20.588503860187444	-47.3550520931225	24933
53fc0c36e524196a0da66e0f57f48b9a4174ea31	robust tracking and behavioral modeling of movements of biological collectives from ordinary video recordings		We propose a novel computational method to extract information about interactions among individuals with different behavioral states in a biological collective from ordinary video recordings. Assuming that individuals are acting as finite state machines, our method first detects discrete behavioral states of those individuals and then constructs a model of their state transitions, taking into account the positions and states of other individuals in the vicinity. We have tested the proposed method through applications to two real-world biological collectives: termites in an experimental setting and human pedestrians in a university campus. For each application, a robust tracking system was developed in-house, utilizing interactive human intervention (for termite tracking) or online agent-based simulation (for pedestrian tracking). In both cases, significant interactions were detected between nearby individuals with different states, demonstrating the effectiveness of the proposed method.	agent-based model;behavioral modeling;finite-state machine;interaction;simulation;tracking system	Hiroki Sayama;Farnaz Zamani Esfahlani;Ali Jazayeri;J. Scott Turner	2017	2017 IEEE Symposium Series on Computational Intelligence (SSCI)	10.1109/SSCI.2017.8285238	computer science;simulation;finite-state machine;behavioral modeling;tracking system;pedestrian	Graphics	-27.261321995168927	-40.31873577074904	24945
8d4420a1895a9583c8dbcaacfb7fb9d06941db52	computationally evaluating and reproducing the beauty of chinese calligraphy	natural language processing computer vision;computers;intelligent cad intelligent system for art chinese calligraphy esthetic computing;feedback mechanism;design automation;general and miscellaneous mathematics computing and information science;handwriting recognition;training;intelligent cad;automatic generation;computer vision;aesthetics;feedback;feedback mechanism chinese calligraphy beauty chinese characters;intelligent system;chinese calligraphy;intelligent system for art;esthetic computing;training feedback handwriting recognition writing graphics art design automation;article;natural language processing	Training a computer to evaluate the aesthetics of Chinese characters provides a feedback mechanism to improve the quality of automatically generated calligraphy.	feedback	Songhua Xu;Hao Jiang;Francis C. M. Lau;Yunhe Pan	2012	IEEE Intelligent Systems	10.1109/MIS.2012.46	computer science;artificial intelligence;feedback;multimedia;handwriting recognition	Embedded	-32.64906584513295	-44.56760176186775	25026
5ee42833218f309e8f90138735f6ca60f55d2ff9	reconceptualizing imitation in social tagging: a reflective search model of human web interaction	organism environment dynamics;semantic stabilization;search of human memory;social tagging	We analyze psychological dynamics of human-Web interaction exemplified by social tagging. Whereas previous models assumed tagging was driven by individual knowledge and social imitation, we introduce a reflective search framework that assumes user behavior (e.g., exploration and tagging of web resources) to arise from an iterative search of human memory shaped continuously by past and present learning episodes. We formalize this framework by means of a mathematical model of search of human memory which interrelates episodic and semantic memory processes. This allows us to simulate both temporal macro dynamics (stabilization of tag distribution) and underlying temporal micro dynamics (reflecting and tagging a resource). While the former are well covered by previous models, these models are not able to explain the latter. We claim that shifting away from imitation to reflective search holds great potential for understanding and designing human web interaction more generally, and to validate models of human memory in large-scale web environments.	folksonomy;iterative method;mathematical model;simulation;web resource	Paul Seitlinger;Tobias Ley	2016		10.1145/2908131.2908157	psychology;artificial intelligence;communication;social psychology	AI	-29.566627794528706	-44.10017309557769	25046
109fb38461edd54c560a1d1c0099acda215c92bc	probabilistic modelling of the impact on bus punctuality of a speed limit proposal in edinburgh (extended version)		We propose a data-driven methodology for evaluating the impact of the introduction of a speed limit on the punctuality of bus services. In particular, we use high-frequency Automatic Vehicle Location data to parameterise a model that represents the movement of a bus along predefined patches of the route. We fit the probability distributions of the time spent in each patch to two classes of probability distributions: hyper-Erlang distributions, for which we use the tool HyperStar, and a variation of the three-parameter gamma distributions recommended by the Traffic Engineering Handbook. In both cases we obtain models that can be expressed using the framework of Probabilistic Timed Automata, allowing us to evaluate bus punctuality using the model checking tool UPPAAL. We conduct a case study involving a proposed speed limit in Edinburgh. This is an extended version of a paper presented at ValueTools 2015 [15].	algorithm;align (company);approximation;automatic vehicle location;bundle adjustment;cluster analysis;erlang (programming language);experiment;handbook;k-means clustering;model checking;patch (computing);schedule;simulation;statistical model;timed automaton;uppaal	Daniël Reijsbergen;Rajeev Ratan	2015	CoRR		simulation;computer science;operations management;computer security	AI	-9.92066927791521	-25.36041029754834	25073
68163af467ba157184b776b745f59cfcdc2f0255	semantic trajectory compression: representing urban movement in a nutshell	transportation network;data compression;trajectories;navigation;semantic description;moving objects;map matching;chunking	There is an increasing number of rapidly growing repositories capturing the movement of people in spacetime. Movement trajectory compression becomes an obvious necessity for coping with such growing data volumes. This paper introduces Semantic Trajectory Compression (STC), which allows for substantially compressing trajectory data with acceptable information loss. STC exploits that human urban mobility typically occurs in transportation networks that define a geographic context for the movement. In STC, a semantic representation of the trajectory that consists of events localized in a transportation network replaces raw, highly redundant position information (e.g., from GPS receivers). An experimental evaluation with real and synthetic trajectories demonstrates the power of STC in reducing trajectories to essential information and illustrates how trajectories can be restored from compressed data.	a-train;circuit restoration;data compression;database;experiment;global positioning system;heuristic (computer science);microsoft outlook for mac;modality (human–computer interaction);odometry;randomness;roundabout;semantic compression;synthetic intelligence	Kai-Florian Richter;Falko Schmid;Patrick Laube	2012	J. Spatial Information Science	10.5311/JOSIS.2012.4.62	data compression;computer vision;navigation;simulation;geography;artificial intelligence;trajectory;machine learning;data mining;mathematics;chunking;cartography	ML	-15.549736553158068	-34.74755950601823	25076
f27ae9b4d98dea8c818061d94b63790d219566f7	modeling moods in bbc programs based on emotional context	emotions;intelligent interfaces;broadband network;user preferences;personalization;automatic generation;lsa latent semantic analysis;semantic space;latent semantic analysis	The increasing amounts of streaming and downloadable media becoming available in converged digital broadcast and next generation mobile broadband networks will require intelligent interfaces capable of personalizing the selection of content according to user preferences and moods. We propose an approach to automatically generate atmospherelike metadata from BBC synopsis descriptions, by applying LSA latent semantic analysis to define the degree of similarity between textual program descriptions and emotional tags in a semantic space.	latent semantic analysis;next-generation network;user (computing);video synopsis	Michael Kai Petersen;Andrius Butkus	2008		10.1007/978-3-540-69478-6_13	semantic similarity;semantic computing;emotion;latent semantic analysis;telecommunications;computer science;personalization;database;multimedia;world wide web;broadband networks	Web+IR	-29.507213094610126	-49.157170058916236	25109
63bf63c2b7baa7c7e9e23f9fadad4a34038da354	music video redundancy and half-life in youtube	metadata;search engines;youtube;music video;urls;preservation;web archives	YouTube is the largest, most popular video digital library in existence, and is quite possibly the most popular digital library regardless of format type. Furthermore, music videos are one of the primary applications of YouTube. Based on our experiences of linking to music videos in YouTube, we observed that while any single URI had a short half-life, music videos were always available at another URI. For this study we collected 1291 music videos and found that very few had zero or one copies in YouTube at any given time, and some had several thousand copies at any given time. Furthermore, individual URIs had a half-life of anywhere from 9 to 18 months, depending on the publication date and remaining commercial potential.	digital library;uniform resource identifier	Matthias Prellwitz;Michael L. Nelson	2011		10.1007/978-3-642-24469-8_16	uniform resource locator;computer science;multimedia;internet privacy;metadata;world wide web;preservation	Web+IR	-27.6198251164085	-47.0655226672562	25155
0875838abd27bd01f390100519ba105e3f5befce	gis applications to resort morphology	geographic information system;gis;wuxi;morphological analysis;sanya;spatial analysis;china;resort morphology	GIS, RS and GPS are powerful tools that are used to explore many geographical subjects. These new methods of data collection and analysis also have the potential to underpin a new era of longitudinal studies of resort morphology. The capabilities of GIS in facilitating spatial analysis, in handling (collecting, classifying and managing) multiple types of data and in analysing complex phenomena to reveal the spatial connections between data units are useful in morphological studies. This paper uses case studies to show how GIS techniques can be used to process both spatial and attribute data, to map morphological features, and to analyse changes in the morphological characteristics of resorts. It suggests some promising directions for GIS applications in studies of resort morphology and associated implications for resort management and development planning.	gis applications;galaxy morphological classification	Jia Liu;Geoffrey Wall;Jie Zhang	2011	IJSTM	10.1504/IJSTM.2011.038666	enterprise gis;morphological analysis;gis and public health;spatial analysis;geographic information system;operations research;china	Vision	-12.661855795277523	-24.02276186957254	25172
51ea20dc4f688af41f9840a854d15bac49db1be6	computing personalized pagerank quickly by exploiting graph structures		We propose a new scalable algorithm that can compute Personalized PageRank (PPR) very quickly. The Power method is a state-of-the-art algorithm for computing exact PPR; however, it requires many iterations. Thus reducing the number of iterations is the main challenge. We achieve this by exploiting graph structures of web graphs and social networks. The convergence of our algorithm is very fast. In fact, it requires up to 7.5 times fewer iterations than the Power method and is up to five times faster in actual computation time. To the best of our knowledge, this is the first time to use graph structures explicitly to solve PPR quickly. Our contributions can be summarized as follows. 1. We provide an algorithm for computing a tree decomposition, which is more efficient and scalable than any previous algorithm. 2. Using the above algorithm, we can obtain a core-tree decomposition of any web graph and social network. This allows us to decompose a web graph and a social network into (1) the core, which behaves like an expander graph, and (2) a small tree-width graph, which behaves like a tree in an algorithmic sense. 3. We apply a direct method to the small tree-width graph to construct an LU decomposition. 4. Building on the LU decomposition and using it as preconditoner, we apply GMRES method (a state-of-theart advanced iterative method) to compute PPR for whole web graphs and social networks.	algorithm;computation;direct method in the calculus of variations;generalized minimal residual method;graph (discrete mathematics);iterative method;lu decomposition;pagerank;portland pattern repository;power iteration;scalability;social network;time complexity;tree decomposition;treewidth;webgraph	Takanori Maehara;Takuya Akiba;Yoichi Iwata;Ken-ichi Kawarabayashi	2014	PVLDB	10.14778/2732977.2732978	combinatorics;power graph analysis;graph bandwidth;computer science;theoretical computer science;data mining;database;distributed computing;graph;moral graph;modular decomposition;strength of a graph;tree decomposition	DB	-10.246860411736877	-40.9479718990067	25175
8508041d68fd314fedf815ed0ca967237543dd1f	how to find appropriate automobile exhibition halls: towards a personalized recommendation service for auto show	profiling;automobile exhibition halls;auto show;recommendation	This paper proposes a novel recommendation methodology to guide visitors to find their proper automobile exhibition halls for auto show. In the proposed method, spatio-temporal features of visitors' behavior are first considered to construct their profiling, and then their interests are extracted based on visitors' clustering. Next, three modules including relevance module, quality module and integration module are developed for ranking visitors' preference of exhibition halls. Finally, highly desired exhibition halls are personalized and recommended to proper visitors. In the proposed modules, the relevance module is developed to measure the relationship of an automobile exhibition and a visitor, while the quality module is constructed to analyze the quality of each automobile exhibition. The integration module is to combine two modules above for recommending appropriate automobile exhibition. The proposed approach is well validated using a real world dataset, and compared with several baseline models. Our experimental results indicate that in terms of the well-known evaluation metrics, the proposed method can achieve more useful and feasible recommendation results, and our finding highlights that the proposed method can help both visitors to find a more appropriate automobile exhibition halls, and manage officers to reduce more management cost.	personalization	Danhuai Guo;Yingqiu Zhu;Wei Xu;Shuo Shang;Zhiming Ding	2016	Neurocomputing	10.1016/j.neucom.2016.02.084	simulation;computer science;profiling;multimedia	Web+IR	-23.89482869955755	-47.946588906497304	25227
eb4f2748440abca3e7e3b8ef54d88fbc3ec5bf3f	timesets: timeline visualization with set relations	research outputs;research publications;qa75 electronic computers computer science	In this paper, we introduce a novel timeline visualization technique, TimeSets, that helps make sense of complex temporal datasets by showing the set relationships among individual events. TimeSets visually groups events that share a topic, such as a place or a person, while preserving their temporal order. It dynamically adjusts the level of detail for each event to suit the amount of information and display estate. Various design options were explored to address issues such as one event belonging to multiple topics. A controlled experiment was conducted to evaluate its effectiveness by comparing it to the KelpFusion method. The results showed significant advantage in accuracy and user preference.	level of detail;timeline	Phong H. Nguyen;Kai Xu;Rick Walker;B. L. William Wong	2016	Information Visualization	10.1177/1473871615605347	computer vision;computer science;artificial intelligence;machine learning;data mining;multimedia;world wide web	HCI	-30.500895008064685	-35.50740385846166	25234
02cb8236d89201bbb4adf1891f8087f946a9d1d0	evolution of artificial neural development - in search of learning genes				Gul Muhammad Khan	2018		10.1007/978-3-319-67466-7	machine learning;neural development;artificial intelligence;computer science	ML	-8.38568634069231	-47.77982568253209	25328
9c39d417d239f10fcd19529662f63df38a65c88c	visual cluster exploration of web clickstream data	pattern clustering;electronic commerce;prototypes;layout;user interfaces data analysis data visualisation electronic commerce internet markov processes pattern clustering self organising feature maps;data visualization visualization markov processes data models hidden markov models prototypes layout;data visualisation;data analysis;visualization;hidden markov models;internet;self organising feature maps;data visualization;markov processes;ebay visual cluster exploration web clickstream data user behavior patterns e commerce companies visual analytics system clickstream clusters self organizing map markov chain models intuitive user interface;user interfaces;data models	Web clickstream data are routinely collected to study how users browse the web or use a service. It is clear that the ability to recognize and summarize user behavior patterns from such data is valuable to e-commerce companies. In this paper, we introduce a visual analytics system to explore the various user behavior patterns reflected by distinct clickstream clusters. In a practical analysis scenario, the system first presents an overview of clickstream clusters using a Self-Organizing Map with Markov chain models. Then the analyst can interactively explore the clusters through an intuitive user interface. He can either obtain summarization of a selected group of data or further refine the clustering result. We evaluated our system using two different datasets from eBay. Analysts who were working on the same data have confirmed the system's effectiveness in extracting user behavior patterns from complex datasets and enhancing their ability to reason.	browsing;clickstream;cluster analysis;e-commerce;glossary of computer graphics;interactivity;level of detail;markov chain;pattern language;problem solving;self-organizing map;user interface;visual analytics	Jishang Wei;Zeqian Shen;Neel Sundaresan;Kwan-Liu Ma	2012	2012 IEEE Conference on Visual Analytics Science and Technology (VAST)	10.1109/VAST.2012.6400494	layout;data modeling;the internet;visualization;clickstream;computer science;data science;data mining;prototype;markov process;data analysis;user interface;world wide web;data visualization;statistics	Visualization	-26.962333940092282	-33.435947377122446	25332
962f5870be18b89647b17811731096f46cd8a168	mobile social group sizes and scaling ratio	mobile device;data mining;mobile phone;social network;information and communication technology;social mobility;social groups;face to face	Social data mining has become an emerging area of research in information and communication technology fields. The scope of social data mining has expanded significantly in the recent years with the advance of telecommunication technologies and the rapidly increasing accessibility of computing resources and mobile devices. People increasingly engage in and rely on phone communications for both personal and business purposes. Hence, mobile phones become an indispensable part of life for many people. In this article, we perform social data mining on mobile social networking by presenting a simple but efficient method to define social closeness and social grouping, which are then used to identify social sizes and scaling ratio of close to “8”. We conclude that social mobile network is a subset of the face-to-face social network, and both groupings are not necessary the same, hence the scaling ratios are distinct. Mobile social data mining.	accessibility;centrality;data mining;image scaling;mobile device;mobile phone;social network	Santi Phithakkitnukoon;Ram Dantu	2009	AI & SOCIETY	10.1007/s00146-009-0230-5	social group;social web;information and communications technology;mobile search;social science;computer science;social mobility;data mining;mobile device;internet privacy;mobile computing;world wide web;social computing;social network	HCI	-27.07014179681088	-43.63389671015012	25412
19c3c0f38d293bc0e3b4ddf58e98fc54d007f819	the feasibility of equilibria in large ecosystems: a primary but neglected concept in the complexity-stability debate		The consensus that complexity begets stability in ecosystems was challenged in the seventies, a result recently extended to ecologically-inspired networks. The approaches assume the existence of a feasible equilibrium, i.e. with positive abundances. However, this key assumption has not been tested. We provide analytical results complemented by simulations which show that equilibrium feasibility vanishes in species rich systems. This result leaves us in the uncomfortable situation in which the existence of a feasible equilibrium assumed in local stability criteria is far from granted. We extend our analyses by changing interaction structure and intensity, and find that feasibility and stability is warranted irrespective of species richness with weak interactions. Interestingly, we find that the dynamical behaviour of ecologically inspired architectures is very different and richer than that of unstructured systems. Our results suggest that a general understanding of ecosystem dynamics requires focusing on the interplay between interaction strength and network architecture.	architecture as topic;assumed;dynamical system;ecology;ecosystem;equilibrium;inspiration function;interaction;network architecture;plant leaves;simulation	Michaël Dougoud;Laura Vinckenbosch;Rudolf P. Rohr;Louis-Félix Bersier;Christian Mazza	2018		10.1371/journal.pcbi.1005988	biology;theoretical ecology;ecological niche;species diversity;ecosystem;ecology;species richness	ECom	-5.621437228735764	-45.63853816246466	25425
f9c59e2db18df0e2e703e9f6763e977ef90d4868	web mining driven object locality knowledge acquisition for efficient robot behavior	text mining;behavioural sciences computing;common sense reasoning;mobile robots;data mining;visualization;internet;search problems visualization mobile robots text mining knowledge acquisition;knowledge acquisition;goal directed robot behaviour web mining driven object locality knowledge acquisition robot behavior information resource visual perception indoor mobile robots common sense knowledge about object locality csol robotic visual search task online knowledge acquisition mechanism conceptual knowledge internet;search problems;mobile robots behavioural sciences computing common sense reasoning data mining internet	As an important information resource, visual perception has been widely employed for various indoor mobile robots. The common-sense knowledge about object locality (CSOL), e.g. a cup is usually located on the table top rather than on the floor and vice versa for a trash bin, is a very helpful context information for a robotic visual search task. In this paper, we propose an online knowledge acquisition mechanism for discovering CSOL, thereby facilitating a more efficient and robust robotic visual search. The proposed mechanism is able to create conceptual knowledge with the information acquired from the largest and the most diverse medium - the Internet. Experiments using an indoor mobile robot demonstrate the efficiency of our approach as well as reliability of goal-directed robot behaviour.	color vision;database;internet;knowledge acquisition;locality of reference;mobile robot;web mining	Kai Zhou;Michael Zillich;Hendrik Zender;Markus Vincze	2012	2012 IEEE/RSJ International Conference on Intelligent Robots and Systems	10.1109/IROS.2012.6385931	mobile robot;computer vision;text mining;commonsense reasoning;the internet;visualization;computer science;knowledge management;artificial intelligence;data mining	Robotics	-26.5438734610895	-41.375647802996696	25479
9288096eefc817d25c22c31a6e37b5f2a2bd2c4c	hetero-convlstm: a deep learning approach to traffic accident prediction on heterogeneous spatio-temporal data		Predicting traffic accidents is a crucial problem to improving transportation and public safety as well as safe routing. The problem is also challenging due to the rareness of accidents in space and time and spatial heterogeneity of the environment (e.g., urban vs. rural). Most previous research on traffic accident prediction conducted by domain researchers simply applied classical prediction models on limited data without addressing the above challenges properly, thus leading to unsatisfactory performance. A small number of recent works have attempted to use deep learning for traffic accident prediction. However, they either ignore time information or use only data from a small and homogeneous study area (a city), without handling spatial heterogeneity and temporal auto-correlation properly at the same time. In this paper we perform a comprehensive study on the traffic accident prediction problem using the Convolutional Long Short-Term Memory (ConvLSTM) neural network model. A number of detailed features such as weather, environment, road condition, and traffic volume are extracted from big datasets over the state of Iowa across 8 years. To address the spatial heterogeneity challenge in the data, we propose a Hetero-ConvLSTM framework, where a few novel ideas are implemented on top of the basic ConvLSTM model, such as incorporating spatial graph features and spatial model ensemble. Extensive experiments on the 8-year data over the entire state of Iowa show that the proposed framework makes reasonably accurate predictions and significantly improves the prediction accuracy over baseline approaches.	artificial neural network;autocorrelation;baseline (configuration management);big data;deep learning;experiment;long short-term memory;network model;routing;sparse matrix	Zhuoning Yuan;Xun Zhou;Tianbao Yang	2018		10.1145/3219819.3219922	predictive modelling;machine learning;data mining;computer science;deep learning;homogeneous;artificial neural network;temporal database;small number;graph;spatial heterogeneity;artificial intelligence	ML	-16.11096179834796	-32.58024933125749	25535
a83af508c7fc5de0e24871b8a9934343e8c1e468	supervised link prediction using multiple sources	social network services;probability theory and statistics;annan data och informationsvetenskap;predictive models color social network services collaboration supervised learning logistics probability;probability;berakningsmatematik;collaboration networks supervised link prediction social network analysis information source supervised learning;supervised learning;supervised link prediction;information source;color;collaboration;supervised learning social network link prediction multiple sources;link prediction;computational mathematics;social network;logistics;collaborative networks;social networking online;prediction accuracy;multiple sources;social network analysis;predictive models;feature selection;learning artificial intelligence;collaboration networks;social networking online learning artificial intelligence;sannolikhetsteori och statistik;other computer and information science	Link prediction is a fundamental problem in social network analysis and modern-day commercial applications such as Face book and My space. Most existing research approaches this problem by exploring the topological structure of a social network using only one source of information. However, in many application domains, in addition to the social network of interest, there are a number of auxiliary social networks and/or derived proximity networks available. The contribution of the paper is twofold: (1) a supervised learning framework that can effectively and efficiently learn the dynamics of social networks in the presence of auxiliary networks, (2) a feature design scheme for constructing a rich variety of path-based features using multiple sources, and an effective feature selection strategy based on structured sparsity. Extensive experiments on three real-world collaboration networks show that our model can effectively learn to predict new links using multiple sources, yielding higher prediction accuracy than unsupervised and single-source supervised models.	bradley–terry model;citeseerx;experiment;feature selection;ibm notes;information source;lu decomposition;predictive modelling;scalability;social network analysis;sparse matrix;statistical model;supervised learning;time series;unsupervised learning	Zhengdong Lu;Berkant Savas;Wei Tang;Inderjit S. Dhillon	2010	2010 IEEE International Conference on Data Mining	10.1109/ICDM.2010.112	logistics;social network analysis;numerical analysis;computer science;dynamic network analysis;data science;machine learning;probability;data mining;predictive modelling;supervised learning;feature selection;social network;collaboration	ML	-15.424232846637715	-46.86112343494919	25599
678601814547ac7e0dad1f298771930271440f15	interactive hierarchical tag clouds for summarizing spatiotemporal social contents	social networking online cloud computing interactive systems;hierarchical latent dirichlet allocation model interactive hierarchical tag clouds spatiotemporal social content summarization social network data tag clouds vesta spatiotemporal data biclustering approach;tag clouds;merging;spatiotemporal phenomena;twitter;tag clouds spatiotemporal phenomena context merging twitter educational institutions;context	In recent years, much effort has been invested in analyzing social network data. However, it remains a great challenge to support interactive exploration of such huge amounts of data. In this paper, we propose Vesta, a system that enables visual exploration of social network data via tag clouds. Under Vesta, users can interactively explore and extract summaries of social network contents published in a certain spatial region during a certain period of time. These summaries are represented using a novel concept called hierarchical tag clouds, which allows users to zoom in/out to explore more specific/general tag summaries. In Vesta, the spatiotemporal data is split into partitions. A novel biclustering approach is applied for each partition to extract summaries, which are then used to construct a hierarchical latent Dirichlet allocation model to generate a topic hierarchy. At runtime, the topic hierarchies in the relevant partitions of the user-specified region are merged in a probabilistic manner to form tag hierarchies, which are used to construct interactive hierarchical tag clouds for visualization. The result of an extensive experimental study verifies the efficiency and effectiveness of Vesta.	biclustering;experiment;formal concept analysis;frame rate control;incremental backup;interactivity;latent dirichlet allocation;real-time computing;scalability;social network;tag cloud;vesta (software configuration management)	Wei Kang;Anthony K. H. Tung;Xinyu Li	2014	2014 IEEE 30th International Conference on Data Engineering	10.1109/ICDE.2014.6816707	computer science;data science;data mining;database;world wide web;tag cloud	DB	-24.656239567286963	-35.510659983569084	25607
200915d31b0ab909b55d5221bcb31511e7fe9f3d	a personalized visualization tool for geo-referenced information	visualization;level of detail;computer science;degree of interest function;user interaction;article;filtering mechanisms	We are developing a prototype for the visualization of geo-referenced information. The data is organized in several topics. The user interactively selects the geographical region and the topics he/she is interest on. The main features of this prototype are: filtering mechanisms to control the amount of data displayed; representations with different levels of detail selected according to the scale of representation. In order to include semantic criteria to reduce the amount of data to display, we use a degree of interest function.	interactivity;personalization;prototype	Sérgio Freitas;Maria Beatriz Carmo;Ana Paula Afonso	2005		10.1145/1067445.1067602	information visualization;visualization;computer science;level of detail;multimedia;world wide web;information retrieval	Visualization	-30.954698831725455	-33.87310005431466	25658
4cd7e5626341ea635ee4df8e75a1e8a720ba578c	combining representations for improved sketch recognition	computer aided design;human computer interaction;sketch recognition;temporal information;electrical engineering and computer science;thesis	Sketching is a common means of conveying, representing, and preserving information, and it has become a subject of research as a method for human-computer interaction, specifically in the area of computer-aided design. Digitally collected sketches contain both spatial and temporal information; additionally, they may contain a conceptual structure of shapes and subshapes. These multiple aspects suggest several ways of representing sketches, each with advantages and disadvantages for recognition. Most existing sketch recognitions systems are based on a single representation and do not use all available information. We propose combining several representations and systems as a way to improve recognition accuracy. This thesis presents two methods for combining recognition systems. The first improves recognition by improving segmentation, while the second seeks to predict how well systems will recognize a given domain or symbol and combine their outputs accordingly. We show that combining several recognition systems based on different representations can improve the accuracy of existing recognition methods. Thesis Supervisor: Randall Davis Title: Professor	computer-aided design;human–computer interaction;sketch recognition	Sonya J. Cates	2009			human–computer interaction;computer science;artificial intelligence;sketch recognition	AI	-30.621026497578267	-38.20252190676462	25674
64b6d9c9dc094e574683ae8c747b1357cbc42b5d	live social semantics	social interaction;real time;sensor integration;heterogeneous data;automatic generation;social experiment;semantic web;online social network;face to face	Social interactions are one of the key factors to the success of conferences and similar community gatherings. This paper describes a novel application that integrates data from the semantic web, online social networks, and a real-world contact sensing platform. This application was successfully deployed at ESWC09, and actively used by 139 people. Personal profiles of the participants were automatically generated using several Web 2.0 systems and semantic academic data sources, and integrated in real-time with face-to-face contact networks derived from wearable sensors. Integration of all these heterogeneous data layers made it possible to offer various services to conference attendees to enhance their social experience such as visualisation of contact data, and a site to explore and connect with other participants. This paper describes the architecture of the application, the services we provided, and the results we achieved in this deployment.	eswc;interaction;online and offline;real-time locating system;recommender system;resource description framework;semantic web;sensor;social media;social network;software deployment;wearable computer;web 2.0	Harith Alani;Martin Szomszor;Ciro Cattuto;Wouter Van den Broeck;Gianluca Correndo;Alain Barrat	2009		10.1007/978-3-642-04930-9_44	social web;social relation;social experiment;computer science;artificial intelligence;semantic web;social semantic web;data mining;database;multimedia;world wide web	HCI	-28.646177405971937	-44.828281230417176	25685
dcc4f78f198a1e7d3a1e720a6ef69a0a768e45a5	sixteen years of agricultural drought assessment of the biobío region in chile using a 250 m resolution vegetation condition index (vci)	vci;spi;vegetation;remote sensing;drought;modis;agriculture;land cover	Francisco Zambrano 1,∗,†, Mario Lillo-Saavedra 1,2,∗,†, Koen Verbist 3,4,† and Octavio Lagos 1,2,† 1 Departament of Water Resources, Universidad de Concepción, Chillán 3801061, Chile; octaviolagos@udec.cl 2 Water Research Center for Agriculture and Mining (CRHIAM) (CONICYT-FONDAP-15130015), Concepción 4070411, Chile 3 UNESCO-IHP, Hydrological Systems and Global Change Section, Santiago 7511019, Chile; k.verbist@unesco.org 4 International Centre for Eremology, Department of Soil Management, Ghent University, Ghent B-9000 Gent, Belgium * Correspondence: frzambra@gmail.com (F.Z.); malillo@udec.cl (M.L.-S.); Tel.: +56-42-220-8807 (M.L.-S.) † These authors contributed equally to this work.	global change	Francisco Zambrano;Mario Lillo-Saavedra;Koen Verbist;Octavio Lagos	2016	Remote Sensing	10.3390/rs8060530	meteorology;agriculture;hydrology;vegetation;remote sensing	Robotics	-10.279834769886165	-26.280928876567728	25760
00f149d5839f7981decb6e5dae39b3fe1f829cbe	leveraging aggregate ratings for improving predictive performance of recommender systems	hierarchical linear model;large dataset;standard deviation;linear regression model;recommender system;hierarchical linear models;collaborative filtering;predictive models;prediction model;aggregate ratings;article;hierarchical models;recommender systems;hierarchical model;graduate student;cold stat problem	One of the key problems in recommender systems is accurate estimation of unknown ratings of individual items for individual users in terms of the previously specified ratings and other characteristics of items and users. In this thesis, we investigate a way of improving estimations of individual ratings using externally provided properties of aggregate ratings for groups of items and users, such as an externally specified average rating of action movies provided by graduate students or externally specified standard deviation of ratings for comedy movies.	aggregate data;recommender system	Akhmed Umyarov	2008		10.1145/1454008.1454064	simulation;computer science;data science;multilevel model;machine learning;data mining;predictive modelling;world wide web;recommender system	ECom	-17.278617728282406	-48.65125523456839	25810
5101432b0f819f98c86a41fd642da47eb6b9ae5d	enhanced network embeddings via exploiting edge labels.		Network embedding methods aim at learning low-dimensional latent representation of nodes in a network. While achieving competitive performance on a variety of network inference tasks such as node classification and link prediction, these methods treat the relations between nodes as a binary variable and ignore the rich semantics of edges. In this work, we attempt to learn network embeddings which simultaneously preserve network structure and relations between nodes. Experiments on several real-world networks illustrate that by considering different relations between different node pairs, our method is capable of producing node embeddings of higher quality than a number of state-of-the-art network embedding methods, as evaluated on a challenging multi-label node classification task.	binary data;experiment;ibm notes;multi-label classification;protein structure prediction;semi-supervised learning;semiconductor industry	Haochen Chen;Xiaofei Sun;Yingtao Tian;Bryan Perozzi;Muhao Chen;Steven Skiena	2018		10.1145/3269206.3269270	artificial intelligence;machine learning;theoretical computer science;semantics;embedding;computer science;inference	AI	-14.492386464802504	-46.43392416481723	25815
d4314c330e36d00db3a9f582a3f73403ac483bf3	ranking of nodes of networks taking into account the power function of its weight of connections		To rank nodes in quasi-hierarchical networks of social nature, it is necessary to carry out a detailed analysis of the network and evaluate the results obtained according to all the given criteria and identify the most influential nodes. Existing ranking algorithms in the overwhelming majority estimate such networks in general, which does not allow to clearly determine the influence of nodes among themselves. In the course of the study, an analysis of the results of known algorithms for ranking the nodes of HITS, PageRank and compares the obtained data with the expert evaluation of the network. For the effective analysis of quasi-hierarchical networks, the basic algorithm of HITS is modified, which allows to evaluate and rank nodes according to the given criteria (the number of input and output links among themselves), which corresponds to the results of expert evaluation. It is shown that the received method in some cases provides results that correspond to the real social relation, and the indexes of the authorship of the nodes pre-assigned social roles.	algorithm;input/output;network topology;pagerank;tree network	A. M. Soboliev;D. V. Lande	2017	CoRR		learning to rank;computer science;data mining;pagerank;social relation;social nature;input/output;power function;ranking	Web+IR	-15.289165647052489	-41.14261513715223	25835
a2037c81ad22cc66ec9dff0162dc8d02968db3e6	an agent based approach for balancing commuter traffic	communication system traffic control;control systems;lighting control;collaborative work;mobile device;sensors;agent based;road traffic;traffic light control;traffic control;cities and towns lighting control control systems roads communication system traffic control telecommunication traffic intelligent agent intelligent sensors global positioning system collaborative work;transport segment transport congestion intelligent mobile devices intelligent agents traffic light control traffic load transport options;transport segment;telecommunication traffic;intelligent agents;traffic information systems cooperative systems mobile computing road traffic traffic control;cooperative systems;traffic information systems;accidents;roads;global positioning system;traffic load;intelligent agent;cities and towns;artificial intelligence;mobile computing;transport congestion;intelligent sensors;conferences;intelligent mobile devices;transport options	Transport congestion within cities represents an omnipresent yet increasingly serious problem. Traditionally the main method of control available to combat it has been the efficient control of traffic lights. The recent rise of intelligent mobile devices carried by road users offers an additional point of control, potentially enabling the manipulation of the routes that people take within the city. The current paper combines the use of such devices with intelligent agents representing different transport segments within the city, including roads, trams, busses and trains. It fuses them in a novel technique which attempts to evenly spread the traffic load throughout the different transport options within the city. In addition the system is capable of rebalancing this load dynamically in response to any events which reduce the capacity of a given transport segment within the city. The system complements the existing work on traffic light control.	global positioning system;intelligent agent;mobile device;mobile phone;network congestion;sensor	Martin Carpenter;Nikolay Mehandjiev	2010	2010 19th IEEE International Workshops on Enabling Technologies: Infrastructures for Collaborative Enterprises	10.1109/WETICE.2010.12	simulation;global positioning system;computer science;sensor;artificial intelligence;mobile device;computer security;intelligent agent;intelligent sensor	Robotics	-20.438297301028527	-26.136683153482554	25940
b826b2c9f6422a9e4a6f57c500e2fbd29771044f	3d reconstruction of paper based assembly drawings: state of the art and approach	concepcion asistida;computer aided design;informacion numerica;art graphique;diseno industrial;industrial drawing;modelo 3 dimensiones;automatic system;drawing art;vectorisation;modele 3 dimensions;digitizing;three dimensional model;numerisation;modele mecanique;vectorization;construction mecanique;mechanical engineering;digital information;construccion mecanica;vectorisacion;arte grafico;sistema automatico;dessin industriel;systeme automatique;conception assistee;numerizacion;information numerique;modelo mecanico;bill of material;3d reconstruction;mechanical model	Engineering solutions are generally documented in assembly and part drawings and bill of materials. A great benefit, qualitatively and commercially, can be achieved if these paper based storages can be transformed into digital information archives. The process of this transformation is called reconstruction. The reconstruction process of paper based assembly drawings consists of four steps: digitization; vectorization/ interpretation; 3D reconstruction of the parts and the 3D reconstruction of the assembly.This paper evaluates existing commercial systems worldwide for interpretation of paper based mechanical engineering drawings. For a complete reconstruction process a 3D reconstruction is needed. This functionality is already supported by some CAD systems to a certain extent, but it still remains a major topic of research work. One CAD system which converts 2D CAD models into 3D CAD models is presented. Finally, after the reconstruction of the parts the whole assembly can be reconstructed. Until now, no system for the automatic reconstruction of assemblies is available. In our paper we present a general approach for automatic reconstruction of 3D assembly model data by interpretation of mechanical engineering 2D assembly drawings, their part drawings, and the bill of materials.	3d reconstruction	El-Fathi El-Mejbri;Hans Grabowski;Harald Kunze;Ralf-Stefan Lossack;Arno Michelis	2001		10.1007/3-540-45868-9_1	3d reconstruction;mechanical systems drawing;computer science;artificial intelligence;computer aided design;vectorization	NLP	-33.39852217157582	-26.044482813893637	26109
68201839ef80144ed3a53b588eefdf560bf38913	tsp: mining top-k closed sequential patterns	minimisation;projected database pruning sequential pattern mining data mining minimum support threshold specification top k frequent closed sequential pattern tsp algorithm dynamic support raising;sequences;data mining databases itemsets testing computer science frequency;frequent pattern;efficient algorithm;data mining;pattern mining;very large databases data mining sequences minimisation;sequential pattern mining;very large databases;sequential pattern	Sequential pattern mining has been studied extensively in data mining community. Most previous studies require the specification of a minimum support threshold to perform the mining. However, it is difficult for users to provide an appropriate threshold in practice. To overcome this difficulty, we propose an alternative task: mining topfrequent closed sequential patterns of length no less than , where is the desired number of closed sequential patterns to be mined, and is the minimum length of each pattern. We mine closed patterns since they are compact representations of frequent patterns. We developed an efficient algorithm, called TSP, which makes use of the length constraint and the properties of topclosed sequential patterns to perform dynamic supportraising and projected database-pruning. Our extensive performance study shows that TSP outperforms the closed sequential pattern mining algorithm even when the latter is running with the best tuned minimum support threshold.	algorithm;data mining;experiment;grammar-based code;mathematical optimization;mined;sequential pattern mining;tree traversal	Petre Tzvetkov;Xifeng Yan;Jiawei Han	2003		10.1109/ICDM.2003.1250939	sequential pattern mining;minimisation;computer science;machine learning;pattern recognition;data mining;sequence;mathematics	ML	-5.67030060057287	-36.88494170336079	26138
107444d65c858555bdb4a93eeeb7b3622a2af1c6	privacy preserving association rule mining in vertically partitioned data	efficient algorithm;heterogeneous data;privacy preservation;data mining;association rule mining;frequent itemset;transaction data;machine learning;association rule;clustering;word sense discovery;evaluation	Privacy considerations often constrain data mining projects. This paper addresses the problem of association rule mining where transactions are distributed across sources. Each site holds some attributes of each transaction, and the sites wish to collaborate to identify globally valid association rules. However, the sites must not reveal individual transaction data. We present a two-party algorithm for efficiently discovering frequent itemsets with minimum support levels, without either site revealing individual transaction values.	algorithm;association rule learning;data mining;database transaction;transaction data	Jaideep Vaidya;Chris Clifton	2002		10.1145/775047.775142	association rule learning;computer science;data science;machine learning;data mining;database;data stream mining;k-optimal pattern discovery	ML	-5.462157100129648	-34.71264654645173	26146
66d5bfc963a545915d0b102f0a604c5ac94feab6	scalable causal learning for predicting adverse events in smart buildings		Emerging smart buildings, such as the NASA Sustainability Base (SB), have a broad range of energyrelated systems, including systems for heating and cooling. While the innovative technologies found in SB and similar smart buildings have the potential to increase the usage of renewable energy, they also add substantial technical complexity. Consequently, managing a smart building can be a challenge compared to managing a traditional building, sometimes leading to adverse events including unintended thermal discomfort of occupants (too hot or too cold). Fortunately, todays smart buildings are typically equipped with thousands of sensors, controlled by Building Automation Systems (BASs). However, manually monitoring a BAS time series data stream with thousands of values may lead to information overload for the people managing a smart building. We present here a novel technique, Scalable Causal Learning (SCL), that integrates dimensionality reduction and Bayesian network structure learning techniques. SCL solves two problems associated with the naive application of dimensionality reduction and causal machine learning techniques to BAS time series data: (i) using autoregressive methods for causal learning can lead to induction of spurious causes and (ii) inducing a causal graph from BAS sensor data using existing graph structure learning algorithms may not scale to large data sets. Our novel SCL method addresses both of these problems. We test SCL using time series data from the SB BAS, comparing it with a causal graph learning technique, the PC algorithm. The causal variables identified by SCL are effective in predicting adverse events, namely abnormally low room temperatures, in a conference room in SB. Specifically, the SCL method performs better than the PC algorithm in terms of false alarm rate, missed detection rate and detection time. Introduction NASA Ames Sustainability Base1 (SB) is a green building that provides a research testbed for different sustainable technologies and concepts. The SB is designed with a Net Zero Energy objective. Detailed monitoring of the BAS is Copyright c © 2016, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved. http://www.nasa.gov/ames/facilities/sustainabilitybase required at regular intervals. SB is instrumented with 2636 sensors, which perform physical or logical measurements. One major area of consumption is the building heating and cooling system. From Jan 2014 to May 2014 many alarms were acknowledged from sensors specific to the heating system. An alarm is initiated whenever a sensor value goes beyond the desired range, indicating an anomalous behavior of the heating system. Some alarms, e.g room temperature going outside the predefined range, cause occupants’ discomfort and others can lead to short-term or long-term damage to the system. In order to eliminate these alarms, it is crucial to identify the causes. An attempt via human inspection is time consuming and can take several weeks or months. As the sensor data captures enough information about the system, an alternative for cause-detection is a data driven approach which does not require intervening with the BAS of SB building. Causality is mainly described by two methods: counterfactuals or causal graphs (Pearl 2000). Here we primarily consider the second one. A causal graph is based on the principle that each variable is independent of its non-effects, conditional on its direct causes. PC, FCI, RFCI and GES are commonly used algorithms to learn causal graphs from data (Spirtes, Glymour, and Scheines 2000; Chickering 2003; Colombo et al. 2012). Bayesian networks have also been shown to convey causal interpretation (Pearl, Verma, and others 1991). A Bayesian network (BN) is a directed acyclic graph (DAG) which represents a family of distributions over its nodes. The structure of a BN represents the conditional independence relations among the nodes. Hence learning the independence relations by conditional independence tests is a main approach in learning the structure of a Bayesian network from data (Margaritis and Thrun 1999). Another structure learning approach is to perform a search over directed graphs based on a score function (Heckerman, Geiger, and Chickering 1995). Hybrid techniques have also been developed to learn BN structure (Tsamardinos, Brown, and Aliferis 2006). However identifying the causal Bayesian network structure only from observations is challenging because it is possible to model one distribution by two distinct directed graphs which have different causal meaning of the variables (Ellis and Wong 2008). In this work we propose a novel amalgamation (Figure  x x .. x  Dimension reduction using autoregressive model Bayesian network structure learning Isolating candidate causes Adverse event prediction Missed detection rate False alarm rate	algorithm;artificial intelligence;automation;autoregressive model;bayesian network;broadcast auxiliary service;bruce ellis;causal filter;causal graph;causality;computational sustainability;computer cooling;counterfactual conditional;dimensionality reduction;directed acyclic graph;directed graph;full configuration interaction;information overload;lasso;machine learning;regular expression;sandy bridge;sensor;smart board;smart tv;sparse matrix;structured text;testbed;time series	Aniruddha Basak;Ole J. Mengshoel;Stefan Hosein;Rodney Martin	2016			building automation;computer science;machine learning;artificial intelligence;simulation;scalability	AI	-12.758654274838129	-45.86135636435626	26174
0b8b5a0c1396dd75679613858b65be970a6e72a5	interacting with temporal data	temporal data visualisation and interaction;temporal data;temporal information;information interfaces;natural phenomena;everyday life	Time serves as a basis for measuring the occurrence and evolution of natural phenomena, and governs the coordination of many of our everyday life activities. As the capacities of our digital tools have grown, they have begun to make readily available to us unprecedented quantities of new, rich, structured temporal information about the people and things in our lives. This abundance of information has laid open avenues for new tools and applications - applications which, in turn, introduce new demands on interface mechanisms used to display, represent and interact with temporal data.  This workshop, the second in a series on Capturing, Interacting with and Visualizing Temporal Data, will focus on such demands, examining interaction challenges emerging across new application domains.		Wendy E. Mackay;Max Van Kleek;Aurélien Tabard	2009		10.1145/1520340.1520740	simulation;computer science;data mining;temporal database	HCI	-28.905983040516453	-30.185604621852956	26312
3c40c424d7be2fadd8253bca7234e6cfadc6709f	mining unexpected rules by pushing user dynamics	prior knowledge;user preferences;association rule;subjective interestingness;unexpected rule	Unexpected rules are interesting because they are either previously unknown or deviate from what prior user knowledge would suggest. In this paper, we study three important issues that have been previously ignored in mining unexpected rules. First, the unexpectedness of a rule depends on how the user prefers to apply the prior knowledge to a given scenario, in addition to the knowledge itself. Second, the prior knowledge should be considered right from the start to focus the search on unexpected rules. Third, the unexpectedness of a rule depends on what other rules the user has seen so far. Thus, only rules that remain unexpected given what the user has seen should be considered interesting. We develop an approach that addresses all three problems above and evaluate it by means of experiments focusing on finding interesting rules.	algorithm;data mining;experiment	Ke Wang;Yuelong Jiang;Laks V. S. Lakshmanan	2003		10.1145/956750.956780	association rule learning;computer science;knowledge management;artificial intelligence;machine learning;data mining	ML	-4.854021438042181	-30.046204692349658	26359
3f53772078710edcca8ce73aab1dabac112cb4be	randomized lu decomposition: an algorithm for dictionaries construction		In recent years, distinctive-dictionary construction has gained importance due to his usefulness in data processi ng. Usually, one or more dictionaries are constructed from a training data and then they are used to classify signals that did not participate in the training process. A new dictionary construction algorithm is introduced. It is based on a low-rank matrix factorization being achieved by the application of the randomized LU decomposition to a training data. This methodis fast, scalable, parallelizable, consumes low memory, outp erforms SVD in these categories and works also extremely well on larg e sparse matrices. In contrast to existing methods, the rando mized LU decomposition constructs an under-complete dictionary , which simplifies both the construction and the classificatio n processes of newly arrived signals. The dictionary constru ction is generic and general that fits different applications. We demonstrate the capabilities of this algorithm for file type identification, which is a fundamental task in digital security arena, performed nowadays for example by sandboxing mechanism, deep packet inspection, firewalls and anti-viru s systems. We propose a content-based method that detects file types that neither depend on file extension nor on metadata. Such approach is harder to deceive and we show that only a few file fragments from a whole file are needed for a successful classification. Based on the constructed dictionaries, we s how that the proposed method can effectively identify executio n code fragments in PDF files.	deep packet inspection;dictionary;fits;lu decomposition;portable document format;randomized algorithm;randomness;sandbox (computer security);scalability;singular value decomposition;sparse matrix;statistical classification	Aviv Rotbart;Gil Shabat;Yaniv Shmueli;Amir Averbuch	2015	CoRR		computer science;theoretical computer science;machine learning;data mining;database;mathematics	ML	-10.05471155302263	-49.49314095376822	26434
30141161664f8a7f83513769f355080add77b86e	detecting anomalies in sequential data with higher-order networks.		A major branch of anomaly detection methods relies on dynamic networks: raw sequence data is first converted to a series of networks, then critical change points are identified in the evolving network structure. However, existing approaches use first-order networks (FONs) to represent the underlying raw data, which may lose important higher-order sequence patterns, making higher-order anomalies undetectable in subsequent analysis. We present a novel higher-order anomaly detection method that is both parameterfree and scalable, building on an improved higher-order network (HON) construction algorithm. We show the proposed higher-order anomaly detection algorithm is effective in discovering variable orders of anomalies. Our data includes a synthetic 11 billion web clickstreams and a real-world taxi trajectory data.		Jian Xu;Mandana Saebi;Bruno Ribeiro;Lance M. Kaplan;Nitesh V. Chawla	2017	CoRR		artificial intelligence;computer science;benchmarking;raw data;anomaly detection;machine learning;big data;scalability;synthetic data	ML	-12.154876139780882	-35.07315740589485	26460
28a2ea93729b5c017ca8f33f6010f31b2eb7838c	listening factors: a large-scale principal components analysis of long-term music listening histories	empirical analysis;listening history;latent factors;lifelogging;web service;large scale;seasonality;principal component analysis;music;pca	There are about as many strategies for listening to music as there are music enthusiasts. This makes learning about overarching patterns and similarities difficult. In this paper, we present an empirical analysis of long-term music listening histories from the last.fm web service. It gives insight into the most distinguishing factors in music listening behavior. Our sample contains 310 histories with up to six years duration and 48 associated variables describing various user and music characteristics. Using a principal components analysis, we aggregated these variables into 13 components and found several correlations between them. The analysis especially showed the impact of seasons and a listener's interest in novelty on music choice. Using this information, a sample of a user's listening history or even just demographical data could be used to create personalized interfaces and novel recommendation strategies. We close with derived design considerations for future music interfaces.	computer user satisfaction;last.fm;microsoft outlook for mac;personalization;principal component analysis;variable (computer science);web service	Dominikus Baur;Jennifer Büttgen;Andreas Butz	2012		10.1145/2207676.2208581	speech recognition;computer science;multimedia;principal component analysis	HCI	-25.61918655412077	-46.987686959894646	26471
a915fe99059e4cc53e0d463725438591cfe7245a	rwr-based resources recommendation on weighted and clustered folksonomy graph	recommendation accuracy improvement rwr based resource recommendation model weighted graph clustered folksonomy graph random walk with restarts collaborative recommendation social systems data sparsity unweighted folksonomy graph edges user resource preference user tag preference resource recommendation model resource clustering user awareness differences lastfm dataset;accuracy motion pictures collaboration data models tagging bipartite graph measurement;folksonomy graph rwr weighting edges resources clustering;weighting edges;resources clustering;folksonomy graph;recommender systems graph theory;rwr	Random Walk with Restarts has been proved as an effective model for collaborative recommendation in social systems, with ability to mitigate the problem of data sparsity. However, the present framework of RWR performs on un-weighted folksonomy graph, thus neglects some useful and implicit information inside the folksonomy, such as the preference of users to resources or tags, the awareness difference of users to resources of the same tag. Inspired by this, this paper presents a resources recommendation model which enhances the original RWR recommendation framework in the twofold. On one hand, the weights are assigned to the edges of folksonomy graph to indicate their importance. On the other hand, resource clustering is applied to solve the awareness differences of users. Experimental results on a Last fm dataset show that the new model can significantly improve the recommendation accuracy compared with original RWR-based recommending model.	cluster analysis;experiment;fm broadcasting;folksonomy;recommender system;running with rifles;social system;sparse matrix;trustworthy computing	Zongzhan Kang;Yijian Pei;Hao Wu	2014	2014 IEEE 11th International Conference on e-Business Engineering	10.1109/ICEBE.2014.30	radar warning receiver;computer science;data mining;world wide web;information retrieval	DB	-20.46397092080114	-46.6720988585165	26485
d0248a1332e64a62a17e8199d34d62626e88a6b9	the contingent wisdom of dyads: when discussion enhances vs. undermines the accuracy of collaborative judgments		We evaluate the effect of discussion on the accuracy of collaborative judgments. In contrast to prior research, we show that discussion can either aid or impede accuracy relative to the averaging of collaborators’ independent judgments, as a systematic function of task type and interaction process. For estimation tasks with a wide range of potential estimates, discussion aided accuracy by helping participants prevent and eliminate egregious errors. For estimation tasks with a naturally bounded range, discussion following independent estimates performed on par with averaging. Importantly, if participants did not first make independent estimates, discussion greatly harmed accuracy by limiting the range of considered estimates, independent of task type. Our research shows that discussion can be a powerful tool for error reduction, but only when appropriately structured: Decision makers should form independent judgments to consider a wide range of possible answers, and then use discussion to eliminate extreme...	contingency (philosophy)	Julia A. Minson;Jennifer S. Mueller;Richard P. Larrick	2018	Management Science	10.1287/mnsc.2017.2823	economics;mathematical optimization;econometrics;data mining;limiting;bounded function	ML	-7.731069752044692	-26.270875881476936	26607
546ef43fa50fea7610c7ff206016e95078d13af0	using geodesic space density gradients for network community detection	density field gradients complex networks community detection geodesic space geodesic distance;social network services;community detection;complex networks;benchmark networks normalized mutual information criterion community detection techniques community membership assignment positive density gradient iterative algorithm density field summation continuous density field geodesic distance vectors network node data mining techniques network data structure encoding real world complex systems network community detection geodesic space density gradients;color;geodesic space;data mining data structures differential geometry gradient methods iterative methods social networking online;geodesic distance;qa76 electronic computers computer science computer software;data structures;diseases;clustering algorithms;complex systems;density field gradients;complex networks community detection geodesic space geodesic distance density field gradients;clustering algorithms color complex systems benchmark testing diseases data structures social network services;benchmark testing	Many real world complex systems naturally map to network data structures instead of geometric spaces because the only available information is the presence or absence of a link between two entities in the system. To enable data mining techniques to solve problems in the network domain, the nodes need to be mapped to a geometric space. We propose this mapping by representing each network node with its geodesic distances from all other nodes. The space spanned by the geodesic distance vectors is the geodesic space of that network. The position of different nodes in the geodesic space encode the network structure. In this space, considering a continuous density field induced by each node, density at a specific point is the summation of density fields induced by all nodes. We drift each node in the direction of positive density gradient using an iterative algorithm till each node reaches a local maximum. Due to the network structure captured by this space, the nodes that drift to the same region of space belong to the same communities in the original network. We use the direction of movement and final position of each node as important clues for community membership assignment. The proposed algorithm is compared with more than 10 state-of-the-art community detection techniques on two benchmark networks with known communities using Normalized Mutual Information criterion. The proposed algorithm outperformed these methods by a significant margin. Moreover, the proposed algorithm has also shown excellent performance on many real-world networks.	algorithm;benchmark (computing);cluster analysis;complex systems;data mining;data structure;distance (graph theory);dolphin;encode;entity;heat map;image gradient;iterative method;mathematical optimization;maxima and minima;mutual information;non-maskable interrupt;social network;structural pattern;xfig	Arif Mahmood;Michael Small;Somaya Al-Máadeed;Nasir M. Rajpoot	2017	IEEE Transactions on Knowledge and Data Engineering	10.1109/TKDE.2016.2632716	benchmark;complex systems;geodesic;topology;data structure;computer science;machine learning;mathematics;geometry;cluster analysis;programming language;complex network	ML	-14.355302119868357	-42.847031748868815	26623
1a9dc6ada87463fa3c52192ba008834a7e34e5f7	data selection for exact value acquisition to improve uncertain clustering	cluster algorithm;uncertainty modeling;data uncertainty;sensor network;probability distribution;uncertain data	In recent years, data uncertainty widely attracts researchers' attention because the amount of imprecise data is growing rapidly. Although data are not known exactly, probability distributions or expected errors are sometimes available. While most researchers on uncertain data mining are looking for methods to extract mining results from uncertain data, which is usually in the form of probability distributions or expected errors, it is also very important to lower the data uncertainty by making a part of data more certain to help get better mining results. For example, input values of some sensors in the sensor network are usually designed to be recorded more frequently than others because they are more important or more likely to change. In this paper, the issue of selecting a part of uncertain data and acquiring their exact values to improve clustering results is explored. Under a general uncertainty model, we propose both global and localized data selection methods, which can be used together with any existing uncertain clustering algorithm. Experimental results show that the quality of clustering improves after the selective exact value acquisition is applied.		Yu-Chieh Lin;De-Nian Yang;Ming-Syan Chen	2010		10.1007/978-3-642-14246-8_45	probability distribution;wireless sensor network;computer science;machine learning;data mining;statistics	EDA	-5.551821865865186	-34.11672020607396	26683
644d9d4f04f669ee162b5928bc18ff3f4a77d0a2	learning context-aware latent representations for context-aware collaborative filtering	context aware;latent factor models;collaborative filtering;recommendation	In this paper, we propose a generic framework to learn context-aware latent representations for context-aware collaborative filtering. Contextual contents are combined via a function to produce the context influence factor, which is then combined with each latent factor to derive latent representations. We instantiate the generic framework using biased Matrix Factorization as the base model. A Stochastic Gradient Descent (SGD) based optimization procedure is developed to fit the model by jointly learning the weight of each context and latent factors. Experiments conducted over three real-world datasets demonstrate that our model significantly outperforms not only the base model but also the representative context-aware recommendation models.	collaborative filtering;consistency model;latent variable;mathematical optimization;stochastic gradient descent	Xin Liu;Wei Wu	2015		10.1145/2766462.2767775	latent class model;computer science;collaborative filtering;machine learning;pattern recognition;data mining;probabilistic latent semantic analysis	Web+IR	-18.42366237650424	-47.7624002942536	26716
4489e76e49f9b49ef27633094696511934a9b14b	personalized view-based search and visualization as a means for deep/semantic web data access	user interface;visual navigation;relational database;view based search;navigation;visualization;personalized faceted browsing;data access;semantic web;deep web;graph visualization	Effective access to and navigation in information stored in deep Web ontological repositories or relational databases has yet to be realized due to issues with usability of user interfaces and the overall scope and complexity of information as well as the nature of exploratory user tasks. We propose the integration and adaptation of novel navigation and visualization approaches to faceted browsing such as visual depiction of facets and restrictions, visual navigation in (clusters of) search results and graph like exploration of individual search results' properties.	data access;deep web;faceted classification;machine vision;relational database;semantic web;usability;user interface	Michal Tvarozek;Mária Bieliková	2008		10.1145/1367497.1367637	data access;navigation;visual analytics;visualization;relational database;computer science;semantic web;web navigation;database;graph drawing;user interface;world wide web;information retrieval;deep web	HCI	-31.275966498569804	-33.621476430043096	26717
c88207004cc7875fb33141560edb747ed135f885	from random to hierarchical data through an irregular pyramidal structure	hierarchical structure;hierarchical data;hierarchical visualization;irregular pyramids;multiresolution visualization;point clustering	This paper proposes to transform data scanned randomly in a well-defined space (e.g, Euclidean) along a hierarchical irregular pyramidal structure in an attempt reduce search time consumed querying these random data. Such a structure is built as a series of graphs with different resolutions. Levels are constructed and surviving cells are chosen following irregular irregular pyramidal rules and according to a proximity criterion among the space points under consideration. Experimental results show that using such a structure to query data can save considerable search time.		Rimon Elias;Mohab Al Ashraf;Omar Aly	2009		10.1007/978-3-642-02124-4_33	combinatorics;discrete mathematics;machine learning;mathematics	HCI	-5.29059629574893	-42.46552958734516	26791
25a1cfc87ce41ef109a2a41e5787a2d148948e0c	a method for collaborative recommendation in document retrieval systems	demographic data based classifier;collaborative recommendation;user profile	"""The most common problem in the context of recommendation systems is """"cold start"""" problem which occurs when new product is recommended or a new user becomes to the system. A great part of systems do not personalize a user until they gather sufficient information. In this paper a novel method for recommending a profile for a new user based only on knowledge about a few demographic data is proposed. The method merges a content-based approach with collaborative recommendation. The main objective was to show that based on knowledge about other similar users, the system can classify a new user based on subset of demographic data and recommend him a non-empty profile. Using the proposed profile, the user will obtain personalized documents. A methodology of experimental evaluation was presented and simulations were performed. The preliminary experiments have shown that the most important demographic attributes are gender, age, favorite browser and level of education."""	document retrieval	Bernadetta Mianowska;Ngoc Thanh Nguyen	2013		10.1007/978-3-642-36543-0_18	user modeling;computer science;data mining;database;world wide web	Web+IR	-27.495802709760568	-50.05627118360383	26795
417200d5dc2ba5941c25b22d2f4ca65c329f380f	"""""""voting with their feet"""": delineating the sphere of influence using social media data"""		Delineating regional boundaries for places has a long tradition in geography, urban analysis and regional planning. Its theoretical basis may be traced back to the central place theory. The normative approach, using spatial interaction models, has been used, and the empirical approach, using commuting data, is also popular. While gathering commuting data using traditional methodologies (e.g., surveys) is costly, data capturing people’s locations and their thoughts, are widely available through social media platforms. This article demonstrates that Twitter data can be used to delineate boundaries among competing places. A generic approach based on the density of place names mentioned in geo-tagged tweets was proposed to reflect the sphere of influence or dominance of places. Locations with the same levels of influence from competing places constitute the boundaries delineating the regions dominated by the respective places. The method was tested to determine the boundaries between two metropolitan regions, two local cities, and two neighborhoods or communities. Results from these simple case studies demonstrated the validity of the general approach for evaluating existing place boundaries and determining boundaries if they have not been delineated. The method is applicable to different levels of the place hierarchy and has practical values for planning of places of different sizes.	automatic identification and data capture;social media	David W. S. Wong;Qunying Huang	2017	ISPRS Int. J. Geo-Information	10.3390/ijgi6110325		HCI	-21.890769537446737	-34.64459150037673	26807
711245cbf4e871cec536ba3b3f48566d42b6337f	social network analysis of different parameters derived from realtime profile	network parameters;netvizz;gephi;facebook;social network analysis	The main objective of this work is to study network parameters commonly used to explain social structures. In this paper, we extract data from a real-time Facebook account using Netvizz application, analyze and evaluate network parameters on some widely recognized graph topology using GEPHI software.	social network analysis	Paramita Dey;Aniket Sinha;Sarbani Roy	2015		10.1007/978-3-319-14977-6_50	organizational network analysis;social network analysis;simulation;computer science;data mining;network simulation;world wide web	Embedded	-19.765044814183828	-41.86991406862775	26825
04850f9b284f8ad0822b4667146b6239cb520066	preference-aware successive poi recommendation with spatial and temporal influence	location based social network;successive poi recommendation	There have been vast advances and rapid growth in Location based social networking (LBSN) services in recent years. Point of Interest (POI) recommendation is one of the most important applications in LBSN services. POI recommendation provides users personalized location recommendation. It helps users to explore new locations and filter uninteresting places that do not match with their interests. But traditional POI recommendation cannot suggest where a user may go the next day or next hour based on their current location or status. In this paper, we consider the task of personalized successive POI recommendation, recommending to a user the very next location where he might be interested to go next based on his current location. Multiple factors influence users to choose a POI, such as user’s categorical preferences, temporal activities and location preferences, popularity of a POI as well as sequential patterns of a user. In this work, we define a unified framework that takes all these factors into consideration to build a better successive POI recommendation model. We evaluate our system with a real-world dataset collected from Foursquare. Experimental results show that our proposed framework works better than other baseline approaches.		Madhuri Debnath;Praveen Kumar Tripathi;Ramez Elmasri	2016		10.1007/978-3-319-47880-7_21	computer science	DB	-23.127138916474642	-45.574737786981096	26855
55f7e8bae51856f62acaaaeb4441ceb9adbfcaac	analyzing category correlations for recommendation system	genre correlation;cold start problem;recommendation system;recommender system;collaborative filtering;sparsity problem	Since the late 20th century, the Internet users have noticeably increased and these users have provided lots of information on the Web and searched for information from the Web. Now there are huge amount of new information on the Web everyday. However, not all data are reliable and valuable. This implies that it becomes more and more difficult to find a satisfactory result from the Web. We often iterate searching several times to find what we are looking for. Researcher suggests a recommendation system to solve this problem. Instead of searching several times, a recommendation system proposes relevant information. In the Web 2.0 era, a recommendation system often relies on the collaborative filtering from users. In general, the collaborative filtering approach works based on user information such as gender, location or preference. However, it may cause the cold-star problem or the sparsity problem since it requires initial user information. Recently, there are several attempts to tackle these collaborative filtering problems. One of such attempts is to use category correlation of contents. For instance, a movie has genre information given by movie experts and directors. We notice that these category information are more reliable compared with user ratings. Moreover, a newly created content always has category information; namely, we can avoid the cold-start problem. We consider a movie recommendation system. We revisit the previous algorithm using genre correlation and improve the algorithm. We also test the modified algorithm and analyze the results with respect to a characteristic of genre correlations.	algorithm;cold start;collaborative filtering;internet;iteration;recommender system;sparse matrix;web 2.0;world wide web	Bernhard Scholz;Sang-Min Choi;Sang-Ki Ko;Hae-Sung Eom;Yo-Sub Han	2011		10.1145/1968613.1968615	cold start;computer science;collaborative filtering;information filtering system;machine learning;data mining;database;world wide web;information retrieval;recommender system	Web+IR	-22.601517008612458	-49.2301672316566	26876
8b7f216d4ecd022b547837eaaccebf90224f569b	reconstructing self organizing maps as spider graphs for better visual interpretation of large unstructured datasets		-Self-Organizing Maps (SOM) are popular unsupervised artificial neural network used to reduce dimensions and visualize data. Visual interpretation from Self-Organizing Maps (SOM) has been limited due to grid approach of data representation, which makes inter-scenario analysis impossible. The paper proposes a new way to structure SOM. This model reconstructs SOM to show strength between variables as the threads of a cobweb and illuminate inter-scenario analysis. While Radar Graphs are very crude representation of spider web, this model uses more lively and realistic cobweb representation to take into account the difference in strength and length of threads. This model allows for visualization of highly unstructured dataset with large number of dimensions, common in Bigdata sources.	algorithm;artificial neural network;big data;data (computing);fastest;lively kernel;machine learning;map;organizing (structure);radar chart;scalability;scenario analysis	Aaditya Prakash	2013	CoRR		computer vision;computer science;artificial intelligence;machine learning;data mining	ML	-24.62877556917436	-32.28264906438947	26900
9e526e93a437ae77e4d5a6c8431ce2ebed3b3a1f	supporting system for quiz in large class - automatic keyword extraction and browsing interface	text mining;keyword extraction;e learning;natural language processing		browsing;keyword extraction	Haruhiko Takase;Hiroharu Kawanaka;Shinji Tsuruoka	2015	JACIII	10.20965/jaciii.2015.p0152	natural language processing;text mining;computer science;world wide web;information retrieval	EDA	-32.177621599368415	-48.57580441918165	26956
be732c7e090cba524c701f6052ae124770fef536	a framework for exploring multidimensional data with 3d projections	intuitive interactive exploration;projected data point;high-dimensional data;multidimensional data;visual space;user study;visual encodings;encoding data cluster;certain exploration task;visual exploration;multi-variate spatial data	Visualization of high-dimensional data requires a mapping to a visual spac e. Whenever the goal is to preserve similarity relations a frequent strategy is to use 2D projections, which afford in tuit ve interactive exploration, e.g., by users locating and selecting groups and gradually drilling down to individu al objects. In this paper, we propose a framework for projecting high-dimensional data to 3D visual spaces, ba ed on a generalization of the LeastSquare Projection (LSP). We compare projections to 2D and 3D visual sp aces both quantitatively and through a user study considering certain exploration tasks. The quantitative analysis confirms that 3D projections outperform 2D projections in terms of precision. The user study indicates that cer tain tasks can be more reliably and confidently answered with 3D projections. Nonetheless, as 3D projections are displayed on 2D screens, interaction is more difficult. Therefore, we incorporate suitable interaction functionalities nto a framework that supports 3D transformations, predefined optimal 2D views, coordinated 2D and 3D vie ws, and hierarchical 3D cluster definition and exploration. For visually encoding data clusters in a 3D setup, we em ploy color coding of projected data points as well as four types of surface renderings. A second user study evaluates the suitability of these visual encodings. Several examples illustrate the framework’s applicability for both v isual exploration of multidimensional abstract (non-spatial) data as well as the feature space of multi-variate sp atial data.non-spatial) data as well as the feature space of multi-variate sp atial data.	3d film;3d printing;3d projection;cer computer;cluster analysis;data point;feature vector;hierarchical clustering;interaction;orthographic projection;usability testing	Jorge Poco;Ronak Etemadpour;Fernando Vieira Paulovich;Tran Van Long;Paul Rosenthal;Maria Cristina Ferreira de Oliveira;Lars Linsen;Rosane Minghim	2011	Comput. Graph. Forum	10.1111/j.1467-8659.2011.01960.x	computer vision;computer science;machine learning;data mining	ML	-29.27663430736772	-33.93937165923436	27016
5760349d4c136411b2271b6f54bb5664d6c660c7	polar-an interactive patterns of life visualisation tool for intelligence analysis	knowledge acquisition behavioural sciences computing data visualisation;research outputs;interactive visualisation;spatial temporal;research publications;image color analysis geospatial analysis data visualization data mining conferences visualization educational institutions;multiple coordinated views;intelligence analysis;behaviour patterns;multiple coordinated views interactive visualisation patterns of life intelligence analysis spatial temporal behaviour patterns;patterns of life;polar visualisation tool pol questions geo temporal dataset knowledge elicitation intelligence analysis patterns of life analysis	POLAR is an experimental test-bed visualisation tool for Patterns of Life analysis, developed on the basis of knowledge elicitation with stakeholders. It uses multiple and coordinated views for exploring geo-temporal datasets. The system has three modes of interaction for addressing different kinds of PoL questions. It supports the exploration of movement patterns with resolutions ranging from intercontinental to local travel and a year or more to just a few minutes.	testbed	Neesha Kodagoda;Simon Attfield;Phong H. Nguyen;Leishi Zhang;Kai Xu;B. L. William Wong;Adrian Wagstaff;Graham Phillips;James Bullock;John Marshall;Stewart Bertram	2014	2014 IEEE Joint Intelligence and Security Informatics Conference	10.1109/JISIC.2014.72	intelligence analysis;interactive visualization;computer science;data science;data mining;multimedia	Visualization	-23.58774809206066	-33.850920327725945	27086
75ab106537974ea380dcc95711615003328b36a2	deep graph clustering in social network	community detection;attributes association;graph clustering	In this paper, we present deep attributes residue graph algorithm (DARG), a novel model for learning deep representations of graph. The algorithm can discover clusters by taking into consideration node relevance. DARG does so by first learns attributes relevance and cluster deep representations of vertices appearing in a graph, unlike existing work, integrates content interactions of the nodes into the graph learning process. First, the relevance of contents between each node pair within the network is abstracted. Then we turn the problem of computing the first k eigenvectors in spectral clustering into a computing deep representations task. This model just need learns content information to represent vertices appearing in a graph and without the need for considering topological information. Such content information is much easier to obtain than topological links in the real world. We conduct an experiment on SNAP Facebook dataset, empirical results demonstrate that proposed approach significantly outperforms other state-of-the-art methods in such task.	algorithm;cluster analysis;interaction;list of algorithms;relevance;social network;spectral clustering;vertex (geometry)	Pengwei Hu;Keith C. C. Chan;Tiantian He	2017		10.1145/3041021.3051158	correlation clustering;fuzzy clustering;computer science;machine learning;pattern recognition;data mining;clustering coefficient;cluster analysis;single-linkage clustering;world wide web;graph database	AI	-15.444911134326233	-45.116327079039245	27093
df76173947757b881b52145e80ad970026b8a8f3	mining social networks for anomalies: methods and challenges	anomaly detection;graph anomaly detection;graph mining;outlier detection;online social networks;social network analysis	Online social networks have received a dramatic increase of interest in the last decade due to the growth of Internet and Web 2.0. They are among the most popular sites on the Internet that are being used in almost all areas of life including education, medical, entertainment, business, and telemarketing. Unfortunately, they have become primary targets for malicious users who attempt to perform illegal activities and cause harm to other users. The unusual behavior of such users can be identified by using anomaly detection techniques. Anomaly detection in social networks refers to the problem of identifying the strange and unexpected behavior of users by exploring the patterns hidden in the networks, as the patterns of interaction of such users deviate significantly from the normal users of the networks. Even though a multitude of anomaly detection methods have been developed for different problem settings, this field is still relatively young and rapidly growing. Hence, there is a growing need for an organized study of the work done in the area of anomaly detection in social networks. In this paper, we provide a comprehensive review of a large set of methods for mining social networks for anomalies by providing a multi-level taxonomy to categorize the existing techniques based on the nature of input network, the type of anomalies they detect, and the underlying anomaly detection approach. In addition, this paper highlights the various application scenarios where these methods have been used, and explores the research challenges and open issues in this field.	social network	P. V. Bindu;P. Santhi Thilagam	2016	J. Network and Computer Applications	10.1016/j.jnca.2016.02.021	anomaly detection;social network analysis;computer science;machine learning;data mining;internet privacy;computer security	Metrics	-20.16671862338325	-43.62507414889669	27123
71a4ea5717068d9b3e89d7f03875f209a83d7b51	experiments on graph clustering algorithms	graph theory;decomposition domaine;analyse amas;teoria grafo;cluster;densite;descomposicion grafo;domain decomposition;amas;graph clustering;descomposicion dominio;densidad;classification;theorie graphe;cluster analysis;graph partitioning;analisis cluster;inproceedings;monton;experimental evaluation;density;clasificacion;graph decomposition;decomposition graphe	A promising approach to graph clustering is based on the intuitive notion of intra-cluster density vs. inter-cluster sparsity. While both formalizations and algorithms focusing on particular aspects of this rather vague concept have been proposed no conclusive argument on their appropriateness has been given. As a first step towards understanding the consequences of particular conceptions, we conducted an experimental evaluation of graph clustering approaches. By combining proven techniques from graph partitioning and geometric clustering, we also introduce a new approach that compares favorably.	algorithm;cluster analysis;conductance (graph);experiment;global motion compensation;graph partition;loss function;macintosh common lisp;monte carlo localization;norm (social);optimization problem;optimizing compiler;refinement (computing);sparse matrix;time complexity;unintended consequences;vagueness	Ulrik Brandes;Marco Gaertler;Dorothea Wagner	2003		10.1007/978-3-540-39658-1_52	correlation clustering;constrained clustering;combinatorics;discrete mathematics;fuzzy clustering;biological classification;density;computer science;graph partition;graph theory;clustering coefficient;mathematics;domain decomposition methods;moral graph;cluster analysis;algorithm;cluster	DB	-9.001451031320475	-44.34190960692155	27138
e4f8a7fe03f79acd5202311b3711dcdf27bd5194	a simply study to steganography on social networks		Steganography aims to conceal the very fact that the communication takes place, by embedding a message into a digit object such as image without introducing noticeable artifacts. A number of steganographic systems have been developed in past years, most of which, however, are confined to the laboratory conditions where the real-world use of steganography are rarely concerned. In this paper, we introduce an alternative perspective to steganography. A graph-theoretic model to steganography on social networks is presented to analyze real-world steganographic scenarios. In the graph, steganographic participants are corresponding to the vertices with meaningless unique identifiers. Each edge allows the two vertices to communicate with each other by any steganographic algorithm. Meanwhile, the edges are associated with weights to quantize the corresponding communication risk (or say cost). The optimization task is to minimize the overall risk, which is modeled as additive over the social network. We analyze different scenarios on a social network, and provide the suited solutions to the corresponding optimization tasks. We prove that a multiplicative probabilistic graph is equivalent to an additive weighted graph. From the viewpoint of an attacker, he may hope to detect suspicious communication channels, the data encoder(s) and the data decoder(s). We present limited detection analysis to steganographic communication on a network.	algorithm;benchmark (computing);experiment;graph theory;mathematical optimization;optimization problem;quantization (signal processing);social network;social network analysis;steganography;synthetic data;systems engineering;unique identifier;utility functions on indivisible goods;vertex (geometry);weighted network	H. Wu;Weiwei Wang;J. Dong;Huaqing Wang	2017	CoRR		theoretical computer science;encoder;steganography;computer science;vertex (geometry);unique identifier;embedding;probabilistic logic;social network;communication channel	ML	-12.94507054948692	-40.21179504799185	27159
782765fb595a378c3b57ccf1921860963a7663b9	discovery of maximum length frequent itemsets	optimization technique;search space;fp tree;large data sets;data mining;frequent itemset;maximum length frequent itemsets;tree structure;frequent itemsets;association analysis	The use of frequent itemsets has been limited by the high computational cost as well as the large number of resulting itemsets. In many real-world scenarios, however, it is often sufficient to mine a small representative subset of frequent itemsets with low computational cost. To that end, in this paper, we define a new problem of finding the frequent itemsets with a maximum length and present a novel algorithm to solve this problem. Indeed, maximum length frequent itemsets can be efficiently identified in very large data sets and are useful in many application domains. Our algorithm generates the maximum length frequent itemsets by adapting a pattern fragment growth methodology based on the FP-tree structure. Also, a number of optimization techniques have been exploited to prune the search space. Finally, extensive experiments on real-world data sets validate the proposed algorithm.	algorithm;algorithmic efficiency;application domain;association rule learning;benchmark (computing);cluster analysis;consistent pricing process;experiment;ftc fair information practice;file inclusion vulnerability;mathematical optimization;recursion;requirement;route inspection problem;scalability;tree (data structure);tree structure	Tianming Hu;Sam Yuan Sung;Hui Xiong;Qian Fu	2008	Inf. Sci.	10.1016/j.ins.2007.08.006	computer science;genetic association;pattern recognition;data mining;database;tree structure	ML	-6.118873224600909	-36.84109250999753	27168
f5df61effe8047eb9ea1702cfcc268dbba678567	differential dataflow		Existing computational models for processing continuously changing input data are unable to efficiently support iterative queries except in limited special cases. This makes it difficult to perform complex tasks, such as social-graph analysis on changing data at interactive timescales, which would greatly benefit those analyzing the behavior of services like Twitter. In this paper we introduce a new model called differential computation, which extends traditional incremental computation to allow arbitrarily nested iteration, and explain—with reference to a publicly available prototype system called Naiad—how differential computation can be efficiently implemented in the context of a declarative dataparallel dataflow language. The resulting system makes it easy to program previously intractable algorithms such as incrementally updated strongly connected components, and integrate them with data transformation operations to obtain practically relevant insights from real data streams.	algorithm;computation;computational model;dataflow programming;dynamic problem (algorithms);incremental computing;iteration;prototype;social graph;strongly connected component	Frank McSherry;Derek Gordon Murray;Rebecca Isaacs;Michael Isard	2013				DB	-10.607827501770332	-39.68634192523053	27201
5640a9618d8f2a3af6298c6ec76f7c8c00c344bc	tailoring music recommendations to users by considering diversity, mainstreaminess, and novelty	user modeling;music information retrieval;evaluation;music recommendation;recommender systems	A shortcoming of current approaches for music recommendation is that they consider user-specific characteristics only on a very simple level, typically as some kind of interaction between users and items when employing collaborative filtering. To alleviate this issue, we propose several user features that model aspects of the user's music listening behavior: diversity, mainstreaminess, and novelty of the user's music taste. To validate the proposed features, we conduct a comprehensive evaluation of a variety of music recommendation approaches (stand-alone and hybrids) on a collection of almost 200 million listening events gathered from \propername{Last.fm}. We report first results and highlight cases where our diversity, mainstreaminess, and novelty features can be beneficially integrated into music recommender systems.	collaborative filtering;recommender system	Markus Schedl;David Hauger	2015		10.1145/2766462.2767763	user modeling;computer science;evaluation;machine learning;multimedia;world wide web;recommender system	Web+IR	-27.85164366602379	-47.75136798321719	27275
15c78b7898e25f79a876f530de106b91667a24a4	the road extension model in the land change modeler for ecological sustainability of idrisi	road network;land use policy;pattern;model performance;regional scale;location;land change model;spatial pattern;gis;land use;biodiversity loss;growth process	Road development is an important proximate cause of deforestation and consequent biodiversity loss. The interaction between road extension and land use calls for an integration of road simulation into land change models to improve model performance. To date there have been few attempts to simulate road development to support land change modeling. The objective of this research is to develop a road extension model to simulate roads network expansion. This road extension model forecasts the location of individual roads at local scale and produces the given spatial pattern of road network at regional scale. Locating individual roads is divided into two consecutive steps, identifying endpoints and locating routes. Spatial pattern is controlled through altering the local road growth process, specifically limiting the number and locations of endpoints. The road extension model was released in 2006 as a component of the Land Change Modeler for Ecological Sustainability in IDRISI 15.0 (the Andes Edition). The model was applied to simulate scenarios of different road placement strategies in lowland Bolivia. The model results showed that the simulated road network exhibited varying spatial arrangements under different pattern parameter settings. The result provides insights into the ecological consequence of human land use policies. It also calls for an empirical based pattern parameter specification to predict road expansion that maintains existing network patterns.	simulation;spatiotemporal pattern;terrset geospatial monitoring and modeling software	Ziying Jiang	2007		10.1145/1341012.1341030	land use;common spatial pattern;geomatics;geography;mathematics;geometry;pattern;location;ecology	AI	-12.788284228671577	-24.236489853186562	27344
765e0291c26e378961090bbec6d9227c166979fb	context-aware collaborative prediction		In this chapter, we introduce the basic concepts of contextual information and collaborative prediction. Then, we introduce the scenarios of context-aware collaborative prediction and point out some limitations of the conventional methods. Finally, we introduce the tasks of collaborative prediction, on which we will compare the performance of our methods and conventional methods.		Shu Wu;Qiang Liu;Liang Wang;Tieniu Tan	2017		10.1007/978-981-10-5373-3	machine learning;feature learning;computer science;artificial intelligence	HCI	-17.59367652118515	-49.261672687981346	27348
5a2fc6b84a4f1354c519f8736e6f0b7b9fa4be64	queue-length estimation using real-time traffic data	detectors;convergence;length measurement;estimation;vehicles;bars;real time systems	We consider the problem of estimating queue-lengths at an intersection from a pair of advance and stop bar detectors that count vehicles, when these measurements are noisy and biased. The key assumption is that we know weather the queue is empty or not. We propose a real-time queue estimation algorithm based on stochastic gradient descent. The algorithm provably learns the detector bias, and efficiently estimates the queue-length with theoretical guarantee. The algorithm is tested in a simulation and in a case study using traffic data from an intersection in Beaufort, North Carolina.	algorithm;approximation algorithm;beaufort cipher;experiment;feedback;queue (abstract data type);real-time clock;sensor;simulation;small-bias sample space;stochastic gradient descent;throughput	Zahra Amini;Ramtin Pedarsani;Alexander Skabardonis;Pravin Varaiya	2016	2016 IEEE 19th International Conference on Intelligent Transportation Systems (ITSC)	10.1109/ITSC.2016.7795752	real-time computing;simulation;computer science;statistics	Robotics	-16.070227707265424	-29.89675075331839	27367
dfa1d52c849ee698e530e258d05e9417fcf668cd	identifying important segments in videos: a collective intelligence approach	user based;important segment detection;interaction;web;semantics;user activity;signal processing;video	This work studies collective intelligence behavior of Web users that share and watch video content. Accordingly, it is proposed that the aggregated users’ video activity exhibits characteristic patterns. Such patterns may be used in order to infer important video scenes leading thus to collective intelligence concerning the video content. To this end, experimentation is based on users’ interactions (e.g., pause, seek/scrub) that have been gathered in a controlled user experiment with information-rich videos. Collective information seeking behavior is then modeled by means of the corresponding probability distribution function. Thus, it is argued that the bell-shaped reference patterns are shown to significantly correlate with predefined scenes of interest for each video, as annotated by the users. In this way, the observed collective intelligence may be used to provide a video-segment detection tool that identifies the importance of video scenes. Accordingly, both a stochastic and a pattern matching approach are applied on the users’ interactions information. The results received indicate increased accuracy in identifying the areas selected by users as having high importance information. In practice, the proposed techniques might improve both navigation within videos on the web as well as video search results with personalised video thumbnails.	collective intelligence;data scrubbing;digital video;information seeking behavior;interaction;pattern matching;thumbnail	Ioannis Karydis;Markos Avlonitis;Konstantinos Chorianopoulos;Spyros Sioutas	2014	International Journal on Artificial Intelligence Tools	10.1142/S0218213014400107	computer vision;interaction;video;computer science;signal processing;video tracking;semantics;multimedia;world wide web	AI	-32.51179273352574	-50.63262595813674	27507
d6147a3ef91a6a59450c75e4fc1156f046f7a3e4	visualisation of hydrological observations in the water data transfer format	visualisation tool;hydrological data;wdtf;data transfer	The Bureau of Meteorology (the Bureau) and the Commonwealth Scientific and Industrial Research Organisation (CSIRO) have developed a Water Data Transfer Format (WDTF) to support the water industry to share and deliver water data to the Bureau as required under the Water Regulations 2008. The data in WDTF is stored into database through a data ingestion process. Until the data ingestion program is completed, there is no standard way to view data of WDTF. The Visualisation Tool is intended to serve the purpose of viewing and inspecting WDTF data in the interim for quality control. This tool also allows the user to explore WDTF (and in the future WaterML) data, including plotting and comparing both time series data and ratings and gauging data. Crown Copyright 2011 Published by Elsevier Ltd. All rights reserved. Software availability Name of software: WDTF Visualisation Tool Developers: Geoffrey Squire and Andrew Pratt Contact address: WIRADA and CSIRO Water for a Healthy Country Flagship, CSIRO, Canberra, ACT 2600, Australia Email: waterdata@bom.gov.au Availability and online documentation: Free download with manual and supportingmaterial at: http://www.bom.gov. au/water/regulations/wdtf/wdtfviewer.shtml Year first available: 2010 Operating system: Windows and Linux/Unix Programming language: Java 1.6	crown group;documentation;download;email;java;knuth–morris–pratt algorithm;linux;operating system;programming language;time series;unix	Spenser Kao;Kemachandra Ranatunga;Geoffrey Squire;Andrew Pratt;Dovey Dee	2011	Environmental Modelling and Software	10.1016/j.envsoft.2011.07.005	computer science;data science;data mining;database;data transmission	DB	-27.93763018420182	-28.912971190069413	27522
53e093763fd5b6ecd74dd42f434dfd8fdb747db1	hybrid parallel approach for personalized literature recommendation system	matrix factorization;mapreduce literature recommendation collaborative filtering topic model matrix factorization;matrix factorization hybrid parallel approach personalized literature recommendation system bookmarklet triggered literature sharing system bibliography functionality doi content negotiation services literature recommendation functionality latent dirichlet allocation lda collaborative filtering techniques implicit user feedback alternating least squares als;collaborative filtering;recommender systems collaborative filtering least squares approximations matrix decomposition parallel programming;mapreduce;literature recommendation;monitoring analytical models conferences vectors;topic model	Researchers regularly access and review large amounts of literatures. In the previous work, we presented a bookmarklet-triggered literature sharing system, which combines bibliography functionalities along with DOI content negotiation services. In this paper, we have made secondary development work to integrate literature recommendation functionalities into this system. We introduce a hybrid approach in parallel to recommend related articles to researchers. First, we collect a large amount of published and new articles using crawlers and RSS listeners to address cold start issue. Second, we adopt Latent Dirichlet Allocation (LDA) as the topic model to category literatures. For one kind of literatures related to researchers' interest, we use collaborative filtering techniques to make further analysis based on implicit user feedbacks in this system. Finally, we take matrix factorization with Alternating Least Squares (ALS) in parallel to compute the top-N recommendations per user.	bookmarklet;cold start;collaborative filtering;content negotiation;latent dirichlet allocation;least squares;personalization;rss;recommender system;topic model	Kun Ma;Tingting Lv;Ajith Abraham	2014	2014 6th International Conference on Computational Aspects of Social Networks	10.1109/CASoN.2014.6920428	computer science;artificial intelligence;data science;collaborative filtering;machine learning;data mining;topic model;matrix decomposition;world wide web;recommender system	Web+IR	-21.860543079655013	-48.91726145541144	27601
928d9d98147de2e8857d349ba67224d0be8e6e36	evaluating the usability of the scale metaphor for querying semantic spaces	digital documents;representacion conocimientos;base donnee;affichage;semantic spaces;systeme information geographique;geographic information system;visualizacion;methode echelle multiple;hierarchized structure;spatial scale;information visuelle;database;base dato;semantics;structure hierarchisee;metodo escala multiple;information visualization;information access;spatialization;semantica;semantique;scale;large scale;informacion visual;level of detail;display;spatial metaphors;visual information;indexation;data visualization;acces information;visualisation donnee;acceso informacion;multiscale method;group membership;semantic space;escala grande;knowledge representation;usability;representation connaissances;estructura jerarquizada;sistema informacion geografica;echelle grande	Information visualizations have become popular tools for extracting knowledge from large bodies of information. Very little is known on the usability of such ‘visual knowledge tools’ for information access. The goal of this paper is to show the usability of the spatial metaphor ‘scale’ to access a large semantic document space. An experiment was conducted to examine whether different user groups can associate graphical changes in resolution in spatialized views with changes of level of detail in an index hierarchy of a digital document collection. Test participants were asked to utilize zoom tools to explore a spatialized subset of the GeoRef database, an extensive collection of geology and earth sciences documents. The outcomes of the experiment suggest that people are able to associate graphical changes in resolution of spatialized views (zooms) with changes in levels of detail of a document collection (hierarchical order). These results are independent of user group membership, but for some displays it takes people longer to make a decision.	archive;georef;graphical user interface;information access;level of detail;spaces;spatial file manager;usability	Sara Irina Fabrikant	2001		10.1007/3-540-45424-1_11	scale;information visualization;usability;computer science;artificial intelligence;level of detail;data mining;database;semantics;geographic information system;world wide web;data visualization;cartography	HCI	-33.45411618434984	-28.050957844243225	27682
c552225a9dd90f83ace1a689f301706123574df4	visual people counting using gender features and lru updating scheme	people counting;gender classification;digital signage;computer vision	The general public spends a significant amount of time in front of digital signage seeking information from many venues such as exhibition halls and shopping centers. This is why advertisement purchasers believe that the number of passing viewers provides crucial information for their marketing strategies. In this paper, a real-time person counting/memorizing system is designed capable of distinguishing the gender of potential customers. An adaptive boosting (Adaboost) machine learning algorithm is used to detect human faces and utilize specific filtering criteria to eliminate useless data. For each detected person, face and torso information are recorded in a database for identification. The least recently used identification record will be deleted if the database is full. Gender classification is performed by support vector machine using hair ratios extracted from gender characterizing regions. Based on a variety of experiments, the accuracy of the proposed algorithm is higher than 90 % for person-counting and higher than 94 % for gender classification. Moreover, the execution speed on personal computers may reach 15–20 fps.	adaboost;algorithm;database;digital media;digital signage;experiment;face detection;heuristic;machine learning;nonlinear system;people counter;personal computer;projection screen;real-time computing;real-time locating system;stacking;statistical classification;support vector machine;web colors	Chen-Chiung Hsieh;Mansour Karkoub;Wei-Ru Lai;Po-Hong Lin	2013	Multimedia Tools and Applications	10.1007/s11042-013-1715-2	computer vision;simulation;telecommunications;computer science;machine learning;multimedia;world wide web;computer security	ML	-28.39184063894866	-42.96365949909837	27710
a2c47a7ebf88c14ef037beccdc1bb3423861b502	identifying aesthetic highlights in movies from clustering of physiological and behavioral signals	art;signal processing humanities pattern clustering;motion pictures;serveur institutionnel;acceleration;physiology;archive institutionnelle;streaming media;motion pictures physiology acceleration multimedia communication art streaming media affective computing;open access;multimedia communication;archive ouverte unige;cybertheses;institutional repository;affective computing;movies spectator reactions annotated aesthetic moments multimodal reaction profile humanities affective computing behavioral signal clustering physiological signal clustering	Affective computing is an important research area of computer science, with strong ties with humanities in particular. In this work we detail recent research activities towards determining moments of aesthetic importance in movies, on the basis of the reactions of multiple spectators. These reactions correspond to the multimodal reaction profile of a group of people and are computed from their physiological and behavioral signals. The highlight identification system using the reaction profile is evaluated on the basis of annotated aesthetic moments. The proposed architecture shows significant ability to determine moments of aesthetic importance, despite the challenges resulting from its operation in ecological situation, i.e. real-life recordings of the reactions of spectators watching a film in the movie theater.	affective computing;cluster analysis;computer science;ecology;multi-user;multimodal interaction;real life;sensor;user profile	Theodoros Kostoulas;Guillaume Chanel;Michal Muszynski;Patrizia Lombardo;Thierry Pun	2015	2015 Seventh International Workshop on Quality of Multimedia Experience (QoMEX)	10.1109/QoMEX.2015.7148098	acceleration;computer vision;simulation;telecommunications;computer science;affective computing;multimedia	HCI	-27.629158926133357	-41.95269747655739	27716
5dcf89340c937b3f6fee70d2eb2c3382e8f5a014	impact of fixed boundary conditions on the basins of attraction in the flower's morphogenesis of arabidopsis thaliana	basins of attraction;chemicals;boundary conditions biological systems biomembranes evolution biology lattices magnetic fields chemicals genetics plants biology lipidomics;magnetic fields;critical point;magnetic field;lattices;boundary conditions;genetic regulatory network;basin of attraction;lipidomics;chemical potential;genetics;biomembranes;arabidopsis thaliana;genetic regulatory network fixed boundary conditions basins of attraction morphogenesis arabidopsis thaliana biological systems toric networks biological networks;genetic algorithms botany boundary value problems;evolution biology;plants biology;basins of attraction complex systems biological networks boundary conditions;complex system;boundary condition;toric networks;biological systems;complex systems;genetic algorithms;boundary value problems;morphogenesis;biological networks;fixed boundary conditions;botany;biological network	Classically, theoretical studies focusing on biological systems are based on toric networks, which does not seem to be coherent with the biological reality. We think that the dynamics of biological networks is also regulated by fixed boundaries, illustrated for instance by external magnetic fields, chemical potentials or environmental constraints. The aim of this paper is to go further in the study of the impact of fixed boundary conditions by showing that they significantly affect the relative size of certain basins of attraction. We argue that this is a critical point in real biological networks by giving an example of boundary influence in the genetic regulatory network of the flower's morphogenesis of the plant Arabidopsis thaliana.	artificial neural network;biological network;biological system;boundary case;coherence (physics);critical point (network science);depth perception;dynamical system;gene regulatory network;selection rule;stochastic neural network	Jacques Demongeot;Michel Morvan;Sylvain Sené	2008	22nd International Conference on Advanced Information Networking and Applications - Workshops (aina workshops 2008)	10.1109/WAINA.2008.68	complex systems;biological network;magnetic field;boundary value problem	Robotics	-5.475815083287294	-47.49308815725995	27753
c9bfbacacb020c2c1300719ea3694b988ea5c523	identifying points of interest by self-tuning clustering	geographic information;web images;spectral clustering;point of interest	Deducing trip related information from web-scale datasets has received very large amounts of attention recently. Identifying points of interest (POIs) in geo-tagged photos is one of these problems. The problem can be viewed as a standard clustering problem of partitioning two dimensional objects. In this work, we study spectral clustering which is the first attempt for the POIs identification. However, there is no unified approach to assign the clustering parameters; especially the features of POIs are immensely varying in different metropolitans and locations. To address this, we are intent to study a self-tuning technique which can properly assign the parameters for the clustering needed.  Besides geographical information, web photos inherently store rich information. These information are mutually influenced each others and should be taken into trip related mining tasks. To address this, we study reinforcement which constructs the relationship over multiple sources by iterative learning. At last, we thoroughly demonstrate our findings by web scale datasets collected from Flickr.	cluster analysis;flickr;iterative method;point of interest;scalability;self-tuning;spectral clustering	Yiyang Yang;Zhiguo Gong;U Hou LeongHou	2011		10.1145/2009916.2010034	constrained clustering;point of interest;fuzzy clustering;computer science;machine learning;data mining;cluster analysis;world wide web;information retrieval;spectral clustering	ML	-17.655657710846587	-48.11249256945987	27794
3922139c576fb48ce46f112f286d3e6fc50e63d2	natural language texts for a cognitive vision system	conceptual knowledge;system approach;road traffic;vehicle detection;cognitive vision;natural language;image sequence	Text-to-logicconversionis studiedin a systemapproach whichextractsaconceptual representationof temporaldevelopments within aroadtraffic scenerecordedby avideocamera.A FuzzyMetric TemporalHornLogic (FMTHL) facilitatesa schematicrepresentationof roadvehiclebehavior at intersections. Geometricresultsof a model-basedvehicledetectionandtrackingsubsystemareusedto interpretthis genericconceptualFMTHL representationin orderto obtaina conceptualdescriptionof the specificdevelopmentsin the recordedtraffic scene. Onetaskacceptsanaturallanguage(NL) Englishtext formulation of thegenericconceptual knowledgeandconvertsthis into theinternal FMTHL representation. This requiresto distinguishalgorithmically betweendiscourse-relatedandscheme-relatedNL statements. A separatesecondtaskcreatesasyntheticvideosequencefrom aNL text, usingasmuchaspossiblethesameapparatusasthefirst one.A comparisonbetweengenuineroadtraffic videosequences andthose generatedsyntheticallyallows to testboththetext-to-logic transformationandthe useof geometricknowledgerepresentedwithin the entiresystemfor imagesequencevaluationandsubsequent interpretation.Resultsobtainedby theexecutionof bothtasksarediscussed.	nl (complexity);natural language	Michael Arens;Artur Ottlik;Hans-Hellmut Nagel	2002			computer vision;simulation;computer science;artificial intelligence;machine learning;natural language	Vision	-25.84748465886624	-39.251967321048674	27843
141c66ef785e3cc765de90d8bb7b43598a9a8576	just-for-me: an adaptive personalization system for location-aware social music recommendation	context aware;social trends;music recommendation	In recent years, location-aware music recommendation is increasing in popularity, as more and more users consume music on the move. In this demonstration, we present an intelligent system, called Just-for-Me, to facilitate accurate music recommendation based on where user presents. Our system is developed based on a novel probabilistic generative model, which can effectively integrate the location contexts and global music popularity trends. This approach allows us to gain more comprehensive modeling on user preference and thus significantly enhances the music recommendation performance.	artificial intelligence;generative model;location awareness;personalization;recommender system	Zhiyong Cheng;Jialie Shen;Tao Mei	2014		10.1145/2600428.2611187	multimedia;world wide web	AI	-23.06739580884286	-46.62922085849408	28028
29e1da16114bed5088c85f5b56c0ce2ad1f5dba2	there is something beyond the twitter network	cascades size distribution;social networks;social network analysis;information diffusion;twitter	How information spreads through a social network? Can we assume, that the information is spread only through a given social network graph? What is the correct way to compare the models of information flow? These are the basic questions we address in this work. We focus on meticulous comparison of various, well-known models of rumor propagation in the social network. We introduce the model incorporating mass media and effects of absent nodes. In this model the information appears spontaneously in the graph. Using the most conservative metric, we showed that the distribution of cascades sizes generated by this model fits the real data much better than the previously considered models.	collaboration graph;fits;propagation delay;social network;software propagation	Andrzej Pacuk;Piotr Sankowski;Karol Wegrzycki;Piotr Wygocki	2016		10.1145/2914586.2914623	social network analysis;social science;network formation;computer science;dynamic network analysis;theoretical computer science;machine learning;data mining;sociology;world wide web;social network	Web+IR	-19.195862140115768	-42.44949953376891	28101
0a9504fbbe436175125b2c23b871dfb223f9bb36	online learning of spacecraft simulation models	simulation;machine learning;nasa;applications	Spacecraft simulation is an integral part of NASA mission planning, real-time mission support, training, and systems engineering. Existing approaches that power these simulations cannot quickly react to the dynamic and complex behavior of the International Space Station (ISS). To address this problem, this paper introduces a unique and efficient method for continuously learning highly accurate models from realtime streaming sensor data, relying on an online learning approach. This approach revolutionizes NASA simulation techniques for space missions by providing models that quickly adapt to real-world feedback without human intervention. A novel regional sliding-window technique for online learning of simulation models is proposed that regionally maintains the most recent data. We also explore a knowledge fusion approach to reduce predictive error spikes when confronted with making predictions in situations that are quite different from training scenarios. We demonstrate substantial error reductions up to 74% in our experimental evaluation on the ISS Electrical Power System and discuss the early deployment of our software in the ISS Mission Control Center (MCC) for ground-based simulations.	floor and ceiling functions;machine learning;mission control;real-time locating system;simulation;software deployment;systems engineering	Justin R. Thomas;Christoph F. Eick	2009			real-time computing;simulation;computer science;artificial intelligence;machine learning;information technology	Robotics	-14.002700077163908	-28.15402228851001	28104
290b0917b66e880b9bba8bfad1f93ee92a44b409	dynamic miss-counting algorithms: finding implication and similarity rules with confidence pruning	optimisation data mining information resources dictionaries very large databases;information resources;optimisation;web pages;large data sets dynamic miss counting algorithms implication rule discovery similarity rule discovery confidence pruning data set columns dynamic pruning techniques data scanning row counting optimization techniques memory size reduction world wide web access logs web page link graph news documents dictionary high confidence rules;optimization technique;web accessibility;large data sets;data mining;heuristic algorithms data mining computer science frequency dictionaries collaboration filtering association rules;dictionaries;very large databases	Dynamic Miss-Countingalgorithms are proposed, which find all implication and similarity rules with confidence pruning but without support pruning. To handle data sets with a large number of columns, we propose dynamic pruning techniques that can be applied during data scanning. DMC counts the numbers of rows in which each pair of columns disagree instead of counting the number of hits. DMC deletes a candidate as soon as the number of misses exceeds the maximum number of misses allowed for that pair. We also propose several optimization techniques that reduce the required memory size significantly. We evaluated our algorithms by using 4 data sets, i.e., Web access logs, Web page-link graph, News documents, and a Dictionary. These data sets have between 74,000 and 700,000 items. Experiments show that DMC can find high-confidence rules for such a large data sets efficiently.	algorithm;bigraph;column (database);dictionary;dynamic markov compression;internet access;mathematical optimization;web page	Shinji Fujiwara;Jeffrey D. Ullman;Rajeev Motwani	2000		10.1109/ICDE.2000.839449	computer science;machine learning;web accessibility;web page;data mining;database;information retrieval	ML	-7.843547497003786	-42.28302486958918	28109
86639fadf02274a77e8199db7852e559d860a405	automated data verification in a large-scale citizen science project: a case study	databases;biology computing;data filters;information filtering;biological system modeling;observers;birds;zoology biology computing data handling information filtering scientific information systems;species distribution modeling;observers biological system modeling birds predictive models data models mathematical model databases;mathematical model;ebird data automated data verification large scale citizen science project broad scale citizen science project bird observations data screen automated data quality filter data driven method outlier detection;predictive models;zoology;data quality;data handling;species distribution modeling applications citizen science crowdsourcing data quality data filters;citizen science;crowdsourcing;applications;scientific information systems;data models	Although citizen science projects can engage a very large number of volunteers to collect volumes of data, they are susceptible to issues with data quality. Our experience with eBird, which is a broad-scale citizen science project to collect bird observations, has shown that a massive effort by volunteer experts is needed to screen data, identify outliers and flag them in the database. The increasing volume of data being collected by eBird places a huge burden on these volunteer experts and other automated approaches to improve data quality are needed. In this work, we describe a case study in which we evaluate an automated data quality filter that improves data quality by identifying outliers and categorizing these outliers as either unusual valid observations or mis-identified (invalid) observations. This automated data filter involves a two-step process: first, a data-driven method detects outliers (ie. observations that are unusual for a given region and date). Next, we use a data quality model based on an observer's predicted expertise to decide if an outlier should be flagged for review. We applied this automated data filter retrospectively to eBird data from Tompkins Co., NY and found that that this automated process significantly reduced the workload of reviewers by as much as 43% and identifies 52% more potentially invalid observations.	categorization;citizen science;data quality;ebird	Jun Yu;Steve Kelling;Jeff Gerbracht;Weng-Keen Wong	2012	2012 IEEE 8th International Conference on E-Science	10.1109/eScience.2012.6404472	computer science;data science;data mining;database	SE	-25.203246431527813	-31.47673085654025	28111
1649319a0f2fc1cab0c0d37df967b6c67b2671dc	single separation analysis for clustered-dot halftones	printing;measurement;printers;presses;human visual system clustered dot halftoning irregularity graininess;printers measurement printing presses rendering computer graphics shape visualization;visualization;shape;rendering computer graphics	The goal of this paper is to investigate the effect of choosing a certain halftone screen on image graininess development and to establish the metrics for image graininess in high-end digital printing technologies. With the obtained knowledge, our model helps us choose the optimal periodicity matrices for designing regular or irregular clustered dot halftones. The main advantage of the proposed model lies in predicting the graininess ratios based solely on the periodicity matrix. We conduct an in-depth Fourier analysis, which exposes to us all the details regarding the spectrum of a desired halftone screen. Hence, at this stage of the design process, there is no need to generate the halftone screens themselves.	fourier analysis;printing;quasiperiodicity	Altyngul Jumabayeva;Tal Frank;Yotam Ben-Shoshan;Robert Ulichney;Jan P. Allebach	2016	2016 IEEE International Conference on Image Processing (ICIP)	10.1109/ICIP.2016.7533188	computer vision;visualization;shape;computer science;mathematics;measurement;computer graphics (images)	Robotics	-29.08050467499805	-37.33265897384726	28213
1a5a522b70eaaf7895491039c5fcb3e1e6ca80ac	an interactive storytelling model for non-player characters on electronic rpgs	bibliographies;computational modeling;phonocardiography;games;strips;adaptation models;context	Software-based RPG consists of traditional RPG themes and rules. However, the challenge of emulating the universe arises in the context of electronic RPGs. Moreover, such universe must be broad, be populated with interacting characters and allow exploration. Interactive Storytelling (IS) models are able to produce plots and interactive stories showing up proactive intelligent agents. This work proposes an IS model for electronic RPGs that takes into account its traditional counterpart. Our model includes a coherent scenario representation and an action system that considers time lapse. Moreover, itallows the description of autonomic characters which are ableto define goals, plans and make decisions. This paper also describes a case study constructed by means of a prototype implementation.	autonomic networking;autonomous robot;autonomous system (internet);coherence (physics);complexity;data validation;database;emulator;experiment;extensibility;intelligent agent;interaction;interactive storytelling;interactivity;np-completeness;optimistic concurrency control;population;precondition;prototype;rpg;simulation;theme (computing)	Artur O. R. Franco;José G. R. Maia;Joaquim A. M. Neto;Fernando de Carvalho Gomes	2015	2015 14th Brazilian Symposium on Computer Games and Digital Entertainment (SBGames)	10.1109/SBGames.2015.13	games;strips;simulation;computer science;artificial intelligence;machine learning;multimedia;computational model	AI	-31.45041014257472	-24.60272521652426	28234
6c80bcd778437915f5e1142e6a8b643047c0a104	exploring multiple evidence to infer users' location in twitter	location inference;network learning;twitter user location	Social networks are valuable sources of information to monitor real-time events, such as earthquakes and epidemics. For this type of surveillance, users location is an essential piece of information, but a substantial number of users choose not to disclose their geographical information. However, characteristics of the users’ behavior, such as the friends they associate with and the types of messages published may hint on their spatial location. In this paper, we present a method to infer the spatial location of Twitter users. Unlike the approaches proposed so far, we incorporate two sources of information to learn geographical position: the text posted by users and their friendship network. We propose a probabilistic approach that jointly models the geographical labels and Twitter texts of users organized in the form of a graph representing the friendship network. We use the Markov random field probability model to represent the network and learning is carried out through a Markov chain Monte Carlo simulation technique to approximate the posterior probability distribution of the missing geographical labels. We show the accuracy of the model in a large dataset of Twitter users, where the ground truth is the location given by the GPS position. The method is evaluated and compared to two baseline algorithms that employ either of these two types of information. The results obtained are significantly better than those of the baseline methods.	approximation algorithm;bag-of-words model;baseline (configuration management);flickr;friendship graph;global positioning system;graph (discrete mathematics);ground truth;hidden variable theory;information source;instagram;markov chain monte carlo;markov random field;monte carlo method;need to know;real-time locating system;robustness (computer science);simulation;social network;sparse matrix;statistical model;tf–idf	Erica C. Rodrigues;Renato Assunção;Gisele Lobo Pappa;Diogo Rennó;Wagner Meira	2016	Neurocomputing	10.1016/j.neucom.2015.05.066	machine learning;data mining;internet privacy;world wide web	ML	-22.321564805664984	-44.846067759019554	28267
4441da070bfa78a0e46dbcfa09b83646151aa10f	predicting twitter hashtags popularity level	standards;twitter tagging time series analysis frequency domain analysis oscillators standards feature extraction;frequency domain analysis;oscillators;time series analysis;feature extraction;viral hashtag twitter hashtags popularity level twitter streaming api adoption time series frequency domain analysis mean and standard deviation characteristics fourier transform spectrum ft spectrum wavelet transform spectrum wt spectrum;wavelet transforms fourier transforms frequency domain analysis social networking online time series;twitter;tagging	This paper investigates the problem of predicting Twitter hashtags popularity level. A data set of more than 18 million tweets containing 748 thousand hashtags has been prepared by using Twitter's Streaming API. Early adoption properties including profile of tweet authors and adoption time series are used to predict a tag's later popularity level. The followers count and tweets count are two such characteristics related to adopters' profile. On the other hand, two types of frequency domain analyses are used to augment the simple mean and standard deviation characteristics of the adoption time series. Fourier transform (FT) spectrum and wavelet transform (WT) spectrum are considered in this study. Experimental results show that WT spectrum improves the prediction result of viral hashtags while FT spectrum does not.	hashtag;streaming media;time series;wavelet transform	Shing-Hwang Doong	2016	2016 49th Hawaii International Conference on System Sciences (HICSS)	10.1109/HICSS.2016.247	speech recognition;feature extraction;computer science;time series;advertising;oscillation;world wide web;frequency domain;statistics	DB	-28.209123520735446	-45.93269803476578	28294
76f8e8591a0c6dfdebc08058521d053494c5b2ca	a topic trend on p2p based social media		This paper shows a topic trend on a P2P based Social Network Service. There is a text-based Social Network Service (SNS) named Mastodon. Mastodon is a peer-to-peer and open-source SNS. Many persons and companies run Mastodon instances. We consider that there is a topic trend for each node. In this paper, we collect text messages and infer topic trend on a Mastodon instance using Latent Dirichlet Allocation(LDA). The understanding a topic trend helps to choice an instance that a user should participate.	social media	Masaki Kohana;Hiroki Sakaji;Akio Kobayashi;Shusuke Okamoto	2017		10.1007/978-3-319-65521-5_105	latent dirichlet allocation;data mining;distributed computing;computer science;social network;social media	NLP	-23.23835152584822	-48.29447084891745	28468
a09780353a9c37d2fea094e18e5eb9ca06ce3f7b	pova: traffic light sensing with probe vehicles	optimisation;joint optimization problem;real time position state estimation;variable interval;real time speed state estimation;sensors;traffic light status detection;road traffic;real time;traffic light optimization;maximum a posterior estimation;optimization algorithm design and analysis heuristic algorithms sensors;trace driven experimentation;traffic management;maximum likelihood estimation;state estimation;large scale urban areas;optimization problem;large scale;maximum a posterior;statistical analysis;system design;heuristic algorithms;pova;traffic light sensing;trace driven experimentation pova traffic light sensing large scale urban areas traffic light status detection traffic management traffic light optimization real time vehicle navigation pervasive probe vehicles real time position state estimation real time speed state estimation statistical features maximum a posterior estimation joint optimization problem heuristic algorithm;real time vehicle navigation;map estimation;urban area;optimization;estimation error;optimal algorithm;pervasive probe vehicles;algorithm design and analysis;field study;heuristic algorithm;statistical features;statistical analysis maximum likelihood estimation optimisation road traffic state estimation	Traffic light sensing aims to detect the status of traffic lights which is valuable for many applications such as traffic management, traffic light optimization, and real-time vehicle navigation. In this work, we develop a system called POVA for traffic light sensing in large-scale urban areas. The system employs pervasive probe vehicles that just report real-time states of position and speed from time to time. POVA has advantages of wide coverage and low deployment cost. The important observation motivating the design of POVA is that a traffic light has a considerable impact on mobility of vehicles on the road attached to the traffic light. However, the system design faces three unique challenges: 1) Probe reports are by nature discrete while the goal of traffic light sensing is to determine the state of a traffic light at any time; 2) there may be a very limited number of probe reports in a given duration for traffic light state estimation; and 3) a traffic light may change its state with a variable interval. To tackle the challenges, we develop a new technique that makes the best use of limited probe reports as well as statistical features of light states. It first estimates the state of a traffic light at the time instant of a report by applying maximum a posterior estimation. Then, we formulate the state estimation of a light at any time into a joint optimization problem that is solved by an efficient heuristic algorithm. We have implemented the system and tested it with a fleet of around 4,000 probe taxis and 2,000 buses in Shanghai, China. Trace-driven experimentation and field study show that nearly 60 percent of traffic lights have an estimation error lower than 19 percent if 20,000 probe vehicles would be employed in the urban area of Shanghai. We further demonstrate that the estimation error rate is as low as 18 percent even when the number of available reports is merely 1 per minute.	algorithm;bus (computing);field research;heuristic (computer science);light field;mathematical optimization;optimization problem;pervasive informatics;real-time clock;real-time transcription;software deployment;systems design	Xuemei Liu;Yanmin Zhu;Minglu Li;Qian Zhang	2012	IEEE Transactions on Parallel and Distributed Systems	10.1109/INFCOM.2012.6195674	heuristic;optimization problem;algorithm design;active traffic management;simulation;computer science;sensor;maximum likelihood;field research;systems design	Mobile	-18.458438254484168	-29.60617175902399	28489
77a2e4fadbea2521240982fa28ba31b53933060d	centrality-aware link recommendations	link recommendations;node centrality;social networks;probabilistic networks	Link recommendations are critical for both improving the utility and expediting the growth of social networks. Most previous approaches focus on suggesting links that are highly likely to be adopted. In this paper, we add a different perspective to the problem by aiming at recommending links that also improve specific properties of the network. In particular, our goal is to recommend to users links that if adopted would improve their centrality in the network. Specifically, we introduce the centrality-aware link recommendation problem as the problem of recommending to a user u, k links from a pool of recommended links so as to maximize the expected decrease of the sum of the shortest path distances of $u$ to all other nodes in the network. We show that the problem is NP-hard, but our optimization function is monotone and sub-modular which guarantees a constant approximation ratio for the greedy algorithm. We present a fast algorithm for computing the expected decrease caused by a set of recommendations which we use as a building block in our algorithms. We provide experimental results that evaluate the performance of our algorithms with respect to both the accuracy of the prediction and the improvement in the centrality of the nodes, and we study the tradeoff between the two.	approximation algorithm;centrality;experiment;greedy algorithm;mathematical optimization;np-hardness;recommender system;shortest path problem;social network;monotone	Nikos Parotsidis;Evaggelia Pitoura;Panayiotis Tsaparas	2016		10.1145/2835776.2835818	machine learning;data mining;distributed computing;social network	AI	-16.256449396448954	-43.975106529224185	28605
b38efe79d871ec9fce903a6297113579377fffb1	genetically programmed strategies for chess endgame	chess;genetic program;genetic programming;evolving strategies;ge netic programming	Classical chess engines exhaustively explore moving possibilities from a chessboard configuration to choose what the next best move to play is. In this article we present a new method to solve chess endgames without using Brute-Force algorithms or endgame tables. We are proposing to use Genetic Programming to combine elementary chess patterns defined by a chess expert. We apply this method specifically to the classical King-Rook-King endgame. We show that computed strategies are both effective and generic for they manage to win against several opponents (human players and artificial ones such as the chess engine CRAFTY). Besides, the method allows to propose strategies that are clearly readable and useable for a purpose such as teaching chess.	algorithm;chess engine;genetic programming;human-readable medium;usability	Nicolas Lassabe;Stéphane Sanchez;Hervé Luga;Yves Duthen	2006		10.1145/1143997.1144144	genetic programming;simulation;computer science;artificial intelligence;machine learning;algorithm	ML	-27.16152643126803	-24.6112447460922	28826
9a583f3879d7795c0994516fafd7a0cfa9bd2355	in situ exploration of large dynamic networks	graph theory;data visualisation;dynamic graph data;data visualization;network theory graphs data visualisation graph theory;multi focus context dynamic graph data multiform visualization;multi focus context;wireless mesh networks large dynamic networks in situ exploration bot nets social networks visualization techniques network structure visual analysis visual representations mental map dynamic graph visualization model versioning;network theory graphs;multiform visualization;data visualization graphics;graphics;dynamic networks	The analysis of large dynamic networks poses a challenge in many fields, ranging from large bot-nets to social networks. As dynamic networks exhibit different characteristics, e.g., being of sparse or dense structure, or having a continuous or discrete time line, a variety of visualization techniques have been specifically designed to handle these different aspects of network structure and time. This wide range of existing techniques is well justified, as rarely a single visualization is suitable to cover the entire visual analysis. Instead, visual representations are often switched in the course of the exploration of dynamic graphs as the focus of analysis shifts between the temporal and the structural aspects of the data. To support such a switching in a seamless and intuitive manner, we introduce the concept of in situ visualization- a novel strategy that tightly integrates existing visualization techniques for dynamic networks. It does so by allowing the user to interactively select in a base visualization a region for which a different visualization technique is then applied and embedded in the selection made. This permits to change the way a locally selected group of data items, such as nodes or time points, are shown - right in the place where they are positioned, thus supporting the user's overall mental map. Using this approach, a user can switch seamlessly between different visual representations to adapt a region of a base visualization to the specifics of the data within it or to the current analysis focus. This paper presents and discusses the in situ visualization strategy and its implications for dynamic graph visualization. Furthermore, it illustrates its usefulness by employing it for the visual exploration of dynamic networks from two different fields: model versioning and wireless mesh networks.	botnet;embedded system;embedding;graph - visual representation;graph drawing;imagery;interactivity;license;mental mapping;mesh networking;seamless3d;social network;sparse matrix;timeline;wireless mesh network	Steffen Hadlak;Hans-Jörg Schulz;Heidrun Schumann	2011	IEEE Transactions on Visualization and Computer Graphics	10.1109/TVCG.2011.213	software visualization;computer vision;visual analytics;information visualization;interactive visual analysis;computer science;graphics;theoretical computer science;machine learning;data mining;mathematics;data visualization;statistics	Visualization	-28.601214328753233	-35.10782021628198	28903
60f4261a6a41309fddf3cb787df92f756ca1c472	smart multi-modal marine monitoring via visual analysis and data fusion	image processing;multi modal sensing;data fusion;spike detection;visual sensing;environmental monitoring	Estuaries and coastal areas contain increasingly exploited resources that need to be monitored, managed and protected efficiently and effectively. This requires access to reliable and timely data and management decisions must be based on analysis of collected data to avoid or limit negative impacts. Visually supported multi-modal sensing and data fusion offer attractive possibilities for such arduous tasks. In this paper, we demonstrate how an in-situ sensor network can be enhanced with the use of contextual image data. We assimilate and alter a state-of-the-art background modelling technique from the image processing domain in order to detect turbidity spikes in water quality sensor measurements automatically. We then combine this with visual sensing to identify abnormal events that are not caused by local activities. The system can potentially assist those charged with monitoring large scale ecosystems, combining real-time analytics with improved efficiency and effectiveness.	ecosystem;image processing;modal logic;real-time clock	Dian Zhang;Edel O'Connor;Timothy Sullivan;Kevin McGuinness;Fiona Regan;Noel E. O'Connor	2013		10.1145/2509896.2509903	computer vision;engineering;data mining;remote sensing	HCI	-11.872593443964819	-31.078159472440657	28956
99df2f094924d8ddb05f7e23d3378f7460e4a9ee	on applications of parameterized hyperplane partitioning	video retrieval system;metric space;indexation;content based searching;access method;similarity search	"""The efficient similarity search in metric spaces is usually based on several low-level partitioning principles, which allow filtering of non-relevant objects during the search. In this paper, we propose a parameterizable partitioning method based on the generalized hyperplane partitioning (GHP), which utilizes a parameter to adjust """"borders"""" of the partitions. The new partitioning method could be employed in the existing metric indexes that are based on GHP (e.g., GNAT, M-index). Moreover, we could employ the parameterizable GHP in the role of a new multi-example query type, defined as a partition determined by an available query object and several """"anti-example"""" objects. We believe that both applications of parameterizable GHP can soon take place in metric access methods and new query models."""	binary space partitioning;gnat;high- and low-level;similarity search	Jakub Lokoc;Tomás Skopal	2010		10.1145/1862344.1862370	mathematical optimization;discrete mathematics;topology;metric space;computer science;theoretical computer science;database;mathematics;programming language;access method	DB	-5.957922335512175	-43.006676982723945	28959
225d3c8aa86269c46c6827015e19268e4bbbe327	customized document research by a stigmergic approach using agents and artifacts		Document research in a digital corpus can be considered as a browsing process driven by some information needs. Such browses requires the use of traditional information retrieval tools to select relevant documents based on a query. But they can be improved by the use of customization and adaptation mechanisms in order to refine the representation of information needs. Several factors are useful to influence this customization: user profiles, browsing profiles, semantic proximity of documents, recommendations from other similar users, ... We propose in this article to treat this diversity of influence by a multiagent system interacting with a shared environment representing the users navigation. We follow a stigmergic approach in which the agents implement different customization factors and modify their shared environment to influence the representation of users needs and the browsing. This multiagent system has been implemented using an artifact layer for the environment.	stigmergy	Zina El Guedria;Laurent Vercouter	2015		10.1007/978-3-319-33509-4_4	data mining;personalization;information needs;computer science	NLP	-31.901697192942667	-49.20748018234377	29014
0362988fbfe5537675cccf413468c1da7da145f5	double percolation phase transition in clustered complex networks		We perform an extensive numerical study of the effects of clustering on the structural properties of complex networks. We observe that strong clustering in heterogeneous networks induces the emergence of a core-periphery organization that has a critical effect on their percolation properties. In such situation, we observe a novel double phase transition, with an intermediate phase where only the core of the network is percolated, and a final phase where the periphery percolates regardless of the core. Interestingly, strong clustering makes simultaneously the core more robust and the periphery more fragile. These phenomena are also found in real complex networks.	cluster analysis;complex network;emergence;numerical analysis;percolation theory;semantic network	Pol Colomer-de-Simon;Marián Boguñá	2014	CoRR		nanotechnology;condensed matter physics	AI	-16.006710906317235	-39.65660935216319	29020
f962f6182c141f1a0a580cd90fa52c52527b8515	audience prism: segmentation and early classification of visitors based on reading interests	segmentation;classification;digital media analytics;clustering;prediction	The largest Media and Entertainment (M&E) web portals today cater to more than 100 Million unique visitors every month. In Customer Relationship Management, customer segmentation plays an important role, with the goal of targeting different products for different segments. Marketers segment their customers based on customer attributes. In the non-subscription based media business, the customer is analogous to the visitor, the product to the content, and a purchase to consumption. Knowing which segment an audience member belongs to, enables better engagement. In this work, we address the problems: 1) How can we segment audience members of an M&E web property based on their media consumption interests? 2) When a new visitor arrives, how can we classify them into one of the above defined segments (without having to wait for consumption history)? We apply our proposed solution to a real world data-set and show that we can achieve coherent clusters and can predict cluster membership with a high level of accuracy. We also build a tool that the editors can find valuable towards understanding their audience.	coherence (physics);customer relationship management;high-level programming language;portals;unique user;web property	Lilly Kumari;Sunny Dhamnani;Akshat Bhatnagar;Atanu R. Sinha;Ritwik Sinha	2016		10.1145/2888451.2888459	engineering;marketing;multimedia;advertising	AI	-26.102370617587777	-45.38864830566044	29044
6e5d3eec24dd1fb5f95cbaae6f7949979e81e8f0	to draw a tree	computer graphics;engineering drawings;tree graphs computer graphics computer science rendering computer graphics data visualization engineering drawings humans tree data structures usa councils image generation;usa councils;tree data structures;tree graphs;image generation;data visualization;humans;computer science;rendering computer graphics	The quintessential goal of information visualization is depicting abstractions and relations for non-spatial data. A hierarchy is a particularly expressive abstraction that can be applied to a broad range of domains: the genealogical lineages of human descent, the functional decomposition of complex mechanical objects, the classification of knowledge, the evolutionary relationships between species. All of these hierarchical relationships are representable through the abstraction of a recursively defined tree. For this reason, trees occupy a place along with arrays, lists and graphs as one of the most important data structures in computer science. Considering the simple problem of how to effectively draw a tree uncovers many issues fundamental to information visualization. Different drawing styles emphasize different properties of trees, often in subtle ways. I will discuss how people think about trees, and thus what kinds of relationships a tree drawing can usefully convey. My discussion will include a review of many methods for drawing trees, including both historical examples from the sciences and techniques recently developed by researchers in information visualization.		Pat Hanrahan	2001		10.1109/INFVIS.2001.963272	scientific visualization;information visualization;visualization;computer science;theoretical computer science;data mining;mathematics;tree;programming language;computer graphics;tree;data visualization;statistics;computer graphics (images)	Robotics	-28.603610257218982	-32.45318047518534	29058
2315b20bb3736c605cc3246afc904a2a7c7f941c	modeling video viewing behaviors for viewer state estimation	gaze behavior;viewer state estimation;saliency dynamics	Human gaze behaviors when watching videos reflect their cognitive states as well as characteristics of the video scenes being watched. Our goal is to establish a method to estimate the viewer states from his/her eye movements toward general videos, such as TV news and commercials. The proposed method is based on a novel model of video viewing behaviors, which takes into account structural and statistical relationships between video dynamics, gaze dynamics and viewer states. This model realizes statistical learning of gaze information while considering dynamic characteristics of video scenes to achieve viewer-state estimation. In this paper, we present an overview of the viewer-state estimation method based on the model of video-viewing behaviors, including several past work done by the author's team.	machine learning	Ryo Yonetani	2012		10.1145/2393347.2396500	computer vision;computer science;multimedia;computer graphics (images)	Vision	-28.20671641815985	-41.41237944247591	29169
a10a7fc7f9f4648b285da0ede10ccc62b7129d34	fuzzy information retrieval based on multi-relationship fuzzy concept networks	busqueda informacion;fuzzy information retrieval;document descriptor;concept;document analysis;concept network;concept matrix;information retrieval;reseau concept;fuzzy relation;document descriptor matrices;matrice concept;reseau;satisfiability;negative association;red;multi relationship fuzzy concept networks;analyse documentaire;recherche information;fuzzy inference;transitive closure;analisis documental;descripteur document;owa operators;relation floue;article;relacion difusa;owa operator;concept matrices;network;concepto	In this paper, we present a new method for fuzzy information retrieval based on multi-relationship fuzzy concept networks. There are four kinds of fuzzy relationships in a multi-relationship fuzzy concept network, i.e., “fuzzy positive association” relationship, “fuzzy negative association” relationship, “fuzzy generalization” relationship and “fuzzy specialization” relationship. By performing fuzzy inferences based on the multi-relationship fuzzy concept network, the fuzzy information retrieval system can retrieve documents containing concepts that are not directly speci6ed by the user but are somehow related to the user’s query. In order to perform fuzzy inferences more e9ciently, we use concept matrices to represent the degrees of fuzzy relationships between concepts in a multi-relationship fuzzy concept network. By calculating the transitive closures of concept matrices, the implicit degrees of fuzzy relationships between concepts are obtained. Multiple degrees of satisfaction that a document satis6es the user’s query with respect to the fuzzy relationships between concepts are calculated. These satisfaction degrees are aggregated according to the user’s speci6cation to 6nd the most relevant documents with respect to the user’s query. The proposed fuzzy information retrieval method is more :exible and more intelligent than the one we presented in (IEEE Trans. Systems Man Cybernet.—Part B: Cybernet. 29(1) (1999) 126). c © 2002 Elsevier B.V. All rights reserved.	fuzzy concept;information retrieval;network model;partial template specialization;transitive closure	Shyi-Ming Chen;Yih-Jen Horng;Chia-Hoang Lee	2003	Fuzzy Sets and Systems	10.1016/S0165-0114(02)00464-5	fuzzy logic;fuzzy cognitive map;membership function;defuzzification;adaptive neuro fuzzy inference system;type-2 fuzzy sets and systems;fuzzy mathematics;fuzzy classification;computer science;artificial intelligence;fuzzy number;neuro-fuzzy;machine learning;fuzzy measure theory;data mining;mathematics;fuzzy set;fuzzy associative matrix;concept;transitive closure;fuzzy set operations;fuzzy control system;satisfiability	AI	-5.372734371986672	-26.000287967686123	29194
8c81ab215ad0486ca8d9e82c5ec45e04c7fdf39f	a framework to identify educational relevance in social networking posts	prediction algorithms;data mining;engineering profession;facebook;predictive models;data models	Social Networking Sites (SNS) have facilitated and promoted various ways by which end users can exhibit their daily life activities, personality traits, choices, preferences, and updates for future events. The recent era of SNS and related web based platforms have accumulated very important data points that contribute to mining and deep analysis of one's talent and ability to be utilized in real world effectively. This paper provides insight of social networking posts by various user age groups and correlates such data points to identify academic contents out of them. This work develops a forecast framework for individuals to identify their specific talents towards academic and real world. This work uses various social networking sites such as Facebook, Twitter, Google+, and LinkedIn to test the framework. Paper is concluded with promising results and associated discussion to support current and future direction. Related study is briefly provided to put this work in progress in context of recent research.	data mining;data point;database trigger;google+;job stream;library (computing);nonlinear system;performance;python;relevance;social engineering (security)	Muhammad Fahim Uddin	2016	2016 IEEE 7th Annual Ubiquitous Computing, Electronics & Mobile Communication Conference (UEMCON)	10.1109/UEMCON.2016.7777873	data modeling;simulation;prediction;human–computer interaction;computer science;data mining;predictive modelling;world wide web;computer security	HCI	-24.730853753649598	-47.1376022393057	29195
d8288322f32ee4501cef5a9b667e5bb79ebd7018	facing scalability: naming faces in an online social network	face naming;scaling up;graph based;face modeling;scalability;online social network;weak labeling	Automatically naming faces in online social networks enables us to search for photos and build user face models. We consider two common weakly supervised settings where: (1) users are linked to photos, not to faces and (2) photos are not labeled but part of a user’s album. The focus is on algorithms that scale up to an entire online social network. We extensively evaluate different graph-based strategies to label faces in both settings and consider dependencies. We achieve results on a par with a recent multi-person approach, but with 60 times less computation time on a set of 300K weakly labeled faces and 1.4 M faces in user albums. A subset of the faces can be labeled with a speed-up of over three orders of magnitude. & 2011 Elsevier Ltd. All rights reserved.	algorithm;computation;face (geometry);scalability;social network;supervised learning;time complexity	Ronald Poppe	2012	Pattern Recognition	10.1016/j.patcog.2011.12.018	scalability;computer science;theoretical computer science;machine learning	AI	-14.601283016484869	-45.22703479114048	29335
781617984608064a7baf53c2c8ed48a3098d0c85	enhancing the situation awareness of decision makers by applying case-based reasoning on streaming data	doctoral thesis	Data is generally expected to continue its exponential growth the next five to ten years. However, it is commonly agreed that the amount of data that currently exist is abundant and that there is still much to achieve with it. The industry, in general, has recognized both the growth and the need to analyze the data. This is also the case with oil well drilling operations. Currently, operators monitor oil well drilling operations manually by staring at real-time measurements visualized in a computer program as graphs. Having humans monitoring the drilling operations manually has its disadvantages, as people get bored, tired and distracted. In this thesis, we investigate whether real-time decision making can be improved by enhancing the decision maker’s situation awareness through applying case-based reasoning on streaming data. This thesis is not about automating decisions, but informing human decision makers about the current situation so that they can make an informed decision. A hybrid reasoning system that abstracts recognize symptoms in time-series data and describe the current situation using these is described. The current situation is compared to past problematic situations and the similar past situations are brought to the attention of the decision maker to support decisions. Furthermore, situation assessment, the process of acquiring an understanding of the current state of a situation, in oil well drilling is analyzed and described. There are four main contributions of the research effort presented in this thesis: (i) a case representation for drilling situations; (ii) a hybrid reasoning architecture that is capable of reasoning with real-time data streams; (iii) a similarity metric for sequences of complex events; and (iv) a knowledge level model of situations and situation assessment.	case-based reasoning;computer program;graph (discrete mathematics);knowledge level;real-time clock;real-time data;real-time locating system;reasoning system;stream (computing);the current;time complexity;time series	Odd Erik Gundersen	2014			computer science;knowledge management;data mining;management science	AI	-14.713058328716475	-29.87859749650909	29364
e6a739f73a2fe38aaddb0203cb3c27c1078dd20f	navigation system for product search	silicon;retail data processing;portals;pattern clustering;user interfaces pattern clustering portals recommender systems retail data processing;user product shopping experiences;web pages;product entity cube;user perception;satisfiability;recommendation system;user product shopping experiences product entity cube recommendation system product search portal query results navigational user interface hybrid object clustering skyline object ranking;product search portal;navigation;user profile;feature extraction;navigation recommender systems feedback portals asia collaboration filtering motion pictures web pages taxonomy;clustering algorithms;search problems;navigation system;query results;user interfaces;recommender systems;hybrid object clustering;cameras;skyline object ranking;navigational user interface	We demonstrate Product EntityCube, a product recommendation and navigation system. While the unprecedented scale of a product search portal enables to satisfy users with diverse needs, this scale also complicates product recommendation. Specifically, our target application poses a unique challenge of overcoming insufficient user profiles and feedbacks. To address this problem, we organize query results into clusters representing different user perceptions of similarity, and provide a navigational UI to handle personal interests. Specifically, we first discuss hybrid object clustering capturing diverse user interests from millions of Web pages and disambiguating different perceptions using feature-based similarity. We then discuss skyline object ranking to highlight interesting items at each cluster. Our demonstration illustrates how Product EntityCube can enrich user product shopping experiences.	association rule learning;cluster analysis;feedback;user interface;user profile;web page	Jongwuk Lee;Seung-won Hwang;Zaiqing Nie;Ji-Rong Wen	2010	2010 IEEE 26th International Conference on Data Engineering (ICDE 2010)	10.1109/ICDE.2010.5447780	navigation;feature extraction;computer science;web page;data mining;database;cluster analysis;silicon;user interface;world wide web;recommender system;satisfiability	DB	-31.788847955700188	-51.37209395336646	29467
9ac83d12f31349d3fbfb82beeb6f3185b58edfbd	highly scalable sequential pattern mining based on mapreduce model on the cloud	databases;unsolicited electronic mail;resource allocation;virtual machines cloud computing data mining parallel processing resource allocation trees mathematics;trees mathematics;data mining;virtual machines;big data;databases data mining unsolicited electronic mail algorithm design and analysis partitioning algorithms reactive power transforms;transforms;sequential pattern mining;mapreduce framework;load balancing sequential pattern mining algorithm iterative mapreduce framework cloud cluster data mining technique scalability problem big data spamc candidate pattern generation candidate pattern pruning lexical sequence tree parallel processing support counting cloud environment virtual machines transactional sequences;mapreduce framework sequential pattern mining big data cloud computing;algorithm design and analysis;parallel processing;cloud computing;partitioning algorithms;reactive power	Sequential pattern mining is an essential data mining technique that has been widely applied to many real world applications. However, traditional algorithms generally suffer from the scalability problem when dealing with big data. In this paper, we aim to significantly upgrade the scale and propose Sequential PAttern Mining algorithm based on MapReduce model on the Cloud (abbreviated as SPAMC). Derived from the prior SPAM algorithm, we design an iterative MapReduce framework to efficiently generate and prune candidate patterns when constructing the lexical sequence tree. This framework not only distributes the sub-tasks of tree construction to independent mappers in parallel, but also enables the parallel processing of support counting. We conduct extensive experiments on the cloud environment of 32 virtual machines with up to 12.8 million transactional sequences. Experimental results show that SPAMC can significantly reduce mining time with big data, achieve extremely high scalability, and provide perfect load balancing on the cloud cluster.	algorithm;apache hadoop;big data;cloud computing;data mining;experiment;iterative method;load balancing (computing);mapreduce;parallel computing;scalability;sequential pattern mining;virtual machine	Chun-Chieh Chen;Chi-Yao Tseng;Ming-Syan Chen	2013	2013 IEEE International Congress on Big Data	10.1109/BigData.Congress.2013.48	computer science;theoretical computer science;data mining;database	DB	-8.216999054340725	-40.99287743163122	29469
9a85284e05e1ce6a51aae7b9d44853b761fb5b25	deep collective classification in heterogeneous information networks		Collective classification has attracted considerable attention in the last decade, where the labels within a group of instances are correlated and should be inferred collectively, instead of independently. Conventional approaches on collective classification mainly focus on exploiting simple relational features (such as count and exists aggregators on neighboring nodes). However, many real-world applications involve complex dependencies among the instances, which are obscure/hidden in the networks. To capture these dependencies in collective classification, we need to go beyond simple relational features and extract deep dependencies between the instances. In this paper, we study the problem of deep collective classification in Heterogeneous Information Networks (HINs), which involves different types of autocorrelations, from simple to complex relations, among the instances. Different from conventional autocorrelations, which are given explicitly by the links in the network, complex autocorrelations are obscure/hidden in HINs, and should be inferred from existing links in a hierarchical order. This problem is highly challenging due to the multiple types of dependencies among the nodes and the complexity of the relational features. In this study, we proposed a deep convolutional collective classification method, called GraphInception, to learn the deep relational features in HINs. The proposed method can automatically generate a hierarchy of relational features with different complexities. Extensive experiments on four realworld networks demonstrate that our approach can improve the collective classification performance by considering deep relational features in HINs.	algorithm;autocorrelation;convolution;experiment	Yizhou Zhang;Yun Xiong;Xiangnan Kong;Shanshan Li;Jinhong Mi;Yangyong Zhu	2018		10.1145/3178876.3186106	machine learning;artificial intelligence;computer science;deep learning;hierarchy	Web+IR	-14.566105549540689	-46.519663474418685	29497
875602eb78c9c91fa9e6c470b2948b105e47c912	linking issue tracker with q&a sites for knowledge sharing across communities	androids humanoid robots semantics software service computing correlation training;stack overflow knowledge sharing citation graph semantic similarity temporal locality android issue tracker	Collaborative development communities and knowledge sharing communities are highly correlated and mutually complementary. The knowledge sharing between these two types of open source communities can be very beneficial to both of them. However, it is a great challenge to automate this process. Current studies mainly focus on knowledge acquisition in one type of community, and few of them have tackle this problem efficiently. In this paper we take Android Issue Tracker and Stack Overflow as a case to study the mutual knowledge sharing between them. We propose an automatic approach by integrating semantic similarity with temporal locality between Android issues and Stack Overflow posts based on the internal citation-graph to reveal the potential associations between them. Our approach explores the internal citations in communities for closely related posts or issues clustering, exploits the rich semantics in fine-grained information of issues and posts for associations building, and leverages the temporal correlations between issues and posts in-depth for associations ranking. Extensive experiments show that the precision of our approach reaches 62.51 percent for top 10 recommendations when recommending Stack Overflow posts to Android issues, and 66.83 percent in reverse.	android;citation graph;cluster analysis;experiment;exploit (computer security);issue tracking system;knowledge acquisition;locality of reference;open-source software;semantic similarity;stack overflow	Huaimin Wang;Tao Wang;Gang Yin;Cheng Yang	2018	IEEE Transactions on Services Computing	10.1109/TSC.2015.2473847	android (operating system);knowledge acquisition;semantic similarity;data mining;services computing;locality of reference;computer science;cluster analysis;exploit;knowledge sharing	SE	-17.239770380174622	-46.80738148090032	29607
fa8536bd5234f5494c283530f80d42701e7070c0	hallp: a hybrid active learning approach to link prediction task	active learning;link prediction;link mining	A new link prediction method using active learning technique, named HALLP, is proposed in this paper. The method provides the user with most useful examples from the large number of unlabeled examples (i.e. unlinked node pairs in the network) for query. Once labeled by users, these examples will be fed to the learner for the improvement of the link predictor in next round. The utility of an example is decided by its uncertainty measure calculated simultaneously by its local structure and its hierarchical structure in networks. Experiments indicate link prediction method can be improved with the use of active learning techniques and both the local structure and global structure are beneficial for selecting examples with high utility.	active learning (machine learning);baseline (configuration management);binary classification;experiment;kerrison predictor;machine learning;randomness;sampling (signal processing);semi-supervised learning;semiconductor industry;snapshot (computer storage);social network;sparse matrix;supervised learning;test set	Ke-Jia Chen;Jingyu Han;Yun Li	2014	JCP	10.4304/jcp.9.3.551-556	computer science;machine learning;pattern recognition;data mining;active learning	ML	-16.72813147868137	-49.052447954752765	29680
7d506ca84052afd013c22eb25f474d709c2caeb6	press: a novel framework of trajectory compression in road networks		Location data becomes more and more important. In this paper, we focus on the trajectory data, and propose a new framework, namely PRESS (Paralleled Road-Network-Based Trajectory Compression), to effectively compress trajectory data under road network constraints. Different from existing work, PRESS proposes a novel representation for trajectories to separate the spatial representation of a trajectory from the temporal representation, and proposes a Hybrid Spatial Compression (HSC) algorithm and error Bounded Temporal Compression (BTC) algorithm to compress the spatial and temporal information of trajectories respectively. PRESS also supports common spatial-temporal queries without fully decompressing the data. Through an extensive experimental study on real trajectory dataset, PRESS significantly outperforms existing approaches in terms of saving storage cost of trajectory data with bounded errors.	algorithm;block truncation coding;data compression;experiment	Renchu Song;Weiwei Sun;Baihua Zheng;Yu Zheng	2014	PVLDB	10.14778/2732939.2732940	simulation;computer science;theoretical computer science;data mining;database	DB	-15.372039875970211	-34.718671322465994	29758
eb02f3eb09ce754145c42253b994afd9ef63f389	a novel fuzzy gaussian-based dissimilarity measure for discovering similarity temporal association patterns		Mining temporal association patterns from time-stamped temporal databases, first introduced in 2009, remain an active area of research. A pattern is temporally similar when it satisfies certain specified subset constraints. The naive and apriori algorithm designed for non-temporal databases cannot be extended to find similar temporal patterns in the context of temporal databases. The brute force approach requires performing \(2^{n }\) true support computations for ‘n’ items; hence, an NP-class problem. Also, the apriori or fp-tree-based algorithms designed for static databases are not directly extendable to temporal databases to retrieve temporal patterns similar to a reference prevalence of user interest. This is because the support of patterns violates the monotonicity property in temporal databases. In our case, support is a vector of values and not a single value. In this paper, we present a novel approach to retrieve temporal association patterns whose prevalence values are similar to those of the user specified reference. This allows us to significantly reduce support computations by defining novel expressions to estimate support bounds. The proposed approach eliminates computational overhead in finding similar temporal patterns. We then introduce a novel dissimilarity measure, which is the fuzzy Gaussian-based dissimilarity measure. The measure also holds the monotonicity property. Our evaluations demonstrate that the proposed method outperforms brute force and sequential approaches. We also compare the performance of the proposed approach with the SPAMINE which uses the Euclidean measure. The proposed approach uses monotonicity property to prune temporal patterns without computing unnecessary true supports and distances.		Vangipuram Radhakrishna;Shadi Aljawarneh;Puligadda Veereswara Kumar;Kim-Kwang Raymond Choo	2018	Soft Comput.	10.1007/s00500-016-2445-y	discrete mathematics;machine learning;data mining;mathematics	NLP	-8.805729036648163	-35.75936374922721	29824
d8ef0e87be41151dce0de36bb10db34b38b62a76	adaptive distance measures for exploration and structuring of music collections		Music similarity plays an important role in many Music Information Retrieval applications. However, it has many facets and its perception is highly subjective – very much depending on a person’s background or retrieval goal. This paper presents a generalized approach to modeling and learning individual distance measures for comparing music pieces based on multiple facets that can be weighted. The learning process is described as an optimization problem guided by generic distance constraints. Three application scenarios with different objectives exemplify how the proposed method can be employed in various contexts by deriving distance constraints either from domain-specific expert information or user actions in an interactive setting.	benchmark (computing);computation;constrained optimization;constraint (mathematics);exemplification;information retrieval;mathematical optimization;optimization problem	Sebastian Stober	2011			computer vision;geography;multimedia;communication	AI	-33.461658114586655	-45.931573453083296	29829
2bc602a50d151249a7e8dca6a07a172e9ec8eef9	efficient anytime anywhere algorithms for closeness centrality in large and dynamic graphs	social network services;approximation algorithms;algorithm design and analysis heuristic algorithms social network services partitioning algorithms approximation algorithms data structures;centrality analysis;parallel and distributed processing;dynamic graphs;anytime algorithms social network analysis parallel and distributed processing centrality analysis dynamic graphs;data structures;heuristic algorithms;social network analysis;anytime algorithms;algorithm design and analysis;dynamism rates anytime anywhere algorithms dynamic graphs dynamic networks high performance architectures parallel distributed tools data structures large scale networks anytime anywhere framework distributed social network analysis algorithms graph analysis problems design algorithms network dynamism closeness centrality analysis edge deletions;partitioning algorithms;parallel algorithms graph theory graphs	Recent advances in social network analysis methodologies for large (millions of nodes and billions of edges) and dynamic (evolving at different rates) networks have focused on leveraging new high performance architectures, parallel/distributed tools and novel data structures. However, there has been less focus on designing scalable and efficient algorithms to handle the challenges of dynamism in large-scale networks. In our previous work, we presented an overarching anytime anywhere framework for designing parallel and distributed social network analysis algorithms that are scalable to large network sizes and can handle dynamism. A key contribution of our work is to leverage the anytime and anywhere properties of graph analysis problems to design algorithms that can efficiently handle network dynamism by reusing partial results, and by reducing re-computations. In this paper, we present an algorithm for closeness centrality analysis that can handle changes in the network in the form of edge deletions. Using both theoretical analysis and experimental evaluations, we examine the performance of our algorithm with different network sizes and dynamism rates.	anytime algorithm;baseline (configuration management);closeness centrality;cloud computing;computation;data structure;distributed social network;scalability;social network analysis;testbed	Eunice E. Santos;John Korah;Vairavan Murugappan;Suresh Subramanian	2016	2016 IEEE International Parallel and Distributed Processing Symposium Workshops (IPDPSW)	10.1109/IPDPSW.2016.215	network science;algorithm design;social network analysis;data structure;computer science;theoretical computer science;machine learning;analysis of parallel algorithms;distributed computing;approximation algorithm;algorithm	HPC	-11.399165291003229	-40.788032487053705	29863
61df6e4ef5a367f63ba9b3abf0537d281ed936d8	data-driven dynamic adaptation framework for multi-agent training game	training;procedural content;multi agent games;procedural content multi agent games online adaptivity emotion modeling;feature extraction;games;mathematical model;predictive models;neural nets computer games data handling multi agent systems;online adaptivity;adaptation models;food distribution training game data driven dynamic adaptation framework multiagent training game dynamic game circumstance artificial neural networks data driven prediction model;dynamic scheduling;emotion modeling;games adaptation models training predictive models feature extraction mathematical model dynamic scheduling	In this paper, we present a dynamic adaptation framework to adapt the game scenarios for a multi-agent training game. We consider the problem where a trainee has to practice along multiple objectives during the training, and each objective is assigned with a desired difficulty level. The proposed dynamic adaptation approach takes into account of individual player's playing ability as well as the dynamic game circumstance to determine how to adapt the game scenario. We utilize artificial neural networks to construct a data-driven prediction model to estimate the effect of taking certain adaptation to the game. Based on the prediction model, our adaptation framework can determine both the direction and quantity of the adaptation. The performance of the proposed framework is testified in a food distribution training game and the results demonstrate the effectiveness of our adaptation framework.	artificial neural network;experiment;feature model;multi-agent system	Haiyan Yin;Linbo Luo;Wentong Cai;Jinghui Zhong	2015	2015 IEEE/WIC/ACM International Conference on Web Intelligence and Intelligent Agent Technology (WI-IAT)	10.1109/WI-IAT.2015.79	games;simulation;dynamic priority scheduling;feature extraction;computer science;machine learning;mathematical model;predictive modelling;multimedia;simulations and games in economics education	Robotics	-25.690908310400175	-25.099412027605986	29875
88a7b699be7e38f714936370ce50356ce98d6de6	inferring metapopulation propagation network for intra-city epidemic control and prevention		Since the 21st century, the global outbreaks of infectious diseases such as SARS in 2003, H1N1 in 2009, and H7N9 in 2013, have become the critical threat to the public health and a hunting nightmare to the government. Understanding the propagation in large-scale metapopulations and predicting the future outbreaks thus become crucially important for epidemic control and prevention. In the literature, there have been a bulk of studies on modeling intra-city epidemic propagation but with the single population assumption (homogeneity). Some recent works on metapopulation propagation, however, focus on finding specific human mobility physical networks to approximate diseases transmission networks, whose generality to fit different diseases cannot be guaranteed. In this paper, we argue that the intra-city epidemic propagation should be modeled on a metapopulation base, and propose a two-step method for this purpose. The first step is to understand the propagation system by inferring the underlying disease infection network. To this end, we propose a novel network inference model called D 2 PRI, which reduces the individual network into a sub-population network without information loss, and incorporates the power-law distribution prior and data prior for better performance. The second step is to predict the disease propagation by extending the classic SIR model to a metapopulation SIR model that allows visitors transmission between any two sub-populations. The validity of our model is testified on a real-life clinical report data set about the airborne disease in the Shenzhen city, China. The D 2 PRI model with the extended SIR model exhibit superior performance in various tasks including network inference, infection prediction and outbreaks simulation.	airborne ranger;approximation algorithm;performance;population;real life;resident monitor;simulation;software propagation	Jingyuan Wang;Xiaojian Wang;Junjie Wu	2018		10.1145/3219819.3219865	artificial intelligence;computer science;data mining;machine learning;diseases transmission;metapopulation;generality;epidemic model;population;inference	ML	-18.375587858063195	-33.55597153142801	29958
ac8c60d42458e34bf1a58d4aee3afab36f8efa98	a delaunay diagram-based min-max cp-tree algorithm for spatial data analysis		Co-location patterns are the subsets of Boolean spatial features whose instances are often located in close geographic proximity. Neighborhood is a major challenge and a key part of spatial co-location pattern mining. In existing conventional models, the neighborhood was defined by the user which is not suitable for massive data set. The idea of this paper is to improve the performance of co-location mining by proposing novel neighborhood model and effective co-location algorithm for spatial data analysis. The first methodology is to model the neighborhood of spatial data by using Delaunay diagram geometry approach. Delaunay-based neighborhood model finds the neighborhoods dynamically and avoids user-based neighborhood. The second methodology is to present novel efficient Min-Max CP-Tree algorithm to discover precise co-location patterns from spatial data. The proposed co-location mining algorithm is effective and efficient for complex landslide spatial data. WIREs Data Mining Knowl Discov 2015, 5:142-154. doi: 10.1002/widm.1151	algorithm;delaunay triangulation;diagram;maxima and minima;spatial analysis	Venkatesan Meenakshi Sundaram;Arunkumar Thangavelu	2015	Wiley Interdiscip. Rev. Data Min. Knowl. Discov.	10.1002/widm.1151	theoretical computer science;data mining	DB	-6.862194311070688	-38.24205924566527	30020
29d0f0556502566f1615ff347b5f568bce46063a	edge weight prediction in weighted signed networks	social network services;prediction algorithms;weight measurement;online banking;correlation;wireless sensor networks	Weighted signed networks (WSNs) are networks in which edges are labeled with positive and negative weights. WSNs can capture like/dislike, trust/distrust, and other social relationships between people. In this paper, we consider the problem of predicting the weights of edges in such networks. We propose two novel measures of node behavior: the goodness of a node intuitively captures how much this node is liked/trusted by other nodes, while the fairness of a node captures how fair the node is in rating other nodes' likeability or trust level. We provide axioms that these two notions need to satisfy and show that past work does not meet these requirements for WSNs. We provide a mutually recursive definition of these two concepts and prove that they converge to a unique solution in linear time. We use the two measures to predict the edge weight in WSNs. Furthermore, we show that when compared against several individual algorithms from both the signed and unsigned social network literature, our fairness and goodness metrics almost always have the best predictive power. We then use these as features in different multiple regression models and show that we can predict edge weights on 2 Bitcoin WSNs, an Epinions WSN, 2 WSNs derived from Wikipedia, and a WSN derived from Twitter with more accurate results than past work. Moreover, fairness and goodness metrics form the most significant feature for prediction in most (but not all) cases.	algorithm;bitcoin;converge;distrust;fairness measure;mutual recursion;recursive definition;requirement;social network;time complexity;wikipedia	Srijan Kumar;Francesca Spezzano;V. S. Subrahmanian;Christos Faloutsos	2016	2016 IEEE 16th International Conference on Data Mining (ICDM)	10.1109/ICDM.2016.0033	wireless sensor network;prediction;theoretical computer science;machine learning;data mining;mathematics;computer security;correlation;statistics	ML	-18.00555693379259	-44.773802145631805	30047
178b10c66c8d2dff1dcf912f8b73f5c63a503f9b	contextualized mobile recommendation service based on interactive social network discovered from mobile users	service provider;social relationship;data mining;social network;social relation;telecommunication;context;mobile user;recommendation service	Personal context is the most significant information for providing contextualized mobile recommendation services at a certain time and place. However, it is very difficult for service providers to be aware of the personal contexts, because each person's activities and preferences are very ambiguous and depending on numerous unknown factors. In order to deal with this problem, we have focused on discovering social relationships (e.g., family, friends, colleagues and so on) between people. We have assumed that the personal context of a certain person is interrelated with those of other people, and investigated how to employ his neighbor's contexts, which possibly have a meaningful influence on his personal context. It indicates that we have to discover implicit social networks which express the contextual dependencies between people. Thereby, in this paper, we propose an interactive approach to build meaningful social networks by interacting with human experts. Given a certain social relation (e.g., isFatherOf), this proposed systems can evaluate a set of conditions (which are represented as propositional axioms) asserted from the human experts, and show them a social network resulted from data mining tools. More importantly, social network ontology has been exploited to consistently guide them by proving whether the conditions are logically verified, and to refine the discovered social networks. We expect these social network is applicable to generate context-based recommendation services. In this research project, we have applied the proposed system to discover the social networks between mobile users by collecting a dataset from about two millions of users.	social network	Jason J. Jung	2009	Expert Syst. Appl.	10.1016/j.eswa.2009.03.067	service provider;social relation;social learning;computer science;knowledge management;social heuristics;data mining;world wide web;social computing;social network	Mobile	-22.925504741674445	-45.01724503185962	30117
9c2fd78e80c805daae07fd9c6fbf5b5094a1a93f	what we breathe as we commute: from the perspective of a developing country	human health;public transport;air quality measurement	Air pollution is a serious threat to public health. The city residents often spend significant time in public transports owing to long traffic tailbacks. So, the air quality inside public transports is an important factor that needs to be considered for the welfare of city residents. In this paper, we study the air quality inside public transports in a metropolitan city from the perspective of a developing country. To capture the diversity of city life, we consider the variation in traffic pattern and public transports, and analyze the data in temporal and spatial domain. Our custom-built sensing module collects data at regular intervals and detects the presence of pollutants above recommendation level. Our temporal analysis shows that concentration of air pollutants inside different public transports do not remain consistent in peak and off-peak hours. Our analysis also reveals that public transports with lower fares are more exposed to air pollutants than those with higher fares.		Tusher Chakraborty;Taslim Arefin Khan;Mahmuda Naznin;Chowdhury Sayeed Hyder;A. B. M. Alim Al Islam	2016		10.1145/3001913.3006628	environmental health;environmental engineering;geography;transport engineering	HCI	-19.111950089451874	-32.59911579695015	30143
b86e680f1ed18a0667a0f7b012cd15af022bfa60	using learning features to find similar trajectories		In the last decade, the trajectories data have been collected by many applications and such trajectories contain rich information that can be used to detect events especially for anomaly event detections. However, there are still many challenges on this problem, the major one is how to identify the similar trajectories on semantic level. In this work, we extract the nature features from raw trajectories and use them to do the semantic trajectory similarity search. To achieve this, we propose a PLS algorithm to detect such semantic similar trajectories efficiently and effectively. We also leverage the DBSCAN to help extract the information from large trajectory data. The results of our algorithm are demonstrated by the real world dataset.		Peiguo Fu;Haozhou Wang;Kuien Liu;Xiaohui Hu;Hui Zhang	2016		10.1007/978-3-319-45835-9_26	data mining;computer science;feature extraction;dbscan;artificial intelligence;trajectory;pattern recognition;nearest neighbor search	NLP	-12.067007952209563	-34.95123642719301	30232
a7e08a2211d22401799ae64800ad45f781d7ea6b	modeling group dynamics using graphical models and tensor decompositions	social network services;tensile stress;hidden markov models tensile stress graphical models signal to noise ratio data models dictionaries social network services;tensors feature extraction graph theory hidden markov models pattern clustering;graphical models;hidden markov models;group information extraction group dynamics modelling graphical model tensor decomposition temporal pattern hidden markov model;dictionaries;signal to noise ratio;data models	We propose a general modeling framework for learning group dynamics in data collected from multiple information sources and over time. In particular, groups are characterized by specific temporal patterns based on hidden Markov models. Tensor decomposition techniques combined with graphical models are used to extract group information from the observed data.	graphical model;hidden markov model;markov chain	Lin Li;Ananthram Swami;Anna Scaglione	2014	2014 IEEE Global Conference on Signal and Information Processing (GlobalSIP)	10.1109/GlobalSIP.2014.7032228	markov chain;maximum-entropy markov model;variable-order bayesian network;computer science;machine learning;pattern recognition;graphical model;markov model;statistics;variable-order markov model	ML	-15.226370073260203	-47.799613032497795	30271
d1ad6b06de6ab238c3aac2463eef0b5a0a145db1	an approach to extract informative rules for web page recommendation by genetic programming	user navigational log;genetic program;web pages;genetic programming;association rule mining;association rule;clickstream;web page recommendation;context	SUMMARY Clickstreams in users’ navigation logs have various datawhich are related to users’ web surﬁng. Those are visit counts, stay times,product types, etc. When we observe these data, we can divide clickstreamsinto sub-clickstreams so that the pages in a sub-clickstream share more con-texts with each other than with the pages in other sub-clickstreams. In thispaper, we propose a method which extracts more informative rules fromclickstreams for web page recommendation based on genetic programmingand association rules. First, we split clickstreams into sub-clickstreamsby contexts for generating more informative rules. In order to split click-streams in consideration of context, we extract six features from users’ nav-igation logs. A set of split rules is generated by combining those featuresthrough genetic programming, and then informative rules for recommen-dation are extracted with the association rule mining algorithm. Throughexperiments, we verify that the proposed method is more eﬀective than theother methods in various conditions.		Jaekwang Kim;KwangHo Yoon;Jee-Hyong Lee	2012	IEICE Transactions	10.1587/transcom.E95.B.1558	association rule learning;computer science;data mining;world wide web;information retrieval	Web+IR	-30.075706259398356	-51.25157048668428	30373
70c6c64106b8d0fe22a3478cc671763c09dfda82	life and its close relatives	dissipative structures;autopoiesis;near life;thermodynamics;developmental systems theory	When driven by an external thermodynamic gradient, nonbiological physical systems can exhibit a wide range of behaviours usually associated with living systems. Consequently, Artificial Life researchers should be open to the possibility that there is no hard-and-fast distinction between the biological and the physical. This suggests a novel field of research: the application of biologists’ methods for studying organisms to simple “near-life” phenomena in non-equilibrium physical systems. We illustrate this with some examples, including natural dynamic phenomena such as hurricanes and human artefacts such as photocopiers. This has implications for the notion of agency, which we discuss.	artificial life;gradient;living systems;photocopier	Simon McGregor;Nathaniel Virgo	2009		10.1007/978-3-642-21314-4_29	biology;dissipative system;computer science;artificial intelligence;autopoiesis;developmental systems theory	HCI	-5.889010831727314	-47.26007117974418	30448
0b504a0165ea6e0eb438c87776eaffd4e8058683	new to online dating? learning from experienced users for a successful match	social network services;training;collaboration;receivers;image edge detection;recommender systems	Online dating arises as a popular venue for finding romantic partners in recent years. Many online dating sites adopt recommender systems to help their users. However, few of current research provides solutions to cold start problem, i.e., providing recommendations to new users. In this research, we propose a new approach of providing reciprocal online dating recommendations to new users. Specifically, we detect communities from existing users, match new users to these communities, and take advantage of reciprocal activities of those community members to provide recommendations to new users. Using data from a popular U.S. online dating site, experiments show that our approach greatly outperforms existing methods.	cold start;experiment;recommender system;venue (sound system)	Mo Yu;Xiaolong Zhang;Derek Kreager	2016	2016 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining (ASONAM)	10.1109/ASONAM.2016.7752276	computer science;multimedia;world wide web;recommender system;collaboration	HCI	-23.005739911638834	-48.32519252265667	30469
79d340aaad842a589199d2644a4f4c5f028f155d	incremental transformation of lattices: a key to effective knowledge discovery	extraction information;variable discreta;graph theory;teoria grafo;closure;discrete data;analisis datos;information extraction;donnee discrete;data mining;theorie graphe;graph transformation;data analysis;transformation graphe;fouille donnee;concept lattice;closure operator;decouverte connaissance;time use;binary relation;descubrimiento conocimiento;analyse donnee;cerradura;busca dato;extraccion informacion;fermeture;knowledge discovery	We show that a formal concept lattice L, with explicit generators, constitutes a viable medium for discrete, deterministic, data mining. All implications of interest can be found and extracted from L independent of the frequency of their occurance.More importantly, we show that these lattices can be grown from a binary relation R one row, or observation, at a time using a transformation that is based on the mathematical properties of the generators and faces of closed sets. Incremental growth is orders of magnitude faster than existing methods which rely on global closure operators.		John L. Pfaltz	2002		10.1007/3-540-45832-8_26	discrete mathematics;artificial intelligence;graph theory;closure;binary relation;mathematics;data analysis;information extraction;algorithm;closure operator	ML	-10.217729551991107	-38.46697265540046	30474
9516dd63400e765d89727d26e1bd8d3a83d7aeef	cosine-neighbourhood-refinement: towards a robust network formation mechanism	graph theory;cluster algorithm;motion pictures;peer to peer network;social networking online graph theory peer to peer computing;prediction algorithms;one dimensional sphere cosine neighbourhood refinement step robust network formation mechanism classical network formation problem peer to peer networks online social networks node similarity interest graph models planted partition model latent space model;social networking online;partitioning algorithms peer to peer computing motion pictures algorithm design and analysis robustness clustering algorithms prediction algorithms;clustering algorithms;network formation;robustness;online social network;graph model;peer to peer computing;high performance;algorithm design;algorithm design and analysis;partitioning algorithms	In this paper we consider the classical network formation problem where nodes want to connect to other nodes that have similar “interests”. This problem is of fundamental importance in the network formation of peer-to-peer networks and online social networks. For this problem, we study whether there exists an algorithm that is robust with respect to the underlying interest graph that models the similarity of nodes in the networks. With robust, we mean that the algorithm is simple and achieves high-performance for a variety of interest graph models. The concrete interest graph models that we consider are the widely used planted partition and latent space model. We propose a network formation mechanism based on a cosine-neighbourhood refinement step and formally show that it performs well for the planted partition model. In addition, it can be shown that this mechanism based on cosine-neighbourhood refinement step also performs well under a latent space model for a one-dimensional sphere. To the best of our knowledge, this is the first time that a network formation mechanism has been shown to be robust and perform well for both the planted partition and latent space model. The proposed algorithm is simple and can be implemented in a distributed or centralized manner.	algorithm;centralized computing;existential quantification;interest graph;ising model;network formation;peer-to-peer;refinement (computing);ring network;social network	Felix Ming;Fai Wong;Peter Marbach	2012	2012 Proceedings IEEE INFOCOM	10.1109/INFCOM.2012.6195542	algorithm design;computer science;graph partition;graph theory;theoretical computer science;machine learning;distributed computing	ML	-15.036187202406678	-42.79537824666507	30569
17e2d3262cbe01a23409fdd9e3300eb8e01248e0	privacy-preserving cooperative route planning	vehicle routing data privacy road traffic road vehicles;vehiclular ad hoc networks intelligent vehicles road traffic path planning communication channels cryptography;privacy risk privacy preserving route planning cooperative route planning street traffic internet of vehicles vehicular routing	Today's street traffic is still largely inefficient. Overburdened roads lead to congestions, accidents, and unnecessary pollution. The increasing interconnection of traffic participants into the Internet of Vehicles (IoV) has tremendous potential for improving this issue. Cooperative route planning, e.g., is a concept for optimizing vehicular routing on a global scale by gathering data about planned routes from interconnected vehicles. As in other IoV applications, the benefits of such a system come at the cost of an increased privacy risk for participating users. Published routes include both the current and the planned future locations of drivers and passengers-all highly sensitive pieces of information. In the scope of this paper, we demonstrate how cooperative route planning can be realized with strong privacy guarantees without significant cuts in utility or cost. According to our knowledge, this is the first work to consider in this issue. We propose a scheme by which vehicles can publish their intent to pass at specific waypoints at approximate times in an anonymous fashion. While providing complete unlinkability of published intentions to individual users, our scheme is protected against abuse, with misbehaving (i.e., lying) users quickly losing their right to participate.	approximation algorithm;cryptography;interconnection;malware;privacy;promise theory;routing;waypoint	Martin Florian;Sören Finster;Ingmar Baumgart	2014	IEEE Internet of Things Journal	10.1109/JIOT.2014.2361016	computer security;computer network	Mobile	-20.328679119401706	-26.696609949576512	30609
82fd6d75632ae9c438d6f78d5cd5ba28a39cf5e5	ontology-based blog collection and profile-based personalised ranking	blogger;personalisation;ranking;semantic web;blogs;ontology	Blogging plays a major role in today's social networking. Large numbers of blogs are available in the web. This becomes a tedious task for the user and the blogger, to search for a technical blog from a list of randomly appearing blogs. Thus a method is required to rank the blogs for the user, according to the relevance of the query. The existing works focus either on the behaviour of the blogger or the linking of one blog with another blog. This paper introduces a novel method of ranking blogs based on the relevance of the content to the query. The semantics of the query is analysed to rank the blogs. The proposed method also uses concept-based profiling, to enable the user to retrieve personalised content for the query. The experimental analysis shows that the proposed personalised semantic blog ranking PSBR is efficient in ranking the technical blogs for the user.	blog	Godfrey Winster Sathianesan;S. Swamynathan	2014	IJCAT	10.1504/IJCAT.2014.059122	ranking;ranking;computer science;semantic web;ontology;personalization;internet privacy;world wide web;information retrieval	NLP	-27.127855548357164	-50.65402551970725	30611
c5bbb13d9e7009390235f9a808b632c57afac997	the duplicated of partial content detection based on pso	checking;evaluation function;vibrations;evaluation function checking pso algorithm;strings similarity;pso;layout;algorithm;simulation experiment;accuracy;particle swarm optimisation partial content detection hybrid mutation pso algorithm strings similarity;hybrid mutation pso algorithm;partial content detection;string matching;layout vibrations accuracy;particle swarm optimisation;string matching particle swarm optimisation	It is discussed how to detect the duplicated of partial contents between two documents in this paper. There are some algorithms which can detect similarity among documents. But these algorithms cannot detect the duplicated of partial contents in documents. A new effective algorithm of the duplicated of partial contents detection in documents is put forward in this paper. The new algorithm is using PSO algorithm to search the optimized partial contents which is the most similar in two documents. For PSO algorithm, it provides the encoding of the particles. A new related coefficient of strings is defined for strings similarity. And the new evaluation function of PSO is designed based on the related coefficient function. The hybrid mutation PSO algorithm is used for searching the most similar partial contents quickly and accurately. The simulation experiments indicate that the algorithm can search the most similar partial contents in two documents effectively.	particle swarm optimization	Qingwei Ye;Dongxing Wu;Yu Zhou;Xiaodong Wang	2010		10.1109/BICTA.2010.5645302	mathematical optimization;theoretical computer science;machine learning;mathematics	EDA	-8.860513780193282	-45.75296015416069	30721
304450127c05ef00708a96591a393d7f5f261e3a	an innovative algorithm for mining multilevel association rules	multilevel association rules;database;association rules;data mining;algorithm;association rule	In this paper, we present a new algorithm for mining multilevel association rules which searches for interesting relationship among items in a given data set at multiple levels in an effective way. This algorithm group the items at data warehousing level for each branch of the decision tree and find the association between them which is effective on a large set of data items. It generates a smaller set of rules, with higher quality and lower redundancy in comparison with general approach of multilevel association rules.		H. Ravi Sankar;M. M. Naidu	2007			association rule learning;computer science;machine learning;pattern recognition;data mining;fsa-red algorithm;apriori algorithm	DB	-4.928972742494055	-36.65827323743607	30833
3e8dbfa088fe822c66d921003c4c30b82b96204c	a social matching system for an online dating network: a preliminary study	social network services;content based technique;online dating network;social matching;online dating social network analysis recommender systems social matching clustering;empirical analysis;social matching system;collaboration;hybrid technique social matching system online dating network recommender system content based technique collaborative filtering;prediction algorithms;social network services prediction algorithms collaboration strontium receivers australia computer science;strontium;receivers;recommender system;collaborative filtering;clustering;social networking online;online dating;success rate;social network analysis;computer science;social networking online recommender systems;recommender systems;hybrid technique;australia	Due to the change in attitudes and lifestyles, people expect to find new partners and friends via various ways now-a-days. Online dating networks create a network for people to meet each other and allow making contact with different objectives of developing a personal, romantic or sexual relationship. Due to the higher expectation of users, online matching companies are trying to adopt recommender systems. However, the existing recommendation techniques such as content-based, collaborative filtering or hybrid techniques focus on users explicit contact behaviors but ignore the implicit relationship among users in the network. This paper proposes a social matching system that uses past relations and user similarities in finding potential matches. The proposed system is evaluated on the dataset collected from an online dating network. Empirical analysis shows that the recommendation success rate has increased to 31% as compared to the baseline success rate of 19%.	baseline (configuration management);collaborative filtering;recommender system	Richi Nayak;Meng Zhang;Lin Chen	2010	2010 IEEE International Conference on Data Mining Workshops	10.1109/ICDMW.2010.36	social network analysis;strontium;prediction;computer science;collaborative filtering;machine learning;data mining;multimedia;internet privacy;cluster analysis;world wide web;recommender system;collaboration	AI	-23.011638060075377	-48.692217334647154	30923
78d96b85e3c1265225031995c9c9142c121f5db8	a visualization system for traffic violation using h2o random forests		Traffic violation is one of the major reasons of road safety preventions and traffic accidents, but the data is too large and complex. Thus, it is important to find useful information, build analysis models, and use interactive tools to understand the relevance, trends, and driving behaviors from the traffic violations data. In this paper, we will establish a traffic violations data analysis model and interactive and visualization platform for users by using historical traffic violation data of Taiwan in recent four years. First, we will focus on using the traffic violations data to understand the definitions and data types of violation attributes in order to exclude the data abnormality, including formatting errors and over-range. Second, we remove the attributes that have no effect on the classification through the violation data analysis and classification which were performed by using the random forest scheme on the H2O platform for those attributes with the most critical impacts. We also performed the spatial, temporal, and behavior analysis to find the features of serious violations. Analysis of violation discrepancy is performed for different time, space, and ages, and different traffic penalty rules for cars and motorcycles. By comparing the information from Taiwan’s northern, central, and southern regions, we also investigate in the regional differences in violations. After the analysis, we do the visualization to show the variety with the number of violations or the differences of violations rules. We use Highcharts and C# development tools to show the results of the analysis, and emphasize on the obvious differences of data such as Heatmap and PivotTable report. Finally, based on the analysis results, users can use the platform to find critical traffic violations, for examples, providing governments or police with information which strengthens the law enforcement and road construction of road safety in the future.	random forest	Chyi-Ren Dow;Zhe-Rong Lin;Kuan-Chieh Wang	2017		10.1007/978-3-319-58753-0_77	human–computer interaction;data classification;data science;data type;law enforcement;computer science;highcharts;random forest;disk formatting;visualization;traffic violation	Robotics	-16.485307339848582	-28.17616972334375	31056
aee4b12fafb5623200cddcaeb62887d7797de564	visugraph: un outil d'exploration de données relationnelles évolutives	alliance;réseau d'acteur;animation;graphe évolutif;semantic network;evolutionary graph;réseau sémantique;mots-clés : dessin de graphe;space/time analogy.;actor network;relational analysis;analyse relationnelle;analogie espace/temps. keywords : graph drawing	Visualization based on graph drawing is a powerful tool to analyze relational information evolution. It is based on big data corpora synthesis. It makes it possible to identify and to evaluate passed and current structures, and to deduce the future ones between actors and concepts. In this context, IRIT SIG team propose the strategic data analyzes platform Tetralogie and the gate Web Xplor dedicated to on line relational information navigation. VisuGraph tool adds to these two tools visualization and interactive relational data classification. We add to VisuGraph a fluid animation of graph representations of various periods, while emphasizing visually major elements and significant tendencies. We develop this approach while insisting on data structure, software ergonomics, graph drawing optimization and its animation. MOTS-CLÉS : Dessin de graphe, analyse relationnelle, réseau d’acteur, réseau sémantique, animation, alliance, graphe évolutif, analogie espace/temps.	big data;data structure;espace;fluid animation;graph drawing;human factors and ergonomics;mathematical optimization;text corpus	Eloïse Loubier;Sabine Carbonnel	2007			graph (abstract data type);big data;visualization;animation;natural language processing;relational database;data structure;graph database;artificial intelligence;computer science;graph drawing	Graphics	-32.792693319918314	-31.370196635120617	31082
8250a54ef7b8c0f3987d97fcd287a676184b3f48	gpsense: a gpu-friendly method for commonsense subgraph matching in massively parallel architectures		In the context of common-sense reasoning, spreading activation is used to select relevant concepts in a graph of common-sense knowledge. When such a graph starts growing, however, the number of relevant concepts selected during spreading activation tends to diminish. In the literature, such an issue has been addressed in different ways but two other important issues have been rather under-researched, namely: performance and scalability. Both issues are caused by the fact that many new nodes, i.e., natural language concepts, are continuously integrated into the graph. Both issues can be solved by means of GPU accelerated computing, which offers unprecedented performance by offloading compute-intensive portions of the application to the GPU, while the remainder of the code still runs on the CPU. To this end, we propose a GPU-friendly method, termed GpSense, which is designed for massively parallel architectures to accelerate the tasks of common-sense querying and reasoning via subgraph matching. We show that GpSense outperforms the state-of-the-art algorithms and efficiently answers subgraph queries on a large common-sense graph.	algorithm;backtracking;central processing unit;coalescing (computer science);commonsense reasoning;graphics processing unit;mathematical optimization;natural language;parallel computing;scalability;shared memory;spreading activation;subgraph isomorphism problem	Ha Nguyen Tran;Erik Cambria	2016		10.1007/978-3-319-75477-2_39	artificial intelligence;computer science;massively parallel;natural language processing;natural language;theoretical computer science;scalability;commonsense reasoning;central processing unit;remainder;commonsense knowledge;graph	AI	-8.75444338300701	-40.70740547315721	31124
07986677192509eb88e719c863da489ebc5121f6	improved model of social networks dynamics		Social networks are currently the most studied structures due to their popularity among IT users. In our paper we will focus on the dynamics of the dissemination of information in these networks. We will introduce the advanced heuristic conceptual model of individuals’ behavior in the network which is based on need for information and knowledge for solving specific problems; the proposed multi-agent model of the social networks dynamics is based on this concept. This version of the model was adapted for scale-free and growing networks. Experiments conducted with new model were focused on verifying its behavior with respect to knowledge about the type of modeled networks and on observation of dynamic effects in them; the results will be presented as well.	attachments;clustering coefficient;degree distribution;diversification (finance);experiment;heuristic;multi-agent system;simulation;social network;verification and validation	Jirí Jelínek;Roman Klimes	2016		10.5220/0005682701410148	conceptual model;machine learning;computer science;artificial intelligence;management science;dynamic network analysis;heuristic;social network;dissemination;popularity	AI	-19.790314990255364	-40.67053627173753	31127
67354e21928329be89405d0a6691c7d68eabf059	the use of simple graphs and cliques for analysis of cartographic eye-tracking data		Usability testing with the use of eye-tracking technology is now emerging. Measuring point of gaze is employed in different fields of research and helps to solve real world problems. One of these areas is cartography. In addition to traditional methods of analyses of eye-tracking data, as attention maps and gaze plots are, a more sophisticated method exists – scanpath comparison. Many different approaches to scanpath comparison exist. One of the most frequently used is String Edit Distance, where the gaze trajectories are replaced by the sequences of visited Areas of Interest. In cartography, these Areas of Interest could be marked around specific parts of maps – map composition elements. We have developed an online tool called ScanGraph which output is visualized as a simple graph, and similar groups of sequences are displayed as cliques of this graph. ScanGraph uses modified Levenshtein distance and Needleman-Wunsch algorithms for calculating the similarities between sequences of visited Areas of Interest. Cliques in the graph are sought with the use of the exhaustive algorithm. ScanGraph functionality is presented in the example of cartographic study dealing with uncertainty in maps. Stimuli in the study contained several visualization methods of uncertainty and eye-tracking experiment with 40 respondents was performed. With the use of ScanGraph, groups of participants with similar strategy were identified.	cartography;clique (graph theory);computation;edit distance;eye tracking;graph (discrete mathematics);levenshtein distance;map;needleman–wunsch algorithm;usability testing	Jitka Dolezalová;Stanislav Popelka	2016			data mining;eye tracking;computer science;graph	HCI	-30.212868992742422	-35.84128880165093	31186
f8126179fb036a87f3f5f6f3af36cd88feb284ba	watershed reanalysis: towards a national strategy for model-data integration	distributed hydrologic model;water resource;data integrity;web services climatology geology soil terrain mapping water resources;real time;water resources;web service;numerical watershed prediction nwp;web services climate reanalysis data analytics distributed hydrologic model numerical watershed prediction nwp pihm software as a service saas visual analytics;data storage;geology;web services;distributed hydrological model;data analytics;climate reanalysis;data models computational modeling web services numerical models atmospheric modeling meteorology soil;software as a service;terrain mapping;visual analytics;water resource prediction watershed reanalysis national strategy model data integration retrospective analysis reanalyzing climate observation weather observation virtualized web service national data product climate reanalysis soil geology terrain land cover water resource simulation data assimilation calibration archival national database computational resources virtualized service cloud cyber infrastructure;data assimilation;software as a service saas;soil;quantitative method;land cover;pihm;climatology	Reanalysis or retrospective analysis is the process of re-analyzing and assimilating climate and weather observations with the current modeling context. Reanalysis is an objective, quantitative method of synthesizing all sources of information (historical and real-time observations) within a unified framework. In this context, we propose a prototype for automated and virtualized web services software using national data products for climate reanalysis, soils, geology, terrain and land cover for the purpose of water resource simulation, prediction, data assimilation, calibration and archival. The prototype for model-data integration focuses on creating tools for fast data storage from selected national databases, as well as the computational resources necessary for a dynamic, distributed watershed prediction anywhere in the continental US. In the future implementation of virtualized services will benefit from the development of a cloud cyber infrastructure as the prototype evolves to data and model intensive computation for continental scale water resource predictions.	computation;computational resource;computer data storage;data assimilation;database;köppen climate classification;meteorological reanalysis;prototype;real-time locating system;simulation;unified framework;watershed (image processing);web service	Christopher J. Duffy;Lorne Leonard;Gopal Bhatt;Xuan Yu;C. Lee Giles	2011	2011 IEEE Seventh International Conference on e-Science Workshops	10.1109/eScienceW.2011.32	meteorology;geography;hydrology;remote sensing	Robotics	-13.335040309491518	-26.808710470987343	31237
2d72d520c53391f1133c395678bd8e62c0a34e6d	identifying rumor source of online social networks in the seir model		Rumor that propagates through online social networks can carry a lot of negative effects and even disturb the social order. This paper addresses the problem of detecting the rumor source in an online social network based on an observed snapshot. We assume the spreading of a rumor in the social networks follows the susceptible-exposed-infected-recovered (SEIR) model. All nodes are assumed initially in susceptible states, but only one single rumor source is in infected state. The susceptible node receives messages from its infected neighbor social nodes and it can be treated as exposed at each time-slot. Once an exposed node believes these received messages and forwarded them, it would turn into the infected state; otherwise, it would drop these messages and then it is considered as in the recovered state. It is assumed that the recovered nodes will never believe these information again. Given an observed snapshot of online social network, in which the susceptible nodes, exposed nodes and recovered nodes cannot be distinguished, the estimator is evaluated to identify the source associated with the most likely infection process based on induction hypotheses. The effectiveness of the proposed method is validated using experiments based on a tree networks and two real-world networks, and the results demonstrate that our estimator performs better than the existing closeness centrality heuristic.		Yousheng Zhou;Chujun Wu	2018		10.1007/978-3-030-00018-9_34	computer science;social order;estimator;snapshot (computer storage);information security;centrality;rumor;social network;heuristic;distributed computing	Metrics	-19.098315872827865	-42.57775201187156	31287
10c2bb9e58944e107d8c986a4c4d7e9c01d353d8	personalized tag recommendations to enhance user's perception	tagging collaboration uniform resource locators algorithm design and analysis books particle swarm optimization iterative algorithms communications technology computer science organizing;swarm intelligence;pheromone updating strategy;ant algorithm;data collection;ant colony;information filtering;collaboration;user perception;collaborative tagging systems;data mining;personalized tag recommendation;internet;tag clouds;web object label;world wide web;agriculture;cooccurrence graph;del icio us collaborative tagging systems swarm intelligence ant colony pheromone updating;communities;cooccurrence graph personalized tag recommendation user perception web object label pheromone updating strategy ant algorithm;collaborative tagging;pheromone updating;internet information filtering;del icio us	Tagging is a process whereby users freely choose keywords to label web objects in order to share or recover them later. Tags associated to an object by the user depict his viewpoint or perception. The perception of the target user can be enhanced by aggregating and analyzing the tags associated to an object by other users who share at least one tag with the target user in common for that object and recommending tags to him. Most of the existing techniques recommend tags on the basis of their popularity among the users. The proposed approach complement these approaches by taking the temporal nature of interests of the user into account and enhancing his perception by analyzing and finding relationship among the tags associated to an object by him and other users. This relationship is analyzed using pheromone updating strategy known from ant algorithms for computing the weights on the edges of the co-occurrence graph containing tags as nodes. To observe the performance of our approach, experiments are carried out on the data collected from del.icio.us, a social book marking site that allows the users to tag URLs and share them with other people.	algorithm;evaporation;experiment;item unique identification;machine perception;recommender system;tag (metadata);tag cloud	Ravish Sharma;Punam Bedi	2009	2009 International Conference on Advances in Recent Technologies in Communication and Computing	10.1109/ARTCom.2009.96	agriculture;swarm intelligence;computer science;ant colony;data mining;world wide web;information retrieval;data collection;collaboration	HCI	-26.28603887085538	-48.974154795328765	31328
9389652d924a0ddb4c995bc1513be96bb4c894ba	science of networks and music: a new approach on musical analysis and creation	modelizacion;generic algorithm;model analysis;musica;acoustique musicale;algoritmo genetico;musical acoustics;modelisation;musique;acustica musical;music analysis;algorithme genetique;autoorganizacion;algorithme evolutionniste;self organization;genetic algorithm;algoritmo evolucionista;melodia;evolutionary algorithm;small world network;modeling;scientific research;music;autoorganisation;melody;melodie	Science of Networks is a very young discipline whose results have rapidly influenced many different fields of scientific research. In this paper we present some experimentations of a new approach on generative music based on small-world networks. The basic idea of this work is that network can be a useful instrument for musical modeling, analysis and creation. We studied over 100 musical compositions of different genres (classical, pop, rock) by means of science of networks, then used this data for generating algorithms for musical creation and author attribution. The first step of this work is the implementation of a software that allows to represent and analyse musical compositions, then we developed a genetic algorithm for the production of networks with particular features. These networks are finally used for the generation of self-organized melodies and scales.		Gianfranco Campolongo;Stefano Vena	2006		10.1007/11732242_61	new interfaces for musical expression;genetic algorithm;computer science;artificial intelligence;evolutionary algorithm;algorithm	Theory	-5.58888087497791	-31.11009058062571	31362
38f35e2a5829b96421ff82b21d5302576f4ac937	a link strength based label propagation algorithm for community detection	social network services;attenuation;big data;taxonomy;stability analysis;sun;computational efficiency	The Label Propagation Algorithm (LPA) is a fast algorithm for community detection. This algorithm has proved its efficiency and scalability even in large social networks. It is basedonly on updating the label of each node by the most frequent label within its neighbors. However, in case of many maximal labels, a random choice is made. This reduces the performance of the algorithm. In this paper, we propose a new version of LPA, called Link Strength-based LPA (LS-LPA), that addresses this issue. In our approach, we rank labels according to the link strength of each neighbor. The strength of links is quantified via k-neighborhood which includes common neighbors and multi-step neighbors. Experiments on different networks with different sizes show that our solution improves LPA's performance significantly.	experiment;label propagation algorithm;maximal set;randomness;scalability;social network;software propagation	Abdallah Lakhdari;Aicha Chorana;Hadda Cherroun;Abdelmounaam Rezgui	2016	2016 IEEE International Conferences on Big Data and Cloud Computing (BDCloud), Social Computing and Networking (SocialCom), Sustainable Computing and Communications (SustainCom) (BDCloud-SocialCom-SustainCom)	10.1109/BDCloud-SocialCom-SustainCom.2016.61	attenuation;von neumann stability analysis;big data;computer science;artificial intelligence;operating system;machine learning;data mining;taxonomy	Metrics	-13.567709435453809	-42.30499747657895	31385
b9b2f84d4e8678cc7673ba10537e81572985be16	photo retrieval: multimedia's chance to solve a real problem for real people	search engine;multimedia information systems;information systems;metadata;search engines;information retrieval;calendars image retrieval digital cameras global positioning system search engines digital images information retrieval multimedia systems information systems face detection;video retrieval;calendars;multimedia information system;multimedia systems;digital cameras;global positioning system;photo retrieval;information retrieval systems;digital image;photo retrieval image retrieval digital images multimedia information systems metadata;face detection;digital images;image retrieval	The author points out the very real problems that major search engines have in retrieving images, videos, and photos, and suggests concrete ways to rethink and improve the image and search retrieval process.	web search engine	Ramesh Jain	2007	IEEE Multimedia	10.1109/MMUL.2007.59	computer vision;image retrieval;computer science;multimedia;world wide web;information retrieval;digital image;search engine	Vision	-31.448313800513297	-45.79452407931354	31410
35f03f5cbcc21a9c36c84e858eeb15c5d6722309	placing broadcast news videos in their social media context using hashtags	video news;video analysis;hash tagging;social media	With the growth of social media platforms in recent years, social media is now a major source of information and news for many people around the world. In particular the rise of hashtags have helped to build communities of discussion around particular news, topics, opinions, and ideologies. However, television news programs still provide value and are used by a vast majority of the population to obtain their news, but these videos are not easily linked to broader discussion on social media. We have built a novel pipeline that allows television news to be placed in its relevant social media context, by leveraging hashtags. In this paper, we present a method for automatically collecting television news and social media content (Twitter) and discovering the hashtags that are relevant for a TV news video. Our algorithms incorporate both the visual and text information within social media and television content, and we show that by leveraging both modalities we can improve performance over single modality approaches.	algorithm;hashtag;information source;modality (human–computer interaction);social media and television	Joseph G. Ellis;Svebor Karaman;Hongzhi Li;Hong Bin Shim;Shih-Fu Chang	2016		10.1145/2964284.2970929	media relations;social media;social media optimization;computer science;news media;multimedia;internet privacy;world wide web	HCI	-26.242444186806104	-48.05007853105386	31435
2c5d93b2c6ded626d55ad3374f61bd14a694a4da	calibrating data to sensitivity in private data analysis: a platform for differentially-private analysis of weighted datasets		We present an approach to differentially private computation in which one does not scale up the magnitude of noise for challenging queries, but rather scales down the contributions of challenging records. While scaling down all records uniformly is equivalent to scaling up the noise magnitude, we show that scaling records non-uniformly can result in substantially higher accuracy by bypassing the worst-case requirements of differential privacy for the noise magnitudes. This paper details the data analysis platform wPINQ, which generalizes the Privacy Integrated Query (PINQ) to weighted datasets. Using a few simple operators (including a non-uniformly scaling Join operator) wPINQ can reproduce (and improve) several recent results on graph analysis and introduce new generalizations (e.g., counting triangles with given degrees). We also show how to integrate probabilistic inference techniques to synthesize datasets respecting more complicated (and less easily interpreted) measurements.	best, worst and average case;computation;differential privacy;image scaling;requirement;scalability	Davide Proserpio;Sharon Goldberg;Frank McSherry	2014	PVLDB	10.14778/2732296.2732300	computer science;theoretical computer science;data mining;database;statistics	DB	-7.393074544858004	-32.70496496245152	31496
4f80f0fb1dded3790c13d45fe8d31a7978cbe5f5	mining personal frequent routes via road corner detection	frequent routes characteristic point extraction cpe corner detection;density based spatial clustering of applications with noise personal frequent route mining road corner detection outdoor behavior pattern trajectory based application gps trajectory global positioning system characteristic point extraction phase corner detection phase trajectory mapping phase linear fitting based algorithm multiple density level dbscan algorithm;trajectory roads global positioning system clustering algorithms topology joining processes measurement;data mining feature extraction global positioning system object detection traffic engineering computing;personal frequent route mining road corner detection outdoor behavior pattern trajectory based application gps trajectory global positioning system characteristic point extraction phase corner detection phase trajectory mapping phase linear fitting based algorithm multiple density level dbscan algorithm density based spatial clustering of applications with noise;characteristic point extraction cpe corner detection frequent routes;traffic engineering computing data mining feature extraction global positioning system object detection	Frequent route is an important individual outdoor behavior pattern that many trajectory-based applications rely on. In this paper, we propose a novel framework for extracting frequent routes from personal GPS trajectories. The key idea of our design is to accurately detect road corners and utilize these new metaphors to tackle the problem of frequent route extraction. Concretely, our framework contains three phases: 1) characteristic point (CP) extraction; 2) corner detection; and 3) trajectory mapping. In the first phase, we present a linear fitting-based algorithm to extract CPs. In the second phase, we develop a multiple density level DBSCAN (density-based spatial clustering of applications with noise) algorithm to locate road corners by clustering CPs. In the third phase, we convert each trajectory into an ordered sequence of road corners and obtain all routes that have been traversed by an individual for at least ${F}$ (frequency threshold) times. We evaluate the framework using real-world trajectory datasets of individuals for one year and the experimental results demonstrate that our framework outperforms the baseline approach by 7.8% on average in terms of precision and 21.9% in terms of recall.	algorithm;baseline (configuration management);cluster analysis;constant phase element;corner detection;dbscan;embedded system;global positioning system;information retrieval;mdl (programming language)	Tianben Wang;Daqing Zhang;Xingshe Zhou;Xin Qi;Hongbo Ni;Haipeng Wang;Gang Zhou	2016	IEEE Transactions on Systems, Man, and Cybernetics: Systems	10.1109/TSMC.2015.2444416	computer vision;machine learning;data mining	DB	-15.855689676550805	-35.468719352955176	31540
7abb296dc6729b43e2b01bd7471561083a1e4ab3	an integrated method for social network extraction	social network;social relation;web mining;user interaction;face to face	A social network can become bases for information infrastructure in the future. It is important to extract social networks that are not biased. Providing a simple means for users to register their social relation is also important. We propose a method that combines various approaches to extract social networks. Especially, three kinds of networks are extracted; user-registered Know link network, Web-mined Web link network, and face-to-face Touch link network. In this paper, the combination of social network extraction for communities is described, and the analysis on the extracted social networks is shown.	hyperlink;mined;social network	Tom Hope;Takuichi Nishimura;Hideaki Takeda	2006		10.1145/1135777.1135907	organizational network analysis;social relation;web mining;intelligent computer network;evolving networks;computer science;dynamic network analysis;machine learning;hierarchical network model;social semantic web;data mining;network simulation;world wide web;social network	Web+IR	-19.742436737418178	-41.87977597486718	31546
c0f53de69242ebbf0725ccf51438d94be8d5d17c	combining details of the chi-square goodness-of-fit test with multivariate data visualization	categories and subject descriptors according to acm ccs i 3 3 computer graphics picture image generation visualization		chi;data visualization	Thorsten May;James Davey;Jörn Kohlhammer	2010		10.2312/PE/EuroVAST/EuroVAST10/045-050	scientific visualization;information visualization;computer science;theoretical computer science;computer graphics (images)	HCI	-32.801726191692545	-32.99350134188897	31561
208b23c65842354871952aa4d77df43b34fed383	personalized recommendation system for sina microcomic users		The MicroComic Website underneath the Chinese biggest social network Sina.com (Comic.sina.com.cn) provides a broad range of comics for a huge set of users. The demand of a personalized recommendation system for comic readers has been put on the table recently to improve the users' experience. This paper first investigates the classic item-based collaborative filtering and latent factor model via utilizing the official data sets provided by the Sina.com Company. Then a hybrid recommendation approach is proposed to enhance the recommender performance. The recommendation system can estimate each individual user's preference of the unread comics and generate recommendation list of comics with relative high ratings. The proposed recommender achieves not only good prediction accuracy but outperforms the current recommendation system in respect of Coverage.	code coverage;collaborative filtering;personalization;recommender system;social network	Yan Lindsay Sun;Tianrou Wang;Yun Huang;Yuqian Sun	2017	2017 Wireless Telecommunications Symposium (WTS)	10.1109/WTS.2017.7943533	recommender system;comics;computer science;collaborative filtering;data mining;social network;data set	Web+IR	-21.950799392794945	-49.81481981383602	31638
67bab613148ee15389e77ceb2b4bc97576d24e21	off-screen visualization techniques for class diagrams	class diagram;uml;interaction;contextual view;software development process;design space;uml class diagram;navigation;visualization technique;node link diagrams;visual representation;interaction technique;modeling tool;formative evaluation;off screen visualization	Visual representations of node-link diagrams are very important for the software development process. In many situations large diagrams - probably consisting of hundreds of nodes and edges - have to be edited and explored. In state-of-the-art modeling tools these activities are often accompanied by time consuming panning and zooming. In this paper we contribute the application of off-screen visualization techniques to the domain of node-link diagrams in general and to UML class diagrams in particular. The basic idea of the approach is to give a contextual view of all nodes which are clipped from the current viewport. Nodes are represented by proxy elements located within an interactive border region. The proxies show information of the associated off-screen nodes and can be used to quickly navigate to the respective node. However, there are several challenges when this technique is adapted to node-link diagrams, for example concerning the change of edge routing or scalability. We describe the design space of this approach and present different visualization and interaction techniques in detail. Furthermore, we conducted a formative evaluation of our first prototype. Based on the observations made during the evaluation, we came to final suggestions how particular techniques should be combined.	class diagram;interaction technique;prototype;router (computing);routing;scalability;software development process;unified modeling language;viewport	Mathias Frisch;Raimund Dachselt	2010		10.1145/1879211.1879236	block diagram;simulation;computer science;theoretical computer science;applications of uml;class diagram;programming language;story-driven modeling	HCI	-30.697437876514087	-35.27648823820562	31660
6ea6725457f32e66da56338f1e96c489f655ed3e	informing the design of pipeline-based software visualisations	design process;software visualisation;technical report;software visualization	In this paper, we consider the process by which an effective software visualisation can be designed and explore the ways in which both special-purpose and general-purpose tools may be used to inform the software visualisation design process. A series of decisions must be made in order to determine which data will contribute, the ‘look & feel’ of the visualisation, the algorithms, stylesheets and configuration parameters which are involved as implementation progresses. In our previous work we have developed a flexible, extensible and configurable pipeline-based approach to the implementation of software visualisation. Data is represented in XML at each stage and undergoes successive transformations as it moves through the implementation pipeline. Pipeline components capture and analyse data, compute geometry and determine the detailed presentation of visual output. In this paper, we describe a parallel pipeline for software visualisation design. Its steps involve making choices which determine the specific implementation pipeline components, together with their configurations, defining a particular visualisation. We discus issues and techniques involved in the software visualisation design pipeline, describe tools which support them, and give examples from our software visualisation research.	algorithm;discus;general-purpose markup language;pipeline (computing);scientific visualization;xml	Neville Churcher;Warwick Irwin	2005			software visualization;computer science;theoretical computer science;software development;software construction;data mining;database	SE	-29.993265139502242	-31.053772113506785	31741
b6e4b03521389c460e380da45d74467f2fd1432e	a comparison of different rating based collaborative filtering algorithms	collaborative filtering	In this paper we present a preliminary work in which different rating based collaborative filtering algorithms are compared in terms of scalability and recommendation quality. Algorithms are tested using a reference database and results show that the selection of one or other algorithm depends on two factors: the scalability of the algorithms and the recommendation quality.	algorithm;collaborative filtering	Fabián P. Lousame;Eduardo Sánchez	2008		10.1007/978-3-540-85565-1_31	computer science;collaborative filtering;data mining;world wide web;information retrieval;recommender system	ML	-21.36253432340929	-48.73303441294175	31807
323ff3177fc57760b9720901fcd40bf04952eb95	topic tensor factorization for recommender system	dimension reduction;text modeling;tensor decomposition;recommender system;topic model	Reviews are collaboratively generated by users on items and generally contain rich information than ratings in a recommender system scenario. Ratings are modeled successfully with latent space models by capturing interaction between users and items. However, only a few models collaboratively deal with documents such as reviews. In this study, by modeling reviews as a three-order tensor, we propose a refined tensor topic model (TTM) for text tensors inspired by Tucker decomposition. User and item dimensions are co-reduced with vocabulary space, and interactions between users and items are captured using a core tensor in dimension-reduced form. TTM is proposed to obtain low-rank representations of words as well as of users and items. Furthermore, general rules are developed to transform a decomposition model into a probabilistic model. TTM is augmented further to predict ratings with the assistance of a low-dimensional representation of users and items obtained by TTM. This augmented model is called matrix factorization by learning a bilinear map. A core regularized version is further developed to incorporate additional information from the TTM. Encouraging experimental results not only show that the TTM outperforms existing topic models in modeling texts with a user-item-word structure, but also show that our proposed rating prediction models outperform state-of-the-art approaches.	recommender system	Xiaolin Zheng;Weifeng Ding;Zhen Lin;Chaochao Chen	2016	Inf. Sci.	10.1016/j.ins.2016.08.042	computer science;artificial intelligence;theoretical computer science;machine learning;mathematics;multimedia;topic model;recommender system;dimensionality reduction	AI	-18.97697613019061	-47.56129256298035	31983
a86cf9dd851fcf2ab38756c0901a85da6355eef5	behavioral analysis of registered web site visitors with help of mouse tracking	computer aided analysis;mice;market research;data acquisition computer aided analysis world wide web data analysis;web pages;standards;web page registered web site visitor visitor behavioral analysis mouse tracking implicit data extraction visitor interest profile user interest trend detection;web sites data handling human factors user interfaces;browsers;trend detection;data analysis;human factors;mice browsers web pages market research tracking standards;web sites;world wide web;data handling;behavior analysis;data acquisition;user interfaces;tracking	We present a method to extract implicit data of registered users of a web site with the help of mouse tracking. This allows us to generate more accurate interest profiles of visitors of a web site and to obtain a solid basis for the calculation of user interests or trend detection in the Web. On the one hand, web site owners have the opportunity to adjust their sites to the interests of their users. On the other hand, they can detect new trends and expand these topics on their web pages accordingly.	google sites;handy board;mouse tracking;personalization;prototype;server (computing);usability testing;user profile;web page;web server;world wide web	Clemens Schefels;Sven Eschenberg;Christian Schoneberger	2012	2012 IEEE 14th International Conference on Commerce and Enterprise Computing	10.1109/CEC.2012.15	market research;web analytics;human–computer interaction;computer science;group method of data handling;web page;tracking;multimedia;data acquisition;data analysis;user interface;world wide web;mashup	DB	-30.727033314439694	-45.70483916231939	32038
e4fb49db2022a67c52360e720907eb1a910f4fa8	a new betweenness centrality measure based on an algorithm for ranking the nodes of a network	eigenvector centrality;pagerank algorithms;info eu repo semantics article;betweenness;centrality measures;street network algorithms;random walk betweenness	We propose and discuss a new centrality index for urban street patterns represented as networks in geographical space. This centrality measure, that we call ranking-betweenness centrality, combines the idea behind the random-walk betweenness centrality measure and the idea of ranking the nodes of a network produced by an adapted PageRank algorithm. We initially use a PageRank algorithm in which we are able to transform some information of the network that we want to analyze into numerical values. Numerical values summarizing the information are associated to each of the nodes by means of a data matrix. After running the adapted PageRank algorithm, a ranking of the nodes is obtained, according to their importance in the network. This classification is the starting point for applying an algorithm based on the random-walk betweenness centrality. A detailed example of a real urban street network is discussed in order to understand the process to evaluate the ranking-betweenness centrality proposed, performing some comparisons with other classical centrality measures. 2014 Elsevier Inc. All rights reserved.	algorithm;betweenness centrality;numerical analysis;pagerank;randomness;world wide web	Taras Agryzkov;José Luis Oliver;Leandro Tortosa;José-Francisco Vicent	2014	Applied Mathematics and Computation	10.1016/j.amc.2014.07.026	network theory;network science;random walk closeness centrality;combinatorics;katz centrality;alpha centrality;machine learning;data mining;mathematics;network controllability;centrality;betweenness centrality	Web+IR	-14.502194806220192	-40.561835088375744	32044
d29ca292a27320cd084a5565ac22adcbfef45ff2	infants' teleological and belief inference: a recurrent connectionist approach to their minimal representational and computational requirements	mirror system;human body;rational choice	This paper explores the minimal representational and processing requirements for teleological and mentalistic inferences. These inferences are already present in 6- to 12-month-old infants when they judge the goals of moving agents like inanimate shapes, without any cue about human body motion. This precludes the mirror system as a potential explanation for these early inferences. I propose a recurrent connectionist network that represents a spatial grid in which objects are moving along trajectories that avoid potential obstacles. This network can simulate young infants' (a) teleological sensitivity to goals and obstacles blocking these goals, as well as their (b) mentalizing sensitivity, like attributing to an individual a false belief that differs from the child's reality. The model demonstrates how infants choose the most rational or efficient way through the grid towards the goal, a rational choice that emerges from prior familiarization with and generalization from trajectories and situational obstacles. In addition, mentalizing is accomplished by explicitly representing in the network an individual who watches (or not) where an object moves and keeping track of this individual's experiences and knowledge. This model helps to clarify that these rudimentary characteristics seem to be essential ingredients for an early teleological and mentalizing system.	algorithm;blocking (computing);connectionism;emoticon;ephrin type-b receptor 1, human;experience;generalization (psychology);grid (spatial index);inference;like button;memory disorders;physical object;population parameter;recurrent neural network;representation (action);requirement;simulation;situational application;unit;weight	Frank Van Overwalle	2010	NeuroImage	10.1016/j.neuroimage.2010.05.028	psychology;human body;neuroscience;artificial intelligence;mirror neuron;communication;social psychology;rational choice theory	ML	-27.82413643911315	-39.46937244229636	32052
acfd2c2502abfd51b9c6cfff9a86e3fc9bf985fb	characterization of user online dating behavior and preference on a large online dating site		Online dating sites have become popular platforms for people to look for romantic partners, providing an unprecedented level of access to potential dates that is otherwise not available through traditional means. Characterization of the user online dating behavior helps us to obtain a deep understanding of their dating preference and make better recommendations on potential dates. In this paper we study the user online dating behavior and preference using a large real-world dateset from a major online dating site in China. In particular, we characterize the temporal behavior, message send and reply behavior of users, study how users online dating behaviors correlate with various user attributes, and investigate how users’ actual online dating behaviors deviate from their stated preferences. Our results show that on average a male sends out more messages but receives fewer messages than a female. A female is more likely to be contacted but less likely to reply to a message than a male. The number of messages that a user sends out and receives per week quickly decreases with time, especially for female users. Most messages are replied to within a short time frame with a median delay of around 9 hours. Many of the user messaging behaviors align with notions in social and evolutionary psychology: males tend to look for younger females while females place more emphasis on the socioeconomic status (e.g., income, education level) of a potential date. The geographic distance between two users and the photo count of users play an important role in their dating behavior. We show that it is important to differentiate between users’ true preferences and random selection. Some user behaviors in choosing attributes in a potential date may largely be a result of random selection. We also find that while both males and females are more likely to reply to users whose attributes come closest to the stated preferences of the receivers, there is significant discrepancy between a user’s stated dating preference and his/her actual online dating behavior. We further characterize how users actual dating behavior deviate from their stated preference. These results can provide valuable guidelines to the design of a recommendation engine for potential dates.	align (company);discrepancy function;geographical distance;ibm notes;population;recommender system	Peng Xia;Kun Tu;Bruno F. Ribeiro;Hua Jiang;Xiaodong Wang;Cindy X. Chen;Benyuan Liu;Donald F. Towsley	2014		10.1007/978-3-319-12188-8_9	world wide web	Web+IR	-24.035227559045993	-41.32297823214273	32068
b52316221b5235c0d828991832c4df15bea01916	distant meta-path similarities for text-based heterogeneous information networks		Measuring network similarity is a fundamental data mining problem. The mainstream similarity measures mainly leverage the structural information regarding to the entities in the network without considering the network semantics. In the real world, the heterogeneous information networks (HINs) with rich semantics are ubiquitous. However, the existing network similarity doesn't generalize well in HINs because they fail to capture the HIN semantics. The meta-path has been proposed and demonstrated as a right way to represent semantics in HINs. Therefore, original meta-path based similarities (e.g., PathSim and KnowSim) have been successful in computing the entity proximity in HINs. The intuition is that the more instances of meta-path(s) between entities, the more similar the entities are. Thus the original meta-path similarity only applies to computing the proximity of two neighborhood (connected) entities. In this paper, we propose the distant meta-path similarity that is able to capture HIN semantics between two distant (isolated) entities to provide more meaningful entity proximity. The main idea is that even there is no shared neighborhood entities of (i.e., no meta-path instances connecting) the two entities, but if the more similar neighborhood entities of the entities are, the more similar the two entities should be. We then find out the optimum distant meta-path similarity by exploring the similarity hypothesis space based on different theoretical foundations. We show the state-of-the-art similarity performance of distant meta-path similarity on two text-based HINs and make the datasets public available.	cosine similarity;data mining;entity;experiment;han unification;ibm notes;internet information services;pubmed;social network;text-based (computing)	Chenguang Wang;Yangqiu Song;Haoran Li;Yizhou Sun;Ming Zhang;Jiawei Han	2017		10.1145/3132847.3133029	information retrieval;data mining;semantics;computer science;intuition	ML	-15.869157413952573	-47.076306758199834	32142
89d92f3b9467e112e8386371d229cac19a22019f	a jointly learned context-aware place of interest embedding for trip recommendations		Trip recommendation is an important location-based service that helps relieve users from the time and efforts for trip planning. It aims to recommend a sequence of places of interest (POIs) for a user to visit that maximizes the user’s satisfaction. When adding a POI to a recommended trip, it is essential to understand the context of the recommendation, including the POI popularity, other POIs co-occurring in the trip, and the preferences of the user. These contextual factors are learned separately in existing studies, while in reality, they impact jointly on a user’s choice of a POI to visit. In this study, we propose a POI embedding model to jointly learn the impact of these contextual factors. We call the learned POI embedding a contextaware POI embedding. To showcase the effectiveness of this embedding, we apply it to generate trip recommendations given a user and a time budget. We propose two trip recommendation algorithms based on our contextaware POI embedding. The first algorithm finds the exact optimal trip by transforming and solving the trip recommendation problem as an integer linear programming problem. To achieve a high computation efficiency, the second algorithm finds a heuristically optimal trip based on adaptive large neighborhood search. We perform extensive experiments on real datasets. The results show that our proposed algorithms consistently outperform state-of-the-art algorithms in trip recommendation quality, with an advantage of up to 43% in F1-score.	algorithm;apache poi;computation;experiment;f1 score;heuristic;integer programming;linear programming;location-based service;point of interest;recommender system;time complexity;user (computing)	Jiayuan He;Jianzhong Qi;Kotagiri Ramamohanarao	2018	CoRR		data mining;computer science;computation;embedding;popularity;integer programming;heuristic	AI	-19.99229649266552	-47.392489073036344	32206
434013939dcb6bd1ddd6eccf404fe0646fda0251	multi-task learning for spatio-temporal event forecasting	hard thresholding;multi task learning;event forecasting;dynamic query expansion;lasso	Spatial event forecasting from social media is an important problem but encounters critical challenges, such as dynamic patterns of features (keywords) and geographic heterogeneity (e.g., spatial correlations, imbalanced samples, and different populations in different locations). Most existing approaches (e.g., LASSO regression, dynamic query expansion, and burst detection) are designed to address some of these challenges, but not all of them. This paper proposes a novel multi-task learning framework which aims to concurrently address all the challenges. Specifically, given a collection of locations (e.g., cities), we propose to build forecasting models for all locations simultaneously by extracting and utilizing appropriate shared information that effectively increases the sample size for each location, thus improving the forecasting performance. We combine both static features derived from a predefined vocabulary by domain experts and dynamic features generated from dynamic query expansion in a multi-task feature learning framework; we investigate different strategies to balance homogeneity and diversity between static and dynamic terms. Efficient algorithms based on Iterative Group Hard Thresholding are developed to achieve efficient and effective model training and prediction. Extensive experimental evaluations on Twitter data from four different countries in Latin America demonstrated the effectiveness of our proposed approach.	algorithm;computer multitasking;feature learning;iterative method;least squares;multi-task learning;population;query expansion;social media;thresholding (image processing);vocabulary	Liang Zhao;Qian Sun;Jieping Ye;Feng Chen;Chang-Tien Lu;Naren Ramakrishnan	2015		10.1145/2783258.2783377	multi-task learning;computer science;machine learning;lasso;pattern recognition;data mining;statistics	ML	-16.97069965307675	-51.344331772888154	32234
61bcbebbddaa4abb6c631e4db9c0412f29c9ba51	development and evaluation of arterial incident detection models using fusion of simulated probe vehicle and loop detector data	traffic simulation;automatic incident detection;neural networks;microscopic traffic simulation;road network;model performance;swinburne;false alarm rate;data fusion;detection rate;neural network model;neural network	This paper describes the development of neural network models for automatic incident detection on arterial roads, using simulated data derived from inductive loop detectors and probe vehicles. The work reported in this paper extends previous research by comparing the performance of various data fusion neural network architectures and assessing model performance for various probe vehicle penetration rates and loop detector configurations. Data from 108 incidents was collected from loop detectors and probe vehicles using a calibrated and validated traffic simulation model. The best performance was obtained for detector configurations found on most existing road networks, with a detection rate of 86%, false alarm rate of 0.36% and probe vehicle penetration rate of 20%. Fusion of speed data further improved performance, resulting in an incident detection rate of 90% and a false alarm rate of 0.5%. The results reported in this paper demonstrate the feasibility of developing advanced data fusion neural network architectures for detection of incidents on urban arterials using data from existing loop detector configurations and probe vehicles.		Hussein Dia;Kim Thomas	2011	Information Fusion	10.1016/j.inffus.2010.01.001	simulation;computer science;machine learning;constant false alarm rate;sensor fusion;computer security;artificial neural network	Robotics	-14.898820932696307	-28.08337512422649	32411
abe7453b4fc69c14e9125e4f5256d338ebc2f326	approaches to visualisation in bioinformatics: from dendrograms to space explorer	3d;3d interaction;sequence comparison;distance measure;gene expression data;data type;research paper;structure comparison;visualisation;principal component analysis;structure comparison data;spring embedding;sequence comparison data;information visualisation;design methodology	With the data explosion in biology visualisation technique s are of paramount importance for further progress. In this paper, we review traditional v isualisation by clustering and dendrogram, which are prevailent in biology. We discuss its hortcomings and develop an alternative approach: Space Explorer 1 . In detail, we first present a framework to characterise the vi sual sation process. We identify two main data types and introduce structure comparison data and gene expression data as representatives, which serve as running examples throug out. Next, we review various distance measures and develop a design methodology for dist ances. We critically review the classical approach of clustering and visualisation thr ough trees, in particular dendrograms, and pinpoint shortcomings of this technique. In orde r to tackle these shortcomings, we survey information visualisation techniques and we deve lop an alternative approach and system: Space Explorer, which maps the relationships of obj ects to distances and visualises these distances in a 3D, interactive space. We develop and ev luate three layout algorithms for the two data types and apply them to our case studies.	algorithm;bioinformatics;cluster analysis;dendrogram;information visualization;map;reflow soldering	Michael Schroeder;David R. Gilbert;Jacques van Helden;Penny Noy	2001	Inf. Sci.	10.1016/S0020-0255(01)00156-6	design methods;data type;computer science;bioinformatics;machine learning;data mining;programming language;3d computer graphics;principal component analysis	PL	-7.9612097670738535	-51.754900942250565	32463
26ea23f266ad2ee662dc8a35e09f3b7846f313cc	brave new task: user account matching		Today, the usage of online social networks and their many manifestations is widespread. Users tend not to be just active on a single platform, they take advantage of a range of platforms for different purposes: Twitter for microblogging, Flickr for sharing pictures, YouTube for sharing videos, etc. The question we consider in this task is to what extent users (unintentionally) leak information in their social Web streams, either through their direct contributions or the meta-data of their contributions, that allows us to automatically identify and match their corresponding accounts across streams. In this paper, we present the data set we developed for the user account matching task and the baseline results.	baseline (configuration management);flickr;image;social network;user (computing)	Claudia Hauff;Gerald Friedland	2012			world wide web;microblogging;streams;social media;social web;social network;computer science	Web+IR	-26.10279275613164	-48.02201070172768	32540
55d5012fb434b38c3e339272ce3961ff5b8fd630	modeling abstractions for dance digital libraries	art;digital libraries;history;frbroo;ieee 1599 standards;labanotation;web browsing;web search;abstraction modeling;chorological research;comprehensive modeling abstraction;computational analysis;critical functionality;dance digital library system;dance knowledge organization;dance movement;dance piece;dance work;generic cultural heritage models;human body movement;multilayered model;music information systems;similarity comparison;standard detailed movement description;standard detailed movement notation;structural movement components;user interaction;conceptual models;dance digital libraries;intangible cultural heritage;labanotation;movement analysis	The description of the human body and its movement is fundamental and a critical part of the content of a Dance Digital Library. It must be captured in an organized way, both for allowing user interaction (browse, search) and computational analysis (similarity comparison) of dances, as well as for exploring meaningful ways to present content to users. In this paper, we present a comprehensive modeling abstraction for such digital libraries, which consists of a multi-layered model that covers different levels for describing dance movement. We address the semantic challenge of organizing knowledge of dance by starting from defining a dance piece or work, going to the characterization of its structural movement components and their related concepts and standard detailed movement description and notation i.e., Labanotation. In addition, we take into account the existing chorological research, as well as, related work in other domains, such as music information systems and standards i.e., IEEE 1599 and generic cultural heritage models i.e., FRBRoo. These modeling abstractions have been devised in the context of a more general on-going effort to develop a Dance Digital Library System and will be instrumental in some critical functionality, i.e., searching by movement concepts and characteristics in a meaningful way for a wide range of users, and linking different manifestations of movement recordings, descriptions, prescriptions or representations.	browsing;digital library;frbroo;information system;library (computing);library classification;organizing (structure)	Katerina El Raheb;Yannis E. Ioannidis	2014	IEEE/ACM Joint Conference on Digital Libraries		simulation;computer science;conceptual model;multimedia;world wide web	HPC	-31.464051591970087	-28.75111224952665	32658
ffd57ef295ed2567879d2246e5c4487230b3e0ee	a novel method for detecting outlying subspaces in high-dimensional databases using genetic algorithm	random sampling technique genetic algorithm high dimensional databases subspace detection outlierness analysis high dimensional data mining;genetic algorithms data mining;high dimensionality;lower and upper bound;random sampling;high dimensional databases;random sampling technique;data mining;computing and communication sciences;high dimensional data mining;genetic algorithms data mining algorithm design and analysis sampling methods spatial databases credit cards computer science data analysis upper bound nearest neighbor searches;high dimensional data;nearest neighbor;280000 information;genetic algorithm;genetic algorithms;outlierness analysis;subspace detection;article;ge netic algorithm	Detecting outlying subspaces is a relatively new research problem in outlier-ness analysis for high-dimensional data. An outlying subspace for a given data point p is the sub- space in which p is an outlier. Outlying subspace detection can facilitate a better characterization process for the detected outliers. It can also enable outlier mining for high- dimensional data to be performed more accurately and efficiently. In this paper, we proposed a new method using genetic algorithm paradigm for searching outlying subspaces efficiently. We developed a technique for efficiently computing the lower and upper bounds of the distance between a given point and its kth nearest neighbor in each possible subspace. These bounds are used to speed up the fitness evaluation of the designed genetic algorithm for outlying subspace detection. We also proposed a random sampling technique to further reduce the computation of the genetic algorithm. The optimal number of sampling data is specified to ensure the accuracy of the result. We show that the proposed method is efficient and effective in handling outlying subspace detection problem by a set of experiments conducted on both synthetic and real-life datasets.	ap computer science;approximation;computation;data mining;data point;earthbound;experiment;fitness function;genetic algorithm;lookup table;monte carlo method;programming paradigm;real life;refinement (computing);sampling (signal processing);sensor;synthetic intelligence;unified model	Ji Zhang;Qigang Gao;Hai H. Wang	2006	Sixth International Conference on Data Mining (ICDM'06)	10.1109/ICDM.2006.6	genetic algorithm;computer science;machine learning;pattern recognition;data mining	DB	-6.5044259486882625	-39.42348327990417	32688
03191cac9ad9a5d6ac6995d6c60ce784ddf6d1cf	a fine-grained indoor location-based social network	social network services;location based services;mobile computing indoor environments ieee 802 11 standard social network services global positioning system mobile handsets business;global positioning system;business;mobile handsets;indoor environments;ieee 802 11 standard;mobile computing;location based social networks;semantic indoor floorplans	Existing Location-based social networks (LBSNs), e.g., Foursquare, depend mainly on GPS or cellular-based localization to infer users’ locations. However, GPS is unavailable indoors and cellular-based localization provides coarse-grained accuracy. This limits the accuracy of current LBSNs in indoor environments, where people spend 89 percent of their time. This in turn affects the user experience, in terms of the accuracy of the ranked list of venues, especially for the small screens of mobile devices, misses business opportunities, and leads to reduced venues coverage. In this paper, we present CheckInside: a system that can provide a fine-grained indoor location-based social network. CheckInside leverages the crowd-sensed data collected from users’ mobile devices during the check-in operation and knowledge extracted from current LBSNs to associate a place with a logical name and a semantic fingerprint. This semantic fingerprint is used to obtain a more accurate list of nearby places as well as to automatically detect new places with similar signature. A novel algorithm for detecting fake check-ins and inferring a semantically-enriched floorplan is proposed as well as an algorithm for enhancing the system performance based on the user implicit feedback. Furthermore, CheckInside encompasses a coverage extender module to automatically predict names of new venues increasing the coverage of current LBSNs. Experimental evaluation of CheckInside in four malls over the course of six weeks with 20 participants shows that it can infer the actual user place within the top five venues 99 percent of the time. This is compared to 17 percent only in the case of current LBSNs. In addition, it increases the coverage of existing LBSNs by more than 37 percent.	algorithm;cyclic redundancy check;digital media player;fingerprint;global positioning system;mobile device;sensor;social network;user experience	Moustafa Elhamshary;Anas Basalmah;Moustafa Youssef	2017	IEEE Transactions on Mobile Computing	10.1109/TMC.2016.2591532	simulation;global positioning system;telecommunications;computer science;operating system;location-based service;mobile computing;computer security;computer network	Mobile	-18.645415667592502	-36.07748069584704	32704
4d3527accd2ea3686f22cbf8231f6f1d043801c6	suggesting recommendations using pythagorean fuzzy sets illustrated using netflix movie data		The web can be perceived as a huge repository of items, and users’ activities can be seen as processes of searching for items of interest. Recommender systems try to estimate what items users may like based on similarities between users, their activities, or on explicitly specified preferences. Users do not have any influence on item selection processes. In this paper we propose a novel collaborative-based recommender system that provides a user with the ability to control a process of constructing a list of suggested items. This control is accomplished via explicit requirements regarding rigorousness of identifying users who become a reference base for generating suggestions. Additionally, we propose a new way of ranking items rated by multiple users. The approach is based on Pythagorean fuzzy sets and takes into account not only assigned rates but also their number. The proposed approach is used to generate lists of recommended movies from the Netflix competition database.	fuzzy set;multi-user;netflix prize;recommender system;requirement;world wide web	Marek Reformat;Ronald R. Yager	2014		10.1007/978-3-319-08795-5_56	computer science;artificial intelligence;data mining;multimedia;world wide web	Web+IR	-28.60778505133256	-48.18852957150823	32715
db1c98dc61f6876c472211ce9671178b694e1a2c	dl-agentrecom - a multi-agent based recommendation system for scientific documents	manuals;document handling;agent based;information filtering;collaboration;collaboration information filtering information filters computer science navigation scientific computing computer architecture search engines information analysis image retrieval;data mining;system architecture dl agentrecom multiagent based recommendation system scientific document;scientific document;navigation;software architecture;multi agent systems;recommender system;software architecture document handling information filtering multi agent systems scientific information systems;clustering algorithms;artificial intelligence;multiagent based recommendation system;computer science;system architecture;scientific information systems;dl agentrecom	The goal is to propose a recommendation system for scientific documents. The paper presents the architecture and the principles of functioning of the system. The way a user organizes its documents is called the user's perspective over the set of documents. Operations with user perspectives are defined, also the system can have and build its own perspective. The users perspective can be mixed with system perspective.	recommender system	Horia Emil Popa;Viorel Negru;Daniel Pop;Ionel Muscalagiu	2008	2008 10th International Symposium on Symbolic and Numeric Algorithms for Scientific Computing	10.1109/SYNASC.2008.79	software architecture;navigation;computer science;artificial intelligence;multi-agent system;data mining;database;cluster analysis;world wide web;information retrieval;recommender system;collaboration	Arch	-29.819482455551494	-49.742773252218704	32723
ff0b4629caceaa1ff24f609ee3919396291dbb0c	a collaborative filtering recommendation algorithm with time adjusting based on attribute center of gravity model	similarity measurement inaccuracy;filtering;time dimensional adjustment;time measurement;simulation;collaboration;gravity;collaborative filtering;classification algorithms;center of gravity;data models	In the collaborative filtering recommendation technology, the similarity measurement part plays a vital role, and similarity measurement accuracy seriously affects the similarity measurement part and all the subsequent parts. However, there are many shortcomings in the similarity measurement part of traditional memory-based collaborative filtering recommendation technology. In order to solve the inaccuracy under special circumstances, this paper proposes an improved algorithm, a collaborative filtering recommendation algorithm with time adjusting based on attribute center of gravity model, through altering the process of similarity calculation. Simulation results show that the improved algorithm gains a higher recommendation accuracy, compared with the traditional algorithms.	algorithm;attribute-value system;collaborative filtering;gravity model of trade;simulation;sparse matrix;table (information)	Liangyou Gao;Mengxing Huang	2015	2015 12th Web Information System and Application Conference (WISA)	10.1109/WISA.2015.54	computer science;data science;collaborative filtering;data mining;information retrieval;recommender system	Web+IR	-21.14577729882502	-48.87673601991178	32760
4b133b9379d80e5ef53174e6d9ea9ed6126b73f7	on preventing location attacks for urban vehicular networks		The prevalence of global positioning system (GPS) equipped in vehicular networks exposes users’ location information to the location-based services. We argue that such data contains rich informative cues on drivers’ private behaviors and preferences, which will lead to the location privacy attacks. In this paper, we proposed a sophisticated prediction model to predict driver’s next location by using a k-order Markov chain-based third-rank tensor representing the partially observed transfer information of vehicles. Then Bayesian Personalized Ranking (BPR) is used to learn the unobserved transitions within the tensor for transition predication. Experimental results manifest the efficacy of the proposed model in terms of location predication accuracy, compared with several state-of-the-art predication methods. We also point out that the precision achieved by such advanced predication model is restricted to the order of the Markov chain k. Accordingly, we propose a schema to decrease the risks of such attacks by preventing the conformation of higher order Markov chain. Experimental results obtained based on the real-world vehicular network data demonstrated the effectiveness of our proposed schema.		Meng Zhou;Xin Li;Lejian Liao	2016	Mobile Information Systems	10.1155/2016/5850670	embedded system;simulation;telecommunications;data mining;computer security	AI	-22.788655951400152	-44.195871110491844	32769
0cd7531522c022c987dcc0434c4c836717d0998f	predicting links in multi-relational and heterogeneous networks	unsupervised learning;unsupervised learning information networks pattern classification probability;probability;link prediction;correlation unsupervised learning diseases time series analysis genetics integrated circuit modeling equations;information networks;heterogeneous network link prediction temporal analysis;coauthorship prediction link prediction multirelational network heterogeneous network network analysis social network dependency structure mrip probabilistic method multirelational influence propagation sparse network classification task unsupervised learning;pattern classification;temporal analysis;heterogeneous network	Link prediction is an important task in network analysis, benefiting researchers and organizations in a variety of fields. Many networks in the real world, for example social networks, are heterogeneous, having multiple types of links and complex dependency structures. Link prediction in such networks must model the influence propagating between heterogeneous relationships to achieve better link prediction performance than in homogeneous networks. In this paper, we introduce Multi-Relational Influence Propagation (MRIP), a novel probabilistic method for heterogeneous networks. We demonstrate that MRIP is useful for predicting links in sparse networks, which present a significant challenge due to the severe disproportion of the number of potential links to the number of real formed links. We also explore some factors that can inform the task of classification yet remain unexplored, such as temporal information. In this paper we make use of the temporal-related features by carefully investigating the issues of feasibility and generality. In accordance with our work in unsupervised learning, we further design an appropriate supervised approach in heterogeneous networks. Our experiments on co-authorship prediction demonstrate the effectiveness of our approach.	baseline (configuration management);dbl-browser;experiment;kerrison predictor;receiver operating characteristic;semantic network;social network;sparse matrix;unsupervised learning	Yang Yang;Nitesh V. Chawla;Yizhou Sun;Jiawei Han	2012	2012 IEEE 12th International Conference on Data Mining	10.1109/ICDM.2012.144	unsupervised learning;heterogeneous network;computer science;dynamic network analysis;machine learning;pattern recognition;probability;data mining;statistics	ML	-15.219390035326505	-46.33456819325158	32855
82b830370e79d15d830c5050c4bf860fe3e76763	from causal models to sound heuristic inference		We investigate whether people rely on their causal intuitions to determine the predictive value or importance of cues. Our real-world data set consists of one criterion variable (child mortality) and nine cues (e.g., GDP per capita). We elicited people’s intuitive causal models about the domain. In a second task, we asked them to rank the cues according to their beliefs about the cues’ predictive value. Alternative cue importance rankings were derived directly from their causal models using measures of causal centrality. The results show that people’s judgments of cue importance corresponded more closely to the causal-based cue orders than to the statistical associations between the cues and the criterion. Using computer simulations, we show that people’s causalbased cue orders form a sound basis for making inferences, even when information about the statistical structure of the environment is scarce or unavailable. Central to the simulations is take-the-best (TTB)—a simple decision strategy that makes inferences by considering cues sequentially. The simulations show that causal-based cue orders can be as accurate as individuals’ judged orders. Causal-based cue orders allow TTB to perform as would be expected from estimating the weights of a linear model using about 35% of the available data. These findings suggest that people can rely on their causal intuitions to determine the importance of cues, thereby reducing the computational complexity involved in finding useful cue orders.	best practice;causal filter;causality;centrality;computational complexity theory;computer simulation;decision theory;heuristic (computer science);linear model;space: above and beyond	Ana Sofia Morais;Lael J. Schooler;Henrik Olsson;Björn Meder	2014			econometrics;frequentist inference;machine learning	AI	-7.115754461427879	-25.583616244130788	32857
8facc8f856f16773470f97ad11a365ef785bb23e	cubethat: news article recommender	diversity;news;recommender;clustering;browser extension	The CubeThat browser extension for Chrome displays recommended additional news stories related to the same topic as the current news story. The recommended stories are organized into clusters, and clusters that the user has already sampled from are grayed out, in order to encourage users to explore multiple aspects of a story. Users can also provide feedback to improve the clustering, by dragging stories from one cluster to another.	browser extension;cluster analysis;computer cluster;drag and drop;grayed out;recommender system	Sidharth Chhabra;Paul Resnick	2012		10.1145/2365952.2366020	news;computer science;machine learning;multimedia;internet privacy;world wide web	HCI	-28.64443048689867	-44.123873417696146	32865
6fe770358df2b31383479eaf4d6330cabe8d4464	a conceptual framework for community detection, characterisation and membership in a social internetworking scenario	community detection;community characterisation;social internetworking;community membership;social networks;user similarity detection	Social internetworking systems are becoming a challenging new reality; they group together multiple, and possibly heterogenous, social networks. The typical problems of social network research become much more complex in a social internetworking context. In this paper, we propose a conceptual framework, and an underlying model, to handle some of these problems, namely community detection, characterisation and membership in a social internetworking scenario. In order to face them, we must preliminarily investigate a further problem, i.e., user similarity detection.	internetworking	Pasquale De Meo;Antonino Nocera;Giovanni Quattrone;Domenico Ursino	2014	IJDMMM	10.1504/IJDMMM.2014.059980	world wide web;computer security;computer network;social network	AI	-20.669596081516538	-41.95717639503733	32869
db20c524a888c5fc75e9af08d436bb707d7ffbf6	tievis: visual analytics of evolution of interpersonal ties		Interpersonal ties, such as strong ties and weak ties, describe the information carried by an edge in social network. Tracking the dynamic changes of interpersonal ties can thus enhance our understanding of the evolution of a complex network. Nevertheless, existing studies in dynamic network visualization mostly focus on the temporal changes of nodes or structures of the network without an adequate support of analysis and exploration of the temporal changes of interpersonal ties. In this paper, we introduce a new visual analytics method that enables interactive analysis and exploration of the dynamic changes of interpersonal ties. The method integrates four well-linked visualizations, including a scatterplot, a pixelbar chart, a layered graph, and a node-link diagram, to allow for multi-perspective analysis of the evolution of interpersonal ties. The scatterplot created by multi-dimensional scaling can help reveal the clusters of ties and detect abnormal ties, while other visualizations allow users to explore the clusters of ties interactively from different perspectives. A case study has been conducted to demonstrate the effectiveness of our approach.	visual analytics	Tao Lin;Fangzhou Guo;Yingcai Wu;Biao Zhu;Fan Zhang;Huamin Qu;Wei Chen	2016		10.1007/978-3-319-40259-8_36	knowledge management;data science	Vision	-27.89803432056407	-35.423701303905524	32905
8048914243dc7a6f54aeeff7c77d1e1e27c6cd6f	network model of knowledge diffusion	h index;network model;knowledge diffusion	This paper introduces a diffusion network model: an individual-citation-based directed network model with a time dimension, as a potentially useful approach to capture the diffusion of research topics. The approach combines social network analysis, network visualization and citation analysis to discuss some of the issues concerning the spread of scientific ideas. The process of knowledge diffusion is traced from a network point of view. Using research on the h-index as a case study, we built detailed networks of individual publications and demonstrated the feasibility of applying the diffusion network model to the spread of a research. The model shows the specific paths and associations of individual papers, and potentially complementing issues raised by epidemic models, which primarily deal with average properties of entire scientific communities. Also, based on the citation-based network, the technique of main path analysis identified the articles that influenced the research for some time and linked them into a research tradition that is the backbone of the h-index field.	bibliometrics;citation analysis;graph drawing;internet backbone;level of detail;network model;path analysis (statistics);social network analysis;sociological theory of diffusion;weighted network;word lists by frequency	Xia Gao;Jiancheng Guan	2011	Scientometrics	10.1007/s11192-011-0554-z	organizational network analysis;social science;network formation;computer science;dynamic network analysis;artificial intelligence;network model;data mining;management science	ML	-18.2529553381387	-40.34759969665358	32935
f937da2cf830b59efb79892249ec6f603c0685d5	finding frequent items in data streams using hierarchical information	taxonomy frequency conversion error analysis filters testing error correction sampling methods data structures algorithm design and analysis telephony;fishmerge algorithm;data stream;hierarchical information;tree data structures;data mining;taxonomy tree frequent item finding data streams hierarchical information mining task fishmerge algorithm;data streams;merging;taxonomy tree;tree data structures data mining merging;frequent item finding;mining task	Finding frequent items or top-k items in data streams is a basic mining task with a wide range of applications. There are lots of algorithms proposed to enhance the performance of these algorithms, whereas not much effort has been made to make use of hierarchical information held by items in data stream. In this paper, we try to improve the accuracy of finding frequent items using hierarchical information in taxonomy. To do that, we propose a method called Merge. According to the strategy, we design and implement an algorithm, named FISHMerge. In order to evaluate the performance of the algorithm, we propose three new measures for testing, and develop a hierarchical stream data generator. After conducting a comprehensive experimental study, we conclude that accuracy of FISHMerge is better than algorithms without using hierarchical information under same amount of memory. In the meantime, our algorithm can also provide some information of higher level items.	algorithm;dspace;experiment;taxonomy (general)	Xiaoyu Wang;Hongyan Liu;Jiawei Han	2007	2007 IEEE International Conference on Systems, Man and Cybernetics	10.1109/ICSMC.2007.4413754	computer science;data science;data mining;database;data stream mining;tree	DB	-5.378993277724606	-36.81356167440091	32962
21ba5c38a6d3107ec31ec423e205ea50632ce01d	visualizing dynamic data with maps	dynamic programming;maps;large scale dynamic relational data;multimedia information systems;geographic data;geographic map metaphor;measurement;graph drawing;information interface and presentation;iptv service;layout;geographic information systems data visualisation dynamic programming;internet radio station;spatialization;data mining;data visualisation;heat map overlays;data visualization layout animation measurement clustering algorithms heuristic algorithms data mining;geographic information systems;iptv service dynamic data visualisation maps geographic data heat map overlays large scale dynamic relational data geographic map metaphor map based visualization system internet radio station tv viewing patterns;heuristic algorithms;map based visualization information interface and presentation multimedia information systems dynamic visualization graph drawing spatialization;animation;data visualization;clustering algorithms;dynamic visualization;map based visualization;dynamic data visualisation;map based visualization system;tv viewing patterns	Maps offer a familiar way to present geographic data (continents, countries), and additional information (topography, geology), can be displayed with the help of contours and heat-map overlays. In this paper, we consider visualizing large-scale dynamic relational data by taking advantage of the geographic map metaphor. We describe a map-based visualization system which uses animation to convey dynamics in large data sets, and which aims to preserve the viewer's mental map while also offering readable views at all times. Our system is fully functional and has been used to visualize user traffic on the Internet radio station last.fm, as well as TV-viewing patterns from an IPTV service. All map images in this paper are available in high-resolution at [CHECK END OF SENTENCE] as are several movies illustrating the dynamic visualization.	animation;calibration;data collection;dynamic data;gif;geology;heat map;human-readable medium;iptv;image resolution;imagery;interaction;last.fm;mental mapping;movies;node - plant part;page (document);prototype;radio broadcasting;topography;usability testing;user interface;web page;wikipedia;contents - htmllinktype	Daisuke Mashima;Stephen G. Kobourov;Yifan Hu	2011	2011 IEEE Pacific Visualization Symposium	10.1109/TVCG.2011.288	layout;anime;computer science;dynamic programming;data mining;database;cluster analysis;graph drawing;world wide web;data visualization;measurement;statistics	Visualization	-33.27649514119939	-30.960184716992174	33008
39f7221ee77ccf5d4cb169ae6bc2b4fe3c2583ba	server selection on the world wide web	high resolution;distributed information retrieval;server selection;effectiveness evaluation;world wide web;3d representation	"""Significant efforts are being made to digitize rare and valuable library materials, with the goal of providing patrons and historians digital facsimiles that capture the """"look and feel"""" of the original materials. This is often done by digitally photographing the materials and making high resolution 2D images available. The underlying assumption is that the objects are flat. However, older materials may not be flat in practice, being warped and crinkled due to decay, neglect, accident and the passing of time. In such cases, 2D imaging is insufficient to capture the """"look and feel"""" of the original. For these materials, 3D acquisition is necessary to create a realistic facsimile. This paper outlines a technique for capturing an accurate 3D representation of library materials which can be integrated directly into current digitization setups. This will allow digitization efforts to provide patrons with more realistic digital facsimile of library materials."""	image resolution;left 4 dead 2;look and feel;world wide web	Nick Craswell;Peter Bailey;David Hawking	2000		10.1145/336597.336628	simulation;computer science;multimedia;world wide web	Graphics	-32.913872476444816	-36.570761826662306	33072
74c560c6aeee4887aee2363e504f6bc107bb4311	consistency and differences between centrality metrics across distinct classes of networks.		The roles of different nodes within a network are often inferred via centrality analysis, which aims to quantify the potential for a node to influence, or be influenced by, others by virtue of network connectivity. Many different centrality measures have been proposed, but the degree to which they offer redundant or unique information, or whether it is advantageous to use multiple centrality measures to define node roles, is unclear. Here, we assess the correlations between 15 different centrality measures quantified in 11 networks, examine how these correlations relate to variations in network density and global topology, and clusters according to their centrality profiles to identify distinct node roles. We find that centrality measures are generally positively correlated, but that the strength of these correlations varies across networks and that this variation in related to the modularity and majorization gap of the network. Clustering of nodes based on centrality scores indicates that most networks contain a putative core, comprising nodes that score highly across nearly all measures. Our findings shed light on topological constraints that shape the pattern of correlations between centrality measures and demonstrate how a broad, comparative approach to centrality can inform the interpretation of nodal roles in networks.	centrality;chao (sonic);economy of second life	Stuart Oldham;Ben D. Fulcher;Linden Parkes;Aurina Arnatkeviciute;Chao Suo;Alex Fornito	2018	CoRR		computer science;machine learning;artificial intelligence;centrality;cluster analysis;modularity	PL	-15.454999336942178	-39.194259502546224	33257
fb2097e701c4ccc2dee3a636dc8ecbc748b405b2	finding causality and responsibility for probabilistic reverse skyline query non-answers	causality and responsibility;object recognition;probabilistic reverse skyline query;prsq probabilistic reverse skyline query nonanswers database causality and responsibility problem crp;probabilistic logic algorithm design and analysis object recognition database systems relational databases decision making;algorithm;algorithm causality and responsibility probabilistic reverse skyline query reverse skyline query;database systems;query processing causality probability;relational databases;probabilistic logic;reverse skyline query;algorithm design and analysis	Causality and responsibility is an essential tool in the database community for providing intuitive explanations for answers/non-answers to queries. Causality denotes the causes for the answers/non-answers to queries, and responsibility represents the degree of a cause which reflects its influence on the answers/non-answers to queries. In this paper, we study the  causality and responsibility problem  (CRP) for the non-answers to probabilistic reverse skyline queries (PRSQ). We first formalize CRP on PRSQ, and then, we propose an efficient algorithm termed as CP to compute the causality and responsibility for the non-answers to PRSQ. CP first finds candidate causes, and then, it performs verification to obtain actual causes with their responsibilities, during which several strategies are used to boost efficiency. Further, we explore the CRP for the non-answers to reverse skyline queries. Towards this, we extend CP to identify directly all the actual causes and their responsibilities for a non-answer to reverse skyline queries without additional verification. Extensive experiments using both real and synthetic data sets demonstrate the effectiveness and efficiency of our presented algorithms.	causality;pareto efficiency	Yunjun Gao;Qing Liu;Gang Chen;Linlin Zhou;Baihua Zheng	2016	IEEE Trans. Knowl. Data Eng.	10.1109/TKDE.2016.2599869	algorithm design;relational database;computer science;theoretical computer science;cognitive neuroscience of visual object recognition;data mining;database;probabilistic logic;algorithm	DB	-7.257080619961232	-36.211402056370574	33266
25cde32f3fab651ec8f99b137a6088ade0bcb747	node classification in uncertain graphs	spreadsheets;scientific data management;relationship identification	In many real applications that use and analyze networked data, the links in the network graph may be erroneous, or derived from probabilistic techniques. In such cases, the node classification problem can be challenging, since the unreliability of the links may affect the final results of the classification process. In this paper, we focus on situations that require the analysis of the uncertainty that is present in the graph structure. We study the novel problem of node classification in uncertain graphs, by treating uncertainty as a first-class citizen. We propose two techniques based on a Bayes model, and show the benefits of incorporating uncertainty in the classification process as a first-class citizen. The experimental results demonstrate the effectiveness of our approaches.	first-class citizen	Michele Dallachiesa;Charu C. Aggarwal;Themis Palpanas	2014		10.1145/2618243.2618277	computer science;artificial intelligence;machine learning;data mining;database;statistics	ML	-10.143682522954055	-32.23321766553056	33303
73813149ea0b0d53877b347d938f4c104dab173e	leveraging the power of local spatial autocorrelation in geophysical interpolative clustering	clustering;geophysical data stream;spatial autocorrelation;inverse distance weighting	Nowadays ubiquitous sensor stations are deployed worldwide, in order to measure several geophysical variables (e.g. temperature, humidity, light) for a growing number of ecological and industrial processes. Although these variables are, in general, measured over large zones and long (potentially unbounded) periods of time, stations cannot cover any space location. On the other hand, due to their huge volume, data produced cannot be entirely recorded for future analysis. In this scenario, summarization, i.e. the computation of aggregates of data, can be used to reduce the amount of produced data stored on the disk, while interpolation, i.e. the estimation of unknown data in each location of interest, can be used to supplement station records. We illustrate a novel data mining solution, named interpolative clustering, that has the merit of addressing both these tasks in time-evolving, multivariate geophysical applications. It yields a time-evolving clustering model, in order to summarize geophysical data and computes a weighted linear combination of cluster prototypes, in order to predict data. Clustering is done by accounting for the local presence of the spatial autocorrelation property in the geophysical data. Weights of the linear combination are defined, in order to reflect the inverse distance of the unseen data to each cluster geometry. The cluster geometry is represented through shape-dependent sampling of geographic coordinates of clustered stations. Experiments performed with several data collections investigate the trade-off between the summarization capability and predictive accuracy of the presented interpolative clustering algorithm.	algorithm;autocorrelation;benchmark (computing);cluster analysis;computation;computer cluster;data mining;feature vector;geographic coordinate system;heuristic (computer science);hierarchical clustering;interpolation;kriging;region of interest;sampling (signal processing);sensor;snapshot (computer storage);spatial analysis;streaming media;time complexity	Annalisa Appice;Donato Malerba	2014	Data Mining and Knowledge Discovery	10.1007/s10618-014-0372-z	data stream clustering;inverse distance weighting;k-medians clustering;fuzzy clustering;computer science;machine learning;data mining;mathematics;spatial analysis;cluster analysis;statistics;clustering high-dimensional data	ML	-13.724362908003306	-32.865338567526834	33337
98523f96be51635e9e89bd20afd7a8391b348dc5	pgx.ui: visual construction and exploration of large property graphs		Transforming existing data into graph formats and visualizing large graphs in a comprehensible way are two key areas of interest of information visualization. Addressing these issues requires new visualization approaches for large graphs that support users with graph construction and exploration. In addition, graph visualization is becoming more important for existing graph processing systems, which are often based on the property graph model. Therefore this paper presents concepts for visually constructing property graphs from data sources and a summary visualization for large property graphs. Furthermore, we introduce the concept of a graph construction time line that keeps track of changes and provides branching and merging, in a version control like fashion. Finally, we present a tool that visually guides users through the graph construction and exploration process.	cluster analysis;computer science;dbpedia;graph (abstract data type);graph (discrete mathematics);graph drawing;information visualization;knowledge graph;machine learning;timeline;usability testing;version control	Julia Kindelsberger;Daniel Langerenken;Malte Husmann;Korbinian Schmid;Hassan Chafi	2017		10.5220/0006231603050310	machine learning	HCI	-28.9301831237024	-34.73775652328294	33362
9f40e6bdc47742e249bad8383d0125c93ab07268	an algorithm for in-core frequent itemset mining on streaming data	false negative;multipass apriori algorithm incore frequent item set mining streaming data data mining one pass algorithm;data mining;frequent itemset;itemsets data mining computer science data engineering frequency data structures;frequent itemset mining;experimental evaluation	Frequent item set mining is a core data mining operation and has been extensively studied over the last decade. This paper takes a new approach for this problem and makes two major contributions. First, we present a one pass algorithm for frequent item set mining, which has deterministic bounds on the accuracy, and does not require any out-of-core summary structure. Second, because our one pass algorithm does not produce any false negatives, it can be easily extended to a two pass accurate algorithm. Our two pass algorithm is very memory efficient, and allows mining of datasets with large number of distinct items and/or very low support levels. Our detailed experimental evaluation on synthetic and real datasets shows the following. First, our one pass algorithm is very accurate in practice. Second, our algorithm requires significantly lower memory than Manku and Motwani's one pass algorithm and the multi-pass Apriori algorithm. Our two pass algorithm outperforms Apriori and FP-tree when the number of distinct items is large and/or support levels are very low. In other cases, it is quite competitive, with possible exception of cases where the average length of frequent item sets is quite high.	apriori algorithm;association rule learning;core data;data mining;data structure;magnetic-core memory;maximal set;out-of-core algorithm;requirement;streaming media;synthetic intelligence	Ruoming Jin;Gagan Agrawal	2005	Fifth IEEE International Conference on Data Mining (ICDM'05)	10.1109/ICDM.2005.21	gsp algorithm;computer science;pattern recognition;data mining;database;fsa-red algorithm;apriori algorithm	DB	-6.38742098058796	-36.700245625522804	33418
b19f0ac4359d03a258224ecdc519dc77792625f5	predisposition to auto-maintenance: fuzzy analysis		At the present time, many companies try implement TPM (Total Productive Maintenance). For this one, they must to analyze his predisposition to automaintenance, because it is pillar of this Japanese maintenance philosophy. We propose to use fuzzy sets (linguistic labels) to obtain the information of workers, and we facilitate the results as a set of three linguistic labels: red, yelow and green depending on their predisposition.	fuzzy set;predispositioning theory;trusted platform module;yellow	Angel M. Gento-Municio;Alfonso Redondo	2005			polyethylene terephthalate;fuzzy logic;auto maintenance;composite material;data mining;materials science;polybutylene terephthalate	AI	-7.525543456860491	-27.67081868465933	33426
3fffa73f4cd8bdfd14402c98b4e1fc694e9ff904	a physically based runoff model analysis of the querétaro river basin		1 División de Estudios de Posgrado, Facultad de Ingenieŕıa, Universidad Autónoma de Querétaro, Cerro de las Campanas S/N Centro, 76000 Querétaro, QRO, Mexico 2 Centro Interamericano de Recursos del Agua (CIRA), Facultad de Ingenierı́a, Cerro de Coatepec CU, 50110 Toluca,MEX, C.P., Mexico 3 División de Estudios de Posgrado, Facultad de Contabilidad y Administración, Universidad Autónoma de Querétaro, Cerro de las Campanas S/N Centro, 76000 Querétaro, QRO, Mexico		Carlos Javier Villa-Alvarado;Eladio Delgadillo-Ruiz;Carlos Alberto Mastachi-Loza;Enrique González-Sosa;Ramos Salinas Norma Maricela	2014	J. Applied Mathematics	10.1155/2014/586872	elevation;mathematical optimization;water balance;structural basin;sea level;runoff model;shetran;mathematics;drainage basin;hydrology	Crypto	-10.78797174163835	-26.594533368154476	33623
d6f6798b0bad4901e11c84de972b936a2500ab1b	discovery of driving patterns by trajectory segmentation	segmentation;trajectory;driving patterns	Telematics data is becoming increasingly available due to the ubiquity of devices that collect data during drives, for different purposes, such as usage based insurance (UBI), fleet management, navigation of connected vehicles, etc. Consequently, a variety of data-analytic applications have become feasible that extract valuable insights from the data. In this paper, we address the especially challenging problem of discovering behavior-based driving patterns from only externally observable phenomena (e.g. vehicle's speed). We present a trajectory segmentation approach capable of discovering driving patterns as separate segments, based on the behavior of drivers. This segmentation approach includes a novel transformation of trajectories along with a dynamic programming approach for segmentation. We apply the segmentation approach on a real-word, rich dataset of personal car trajectories provided by a major insurance company based in Columbus, Ohio. Analysis and preliminary results show the applicability of approach for finding significant driving patterns.	columbus;dynamic programming;observable;telematics	Sobhan Moosavi;Rajiv Ramnath;Arnab Nandi	2016		10.1145/3003819.3003824	computer vision;simulation;geography;operations management	ML	-18.048873977522565	-32.28319915143707	33625
c84699a33b8a78f1a14d425441dbe4d517162e69	i want to answer; who has a question?: yahoo! answers recommender system	user models;large scale;recommender system;question answering system;user experience;user interaction;recommender systems;yahoo answers;question answering;user model	"""Yahoo! Answers is currently one of the most popular question answering systems. We claim however that its user experience could be significantly improved if it could route the """"right question"""" to the """"right user."""" Indeed, while some users would rush answering a question such as """"what should I wear at the prom?,"""" others would be upset simply being exposed to it. We argue here that Community Question Answering sites in general and Yahoo! Answers in particular, need a mechanism that would expose users to questions they can relate to and possibly answer.  We propose here to address this need via a multi-channel recommender system technology for associating questions with potential answerers on Yahoo! Answers. One novel aspect of our approach is exploiting a wide variety of content and social signals users regularly provide to the system and organizing them into channels. Content signals relate mostly to the text and categories of questions and associated answers, while social signals capture the various user interactions with questions, such as asking, answering, voting, etc. We fuse and generalize known recommendation approaches within a single symmetric framework, which incorporates and properly balances multiple types of signals according to channels. Tested on a large scale dataset, our model exhibits good performance, clearly outperforming standard baselines."""	baseline (configuration management);interaction;organizing (structure);question answering;recommender system;user experience;yahoo! answers	Gideon Dror;Yehuda Koren;Yoelle Maarek;Idan Szpektor	2011		10.1145/2020408.2020582	user modeling;question answering;computer science;data mining;world wide web;information retrieval	Web+IR	-19.711594679951464	-47.65561689863698	33657
17484ebbccdb8678287043f6db241dc5fe39a135	distribution-free data density estimation in large-scale networks	distribution-free;data density estimation;random sampling	Estimating the global data distribution in large-scale networks is an important issue and yet to be well addressed. It can benefit many applications, especially in the cloud computing era, such as load balancing analysis, query processing, and data mining. Inspired by the inversion method for random variate (number) generation, in this paper, we present a novel model called distribution-free data density estimation for large ring-based networks to achieve high estimation accuracy with low estimation cost regardless of the distribution models of the underlying data. This model generates random samples for any arbitrary distribution by sampling the global cumulative distribution function and is free from sampling bias. Armed with this estimation method, we can estimate data densities over both one-dimensional and multidimensional tuple sets, where each dimension could be either continuous or discrete as its domain. In large-scale networks, the key idea for distribution-free estimation is to sample a small subset of peers for estimating the global data distribution over the data domain. Algorithms on computing and sampling the global cumulative distribution function based on which the global data distribution is estimated are introduced with a detailed theoretical analysis. Our extensive performance study confirms the effectiveness and efficiency of our methods in large ring-based networks.		Minqi Zhou;Rong Zhang;Weining Qian;Aoying Zhou	2016	Frontiers of Computer Science	10.1007/s11704-016-6194-y	cumulative distribution function;random variate;artificial intelligence;inverse transform sampling;pattern recognition;data domain;sampling (statistics);density estimation;algorithm;computer science;sampling bias;load balancing (computing)	DB	-7.826251543995466	-33.396033944621	33690
3ef2177ccc6c5ada8f6470e3e6288db8b714e2a0	a shape-based visual interface for text retrieval	data visualization information retrieval data mining shape control visual databases fractals multidimensional systems testing engines web search;information retrieval;data mining;data visualisation;graphical user interfaces;procedural shape generation shape based visual interface text retrieval information retrieval shape recognition text retrieval engine 3d shapes glyphs text based queries summarization data visualization information overview data mining;text retrieval;visual interfaces;data mining information retrieval graphical user interfaces data visualisation	n recent ye a rs, visualization has ra p i d ly evo lved from a specialized re s e a rch nich e i n to a viable tool for analysis. In the emerging discipline of information visualization, for example, researchers use visual analysis for ex p l o ring nonspatial info rm at i o n. 1 As visualization te ch n i ques mature and powe r-ful, affordable, personal computers become common, e ffo rts in applying visual te ch n i ques ex tend to bro a d e r problem domains. The explosion in the number, size, and availability of info rm a t i o n s o u rces has sparked inte re st in data mining, which allows inte ra c t i ve ex p l o ration and discove ry of hidden k n owl e d ge and relationships buri e d w i thin this data glut. Vi s u a l i z a t i o n augments this analysis process. Coupling visualization with info rm a t i o n mining and analysis te ch n i qu e s fo rms a unique and powe rful new p a radigm for ex p l o ration and disc ove ry—visual analys i s. Visual data mining re qu i res a t i g h t ly coupled visual inte rface with u n d e rlying info rmation ret ri ev a l and analysis engines. To be useful, these te ch n i ques must augment human ex p l o ration and discove ry b eyond ex i sting methods. Since d a ta mining aims to provide humans with support i n g tools to think and ex p l o re, human perc e ptual issues remain an imp o rtant component of effe c t i ve visual inte r-faces for such syste m s. In this article, we describe a shape-based visual inte r-face for info rmation ret ri eval and inte ra c t i ve ex p l oration that exploits shape recognition. Our ex p l o ra to ry s ystem uses pro c e d u ra l ly ge n e ra ted shapes coupled w i th an underlying tex t-ret ri eval engine. A visual inte r-face based on …	bro;compaq evo;data mining;document retrieval;enhanced vob;eval;information visualization;personal computer;pro*c;problem domain;sting	Randall M. Rohrer;John L. Sibert;David S. Ebert	1999	IEEE Computer Graphics and Applications	10.1109/38.788797	document retrieval;text mining;visual word;computer science;data mining;graphical user interface;world wide web;information retrieval;data visualization;human–computer information retrieval	Vision	-31.31221918772118	-29.881012325655135	33711
bf24c203624999a7b606c18c9bfc741586815adf	analysis on the spatial variation of the center of gravity of inbound tourism in china.	center of gravity (cog);china;inbound tourism;spatial distribution	This paper examines CoG movement of the chief indicators of inbound tourism in China from 2000-2010. Three themes guide the analysis. First, the changing CoG of China inbound tourism is calculated and mapped. Second, the changing inbound tourism size distribution of the 31 provinces is examined. Third, the provinces are ranked according to their growth rate, and analyse the changing spatial concentration of inbound tourism. Some generalizations regarding spatial variation are given and future trends for the balanced development of inbound tourism are briefly discussed.	cog (project);inbound marketing;spatial reference system	Yining Chen;Hui Zhang	2011			remote sensing;data mining;center of gravity;tourism;china;computer science;spatial variability	HCI	-12.280329471870608	-24.761910638885176	33789
612079d5d8c0ea24f35652e441815603358bd630	movie recommendation system employing the user-based cf in cloud computing		Collaborative filtering algorithm is widely used in the recommendation system of e-commerce website, which is based on the analysis of a large number of user’s historical behavior data, so as to explore the user’s interest and recommend the appropriate products to users. In this paper, we focus on how to design a reliable and highly accurate algorithm for movie recommendation. It is worth noting that the algorithm is not limited to film recommendation, but can be applied in many other areas of e-commerce. In this paper, we use Java language to implement a movie recommendation system in Ubuntu system. Benefiting from the MapReduce framework and the recommendation algorithm based on items, the system can handle large data sets. The experimental results show that the system can achieve high efficiency and reliability in large data sets.	algorithm;cloud computing;collaborative filtering;e-commerce;mapreduce;recommender system;ubuntu	Tianqi Zhou;Lina Chen;Jian Shen	2017	22017 IEEE International Conference on Computational Science and Engineering (CSE) and IEEE International Conference on Embedded and Ubiquitous Computing (EUC)	10.1109/CSE-EUC.2017.194	recommender system;collaborative filtering;scalability;algorithm design;cloud computing;data mining;computer science;overlay network;data set;java	DB	-22.79792337897936	-49.459974866279836	33793
4b42c5ecf7a757c19cdbbf081513d339292006bd	assessing the air traffic control safety impact of airline pilot induced latencies	human performance model;safety assessment;collision risk model;sensitivity analysis;agent based modeling and simulation;human machine interaction;air traffic management	Current arrival operations in the terminal airspace, designed according to ICAO guidelines to comply with a target level of safety of 10 -7 per approach, rely on spatial protection zones and complementing procedures (ICAO Doc. 4444). The purpose of this paper is to quantitatively demonstrate inherent safety margins, which form the basic prerequisite for increasing flight efficiency both economically and ecologically. By means of expert interview, task analyses and experiments on a procedure trainer, human-machine interaction latencies on the flight deck are analyzed as a performance shaping factor and thus a potential driver for collision risk. The effects are studied by means of a sensitivity analysis, performed by coupling our actualnavigation-performance-enhanced collision risk model and agent-based fast-time simulation. The results show that temporal safety margins exist for implementation latencies of advised speed and heading changes alike. For heading changes, the margin is well-defined at 10 seconds. For speed changes, the safety level decreases gradually with human-machine interaction latencies, to become critical between 15 and 20 seconds. Trajectory-based concepts with fewer, but more time-consuming interactions between pilot and airborne IT systems may benefit from these findings.	advanced transportation controller;agent-based model;airborne ranger;conformance testing;course (navigation);ecology;entity;experiment;financial risk modeling;human–computer interaction;instrument flight rules;microsoft outlook for mac;radar;safety engineering;simulation;smoothing;tower mounted amplifier;traffic shaping	Markus Vogel;Christoph Thiel;Hartmut Fricke	2012			simulation;engineering;operations management;forensic engineering	Mobile	-19.321708060127964	-25.590120863369247	33797
e1c0ec9847eeef9313b2101c0d88c440e476e656	predicting poaching for wildlife protection		Wildlife species such as tigers and elephants are under the threat of poaching. To combat poaching, conservation agencies (“defenders”) need to (1) anticipate where the poachers are likely to poach and (2) plan effective patrols. We propose an anti-poaching tool CAPTURE (Comprehensive Anti-Poaching tool with Temporal and observation Uncertainty REasoning), which helps the defenders achieve both goals. CAPTURE builds a novel hierarchical model for poacher-patroller interaction. It considers the patroller’s imperfect detection of signs of poaching, the complex temporal dependencies in the poacher's behaviors and the defender’s lack of knowledge of the number of poachers. Further, CAPTURE uses a new game-theoretic algorithm to compute the optimal patrolling strategies and plan effective patrols. This paper investigates the computational challenges that CAPTURE faces. First, we present a detailed analysis of parameter separation and target abstraction, two novel approaches used by CAPTURE to efficiently learn the parameters in the hierarchical model. Second, we propose two heuristics – piece-wise linear approximation and greedy planning – to speed up the computation of the optimal patrolling strategies. We discuss in this paper the lessons learned from using CAPTURE to analyze real-world poaching data collected over 12 years in Queen Elizabeth National Park in Uganda. Introduction Wildlife poaching presents a significant threat to large-bodied animal species. It is one major driver of the population declines of key wildlife species such as tigers, elephants, and rhinos, which are crucial to the functioning of natural ecosystems as well as local and national economies [1, 2]. Poachers illegally catch wildlife by placing snares or hunting. To combat poaching, both government and non-government agencies send well-trained patrollers to wildlife conservation areas. In this work, we focus on snare poaching. The patrollers conduct patrols with the aim of preventing poachers from poaching animals either by catching the poachers or by removing animal traps set by the poachers. Signs of poaching are collected and recorded during the patrols, including snares, traps and other signs such as poacher tracks, which can be used together with other domain features such as animal density or slope of the terrain to analyze and predict the poachers' behavior [3, 4]. It is critical to learn the poachers' behavior, anticipate where the poachers would go for poaching, and further use such information to guide future patrols and make them more effective. Poachers’ behavior is adaptive to patrols as evidenced by multiple studies [5, 6, 7]. Instead of falling into a static pattern, the distribution of poaching activities can be affected by ranger patrols as the poachers will take the patrol locations into account when making decisions. As a result, the rangers should also consider such dynamics when planning the patrols. Such strategic interaction between the conservation agencies and the poachers make game theory an appropriate framework for the problem. Stackelberg Security Games (SSGs) in computational game theory have been successfully applied to various infrastructure security problems in which the defender	computation;ecosystem;game theory;greedy algorithm;heuristic (computer science);hierarchical database model;linear approximation;snare (software);the lone ranger	Fei Fang;Thanh Hong Nguyen;Arunesh Sinha;Shahrzad Gholami;Andrew J. Plumptre;Lucas Joppa;Milind Tambe;Margaret Driciru;Fred Wanyama;Aggrey Rwetsiba;Rob Critchlow;Colin M. Beale	2017	IBM Journal of Research and Development		real-time computing;environmental protection;computer science;wildlife;poaching	AI	-15.342491457484707	-28.375080701723892	33803
1267347de992c524b933040cb96fabb93cba1738	fast community detection algorithm with gpus and multicore architectures	graph theory;community detection;cluster algorithm;parallel algorithm;multicore architectures;community detection algorithm;detection algorithms;hep th graph;edge detection;power 6 architecture;communities image edge detection algorithm design and analysis detection algorithms graphics processing unit clustering algorithms partitioning algorithms;weighted label propagation;gpgpu;parallel architectures graph theory multiprocessing systems parallel algorithms;parallel architectures;image edge detection;football;detection algorithm;graphic processing unit;clustering algorithms;dolphin network;football club community detection algorithm multicore architectures parallel algorithm weighted label propagation wikipedia graph rmat graph hep th graph power 6 architecture parallel architectures gpgpu zachary karate club dolphin network;zachary karate club;multiprocessing systems;rmat graph;parallel architecture;communities;graphics processing unit;wikipedia graph;algorithm design;algorithm design and analysis;partitioning algorithms;parallel algorithms;football club	In this paper, we present the design of a novel scalable parallel algorithm for community detection optimized for multi-core and GPU architectures. Our algorithm is based on label propagation, which works solely on local information, thus giving it the scalability advantage over conventional approaches. We also show that weighted label propagation can overcome typical quality issues in communities detected with label propagation. Experimental results on well known massive scale graphs such as Wikipedia (100M edges) and also on RMAT graphs with 10M - 40M edges, demonstrate the superior performance and scalability of our algorithm compared to the well known approaches for community detection. On the \textit{hep-th} graph ($352$K edges) and the \textit{wikipedia} graph ($100$M edges), using Power 6 architecture with $32$ cores, our algorithm achieves one to two orders of magnitude better performance compared to the best known prior results on parallel architectures with similar number of CPUs. Further, our GPGPU based algorithm achieves $8\times$ improvement over the Power 6 performance on $40$M edge R-MAT graph. Alongside, we achieve high quality (modularity) of communities detected, with experimental evidence from well-known graphs such as Zachary karate club, Dolphin network and Football club, where we achieve modularity that is close to the best known alternatives. To the best of our knowledge these are best known results for community detection on massive graphs ($100$M edges) in terms of performance and also quality vs. performance trade-off. This is also a unique work on community detection on GPGPUs with scalable performance.	central processing unit;display resolution;dolphin;general-purpose computing on graphics processing units;graphics processing unit;iteration;mathematical model;multi-core processor;parallel algorithm;scalability;software propagation;speedup;time complexity;whole earth 'lectronic link;wikipedia;zachary lemnios;zachary's karate club	Jyothish Soman;Ankur Narang	2011	2011 IEEE International Parallel & Distributed Processing Symposium	10.1109/IPDPS.2011.61	algorithm design;parallel computing;computer science;graph theory;theoretical computer science;operating system;distributed computing;parallel algorithm	HPC	-13.041221912097436	-42.195002952710524	33837
11076c0a129e588daa9d25fcd222f7b5ea6b4089	modeling inter-country connection from geotagged news reports: a time-series analysis		The development of theories and techniques for big data analytics offers tremendous flexibility for investigating large-scale events and patterns that emerge over space and time. In this research, we utilize a unique open-access dataset “The Global Data on Events, Location and Tone” (GDELT) to model the image of China in mass media, specifically, how China has related to the rest of the world and how this connection has evolved upon time based on an autoregressive integrated moving average (ARIMA) model. The results of this research contribute in both methodological and empirical perspectives: We examined the effectiveness of time series models in predicting trends in long-term mass media data. In addition, we identified various types of connection strength patterns between China and its top 15 related countries. This study generates valuable input to interpret China’s diplomatic and regional relations based on mass media data, as well as providing methodological references for investigating international relations in other countries and regions in the big data era.	autoregressive integrated moving average;autoregressive model;big data;geotagging;time series	Yihong Yuan	2017		10.1007/978-3-319-61845-6_19	data science;mass media;computer science;time series;data mining;big data;autoregressive integrated moving average	SE	-20.092793322969403	-35.142199746157964	33885
cdbd1bf965a0a994e2122f51ef4254d1326c22d4	crowdsourcing predictors of residential electric energy usage		Crowdsourcing has been successfully applied in many domains including astronomy, cryptography, and biology. In order to test its potential for useful application in a smart grid context, this paper investigates the extent to which a crowd can contribute predictive hypotheses to a model of residential electric energy consumption. In this experiment, the crowd generated hypotheses about factors that make one home different from another in terms of monthly energy usage. To implement this concept, we deployed a web-based system within which 627 residential electricity customers posed 632 questions that they thought predictive of energy usage. While this occurred, the same group provided 110 573 answers to these questions as they accumulated. Thus, users both suggested the hypotheses that drive a predictive model and provided the data upon which the model is built. We used the resulting question and answer data to build a predictive model of monthly electric energy consumption, using random forest regression. Because of the sparse nature of the answer data, careful statistical work was needed to ensure that these models are valid. The results indicate that the crowd can generate useful hypotheses, despite the sparse nature of the dataset.	crowdsourcing;cryptography;predictive modelling;random forest;sparse matrix;web application	Mark Wagy;Josh C. Bongard;James P. Bagrow;Paul Hines	2018	IEEE Systems Journal	10.1109/JSYST.2017.2778144	electric energy;computer science;smart grid;energy consumption;random forest;data modeling;data mining;electric energy consumption;crowdsourcing	AI	-22.06498346201067	-36.25280150241883	33910
e589306972efed08819be0c1217282c9990ab99f	estimating intervals of interest during tv viewing for automatic personal preference acquisition	tratamiento automatico;television;modelo markov oculto;multimedia;taux interet;service information;modele markov cache;tv viewer s behaviors;hidden markov model;interest rate;estimating intervals of interest;automatic processing;temporal pattern;preferencia;servicio informacion;preference;tasa interes;information service;personal preferences;traitement automatique;personalized services	The demand for information services considering personal preferences is increasing. In this paper, aiming at the development of a system for automatically acquiring personal preferences from TV viewers’ behaviors, we propose a method for automatically estimating TV viewers’ intervals of interest based on temporal patterns in facial changes with Hidden Markov Models. Experimental results have shown that the proposed method was able to correctly estimate intervals of interest with a precision rate of 86.6% and a recall rate of 80.6%.		Makoto Yamamoto;Naoko Nitta;Noboru Babaguchi	2006		10.1007/11922162_71	simulation;computer science;interest rate;multimedia;television;hidden markov model	NLP	-28.094385645998123	-44.141464775359076	33913
2e153bd50d94c7ad7f0c30a11592592070deaeb5	a service recommendation algorithm based on modeling of implicit demands	user demand modeling;latent dirichlet allocation;service recommendation;service computing	The results from using the current service recommendation algorithms are still unable to meet the dynamic and diverse demands of users. Therefore, a recommendation algorithm is proposed to take into account the dynamic and diverse demands of users. This algorithm extracts the user-implicit-demand-factors from the Latent Dirichlet Allocation model in the field of machine learning, and uses both explicit and implicit demand as the intermediary variable to generate a service recommendation list for the user. Experimental results on a real-world data set regarding service composition show that the proposed algorithm can represent a variety of user demands, and the performance of the proposed algorithm is better than the existing algorithms in terms of accuracy, novelty and timeliness.	algorithm;latent dirichlet allocation;machine learning;service composability principle	Yanmei Zhang;Tingpei Lei;Yan Wang	2016	2016 IEEE International Conference on Web Services (ICWS)	10.1109/ICWS.2016.12	latent dirichlet allocation;computer science;data mining;database;services computing;world wide web	DB	-22.378432278937147	-48.39932322033438	33956
f94fe82757d36b8cfb1c44b382e0669586bf4773	how do we spread on twitter?	complex networks;social networking online augmented reality behavioural sciences computing helmet mounted displays;twitter niobium nominations and elections market research communities augmented reality real time systems;data mining;human behavior;human behavior complex networks social network analysis diffusion spreading;graphical tool twitter diffusion phenomena public discussion areas human behaviors collective feelings microsoft hololens augmented reality headset political election greece;spreading;social network analysis;diffusion	The emergence of new communication means such as online newspapers and exchange and sharing websites allow us to go further in the understanding of diffusion phenomena. Indeed, these public discussion areas are now firmly established in our societies and are known to be strong sensors of both human behaviors and collective feelings. In this paper we focus on diffusion phenomena that occur on Twitter and we propose a set of measures that aims to characterize globally and locally the processes. Our objective is to identify what are the conditions in which a person decides to forward the information. Our measures have been used to study two events occurred in January 2015: the presentation of Microsoft HoloLens, a new augmented reality headset, and the political election in Greece. The results obtained show a strong heterogeneity in the individual behaviours involved in the diffusion process. Our approach has been implemented into a graphical tool which is able to conduct real time analysis on any kind of topics occurring on Twitter.	augmented reality;emergence;expect;graphical user interface;headset (audio);microsoft hololens;mind;neighbourhood (graph theory);population;predictive modelling;sensor	Erick Stattner;Reynald Eugenie;Martine Collard	2015	2015 IEEE 9th International Conference on Research Challenges in Information Science (RCIS)	10.1109/RCIS.2015.7128894	social network analysis;simulation;computer science;engineering;artificial intelligence;data mining;diffusion;human behavior;management;world wide web;complex network	DB	-20.69471091620924	-41.71178955394408	33980
7e9d2269e6e7b68b3457312c09aad12190c40a23	visualizing tags over time	flickr;large dataset;real time;temporal evolution;visualization;covering problem;interval covering;social media;algorithms and data structure;tags	We consider the problem of visualizing the evolution of tags within the Flickr (flickr.com) online image sharing community. Any user of the Flickr service may append a tag to any photo in the system. Over the past year, users have on average added over a million tags each week. Understanding the evolution of these tags over time is therefore a challenging task. We present a new approach based on a characterization of the most interesting tags associated with a sliding interval of time. An animation provided via Flash in a web browser allows the user to observe and interact with the interesting tags as they evolve over time.New algorithms and data structures are required to support the efficient generation of this visualization. We combine a novel solution to an interval covering problem with extensions to previous work on score aggregation in order to create an efficient backend system capable of producing visualizations at arbitrary scales on this large dataset in real time.	adobe flash;algorithm;append;covering problems;data structure;flickr;music download;programming paradigm	Micah Dubinko;Ravi Kumar;Joseph Magnani;Jasmine Novak;Prabhakar Raghavan;Andrew Tomkins	2006		10.1145/1135777.1135810	visualization;social media;computer science;data mining;world wide web;information retrieval	Visualization	-24.664944373967753	-35.578704327479464	33989
180862966838ad70b977a312bc94b1ea00bf3fb8	using graph clustering for community discovery in web-based social networks		Knowledge discovery in social networks is not a trivial task. Often research in this context uses concepts of data mining, social network analysis, trust discovery and sentiment analysis. The connected network of people is generally represented by a directed graph (social graph), whose formulation includes representing people as nodes and their relationships as edges, which also can be labeled to describe the relationship (eg. friend, son and girlfriend). This environment of connected nodes behaves like a dynamic network, whose nodes and connections are constantly being updated. People tend to communicate or relate better with other people who have a common or similar way of thinking, which generates groups of people with common interests, the communities. This paper studies the use of a graph clustering approach, the Coring Method, originally employed in image segmentation task, in order to be applied in the context of community discovery on a social network environment.	social network	Jackson Gomes de Souza;Edeilson Milhomem da Silva;Parcilene Fernandes Brito;José Alfredo Ferreira Costa;Ana Carolina Salgado;Silvio Romero de Lemos Meira	2013		10.1007/978-3-642-38715-9_15	clique percolation method;complex network	ML	-17.890515398971846	-41.633816115297606	34015
68408be8d4a797b528634099aea5b8ca2a610b97	fuel consumption estimates based on driving pattern recognition	traffic engineering computing computerised monitoring controller area networks data mining petroleum road traffic road vehicles;road traffic;controller area networks;driving pattern;controller area network;data mining;fuel consumption;petroleum;fuel consumptioin monitoring system fuel consumption controller area network driving pattern;fuels vehicles vectors acceleration roads atmospheric modeling educational institutions;traffic engineering computing;fuel consumptioin monitoring system;computerised monitoring;fuel consumption estimation air pollution driving pattern discovery fuel consumption distribution fuel consumption monitoring system fuel consumption calculation model controller area network can intelligent terminal urban road network spatial distribution temporal distribution meso model transportation;road vehicles	Fuel consumption and air pollution caused by transportation is becoming more and more serious. Developing an effective meso model to analyze dynamically the temporal and spatial distribution of fuel consumption in the urban road network has become a research focus. However, parameters used by most meso models in the traffic field are not detailed enough, and the generalization ability and accuracy of these models are still to be improved. For discovering typical driving features and the relationship with fuel consumption, this paper collected 150 million records within two weeks by the intelligent terminal based on CAN (Controller Area Network) installed in 600 private vehicles. These records contained the information of latitude, longitude, speed, fuel consumption, etc. Based on these data, this paper discovered typical driving patterns that were closely related to fuel consumption, and then developed a fuel consumption calculation model. At last, this paper developed a fuel consumption monitoring system to show the distribution of fuel consumption of the road network in Beijing.	adobe air;algorithm;can bus;cluster analysis;computer terminal;feature vector;gradient;map matching;mesoscopic physics;pattern recognition;principal component analysis	Xiaohua Zhou;Jian Huang;Weifeng Lv;Dapeng Li	2013	2013 IEEE International Conference on Green Computing and Communications and IEEE Internet of Things and IEEE Cyber, Physical and Social Computing	10.1109/GreenCom-iThings-CPSCom.2013.99	can bus;computer science;fuel efficiency;petroleum	Robotics	-17.137138708775307	-32.28161443537311	34060
38da60aac4f5e80ed7222a657e76fa5f33159afc	inflo: collaborative reasoning via open calculation graphs	knowledge curation;collaboration;collaborative decision making	Inflo is a web tool that introduces new ways to collaboratively construct and deconstruct logical arguments drawn as visual dataflow graphs. Inflo graphs are dynamic: nodes are logical propositions that can contain computations based on other nodes. Inflo nodes and graphs have URLs, permitting sharing via blogs, e-mails, papers, etc. People can collaboratively construct, refine, and adapt/reuse arguments by making changes to shared nodes. Combining community-curated nodes and using Inflo's nodes for computation, back-of-the-envelope calculations can rapidly be made.	application programming interface;blog;computation;dataflow;email;graph (discrete mathematics);logistics;organizing (structure);plug-in (computing);traceability	Jonathan Lung;Steve M. Easterbrook	2012		10.1145/2145204.2145384	group decision-making;computer science;theoretical computer science;data mining;communication;management;world wide web;collaboration	ECom	-30.203249604750877	-28.651338431298804	34061
5153accb4382437a2264438a78026e82d8a58c28	rotation, scaling and translation analysis of biometric signature templates	biometric authentication;signature verification;pattern recognition;rotation scaling and translation;human error	Biometric authentication systems that make use of signature verification methods often render optimum performance only under limited and restricted conditions. Such methods utilize several training samples so as to achieve high accuracy. Moreover, several constraints are imposed on the end-user so that the system may work optimally, and as expected. For example, the user is made to sign within a small box, in order to limit their signature to a predefined set of dimensions, thus eliminating scaling. Moreover, the angular rotation with respect to the referenced signature that will be inadvertently introduced as human error, hampers performance of biometric signature verification systems. To eliminate this, traditionally, a user is asked to sign exactly on top of a reference line. In this paper, we propose a robust system that optimizes the signature obtained from the user for a large range of variation in Rotation-ScalingTranslation (RST) and resolves these error parameters in the user signature according to the reference signature stored in the database.	8-bit;american and british english spelling differences;angularjs;arithmetic logic unit;authentication;biometrics;comparator;control unit;digital signature;human error;image scaling;intel matrix raid;modelsim;multiplexer;register file;spartan;three-state logic;user (computing);vhdl;xilinx ise	Aman Chadha;Divya Jyoti;M. Mani Roja	2011	CoRR		human error;speech recognition;computer science;theoretical computer science;pattern recognition;data mining;biometrics;signature recognition	Vision	-32.10713494915594	-25.882745941101533	34131
02137d45c0323263c5be8de5e15dc4c39451a0bf	visual exploration of sparse traffic trajectory data	sparse traffic trajectory;pedestrian safety;poison control;injury prevention;traffic engineering computing data visualisation road pricing tolls road vehicles;safety literature;traffic safety;injury control;dynamic graph;home safety;route selection visual exploration sparse traffic trajectory data visual analysis system transportation cells road vehicles macrotraffic analysis macrotraffic patterns trajectory aggregation techniques cell status pattern intercell flow pattern traffic congestion traffic flows;injury research;trajectory data;safety abstracts;trajectory;human factors;traffic congestion;visual exploration;traffic visualization;期刊论文;occupational safety;safety;dynamic graph visualization;data visualization;trajectory visual analytics data visualization aircraft navigation;safety research;accident prevention;violence prevention;bicycle safety;visual analytics;poisoning prevention;falls;ergonomics;suicide prevention;aircraft navigation	In this paper, we present a visual analysis system to explore sparse traffic trajectory data recorded by transportation cells. Such data contains the movements of nearly all moving vehicles on the major roads of a city. Therefore it is very suitable for macro-traffic analysis. However, the vehicle movements are recorded only when they pass through the cells. The exact tracks between two consecutive cells are unknown. To deal with such uncertainties, we first design a local animation, showing the vehicle movements only in the vicinity of cells. Besides, we ignore the micro-behaviors of individual vehicles, and focus on the macro-traffic patterns. We apply existing trajectory aggregation techniques to the dataset, studying cell status pattern and inter-cell flow pattern. Beyond that, we propose to study the correlation between these two patterns with dynamic graph visualization techniques. It allows us to check how traffic congestion on one cell is correlated with traffic flows on neighbouring links, and with route selection in its neighbourhood. Case studies show the effectiveness of our system.	animation;behavior;drug vehicle;flow;graph drawing;imagery;movement;network congestion;silo (dataset);sparse matrix;track (course);traffic analysis	Zuchao Wang;Tangzhi Ye;Min Lu;Xiaoru Yuan;Huamin Qu;Jacky Yuan;Qianliang Wu	2014	IEEE Transactions on Visualization and Computer Graphics	10.1109/TVCG.2014.2346746	simulation;computer science;suicide prevention;human factors and ergonomics;trajectory;injury prevention;computer security	Visualization	-17.00300874654699	-31.710491045369686	34157
9396db3fa06a9002ffb5f3dc5e3616f34236d967	predicting private company exits using qualitative data	qualitative data;private equity fund;different databases;random forest algorithm;imbalanced class distribution;roc curve;business decision;random forest classifier;explanatory power;pe space;private company	Private companies backed by venture capitalists or private equity funds receive their funding in a series of rounds. Information about when each round occurred and which investors participated in each round has been compiled into different databases. Here we mine one such database to model how the private company will exit the VC/PE space. More specifically, we apply a random forest algorithm to each of nine sectors of private companies. Resampling is used to correct imbalanced class distributions. Our results show that a late-stage investor may be able to leverage purely qualitative knowledge of a company’s first three rounds of funding to assess the probability that (1) the company will not go bankrupt and (2) the company will eventually make an exit of some kind (and no longer remain private). For both of these two-class classification problems, our models’ out-of-sample success rate is 75% and the area under the ROC curve is 0.83, averaged across all sectors. Finally, we use the random forest classifier to rank the covariates based on how predictive they are. The results indicate that the models could provide both predictive and explanatory power for business decisions.	algorithm;compiler;database;random forest;receiver operating characteristic	Harish S. Bhat;Daniel Zaelit	2011		10.1007/978-3-642-20841-6_33	actuarial science;data mining;statistics	ML	-7.919825469745402	-29.78725846934314	34170
bbe77ddf13f7748e63f1edd212f9da98a59d4bc0	a survey and task-based quality assessment of static 2d colormaps	quality measurement;information visualization;quality measurement computer programming data analysis information visualization;computer programming;data analysis;inproceedings	Color is one of the most important visual variables since it can be combined with any other visual mapping to encode information without using additional space on the display. Encoding one or two dimensions with color is widely explored and discussed in the field. Also mapping multi-dimensional data to color is applied in a vast number of applications, either to indicate similar, or to discriminate between different elements or (multi-dimensional) structures on the screen. A variety of 2D colormaps exists in literature, covering a large variance with respect to different perceptual aspects. Many of the colormaps have a different perspective on the underlying data structure as a consequence of the various analysis tasks that exist for multivariate data. Thus, a large design space for 2D colormaps exists which makes the development and use of 2D colormaps cumbersome. According to our literature research, 2D colormaps have not been subject of in-depth quality assessment. Therefore, we present a survey of static 2D colormaps as applied for information visualization and related fields. In addition, we map seven devised quality assessment measures for 2D colormaps to seven relevant tasks for multivariate data analysis. Finally, we present the quality assessment results of the 2D colormaps with respect to the seven analysis tasks, and contribute guidelines about which colormaps to select or create for each analysis task. © (2015) COPYRIGHT Society of Photo-Optical Instrumentation Engineers (SPIE). Downloading of the abstract is permitted for personal use only.		Jürgen Bernard;Martin Steiger;Sebastian Mittelstädt;Simon Thum;Daniel A. Keim;Jörn Kohlhammer	2015		10.1117/12.2079841	simulation;information visualization;computer science;data science;data mining;computer programming;data analysis	HCI	-27.149715867429	-34.573329200437165	34194
1a8a0e5af29c449759aaa8a2564b068c9c14a573	predominance tag maps		A predominance map expresses the predominant data category for each geographical entity and colors are used to differentiate a small number of data categories. In tag maps, many data categories are present in the form of different tags, but related tag map approaches do not account for predominance, as tags are either displaced from their respective geographical locations or visual clutter occurs. We propose  predominance tag maps, a layout algorithm that accounts for predominance for arbitrary aggregation granularities. The algorithm is able to utilize the font sizes of the tags as visual variable and it is further configurable to implement aggregation strategies beyond visualizing predominance. We introduce various measures to evaluate numerically the qualitative aspects of tag maps regarding local predominance, global features, and layout stability and we comparatively analyze our method to the tag map approach by Thom et al.  [1] on the basis of real world data sets.	algorithm;categories;clutter;color;force-directed graph drawing;map;numerical analysis;tag cloud;tag system	Martin Reckziegel;Muhammad Faisal Cheema;Gerik Scheuermann;Stefan Jänicke	2018	IEEE Transactions on Visualization and Computer Graphics	10.1109/TVCG.2018.2816208	computer vision;data visualization;geospatial analysis;artificial intelligence;visualization;computer science;tag cloud;small number;data set;pattern recognition	Visualization	-25.99111412698435	-32.64721840336895	34287
182436d6a77951b811249dc38918dead35876746	a web-based communication module design of a real-time multi-sensor fire detection and notification system	fires gsm google navigation real time systems logic gates databases;web based gsm algorithm fire detection multi sensors real time;sensor fusion cellular radio emergency management fires internet real time systems;fire outbreak web based communication module design real time multisensor fire detection system real time multisensor fire notification system sim900 global system for mobile communication module remote notification fire alerts rescue crew fire crew map based navigation system	This paper presents the design and implementation of a web-based communication module of a multi-sensor fire detection system and notification system. A SIM900 Global System for Mobile Communication (GSM) module is used to send fire alerts to building owners and the web-based fire notification subsystem in real-time. The web-based notification system is intended for remote notification of fire alerts, allows fire and rescue crew to receive notifications of a fire outbreak in real time. Also implemented was a map based navigation system to guide the fire and rescue crew to the location of a fire outbreak. This component is crucial in areas and situations with less than ideal planning to improve the response times during a fire outbreak. A comparison between the efficiency of the notification system employed by standard fire detectors and the multi-sensor remote based notification approach adopted in this paper showed significant improvements in the form of timely detection, alerting and response.	notification system;real-time clock;real-time web;sensor;web application;world wide web	Robert Sowah;Abdul R. Ofoli;Selase Krakani;Seth Fiawoo	2014	2014 IEEE Industry Application Society Annual Meeting	10.1109/IAS.2014.6978416	embedded system;simulation;engineering;manual fire alarm activation;computer security	Mobile	-22.115904056340337	-28.862424484068725	34497
4ec838e140ef53583ac79370d78eee7064768e74	machine learning algorithms for event detection	relational data;scientific data;event detection;human behavior;real world application;spatio temporal data;machine learning;environmental science;public health	A common task in many machine learning application domains involves monitoring routinely collected data for ‘interesting’ events. This task is prevalent in surveillance, but also in tasks ranging from the analysis of scientific data to the monitoring of naturally occurring events, and from supervising industrial processes to observing human behavior. We will refer to this monitoring process with the purpose of identifying interesting occurrences, as event detection. We put together this special issue of the Machine Learning journal with the belief that principled machine learning approaches can and will be a differentiator in addressing event detection tasks, and that theoretical and practical advances of machine learning in this area have the potential to impact a wide range of important real-world applications such as security, public health and medicine, biology, environmental sciences, manufacturing, astrophysics, business, and economics. In the recent past, domain experts in these areas have had the laborious job of manually examining the collected data for events of interest. With the emergence of computers, many efforts have been made to replace manual inspection with an automated process. Data, however, have become increasingly complex, and the quantities of collected data have become extremely large in recent years. Multivariate records, images, video footage, audio recordings, spatial and spatio-temporal data, text documents, and even relational data are now routinely collected. We all expect that advances in machine learning would be well-suited for this class of tasks. However, in practice, the peculiarities of the application often grossly violate the	algorithm;application domain;computer;differentiator;emergence;image;machine learning;subject-matter expert;the machine	Dragos D. Margineantu;Weng-Keen Wong;Denver Dash	2010	Machine Learning	10.1007/s10994-010-5184-9	public health;relational database;computer science;data science;machine learning;data mining;human behavior;data	ML	-10.434047709491407	-34.29115890237422	34572
dd12684374233747fc841a8f715b7209507eef52	an improved simulated annealing algorithm for process mining	annealing;probability density function;simulated annealing algorithm;simulated annealing;data mining;process mining;simulated annealing business data processing data mining petri nets;simulated annealing computational modeling automatic control discrete event simulation information systems genetic algorithms prom collaborative work algorithm design and analysis computer simulation;business process execution;business data processing;control flow mining;control flow;genetic algorithms;process model;petri net process mining control flow mining simulated annealing;petri nets;prom;petri net simulated annealing process mining business process execution control flow mining;petri net;algorithm design and analysis	The target of process mining is to automatically extract process models from event logs related to actual business process executions. One of the most important fields concerned is control flow mining, i.e., ordering of activities. However, the presence of complicated constructs, such as duplicate tasks, invisible tasks and non-free-choice structures, hinders us from correctly discovering the relations between activities. Therefore, an improved simulated annealing approach is proposed in this paper to tackle these problems. To verify the performance, experiments are conducted in the process minig framework. The result is expressed in terms of Petri net.	algorithm;american cryptogram association;business process;computation;control flow;experiment;genetic algorithm;petri net;simulated annealing;time complexity	Dianfang Gao;Qiang Liu	2009	2009 13th International Conference on Computer Supported Cooperative Work in Design	10.1109/CSCWD.2009.4968104	simulated annealing;computer science;machine learning;data mining;database;petri net	Visualization	-7.3126670865368615	-29.43002993909628	34589
e3e244d40bc6fbeb96d9dda6141b59f9ebda80d1	machine learning for the activation of contraflows during hurricane evacuation	disaster management;traffic control;real time traffic data emergency evacuation plan contraflow lane reversal evacuation routes contraflow plan southeast louisiana hurricane evacuation hurricane threat contraflow activation scheduling landfall machine learning techniques;disaster management traffic control machine learning;storms emergency management learning artificial intelligence road traffic;machine learning;hurricanes machine learning algorithms delays algorithm design and analysis supervised learning prediction algorithms classification algorithms	Contraflows are a critical part of an emergency evacuation plan. In most cases, a contraflow lane reversal will double the capacity of key evacuation routes. The Contraflow plan for the evacuation of southeast Louisiana during a hurricane threat uses a typical schedule for the activation of contraflows based on the predicted time of landfall. This work will apply machine learning techniques using real-time traffic data to schedule the activation of contraflows. Optimizing the Contraflow plan should increase the effectiveness of the evacuation plan by increasing the flow of evacuation traffic based on demand and retaining the availability of incoming traffic until contraflow lanes are needed. These techniques could be applied to other locations, including those without an existing evacuation plan.	machine learning;optimizing compiler;plan 9 from bell labs;real-time clock	John W. Burris;Rahul Shrestha;Bibek Gautam;Bibidh Bista	2015	2015 IEEE Global Humanitarian Technology Conference (GHTC)	10.1109/GHTC.2015.7343981	simulation;engineering;operations research;computer security	AI	-15.594412673446026	-28.630797596328765	34643
61164025a668b6756884a5a3af6f51cfd08a3326	the design space of construction tools for information visualization: a survey		Abstract Information visualization has been widely used to convey information from data and assist communication. There are enormous needs of efficient visualization design for users from diverse fields to leverage the power of data. As a result, emerging construction tools for information visualization focus on providing solutions with different aspects including expressiveness, accessibility, and efficiency. In this paper, we review existing works on declarative specifications and user interfaces for visualization construction. By summarizing their methods for producing information visualizations and efforts on improving usability, we express the design patterns in terms of a design space which describes the tools in several different aspects. We discuss how the design space can be applied to support further exploration of potential research topics in the future.	information visualization	Honghui Mei;Yuxin Ma;Yating Wei;Wei Chen	2018	J. Vis. Lang. Comput.	10.1016/j.jvlc.2017.10.001	data mining;starlight information visualization system;theoretical computer science;visualization;visual analytics;software design pattern;computer science;usability;human–computer interaction;information visualization;user interface;information design	Visualization	-30.202127932805467	-31.615577378098266	34678
3cee856517f6194e79de504a561a6e22d4e717da	an unlicensed taxi identification model based on big data analysis	vehicles public transportation big data licenses data models real time systems;big data intelligent transportation systems machine learning data driven its unlicensed taxi;big data cost reduction data analysis intelligent transportation systems learning artificial intelligence mobile computing road vehicles social networking online;travel demand;social networking online big data cost reduction data analysis intelligent transportation systems learning artificial intelligence mobile computing road vehicles;urban transportation;networks;intelligent transportation systems;public transportation;taxi services;platform;unlicensed taxi big data intelligent transportation systems machine learning data driven its;travel;cyber physical systems;data analysis;machine learning;big data;licenses;algorithms;data driven its;vehicles;management;architecture;associated cost reduction unlicensed taxi identification model big data analysis social networks mobile networks big data analytics intelligent transportation systems data driven its d 2 its taxi business sector smart model submodel components candidate selection model candidate refined model coarse grained suspected unlicensed taxi candidate list machine learning traffic operation;unlicensed taxi identification model big data analysis social networks mobile networks big data analytics intelligent transportation systems data driven its d 2 its taxi business sector smart model submodel components candidate selection model candidate refined model coarse grained suspected unlicensed taxi candidate list machine learning traffic operation associated cost reduction;unlicensed taxi;data models;real time systems	Social networks and mobile networks are exposing human beings to a big data era. With the support of big data analytics, conventional intelligent transportation systems (ITS) are gradually changing into data-driven ITS (D2 ITS). Along with traffic growth, D2ITS need to solve more real-life problems, including the issue of unlicensed taxis and their identification, which potentially disrupts the taxi business sector and endangers society safety. As a remedy to this issue, a smart model is proposed in this paper to identify unlicensed taxis. The proposed model consists of two submodel components, namely, candidate selection model and candidate refined model. The former is used to screen out a coarse-grained suspected unlicensed taxi candidate list. The list is taken as an input for the candidate refined model, which is based on machine learning to get a fine-grained list of suspected unlicensed taxis. The proposed model is evaluated using real-life data, and the obtained results are encouraging, demonstrating its efficiency and accuracy in identifying unlicensed taxis, helping governments to better regulate the traffic operation and reduce associated costs.	big data;machine learning;real life;while	Wei Yuan;Pan Deng;Tarik Taleb;Jiafu Wan;Chaofan Bi	2016	IEEE Transactions on Intelligent Transportation Systems	10.1109/TITS.2015.2498180	simulation;big data;computer science;engineering;architecture;transport engineering;data analysis;platform;computer security	AI	-17.98049584846628	-33.477917891337256	34688
3030e3d92e27dfd92f7f9ff7247a852bf3f3f0d7	social context-aware trust network discovery in complex contextual social networks	macquarie university institutional repository;trust;researchonline;digital repository;macquarie university;social network;network discovery	Trust is one of the most important factors for participants’ decision-making in Online Social Networks (OSNs). The trust network from a source to a target without any prior interaction contains some important intermediate participants, the trust relations between the participants, and the social context, each of which has an important influence on trust evaluation. Thus, before performing any trust evaluation, the contextual trust network from a given source to a target needs to be extracted first, where constraints on the social context should also be considered to guarantee the quality of extracted networks. However, this problem has been proved to be NP-Complete. Towards solving this challenging problem, we first propose a complex contextual social network structure which considers social contextual impact factors. These factors have significant influences on both social interaction between participants and trust evaluation. Then, we propose a new concept called QoTN (Quality of Trust Network) and a social context-aware trust network discovery model. Finally, we propose a Social Context-Aware trust Network discovery algorithm (SCAN) by adopting the Monte Carlo method and our proposed optimization strategies. The experimental results illustrate that our proposed model and algorithm outperform the existing methods in both algorithm efficiency and the quality of the extracted trust network.	algorithm;algorithmic efficiency;mathematical optimization;monte carlo method;np-completeness;recommender system;run time (program lifecycle phase);social network;web of trust	Guanfeng Liu;Yan Wang;Mehmet A. Orgun	2012			digital library;computer science;dynamic network analysis;data mining;trustworthy computing;computational trust;social network	AI	-18.42931293335103	-45.037473091636635	34732
351b86ffc19cb02e51466522a0b4b199ac1dbd06	linking accounts across social networks: the case of stackoverflow, github and twitter		Social Web accommodates a wide spectrum of user activities, including information sharing via social media networks (e.g., Twitter), question answering in collaborative Q&A systems (e.g., StackOverflow), and more profession-oriented activities such as social coding in code sharing systems (e.g., Github). Social Web enables the distinctive opportunity for understanding the interplay between multiple user activity types. To enable such studies, a basic requirement, and a big challenge, is the ability to link user profiles across multiple social networks. By exploiting user attributes, platform-specific services, and different matching strategies, this paper contributes a methodology for linking user accounts across StackOverflow, Github and Twitter. We show how tens of thousands of accounts in StackOverflow, Github, and Twitter could be successfully linked. To showcase the type of research enabled by datasets built with our methodology, we conduct a comparative study of user interaction networks in the three platforms, and investigate correlations between users interactions across the different networks.	activity recognition;interaction;platform-specific model;question answering;social media;social network;stack overflow;user (computing);user profile	Giuseppe Silvestri;Jie Yang;Alessandro Bozzon;Andrea Tagarelli	2015			world wide web;internet privacy;social network;political science	Web+IR	-26.57907176254608	-47.96278717454371	34733
4c7e2869221c3ffd418c46089cc6256ec39228f0	utilization of discrete event simulation in the prospective determination of optimal cardiovascular lab processes	cardiovascular system;discrete event simulation;diseases;health care;optimisation;cardiovascular catheterization lab optimizing;cardiovascular disease;discrete event simulation;emergency department patients;optimal cardiovascular lab processes;process modification;prospective determination;simulation model;state model	The clinical character of cardiovascular disease creates challenges in optimizing cardiovascular catheterization lab (CVL) throughput. These challenges are due to case load fluctuations caused by unscheduled Emergency Department patients and simultaneous conflicting demands on cardiologist time. The simulation model provides insight into the complex relationship between patient acuity, treatment, occurrence of queues and bottlenecks in the transfer of patients. The study performed a comparative analysis between CVL operational schemes and assessed how those schemes impacted a variety of metrics related to throughput improvement. A current state model was developed, pertinent data was collected for the patient group and validation of the model was performed. Analysis of simulation results determined the most efficient CVL schedule and resource allocation to improve throughput and resource utilization. The study provides objective guidance to the optimal process modification and allows comparison of the relative differences in cost between the several redesign options.	bottleneck (software);prospective search;qualitative comparative analysis;queue (abstract data type);relevance;simulation;throughput	John S. Pirolo;Abhijit Ray;Matt Gadzinski;Mario Manese;Brannon Garvert;George Scoville;Howard Walpole;Bob Amland;Rebecca Boos;Ian Mamminga;Joan Brown;Kipp Donlon	2009	Proceedings of the 2009 Winter Simulation Conference (WSC)		qualitative comparative analysis;data modeling;communications protocol;throughput;in situ resource utilization;simulation;computer science;discrete event simulation;circulatory system;simulation modeling;biological engineering;health care	HPC	-16.646529974935323	-24.647547064512988	34739
500bc28498f0565beb14fc58ab54b9b360105466	assigning sentiment score for twitter tweets		Customer satisfaction has become a part of many business. Unlike in the past, companies just do not rely on pure advertisement to make their product more desirable. Their prime concern now has turned towards customer satisfaction. Similarly, people are more curious to know about the current popular opinion on events happening around the world and information about the favorite celebrities, favorite product, etc. People have turned towards social media to share their experiences and views about products as well as other people. The current work aims at using this as a base for developing a system that perceives the opinion of people about a specific product or a person. Till now, there is a lot of research that has been done in this topic. Various papers have showed different strategies to enhance sentiment analysis. In this paper, we have worked on improving the algorithms so that the sentiment conveyed can be classified in the appropriate class it belongs to.		Srinidhi Bhat;Saksham Garg;G. Poornalatha	2018	2018 International Conference on Advances in Computing, Communications and Informatics (ICACCI)	10.1109/ICACCI.2018.8554762	computer science;control engineering;marketing;feature extraction;customer satisfaction;sentiment analysis;social media	AI	-21.80201730750644	-51.710235970611784	34813
8e09e9619e86db9b701a05b65d3f8fdf6089c4c0	ds-cuber: an integrated olap environment for data streams	data cube;data stream;olap;data streams;network traffic	Most of emerging applications deal with an infinite data stream in an incessant, immense and volatile manner. Consequently, it is very important to analyze not only the varying characteristics of a source data stream in a short-term period but also those in a long-term period. For this purpose, this paper demonstrates an OLAP system, DS-Cuber (Data Stream Cuber) for the analysis of data streams. The proposed system consists of two analytic components: short-term and long-term, so that it can provide an integrated analysis environment for infinite data streams. Furthermore, each of these two components supports diversified exception detection methods which can be used for the automatic identification of abnormality in the data elements of a data stream in order to guide the data cube navigation of a user effectively. Network traffic flow streams are used to demonstrate the features of the DS-Cube system.	anomaly detection;automatic identification and data capture;data cube;network packet;online analytical processing;source data	Ho Jin Woo;Se Jung Shin;Woo Sock Yang;Won Suk Lee	2009		10.1145/1645953.1646304	online analytical processing;computer science;machine learning;data mining;database;data stream mining;world wide web;data cube	HPC	-10.155879731544488	-33.80621513030264	34898
591a930fbe9ce42156b057b72bf8e6d18a3148bf	characterizing uncertain data using compression		Motivated by sensor networks, mobility data, biology and life sciences, the area of mining uncertain data has recently received a great deal of attention. While various papers have focused on efficiently mining frequent patterns from uncertain data, the problem of discovering a small set of interesting patterns that provide an accurate and condensed description of a probabilistic database is still unexplored. In this paper we study the problem of discovering characteristic patterns in uncertain data through information theoretic lenses. Adopting the possible worlds interpretation of probabilistic data and a compression scheme based on the MDL principle, we formalize the problem of mining patterns that compress the database well in expectation. Despite its huge search space, we show that this problem can be accurately approximated. In particular, we devise a sequence of three methods where each new method improves the memory requirements orders of magnitudes compared to its predecessor, while giving up only a little in terms of approximation accuracy. We empirically compare our methods on both synthetic data and real data from life science. Results show that from a probabilistic matrix with more than one million rows and columns, we can extract a small set of meaningful patterns that accurately characterize the data distribution of any probable world.	approximation algorithm;bioinformatics;column (database);concatenation;experiment;jussi karlgren;mdl (programming language);possible world;probabilistic database;requirement;sampling (signal processing);synthetic data;theory;uncertain data	Francesco Bonchi;Matthijs van Leeuwen;Antti Ukkonen	2011		10.1137/1.9781611972818.46	uncertain data;wireless sensor network;fold (higher-order function);machine learning;computer science;artificial intelligence;pattern recognition;small set;probabilistic logic;probabilistic database;matrix (mathematics);synthetic data	DB	-9.196773181248572	-35.96352466795301	34954
2ed5bcb0d56c1b7b7e4805de1eeff031d68c3c96	top-k most incremental location selection with capacity constraint	brnn;capacity constraint;location selection;spatial database	Bichromatic reverse nearest neighbor (BRNN) based query uses the number of reverse nearest customers to model the influence of a facility location. The query has great potential for real life applications and receives considerable attentions from spatial database studies. In real world, facilities are inevitably constrained by designed capacities. When the needs of service increase, facilities in those booming areas may suffer from overloading. In this paper, we study a new kind of BRNN related query. It aims at finding most promising candidate locations to increase the overall service quality. To efficiently answer the query, we propose an O(n log n) algorithm using pruning techniques and spatial indices. To evaluate the efficiency of proposed algorithm, we conduct extensive experiments on both real and synthetic datasets. The results show our algorithm has superior performance over the basic solution.	algorithm;dhrystone;experiment;function overloading;quality of service;real life;spatial database	Yu Sun;Jin Huang;Yueguo Chen;Xiaoyong Du;Rui Zhang	2012		10.1007/978-3-642-32281-5_16	computer science;artificial intelligence;machine learning;data mining;database;world wide web	DB	-13.808865771417722	-36.99538592799596	34969
0fb2df74d8416144a6616c1ad4e235b5becb4fa2	an interactive visual query environment for exploring data	direct manipulation;interactive visualization;dynamic linking;lens interaction techniques;object oriented systems;data visualization;dynamic queries;subarctic;interactive debugging;interactive data exploration;context based rendering;database query;user interface toolkits;java;visual query language	Direct manipulation of visualizations is a powerful technique for performing exploratory data operations such as navigation, aggregation, and filtering. Its immediacy facilitates rapid, incremental, and ,reversible forays. into the *(data. However it does not provide for! reuse or modification of exploration sessions. This paper describes a visual query language, VQE, that adds these capabilities to a direct manipulation exploration environment called Visage. Queries and visualizations are’ dynamically linked: operations on either one immediately update the other, in contrast to the feedforward sequence of database query followed by .visualization of results common in traditional systems. 8, These features are supported by the architectural concept of threads,, which represent a sequence of navigation steps on particular objects. Because they are tied to, particular data objects, they can. be directly manipulated. : Because they represent operations, they can be generalized into queries. We expect this technique to apply to direct manipulation interfaces to any object-oriented system that represents both objects and the relationships among them. NOTE: Color versions of the, figures are at, e.g., htrp://www.cs.cmu.edu/-sageKJIST97/figurel.gif 1. THE MULTIPLE OBJECT PROBLEM We are concerned with data visualization systems that produce “business graphics” consisting of charts, maps, network ‘diagrams, as well & more sophisticated and special purpose graphics showing abstract data. It is often natural to provide $e user with -an object-oriehted data model to accompanj; these @alizations. For instance in Permission to make di&l/iwd copies’ofnll or port ofthis material for pcrsonnl or clnssroom use is’gnntcd without fee provided that the copies ore not mndc or distribukd for prolit or conunrrcinl ndvnntage. (IIF copyri&t notice, the title of tl!e,publicntioo nod its date appear. and notice is. given that copyri&t is by permission ofthe ACM, Inc. To copy otherwise, to republish. to post on servers or to redistribllte to lists, requires specific	chart;data model;data visualization;database;diagram;direct manipulation interface;feedforward neural network;filter (signal processing);graphics;iif;map;query language;thread (computing);visage	Mark Derthick;John Kolojejchick;Steven F. Roth	1997		10.1145/263407.263545	interactive visualization;human–computer interaction;computer science;theoretical computer science;operating system;database;subarctic climate;programming language;java;world wide web;data visualization	DB	-29.70019151432731	-32.81407629949712	35045
a436b8a5167eafc78c8936b848d687ce707b80da	cluster analysis for personalised mobile entertainment content		There is much attention given to emerging technologies like mobile internet because of its increasing popularity. Much research has concentrated on hardware and some have focused on personalisation in terms of content visualisation. The focus of this paper is on mobile content personalisation, seeking to understand the user groups through clustering users based on their profile. This paper focuses on the implementation of a technique known as ‘Zoning-Centroid’, which is the evaluation technique used to determine the appropriate number of clusters required to best cluster the given users profile. The user profile used in this paper includes mobile content usage and their demographic factors. The clustering algorithm used in this paper is k-means clustering. The results show that the proposed technique could suggest appropriate number of clusters to be used with the k-values, in order to implement for mobile entertainment content personalisation.	algorithm;cluster analysis;geographical zoning;k-means clustering;personalization;user profile	Worapat Paireekreng;Kevin Kok Wai Wong;Lance Chun Che Fung	2010		10.1007/978-3-642-15214-6_4	mobile search;multimedia;world wide web	Web+IR	-27.07380922689006	-43.762612651542824	35106
83a0dda1cc5c2daf3173232f259ed13271234d08	efficient method for mining patterns from highly similar and dense database based on prefix-frequent-items	sequential pattern mining	In recent years, there are a great deal of efforts on sequential pattern mining, but some challenges have not been resolved, such as large search spaces and the ineffectiveness in handling highly similar, dense and long sequences. This paper mainly focuses on how to design some effective search space pruning methods to accelerate the mining process. We present a novel structure, PrefixFrequent-Items Graph (PFI-Graph), which presents the prefix frequent items of other items in sequential patterns. An efficient algorithm PFI-PrefixSpan (Prefix-FrequentItems PrefixSpan) based on PFI-Graph is proposed in this paper. It avoids redundant data scanning, and thus can effectively speed up the discovery process of new patterns. Extensive experimental results on some synthetic and real sequence datasets show that the proposed novel structure is substantially more efficient than PrefixSpan with physicalprojection and pseudo-projection, especially for dense and highly similar sequence databases.	algorithm;data mining;redundancy (engineering);sequence database;sequential pattern mining;synthetic intelligence	Meng Han;Zhihai Wang;Jidong Yuan	2014	JSW		sequential pattern mining;computer science;bioinformatics;data mining;database	ML	-6.398444636810913	-38.24907789654834	35133
1ed8d055f24e60db967a84600eb5cd0d01af5180	blog community discovery and evolution based on mutual awareness expansion	information services web sites internet humans web search search engines decision making data mining clustering algorithms partitioning algorithms;directed graphs;community evolution;web sites decision making directed graphs information needs query processing random processes social sciences computing;directed action graph;time dependent;community dynamics;community evolution blog community discovery mutual awareness expansion information needs community centric search decision making temporal dynamics thematic communities query directed action graph random walk process;temporal dynamics;query processing;blog community discovery;information needs;satisfiability;web search engine;community centric search;social sciences computing;random walk;web sites;random processes;query;thematic communities;random walk process;mutual awareness expansion;information need;interactive space	There are information needs involving costly decisions that cannot be efficiently satisfied through conventional web search engines. Alternately, community centric search can provide multiple viewpoints to facilitate decision making. We propose to discover and model the temporal dynamics of thematic communities based on mutual awareness, where the awareness arises due to observable blogger actions and the expansion of mutual awareness leads to community formation. Given a query, we construct a directed action graph that is time-dependent, and weighted with respect to the query. We model the process of mutual awareness expansion using a random walk process and extract communities based on the model. We propose an interaction space based representation to quantify community dynamics. Each community is represented as a vector in the interaction space and its evolution is determined by a novel interaction correlation method. We have conducted experiments with a real-world blog dataset and have promising results for detection as well as insightful results for community evolution.	blog;blogger;emergence;emoticon;evolution;experiment;information needs;observable;web search engine	Daniel Crabtree;Peter Andreae;Xiaoying Gao	2007	IEEE/WIC/ACM International Conference on Web Intelligence (WI'07)	10.1109/WI.2007.30	information needs;web search engine;computer science;data science;machine learning;data mining;world wide web;random walk;statistics	AI	-22.103364136608125	-43.79049467374925	35190
1eed2fd255dea2e8695583b7a9e987477b8029b9	dengueviz: a knowledge-based expert system integrated with parallel coordinates visualization in the dengue diagnosis		The DengueViz is a knowledge-based expert system integrated with parallel coordinates as its visualization technique to diagnose dengue. The dengue diagnosis results includes the dengue classifications and their probability according to the interactions of users with the system. The knowledge base of this system consists of 140 rules for the classification of dengue. The integration of parallel coordinates visually presents the large amount of dengue information into a single visualization, where data interactions such as the selection of axes, filtering and highlighting reduces the clutter for it to be more comprehensible and enhances the correlation between the attributes of the information.	clutter;expert system;information visualization;interaction;knowledge base;parallel coordinates;venue (sound system)	Jodene Yen Ling Ooi;J. Joshua Thomas	2017		10.1007/978-3-319-70010-6_5	visualization;knowledge base;computer vision;artificial intelligence;parallel coordinates;expert system;information visualization;computer science	HPC	-27.004901165572093	-31.003907684341264	35213
5c0660f31c022bfaa100b78c2eacf632382ac4c5	large scale cohesive subgraphs discovery for social network visual analysis	important social actor;active social community;social network;local cohesive subgraph;social graph;cohesive subgraphs discovery;social interaction;social actor;visual analysis;cohesive subgraphs;large scale;social network analysis	Graphs are widely used in large scale social network analysis nowadays. Not only analysts need to focus on cohesive subgraphs to study patterns among social actors, but also normal users are interested in discovering what happening in their neighborhood. However, effectively storing large scale social network and efficiently identifying cohesive subgraphs is challenging. In this work we introduce a novel subgraph concept to capture the cohesion in social interactions, and propose an I/O efficient approach to discover cohesive subgraphs. Besides, we propose an analytic system which allows users to perform intuitive, visual browsing on large scale social networks. Our system stores the network as a social graph in the graph database, retrieves a local cohesive subgraph based on the input keywords, and then hierarchically visualizes the subgraph out on orbital layout, in which more important social actors are located in the center. By summarizing textual interactions between social actors as tag cloud, we provide a way to quickly locate active social communities and their interactions in a unified view.	experiment;frame rate control;friend-to-friend;graph database;input/output;interaction;molecular orbital;scalability;social graph;social media;social network analysis;tag cloud	Anthony K. H. Tung	2012	PVLDB	10.14778/2535568.2448942	computer science;data science;data mining;database;world wide web	DB	-28.15776331205028	-35.588006476575394	35219
1c017445cf770f520c395ecdea7d301d0ddeab25	centrality and cluster analysis of yelp mutual customer business graph	pattern clustering business data processing customer relationship management graph theory;business urban areas sociology statistics joining processes weight measurement web pages;spectral clustering cluster analysis yelp mutual customer business graph customer relationships yelp academic dataset las vegas phoenix centrality analysis spectral analysis pagerank graph measures graph centralities	This paper proposes a novel approach to understand customer relationships among businesses and the type of information that can be inferred from these relationships. Our approach is grounded in a unique method of constructing a mutual customer business graph, where businesses are represented by nodes and the weight of the edge connecting two businesses reflects the strength of their mutual customer population, which is estimated based on the reviews from the Yelp academic data set. We construct and analyze these mutual customer business graphs for cities of Las Vegas and Phoenix using centrality and spectral analysis techniques. Centrality analysis computes unweighted and weighted versions of degree and PageRank graph measures; the results reveal that businesses with high graph centralities also tend to be geographically central relative to other businesses. Spectral clustering partitions the graph to group businesses that are frequented by the same set of customers. An analysis of the frequency distribution of words from the reviews within each cluster suggests that businesses aggregate around a theme. Taken together, these findings suggest that customers prefer to visit businesses that are geographically proximate and/or offer similar products and services. We discuss how businesses could strategically position themselves by considering the impact of these two factors in attracting clientele.	aggregate data;algorithm;centrality;cluster analysis;ibm parallel sysplex;pagerank;spectral clustering;spectrum analyzer	Brian McClanahan;Swapna S. Gokhale	2016	2016 IEEE 40th Annual Computer Software and Applications Conference (COMPSAC)	10.1109/COMPSAC.2016.79	artificial intelligence;data mining;database;management;computer security	DB	-19.533739989418734	-38.89549015237904	35220
ff936ae8e3f890313dc91aa909ab8e6342fb1409	personalized social network activity feeds for increased interaction and content contribution	user engagement;feed personalization;social network feed;content contribution;online evaluation	Online social networks were originally conceived as means of sharing information and activities with friends, and their success has been one of the primary contributors of the tremendous growth of the Web. Social network activity feeds were devised as a means to aggregate recent actions of friends into a convenient list. But the volume of actions and content generated by social network users is overwhelming, such that keeping users up-to-date with friend activities is an ongoing challenge for social network providers. Personalization has been proposed as a solution to combat social network information overload and help users to identify the nuggets of relevant information in the incoming flood of network activities. In this paper, we propose and thoroughly evaluate a personalized model for predicting the relevance of the activity feed items, which informs the ranking of the feeds and facilitates personalization. Results of a live study show that the proposed feed personalization approach successfully identifies and promotes relevant feed items and boosts the uptake of the feeds. In addition, it increases the contribution of user-generated content to the social network and spurs interaction between users.	aggregate data;information overload;institute for operations research and the management sciences;personalization;relevance;social network;user-generated content;web feed;world wide web	Shlomo Berkovsky;Jill Freyne	2015	Front. Robotics and AI	10.3389/frobt.2015.00024	multimedia;world wide web	Web+IR	-26.97489699005783	-46.23715671908313	35222
1b8ab29abbb2c040a8657bcc2455a53f670a5d8e	nearness and influence based link prediction (nilp) in distributed platform		Link prediction is a trending research direction in the field of social network analysis due to its vast application especially in the field of network evolution analysis like discovering missing links, identifying positive and negative links etc. It is also used for recommending commodities in e-commerce sites and suggesting friends in online social network. The objective of this paper is to predict hidden or missing links in a directed or undirected, unweighted social network using distributed platform like Spark, which is found to be both accurate and reasonably robust due to its scalable nature. This approach is found to be effective as compared to conventional methods as it considers number of parameters together such as the influence of a node, community structure of the network and the shortest paths between nodes. This approach is found to be efficient as compared to other path-based approaches as it has comparatively less time complexity and preferable over other node-based approaches owing to its accuracy with reasonable computational time.		Ranjan Kumar Behera;Lov Kumar;Monalisa Jena;Sambit Mahapatra;Abhishek Sai Shukla;Santanu Kumar Rath	2017		10.1007/978-3-319-62407-5_23	time complexity;social network analysis;computer network;spark (mathematics);scalability;computer science;social network;community structure;distributed computing	Robotics	-13.003191950158959	-41.83347681418282	35283
ca87ca7d442ec5c1e5c6288f6dc8fb9d10b99d0a	performance analysis of healthcare processes through process mining		is based on explicit personalization, by exploiting the scientists’ social networks, using gossip protocols that scale well. Relevance measures may be expressed based on similarities, users’ confidence, document popularity, rates, etc., and combined to yield different recommendation criteria. With P2Prec, each user can identify data (documents, annotations, datasets, etc.) provided by others and send queries to them. For instance, one may want to know which scientists are expert in a topic and get documents highly rated by them. Or another may look for the best datasets used by others for some experiment. To efficiently disseminate information among peers, we propose new semantic-based gossip protocols. Furthermore, P2Prec has the ability to get reasonable recall with acceptable query processing load and network traffic.	database;document;experiment;gossip protocol;network traffic control;personalization;profiling (computer programming);relevance;social network	Diogo R. Ferreira	2012	ERCIM News		data science;data mining;business process discovery;process mining;computer science;health care	DB	-24.787039189202574	-49.73040629383396	35296
17e7e12f263bb9f484c080a975dc8e41f928d57b	development of the rule based approach to traffic management by the dutch road authorities		Rule based traffic management is a methodology for dynamic traffic management that is a joint development of the different road authorities in the Netherlands. The approach tackles operational issues by disentangling problem detection, problem solution and conflict handling for each element in the road network. Each element in the road network follows the same generic rules and defers the traffic problem to other roads in the network that have less priority. This way traffic is distributed across the road network and congestion is prevented.	network congestion	Silvie Spreeuwenberg;Rolf Krikke	2017			data mining;rule-based system;computer science	Metrics	-16.826546947999663	-25.524517429171166	35304
399d1a909610fe732989dad763191c73514b2b16	cardinality estimation: an experimental survey		Data preparation and data profiling comprise many both basic and complex tasks to analyze a dataset at hand and extract metadata, such as data distributions, key candidates, and functional dependencies. Among the most important types of metadata is the number of distinct values in a column, also known as the zeroth-frequency moment. Cardinality estimation itself has been an active research topic in the past decades due to its many applications. The aim of this paper is to review the literature of cardinality estimation and to present a detailed experimental study of twelve algorithms, scaling far beyond the original experiments. First, we outline and classify approaches to solve the problem of cardinality estimation – we describe their main idea, error-guarantees, advantages, and disadvantages. Our experimental survey then compares the performance all twelve cardinality estimation algorithms. We evaluate the algorithms’ accuracy, runtime, and memory consumption using synthetic and real-world datasets. Our results show that different algorithms excel in different in categories, and we highlight their trade-offs. PVLDB Reference Format: Hazar Harmouch and Felix Naumann. Cardinality Estimation: An Experimental Survey. PVLDB, 11(4): 499 512, 2017. DOI: https://doi.org/10.1145/3164135.3164145 1. DATA PROFILING AND CARDINALITY The research area of data profiling includes a large set of methods and processes to examine a given dataset and determine metadata about it [1]. Typically, the results comprise various statistics about the columns and the relationships among them, in particular dependencies. Among the basic statistics about a column are data type, the number of unique values, maximum and minimum values, the number of null values, and the value distribution. Dependencies involve for instance functional dependencies, inclusion dependencies, and their approximate versions. Data profiling has Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Articles from this volume were invited to present their results at The 44th International Conference on Very Large Data Bases, August 2018, Rio de Janeiro, Brazil. Proceedings of the VLDB Endowment, Vol. 11, No. 4 Copyright 2017 VLDB Endowment 2150-8097/17/12... $ 10.00. DOI: https://doi.org/10.1145/3164135.3164145 a wide range of conventional use cases, namely data exploration, cleansing, and integration. The produced metadata is also useful for database management and schema reverse engineering. Data profiling has also more recent use cases, such as big data analytics. The generated metadata describes the big data structure, how to import it, what it is about, and how much of it there is. Thus, data profiling can be considered as an important preparatory task for many big data analysis and mining scenarios to assess which data might be useful and to reveal a new dataset’s characteristics. In this paper, we focus on one facet of big data profiling: finding the number of distinct values in a column of a large dataset. Finding this “cardinality” is an active research area, because of its ever growing number of applications in a wide range of computer science domains. Besides its importance as a fundamental task in database query processing and optimization [33], counting distinct values is considered as one of the main studied problems in network security monitoring [12], data streams [2], search engines and online data mining [24, 27]. Moreover, the number of distinct values is used in connectivity analysis of internet topology to find the distance between a pair of nodes in the Internet graph [17]. Without doubt, given a memory size linear to the cardinality of the dataset makes finding the cardinality an easy task. Nevertheless, such memory need is too much for some applications. Therefore, many algorithms to approximate the cardinality of a dataset have been developed in a manner reducing resource/memory consumption. The other costdimension to consider is that of I/O. However, it can be shown that approaches that save cost by sampling cannot guarantee any reasonable degree of accuracy. Thus, research has focussed on reducing memory consumption and assumes to read all data only once. This paper presents many wellknown algorithms with which the cardinality can be estimated in big datasets using small additional storage and a small number of operations per element. Our results serve as a guide to choose a suitable algorithm for a given use-case. Outline. The rest of this paper is organized as follows: We first formally define the problem of finding the cardinality of a dataset, present general approaches used in literature to solve this problem, and discuss several classifications of concrete algorithms to estimate the cardinality of a dataset in Section 2. In Section 3, we present, discuss, and compare twelve well-known algorithms. Section 4 presents our comprehensive set of comparative experiments using both synthetic and real-world data, and reports the results of the empirical evaluation. Finally, we conclude in Section 5.	approximation algorithm;big data;column (database);computer science;data mining;data structure;database;dhrystone;experiment;functional dependency;image scaling;internet topology;mathematical optimization;maxima and minima;network security;referential integrity;reverse engineering;sampling (signal processing);streaming algorithm;synthetic intelligence;vldb;web search engine;winsock	Hazar Harmouch;Felix Naumann	2017	PVLDB	10.1145/3164135.3164145	cardinality;data mining;computer science	DB	-8.780637009410682	-33.82346680545051	35316
636894c6fb51673b181600378daf0f70cab454bd	simulation-based evaluation of adaptive automation revoking strategies on cognitive workload and situation awareness	simulation adaptive automation human performance modeling revoking strategies;automation adaptive systems adaptation models physiology monitoring real time systems safety	Adaptive systems have used a variety of approaches to return the task responsibility back to the user, including restoration of performance or physiological thresholds, leveling of task loads, and user-initiated deactivation. Little attention has been paid to evaluating the relative effectiveness of these various hand-off mechanisms, or the impact that these mechanisms may have on operator workload and situation awareness (SA). This study uses an Improved Performance Research Integration Tool simulation, based upon a human-in-the-loop study, to examine two different revoking strategies (minimum duration and workload threshold) across numerous levels in order to identify impacts on operator workload and SA. This study finds that operator workload and SA are affected by the type of revoking strategy as well as the particular level used for that strategy. For the scenario examined, automation revoking that relied upon a minimum duration of at least 5 s was found to be more effective in reducing workload and increasing SA than using a revoking strategy based upon workload thresholds.	adaptive system;automation;business analytics;circuit restoration;computer simulation;dynamical system;human factors and ergonomics;human performance modeling;human reliability;humans;human–computer interaction;industrial engineering;institute for operations research and the management sciences;inventory;management science;mathematical optimization;multi-objective optimization;partial template specialization;performance prediction;scheduling (computing);systems engineering;taxonomy (general);telerobotics;theory;user interface	Christina F. Rusnock;Christopher D. Geiger	2017	IEEE Transactions on Human-Machine Systems	10.1109/THMS.2016.2618004	workload;adaptive system;operator (computer programming);automation;computer science;real-time computing;situation awareness;cognition	DB	-24.565185235192068	-24.261112965112737	35347
7bbe5105a8578344faa35c76fc75d8c24d7cb620	a freight train simulator - design and implementation of a training simulator for freight train conductors			train simulator	R. P. Marques;F. Kassab Junior;Rodrigo dos Santos Barbosa;Koji Nishimoto	2013			simulation;engineering;rail freight transport;automotive engineering	HCI	-20.93543474603949	-24.74698227851603	35359
30fbc13ab546efd0af01621dcfc28e191a32a7e8	improving search engines via large-scale physiological sensing		Result ranking in commercial web search engines is based on a wide array of signals, from keywords appearing on web pages to behavioral (clickthrough) data aggregated across many users or from the current user only. The recent emergence of wearable devices has enabled the collection of physiological data such as heart rate, skin temperature, and galvanic skin response at a population scale. These data are useful for many public health tasks, but they may also provide novel clues about people's interests and intentions as they engage in online activities. In this paper, we focus on heart rate and show that there are strong relationships between heart rate and various measures of user interest in a search result. We integrate features of heart rate, including heart rate dynamics, as additional attributes in a competitive machine-learned web search ranking algorithm. We show that we can obtain significant relevance improvements from this physiological sensing that vary depending on the search topic.	emergence;galvanic isolation;relevance;search algorithm;wearable technology;web page;web search engine	Ryen W. White;Ryan Ma	2017		10.1145/3077136.3080669	computer science;web page;information retrieval;world wide web;wearable technology;data mining;skin conductance;search engine;wearable computer;ranking;population	Web+IR	-27.83409619843453	-45.43777667820173	35360
0602fcaa5967a653ec69f7b5e6708428bbd4e261	big data for stock market by means of mining techniques	text mining;stock prediction;big data	Predict and prevent future events are the major advantages to any company. Big Data comes up with huge power, not only by the ability of processes large amounts and variety of data at high velocity, but also by the capability to create value to organizations. This paper presents an approach to a Big Data based decision making in the stock market context. The correlation between news articles and stock variations it is already proved but it can be enriched with other indicators. In this use case they were collected news articles from three different web sites and the stock history from the New York Stock Exchange. In order to proceed to data mining classification algorithms the articles were labeled by their sentiment, the direct relation to a specific company and geographic market influence. With the proposed model it is possible identify the patterns between this indicators and predict stock price variations with accuracies of 100 percent. Moreover the model shown that the stock market could be sensitive to news with generic topics, such as government and society but they can also depend on the geographic cover.		Luciana Lima;Filipe Portela;Manuel Filipe Santos;António Abelha;José Machado	2015		10.1007/978-3-319-16486-1_67	data science;data mining;commerce	ML	-9.26922685417626	-31.00496946711709	35382
d25d70073cbfc6a627f0980095298e902885bf01	a comparison of structural and behavioral community detection algorithms.		Community detection in large social, biological or information network is an important problem since it helps uncover hidden structural properties in the network. For detecting communities, one typically defines or chooses an objective function such that a higher value corresponds to clusters densely connected inside and sparsely connected to nodes outside its cluster. It is shown that such communities often have things in common among its members. There have been a multitude of comparative studies of different objective functions and/or different methodologies for optimization. But to the best of author’s knowledge, there have not been any comparative study of community detection methodologies that rely only on structural data with methodologies that rely entirely on behavioral data. For this purpose, node pair similarity is modelled in terms of behaviour data and well known clustering methodologies along with other structural methods are executed on a real world network. The results are then objectively evaluated using 6 well defined quality functions, i.e., modularity, density, separability, clustering coefficient, like-mindedness and like-mindedness ratio. We also provide a new behavioral property based hierarchical clustering algorithm which attempts to maximize one of the behavioral quality functions (like-mindedness).	algorithm;cluster analysis;clustering coefficient;hierarchical clustering;linear separability;loss function;mathematical optimization;mind;optimization problem;sensor	Hindol Adhya;Shyamal Kejriwal;Talasila Sai Deepak;Bhanuteja Gullapalli;Saswata Shannigrahi	2013	CoRR		machine learning	ML	-14.231611633335925	-41.47664705342249	35404
4a7570a52f44f96327c605160d41c911e8d0d8e8	lattice navigation for collaborative filtering by means of (fuzzy) formal concept analysis	settore inf 01 informatica;lattice navigation algorithm;collaborative filtering;fuzzy formal concept analysis;recommender systems	"""Recommender systems rely on the opinions of a community of users to provide """"recommendations"""" that can help users of the same community in discerning content of interest from a wide range of possibilities. Particularly, collaborative information filtering represents one of techniques widely exploited by recommender systems to suggest which items better meet the user needs and preferences. This paper introduces a model for collaborative filtering based on Formal Concept Analysis, a theoretical framework suitable to generate correlations among data through a lattice design. In particular, a fuzzy annotation of the lattice allows discovering similarities among items as well as users, arranged as a ranked list."""	collaborative filtering;formal concept analysis;information filtering system;recommender system	Sabrina Senatore;Gabriella Pasi	2013		10.1145/2480362.2480538	computer science;knowledge management;artificial intelligence;collaborative filtering;machine learning;data mining;database;world wide web;recommender system	Web+IR	-27.337209540703032	-50.344020468206935	35417
f5fa10c0966b872a67e12ac1a57f08e61706e4ab	generating useful photo context metadata for the semantic web	mobile device;search engines;conference management;digital cameras;mobile handsets;semantic web;semantic web marketing and sales search engines digital cameras needles mobile handsets digital images conference management;digital images;needles;marketing and sales	An approach focussed on resolving identity of subjects in a photo using mobile device connectivity and semantics is presented in this paper. Semantic Web and mobile device sensors are combined to provide meaningful photo annotation metadata that can be used to recall photos from the Web. Useful metadata can be gleaned from the environment at the time of capture and inferred from previous metadata tapped from existing sources.	mobile device;semantic web;sensor;world wide web	Fergal Monaghan;David O'Sullivan	2006	7th International Conference on Mobile Data Management (MDM'06)	10.1109/MDM.2006.93	mobile search;semantic grid;image retrieval;computer science;operating system;semantic web;social semantic web;mobile device;semantic web stack;database;multimedia;internet privacy;world wide web;digital image	Robotics	-29.1825950173751	-51.7351447357819	35426
4cb8f3a5987799ade8b12d269cc89566afc32b75	cotrams: a collaborative and opportunistic traffic monitoring system	traffic simulation;wireless lan computerised monitoring road traffic control road vehicles telecontrol traffic engineering computing;wireless communication systems;prototypes;collaboration;smartphones;collaborative and opportunistic traffic monitoring system road condition network bandwidth global positioning system brazil rio de janeiro real public wireless network ieee 802 11 b g network vehicle movement user participation automated systems video cameras traffic jams traffic control cotrams;vehicles roads ieee 802 11 standards monitoring global positioning system collaboration prototypes;monitoring;roads;global positioning system;ieee 802 11 standards;rio de janeiro brazil;algorithms;traffic surveillance;vehicles;ieee 802 11 standard;wireless networks automotive applications wireless application protocol	Traffic monitoring and control are becoming more and more important as the number of vehicles and traffic jams grow. Nevertheless, these tasks are still predominantly performed by visual means using strategically placed video cameras. For more effectiveness, proposals to improve traffic monitoring and control should consider automated systems. In this paper, we propose the Collaborative and Opportunistic Traffic Monitoring System (COTraMS), which is a system that monitors traffic using available IEEE 802.11 networks. COTraMS is collaborative because user participation is essential in defining the vehicle movement and opportunistic because it uses existing information. To evaluate the performance of COTraMS, a prototype is implemented using an IEEE 802.11 b/g network. Measurements from a real public wireless network in Rio de Janeiro, Brazil, demonstrate the possibility of obtaining traffic conditions with our proposed monitoring system. In addition, we analyze COTraMS via simulation to evaluate its performance in scenarios with a larger number of vehicles. The comparison of the obtained results with data obtained from Global Positioning System shows high accuracy in detecting both the position of the vehicle and the estimation of the road condition, using a simple architecture and a small amount of network bandwidth.	global positioning system;prototype;sensor;simulation;website monitoring;winsock	José Geraldo Ribeiro;Miguel Elias M. Campista;Luís Henrique Maciel Kosmalski Costa	2014	IEEE Transactions on Intelligent Transportation Systems	10.1109/TITS.2013.2291996	traffic generation model;network traffic control;floating car data;global positioning system;telecommunications;computer science;engineering;prototype;computer security;computer network;collaboration	Mobile	-19.27071744670265	-29.637910663585906	35427
43162caec5b6cad5437e7896216c0cb3e2a24887	collaborative dynamic sparse topic regression with user profile evolution for item recommendation		In many time-aware item recommender systems, modeling the accurate evolution of both user profiles and the contents of items over time is essential. However, most existing methods focus on learning users’ dynamic interests, where the contents of items are assumed to be stable over time. They thus fail to capture the dynamic changes in the item’s contents. In this paper, we present a novel method CDUE for time-aware item recommendation, which captures the evolution of both user’s interests and item’s contents information via topic dynamics. Specifically, we propose a dynamic sparse topic model to track the evolution of topics for changes in items’ contents over time and adapt a vector autoregressive model to profile users’ dynamic interests. The item’s topics and user’s interests and their evolutions are learned collaboratively and simultaneously into a unified learning framework. Experimental results on two real-world data sets demonstrate the quality and effectiveness of the proposed method and show that our method can be used to make better future recommendations.	autoregressive model;evolution;recommender system;sparse matrix;topic model;user profile;vector autoregression	Li Gao;Jia Wu;Chuan Zhou;Yue Hu	2017			recommender system;computer science;data mining;information retrieval;user profile	AI	-18.850429152392177	-47.975516906840355	35449
f3e3af450960d8614efe53d3f076b6e43966efbd	a face-encoding grammar for the generation of tetrahedral-mesh soft bodies		Many of the most profound works of artificial life have emerged through the composition of physical simulation and generative representations. And yet, while physics engine s are becoming more realistic, and generative representatio s are growing more powerful, they are still predominantly use d to simulaterigid objects. The natural world and its organisms are, by contrast, soft, and full of much more interesting (and complex) interactions than those which can be faithfully re produced by rigid body dynamics. In this work we describe and implement a grammatical encoding capable of generating large, complex, and multi-resolution soft structureswhich can be natively simulated by the state-of-the-art hardware accelerated physics engines. The structures generated by t he encoding exhibit all the benefits (structural modularity, l argescale co-ordinated change) of more conventional rigid-bod y generative encodings.	artificial life;british informatics olympiad;dynamical simulation;generative grammar;hardware acceleration;interaction;physics engine	John Rieffel;Schuyler Smith	2010			natural language processing;computer science;artificial intelligence;machine learning	AI	-6.052149140471712	-48.132957860585286	35539
b426e5ea01e6cf934508f109d5e9cb0a2c4fc9f0	personalized intra- and inter-city travel recommendation using large-scale geotags	travel recommendation;intra city recommendation;inter city recommendation;geotag;seasonal and temporal information	In this paper, a geotag-based inter- and intra-city travel recommendation system that considers both the personal preference and the seasonal/temporal popularity is presented. For the inter-city recommendation, a combination of two similarity measure among users is proposed. Accurate intra-city recommendation is achieved by incorporating the seasonal and temporal information into a Markov model. The effectiveness of the proposed algorithm has been experimentally demonstrated by using more than 6 million geotags downloaded from Flickr.	algorithm;experiment;flickr;geotagging;markov chain;markov model;recommender system;seasonality;similarity measure	Toshihiko Yamasaki;Andrew C. Gallagher;Tsuhan Chen	2013		10.1145/2509230.2509237	geography;multimedia;advertising;world wide web	Web+IR	-23.528545401860974	-46.07633420019109	35654
25bc48fcdd1d32d9a09e77d457c57c3dca6db761	followee recommendation in asymmetrical location-based social networks	semantic similarity;location based social network lbsn;data mining;followee recommendation	Researches on recommending followees in social networks have attracted a lot of attentions in recent years. Existing studies on this topic mostly treat this kind of recommendation as just a type of friend recommendation. However, apart from making friends, the reason of a user to follow someone in social networks is inherently to satisfy his/her information needs in asymmetrical manner. In this paper, we propose a novel mining-based recommendation approach named Geographic-Textual-Social Based Followee Recommendation (GTS-FR), which takes into account the user movements, online texting and social properties to discover the relationship between users' information needs and provided information for followee recommendation. The core idea of our proposal is to discover users' similarity in terms of all the three properties of information which are provided by the users in a Location-Based Social Network (LBSN). To achieve this goal, we define three kinds of features to capture the key properties of users' interestingness from their provided information. In GTS-FR approach, we propose a series of novel similarity measurements to calculate similarity of each pair of users based on various properties. Based on the similarity, we make on-line recommendation for the followee a user might be interested in following. To our best knowledge, this is the first work on followee recommendation in LBSNs by exploring the geographic, textual and social properties simultaneously. Through a comprehensive evaluation using a real LBSN dataset, we show that the proposed GTS-FR approach delivers excellent performance and outperforms existing stat-of-the-art friend recommendation methods significantly.	arm big.little;binary classification;experiment;fr-v (microprocessor);geosocial networking;global telecommunications system;information needs;online and offline;social network	Jia-Ching Ying;Eric Hsueh-Chan Lu;Vincent S. Tseng	2012		10.1145/2370216.2370431	semantic similarity;computer science;data mining;world wide web;information retrieval	Web+IR	-21.907402139127925	-48.04960303367054	35766
f3e6aa966fcd722e50233b28d5885968576d8573	the mechanism to predict folders in automatic classification email messages to folders in the mailboxes		This paper was proposed a new method for suggesting creating folders in users mailboxes by using Ant Colony Optimization algorithms and Social Networks Analysis. The aim of this paper is to create a mechanism to predict new folders in automatic classification email messages to folders in the mailboxes. The proposed algorithm uses the elements of Social Networks Analysis used to determine the groups of users who have a similar folder structure in mailboxes, on the basis of which the mechanism suggest new folders for the users. The operation of the proposed method has been tested on a public Enron E-mail Dataset.	email	Barbara Probierz	2018		10.1007/978-3-319-98446-9_33	data mining;social network analysis;ant colony optimization algorithms;computer science;social network	NLP	-22.46838200721274	-51.13539501883581	35775
94cf1446fe46bb0e646a316de555c8a917ba56e3	relationship between the construction of chinese character and the correct ratio of writer indentification	building materials;geometrical construction;handwriting recognition;image processing;stroke order;writing motion;pen direction;computational geometry;motor aspects;handwriting examination writer indentification chinese characters standardization multidimensional euclidean distance identification ratio stroke order pen direction geometrical construction motor aspects writing motion;euclidean distance;writer identification;identification ratio;computer science education;multidimensional euclidean distance;computational geometry handwriting recognition;chinese characters;writing;handwriting examination;writer indentification;measurement standards;coordinate measuring machines;standardization;microcomputers;multidimensional systems;euclidean distance coordinate measuring machines multidimensional systems writing standardization building materials microcomputers image processing measurement standards computer science education	The relationship between the correct ratio of the writer identification and the construction of the character was investigated. Thirty subjects were asked to write 32 kinds of Chinese characters 6 times. Coordinates of each stroke of the characters were measured. After the standardization of the origin and the size, the writers were classified and identified using multidimensional Euclidean distance. In Experiment 1, the number of strokes had little effect on the correct ratio of the identification. In Experiment 2, the relationship between the arrangement of the components of a character and the correct identification ratio was observed. These results were explained by the investigation into the stroke order, pen direction, and interaction between components along with geometrical construction. The results suggest that the investigation based on the motor aspects of writing motion is necessary to the handwriting examination. >		Yoko Seki;Noriyoshi Takasawa	1993		10.1109/ICDAR.1993.395607	speech recognition;multidimensional systems;image processing;computational geometry;computer science;euclidean distance;microcomputer;handwriting recognition;writing;standardization	AI	-32.059261164099105	-43.955875096489464	35848
dded5adc75208c63b14388e3ae03684dd926c9d2	auditing black-box models for indirect influence		Data-trained predictive models see widespread use, but for the most part they are used as black boxeswhich output a prediction or score. It is therefore hard to acquire a deeper understanding of model behavior and in particular how different features influence the model prediction. This is important when interpreting the behavior of complex models or asserting that certain problematic attributes (such as race or gender) are not unduly influencing decisions. In this paper, we present a technique for auditing black-box models, which lets us study the extent to which existing models take advantage of particular features in the data set, without knowing how the models work. Our work focuses on the problem of indirect influence: how some features might indirectly influence outcomes via other, related features. As a result, we can find attribute influences even in cases where, upon further direct examination of the model, the attribute is not referred to by the model at all.Our approach does not require the black-box model to be retrained. This is important if, for example, the model is only accessible via an API, and contrasts our work with other methods that investigate feature influence such as feature selection. We present experimental evidence for the effectiveness of our procedure using a variety of publicly available data sets and models. We also validate our procedure using techniques from interpretable learning and feature selection, as well as against other black-box auditing procedures. To further demonstrate the effectiveness of this technique, we use it to audit a black-box recidivism prediction algorithm. A preliminary version of this work with authors Philip Adler, Casey Falk, Sorelle A. Friedler, Gabriel Rybeck, Carlos Scheidegger, Brandon Smith, and Suresh Venkatasubramanian was titled Auditing Black-box Models for Indirect Influence and appeared in the Proceedings of the IEEE International Conference on Data Mining (ICDM) in 2016. This research was funded in part by the NSF under Grants IIS-1251049, CNS-1302688, IIS-1513651, DMR-1307801, IIS-1633724, and IIS-1633387. B Sorelle A. Friedler sorelle@cs.haverford.edu 1 Department of Computer Science, Haverford College, Haverford, PA 19041, USA 2 Department of Computer Science, University of Arizona, Tucson, AZ, USA 3 Department of Computer Science, University of Utah, Salt Lake City, UT, USA	algorithm;application programming interface;assignment zero;black box;casey neistat;computer science;data mining;feature selection;ibm notes;model checking;predictive modelling;proceedings of the ieee	Philip Adler;Casey Falk;Sorelle A. Friedler;Gabriel Rybeck;Carlos Eduardo Scheidegger;Brandon Smith;Suresh Venkatasubramanian	2016		10.1109/ICDM.2016.0011	black box (phreaking);machine learning;data mining;contrast (statistics);deep learning;feature selection;computer science;data modeling;black box;artificial intelligence;audit	DB	-10.014204845203267	-29.536910391858957	35860
7d8dca43f24e5cda074dcec09b037493c14e3820	visualizing a tennis match	top nesting layered maps;hierarchical structure;time varying;information filtering;tree data structures;data visualization lenses information filtering information filters displays tree data structures computer science graphics hardware web sites;iconic representations;data visualisation;tennis match;displays;web sites;data visualization;lenses;visualizing;computer science;sport;competition property tennis match visualizing athletic events iconic representations top nesting layered maps;information filters;graphics;competition property;athletic events;hardware	This paper describes our work on visualizing the information of a tennis match. We use competition trees to organize the information of a tennis match and visualize the competition trees by the top-nesting layered maps with translucent colored layers. We create iconic representations to describe the detailed information of athletic events in an intuitive manner. Specialized views of the information are displayed by applying multiple Magic Lens lters on the top-nesting layered maps. The dynamic nature of the tennis match is depicted by the time-varying display. The approach we present in this paper can be used to visualize other sports information , information with competition property, or information with hierarchical structure.	map	Liqun Jin;David C. Banks	1996		10.1109/INFVIS.1996.559229	simulation;computer science;graphics;sport;multimedia;data visualization;statistics;computer graphics (images)	Visualization	-33.11885491122125	-34.50553532829504	36093
434b04f13f4636fe9a7ef150e3523cbd9b4a86a8	finding your spot: a photography suggestion system for placing human in the scene	view specific;aesthetic principles;hot spot landmark locations photography suggestion system high visual quality photos aesthetic composition rules visual perception principles aesthetic score prediction model geometric detection hierarchical search;view specific photography suggestion aesthetic principles;photography suggestion;photography visualization predictive models conferences visual perception mobile handsets computational modeling;visual perception image processing photography	Capturing a professional like photo is always a challenging task, especially for novice users. This paper proposes a photography suggestion approach to assist users to take high visual quality photos with human in the scene. In this research, we first investigate a set of aesthetic composition rules and visual perception principles to construct an aesthetic score prediction model in order to measure visual quality in terms of photo composition. Then we conduct a study on professional photos to define a proper size for the enclosure of human into the picture of a given scene. The proposed approach is able to leverage saliency and geometric detection to represent composition features. Finally, we utilize an efficient hierarchical search to obtain the optimal enclosure for human in the scene. Extensive experiments have been performed for hot spot landmark locations. Through subjective evaluation, the results show that the proposed approach can effectively provide appealing composition recommendation to help users take high quality photos with human in the scene.	color vision;display resolution;experiment;hotspot (wi-fi)	Shuang Ma;Yangyu Fan;Chang Wen Chen	2014	2014 IEEE International Conference on Image Processing (ICIP)	10.1109/ICIP.2014.7025111	computer vision;multimedia;computer graphics (images)	Robotics	-30.648410253206414	-44.66279775512787	36220
1c61c0364c7092d74531fc755d598f4a29fff17f	scaling up markov logic probabilistic inference for social graphs	social network services;probabilistic graphical models;markov logic network social network analysis graph pruning probabilistic graphical models;markov logic network;graphical models;cognition;social network analysis;social network services markov processes probabilistic logic knowledge engineering graphical models cognition computer science;markov processes;computer science;probabilistic logic;graph pruning;knowledge engineering	Link prediction is a fundamental problem in social network analysis. Although the link prediction problem is not new, the challenge of how to exploit various existing network information, such as network structure data and node attribute data, to enable AI-style knowledge inference for large social networks still remains unsolved. In this paper, we design and implement a scalable framework that treats link prediction as knowledge reasoning using Markov Logic Networks (MLNs). Differing from other probabilistic graphical models, MLNs allow undirected relationships with cycles and long-range (non-adjacent) dependency, which are essential and abound in social networks. In our framework, the prior knowledge is captured as the structure dependency (such as friendship) and the attribute dependency (such as social communities) in terms of inference rules, associated with uncertainty represented as probabilities. Next, we employ the random walk to discover the inference subgraph, on which probabilistic inference is performed, so that the required computation and storage cost can be significantly reduced without much sacrifice of the inference accuracy. Our extensive experiments with real-world datasets verify the superiority of our proposed approaches over two baseline methods and show that our approaches are able to provide a tunable tradeoff between inference accuracy and efficiency.	baseline (configuration management);computation;experiment;graph (discrete mathematics);graphical model;markov chain;markov logic network;scalability;social network analysis	Haiquan Chen;Wei-Shinn Ku;Haixun Wang;Liang Tang;Min-Te Sun	2017	IEEE Transactions on Knowledge and Data Engineering	10.1109/TKDE.2016.2625251	organizational network analysis;variable elimination;probabilistic ctl;computer science;dynamic network analysis;artificial intelligence;theoretical computer science;machine learning;knowledge engineering;data mining;database;graphical model;probabilistic logic;probabilistic logic network;statistics	ML	-14.066046279184372	-45.84600542478727	36260
337867c509efe560307ba9c455350a70dca9bfa4	applying spark based machine learning model on streaming big data for health status prediction		Machine learning is one of the driving forces of science and commerce, but the proliferation of Big Data demands paradigm shifts from traditional methods in the application of machine learning techniques on this voluminous data having varying velocity. With the availability of large health care datasets and progressions in machine learning techniques, computers are now well equipped in diagnosing many health issues. This work aims at developing a real time remote health status prediction system built around open source Big Data processing engine, the Apache Spark, deployed in the cloud which focus on applying machine learning model on streaming Big Data. In this scalable system, the user tweets his health attributes and the application receives the same in real time, extracts the attributes and applies machine learning model to predict user's health status which is then directly messaged to him/her instantly for taking appropriate action.	big data;machine learning	Lekha R. Nair;Sujala D. Shetty;Siddhanth D. Shetty	2018	Computers & Electrical Engineering	10.1016/j.compeleceng.2017.03.009	simulation;computer science;engineering;electrical engineering;artificial intelligence;data science;operating system;machine learning;data mining;active learning;algorithm	AI	-10.767657488489244	-31.516779241068807	36294
4315c5cc6c02a60045e9d82b46048b14147d0ac5	improving marketing response by data mining in social network	social network services;tree data structures data mining internet marketing data processing regression analysis social networking online;classification and regression tree;classification tree;marketing data processing;marketing response social network data mining classification tree;virtual community;biological system modeling;statistical significance;tree data structures;data mining;classification tree analysis social network services biological system modeling data mining data models business predictive models;classification and regression tree marketing response improvement data mining social network virtual community;social network;internet;marketing response;business;social networking online;predictive models;regression analysis;marketing response improvement;classification tree analysis;business value;experience base;data models	Social networks have generated great expectations connected with their potential business value. The purpose of our research is to present that even a rudimentary application of data mining techniques can bring statistically significant improvement in marketing response accuracy throughout the virtual community. In our test the C&RT (classification and regression tree) approach was used to generate a classification tree that allows us to formulate some specific rules to identify the proper target group. In the performed empirical experiments, based on the real social network data, we showed that it is possible to improve marketing response. This promising result was obtained without any advanced and time consuming transformation of the available data.	data mining;decision tree learning;experiment;social network;virtual community	Jerzy Surma;Anna Furmanek	2010	2010 International Conference on Advances in Social Networks Analysis and Mining	10.1109/ASONAM.2010.21	data modeling;the internet;decision tree learning;computer science;data science;business value;machine learning;data mining;statistical significance;predictive modelling;tree;world wide web;regression analysis;social network	ML	-24.373011041068185	-42.42749487097119	36434
4119211820047d6f1daabae175a22f4a26c4c0d6	iimof: an iterative framework to settle influence maximization for opinion formation in social networks		Influence maximization for opinion formation (IMOF) in social networks is an important problem, which is used to determine some initial nodes and propagate the most ideal opinions to the whole network. The existing researches focus on improving the opinion formation models to compute the opinion of each node. However, little work has been done to describe the IMOF process mathematically, and the current researches cannot provide an effective mechanism to deal with the IMOF. In this paper, the IMOF is formulated mathematically and solved by an iterative framework. At first, we describe the IMOF as a constrained optimization problem. Then, based on node influence and neighbor coordination, the weighted coordination model is proposed to compute the opinions of network nodes with the change of iterations. In particular, in order to determine top- $k$  influential nodes (i.e., seed nodes), an iterative framework for the IMOF, called IIMOF is presented. Based on the framework, the score and rank of each node by Iterative 2-hop algorithm, i.e., SRI2 is proposed to compute the influence score of each node. Based on small in-degree and high out-degree, one-hop measure is proposed to better reflect the rank of all initial nodes. We also prove that IIMOF converges to a stable order set within the finite iterations. The simulation results show that IIMOF has superior average opinions than the comparison algorithms.	consistency model;constrained optimization;constraint (mathematics);directed graph;entropy maximization;expectation–maximization algorithm;iteration;mathematical optimization;optimization problem;simulation;social network	Qiang He;Xingwei Wang;Chuangchuang Zhang;Min Huang;Yong Zhao	2018	IEEE Access	10.1109/ACCESS.2018.2867540	iterative method;constrained optimization;node (networking);mathematical optimization;distributed computing;computer science;social network;greedy algorithm;maximization	AI	-16.577983658045056	-43.67980531315307	36443
932e71f8a35768e4ffeb096bc513c7e38caeb42a	ehaupm: efficient high average-utility pattern mining with tighter upper bounds	data mining;high average-utility pattern;pruning strategy;tighter upper bounds;utility mining	High-utility itemset mining (HUIM) has become a popular data mining task, as it can reveal patterns that have a high-utility, contrarily to frequent pattern mining, which focuses on discovering frequent patterns. High average-utility itemset mining (HAUIM) is a variation of HUIM that provides an alternative measure, called the average utility, to select patterns by considering both their utilities and lengths. In the last decades, several algorithms have been developed to mine high average-utility itemsets (HAUIs). But most of them consume large amounts of memory and have long execution times, since they generally utilize the average-utility upper-bound (auub) model to overestimate the average utilities of itemsets. To improve the performance of HAUIM, this paper proposes two novel tighter upper-bound models as alternative to the traditional auub model for miningHAUIs. The looser upper-bound model considers the remaining-maximum utility in transactions to reduce the upper bound on the utilities of itemsets. The second upper-bound model ignores irrelevant items in transactions to further tighten the upper bound. Three pruning strategies are also designed to reduce the search space for mining HAUIs by a greater amount compared with the state-of-the-art HAUI-Miner algorithm. Experiments conducted on several benchmark data sets show that the designed algorithm integrating the two novel upper-bound models outperforms the traditional HAUI-Miner algorithm in terms of runtime, memory usage, number of join operations, and scalability.	algorithm;benchmark (computing);data mining;loose coupling;relevance;scalability	Jerry Chun-Wei Lin;Shifeng Ren;Philippe Fournier-Viger;Tzung-Pei Hong	2017	IEEE Access	10.1109/ACCESS.2017.2717438	computer science;algorithm design;scalability;data mining;data set;upper and lower bounds	ML	-6.26394751856492	-36.64474843979724	36494
47951e87722a1964eb1132be5bca08ddbfd09105	a computational morphogenesis approach to simple structure development	computational problem;biological cell;simple structure generation;simple structure development;new model;computational embryology;computational morphogenesis;promising result;complex problem	This paper presents a new model for computational embryology that mimics the behaviour of biological cells, whose characteristics can be applied to the solution of computational problems. The presented tests apply the model to simple structure generation and provide promising results with regard to its behaviour and applicability to more complex problems.	computation	Enrique Fernández-Blanco;Julian Dorado;Juan R. Rabuñal;Marcos Gestal;Nieves Pedreira	2007		10.1007/978-3-540-74913-4_83	biology;computational model;algorithm	Robotics	-5.424048909282332	-49.387540340966844	36524
2bd3ba7740cf94c6eb79566a2dcf2e27eaf8dca3	measuring and mitigating product data inaccuracy in online retailing		Nowadays, consumers rely more on rich and accurate online product information to make purchasing decisions. As one of the first studies, we quantify how accurate online product data is today and evaluate existing approaches of mitigating inaccuracy. The result shows that the accuracy varies a lot across different sites and can be as low as 20%. However, when aggregating product information across different Web pages, the accuracy can be improved on average by 11.3%. Based on the analysis, we propose an attribute-based authentication approach based on Semantic Web to further mitigate online data inaccuracy.	authentication;purchasing;semantic web;web page	Runhua Xu;Alexander Ilic	2014		10.1007/978-3-319-11746-1_39	embedded system;real-time computing;data mining	Web+IR	-21.318044426472216	-50.56742342379663	36564
a596ceb7d3808cd910a7c535afdda8a9f49c5353	reasoning for sensor data interpretation: an application to air quality monitoring	datavetenskap datalogi;datavetenskap;computer science	In this paper we introduce a representation and reasoning model for the interpretation of time-series signals of a gas sensor situated in a sensor network. The interpretation process includes infer ...		Marjan Alirezaie;Amy Loutfi	2015	JAISE	10.3233/AIS-150323	computer science;artificial intelligence;machine learning;data mining	Robotics	-11.79976591820844	-29.148615112120222	36592
84578416fd99c3f2cf3c6099adbb64b456af0808	analyse de la dynamique et des indices d'évolution des paysages selon vmap1		This paper introduces a new approach for modelling landscape evolution. This research is based on a temporal analysis of cartographical objects of the standard product VMAP1, an important reference for military mapping. The proposed approach relies on a preliminary analysis of natural and urban landscapes, and to determine their evolution constraints. This analysis is then completed by the elaboration of evolution indices, modelled using basic principles of fuzzy logics, that characterize the way VMAP1 objects evolve (at the individual and agregated levels). These principles are illustrated by a case study. MOTS-CLES : VMAP1, paysage, dynamique, mise a jour cartographique, logique floue.	linear algebra;vector map	Dominique Badariotti;Christophe Claramunt;Emmanuel Devys	2002	Revue Internationale de Géomatique	10.3166/rig.12.187-214	fuzzy logic;machine learning;artificial intelligence;elaboration;mathematics	Crypto	-8.906526983778567	-24.180903422510685	36633
1246c973297da23f7d5edf68b34c976eb159a084	simulating information creation in social semantic web applications	social network;semantic web;ranking algorithm;simulation model	Appropriate ranking algorithms and incentive mechanisms are essential to the creation of high-quality information by users of a social network. However, evaluating such mechanisms in a quantifiable way is a difficult problem. Studies of live social networks of limited utility, due to the subjective nature of ranking and the lack of experimental control. Simulation provides a valuable alternative: insofar as the simulation resembles the live social network, fielding a new algorithm within a simulated network can predict the effect it will have on the live network. In this paper, we propose a simulation model based on the actor-conceptinstance model of semantic social networks, then we evaluate the model against a number of common ranking algorithms. We observe their effects on information creation in such a network, and we extend our results to the evaluation of generic ranking algorithms and incentive mechanisms.	algorithm;formal methods;iteration;open-source license;open-source software;semantic network;simulation;social semantic web;social network;software deployment	Xixi Luo;Xiaowu Chen;Qinping Zhao;Joshua Shinavier	2010	CoRR		computer science;dynamic network analysis;artificial intelligence;data science;machine learning;semantic web;simulation modeling;social semantic web;data mining;network simulation;world wide web;social network	Web+IR	-20.025451741482414	-40.474219942453196	36653
eab03623da120bd5ba42ae116862010cd254f05e	a novel hybrid algorithm for discovering motifs from financial time series		Time series motifs are pairs of individual subsequences, which are very similar to each other within the time series. In this paper, we propose an efficient and novel hybrid algorithm by taking best out of two popular algorithms namely MK algorithm and EP-C algorithm that exist in literature. We demonstrate the efficiency of our approach in terms of time elapsed and distance obtained between the subsequences through experiments conducted on financial time series datasets viz., foreign exchange rates, Gold price and Crude oil price in terms of US dollars.	hybrid algorithm;time series	Dadabada Pradeepkumar;Maneesh Bhunwal;Vadlamani Ravi	2014		10.1007/978-3-319-20294-5_18	bioinformatics;machine learning;data mining	ML	-4.692536737645779	-35.24913878851867	36725
a4417d46cf0e6b2f3261f4619f9f2a6021f169cf	an effective drill-down paths pruning method in olap	vectorial angle method;multidimensional data structure;olap;data structures data mining;data mining;multi dimensional;data mining vectors performance analysis marketing and sales asia data analysis information analysis space exploration data structures multidimensional systems;drill down paths pruning method;data structures;vectorial angle method drill down paths pruning method olap multidimensional data structure;data structure	The complexity of multi-dimensional data structure affects the efficiency of OLAP, because there are too many drill-down paths to be chosen from when analysis. While most methods in the literature are associated to some specific analysis tasks, so they cannot get reasonable effect. In this paper, we proposed a new method that is irrelevant to analysis task that we try to prune the invalid drill-down operations. The vectorial angle method is employed to evaluate the validness of every drill-down operation. We give the corresponding path pruning algorithm, and it is effective that it takes the fact table as the input in only one pass scanning. The experiments show that our method is feasible, effective, sparsity-proof and skewness-proof	algorithm;data drilling;data structure;experiment;online analytical processing;relevance;sparse matrix	Dehui Zhang;Shiwei Tang;Dongqing Yang;Lizheng Jiang	2007	Fourth International Conference on Fuzzy Systems and Knowledge Discovery (FSKD 2007)	10.1109/FSKD.2007.148	data structure;online analytical processing;computer science;machine learning;data mining;database	DB	-7.018606539318484	-38.841793259033444	36769
0fc38c6675853d7099c212d6081de62d8029c044	exploring discrete dynamics. andrew wuensche. (2011, luniver press.) xxxvii + 498 pages, 290 figures, 31 tables.	discrete dynamic;book review;andrew wuensche;luniver press	Exploring Discrete Dynamics. Andrew Wuensche. (2011, Luniver Press.) xxxvii + 498 pages, 290 figures, 31 tables. Exploring Discrete Dynamics is a very extended computational and analytic exploration of discrete dynamical systems. The book makes a summary of more than 19 years of results, programming, and research by Andrew Wuensche. In 1992, at the Santa Fe Institute, Wuensche together with Mike Lesser published the celebrated book in cellular automata theory The Global Dynamics of Cellular Automata [26]. This book introduced a reverse algorithm for cellular automata, and presented an atlas of basin of attraction fields computed by means of the algorithm. Motivated by these results and Kauffmanʼs model of genetic regulatory networks [12], Wuensche subsequently developed new algorithms for random Boolean networks and discrete dynamical networks in general. His achievements have had a great influence on outstanding researchers such as Stuart Kauffman [12], Harold V. McIntosh [18], Andrew Adamatzky [1], and Christopher Langton [26], among many others; and hundreds of references in books and research articles. These results have been obtained mainly by making use of his popular open source software DDLab (Discrete Dynamics Lab, http://www.ddlab.org/), which is widely used in the scientific community and offers free access to software, code, and manual. Wuenscheʼs latest book, Exploring Discrete Dynamics, presents a very extensive description of the current features of DDLab. Successive chapters describe, in detail and in depth, every function of this tool, illustrated with numerous examples from his research. Analyses concentrate mainly on four systems of increasing generality: cellular automata (CAs), random Boolean networks (RBNs), discrete dynamical networks (DDNs), and random maps. Consequently, in this book we have a ramification that connects and relates concepts naturally derived from these main subjects: reverse algorithms, rule space, state space, basins of attraction, stability, order, chaos, complexity, networks, emergent structures, classes, filters, self-reproduction, reactiondiffusion, cryptography, and beyond [4, 7, 9, 11, 21, 24, 28, 30–33, 35–37]. Without doubt, the DDLab software is unique in its ability to study and classify discrete dynamical systems, analyze and unravel networks with the network graph, create flexible simulations where parameters can be changed on the fly, and generate basins of attraction and subtrees. In DDLab we can experiment with mutations, calculate preimages (or ancestors [10, 23]), and analyze state space configurations iterating for unlimited spans of time, including simulations in one, two, and three dimensions. In the state space implementation, we can calculate the changing input entropy and pattern density, which helps us to understand the properties of dynamical systems—applied in particular to automatically categorize CA rule space between order, complexity, and chaos. The static Z parameter, based on just the rule table, also categorizes CA rule space by predicting the indegree in subtrees to identify maximum chaos—this is applied for a method of encryption [34]. An interesting point in the book is the incorporation of a jump graph of the basin of attraction field (see p. 207). Thinking in terms of Edward Fredkinʼs finite nature hypothesis [13], the most important implication of this hypothesis is “that every volume of space-time has a finite amount of information	algorithm;andrew adamatzky;automata theory;book;boolean network;categorization;cellular automaton;chaos theory;complexity;cryptography;directed graph;dynamical system;emergence;encryption;field electron emission;langton's ant;map;mike lesser;on the fly;open-source software;ramification problem;simulation;state space;tree (data structure)	Genaro Juárez Martínez	2012	Artificial Life	10.1162/artl_r_00068		Theory	-7.847785457829046	-47.474184456035886	36825
3f9f4930b827dca9c58c1919d51bc0bbf96caa96	sici explorer: situation monitoring of cities in social media streaming data		The continuous growth of social networks and the active use of social media services result in massive amounts of user-generated data. More and more people worldwide report and distribute up-to-date information about almost any topic. Therefore, we argue that this kind of data is a good basis to observe ongoing situations in cities as well as related situations from outside about these cities in real-time. This paper presents a visualization for monitoring the situation (current topics and emotions) in cities and about cities, which is reflected in the live message stream of the social microblogging service Twitter, by using continuously updating and with sentiment colored TagClouds.	real-time transcription;social media;social network;stream (computing);streaming media;user-generated content	Andreas Weiler;Michael Grossniklaus;Marc H. Scholl	2014				Web+IR	-25.979498228837997	-45.60250019004628	36826
bea2049b37acf710a02614c5792a5e1348988cb1	detecting friendship within dynamic online interaction networks.	temporal data;machine learning;social networks	In many complex social systems, the timing and frequency of interactions between individuals are observable but friendship ties are hidden. Here, we investigate the accuracy of multiple statistical features, based either purely on temporal interaction patterns or on the cooperative nature of the interactions, for automatically extracting latent social ties. Using self-reported friendship and non-friendship labels derived from an anonymous online survey, we learn highly accurate predictors for recovering hidden friendships within a massive online data set encompassing 18 billion interactions among 17 million individuals of the popular online game Halo: Reach. We find that periodicities in interaction time series are sufficient to correctly classify 95% of ties, even for casual users. These results clarify the nature of friendship in online social environments and suggest new opportunities and new privacy concerns for friendship-aware applications that do not require the disclosure of private friendship information.	algorithm;autocorrelation;big data;computation;computational social science;contact list;data acquisition;extrapolation;ground truth;halo: reach;interaction;k-means clustering;mason;observable;personally identifiable information;privacy;quasiperiodicity;sensor;social network;social system;software deployment;sparse matrix;synergy;theory;time series;unsupervised learning;on-line system	Sears Merritt;Abigail Z. Jacobs;Winter A. Mason;Aaron Clauset	2013	CoRR		friendship;internet privacy;interpersonal ties;artificial intelligence;data mining;machine learning;temporal database;social network;casual;computer science;social system	HCI	-22.431119479705032	-43.22495765949121	36838
3a15b9d82463e4c8ed6fbbf1b0cc376bba2fada1	complex networks are an emerging property of hierarchical preferential attachment		Real complex systems are not rigidly structured; no clear rules or blueprints exist for their construction. Yet, amidst their apparent randomness, complex structural properties universally emerge. We propose that an important class of complex systems can be modeled as an organization of many embedded levels (potentially infinite in number), all of them following the same universal growth principle known as preferential attachment. We give examples of such hierarchy in real systems, for instance, in the pyramid of production entities of the film industry. More importantly, we show how real complex networks can be interpreted as a projection of our model, from which their scale independence, their clustering, their hierarchy, their fractality, and their navigability naturally emerge. Our results suggest that complex networks, viewed as growing systems, can be quite simple, and that the apparent complexity of their structure is largely a reflection of their unobserved hierarchical nature.	attachments;blueprint;cluster analysis;complex network;complex systems;embedded system;embedding;entity;randomness;rule (guideline);statistical cluster	Laurent Hébert-Dufresne;Edward Laurence;Antoine Allard;Jean-Gabriel Young;Louis J. Dubé	2015	Physical review. E, Statistical, nonlinear, and soft matter physics	10.1103/PhysRevE.92.062809	combinatorics;mathematics	ML	-15.055677869850191	-38.743875205235526	36870
589e6e9a27be9b07f68eb8e4f02db0206ae17435	an ensemble fuzzy logic approach to game bot detection through behavioural features		On line games market is vastly growth in the last years thanks to the diffusion of innovative and performant platforms. Game players can be involved in always more convincing environment where they compete, collaborate and change information with other players. This allows game developers to invest a huge amount of resources to ensure game player safeness and satisfaction. According to this, an increasing interest is pointed towards the study of a new approach for the game bots detection since game bots are used by cheater players to obtain personal advantages with a consequent disappointment and reduction of the game appealing. This paper describes an ensemble Fuzzy Logic approach aiming to discriminate between human players and game bots using a set of features describing their behavior in the game environment. The evaluation is performed on a real on-line role player game and gives effective results.	algorithm;ensemble learning;fuzzy control system;fuzzy logic;online and offline;polystation;video game bot	Mario Luca Bernardi;Marta Cimitile;Fabio Martinelli;Francesco Mercaldo	2018	2018 IEEE International Conference on Fuzzy Systems (FUZZ-IEEE)	10.1109/FUZZ-IEEE.2018.8491615	fuzzy logic;artificial intelligence;machine learning;feature extraction;disappointment;statistical classification;computer science;game developer	Robotics	-7.339110110402045	-28.120210361820057	36909
a4e83ffd58f84be5caa9250d695d7e54aa510d9b	online density estimates: a probabilistic condensed representation of data for knowledge discovery				Michael Geilke	2017				ML	-9.275677861738723	-33.213105053545455	36955
b34d4869694d8e612797247387422e426269a2be	when taxi meets bus: night bus stop planning over large-scale traffic data		With more and more citizens traveling for life or work at night, there is a big gap between the demands and supplies for public transportation service in China. In this paper, we address the problem of night-bus stop planning by investigating the characteristics of taxi GPS trajectories and transactions, rather than leveraging subjective and costly surveys about citizen mobility patterns. There are two stages in our method. In the first stage, we extract the Pick-up and Drop-off Records (PDRs) from the taxi GPS trajectories and transactions for capturing citizens travel patterns at night. In the second stage, we propose DC-DBSCAN, an improved DBSCAN clustering algorithm by considering the Distance Constraint, to detect hot locations as candidate night-bus stops from the PDRs dataset. We take the service range of a bus stop into consideration, and optimize the candidates by considering the cost and convenience factors. Finally, our experiments demonstrate that our method is valid and with better performance than that of K-means.	algorithm;cluster analysis;dbscan;experiment;global positioning system;k-means clustering;two-phase locking	Luyan Xiao;Xiaopeng Fan;Haixia Mao;Cheng-Zhong Xu;Ping Lu;Shengmei Luo	2016	2016 7th International Conference on Cloud Computing and Big Data (CCBD)	10.1109/CCBD.2016.015	public transport;real-time computing;computer science;global positioning system;simulation;cluster analysis;dbscan	Robotics	-16.52370990542561	-33.143822408249314	36959
68b6ce68a822475930fed357e7655c2c66f7e939	ihearu-play: introducing a game for crowdsourced data collection for affective computing	databases;supervised machine learning ihearu play web based multiplayer game data crowdsourcing affective computing web interface open source high level python web framework django;data collection;user interfaces computer games data handling internet learning artificial intelligence outsourcing public domain software;speech;annotation;annotation crowdsourcing gamification data collection;games;artificial intelligence;games databases labeling crowdsourcing affective computing speech artificial intelligence;gamification;crowdsourcing;labeling;affective computing	We introduce iHEARu-PLAY, a web-based multi-player game for crowdsourced database collection and - most important - labelling. Existing databases (with speech and video content) can be added to the game and labelling tasks can be defined via a web-interface. The primary purpose of iHEARu-PLAY is multi-label, holistic annotation of multi-modal affective speech databases. Players perform labelling (or prompted recording) tasks and are rewarded with scores and prizes, which are computed based on the “correctness” of their annotations, e.g., the agreement with a pre-defined gold standard or with the other players. iHEARu-PLAY is implemented with the open source high-level Python Web framework Django and can be installed on Unix and Windows platforms. Its modular architecture allows for easy integration of custom extensions: New gaming components can be added as plugins in order to support new databases and modalities. Label categories for each database are individually selectable and editable. Audio, image and video annotation are currently supported. iHEARu-PLAY will be available to the research community as a ready-to-use web-service. Researchers can add their own databases, optionally post rewards, and receive annotation results in the end. General users can register to play the game, have fun, compete with other players, and at the same time support science.	affective computing;correctness (computer science);crowdsourcing;database;digital video;django;high- and low-level;holism;microsoft windows;modal logic;modular programming;multi-label classification;open-source software;play store;plug-in (computing);python;unix;user interface;web application;web framework;web service	Simone Hantke;Florian Eyben;Tobias Appel;Björn W. Schuller	2015	2015 International Conference on Affective Computing and Intelligent Interaction (ACII)	10.1109/ACII.2015.7344680	games;labeling theory;speech recognition;computer science;speech;artificial intelligence;operating system;machine learning;data mining;affective computing;multimedia;internet privacy;world wide web;crowdsourcing;data collection	DB	-33.66834052403003	-44.26178515379974	36992
33eda6d921c7c21c951145ca785a7b34a2d85430	proposal for a growth model of social network service	social network services;graph theory;shortest path;pattern clustering;article publisher;social networking service;communication system;small world social network analysis social networking service scale free;social networking services;small world;degree distribution;network topology;scale free;internet;social sciences computing graph theory internet pattern clustering;clustering coefficient;social sciences computing;chromium;fitness model growth model social network service academic community system amippy network topology power law degree distribution negative assortativity numerical simulations connecting nearest neighbor model;social network analysis;power law;network structure;communities;couplings;numerical models;numerical models social network services data models chromium communities couplings equations;growth model;data models;numerical simulation	In this paper, we analyze the network structure of two SNSs, Academic Community System (ACS) and Amippy. From the viewpoint of network topology, the major characteristics of these data sets can be summarized as follows: low average shortest-path length, high clustering coefficient, presence of a power law degree distribution and negative assortativity. Based on our analysis, we propose a growth model of SNS networks. We conducted numerical simulations to compare actual data sets with networks generated by the proposed model. Results of simulations indicated that the processes of the CNN model and Fitness model are needed to reproduce the networks of SNSs.	assortativity;clustering coefficient;computer simulation;degree distribution;network topology;numerical analysis;population dynamics;shortest path problem;social network	Ken Ishida;Fujio Toriumi;Kenichiro Ishii	2008	2008 IEEE/WIC/ACM International Conference on Web Intelligence and Intelligent Agent Technology	10.1109/WIIAT.2008.194	power law;chromium;social network analysis;simulation;degree distribution;computer science;artificial intelligence;graph theory;theoretical computer science;machine learning;hierarchical network model;data mining;clustering coefficient;world wide web;network topology	HPC	-17.407376979583667	-40.95479184440428	37107
efbbb000c0b9fa52d25a2a9b518f2b37567047cd	gps-gis for the identification of a new air approach path through rnav procedure		The high congestion of airports, due to the increase in air traffic demand and the lack of significant infrastructure interventions, must be accompanied by a high level of security in airport areas. The risk related to interference between aircraft and vehicles during ground movements is still high and, for this reason, adequate distances must be ensured between them as well as during flight. In particular, the airport traffic areas must be monitored continuously in order to know at any time the position of all moving objects, land and ground vehicles. This note proposes an integrated GPS and GIS system for the monitoring of airport areas, following the new requirements of the Intelligent Transport System (ITS) applications and with an innovative communication between GIS networks. This system we also used for the development and subsequent verification of a new approach to RWY 33 of the Reggio Calabria airport, applying the RNAV technique.	geographic information system;global positioning system	Vincenzo Barrile;Antonino Fotia;Giuliana Bilotta	2018		10.1007/978-3-319-95168-3_21	computer network;area navigation;computer science;air traffic control;global positioning system;transport engineering	ML	-17.868913872218073	-28.402725118304268	37143
d000669d17837a22259f65b0c7ea0501067d9706	a context-based information agent for supporting intelligent distance learning environments	pedagogical agent;distance learning;community of learners;information agent;tutoring system	The large amount of information now available on the Web can play a prominent role in building a cooperative intelligent distance learning environment. We propose a system to provide learners with useful information in a group discussion. Finding the right information at the right moment is quite a difficult task, especially when the learner’s interests are continually updated during the discussion. This paper presents a context-based information agent that can observe conversations among a community of learners on the Web, interpret the learners’ inputs, and then assess the current context of the session. The agent must be able to adapt its behavior autonomously to the changing context, build a new query to get updated information from the Web, and originate the search task. Then, it can filter the results, organizing, and presenting information useful to the learners in their current activities. We claim that specifying the context of a search better can significantly improve search results. An important task, therefore, is to assess the context. For this, we have developed dominant meaning space. That is a new set based measure to evaluate the closeness between queries and documents. Our experiments show that the proposed method greatly improves retrieval effectiveness, in terms of average overall accuracy as well as that in the top twenty documents. This work is the core component of a new pedagogical agent to help people learn tasks defined within greater Web-based tutoring systems.	autonomous robot;centrality;document;experiment;information needs;organizing (structure);pedagogical agent;world wide web	Mohammed Abdel Razek;Claude Frasson;Marc Kaltenbach	2003			distance education;computer science;knowledge management;machine learning;database;multimedia;world wide web	AI	-32.50095734136758	-49.95938070166468	37244
a8a4cf29c7483f5eed5aa808df2225661506e1b4	hybrid music recommender using content-based and social information	vectors convolution information filtering internet learning artificial intelligence music neural nets recommender systems;mir deep learning convolutional neural networks estimation of distribution algorithms recom mender systems;deep learning;n dimensional vector hybrid music recommender content based recommender social information internet resources songs music albums music playlists podcasts filtering task deep learning technique convolutional deep neural networks audio segment;recommender systems spectrogram music prediction algorithms training tensile stress estimation;convolutional neural networks;recom mender systems;estimation of distribution algorithms;mir	Internet resources available today, including songs, albums, playlists or podcasts, that a user cannot discover if there is not a tool to filter the items that the user might consider relevant. Several recommendation techniques have been developed since the Internet explosion to achieve this filtering task. In an attempt to recommend relevant songs to users, we propose an hybrid recommender that considers real-world users information and high-level representation for audio data. We use a deep learning technique, convolutional deep neural networks, to represent an audio segment in a n-dimensional vector, whose dimensions define the probability of the segment to belong to a specific music genre. To capture the listening behavior of a user, we investigate a state-of-the-art technique, estimation of distribution algorithms. The designed hybrid music recommender outperforms the predictions compared with a traditional content-based recommender.	artificial neural network;convolutional neural network;deep learning;estimation of distribution algorithm;high- and low-level;podcast;recommender system	Paulo Chiliguano;György Fazekas	2016	2016 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)	10.1109/ICASSP.2016.7472151	speech recognition;estimation of distribution algorithm;computer science;machine learning;deep learning;multimedia;recommender system	DB	-18.339582103127	-50.636258563561775	37254
c24182b0da214668513d6c981572d15675122d3e	exploiting shopping and reviewing behavior to re-score online evaluations	e commerce;customer credibility;online shopping;review inconsistency	Analysis to product reviews has attracted great attention from both academia and industry. Generally the evaluation scores of reviews are used to generate the average scores of products and shops for future potential users. However, in the real world, there is the inconsistency problem between the evaluation scores and review content, and some customers do not give out fair reviews. In this work, we focus on detecting the credibility of customers by analyzing online shopping and review behaviors, and then we re-score the reviews for products and shops. In the end, we evaluate our algorithm based on the real data set from Taobao, the biggest E-commerce site in China.	algorithm;e-commerce payment system;online shopping;sensor;taobao marketplace	Rong Zhang;Chaofeng Sha;Minqi Zhou;Aoying Zhou	2012		10.1145/2187980.2188171	e-commerce;computer science;world wide web	ML	-21.67130168389455	-50.618155819051445	37262
1e92fe2694d21b7411a680ff8ca06e172b018831	opinion dynamics approach for identifying community structures in complex networks	community detection;networks;majority model;opinion dynamics	This paper suggests an opinion dynamics approach to define community structures in complex networks. If a typical opinion dynamics model is applied to a network with a community structure, the network can separate in two groups of nodes. Such bisection in a given network can arise in many different ways depending on the initial conditions. The opinion distance between two nodes is defined as the probability of disagreement, or the probability that the two nodes belong to different bisections in multiple Monte Carlo simulations. The communities can be defined in terms of the distance. Closer nodes belong to the same community. Three opinion dynamics models were tested to show how the method works. Through various example networks, it was shown that the distance data can be used as a unique metric for identifying hierarchical structures and overlapping nodes in networks, as well as for identifying the community structure itself.	complex systems	Jae Kyun Shin	2014	Advances in Complex Systems	10.1142/S0219525914500234	computer science;artificial intelligence;data mining;mathematics;social psychology;community structure	AI	-15.48020826784082	-40.8442374811632	37298
374ed2e362722a4969696cc3af37a05adf5a8fc5	user behavior based automatical navigation system on android platform	smartphones user behavior based automatical navigation system android platform;navigation memory receivers;smart phones navigation	Nowadays, navigation applications in smartphones are widely used in our daily lives. But the problem existing in using the applications is that a lot of operations between users and smartphones are needed, such as destination setting, options setting and zooming in/out. Potential dangers may bring to the users when they are walking on the street or especially driving. In this paper, we study providing an automatical navigation system, in which the number of users' operations is largely reduced. The navigation system can automatically predict user's future possible destinations and routes without any operation from users. The prediction is performed by analyzing both user's current position and historical tracing data. We implement the proposed system on the Android platform. The experimental results show that the application works effectively to provide anticipated routes and destinations for a single user.	android;driving simulator;smartphone	Jie Tian;Guiling Wang;Xin Gao;Kaixuan Shi	2014	2014 23rd Wireless and Optical Communication Conference (WOCC)	10.1109/WOCC.2014.6839916	turn-by-turn navigation;embedded system;simulation;engineering;computer security;mobile robot navigation	Mobile	-20.113947937533553	-29.49760859060725	37321
0fc009d929378bad8229c3a55637942b3c2ab340	practical experiences towards generic resource navigation and visualization	formal language;information visualization;semantic web;topic maps;connected graph	The Star Resource Navigator is an ontology based tool to visualize, navigate and search web distributed RDF resources. Resources and their connections are graphically represented as a star connected graph with labels indicating the existing relations. The Navigator has been tested in different application domains, coded by means of different ontologies. Because of its intuitive and easy to use interface, the system is oriented to end-users who are not Semantic Web experts. After a brief analysis of existing tools and techniques to visualize RDF structures, the paper describes the Star Resource Navigator, as an example of intuitive environment for resource navigation and visualization.	a* search algorithm;application domain;connectivity (graph theory);ontology (information science);resource description framework;semantic web	Nadia Catenazzi;Lorenzo Sommaruga	2005			information retrieval;semantic web;topic maps;connectivity;rdf;computer science;visual analytics;visualization;ontology (information science);information visualization	HCI	-30.993835039897753	-31.880712884751155	37333
6d1c9bf707f5cc0ea95e18882e723b7efcbdb8c7	human-machine skill transfer extended by a scaffolding framework	robot learning;robot sensing systems;man machine systems robot sensing systems humans educational robots robot kinematics surgery sensor fusion robotics and automation humanoid robots mobile robots;robotic learning;intelligent robots;mobile robots;educational robots;human machine skill transfer;learning by example;humanoid robots;learning by demonstration;surgery;scaffolding;learning by example intelligent robots;situated learning;humans;sensor fusion;situated learning learning by demonstration scaffolding;foreign language;man machine systems;robotics and automation;scaffolding framework;learning by demonstration human machine skill transfer scaffolding framework robotic learning;social environment;robot kinematics	"""The term scaffolding, with respect to human education, was first coined in the 1970ies, although the basic concept originates back to the 1930ies. The main idea is to formalize the superior knowledge of a teacher in a certain way to generate support for a trainee. In practice, this concept can be implemented as concrete as a cloze, which assists pupils in learning a foreign language, or it might be as abstract as a social environment, which facilitates learning of specific tasks. This paper introduces a novel approach towards robotic learning by means of such a scaffolding framework. In this case, the scaffolding is constituted by abstract patterns, which facilitate the structuring and segmentation of information during """"Learning by Demonstration"""". The methodology was applied to a real-world scenario of robot-assisted surgery."""	automaton;finite-state machine;knowledge base;pulse-width modulation;robot;situated;universal instantiation	Hermann Georg Mayer;Darius Burschka;Alois Knoll;Eva U. Braun;Rüdiger Lange;Robert Bauernschmitt	2008	2008 IEEE International Conference on Robotics and Automation	10.1109/ROBOT.2008.4543644	foreign language;situated learning;mobile robot;robot learning;social environment;simulation;computer science;engineering;humanoid robot;artificial intelligence;sensor fusion;educational robotics;robot kinematics	Robotics	-33.00000912220355	-39.85846179225679	37375
8dd563e1c0355ddab8a1a9fb35fdf8f60e1d288f	a cpm-based change detection test for big data		Big data analytics nowadays represent one of the most relevant and promising research activities in the field of Big Data. Tools and solutions designed for such purpose are meant to analyse very large sets ot data to extract relevant/valuable information. In this path, this paper addresses the problem of sequentially analysing big streams of data inspecting for changes. This problem that has been extensively studied for scalar or multivariate datastreams, has been mostly left unattended in the Big Data scenario. More specifically, the aim of this paper is to introduce a change detection test able to detect changes in datastreams characterized by very-large dimensions (up to 1000). The proposed test, based on a change-point method, is non parameteric (in the sense that it does not require any apriori information about the system under inspection or the possible changes) and is designed to detect changes in the mean vector of the datastreams. The effectiveness and the efficiency of the proposed change detection test has been tested on both synthetic and real datasets.	big data	Giada Tacconelli;Manuel Roveri	2016		10.1007/978-3-319-47898-2_11	streams;data mining;change detection;big data;multivariate statistics;computer science	ML	-10.65758685260263	-34.51408914178866	37378
347f66cee336a14a1438ee8034c8a4742e2f319a	depiction of uncertainty in the visually interpreted land cover data		Abstract Remote sensing data analysis to infer land cover and the subsequent modelling of land use change are subject to uncertainties, which may have an impact on the accuracy of future land-use predictions. Part of these uncertainties come from the visual interpretation of remote sensing data as during this phase a specific knowledge and expertise are crucial. Visual interpretation includes the meaning of the image content but also goes beyond what can be seen on the image to recognize spatial and landscape patterns. The quality of recognition depends on the expertise in image interpretation and visual perception. Based on this statement, it is necessary to visualize also the information about uncertainty. This paper describes different perspectives of uncertainty visualization on the example of visually interpreted aerial photographs in a mining area. The study is focused on visualization techniques for uncertainty awareness analysis of land cover data. This approach should contribute to better understanding, assessment and potential spreading of visual information of uncertainty and help to appraise the data critically. The goal of this paper is to raise uncertainty awareness among practitioners who deal with land cover data and stress the visualizations techniques as a more reliable means to assess the quality, and hence the uncertainty, of these data.		Jan Brus;Vilém Pechanec;Ivo Machar	2018	Ecological Informatics	10.1016/j.ecoinf.2017.10.015	land use, land-use change and forestry;data mining;creative visualization;visualization;land cover;depiction;computer science;visual perception	ML	-24.033634118964724	-31.42116548659658	37421
2cd800fb976390e0b876acf713ba79a3f27cf7a7	timenotes: a study on effective chart visualization and interaction techniques for time-series data	data visualization layout context lenses visualization rivers data mining;rivers;interaction techniques;interaction techniques time series exploration focus context lens;layout;data mining;visualization;time series exploration;data visualization;lenses;lens;time series data analysis data visualisation sensor fusion;chronolenses timenotes chart visualization interaction techniques time series data sensor data temporal data set visualization temporal data set analysis one dimensional time series charts multiscale representations frequency based interaction lens based interaction stack zoom;context;focus context	Collecting sensor data results in large temporal data sets which need to be visualized, analyzed, and presented. One-dimensional time-series charts are used, but these present problems when screen resolution is small in comparison to the data. This can result in severe over-plotting, giving rise for the requirement to provide effective rendering and methods to allow interaction with the detailed data. Common solutions can be categorized as multi-scale representations, frequency based, and lens based interaction techniques. In this paper, we comparatively evaluate existing methods, such as Stack Zoom [15] and ChronoLenses [38], giving a graphical overview of each and classifying their ability to explore and interact with data. We propose new visualizations and other extensions to the existing approaches. We undertake and report an empirical study and a field study using these techniques.	categorization;chart;classification;display resolution;field research;graphical user interface;interaction technique;numerous;sensor;time series	James S. Walker;Rita Borgo;Mark W. Jones	2016	IEEE Transactions on Visualization and Computer Graphics	10.1109/TVCG.2015.2467751	computer vision;information visualization;computer science;data science;data mining;lens;data visualization	Visualization	-26.101139633274332	-33.21932465787316	37436
039ca174a9bc2965c4579e2fde530e80c0ca0567	relaxing graph pattern matching with explanations		Traditional graph pattern matching is based on subgraph isomorphism, which is often too restrictive to identify meaningful matches. To handle this, taxonomy subgraph isomorphism has been proposed to relax the label constraints in the matching. Nonetheless, there are many cases that cannot be covered. In this study, we first formalize taxonomy simulation, a natural matching semantics combing graph simulation with taxonomy, and propose its pattern relaxation to enrich graph pattern matching results with taxonomy information. We also design topological ranking and diversified topological ranking for top-k relaxations. We then study the top-k pattern relaxation problems, by providing their static analyses, and developing algorithms and optimization for finding and evaluating top-k pattern relaxations. We further propose a notion of explanations for answers to the relaxations and develop algorithms to compute explanations. These together give us a framework for enriching the results of graph pattern matching. Using real-life datasets, we experimentally verify that our framework and techniques are effective and efficient for identifying meaningful matches in practice.	algorithm;experiment;linear programming relaxation;mathematical optimization;pattern matching;real life;simulation;static program analysis;subgraph isomorphism problem;taxonomy (general)	Jia Li;Yang Cao;Shuai Ma	2017		10.1145/3132847.3132992	data mining;pattern matching;machine learning;semantics;theoretical computer science;computer science;subgraph isomorphism problem;graph;artificial intelligence;ranking	DB	-9.809783711381112	-37.68131024763232	37491
3fe418fb41749b48d2ff29952098ac0915667c6b	leveraging multiple networks for author personalization		Recommender systems provide personalized item suggestions by identifying patterns in past user-item preferences. Most existing approaches for recommender systems work on a single domain, i.e., use user preferences from one domain and recommend items from the same domain. Recently, some recommendation models have been proposed to use user preferences from multiple related item source domains to improve recommendation accuracy for a target item domain, an area of research known as cross-domain recommender systems. One typical assumption in these systems is that users, items, and user preferences for items are similar across domains. In this paper, we introduce a new crossdomain recommendation problem which does not meet this typical assumption. For example, for some scientometric datasets, when the objective is to recommend co-authors, conferences, and references, respectively, to authors, although the users are similar across domains, the items and user-item preferences are different. To address this problem, we propose two approaches to aggregate knowledge from multiple domains. Our approaches allow us to control the knowledge transferred between domains. Experimental results on a DBLP subset show that the proposed cross-domain approaches are helpful in improving recommendation accuracy as compared to single domain approaches.	aggregate data;citation network;domain theory;journal citation reports;personalization;recommender system;scientometrics;user (computing)	Rohit Parimi;Doina Caragea	2015			personalization;data mining;computer science	AI	-21.595014788862184	-48.0488564403699	37526
c503c9d9cb2ee6587588c9724620242593913ba0	monitoring urban sprawl and sustainable urban development using the moran index: a case study of stellenbosch, south africa	local moran i;spatial cluster and outlier;sustainable urban development;distance band;urban sprawl;global moran i	The management of urban sprawl is fundamental to achieving sustainable urban development. Monitoring urban sprawl is, however, challenging. This study proposes the use of two spatial statistics, namely global Moran and local Moran to indentify statistically significant urban sprawl hot and cold spots. The findings reveal that the Moran indexes are sensitive to the distance band spatial weight matrices employed and that multiple bands should be used when these indexes are used. The authors demonstrate how the indexes can be used in combination with various visualisation methods to support planning decisions. Monitoring Urban Sprawl and Sustainable Urban Development Using the Moran Index: A Case Study of Stellenbosch, South Africa	spatial analysis	Walter Musakwa;Adriaan Van Niekerk	2014	IJAGR	10.4018/ijagr.2014070101	urban sprawl;geography;ecology;cartography	HCI	-12.535930976027796	-24.079183525082694	37565
dcf9350d324f0afb54168a414ff01b605954e69c	more: a user controlled content based movie recommender with explanation and negative feedback	negative feedback	Recommendation systems have become a popular approach for accessing relevant products and information. Existing approaches for movie recommendation systems are insufficient, because they do not provide transparency to the users through enabling them to view and edit their profiles. In addition, negative feedback, which is an important clue for the recommender, is not taken into account. In this paper we concentrate on the ideas of automatically generating user profiles from the user’s item preferences, and enabling users to view and edit their profiles to get satisfaction. In addition, taking negative feedback for specific values is examined and discussed, which is observed to produce more accurate recommendations. The system also provides the explanations for the produced recommendations and allows users to modify their profile accordingly and see their modifications’ effects on the results directly. Initial experimental results demonstrate that the system produces accurate recommendations and gets user trust and satisfaction with the transparency and explanation facility.	negative feedback;recommender system;user profile	Oznur Kirmemis;Aysenur Birturk	2008			computer science;multimedia;internet privacy;world wide web;negative feedback	HCI	-28.239474457428802	-48.020204276309485	37603
30febe8b5ea6e6e55c545d5cc45d1ca437b0021f	ggobi: evolving from xgobi into an extensible framework for interactive data visualization	software;metodo estadistico;extensible markup language;interfase usuario;interfaz grafica;analisis datos;logiciel;api;interoperabilite;graphical interface;interoperabilidad;user interface;direct manipulation;xml language;representation graphique statistique;statistical data analysis;statistical method;application program interface;systeme conversationnel;data analysis;norme api;interactive system;methode statistique;plugins;data visualization;xml;sistema conversacional;norma api;logicial;analyse donnee;lookup table;interface utilisateur;visualisation donnee;interoperability;interface graphique;statistical graphics;langage xml;lenguaje xml;api standards;r	GGobi is a direct descendent of a data visualization system called XGobi that has been around since the early 1990’s. GGobi’s new features include multiple plotting windows, a color lookup table manager, and an XML (Extensible Markup Language) file format for data. Perhaps the biggest advance is that GGobi can be easily extended, either by being embedded in other software or by the addition of plugins; either way, it can be controlled using an API (Application Programming Interface). An illustration of its extensibility is that it can be embedded in R. The result is a full marriage between GGobi’s direct manipulation graphical environment and R’s familiar extensible environment for statistical data analysis.	application programming interface;colour look-up table;compiler;component-based software engineering;computational statistics;direct manipulation interface;documentation;embedded system;event loop;extensibility;graphical user interface;graphics;interactive data visualization;interoperability;lookup table;markup language;microsoft windows;mind;operability;plug-in (computing);reinventing the wheel;s (programming language);software developer;xml	Deborah F. Swayne;Duncan Temple Lang;Andreas Buja;Dianne Cook	2003	Computational Statistics & Data Analysis	10.1016/S0167-9473(02)00286-4	xml;statistical graphics;computer science;operating system;database;world wide web;data visualization;statistics	DB	-27.835007784821173	-29.274946596319896	37659
ac3f92e7018551348e5b054bbbdf7b18b5f81bcc	human mobility analysis based on social media and fuzzy clustering		A better understanding of the movement of a city aids to the efficient adaptation of the energy consumption to the necessities of citizens. For this purpose, the use of clustering algorithms applied to large amounts of geo-tagged data generated in social-networks is foreseen to become an interesting course of action. This will help to comprehensively capture and understand the movement of people in large spatial regions. Due to the nature of this kind of data (with high levels of uncertainty and noise) soft-computing owns the necessary characteristics to extract accurate mobility models. The present work introduces a novel approach to extract personal mobility patterns by means of the fuzzy c-means (FCM) algorithm. A preliminary study with a real Twitter database is also included.	algorithm;cluster analysis;fuzzy clustering;fuzzy cognitive map;gene ontology term enrichment;population;social media;soft computing	Jesús Cuenca-Jara;Fernando Terroso-Saenz;Mercedes Valdés-Vela;Aurora González-Vidal;Antonio F. Gómez-Skarmeta	2017	2017 Global Internet of Things Summit (GIoTS)	10.1109/GIOTS.2017.8016266	fuzzy logic;computer science;computer security;fuzzy clustering;cluster analysis;data mining;social media;mobility model;personal mobility	ML	-19.43604861359847	-35.66047473905884	37690
3db587832eed90171614fc5524887e8a3ab1b363	effect of perturbing the geographic coordinates of forest inventory plots on hotspot cluster detection	spatial scan statistic;fia data;point pattern analysis;satscan	The USDA Forest Service Forest Inventory and Analysis (FIA) program makes and keeps current an inventory of all forest land in the United States. Data from this ongoing inventory are available to the public, though FIA is restricted from releasing exact plot locations by the 2000 Interior and Related Agencies Appropriations Act (H.R. 3423). To comply with this policy while at the same time offering its data to the public, FIA makes approximate plot locations available through a process known as perturbing and swapping. This process has little to no effect on some research questions and a considerable effect on others. In this study, using the perturbed and swapped, i.e., the publicly available plot locations, was shown to affect the location, size, and composition of clusters of standing dead trees in the eastern United States as detected by the free spatial scanning software program SaTScan TM . When employing SaTScan with publicly available FIA plot coordinates as compared to using the confidential FIA plot coordinates, users risk identifying a cluster that does not exist (false positive) or failing to identify a cluster that does exist (false negative), or both.	geographic coordinate system;java hotspot virtual machine	KaDonna C. Randolph	2017	MCFNS		geography;operations management;data mining;computer security	Vision	-16.250825040780782	-29.758988593969903	37731
1c471ec484b236fa270df0333c8cfcf5d2ac40ab	mining host behavior patterns from massive network and security logs		Mining host behavior patterns from massive logs plays an important and crucial role in anomalies diagnosing and management for large-scale networks. Almost all prior work gives a macroscopic link analysis of network events, but fails to microscopically analyze the evolution of behavior patterns for each host in networks. In this paper, we propose a novel approach, namely Log Mining for Behavior Pattern (LogM4BP), to address the limitations of prior work. LogM4BP builds a statistical model that captures each host’s network behavior patterns with the nonnegative matrix factorization algorithm, and finally improve the interpretation and comparability of behavior patterns, and reduce the complexity of analysis. The work is evaluated on a public data set captured from a big marketing company. Experimental results show that it can describe network behavior patterns clearly and accurately, and the significant evolution of behavior patterns can be mapped to anomaly events i real world i tuitively.	algorithm;anomaly detection;information privacy;link analysis;non-negative matrix factorization;statistical model	Jing Ya;Tingwen Liu;Quangang Li;Jinqiao Shi;Haoliang Zhang;Pin Lv;Li Guo	2017		10.1016/j.procs.2017.05.072	data mining;artificial intelligence;machine learning;computer science;link analysis;network management;statistical model;behavioral pattern;non-negative matrix factorization	ML	-18.661769628578806	-38.351915280232795	37769
e64af0f32374bcee783b756416ba40073d05723b	indexable bayesian personalized ranking for efficient top-k recommendation		Top-k recommendation seeks to deliver a personalized recommendation list of k items to a user. The dual objectives are (1) accuracy in identifying the items a user is likely to prefer, and (2) efficiency in constructing the recommendation list in real time. One direction towards retrieval efficiency is to formulate retrieval as approximate k nearest neighbor (kNN) search aided by indexing schemes, such as locality-sensitive hashing, spatial trees, and inverted index. These schemes, applied on the output representations of recommendation algorithms, speed up the retrieval process by automatically discarding a large number of potentially irrelevant items when given a user query vector. However, many previous recommendation algorithms produce representations that may not necessarily align well with the structural properties of these indexing schemes, eventually resulting in a significant loss of accuracy post-indexing. In this paper, we introduce Indexable Bayesian Personalized Ranking (IBPR) that learns from ordinal preference to produce representation that is inherently compatible with the aforesaid indices. Experiments on publicly available datasets show superior performance of the proposed model compared to state-of-the-art methods on top-k recommendation retrieval task, achieving significant speedup while maintaining high accuracy.	align (company);approximation algorithm;data structure;experiment;inverted index;k-nearest neighbors algorithm;locality of reference;locality-sensitive hashing;ordinal data;personalization;real-time computing;recommender system;relevance;speedup;surface web;user (computing);lsh	Dung D. Le;Hady W. Lauw	2017		10.1145/3132847.3132913	inverted index;information retrieval;hash function;search engine indexing;speedup;ordinal number;k-nearest neighbors algorithm;computer science;bayesian probability;ranking	Web+IR	-6.439924287332641	-41.22239414782454	37781
c65dc027f4c1d19f6efab45a26c8ccf1490a4ce7	assessment of distractions inferred by in-vehicle information systems on a naturalistic simulator	gaze;attention lapses;driving simulators;detection capacity in vehicle information systems naturalistic simulator national highway traffic safety administration cell phones gps navigation systems automatic distraction monitoring system driver gaze focalization non intrusive vision based approach;in vehicle support systems;automatic data collection systems;driver monitoring;vehicles driver information systems;vehicles;vehicles global positioning system roads face cameras monitoring estimation;driver information systems;distraction	Driving inattention is a major factor to highway crashes. The National Highway Traffic Safety Administration (NHTSA) estimates that approximately 25% of police-reported crashes involve some form of driving inattention. Increasing use of in-vehicle information systems (IVISs) such as cell phones or GPS navigation systems has exacerbated the problem by introducing additional sources of distraction. Enabling drivers to benefit from IVIS without diminishing safety is an important challenge. In this paper, an automatic distraction monitoring system based on gaze focalization for the assessment of IVISs induced distraction is presented. Driver's gaze focalization is estimated using a non-intrusive vision-based approach. This system has been tested in a naturalistic simulator with more than 15 hours of driving in different scenarios and conditions and 12 different professional drivers. The purpose of this work is, on the one hand, to assess the detection capacity of the monitoring system and, in the other hand, to study drivers reactions to different IVISs. Gathering this information the optimal IVISs location and the way the indications should be delivered to the drivers can be studied to reduce the interference with their driving.	crash (computing);gps navigation device;global positioning system;information system;interference (communication);mobile phone;simulation;vii	Noelia Hernández;Pedro Jiménez;Luis Miguel Bergasa;Ignacio Parra;Irene García;Manuel Ocaña;Beatriz Delgado;Matias Sevillano	2011	2011 14th International IEEE Conference on Intelligent Transportation Systems (ITSC)	10.1109/ITSC.2011.6082886	computer vision;simulation;engineering;computer security	Robotics	-19.397136202263606	-27.37486861679825	37786
3f7a1430b1eb47cbfa57262a0d7cda98cd10303b	review of transportation mode detection techniques		This paper reviews the works found in the literature in the field of Transportation Mode Detection (TMD) which is a subfield of Activity Recognition aiming at indentifying (i.e. classifying) the mean of transportation a person is using. The solutions found in literature have different characteristics according to the device for which the solution was tailored (smartphones or other systems such as, e.g., GPS loggers) and to the algorithm used for the classification task. This may vary a lot according to the number and type of input used (e.g. accelerations, GPS, maps information or GIS Geographical Information System information) and to the identified classes of transportation mode. These two aspects are the most relevant to consider when evaluating and comparing the accuracies claimed by each work. A comparison of the works is proposed taking into account the characteristics discussed above. In general the accelerometer is the most widely used sensor for TMD applications, as it limits battery consumption and captures relevant features for detecting motion. Indeed a key challenge in TMD is to detect different motorized classes such as bus, car, train and metro because they share common characteristics (such as e.g. the average speed and accelerations) which make hard identifying suitable features for the classification algorithm. Identifying the “walk” and “stationary” transportation modes is a simpler task because they are characterized by distinct features.	activity recognition;algorithm;gps tracking unit;geographic information system;global positioning system;map;sensor;smartphone;stationary process;system information (windows);tip-magnetic driving;transition metal dichalcogenide monolayers	Jacopo Biancat;Chiara Brighenti;Attilio Brighenti	2014	ICST Trans. Ambient Systems	10.4108/amsys.1.4.e7	computer science	HCI	-17.417567246027073	-33.04051536160506	37860
836b7a9b635dbed7b5c81f799a6af42f7e4f19ea	scanning text with a 1401	indexation	Scanning text on a computer, as in forming word lists or editing, usually involves isolating and identifying certain characters or classes of characters. For example, if we scan text to form a list of words, the definition of “word” might be “everything between two blanks that isn't punctuation.” To program this, we must be able to identify a single character (blank) and a class of characters (punctuation). In a computer such as the 7090, where characters are numbers, we can put a character into an index register and index a table of transfers (one table-entry per character), thus getting to a section of code appropriate for handling that particular character. This is not natural for the 1401 because characters are not numbers and turning them into numbers is a bit clumsy. However, 1401 addresses are a combination of numbers and other characters, and we can use characters directly to reference certain addresses provided we can turn all characters (there are 64) into the 40 that are allowable in specifying an address.	dictionary attack;ibm 1401;image scanner;index register	James J. Baker	1964	Commun. ACM	10.1145/355588.365134	arithmetic;speech recognition;computer science;algorithm	Graphics	-32.195609112806665	-25.893832954436714	37932
9496a9506703e12ae896590163d93f5e1f10a333	complex network tools to understand the behavior of criminality in urban areas		Complex networks are nowadays employed in several applications. Modeling urban street networks is one of them, and in particular to analyze criminal aspects of a city. Several research groups have focused on such application, but until now, there is a lack of a well-defined methodology for employing complex networks in a whole crime analysis process, i.e. from data preparation to a deep analysis of criminal communities. Furthermore, the “toolset” available for those works is not complete enough, also lacking techniques to maintain up-to-date, complete crime datasets and proper assessment measures. In this sense, we propose a threefold methodology for employing complex networks in the detection of highly criminal areas within a city. Our methodology comprises three tasks: (i) Mapping of Urban Crimes; (ii) Criminal Community Identification; and (iii) Crime Analysis. Moreover, it provides a proper set of assessment measures for analyzing intrinsic criminality of communities, especially when considering different crime types. We show our methodology by applying it to a real crime dataset from the city of San Francisco – CA, USA. The results confirm its effectiveness to identify and analyze high criminality areas within a city. Hence, our contributions provide a basis for further developments on complex networks applied to crime analysis.	complex network;the wall street journal	Gabriel Spadon;Lucas C. Scabora;Marcus V. S. Araujo;Paulo H. Oliveira;Bruno Brandoli Machado;Elaine P. M. de Sousa;Caetano Traina;José F. Rodrigues	2016	CoRR	10.1007/978-3-319-54978-1_63	criminology;social psychology	ML	-14.043673722643208	-24.30422435324329	37963
10d087157c97dbd3eb6fb29eaea7513e7db558e4	interactive by-example design of artistic packing layouts	distribution;user interface;packing;layout inference	"""We propose an approach to """"pack"""" a set of two-dimensional graphical primitives into a spatial layout that follows artistic goals. We formalize this process as projecting from a high-dimensional feature space into a 2D layout. Our system does not expose the control of this projection to the user in form of sliders or similar interfaces. Instead, we infer the desired layout of all primitives from interactive placement of a small subset of example primitives. To produce a pleasant distribution of primitives with spatial extend, we propose a novel generalization of Centroidal Voronoi Tesselation which equalizes the distances between boundaries of nearby primitives. Compared to previous primitive distribution approaches our GPU implementation achieves both better fidelity and asymptotically higher speed. A user study evaluates the system's usability."""	centroidal voronoi tessellation;feature vector;graphical user interface;graphics processing unit;interactivity;set packing;usability testing;voronoi diagram	Bernhard Reinert;Tobias Ritschel;Hans-Peter Seidel	2013	ACM Trans. Graph.	10.1145/2508363.2508409	distribution;computer vision;simulation;computer science;theoretical computer science;operating system;machine learning;mathematics;user interface;computer graphics (images)	Graphics	-29.953886890779113	-34.69891883971414	38004
25196557366910264d3a9ba30b07a23813e50dee	incorporating metadata into dynamic topic analysis		Everyday millions of blogs and micro-blogs are posted on the Internet These posts usually come with useful metadata, such as tags, authors, locations, etc. Much of these data are highly specific or personalized. Tracking the evolution of these data helps us to discover trending topics and users’ interests, which are key factors in recommendation and advertisement placement systems. In this paper, we use topic models to analyze topic evolution in social media corpora with the help of metadata. Specifically, we propose a flexible dynamic topic model which can easily incorporate various type of metadata. Since our model adds negligible computation cost on the top of Latent Dirichlet Allocation, it can be implemented very efficiently. We test our model on both Twitter data and NIPS paper collection. The results show that our approach provides better performance in terms of held-out likelihood, yet still retains good interpretability.	blog;computation;dynamic topic model;latent dirichlet allocation;nips;personalization;social media;text corpus	Tianxi Li;Branislav Kveton;Yu Wu;Ashwin Kashyap	2012			the internet;latent dirichlet allocation;topic model;social media;information retrieval;data mining;metadata repository;interpretability;metadata;dynamic topic model;computer science	Web+IR	-20.13963747438815	-49.610500855558605	38061
39282ff070f62ceeaa6495815098cbac8411101f	collaborative location and activity recommendations with gps history data	matrix factorization;location based service;location and activity recommendations;social network;specific activity;collaborative filtering;empirical evaluation;geographic database	With the increasing popularity of location-based services, such as tour guide and location-based social network, we now have accumulated many location data on the Web. In this paper, we show that, by using the location data based on GPS and users' comments at various locations, we can discover interesting locations and possible activities that can be performed there for recommendations. Our research is highlighted in the following location-related queries in our daily life: 1) if we want to do something such as sightseeing or food-hunting in a large city such as Beijing, where should we go? 2) If we have already visited some places such as the Bird's Nest building in Beijing's Olympic park, what else can we do there? By using our system, for the first question, we can recommend her to visit a list of interesting locations such as Tiananmen Square, Bird's Nest, etc. For the second question, if the user visits Bird's Nest, we can recommend her to not only do sightseeing but also to experience its outdoor exercise facilities or try some nice food nearby. To achieve this goal, we first model the users' location and activity histories that we take as input. We then mine knowledge, such as the location features and activity-activity correlations from the geographical databases and the Web, to gather additional inputs. Finally, we apply a collective matrix factorization method to mine interesting locations and activities, and use them to recommend to the users where they can visit if they want to perform some specific activities and what they can do if they visit some specific places. We empirically evaluated our system using a large GPS dataset collected by 162 users over a period of 2.5 years in the real-world. We extensively evaluated our system and showed that our system can outperform several state-of-the-art baselines.	baseline (configuration management);database;digital history;geosocial networking;global positioning system;location-based service;social network;world wide web	Vincent Wenchen Zheng;Yu Zheng;Xing Xie;Qiang Yang	2010		10.1145/1772690.1772795	simulation;computer science;collaborative filtering;location-based service;specific activity;data mining;database;matrix decomposition;world wide web;social network	Web+IR	-18.531412420091485	-35.37048970089867	38151
5690bd559a0b3f597c57f7ebc8828e994a377eaf	implementation of synthetic aperture radar and geoinformation technologies in the complex monitoring and managing of the mining industry objects		Design, planning and management of opencast and underground mining require safety control of mining operations. Geodynamic monitoring of mining areas is necessary for operational forecasting and prevention of dangerous deformation processes. The identification of geodynamic active zones and forecasting of geodynamic risks are based on systematic observations of the surface and mining facilities. A promising method of obtaining timely spatial information to solve the problems mentioned is the satellite radar imagery. The integration of radar products and intelligent information systems improves the efficiency and accuracy of data analysis. The paper presents the methods of radar image processing in order to conduct comprehensive monitoring of the Earth’s surface and infrastructure in mining enterprises. For efficient use of thematic processing products the results were placed on the web server in the information-analytical system “RegionView” providing distributed access to spatial data through the web interface and standard protocols.	geographic information system;synthetic intelligence	Maria R. Ponomarenko;Ilya Yu. Pimanov	2017		10.1007/978-3-319-57264-2_30	radar imaging;remote sensing;spatial analysis;radar;synthetic aperture radar;information system;underground mining (hard rock);artificial intelligence;computer vision;geographic information system;engineering	DB	-13.238604919714936	-27.354087119206632	38157
68d8138e63196ffe214b1246614c4749fe83d329	deep dense convolutional networks for repayment prediction in peer-to-peer lending		In peer-to-peer (P2P) lending, it is important to predict default of borrowers because the lenders would suffer financial loss if the borrower fails to pay money. The huge lending transaction data generated online helps to predict repayment of the borrowers, but there are limitations in extracting features based on the complex information. Convolutional neural networks (CNN) can automatically extract useful features from large P2P lending data. However, as deep CNN becomes more complex and deeper, the information about input vanishes and overfitting occurs. In this paper, we propose a deep dense convolutional networks (DenseNet) for default prediction in P2P social lending to automatically extract features and improve the performance. DenseNet ensures the flow of loan information through dense connectivity and automatically extracts discriminative features with convolution and pooling operations. We capture the complex features of lending data and reuse loan information to predict the repayment of the borrower. Experimental results show that the proposed method automatically extracts useful features from Lending Club data, avoids overfitting, and is effective in default prediction. In comparison with deep CNN and other machine learning methods, the proposed method has achieved the highest performance with 79.6%. We demonstrate the usefulness of the proposed method as the 5-fold cross-validation to evaluate the performance.	peer-to-peer lending	Ji-Yoon Kim;Sung-Bae Cho	2018		10.1007/978-3-319-94120-2_13	overfitting;convolutional neural network;machine learning;peer-to-peer;deep learning;loan;artificial intelligence;computer science;transaction data;default;pooling	ML	-13.423567330066055	-49.30910815674164	38207
1c8398e59b8469c4e650f029c0b394e11dcbf5b7	tsunami early alert and evacuation support system for fishery workers by mobile phones	early warning system;comprehensive anti tsunami measures;evacuation support system;oceans;electronic mail;tsunami;tsunami early alert;prototypes;indian ocean;industries;earthquakes;information services;tsunami aquaculture mobile handsets postal services earthquakes oceans sea measurements seismic measurements electronic mail prototypes;aquaculture;mobile phone;support system;disaster information service;tsunami electronic mail emergency services information services mobile computing;servers;postal services;global positioning system;mobile handsets;area mail;tsunami disaster;information service;mobile phones;mobile computing;fishery workers;area mail tsunami disaster early warning system mobile phone;ntt docomo tsunami early alert evacuation support system fishery workers mobile phones comprehensive anti tsunami measures disaster information service area mail;pacific coast;seismic measurements;ntt docomo;sea measurements;emergency services;boats	"""An Indian Ocean tsunami on December 26, 2004 - which killed about 230,000 people in 11 countries - is the worst on record. An earthquake and a following tsunami killed more than 180 people on Samoa, American Samoa and nearby islands on Sept. 2009. In Japan, earthquakes are expected to occur with high probability at the seismic center near the pacific coast of Japan archipelago, especially somewhere in the oceanic trench of the southern Sanriku region. For that reason, some kind of enforcement of comprehensive anti-tsunami measures is expected to take place as soon as possible for the people of the Sanriku region across Iwate and Miyagi prefectures. Regarding the disaster information service """"Area Mail"""" that NTT DoCoMo provides, it is possible to deliver information simultaneously for afflicted limited areas unlike traditional mobile e-mail system. It is thought that the Area Mail can be used to notify not only to inhabitants but also to the tourists at the time of the disaster. Furthermore, because Area Mail covers the main fishery region in the coast, service to fishery workers is possible while they operate along the coast. They can avoid tsunami damage even in very early stages of an event. In this study, we built a prototype and carried out an experiment at one of the fisheries cooperatives in Miyako city to evaluate and assess the feasibility of the system."""	email;mobile phone;prototype;requirement;with high probability	Hidenori Torii;Jun Sawamoto;Norihisa Segawa;Eiji Sugino;Yukinori Nomura	2010	2010 IEEE 24th International Conference on Advanced Information Networking and Applications Workshops	10.1109/WAINA.2010.24	aquaculture;global positioning system;computer science;operating system;prototype;mobile computing;computer security;information system;server	Robotics	-19.33507158466102	-29.091685896080357	38236
4cded4842aa93835276b8121d440ed5a3cf29955	improving recommendation accuracy and diversity via multiple social factors and social circles		Recommender systems (RS) have been widely employed to suggest personalized online information to simplify user's information discovery process. With the popularity of online social networks, analysis and mining of social factors and social circles have been utilized to support more effective recommendations, but have not been fully investigated. In this paper, the authors propose a novel recommendation model with the consideration of more comprehensive social factors and topics that user is explicitly and implicitly interested in. Concretely, to further enhance recommendation accuracy, four social factors, individual preference, interpersonal trust influence, interpersonal interest similarity and interpersonal closeness degree, are simultaneously injected into our recommendation model based on probabilistic matrix factorization. Meanwhile, the authors explore several new methods to measure these social factors. Moreover, the authors infer explicit and implicit social circles to enhance the performance of recommendation diversity. Finally, the authors conduct a series of experiments on publicly available data. Experimental results show the proposed model achieves significantly improved performance (accuracy and diversity) over the existing models in which social information have not been fully considered.		Yong Feng;Heng Li;Zhuo Chen	2014	Int. J. Web Service Res.	10.4018/IJWSR.2014100103	data mining;social psychology;world wide web	Web+IR	-20.05846616048333	-46.717810347374524	38269
0709d801d3fbd75178431d4e68444e012c0a80f7	fast marching solution for the social path planning problem		Traditional path planning for robots is a well-studied problem. However, the classical setting of the problem is simple to state: plan a path for a robot, starting from an initial point, and ending at a desired target point, given an environmental map, usually in the form of an occupancy grid. In this setting though, no special consideration is given to humans; they are thought of simply, as being obstacles in the environment, equivalent to chairs or walls. However, with more robots entering human spaces, special consideration needs to be given: humans need special treatment as obstacles, and furthermore humans can also serve the goal of goal points, towards starting a social interaction; either individual humans or groups of humans. Also, special mechanisms are required for engaging and disengaging in such interactions, taking into account psychological considerations of proxemics. In this paper, we first introduce our unifying theoretical framework for all the subproblems of social path planning; then, we propose an extended mode for engaging groups of people; and then, by using a special version of the fast-marching square planning method, we present and demonstrate actual algorithmic solutions for the social path planning subproblems. Our results prove the strengths of our approach and its generalizability. Finally, concrete further steps are discussed.	fast marching method;humans;interaction;motion planning;robot	Javier V. Gómez;Nikolaos Mavridis;Santiago Garrido	2014	2014 IEEE International Conference on Robotics and Automation (ICRA)	10.1109/ICRA.2014.6907105	computer vision;mathematical optimization;simulation;any-angle path planning	Robotics	-32.55580874165084	-41.891806779941554	38300
6cfdf2ce577f78a4af9fe121d866e22a4d0f8d70	clique covering of large real-world networks	software;edge clique cover;large networks;real world networks	The edge clique covering (ecc) problem deals with discovering a set of (possibly overlapping) cliques in a given network, such that each edge is part of at least one of these cliques. We address the ecc problem from an alternative perspective reconsidering the quality of the cliques found, and proposing more structured criteria with respect to the traditional measures such as minimum number of cliques. In the case of real-world networks, having millions of nodes, such as social networks, the possibility of getting a result is constrained to the running time, which should be linear or almost linear in the size of the network. Our algorithm for finding eccs of large networks has linear-time performance in practice, as our experiments show on real-world networks whose number of nodes ranges from thousands to several millions.	algorithm;experiment;social network;time complexity	Alessio Conte;Roberto Grossi;Andrea Marino	2016		10.1145/2851613.2851816	evolving networks;network motif;machine learning;clique percolation method	ML	-11.914716607379326	-40.983681558770314	38306
29c554d063e07f5ccea7272719af77a72033a4e8	generating recommendations by graph traversal in social rating networks		Collaborative filtering recommender systems make automatic predictions about users' interests by utilizing information collected from similarly minded users in order to recommend new items. However in most practical settings the ratings matrix is extremely sparse and thus the step of calculating similarities between users often fails. We propose a method for generating recommendations in such problematic cases by expanding and traversing the users' similarity graph so as to make new link predictions between users that are not directly connected. We evaluate our proposal on the Epin-ions social rating network, and show that the infusion of this new information in the similarity graph is comparable to state of the art graph embedding techniques but with lower computational cost and directly comparable coverage.	algorithmic efficiency;collaborative filtering;computation;graph embedding;graph traversal;recommender system;sparse matrix;tree traversal	Flora Sakketou;Nicholas Ampazis;Dimosthenis Drivaliaris	2018		10.1145/3200947.3201009	computer science;artificial intelligence;collaborative filtering;recommender system;machine learning;graph embedding;data mining;k-means clustering;graph traversal;cluster analysis;graph;matrix (mathematics)	AI	-14.673641400557248	-44.48355277227478	38319
b75456f78ec4d1c63e083ae3bb6e37e7e065ccfe	social media-based forecasting: a case study of tweets and stock prices in the financial services industry	forecasting;stock market;sentiment analysis;twitter;social media	Social media-based forecasting has received significant attention from academia and industries in recent years. With a focus on Twitter, this paper investigates whether sentiments of the tweets regarding the 7 largest US financial service companies (in U.S. dollars) are related to the stock price changes of these companies. The authors’ findings indicate, in the financial services context, negative sentiments predict firms’ future stock prices. However, the number of and the positive sentiment of tweets are not correlated with stock prices. The findings of this paper suggest the possible predictive value of social media data on stock prices at the company level. KEywORdS Forecasting, Sentiment Analysis, Social Media, Stock Market, Twitter	sentiment analysis;social media	Wu He;Lin Guo;Jiancheng Shen;Vasudeva Akula	2016	JOEUC	10.4018/JOEUC.2016040105	stock exchange;stock market bubble;social media;forecasting;computer science;marketing;restricted stock;stock;world wide web;sentiment analysis;commerce	ML	-9.288044324344533	-30.726263774581145	38347
10d58512bf70cc47ae076985e8cb9bf907e795d2	jholes: a tool for understanding biological complex networks via clique weight rank persistent homology	complex networks;tumor diagnosys;biological networks;betti number;computational topology	Complex networks equipped with topological data analysis are one of the promising tools in the study of biological systems (e.g. evolution dynamics, brain correlation, breast cancer diagnosis, etc. . . ). In this paper, we propose jHoles, a new version of Holes, an algorithms based on persistent homology for studying the connectivity features of complex networks. jHoles fills the lack of an efficient implementation of the filtering process for clique weight rank homology. We will give a brief overview of Holes, a more detailed description of jHoles algorithm, its implementation and the problem of clique weight rank homology. We present a biological case study showing how the connectivity of epidermal cells changes in response to a tumor presence. The biological network has been derived from the proliferative, differentiated and stratum corneum compartments, and jHoles used for studying variation of the connectivity.		Jacopo Binchi;Emanuela Merelli;Matteo Rucco;Giovanni Petri;Francesco Vaccarino	2014	Electr. Notes Theor. Comput. Sci.	10.1016/j.entcs.2014.06.011	betti number;biological network;combinatorics;discrete mathematics;computational topology;topology;computer science;mathematics;complex network	Theory	-8.440531040195392	-51.07984714123307	38430
57d5f4784b0ba6370426e259160c50963787bee6	a distributed intelligent monitoring system applied to a micro-scale turning process	ultra precision diamond turning;fuzzy modeling;monitoring system;intelligent distributed networked monitoring system;real time application;fuzzy model;distributed architecture	In this paper, a distributed intelligent monitoring system for a micro-scale turning process is presented. A fuzzy model,  running on a distributed architecture, helps on decision-making about the imbalance degree of the spindle in the ultra-precision  diamond turning process. The suitability of a three-input/single-output fuzzy model is assessed directly on an ultra-precision  lathe, verifying it effectiveness. A brief explanation of the single point diamond turning process and problems caused by  the vibrations generated due to the imbalance of the spindle, are also presented. Real-time application of the fuzzy decision  making, as part of a networked distributed monitoring system, assists the operator when manufacturing complex parts.  		Raúl M. del Toro;Rodolfo E. Haber;Michael Schmittdiel	2009		10.1007/978-3-642-02481-8_48	embedded system;real-time computing;computer science	Robotics	-8.255481392255916	-25.120507470782435	38469
78ed2b5ef562f8c4b6285fc610d9c9e88a61a67f	novel leakage detection by ensemble cnn-svm and graph-based localization in water distribution systems		In many water distribution systems, a significant amount of water is lost because of leakage during transit from the water treatment plant to consumers. As a result, water leakage detection and localization have been a consistent focus of research. Typically, diagnosis or detection systems based on sensor signals incur significant computational and time costs, whereas the system performance depends on the features selected as input to the classifier. In this paper, to solve this problem, we propose a novel, fast, and accurate water leakage detection system with an adaptive design that fuses a one-dimensional convolutional neural network and a support vector machine. We also propose a graph-based localization algorithm to determine the leakage location. An actual water pipeline network is represented by a graph network and it is assumed that leakage events occur at virtual points on the graph. The leakage location at which costs are minimized is estimated by comparing the actual measured signals with the virtually generated signals. The performance was validated on a wireless sensor network based test bed, deployed on an actual WDS. Our proposed methods achieved 99.3% leakage detection accuracy and a localization error of less than 3 m.	algorithm;artificial neural network;assistive technology;computation;convolutional neural network;internationalization and localization;location-based service;remote desktop services;spectral leakage;support vector machine;testbed	Jiheon Kang;Youn-Jong Park;Jaeho Lee;Soo-Hyun Wang;Doo Seop Eom	2018	IEEE Transactions on Industrial Electronics	10.1109/TIE.2017.2764861	convolutional neural network;wireless sensor network;control engineering;engineering;feature extraction;support vector machine;leakage (electronics);pattern recognition;graph;artificial intelligence	Robotics	-12.329832502894927	-30.616949544940788	38539
aad75465bcc932924188984e8fa656d6965a2982	a system for storing and retrieving huge amount of trajectory data, allowing spatio-temporal dynamic queries	video surveillance;image motion analysis;image segmentation;segmentation stage trajectory data storing trajectory data retrieval spatio temporal dynamic query intelligent traffic surveillance surveillance camera spatio temporal data indexing off the shelf bidimensional index;surveillance;information retrieval;intelligent transportation systems;video surveillance automated highways image motion analysis image segmentation traffic engineering computing;automated highways;data mining;data storage;trajectory;indexing;data files;traffic engineering computing;traffic surveillance;vehicles;road transportation;cameras;trajectory indexing vehicles road transportation surveillance data mining;vehicle trajectories	In the framework of intelligent traffic surveillance, we propose a system for efficiently storing and retrieving moving objects' trajectories extracted from surveillance cameras. We index spatio-temporal data by using a method based on off-the-shelf (widely available) bi-dimensional indexes and enhanced by a segmentation stage. The proposed system does not restrict the choice of the parameters of range queries at query time, unlike clustering and similarity-based methods do. The experimental results, obtained on a standard PC-based system both on a well known real-world trajectory dataset and on synthetic data, confirm the efficiency of the proposed approach.	algorithm;central processing unit;closed-circuit television;cluster analysis;multi-core processor;range query (data structures);synthetic data	Antonio d'Acierno;Marco Leone;Alessia Saggese;Mario Vento	2012	2012 15th International IEEE Conference on Intelligent Transportation Systems	10.1109/ITSC.2012.6338684	computer vision;geography;data mining;database	Robotics	-15.057827306934511	-35.415623102234235	38691
2904a9b802b50bfcec25f84bcfc9e6212c135001	clustering daily patterns of human activities in the city	human activity;eigen decomposition;daily activity clustering;metropolitan area;statistical learning	Data mining and statistical learning techniques are powerful analysis tools yet to be incorporated in the domain of urban studies and transportation research. In this work, we analyze an activity-based travel survey conducted in the Chicago metropolitan area over a demographic representative sample of its population. Detailed data on activities by time of day were collected from more than 30,000 individuals (and 10,552 households) who participated in a 1-day or 2-day survey implemented from January 2007 to February 2008. We examine this large-scale data in order to explore three critical issues: (1) the inherent daily activity structure of individuals in a metropolitan area, (2) the variation of individual daily activities—how they grow and fade over time, and (3) clusters of individual behaviors and the revelation of their related socio-demographic information. We find that the population can be clustered into 8 and 7 representative groups according to their activities during weekdays and weekends, respectively. Our results enrich the traditional divisions consisting of only three groups (workers, students and non-workers) and provide clusters based on activities of different time of day. The generated clusters combined with social demographic information provide a new perspective for urban and transportation planning as well as for emergency response and spreading dynamics, by addressing when, where, and how individuals interact with places in metropolitan areas.	activity recognition;algorithm;algorithmic efficiency;antivirus software;cluster analysis;computation;computer cluster;data mining;eigen (c++ library);geographic information system;k-means clustering;machine learning;mobile phone;network congestion;population;schedule (computer science);simulation;telecommuting;wireless access point;word lists by frequency	Shan Jiang;Joseph Ferreira;Marta C. González	2012	Data Mining and Knowledge Discovery	10.1007/s10618-012-0264-z	simulation	HCI	-19.18771228296799	-34.219379525356565	38712
c0696cc5ce3f3dce6fbbbc835e354064bb0777b4	preface to the special section on human factors and automation in vehicles: designing highly automated vehicles with the driver in mind	highway and vehicle design;pedestrian safety;poison control;injury prevention;safety literature;traffic safety;system design features;injury control;home safety;injury research;safety abstracts;human factors;occupational safety;safety;safety research;accident prevention;violence prevention;bicycle safety;driver behavior;poisoning prevention;falls;ergonomics;suicide prevention;aerospace systems;surface transportation systems	OBJECTIVE This special section brings together diverse research regarding driver interaction with advanced automotive technology to guide design of increasingly automated vehicles.   BACKGROUND Rapidly evolving vehicle automation will likely change cars and trucks more in the next 5 years than the preceding 50, radically redefining what it means to drive.   METHOD This special section includes 10 articles from European and North American researchers reporting simulator and naturalistic driving studies.   RESULTS Little research has considered the consequences of fully automated driving, with most focusing on lane-keeping and speed control systems individually. The studies reveal two underlying design philosophies: automate driving versus support driving. Results of several studies, consistent with previous research in other domains, suggest that the automate philosophy can delay driver responses to incidents in which the driver has to intervene and take control from the automation. Understanding how to orchestrate the transfer or sharing of control between the system and the driver, particularly in critical incidents, emerges as a central challenge.   CONCLUSION Designers should not assume that automation can substitute seamlessly for a human driver, nor can they assume that the driver can safely accommodate the limitations of automation. Designers, policy makers, and researchers must give careful consideration to what role the person should have in highly automated vehicles and how to support the driver if the driver is to be responsible for vehicle control. As in other domains, driving safety increasingly depends on the combined performance of the human and automation, and successful designs will depend on recognizing and supporting the new roles of the driver.	automation;automotive occupations;autonomous car;control system;definition;device driver;drug vehicle;human factors and ergonomics;objective-c;philosophy;simulation;simulators	Natasha Merat;John D. Lee	2012	Human factors	10.1177/0018720812461374	simulation;medicine;environmental health;advanced driver assistance systems;engineering;suicide prevention;human factors and ergonomics;injury prevention;transport engineering;forensic engineering;mechanical engineering	HCI	-19.499211979999966	-25.23289966579296	38788
25b39c0a071bfc739ee447575124b4537b084377	cookie synchronization: everything you always wanted to know but were afraid to ask		User data is the primary input of digital advertising, the fuel of free Internet as we know it. As a result, web entities invest a lot in elaborate tracking mechanisms to acquire more and more user data that can sell to data markets and advertisers. The primary identification mechanism of web is through cookies, where each entity assigns a userID on the user’s side. However, each tracker knows the same user with a different ID. So how can the collected data be sold and merged with the associated user data of the buyer? To address this, Cookie Synchronization (CSync) came to the rescue. CSync facilitates an information sharing channel between third parties that may or may not have direct access to the website the user visits. With CSync, they merge the user data they own in the background, but also reconstruct the browsing history of a user bypassing the same origin policy. In this paper, we perform a first to our knowledge in-depth study of CSync in the wild, using a year-long dataset that includes web browsing activity from 850 real mobile users. Through our study, we aim to understand the characteristics of the CSync protocol and the impact it has to the users privacy. Our results show that 97% of the regular web users are exposed to CSync: most of them within the first week of their browsing. In addition, the average user receives ∼1 synchronization per 68 GET requests, and the median userID gets leaked, on average, to 3.5 different online entities. In addition, we see that CSync increases the number of entities that track the user by a factor of 6.7. Finally, we propose a novel, machine learning-based method for CSync detection, which can be effective when the synced IDs are obscured.	entity;http cookie;internet;machine learning;random access;same-origin policy;user identifier	Panagiotis Papadopoulos;Nicolas Kourtellis;Evangelos P. Markatos	2018	CoRR		the internet;computer science;world wide web;synchronization;ask price;information sharing;same-origin policy;obfuscation;user identifier;communication channel	Web+IR	-26.731175476359052	-45.197586766827484	38815
7d403ef5facf942c364cd6936bbaaf76e6360899	built environment and driving outcomes: the case for an integrated gis/gps approach	pedestrian safety;poison control;injury prevention;safety literature;traffic safety;injury control;home safety;injury research;safety abstracts;human factors;occupational safety;safety;safety research;accident prevention;violence prevention;bicycle safety;poisoning prevention;falls;ergonomics;suicide prevention	This study demonstrates a segment-based approach to integrate GIS and GPS data to address questions about the connections between the built environment and travel behaviors. Methods and challenges of GPS/ GIS integration are discussed, and an application integrating GPS naturalistic driving data from Southeast Michigan together with GIS data from several sources is demonstrated. The integrated dataset is used to explore connections between the built environment and driving behavior, specifically between business concentration, driving speed, vehicle stops and rear-end crashes. Driving speed, an important determinant of driver behavior linked to traffic safety, is found to be inversely related to business concentration, a pattern that does not vary by time of day. Rear-end crashes are found to increase with vehicle stops which increase with business concentration. This demonstration showed that fusing GPS and GPS data provides spatial intelligence which can be used to address planning, traffic safety, and transportation related issues. Built Environment and Driving Outcomes: The Case for an Integrated GIS/GPS Approach	crash (computing);geographic information system;global positioning system	Xiaoguang Wang;Lidia P. Kostyniuk;Michelle Barnes	2014	IJAGR	10.4018/ijagr.2014040102	engineering;suicide prevention;human factors and ergonomics;injury prevention;transport engineering;forensic engineering;computer security	ML	-18.340605011045113	-26.969698349215722	39096
d53651e04cbc5d5fe6e734aee7aac31694e60634	pairwise preferences and recommender systems	ratings;pairwise preferences;recommender systems	Most of the present research and application of Recommender Systems is based on the usage of preferences derived from absolute evaluations, such as user ratings or clicks. However, this type of preferences has few disadvantages, e.g., if most of the user rated items are 5 stars, then it is difficult to understand which item the user prefers among them. In this research work, we focus on pairwise preferences as an alternative way for modeling user preferences and compute recommendations. In our scenario, users provide pair scores for a set of item pairs, indicating which item, and to what extent, is preferred. In this Ph.D research, we aim at developing intelligent user interfaces that optimally combine ratings with pairwise preferences. Furthermore, we aim at identifying specific conditions/situations where pairwise preferences elicitation is meaningful and beneficial.	intelligent user interface;p3p;recommender system;requirements elicitation;user (computing)	Saikishore Kalloori	2017		10.1145/3030024.3038278	pairwise comparison;computer science;machine learning;data mining;world wide web;recommender system	Web+IR	-21.632990318992352	-47.540118157780626	39149
1b3c96ff6dcef3471c59a44b7fdf5dbfdef097bd	client- and server-side revisitation prediction with supra	web pages;collaborative application;real time;contextual information;machine learning;web behavior;revisitation prediction;contextual support	Users of collaborative applications as well as individual users in their private environment return to previously visited Web pages for various reasons; apart from pages visited due to backtracking, they typically have a number of favorite or important pages that they monitor or tasks that reoccur on an infrequent basis. In this paper, we introduce a library of methods that facilitate revisitation through the effective prediction of the next page request. It is based on a generic framework that inherently incorporates contextual information, handling uniformly both server- and the client-side applications. Unlike other existing approaches, the methods it encompasses are real-time, since they do not rely on training data or machine learning algorithms. We evaluate them over two large, real-world datasets, with the outcomes suggesting a significant improvement over methods typically used in this context. We have also made our implementation and data publicly available, thus encouraging other researchers to use it as a benchmark and to extend it with new techniques for supporting user's navigational activity.	algorithm;backtracking;benchmark (computing);client (computing);client-side;intelligent user interface;long tail;machine learning;real-time clock;real-time computing;real-time locating system;server-side;software propagation;sourceforge;supra, inc.;web page	George Papadakis;Ricardo Kawase;Eelco Herder	2012		10.1145/2254129.2254149	computer science;data science;data mining;world wide web	Web+IR	-23.917652070361754	-40.174641383453675	39171
a9e35b386935e1b6a23dd6d7702fbf72a6225683	detection of drowsy driving based on driving information	accident prevention;driver information systems;road accidents;road traffic;driving information;drowsy driving;lane-related information;steering-related information;traffic accident;vehicle simulator;drowsy driving;steering wheel;vehicle simulator;vehicle's behavior	A drowsy driving can bring severe traffic accidents. To prevent these accidents and give a warning to a driver, we analyzed the driving information collected from a vehicle simulator and made a model to detect drowsy driving based on vehicle's behavior such as steering-related and lane-related information. It will be able to provide more effective service for drivers when applied to a vehicle augmented reality system.	augmented reality;simulation	Jeong-Woo Lee;Shin-Kyung Lee;Cheol-Hong Kim;Kyong-Ho Kim;Oh-Cheon Kwon	2014	2014 International Conference on Information and Communication Technology Convergence (ICTC)	10.1109/ICTC.2014.6983224	computer science	Robotics	-19.23956200499417	-27.309493028696973	39287
d7352c8322e310acbefc415825c06a53e03e28f4	dynamic feature generation and selection on heterogeneous graph for music recommendation	libraries;collaboration;heuristic algorithms;feature extraction;music;recommender systems;algorithm design and analysis	In the past decade, online music streaming services (MSS), e.g., Pandora and Spotify, revolutionized the way people access, consume and share music. MSS serve users with a huge digital music library, various kinds of music discovery channels, and a number of tools for music sharing and management (e.g. bookmark, playlist, comment, etc.). As a result, metadata and user-generated data hosted on MSS demonstrate great heterogeneity, which provides important potential to enhance music recommendation performance. In this study, we propose a novel music recommendation approach by leveraging heterogeneous graph schema mining and ranking feature selection. Unlike existing heterogeneous graph-based recommendation techniques, the new method can automatically generate and select the optimized meta-path-based features for the learning to rank model. To make feature selection more efficient, we propose the Dynamic Feature Generation Tree algorithm (DFGT), which can activate and eliminate the short sub-meta-paths for feature evolution at a low cost. Experiments show that the proposed algorithm can efficiently generate optimized ranking feature set for meta-path-based music recommendation, which significantly enhances the state-of-the-art collaborative filtering algorithms.	algorithm;collaborative filtering;computation;experiment;feature selection;file sharing;information retrieval;learning to rank;list of algorithms;online music store;personalization;streaming media;structure mining;time complexity;user-generated content	Chun Guo;Xiaozhong Liu	2016	2016 IEEE International Conference on Big Data (Big Data)	10.1109/BigData.2016.7840658	computer science;data mining;multimedia;world wide web	DB	-21.442043126523014	-48.764423741847025	39319
15fb558616b2c5d3a08aa9f96028b85637333168	artemis: assessing the similarity of event-interval sequences	computer science and information systems;distance measure;event interval sequence;hungarian algorithm;dynamic time warping	In several application domains, such as sign language, medicine, and sensor networks, events are not necessarily instantaneous but they can have a time duration. Sequences of interval-based events may contain useful domain knowledge; thus, searching, indexing, and mining such sequences is crucial. We introduce two distance measures for comparing sequences of interval-based events which can be also used for several data mining tasks such as classification and clustering. The first measure maps each sequence to a set of vectors that hold information about all concurrent events. These sets are then compared using an existing dynamic programming method. The second method attempts to find correspondence between intervals by mapping the two sequences into a bipartite graph. Similarity is inferred by employing the Hungarian algorithm. The performance of the proposed measures is tested on data from three domains: sign language, medicine, and sensor networks. In addition, we present a linear-time lower-bound for the second measure. Experiments show that our measures are robust in terms of retrieval accuracy even for high levels of artificially introduced noise.	cluster analysis;data mining;dynamic programming;experiment;hungarian algorithm;image noise;map;time complexity	Orestis Kostakis;Panagiotis Papapetrou;Jaakko Hollmén	2011		10.1007/978-3-642-23783-6_15	computer science;machine learning;dynamic time warping;hungarian algorithm;data mining;mathematics;algorithm	AI	-8.89944860573071	-36.61479702644655	39337
22dc72c8c7cbca42476218986a22da235ccbb011	research of distributed algorithm based on usage mining	electronic commerce;log files;web pages;web usage mining data mining distributed algorithm;web server log file distributed algorithm usage mining web mining electronic commerce web site application data mining;data mining;artificial intelligent;web site design;internet;internet data mining;web usage mining;web mining;distributed algorithm;distributed algorithms data mining web mining artificial intelligence web page design algorithm design and analysis electronic commerce web server web pages web design	Web mining applies the data mining, the artificial intelligence and the chart technology and so on to the web data and traces users' visiting characteristics, and then extracts the users’ using pattern. This article will study on Web Mining Algorithm based on Usage Mining. And it also produces the design mentality of the electronic commerce website application algorithm. Web usage mining is an application of data mining technology to mining the data of the web server log file. It can discover the browsing patterns of user and some kind of correlations between the web pages. Web usage mining provides the support for the web site design, providing personalization server and other business making decision, etc. This algorithm is simple, effective and easy to realize, it is suitable to the web usage mining demand of construct a low cost B2C website.	artificial intelligence;data mining;distributed algorithm;e-commerce;personalization;server (computing);server log;tracing (software);usability;web design;web mining;web page;web server	Qingtian Han;Xiaoyan Gao	2009	2009 Second International Workshop on Knowledge Discovery and Data Mining	10.1109/WKDD.2009.95	web service;web application security;web mining;static web page;web development;web modeling;the internet;data web;web analytics;web mapping;web design;web standards;computer science;web api;web navigation;web log analysis software;web page;data mining;database;web intelligence;web 2.0;world wide web;web server	ML	-29.604004667093438	-51.96705667825471	39375
3e59a900cecbe5dddaddea51f97fb7d12d99b44b	affordance learning and inference based on vision-speech association in human-robot interactions		Human-robot interactions is important for a robot to learn the environment and finish tasks. However, humans are difficult to teach a robot all the required information so the robot needs to infer some new knowledge based on that has been learned. Humans and other animals understand the world based on affordances which have been introduced into robotics to promote a robot's cognitive capabilities in planning, recognition and control. An affordance, which is jointly determined by the object and robot, encodes a potential action that the robot might execute upon the object. Most existing works make a robot build its affordance knowledge in only one dimension such as vision. In order to guide a robot to develop its intelligence like humans as much as possible, we propose an affordance-based interaction model that learns affordances based on vision-speech association. Our model has the following features: (i) use speech to abstractly represent behavioral and visual information in a high level without considering the detail; (ii) reduce the number of parameters in human-robot communications; (iii) infer the unknown information through table association; (iv) promote affordance learning from one dimension to double dimensions. The experiment is carried out on a NAO humanoid robot, and it is proved that our method supports affordance learning and inference correctly and effectively.	high-level programming language;humanoid robot;humans;interaction;nao (robot);robotics;social affordance	Chang'an Yi;Huaqing Min;Jin-Hui Zhu;Xinshi Xu;Pengshuai Yin;Guofei Zheng	2017	2017 IEEE International Conference on Robotics and Biomimetics (ROBIO)	10.1109/ROBIO.2017.8324506	task analysis;humanoid robot;control engineering;interaction model;affordance;robot;engineering;machine learning;inference;robotics;artificial intelligence;human–robot interaction	Robotics	-33.007273833992556	-40.290313560773065	39377
f44f5ee766347cc1de05d0b15dc137a8d7bb4d97	visual mining business service using pixel bar charts	visualizacion;analisis datos;mining;web service;data mining;carta de datos;data distribution;data analysis;visualization;management data processing;visualisation;visualization technique;fouille donnee;mappage;hewlett packard;informatique gestion;analyse donnee;service level agreement;mapping;busca dato;informatica gestion	Basic bar charts have been commonly available, but they only show highly aggregated data. Finding the valuable information hidden in the data is essential to the success of business. We describe a new visualization technique called pixel bar charts, which are derived from regular bar charts. The basic idea of a pixel bar chart is to present all data values directly instead of aggregating them into a few data values. Pixel bar charts provide data distribution and exceptions besides aggregated data. The approach is to represent each data item (e.g. a business transaction) by a single pixel in the bar chart. The attribute of each data item is encoded into the pixel color and can be accessed and drilled down to the detail information as needed. Different color mappings are used to represent multiple attributes. This technique has been prototyped in three business service applications – Business Operation Analysis, Sales Analysis, and Service Level Agreement Analysis at Hewlett Packard Laboratories. Our applications show the wide applicability and usefulness of this new idea.	chart;daniel a. keim;data drilling;data item;diagram;experiment;pixel;service-level agreement	Ming C. Hao;Umeshwar Dayal;Fabio Casati	2004		10.1117/12.526933	engineering;data mining;database;world wide web	ML	-27.755566458147737	-29.527863356496137	39391
18550a02a78741eec4047c87e6a503e662c46947	coherent closed quasi-clique discovery from large dense graph databases	optimization technique;search space;internal structure;graph mining;quasi clique;coherent subgraph	Frequent coherent subgraphs can provide valuable knowledge about the underlying internal structure of a graph database, and mining frequently occurring coherent subgraphs from large dense graph databases has been witnessed several applications and received considerable attention in the graph mining community recently. In this paper, we study how to efficiently mine the complete set of coherent closed quasi-cliques from large dense graph databases, which is an especially challenging task due to the downward-closure property no longer holds. By fully exploring some properties of quasi-cliques, we propose several novel optimization techniques, which can prune the unpromising and redundant sub-search spaces effectively. Meanwhile, we devise an efficient closure checking scheme to facilitate the discovery of only closed quasi-cliques. We also develop a coherent closed quasi-clique mining algorithm, <B>Cocain</B>1 Thorough performance study shows that Cocain is very efficient and scalable for large dense graph databases.	algorithm;alpha–beta pruning;coherent;dhrystone;goto;graph database;induced subgraph;jasmine;k-vertex-connected graph;kegg;mathematical optimization;microarray databases;nice (unix);ocean observatories initiative;panos;scalability;structure mining	Zhiping Zeng;Jianyong Wang;Lizhu Zhou;George Karypis	2006		10.1145/1150402.1150506	combinatorics;discrete mathematics;searching the conformational space for docking;theoretical computer science;mathematics;graph;graph database	ML	-9.78864680363194	-40.15166399885716	39408
0206037ae7ce2d471428be61dab1ac68c008f917	data interpolation for participatory sensing systems	gibbs sampler;mrf;kriging;ica;pca	In this paper, we study the problem of applying data interpolation techniques in Participatory Sensing (PS) systems using an air quality/pollution monitoring application as an example. While traditional environmental monitoring systems consist of very few static measuring stations, PS systems rely on the participation of many mobile stations. As a result, the structure of the data provided by each system is different and instead of a multivariate time series with a few gaps in the same space, now we have a multivariate time-space series with many gaps in time and space. First, two data interpolation techniques, Markov Random Fields and kriging, are analyzed. After showing the trade-offs and superiority of kriging, this technique is used to perform a one-variable data interpolation. Then, the problems of cokriging for multivariate interpolation are introduced and Principal Component Analysis and Independent Component Analysis are utilized along with kriging to overcome these problems. Finally, an alternative approach to interpolate data in time and space is proposed, which is really useful for PS systems. The results indicate that the accuracy of the estimates improveswith the amount of data, i.e., one variable,multiple variables, and space and time data. Also, the results clearly show the advantage of a PS system compared with a traditional measuring system in terms of the precision and granularity of the information provided to the users. © 2012 Elsevier B.V. All rights reserved.	independent computing architecture;independent component analysis;kriging;markov chain;markov random field;mobile phone;multivariate interpolation;participatory sensing;point of view (computer hardware company);principal component analysis;scalability;time series;utility	Diego Mendez;Miguel A. Labrador;K. Ramachandran	2013	Pervasive and Mobile Computing	10.1016/j.pmcj.2012.11.001	materials recovery facility;gibbs sampling;computer science;data mining;multivariate interpolation;kriging;statistics;principal component analysis	AI	-13.709111654754746	-32.89522354349523	39442
9f592287d480f121b41f6b45580000a87d0e9508	an efficient algorithm for calculating drainage accumulation in digital elevation models based on the basin tree index	algorithm design and analysis time complexity buildings digital elevation models computational modeling sorting indexes;watershed basin drainage accumulation geographic information system gis hydrology	Calculating drainage accumulation in a digital elevation model (DEM) is a common requirement for hydrology and terrain analysis. This letter presents a basin tree index (BTI) algorithm to improve the efficiency of this calculation, achieving the time complexity of  $O(N)$ and the input–output efficiency of  $O(\hbox{Scan}(N))$. We have developed a BTI to guide the calculation sequence, allowing us to avoid invalid and repeat manipulation and to reduce random scattered data access. The BTI provides a one-to-one correspondence between a basin and an outlet, and it maintains cells orderly in terms of both the elevation and the spatial distribution, as it is built by tracing the drainage path from the outlet to the source directly. This is achieved according to the drainage direction for each basin extracted from the DEM, where basins are divided based on watersheds. Therefore, the drainage accumulation can be calculated by traversing the BTIs from their leaves to roots linearly and simultaneously. These BTIs divide the entire study area into several basins that can be processed in isolation, reducing the search scope for basins and allowing the algorithm to efficiently utilize the main memory and decrease the data swapping between the main memory and the disk. A DEM for the Zhejiang Province in China was used to validate the results and compare the processing speeds. The results show that the algorithm provides the same calculation result as alternative algorithms but becomes more efficient as the volume of the DEM data increases. Furthermore, the BTI algorithm in this letter is easy to implement.	algorithm;btrieve;computer data storage;data access;digital elevation model;one-to-one (data model);paging;time complexity;tree accumulation	Cheng Su;Wei-Bin Yu;Cun-Jun Feng;Chun-Na Yu;Zhi-cai Huang;Xiao-Can Zhang	2015	IEEE Geoscience and Remote Sensing Letters	10.1109/LGRS.2014.2345561	geomorphology;hydrology;physics	DB	-10.439604880233285	-35.981199620294475	39446
5b637ed4a4c3b5f58fbbb776691072d2b57fe1c3	two-probabilities focused combination in recommender systems	uncertain reasoning;collaborative filtering;dempster shafer theory;information fusion;recommender systems	In this paper, we propose a new method called 2-probabilities focused combination for combining information about user preferences on products or services in recommender systems based on Dempster–Shafer theory. Regarding this method, in focal sets of mass functions representing user preferences, focal elements with probabilities in top two highest ones are retained and the remaining focal elements are considered as noise and then transferred to the whole set element. To demonstrate the advantages of the new method, a baseline known as 2-points focused combination is selected for performance comparison in a range of experiments using Movielens and Flixster data sets. According to the results of experiments, the new method is more effective in accuracy of recommendations and comparable in computational time. Also, the new method is capable of overcoming the weakness of the baseline because of the ability to generate stable results.		Van-Doan Nguyen;Van-Nam Huynh	2017	Int. J. Approx. Reasoning	10.1016/j.ijar.2016.09.005	dempster–shafer theory;computer science;artificial intelligence;collaborative filtering;machine learning;data mining;information retrieval;statistics;recommender system	AI	-21.238140633726104	-48.1654849513659	39457
cec0be17eaa62d9c4428bb43390b6048f893edec	a modified maintenance algorithm for updating fusp tree in dynamic database	dynamic database;pre large concept;data mining;sequence modification;fusp tree	In the past, we proposed a pre-large FUSP tree to preserve and maintain both large and pre-large sequences in the built tree structure. In this paper, the pre-large concept is also adopted for maintaining and updating the FUSP tree. Only large sequences are kept in the built tree structure for reducing computations. The PreFUSP-TREE-MOD maintenance algorithm is proposed to reduce the rescans of the original database due to the pruning properties of pre-large concept. When the number of modified sequences is smaller than the safety bound of the pre-large concept, better results can be obtained by the proposed PreFUSP-TREE-MOD maintenance algorithm for sequence modification in the dynamic database.	algorithm	Ci-Rong Li;Chun-Wei Lin;Wensheng Gan;Tzung-Pei Hong	2014		10.1007/978-3-319-07455-9_32	computer science;data mining;database;algorithm	DB	-5.919919615975176	-37.338083250642356	39477
1baa087c1285df7463bf44438f8f5c26ee479253	cartogram visualization for bivariate geo-statistical data		We describe bivariate cartograms, a technique specifically designed to allow for the simultaneous comparison of two geo-statistical variables. Traditional cartograms are designed to show only a single statistical variable, but in practice, it is often useful to show two variables (e.g., the total sales for two competing companies) simultaneously. We illustrate bivariate cartograms using Dorling-style cartograms, yet the technique is simple and generalizable to other cartogram types, such as contiguous cartograms, rectangular cartograms, and non-contiguous cartograms. An interactive feature makes it possible to switch between bivariate cartograms, and the traditional (monovariate) cartograms. Bivariate cartograms make it easy to find more geographic patterns and outliers in a pre-attentive way than previous approaches, as shown in Fig. 2 . They are most effective for showing two variables from the same domain (e.g., population in two different years, sales for two different companies), although they can also be used for variables from different domains (e.g., population and income). We also describe a small-scale evaluation of the proposed techniques that indicates bivariate cartograms are especially effective for finding geo-statistical patterns, trends and outliers.	bivariate normal distribution;bivariate data;correlation study;imagery	Sabrina Nusrat;Muhammad Jawaherul Alam;Carlos Eduardo Scheidegger;Stephen G. Kobourov	2018	IEEE Transactions on Visualization and Computer Graphics	10.1109/TVCG.2017.2765330	market research;data visualization;theoretical computer science;data mining;bivariate analysis;outlier;visualization;population;computer science;cartogram	Visualization	-26.147257273917138	-32.9636047623977	39488
3f6e127ef59a4a352f4d06d1bb7ed646942f7ebd	sioc in action representing the dynamics of online communities	streams;linked data;activity;social web;semantic web technology;action;online community;semantic web;sioc;web technology;traces	SIOC --- Semantically-Interlinked Online Communities --- provides the Semantic Web with a vocabulary for representing activities and contributions of online communities. However, it focuses on the state of online communities at a given time, while a number of Web application put a strong emphasis on the dynamics of their components and users, including microblogging, status and geolocation notification, etc. and as also testified by recent efforts on modelling activity streams. This work proposes a new module for the SIOC vocabulary designed to represent the dynamics of actions within online communities. Hence, we provide an action-centric view of online communities, while previous work focused on a document-centric or user-centric one. Furthermore, we align our work with related vocabularies and Web technologies --- both in use and emerging --- inside and outside the field of Semantic Web technologies.	align (company);geolocation;online community;semantic web;semantically-interlinked online communities;vocabulary;web application	Pierre-Antoine Champin;Alexandre Passant	2010		10.1145/1839707.1839722	web modeling;data web;web standards;computer science;semantic web;social semantic web;data mining;semantic web stack;multimedia;world wide web;online participation	Web+IR	-26.736972907949344	-48.02725511169971	39494
d0c0cf9de10f4959595709a242d0b2d2a21c6a0f	analyses of social webhouse integrating sna metrics		Web 2.0 technologies have brought new ways of connecting people in social networks for collaboration and communication in various on-line communities. Social network analysis (SNA) is used to model social relationships as nodes (individuals, organizations: actors) and edges (relationships between these nodes). This analysis is based on a structural approach in order to describe relations between Facebook members (communication, collaboration, cohesion, centrality of members, etc.) using a set of SNA metrics. Decisional systems such as Data WeBHouse (DWB), known by their data-consuming, must be enriched by this kind of metrics to give better help to decision makers. So, several steps of the DWB life cycle must be revised to integrate this social data. In this paper, we propose a modeling approach for Social Data WeBHouse (SDWB) based on social data. Our multidimensional schema integrates SNA metrics applied on graphs of Facebook pages and groups. We have implemented two techniques to analyze our SDWB which are the Online Analytical Process (OLAP) analysis and the contextualized association rules. The result of these analyses helps decision makers to identify the most collaborative members in groups and pages. Our approach is validated by an SDWB prototype.	association rule learning;centrality;cohesion (computer science);data mining;decision tree;diagram;online analytical processing;online and offline;prototype;second source;social network analysis;software requirements specification;web 2.0	Marwa Masmoudi;Faïza Ghozzi	2016	2016 IEEE/ACS 13th International Conference of Computer Systems and Applications (AICCSA)	10.1109/AICCSA.2016.7945814	online analytical processing;structural approach;social network analysis;computer science;data mining;centrality;association rule learning;schema (psychology);social network;graph	DB	-20.726143667701574	-39.24252089535944	39507
45c022676abb99a0f6e2560d8d5f601353075fb7	on the method for data streams aggregation to predict shoppers loyalty	training;business informatics bigdata data streams data aggregation classification and regression shopping loyalty churn marketing;retail data processing big data consumer behaviour internet learning artificial intelligence pattern classification regression analysis;companies;companies lead training repeaters;lead;repeaters;postal mail data stream aggregation shopper loyalty prediction big data data matrix regression machine learning models marketing material email	While dealing with Big Data and with data streams in particular, it is a common practice to summarize or aggregate customers' transaction history to the periods of few months. Consequently, we shall compress the given huge volume of data, and shall transfer the data stream to the standard rectangular format, where columns represent secondary aggregated features and rows represent customers. This data-matrix is suitable as an input to many classification or regression machine learning models. Using those models, we can explore a variety of practically or theoretically motivated tasks. For example, we can rank the given field of customers in accordance to their loyalty or intension to repurchase in the near future. This objective has very important practical application. It leads to preferential treatment of the right customers. It also reduces the likelihood of bombarding customers, who are less likely to purchase, with marketing material over email or postal mail. We tested our model (with competitive results) online during Kaggle-based Acquire Valued Shoppers Challenge in 2014.	aggregate data;big data;column (database);email;intension;machine learning;postal	Vladimir Nikulin	2015	2015 International Joint Conference on Neural Networks (IJCNN)	10.1109/IJCNN.2015.7280493	lead;data mining;repeater	ML	-8.229896946678279	-30.456661476605674	39519
0988d07cf5dcadeb1e97228ee5f74bdd173cce54	visual maps for data-intensive ecosystems		Data-intensive ecosystems are conglomerations of one or more databases along with software applications that are built on top of them. This paper proposes a set of methods for providing visual maps of data-intensive ecosystems. We model the ecosystem as a graph, with modules (tables and queries embedded in the applications) as nodes and data provision relationships as edges. We cluster the modules of the ecosystem in order to further highlight their interdependencies and reduce visual clutter. We employ three alternative, novel, circular graph drawing methods for creating a visual map of the graph.	clutter;data-intensive computing;database;ecosystem;embedded system;graph (discrete mathematics);graph drawing;interdependence;map;table (database)	Efthymia Kontogiannopoulou;Petros Manousis;Panos Vassiliadis	2014		10.1007/978-3-319-12206-9_32	cycle graph;computer science;data mining;visualization;software;ecosystem;graph	DB	-28.86809794370277	-34.62890698018481	39583
4a618ba8c6b7262c4127f3e4a262d66b7fd9d847	adjustable autonomy for uav supervision applications through mental workload assessment techniques		In recent years, unmanned aerial vehicles have received a significant attention in the research community, due to their adaptability in different applications, such as surveillance, disaster response, traffic monitoring, transportation of goods, first aid, etc. Nowadays, even though UAVs can be equipped with some autonomous capabilities, they often operate in high uncertainty environments in which supervisory systems including human in the control loop are still required. Systems envisaging decision-making capabilities and equipped with flexible levels of autonomy are needed to support UAVs controllers in monitoring operations. The aim of this paper is to build an adjustable autonomy system able to assist UAVs controllers by predicting mental workload changes when the number of UAVs to be monitored highly increases. The proposed system adjusts its level of autonomy by discriminating situations in which operators’ abilities are sufficient to perform UAV supervision tasks from situations in which system suggestions or interventions may be required. Then, a user study was performed to create a mental-workload prediction model based on operators’ cognitive demand in drone monitoring operations. The model is exploited to train the system developed to infer the appropriate level of autonomy accordingly. The study provided precious indications to be possibly exploited for guiding next developments of the adjustable autonomy system proposed.	autonomy;unmanned aerial vehicle	Federica Bazzano;Angelo Grimaldi;Fabrizio Lamberti;Gianluca Paravati;Marco Gaspardone	2017		10.1007/978-3-319-72038-8_4	artificial intelligence;workload;simulation;machine learning;computer science;operator (computer programming);adaptability;control system;cognition;psychological intervention;supervisory control;autonomy	HCI	-22.781961696558405	-27.01592569975882	39608
059aef94c84db2e73e680285632c8c699d6bcc25	towards contextual goal-oriented perception for pedestrian simulation		Perception is often seen in multiagent systems and in robotics from a passive point of view. The sensors of the agent collect information on its environment; however the potentially important number of percepts is not realistic and may decrease the agents efficiency. In this article, we introduce a contextual goal-oriented perception filtering. Besides the lack of plausibility of omniscient agents, it addresses the problem of transmitting too much information to the agents. This goal-oriented perception module is evaluated model in terms of validity of the resulting behavior and of time complexity.	agent-based model;cognition;multi-agent system;plausibility structure;point of view (computer hardware company);refinement (computing);robotics;sensor;simulation;time complexity;transmitter;visual artifact	Laure Bourgois;Julien Saunier;Jean-Michel Auberlet	2012			human–computer interaction;artificial intelligence;machine learning;computer science;perception;goal orientation;pedestrian	AI	-31.9978560772278	-40.543394473007204	39636
f613fed42cef7dde68394f4a3a42d5c791105d85	road-geometry-based risk estimation model for horizontal curves	geometric design;crash risk forecasting;sensors;slopes;highway curves;data collection;geometry;advanced driver assistant system road geometry based risk estimation model horizontal curves rural roads curved roads road geometry components curve structure road slope type uphill downhill road curvature curve direction vehicle speed road image capture two view approach bend slope type single view front camera geometrical derivations salient visual clues reverse view technique risk components;county roads;makale bilimsel dergi makalesi cok yazarli;accident risk bend road curve road curvature road features road geometry two view camera;estimation;accidents;roads;road vehicles cameras driver information systems image capture risk management;algorithms;image analysis;vehicles;roads vehicles cameras estimation geometry accidents sensors;cameras;firat universitesi kutuphanesi teknoloji	Rural roads present potential risks for drivers. One of them is horizontal curve, which poses higher risk than freeway. This is the major theme for the presented work here aiming to develop a model that predicts risk of curved roads. Major road geometry components associated with curve structure are road slope type being uphill or downhill, road curvature, and curve direction along with vehicle speed as being a critical factor. In this study, cameras mounted in rear and front ends of a vehicle that capture road images are utilized to detect the components emerging risk. This two-view approach is exploited to obtain vehicle speed and bend slope type, whereas curve direction and road curvature are determined by single-view front camera. The proposed approach is leveraged by geometrical derivations using salient visual clues such as vanishing points and road boundary. Additionally, velocity is estimated by reverse-view technique, that is, plane of front view at instance t and the plane of rear view in t+1. Subsequently, overall potential hazard is predicted by assigning weights for each risk components via developed risk estimation model. The proposed model would be an integral part of an advanced driver assistant system by alerting driver about the prominent risk of horizontal curve ahead of time.	architecture design and assessment system;autonomous car;floor and ceiling functions;freeway;steering wheel;velocity (software development)	Ozgur Karaduman;Haluk Eren;Hasan Kurum;Mehmet Celenk	2016	IEEE Transactions on Intelligent Transportation Systems	10.1109/TITS.2015.2506609	computer vision;estimation;image analysis;simulation;geometric design;sensor;mathematics;forensic engineering;slope;statistics;data collection	Robotics	-17.351381151174394	-27.14025171760557	39644
19e74fc587b5460af7bbb4c549c8bce78019abe8	feature-based similarity search in graph structures	graph database;index;complexity;search performance;query graph;effective feature set;effective feature set selection;optimal feature set selection;feature-based similarity search;graph structure;approximate nonconsecutive sequence;substructure similarity search;pairwise similarity computation;graph databases;similarity search	Similarity search of complex structures is an important operation in graph-related applications since exact matching is often too restrictive. In this article, we investigate the issues of substructure similarity search using indexed features in graph databases. By transforming the edge relaxation ratio of a query graph into the maximum allowed feature misses, our structural filtering algorithm can filter graphs without performing pairwise similarity computation. It is further shown that using either too few or too many features can result in poor filtering performance. Thus the challenge is to design an effective feature set selection strategy that could maximize the filtering capability. We prove that the complexity of optimal feature set selection is Ω(2m) in the worst case, where m is the number of features for selection. In practice, we identify several criteria to build effective feature sets for filtering, and demonstrate that combining features with similar size and selectivity can improve the filtering and search performance significantly within a multifilter composition framework. The proposed feature-based filtering concept can be generalized and applied to searching approximate nonconsecutive sequences, trees, and other structured data as well.	similarity search	Xifeng Yan;Feida Zhu;Philip S. Yu;Jiawei Han	2006	ACM Trans. Database Syst.	10.1145/1189777	filter;case-based reasoning;complexity;selectivity;similarity;data structure;performance;data model;computer science;similitude;machine learning;pattern recognition;data mining;generalized complex structure;database;feature;graph database	DB	-7.142776420233027	-39.85790778422152	39682
d5dc71aa641a2bb50d20edae277c7fe3ce366718	explainable reasoning over knowledge graphs for recommendation		Incorporating knowledge graph into recommender systems has attracted increasing attention in recent years. By exploring the interlinks within a knowledge graph, the connectivity between users and items can be discovered as paths, which provide rich and complementary information to user-item interactions. Such connectivity not only reveals the semantics of entities and relations, but also helps to comprehend a user’s interest. However, existing efforts have not fully explored this connectivity to infer user preferences, especially in terms of modeling the sequential dependencies within and holistic semantics of a path. In this paper, we contribute a new model named Knowledgeaware Path Recurrent Network (KPRN) to exploit knowledge graph for recommendation. KPRN can generate path representations by composing the semantics of both entities and relations. By leveraging the sequential dependencies within a path, we allow effective reasoning on paths to infer the underlying rationale of a user-item interaction. Furthermore, we design a new weighted pooling operation to discriminate the strengths of different paths in connecting a user with an item, endowing our model with a certain level of explainability. We conduct extensive experiments on two datasets about movie and music, demonstrating significant improvements over state-of-the-art solutions Collaborative Knowledge Base Embedding and Neural Factorization Machine. Introduction Prior efforts have shown the importance of incorporating auxiliary data into recommender systems, such as user profiles (Wang et al. 2018c) and item attributes (Bayer et al. 2017). Recently, knowledge graphs (KGs) have attracted increasing attention (Zhang et al. 2016; Shu et al. 2018; Wang et al. 2018a), due to its comprehensive auxiliary data: background knowledge of items and their relations amongst them. It usually organizes the facts of items in the form of triplets like (Ed Sheeran, IsSingerOf, Shape of You), which can be seamlessly integrated with user-item interactions (Chaudhari, Azaria, and Mitchell 2016; Cao et al. 2017). More important, by exploring the interlinks within ∗The first three authors have equal contribution. †Dingxian Wang is the corresponding author. Copyright c © 2019, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved. Knowledge Graph Shape of You Ed Sheeran SungBy WrittenBy ÷	artificial intelligence;artificial neural network;big data;cold start;design rationale;entity;experiment;holism;interaction;kgs go server;kasparov's gambit;knowledge graph;knowledge base;long short-term memory;mitchell corporation;neural networks;recommender system;recurrent neural network;software propagation;user (computing);user profile;wang tile;yang	Xiang Wang;Dingxian Wang;Canran Xu;Xiangnan He;Yixin Cao;Tat-Seng Chua	2018	CoRR			AI	-14.992640242088017	-46.00214952989286	39698
1c23288f65ccf4ec8d75660ffdca7fbfeb82215e	analysis of energy behaviour profiles of prosumers	renewable energy resources;energy consumption electricity australia renewable energy resources solar system time series analysis meteorology;government;tariffs;smart grid;synthetic dataset energy behaviour profiles analysis prosumers smart grid bidirectional energy energy user utility grid excess energy negative climate impacts government regulations electricity costs feed in tariff schemes energy behavior australia;energy profile;smart power grids;time series analysis;energy consumption;feed in tariff;energy profile smart grid prosumer feed in tariff;solar system;electricity;prosumer;tariffs government smart power grids;meteorology;australia	Smart Grid (SG) achieves bidirectional energy and information flow between the energy user and the utility grid, allowing energy users not only to consume energy, but also to generate the energy and share the excess energy with the utility grid or with other energy consumers. This type of energy user is called the “prosumer”. In current society, a massive number of energy-users have transformed into prosumers due to many reasons such as the strong society attitude with respect to alleviation of negative climate impacts, desires to decrease electricity costs, and various government regulations, including generous feed-in tariff schemes. This leads much attention within the research community on investigating the aspects of prosumers connected to SG. However most researchers find it challenges to find a large dataset of prosumers for performing the experiments. This leads the necessity of identifying the generic prosumers' realistic energy behaviors, and accordingly generates a synthetic dataset. In this research paper, we present prosumers' realistic energy behavior profiles during summer and winter periods in Australia and present its application in generating a synthetic dataset. The new researchers can use the identified energy profiles as a benchmark to generate a synthetic dataset for their experiments.	benchmark (computing);dhrystone;experiment;load profile;offset binary;suicidegirls;synthetic data;synthetic intelligence;time series	A. J. Dinusha Rathnayaka;Vidyasagar Potdar;Tharam S. Dillon;Omar Khadeer Hussain;Samitha Kuruppu	2012	IEEE 10th International Conference on Industrial Informatics	10.1109/INDIN.2012.6301138	simulation;economics;economy;commerce	HPC	-21.157569984277096	-37.022841587590044	39769
8b9f253c7c91a4d9b43e19ee786deaea6faff9cf	envi4all: personalised air quality information based on open environmental data and user-generated information		Air pollution open data has a huge value for citizens, especially these belonging to vulnerable groups. Information on air quality can help them to take better informed decisions that safeguard their health. Although this information is available in multiple sources, in the form that the data is provided, it is difficult for citizens to extract the information they actually need. In addition, existing monitoring stations mainly cover only large cities, and fail to take into account differences in microclimates occurring within a specific area. ENVI4ALL will be an application that addresses these challenges by providing direct access to personalised and localised information on air quality (current, forecast, and historical), making use of diverse sources of large datasets of open air quality data, and crowdsourced information on the perception of app users about the current air quality. An empirical model will be also applied for the provision of air quality forecasts.	user-generated content	Evangelos Kosmidis;Konstantinos Kourtidis;Panagiota Syropoulou	2016		10.1007/978-3-319-50237-3_8	knowledge management;data mining;information retrieval	HCI	-20.08146969752388	-32.46917973676817	39784
d32fe009fad45ebbf4841d9108d2c27596721a5d	a new online anomaly learning and detection for large-scale service of internet of thing		The online anomaly detection has been propounded as the key idea of monitoring fault of large-scale sensor nodes in Internet of Things. Now, the exciting progresses of research have been made in online anomaly detection area. However, the highly dynamic distributing character of Internet of Things makes the anomaly detection scheme difficult to be used in online manner. This paper presents a new online anomaly learning and detection mechanism for large-scale service of Internet of Thing. Firstly, our model uses the reversible-jump MCMC learning to online learn anomaly-free of dynamics network and service data. Next, we perform a structural analysis of IoT-based service topology by network utility maximization theory. The results of experiment demonstrate the method accuracy in forecasting dynamics network and service structures from synthetic data.	anomaly detection;expectation–maximization algorithm;internet of things;living lab;network utility;reversible-jump markov chain monte carlo;scalability;structural analysis;synthetic data	Junping Wang;Qiuming Kuang;Shihui Duan	2015	Personal and Ubiquitous Computing	10.1007/s00779-015-0874-8	computer science;internet privacy;world wide web;computer security	Metrics	-17.60982529872805	-37.78621797902753	39873
40c871f921badbf8de01e83c8c956f7741673eb9	leveraging network properties for trust evaluation in multi-agent systems	belief networks;value system;multi agent system;evaluation method;agent communication;agent reputation and trust collective classification homophily;agent reputation and trust;feature vector;multi agent systems;independent and identically distributed;network connectivity;social networking online;pattern classification;accuracy training robustness communities logistics correlation humans;shared beliefs trust evaluation multiagent system collective classification approach untrustworthy individual identification network connections independent and identically distributed sample iid sample relational feature set feature vector human communities shared attitudes;homophily;social networking online belief networks multi agent systems pattern classification;collective classification	In this paper, we present a collective classification approach for identifying untrustworthy individuals in multi-agent communities from a combination of observable features and network connections. Under the assumption that data are organized as independent and identically distributed (i.i.d.)samples, traditional classification is typically performed on each object independently, without considering the underlying network connecting the instances. In collective classification, a set of relational features, based on the connections between instances, is used to augment the feature vector used in classification. This approach can perform particularly well when the underlying data exhibits homophily, a propensity for similar items to be connected. We suggest that in many cases human communities exhibit homophily in trust levels since shared attitudes toward trust can facilitate the formation and maintenance of bonds, in the same way that other types of shared beliefs and value systems do. Hence, knowledge of an agent's connections provides a valuable cue that can assist in the identification of untrustworthy individuals who are misrepresenting themselves by modifying their observable information. This paper presents results that demonstrate that our proposed trust evaluation method is robust in cases where a large percentage of the individuals present misleading information.	feature vector;multi-agent system;observable;trust metric;value (ethics)	Xi Wang;Mahsa Maghami;Gita Reese Sukthankar	2011	2011 IEEE/WIC/ACM International Conferences on Web Intelligence and Intelligent Agent Technology	10.1109/WI-IAT.2011.217	independent and identically distributed random variables;feature vector;computer science;artificial intelligence;machine learning;multi-agent system;data mining;value system;world wide web	AI	-19.712305452447396	-44.5550329947791	40053
725ac4b7c53bca4404e498c31a07e724238aae93	real-time pedestrian detection approach with an efficient data communication bandwidth strategy		Vehicle-to-Pedestrian (V2P) communication can significantly improve pedestrian safety at a signalized intersection. It is unlikely that pedestrians will carry a low latency communication enabled device and activate a pedestrian safety application in their hand-held device all the time. Because of this limitation, multiple traffic cameras at the signalized intersection can be used to accurately detect and locate pedestrians using deep learning and broadcast safety alerts related to pedestrians to warn connected vehicles around a signalized intersection. However, unavailability of high-performance computing infrastructure at the roadside and limited network bandwidth between traffic cameras and the computing infrastructure limits the ability of real-time data streaming and processing for pedestrian detection. In this paper, we developed an edge computing based real-time pedestrian detection strategy combining pedestrian detection algorithm using deep learning and an efficient data communication approach to reduce bandwidth requirements while maintaining a high object detection accuracy. We utilized a lossy traffic camera data compression technique to determine the tradeoff between the reduction of the communication bandwidth requirements and a defined object detection accuracy. The performance of the pedestrian-detection strategy is measured in terms of pedestrian classification accuracy with varying peak signal-to-noise ratios. The analyses reveal that we detect pedestrians by maintaining a defined detection accuracy with a peak signal-to-noise ratio (PSNR) 43 dB while reducing the communication bandwidth from 9.82 Mbits/sec to 0.31 Mbits/sec.	algorithm;bandwidth (signal processing);data compression;deep learning;edge computing;lossy compression;megabit;mobile device;object detection;peak signal-to-noise ratio;pedestrian detection;real-time clock;real-time data;real-time transcription;requirement;supercomputer;unavailability	Mizanur Rahman;Mhafuzul Islam;Jon Calhoun;Mashrur Chowdhury	2018	CoRR		lossy compression;real-time computing;transport engineering;object detection;latency (engineering);engineering;unavailability;bandwidth (signal processing);edge computing;traffic camera;pedestrian detection	Mobile	-21.29858043293039	-28.65776017645347	40144
af1e443e89ebdfd2f31f61d1e52c86d0a5cd95f8	exploiting cross-source knowledge for warming up community question answering services		Abstract Community Question Answering (CQA) services such as Yahoo! Answers, Quora and StackOverflow are collaborative platforms where users can share and exchange their knowledge explicitly by asking and answering questions. One essential task in CQA is learning topical expertise of users, which may benefit many applications such as question routing and best answers identification. One limitation of existing related works is that they only consider the warm-start users who have posted many questions or answers, while ignoring cold-start users who have few posts. In this paper, we aim to exploit knowledge from cross sources such as GitHub and StackOverflow to build up the richer views of expertise for better CQA. Inspired by the idea of Bayesian co-training, we propose a topical expertise model from the perspective of multi-view learning. Specifically, we incorporate the consistency existing among multiple views into a unified probabilistic graphic model. Comprehensive experiments on two real-world datasets demonstrate the performance of our proposed model with the comparison of some state-of-the-art ones.		Yao Wan;Guandong Xu;Liang Chen;Zhou Zhao;Jian Wu	2018	Neurocomputing	10.1016/j.neucom.2018.08.012	data mining;probabilistic logic;artificial intelligence;machine learning;exploit;question answering;mathematics;bayesian probability	NLP	-18.06599639921076	-47.839641399501026	40162
89d7215dd9aeaedbc8b8be9094606e938fbd41c7	automated web navigation using multiagent adaptive dynamic programming	dynamic programming;web navigation;multiagent adaptive dynamic programming;automated web navigation;uncertainty;information retrieval;hyperlink chasing;user interests;navigation dynamic programming world wide web learning systems feedback information retrieval motion planning decision making uncertainty web sites;information searching;user feedback;adaptive dynamics;learning systems;online front ends;learning system;navigation;multi agent systems;feedback;internet;multiple model based learning agents automated web navigation multiagent adaptive dynamic programming hyperlink chasing learning system user interests information searching information retrieval;web sites;motion planning;multiple model;world wide web;multiple model based learning agents;dynamic programming internet online front ends multi agent systems	Today a massive amount of information available on the WWW often makes searching for information of interest a long and tedious task. Chasing hyperlinks to find relevant information may be daunting. To overcome such a problem, a learning system, cognizant of a user's interests, can be employed to automatically search for and retrieve relevant information by following appropriate hyperlinks. In this paper, we describe the design of such a learning system for automated Web navigation using adaptive dynamic programming methods. To improve the performance of the learning system, we introduce the notion of multiple model-based learning agents operating in parallel, and describe methods for combining their models. Experimental results on the WWW navigation problem are presented to indicate that combining multiple learning agents, relying on user feedback, is a promising direction to improve learning speed in automated WWW navigation.	agent-based model;dynamic programming;web navigation	J. Varghese;S. Mukhopadhyay	2003	IEEE Trans. Systems, Man, and Cybernetics, Part A	10.1109/TSMCA.2003.817043	navigation;the internet;simulation;uncertainty;computer science;artificial intelligence;machine learning;dynamic programming;web navigation;multi-agent system;feedback;motion planning;multimedia;world wide web	Robotics	-31.420138024674625	-51.60202566901	40169
5c774f774420015eafa3412f4a1ef536dad2ee76	real-time graph partition and embedding of large network		Recently, large-scale networks attract significant attention to analyze and extract the hidden information of big data. Toward this end, graph embedding is a method to embed a high dimensional graph into a much lower dimensional vector space while maximally preserving the structural information of the original network. However, effective graph embedding is particularly challenging when massive graph data are generated and processed for real-time applications. In this paper, we address this challenge and propose a new real-time and distributed graph embedding algorithm (RTDGE) that is capable of distributively embedding a large-scale graph in a streaming fashion. Specifically, our RTDGE consists of the following components: (1) a graph partition scheme that divides all edges into distinct subgraphs, where vertices are associated with edges and may belong to several subgraphs; (2) a dynamic negative sampling (DNS) method that updates the embedded vectors in real-time; and (3) an unsupervised global aggregation scheme that combines all locally embedded vectors into a global vector space. Furthermore, we also build a real-time distributed graph embedding platform based on Apache Kafka and Apache Storm. Extensive experimental results show that RTDGE outperforms existing solutions in terms of graph embedding efficiency and accuracy.	algorithm;apache kafka;apache storm;big data;embedded system;graph embedding;graph partition;heuristic;performance evaluation;real-time clock;real-time computing;sampling (signal processing)	Wenqi Liu;Hongxiang Li;Bin Xie	2018	2018 18th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing (CCGRID)	10.1109/CCGRID.2018.00070	graph embedding;theoretical computer science;computer science;sampling (statistics);big data;vertex (geometry);embedding;vector space;graph;graph partition	EDA	-11.81655519028182	-41.57284589760285	40224
67775f52fbc2b87a9ca1ee8991f196cc67497bbe	map-matching cell phone trajectories of low spatial and temporal accuracy	cellular telephones;intelligent transportation systems;location;road networks;urban areas;trajectory;global positioning system;intelligent transportation systems map matching cell phone trajectories low spatial temporal accuracy road network base station search graph chronological order dijkstra algorithm tunable parameters cell phone data;roads trajectory base stations cellular phones accuracy global positioning system joining processes;algorithms;map matching;rural areas;smart phones graph theory intelligent transportation systems mobile communication mobile computing search problems	This paper presents an approach for matching cell phone trajectories of low spatial and temporal accuracy to the underlying road network. In this setting, only the position of the base station involved in a signaling event and the timestamp are known, resulting in a possible error of several kilometers. No additional information, such as signal strength, is available. The proposed solution restricts the set of admissible routes to a corridor by estimating the area within which a user is allowed to travel. The size and shape of this corridor can be controlled by various parameters to suit different requirements. The computed area is then used to select road segments from an underlying road network, for instance OpenStreetMap. These segments are assembled into a search graph, which additionally takes the chronological order of observations into account. A modified Dijkstra algorithm is applied for finding admissible candidate routes, from which the best one is chosen. We performed a detailed evaluation of 2249 trajectories with an average sampling time of 260 seconds. Our results show that, in urban areas, on average more than 44% of each trajectory are matched correctly. In rural and mixed areas, this value increases to more than 55%. Moreover, an in-depth evaluation was carried out to determine the optimal values for the tunable parameters and their effects on the accuracy, matching ratio and execution time. The proposed matching algorithm facilitates the use of large volumes of cell phone data in Intelligent Transportation Systems, in which accurate trajectories are desirable.	admissible heuristic;approximation algorithm;dijkstra's algorithm;fundamental fysiks group;map matching;mobile phone;olga (technology);openstreetmap;requirement;run time (program lifecycle phase);sampling (signal processing)	Gunnar Schulze;Christopher Horn;Roman Kern	2015	2015 IEEE 18th International Conference on Intelligent Transportation Systems	10.1109/ITSC.2015.435	computer vision;real-time computing;simulation;geography	Robotics	-16.285975757167954	-33.72037934146383	40225
696da38aad92a9c9f602d6974bc6ccb33bca75ca	predicting passengers in public transportation using smart card data	smart card;back propagation neural network;transportation;bag of words;prediction	Transit prediction has long been a hot research problem, which is central to the public transport agencies and operators, as evidence to support scheduling and urban planning. There are several previous work aiming at transit prediction, but they are all from the macro perspective. In this paper, we study the prediction of individuals in the context of public transport. Existing research on the prediction of individual behaviour are mostly found in information retrieval and recommender systems, leaving it untouched in the area of public transport. We propose a NLP based back-propagation neural network for the prediction job in this paper. Specifically, we adopt the concept of “bag of words” to build user profile, and use the result of clustering as input of back-propagation neural network to generate predictions. To illustrate the effectiveness of our method, we conduct an extensive set of experiments on a dataset from public transport fare collecting system. Our detailed experimental evaluation demonstrates that our method gets good performance on predicting public transport individuals.	smart card	Mengyu Dou;Tieke He;Hongzhi Yin;Xiaofang Zhou;Zhenyu Chen;Bin Luo	2015		10.1007/978-3-319-19548-3_3	smart card;transport;simulation;prediction;computer science;bag-of-words model;data mining;database;computer security	HCI	-17.68371558408736	-34.04803400550105	40240
d7d472adfc0c36b964081b4fa8add4c86de695ff	analysis of the eyes on face images for compliance with iso/icao requirements	databases;standards;skin;image edge detection;image color analysis;face;iris	The face has been used in identity documents and represents the ideal biometric characteristic in many applications. The International Civil Aviation Organization endorsed the use of face as the globally interoperable biometric characteristic. Successively, the International Standard Organization proposed the ISO/IEC 19794-5 standard for face usage in travel documents. The purpose of this work is to evaluate the quality of face images for identification documents and check if the face images satisfy the requirements defined by the ISO/IEC 19794-5. This work presents approaches for the evaluation of the following ISO/ICAO requirements: eyes state, red eyes and looking away. In addition, an approach to estimate the location of the center of the eyes is proposed. The proposed methods to check ISO/ICAO requirements were evaluated using the BioLab-ICAO Framework. The results achieved by the proposed methods were satisfactory, overcoming almost all the works in the literature for this purpose.	biometrics;enhanced entity–relationship model;face detection;iso/iec 42010;interoperability;pixel;requirement;sensor	Erick Vagner Cabral De Lima Borges;Igor Lucena Peixoto Andrezza;Jose R. T. Marques;Rajiv A. T. Mota;Joao Janduy B. Primo	2016	2016 29th SIBGRAPI Conference on Graphics, Patterns and Images (SIBGRAPI)	10.1109/SIBGRAPI.2016.032	computer vision;engineering;computer security;engineering drawing	Vision	-10.062499317720517	-46.995887413928244	40286
1365080630ef02ec4aa88d74a7e1970bf3a36afe	noise-tolerance matrix completion for location recommendation	lbsns;recommender system;check-in;structural noise;bregman iteration	Due to the sharply increasing number of users and venues in Location-Based Social Networks, it becomes a big challenge to provide recommendations which match users’ preferences. Furthermore, the sparse data and skew distribution (i.e., structural noise) also worsen the coverage and accuracy of recommendations. This problem is prevalent in traditional recommender methods since they assume that the collected data truly reflect users’ preferences. To overcome the limitation of current recommenders, it is imperative to explore an effective strategy, which can accurately provide recommendations while tolerating the structural noise. However, few study concentrates on the process of noisy data in the recommender system, even recent matrix-completion algorithms. In this paper, we cast the location recommendation as a mathematical matrix-completion problem and propose a robust algorithm named Linearized Bregman Iteration for Matrix Completion (LBIMC), which can effectively recover the user-location matrix considering structural noise and provide recommendations based solely on check-in records. Our experiments are conducted by an amount of check-in data from Foursquare, and the results demonstrate the effectiveness of LBIMC.	algorithm;baseline (configuration management);bregman divergence;compressed sensing;entity–relationship model;experiment;feedback;imperative programming;iteration;non-negative matrix factorization;privacy;recommender system;signal-to-noise ratio;sparse matrix	Bin Xia;Tao Li;Qianmu Li;Hong Zhang	2017	Data Mining and Knowledge Discovery	10.1007/s10618-017-0516-z	matrix completion;artificial intelligence;recommender system;data mining;noisy data;computer science;machine learning;sparse matrix;skew;matrix (mathematics);social network	ML	-17.985665652586245	-45.863549223991114	40288
35400ac2726404db90d8d29b6ecdac0df5b606d2	accelerating the mining of influential nodes in complex networks through community detection	parallel computing;influence maximization;community detection;complex networks;clustering;diffusion	Computing the set of influential nodes of a given size, which when activated will ensure maximal spread of influence on a complex network, is a challenging problem impacting multiple applications. A rigorous approach to influence maximization involves utilization of optimization routines that come with a high computational cost. In this work, we propose to exploit the existence of communities in complex networks to accelerate the mining of influential seeds. We provide intuitive reasoning to explain why our approach should be able to provide speedups without significantly degrading the extent of the spread of influence when compared to the case of influence maximization without using the community information. Additionally, we have parallelized the complete workflow by leveraging an existing parallel implementation of the Louvain community detection algorithm. We then conduct a series of experiments on a dataset with three representative graphs to first verify our implementation and then demonstrate the speedups. Our method achieves speedups ranging from 3x to 28x for graphs with small number of communities while nearly matching or even exceeding the activation performance on the entire graph. Complexity analysis reveals that dramatic speedups are possible for larger graphs that contain a correspondingly larger number of communities. In addition to the speedups obtained from the utilization of the community structure, scalability results show up to 6.3x speedup on 20 cores relative to the baseline run on 2 cores. Finally, current limitations of the approach are outlined along with the planned next steps.	algorithmic efficiency;baseline (configuration management);complex network;entropy maximization;expectation–maximization algorithm;experiment;louvain modularity;mathematical optimization;maximal set;parallel programming model;scalability;seeds (cellular automaton);speedup	Mahantesh Halappanavar;Arun V. Sathanur;Apurba K. Nandi	2016		10.1145/2903150.2903181	computer science;machine learning;data mining;distributed computing	ML	-12.897453988149692	-41.73450029850792	40348
40e2338c189c38dd8c7e02a768f5f965c4952547	crawling facebook for social network analysis purposes	complexity theory;scaling law;data collection;information network;web data;degree distribution;social network;social network analysis;computers and society;dynamical systems;online social network	We describe our work in the collection and analysis of massive data describing the connections between participants to online social networks. Alternative approaches to social network data collection are defined and evaluated in practice, against the popular Facebook Web site. Thanks to our ad-hoc, privacy-compliant crawlers, two large samples, comprising millions of connections, have been collected; the data is anonymous and organized as an undirected graph. We describe a set of tools that we developed to analyze specific properties of such social-network graphs, i.e., among others, degree distribution, centrality measures, scaling laws and distribution of friendship.	centrality;degree distribution;graph (discrete mathematics);hoc (programming language);social network analysis	Salvatore Catanese;Pasquale De Meo;Emilio Ferrara;Giacomo Fiumara;Alessandro Provetti	2011		10.1145/1988688.1988749	organizational network analysis;network science;social network analysis;dynamical systems theory;social science;degree distribution;computer science;dynamic network analysis;theoretical computer science;machine learning;data mining;sociology;world wide web;social network;data collection	Web+IR	-17.759209871625938	-41.05229010766086	40398
e2f03bfeac820b631050eeb91b7494214bc1f162	personalized sentiment analysis and a framework with attention-based hawkes process model		People use different words when expressing their opinions. Sentiment analysis as a way to automatically detect and categorize people’s opinions in text, needs to reflect this diversity and individuality. One possible approach to analyze such traits is to take a person’s past opinions into consideration. In practice, such a model can suffer from the data sparsity issue, thus it is difficult to develop. In this article, we take texts from social platforms and propose a preliminary model for evaluating the effectiveness of including user information from the past, and offer a solution for the data sparsity. Furthermore, we present a finer-designed, enhanced model that focuses on frequent users and offers to capture the decay of past opinions using various gaps between the creation time of the text. An attention-based Hawkes process on top of a recurrent neural network is applied for this purpose, and the performance of the model is evaluated with Twitter data. With the proposed framework, positive results are shown which opens up new perspectives for future research.		Siwen Guo;Sviatlana Höhn;Feiyu Xu;Christoph Schommer	2018		10.1007/978-3-030-05453-3_10	artificial intelligence;computer science;machine learning;sentiment analysis;user information;categorization;recurrent neural network	NLP	-24.481445208281862	-48.7525296072647	40457
609b00dcffe77633f506c53f1188054f7efefd28	the emergence of roles in large-scale networks of communication	online networks;bridges;complexity;structural holes;computer appl in social and behavioral sciences;structural equivalence;modularity;structural similarity;socio and econophysics population and evolutionary models	Communication through social media mediates coordination and information diffusion across a range of social settings. However, online networks are large and complex, and their analysis requires new methods to summarize their structure and identify nodes holding relevant positions. We propose a method that generalizes the sociological theory of brokerage, originally devised on the basis of local transitivity and paths of length two, to make it applicable to larger, more complex structures. Our method makes use of the modular structure of networks to define brokerage at the local and global levels. We test the method with two different data sets. The findings show that our approach is better at capturing role differences than alternative approaches that only consider local or global network features.	emergence;global network;social media;vertex-transitive graph	Sandra González-Bailón;Ning Wang;Javier Borge-Holthoefer	2014	EPJ Data Science	10.1140/epjds/s13688-014-0032-y	complexity;computer science;artificial intelligence;structural similarity;modularity;mathematics;algorithm	ML	-18.01591308733708	-40.31291909927187	40469
183eaf81218ef267a2e01fe6602e39a7b717930b	human-guided fuzzy decision for image similarity analysis and classification based on information compression	t technology general;qa76 computer software;image similarity	This paper introduces an original unsupervised learning algorithm for information compression that is further used in the proposed fuzzy inference procedure for discovering similarities between different images for the purpose of their classification. Two features extracted from each compressed information model are used in the paper to represent the location of the compressed model in the three-dimensional red-green-blue (RGB) space and its size (volume). A method for tuning the fuzzy inference procedure is proposed in the paper that uses a predefined human preference in the form of a given list of similar images with their approximate similarity levels. Thus the whole computation scheme is a kind of human-guided similarity analysis. The choice of the optimization algorithm and the selection of the optimization criterion are among the important problems, discussed in the paper. The final goal is to achieve a plausible “human-like” decision for similarity, when processing large number of images and other pictorial information. The whole proposed computation scheme for similarity analysis and classification is illustrated on a test example of flower images followed by detailed discussions. C © 2010 Wiley Periodicals, Inc.	approximation algorithm;computation;fuzzy logic;image;information model;john d. wiley;mathematical optimization;optimization problem;unsupervised learning	Gancho Vachkov	2011	Int. J. Intell. Syst.	10.1002/int.20465	computer science;artificial intelligence;machine learning;data mining;mathematics;information retrieval;statistics	ML	-5.8814832685189105	-27.899012022653867	40482
70be068699bc40d52cbff7059dbe9592bc29cf4a	scopas - semantic computation of page score	search result ordering;web page model;semantic scoring	This paper presents a novel model for scoring web pages, entitled SCOPAS (Semantic COmputation of PAge Score). With the prolific growth in the number of users of World Wide Web and the heterogeneity of their information needs, it becomes mandatory to evaluate the relevance of a web page in terms of user specific requirements. SCOPAS is aimed at modeling the web pages to facilitate efficient evaluation by harnessing the inherent features of the page in terms of its content and structure. The proposed model further enriches the scoring procedure by fine-graining the evaluation to a micro level through segmentation of the page. A variable magnitude, multi-dimensional approach is proposed for evaluating each of the segments by incorporating the relevance of intra-segment level components. The user-interest is captured with the help of FOAF (Friend Of A Friend) Ontology to achieve personalized page scoring. The generic SCOPAS model is extended to SCOPAS-Rank, which explores utilization of the model in improving the web search engine's result ordering. A prototype implementation of the proposed SCOPAS-Rank model is developed and experiments were conducted on it. The results of the experiments validate the effectiveness of the proposed model.	computation;computational semantics	K. S. Kuppusamy;G. Aghila	2013	International Journal of Information Technology and Decision Making	10.1142/S0219622013500387	computer science;data mining;world wide web;information retrieval	Robotics	-27.667855309014808	-51.6242908473358	40484
513fcd124054e6963a65a1f8ce95ba60f45655f7	plausibility measures: a general approach for representing uncertainty	possibility measure;model uncertainty;dempster shafer	The standardapproachto modelinguncertaintyis probability theory. In recentyears,researchers, motivatedby varying concernsincludinga dissatisf actionwith someof theaxiomsof probabilityandadesireto represent informationmore qualitatively, have introduceda numberof generalizations andalternati vesto probability, includingDempster -Shaferbelief functions [Shafer , 1976], possibility measures[Dubois and Prade,1990], lexicographicprobability [Blume et al., 1991], andmany others. Ratherthan investigatingeachof theseapproachespiecemeal,I considerherean approachto representinguncertaintythatgeneralizesthemall, andletsus understandtheir commonalitiesanddifferences. A plausibility measur e [FriedmanandHalpern,1995] associateswith asetaplausibility, which is justanelementin a partiallyorderedspace.Theonly realrequirement is thatif is asubsetof , thentheplausibilityof is lessthanequalto the plausibility of . Probabilitymeasuresareclearlyplausibility measures;every other representationof uncertainty that I amawareof canalsobeviewedasa plausibility measure.Givenhow little structureplausibility measureshave, it is perhapsnotsurprisingthatplausibilitymeasuresgeneralize somany othernotions. This very lack of structureturnsout to bea significantadvantage.By addingstructureon an“as needed”basis,it is possibleto characterizewhatis requiredto ensurethataplausibilitymeasurehascertainpropertiesof interest.Thisbothgivesinsightinto theessential featuresof the propertiesin questionandmakesit possibleto provegeneral resultsthatapplyto many representations of uncertainty. In thispaper , I discussthreeexamplesof thisphenomenon.	plausibility structure	Joseph Y. Halpern	2001			uncertainty analysis;dempster–shafer theory;machine learning;pattern recognition;data mining	AI	-5.63995639533953	-25.382463008216902	40548
834c98134209541106bfd084cb6351c9707c5e2a	a new web service model of hybrid personalized recommendation	filtering collaboration filtering algorithms educational institutions prediction algorithms accuracy ontologies;content based filtering;web services collaborative filtering recommender systems ubiquitous computing;k nearest neighbor method web service model web services recommendation recommendation quality hybrid personalized recommendation model behaviors context aware content based filtering collaborative filtering methods;hybrid personalized recommendation system content based filtering collaborative filtering;collaborative filtering;hybrid personalized recommendation system	In recent years, personalized recommendation has become a research focus on the Web services recommendation. The current recommendation system can be improved in the prediction accuracy and recommendation quality. This paper proposes a hybrid personalized recommendation model based on users' behaviors context-aware, which combines content-based filtering with collaborative filtering methods. First, we have selected m service subclasses by using content-based filtering method according to classify characteristics and current user-state. Next, users' specific ratings are predicted by K-nearest neighbor method. Finally, the Top-N services in the subclass will be recommended. Through the final experiment, we can draw a conclusion that the improved algorithm has good recommendation effect and high accuracy.	collaborative filtering;k-nearest neighbors algorithm;mcgurk effect;nearest neighbor search;personalization;recommender system;web service;world wide web	Huichuan Liao	2013	2013 Ninth International Conference on Natural Computation (ICNC)	10.1109/ICNC.2013.6818098	computer science;collaborative filtering;data mining;world wide web;information retrieval;recommender system	Web+IR	-22.48868776098351	-48.64874115775689	40605
f26a47b8e16d74d1f7657de32d581664f028a63c	the potential impact of vehicle-to-vehicle and sensor-to-vehicle communication in urban parking	traffic control;information services;article letter to editor;urban areas;traffic congestion;vehicle to infrastructure communications;cruising;vehicle to vehicle communications;urban areas information services traffic control;on street parking	Studies have shown that up to thirty percent of all traffic in crowded urban areas can be cruising for parking. Information provision to drivers can potentially decrease cruising time for individual drivers and subsequently improve the performance of the overall system. While most cities provide drivers with information on the occupancy rates of off-street parking facilities, information on single on-street parking places was non-existing until recently. Recent technological advances have made it possible to provide such information.	device driver	Geert Tasseron;Karel Martens;Rob van der Heijden	2015	IEEE Intelligent Transportation Systems Magazine	10.1109/MITS.2015.2390918	simulation;vehicle information and communication system;parking guidance and information;transport engineering;computer security;information system	ML	-17.649529621631867	-28.75722520802125	40610
853d5712a3f9c5fa7e0fa39bc5067a21914822b0	predicting supportive behaviors for human-robot collaboration		We present a model for predicting what supportive behaviors a robot should offer to a person during a human-robot collaboration (HRC) scenario. We train and test our model in simulation, using noisy data that mimics a real-world HRC interaction. Our results show that we can achieve accurate predictions, using only a small set of labeled demonstrations. We also show transfer learning capability: we train our model on an initial task and test it on a new task composed of the same building blocks but structured differently.	human–robot interaction;robot;signal-to-noise ratio;simulation	Elena Corina Grigore;Olivier Mangin;Alessandro Roncone;Brian Scassellati	2018			computer science;transfer of learning;noisy data;machine learning;robot;artificial intelligence;robotics;human–robot interaction	AI	-26.487900317814617	-40.13866326501591	40618
08b9f75c28cb15124c5d653ae318362e90eb0e37	library personalized recommendation service method based on improved association rules		PurposernrnrnrnrnNowadays, database management system has been applied in library management, and a great number of data about readers’ visiting history to resources have been accumulated by libraries. A lot of important information is concealed behind such data. The purpose of this paper is to use a typical data mining (DM) technology named an association rule mining model to find out borrowing rules of readers according to their borrowing records, and to recommend other booklists for them in a personalized way, so as to increase utilization rate of data resources at library.rnrnrnrnrnDesign/methodology/approachrnrnrnrnrnAssociation rule mining algorithm is applied to find out borrowing rules of readers according to their borrowing records, and to recommend other booklists for them in a personalized way, so as to increase utilization rate of data resources at library.rnrnrnrnrnFindingsrnrnrnrnrnThrough an analysis on record of book borrowing by readers, library manager can recommend books that may be interested by a reader based on historical borrowing records or current book-borrowing records of the reader.rnrnrnrnrnResearch limitations/implicationsrnrnrnrnrnIf many different categories of book-borrowing problems are involved, it will result in large length of encoding as well as giant searching space. Therefore, future research work may be considered in the following aspects: introduce clustering method; and apply association rule mining method to procurement of book resources and layout of books.rnrnrnrnrnPractical implicationsrnrnrnrnrnThe paper provides a helpful inspiration for Big Data mining and software development, which will improve their efficiency and insight on users’ behavior and psychology.rnrnrnrnrnSocial implicationsrnrnrnrnrnThe paper proposes a framework to help users understand others’ behavior, which will aid them better take part in group and community with more contribution and delightedness.rnrnrnrnrnOriginality/valuernrnrnrnrnDM technology has been used to discover information concealed behind Big Data in library; the library personalized recommendation problem has been analyzed and formulated deeply; and a method of improved association rules combined with artificial bee colony algorithm has been presented.	association rule learning;personalization	Kaigang Yi;Tinggui Chen;Guodong Cong	2018	Library Hi Tech	10.1108/LHT-06-2017-0120	world wide web;utilization rate;library management;data mining;software development;association rule learning;big data;procurement;cluster analysis;computer science;originality	Web+IR	-22.50240607251708	-51.95877850567882	40650
d45d2cb87d33f0d8f96c428aeb90840a275a0c8b	effective pruning for the discovery of conditional functional dependencies	minimal set;constant cfd discovery;efficient constant cfd discovery;effective pruning;constant cfds;search space;conditional functional dependencies;fast algorithm;inconsistent data;large real-world data set;proposed algorithm	Conditional Functional Dependencies (CFDs) have been proposed as a new type of semantic rules extended from traditional functional dependencies. They have shown great potential for detecting and repairing inconsistent data. Constant CFDs are 100% confidence association rules. The theoretical search space for the minimal set of CFDs is the set of minimal generators and their closures in data. This search space has been used in the currently most efficient constant CFD discovery algorithm. In this paper, we propose pruning criteria to further prune the theoretic search space, and design a fast algorithm for constant CFD discovery. We evaluate the proposed algorithm on a number of medium to large real world data sets. The proposed algorithm is faster than the currently most efficient constant CFD discovery algorithm, and has linear time performance in the size of a data set.	algorithm;association rule learning;band iii;chi;functional dependency;lu decomposition;poo-chi;sensor;star catalogue;theory;time complexity	Jiuyong Li;Jixue Liu;Hannu Toivonen;Jianming Yong	2013	Comput. J.	10.1093/comjnl/bxs082	theoretical computer science;machine learning;data mining;mathematics	DB	-7.24692470229031	-37.48542349762225	40708
242f8624f2926d32632016ff3a368b3e8dfc09ed	scalable image retrieval with multimodal fusion		As the number of images grows rapidly on the Internet, the scalability of image retrieval systems becomes a significant issue. In this paper, we propose two distributed clustering algorithms to scale up the bag-ofvisual-words model on millions of images and billions of visual features by leveraging distributed systems. We also introduce a multimodal fusion model to utilize textual data to improve the quality of image retrieval. Our experiments on multimodal datasets demonstrated our fusion approach can achieve high retrieval quality compared to image-only retrieval and text-only retrieval.	algorithm;apache hadoop;apache mahout;cluster analysis;computer vision;deep learning;distributed computing;experiment;image retrieval;internet;k-means clustering;machine learning;multimodal interaction;oracle fusion architecture;oracle fusion middleware;scalability;text corpus;text-based user interface;workbench	Yang Peng;Xiaofeng Zhou;Daisy Zhe Wang;Chunsheng Victor Fang	2016			machine learning;computer vision;fusion;scalability;image retrieval;computer science;artificial intelligence	Web+IR	-14.132840179529445	-51.637786740394226	40717
8801642e98ad747f0c43cb60846c22e15ec48771	review spam detection via temporal pattern discovery	adversarial data mining;electronic commerce;time window;time series;data mining;pattern detection;temporal pattern;review spam;spam detection	Online reviews play a crucial role in today's electronic commerce. It is desirable for a customer to read reviews of products or stores before making the decision of what or from where to buy. Due to the pervasive spam reviews, customers can be misled to buy low-quality products, while decent stores can be defamed by malicious reviews. We observe that, in reality, a great portion (> 90% in the data we study) of the reviewers write only one review (singleton review). These reviews are so enormous in number that they can almost determine a store's rating and impression. However, existing methods did not examine this larger part of the reviews. Are most of these singleton reviews truthful ones? If not, how to detect spam reviews in singleton reviews? We call this problem singleton review spam detection.  To address this problem, we observe that the normal reviewers' arrival pattern is stable and uncorrelated to their rating pattern temporally. In contrast, spam attacks are usually bursty and either positively or negatively correlated to the rating. Thus, we propose to detect such attacks via unusually correlated temporal patterns. We identify and construct multidimensional time series based on aggregate statistics, in order to depict and mine such correlations. In this way, the singleton review spam detection problem is mapped to a abnormally correlated pattern detection problem. We propose a hierarchical algorithm to robustly detect the time windows where such attacks are likely to have happened. The algorithm also pinpoints such windows in different time resolutions to facilitate faster human inspection. Experimental results show that the proposed method is effective in detecting singleton review attacks. We discover that singleton review is a significant source of spam reviews and largely affects the ratings of online stores.	aggregate data;algorithm;anomaly detection;anti-spam techniques;e-commerce;ibm notes;microsoft windows;online shopping;pattern recognition;pervasive informatics;sensor;spamming;time series	Sihong Xie;Guan Wang;Shuyang Lin;Philip S. Yu	2012		10.1145/2339530.2339662	e-commerce;computer science;machine learning;time series;data mining;internet privacy;world wide web;statistics	ML	-27.658539383836587	-42.841042940340735	40730
127b97641a03e4f640e5431647c4898b21585c99	scalable diversified ranking on large graphs	diversified ranking;graph theory;optimisation;near optimal randomized greedy algorithm scalable diversified ranking information retrieval data mining task diversified ranking algorithms memory requirements diversified ranking measure submodular set function maximization problem submodularity linear time complexity space complexity near optimal diversified ranking generalized diversified ranking;complexity theory;approximation algorithms;information retrieval;randomised algorithms;greedy algorithms;data mining;submodular function;binary trees;diversity reception;submodular function diversified ranking graph algorithms scalability flajolet martin sketch;vectors;computational complexity;greedy algorithms diversity reception algorithm design and analysis vectors binary trees complexity theory approximation algorithms;scalability;graph algorithms;randomised algorithms computational complexity data mining graph theory greedy algorithms information retrieval optimisation;algorithm design and analysis;flajolet martin sketch	Enhancing diversity in ranking on graphs has been identified as an important retrieval and mining task. Nevertheless, many existing diversified ranking algorithms either cannot be scalable to large graphs due to the time or memory requirements, or lack an intuitive and reasonable diversified ranking measure. In this paper, we propose a new diversified ranking measure on large graphs, which captures both relevance and diversity, and formulate the diversified ranking problem as a submodular set function maximization problem. Based on the submodularity of the proposed measure, we develop an efficient greedy algorithm with linear time and space complexity w.r.t. the size of the graph to achieve near-optimal diversified ranking. In addition, we present a generalized diversified ranking measure and give a near-optimal randomized greedy algorithm with linear time and space complexity for optimizing it. We evaluate the proposed methods through extensive experiments on five real data sets. The experimental results demonstrate the effectiveness and efficiency of the proposed algorithms.		Rong-Hua Li;Jeffrey Xu Yu	2013	IEEE Trans. Knowl. Data Eng.	10.1109/TKDE.2012.170	algorithm design;mathematical optimization;combinatorics;greedy algorithm;scalability;binary tree;computer science;graph theory;submodular set function;machine learning;mathematics;computational complexity theory;ranking svm;algorithm	DB	-8.411843090189386	-39.37144088606512	40752
0d9554e12bbd689dd985317a00dfb34a8bd50a3d	the fragmented orchestra		The Fragmented Orchestra is a distributed musical instrument which combines live audio streams from geographically disparate sites, and granulates each according to the spike timings of an artificial spiking neural network. This paper introduces the work, outlining its historical context, technical architecture, neuronal model and network infrastructure, making specific reference to modes of interaction with the public.	artificial neural network;fragmented object;information technology architecture;spiking neural network;the spike (1997)	Daniel Jones;Tim Hodgson;Jane Grant;John Matthias;Nicholas Outram;Nick Ryan	2009			real-time computing;simulation;computer science;artificial intelligence	ML	-28.093948598314178	-27.901800862875298	40788
b9305969660601bdbadf3896a62d0c68f6f17973	rdf graph visualization tools: a survey		Semantic Web technologies are increasingly being used for the development of Future Internet applications, mainly due to the impressive growth of the Internet of Things research area. This spread pushes for effective and efficient ways to visualize the content of RDF ontologies and knowledge bases. Several strategies can be adopted to visualize semantic data and one of this consists in exploiting the graph representation intrinsic in the RDF model. In this paper, we propose a survey of the main tools for the graphical visualization of triples (being them terminological or assertional statements) exploiting a graph representation.		Francesco Antoniazzi;Fabio Viola	2018	2018 23rd Conference of Open Innovations Association (FRUCT)	10.23919/FRUCT.2018.8588069	rdf;data mining;data visualization;semantic data model;semantic web;visualization;graph (abstract data type);knowledge-based systems;graph drawing;computer science	HCI	-29.85875824981042	-32.071123056267936	40808
0771da52918cc9703f9d9cb93030f51b8e55cd01	high-performance computing tools for modeling evolution in epidemics	biology computing;evolutionary dynamics;individual based model;spatially explicit;genetics;experiments high performance computing epidemic evolution modeling stepwise refinements biological model simulation co evolutionary dynamics macroparasite microparasite genetic algorithms pathogen virulence cellular automata two dimensional lattice biotic spatial heterogeneity abiotic spatial heterogeneity;cellular automata biology computing digital simulation genetic algorithms;high performance computer;genetic algorithm;genetic algorithms;biological system modeling capacitive sensors computational modeling evolution biology genetic algorithms biology computing immune system frequency computer science computer simulation;cellular automata;spatial heterogeneity;high performance;digital simulation	We describe a series of stepwise refinements of a biological model resulting in a high-performance simulation system for individual-based models of the co-evolutionary dynamics associated with spatially explicit epidemic processes. Our model includes two competing host species, a macroparasite capable of serving as a vector, and the vector-borne microparasite. Genetic algorithms are used to simulate genetic change; we are particularly interested in the evolution of pathogen virulence. The simulation system employs cellular automata to track individual organisms distributed over a two-dimensional lattice. Our models are able to identify each individual's parentage, and to account for both biotic and abiotic spatial heterogeneity. Using the developed system we conducted a series of experiments to demonstrate how individual-based modeling and explicit representation of space, although computationally expensive, can produce qualitatively new biological results.		William Maniatty;Boleslaw K. Szymanski;Thomas Caraco	1999		10.1109/HICSS.1999.773085	cellular automaton;genetic algorithm;computer science;bioinformatics	HPC	-4.756375743237379	-49.69654169247803	40813
51c1a29116d16a0495faf6265bbf97ba6b5aeb16	a neural network implementation of a data association algorithm	networks graphs;neural network approach to matching;programming heuristic;data association in surveillance;data association;heuristic for assignment problem;matching;military surveillance;neural network	In this paper we are concerned with a time varying set of entities located in a fixed field. These entities are sensed at discrete time instances with a single sensor modality. At a given time instant a collection of bivariate Gaussian sensor reports is produced, estimating the locations of a subset of the entities present in the field. A database of reports is maintained which should ideally contain exactly one report for each entity that has been sensed. Whenever a collection of sensor reports is received the database must be updated to reflect the new information. This updating requires correspondence processing between the database reports and the new sensor reports to determine which pairs of sensor and database reports correspond to the same entity. We present an algorithm for performing this correspondence processing under the assumptions that each new collection of sensor reports contains at most one report for any entity, and that the database can be reasonably assumed to contain at most one repo...	algorithm;artificial neural network	Allen L. Barker;Donald E. Brown;Worthy N. Martin	1990	INFORMS Journal on Computing	10.1287/ijoc.2.2.100	matching;computer science;machine learning;data mining;database;artificial neural network	HPC	-6.5966145478151414	-30.232396014308843	40840
923fc98a3e227ec5ca9d9b54f8054c4d9c7b7ba9	"""discussion of """"analysis of spatio-temporal mobile phone data: a case study in the metropolitan area of milan"""""""			mobile phone	Anestis Antoniadis;Jean-Michel Poggi	2015	Statistical Methods and Applications	10.1007/s10260-015-0309-8	telecommunications	HCI	-19.980668604617478	-33.17605843902046	40866
fba081c909b062b0a9bd41b922d60d861bec3c72	biological system dynamics: from personal discovery to universal application	biological systems	Many biomedical problems, including diabetes, hypertension, and drug tolerance, are fundamentally problems of biological control systems. Computer modeling and simulation constitute an effective tool for the systematic study of such systems. In particular, System Dynamics provides a graphical interface which allows one to develop a model structure using a parsimo nious set of symbols. The structural diagram is linked with a set of equations to quantitatively describe each component in the system. Simulations can then be conducted to examine the behavior of the system under a variety of circumstances. Once models are developed, they may be used by a larger audience after only a few hours' training. It soon becomes evident that a given model may be applied to a surprisingly wide variety of biological systems. Finally, System Dynamics models may be readily modified, adapted, and expanded, leading to a growing body of models which are relevant to the biomedical community.	biological system;system dynamics	Edward J. Gallaher	1996	Simulation	10.1177/003754979606600408	simulation;computer science;engineering;artificial intelligence	Robotics	-7.503288135919986	-48.6595240820617	40868
44006912454495af31540cefebc2bc4341acc60c	cosbilab lime: a language interface for stochastic dynamical modelling in ecology	software tool;metacommunity;programming language;ecosystem model;concurrency;blenx;stochastic dynamics;static analysis;process algebra	We present a simple language tool, CoSBiLab LIME, for building ecosystem models for stochastic dynamic simulation. The LIME language allows the user to give a biologically intuitive model description in a narrative style. After performing static analysis on the model structure, the software tool translates the model description into the BlenX programming language for stochastic dynamical simulation. These features facilitate the analysis of parallel, multiple ecological interactions in metacommunities. The software tool thus allows ecologists with no programming background to perform quite complicated, process-algebra-based simulations.	ecology	Ozan Kahramanogullari;Ferenc Jordán;James F. Lynch	2011	Environmental Modelling and Software	10.1016/j.envsoft.2010.12.007	process calculus;simulation;ecosystem model;concurrency;computer science;theoretical computer science;static analysis	Robotics	-27.21521501623431	-27.230367589180023	40890
06075cb83edc324d06b754916f77cab8f1e62c2d	active or inactive: infer private user information in location-based social network	location based services;big data;social networks;privacy inference;lbs;private information;bayesian networks	Private user information can be compromised while revealing individual location data in widely used location-based social networks (LBSNs). In order to reveal the risk of location privacy faced by users, we demonstrate a method, which transforms social networks into Bayesian networks, to infer private information through the location data and relationships among users in LBSNs, such as Gowalla, regardless of whether users are active or inactive. Location data from active users can be easily used to infer private information like consumption level. For example, people who frequently appear in expensive restaurants are likely to rank the high consumption level. Those inactive users, who share sparse location data, reveal their private information through their active friends whose private information is easily divulged. Our experimental results show that friends have a high probability of having been to the same places. Combining with relationship data, the possibility of revealing private information is dr...	geosocial networking;social network	Chi Guo;Meng Luo;Xuan Liu;Jingsong Cui	2016	IJES	10.1504/IJES.2016.076112	private information retrieval;big data;computer science;location-based service;bayesian network;data mining;pound;internet privacy;world wide web;social network	ECom	-22.617809927134697	-44.593163512953026	40905
affb39b2a804e1a4182d0accd7c65d75f2fe83e0	on budgeted influence maximization in social networks	belief networks;belief propagation budgeted influence maximization social network information diffusion;probability;graph structure fixed budget arbitrary cost budgeted influence maximization bim problem seed node information dissemination influence spread seed selection algorithm approximation ratio seed set p complex marginal probability bayesian network heuristic algorithm large scale social network computation cost synthetic dataset network parameter;social networking online approximation theory belief networks information dissemination probability;approximation theory;information dissemination;social networking online;approximation algorithms approximation methods belief propagation integrated circuit modeling complexity theory social network services bayes methods	Given a fixed budget and an arbitrary cost for selecting each node, the budgeted influence maximization (BIM) problem concerns selecting a set of seed nodes to disseminate some information that maximizes the total number of nodes influenced (termed as influence spread) in social networks at a total cost no more than the budget. Our proposed seed selection algorithm for the BIM problem guarantees an approximation ratio of (1-1/√e). The seed selection algorithm needs to calculate the influence spread of candidate seed sets, which is known to be #P-complex. Identifying the linkage between the computation of marginal probabilities in Bayesian networks and the influence spread, we devise efficient heuristic algorithms for the latter problem. Experiments using both large-scale social networks and synthetically generated networks demonstrate superior performance of the proposed algorithm with moderate computation costs. Moreover, synthetic datasets allow us to vary the network parameters and gain important insights on the impact of graph structures on the performance of different algorithms.	approximation algorithm;bayesian network;bim;computation;entropy maximization;expectation–maximization algorithm;experiment;heuristic;linkage (software);marginal model;selection algorithm;social network;synthetic intelligence	Huy Nguyen;Rong Zheng	2013	IEEE Journal on Selected Areas in Communications	10.1109/JSAC.2013.130610	mathematical optimization;computer science;machine learning;probability;data mining;statistics;approximation theory	ML	-16.56745381993623	-43.47214248485731	40919
35a6da5bec330bb56ba63a461edee3622ef553dd	the provision of real-time information for passengers in metro networks case studies : london and hong kong	level of service;smart card;urban transportation;travel time;ucl;case studies;public transport;data collection;traveler information and communication systems;discovery;theses;conference proceedings;digital web resources;smart cards;ucl discovery;open access;united kingdom;transport performance;public transit;traffic delays;ucl library;book chapters;open access repository;hong kong;london;urban transport;travel information;ucl research	This study looks at discovering information about the dynamics of a metro network, in real-time, using entry and exit data from the passengers’ smart cards. The data shows to be a valuable source of information about the current conditions of the network for both operators and passengers. An algorithm was developed which used real-time data to determine journey time characteristics, and to determine deviations from normal travel time and the extent to which these constitute a delay. This study focuses on the London Underground network and the Hong Kong MTR network as case studies to test the algorithm using the data produced by the automated ticketing systems. It aims to mine the data to provide information that can be used by passengers of the network. This information can lead to passengers knowing optimal routes, a realistic travel time and the number of minutes a delay may cost them; when the delay may be caused by congestion or service problems. Operationally this can allow for delay status reports to be more realistic, dynamic and responsive to crowding and provide information to the operators about the dynamics of the network in realtime.	algorithm;crowding;information source;mtr;network congestion;real-time data;real-time transcription;smart card;underground	Emily Digges La Touche	2015			telecommunications;engineering;advertising;operations research	Embedded	-17.32316527955303	-29.00295482153137	41026
4f2738d54999745bba5b7afb2b439051eec87528	blog rating as an iterative collaborative process	search engine;information retrieval;world wide web	The blogosphere is a part of the World Wide Web, enhanced with several characteristics that differentiate blogs from traditional websites. The number of different authors, the multitude of user-provided tags, the inherent connectivity between blogs and bloggers, the high update rate, and the time information attached to each post are some of the features that can be exploited in various information retrieval tasks in the blogosphere. Traditional search engines perform poorly on blogs since they do not cover these aspects. In an attempt to exploit these features and assist any specialized blog search engine to provide a better ranking of blogs, we propose a rating mechanism, which capitalizes on the hyperlinks between blogs. The model assumes that the intention of a blog owner who creates a link to another blog is to provide a recommendation to the blog readers, and quantifies this intention in a score transferred to the blog being pointed. A set of implicit and explicit links between any two blogs, along with the links’ type and freshness, affect the exchanged score. The process is iterative and the overall ranking score for a blog is subject to its previous score and the weighted aggregation of all scores assigned by all other blogs.	backlink;blog;blogosphere;emoticon;entity;glossary of blogging;hyperlink;information retrieval;interpreter (computing);iteration;replay attack;spamming;web search engine;world wide web	Malamati D. Louta;Iraklis Varlamis	2010		10.1007/978-3-642-11684-1_11	spam blog;computer science;internet privacy;world wide web;information retrieval	Web+IR	-25.08174819993976	-48.84370721281891	41037
947345e34f538a43a4bc174d11189ff38e0cdc74	oct: a novel opportunistic compression and transmission approach for private car trajectory data		The advances in mobile sensing and vehicle cloud service techniques have generated massive spatial-temporal trajectory data, which has caused the crises of storage and communication. In this paper, we propose a novel Opportunistic Compression and Transmission approach, namely OCT, with aims of reducing trajectory transmission overhead and storage cost. We first present the design of trajectory collection terminal based on GPS & OBD wherein the main process of OCT can be implemented rather than the cloud server. Within the proposed OCT, we devise a map-matching method based on MIV-matching and calibrating trajectory, which significantly reduces sampling errors of raw trajectories. Then we divide trajectory data into two parts, i.e. spatial and temporal parts, and realize compression operation separately. By using a prediction model based on historical trajectory velocity, we make use of opportunistic transmission of trajectory data from the GPS & OBD terminal to vehicle cloud server and thus dramatically decrease the transmission overhead. The proposed OCT not only realizes real-time trajectory preprocessing and compressing, but also ensures high trajectory compression ratio. To validate the performance of the OCT, we collect a large-scale private car trajectory data from real urban environments. Extensive experiments verify the effectiveness and superiority of the proposed method.	cloud computing;experiment;global positioning system;overhead (computing);preprocessor;real-time clock;sampling (signal processing);server (computing);velocity (software development);virtual private server	Jie Chen;Dong Wang;Zhu Xiao;Vincent Havyarimana	2018	2018 Data Compression Conference	10.1109/DCC.2018.00054	compression ratio;data modeling;artificial intelligence;computer vision;data compression;computer science;global positioning system;cloud computing;compression (physics);transmission (mechanics);trajectory	Robotics	-15.702342287088634	-32.9718507305577	41038
ece89b7dfc2dbf8fe4c5ffab8e3f15d61f1a1acc	robust community detection on dynamic graph	complex networks;detection algorithms;time complexity;network theory graphs complex networks graph theory;heuristic algorithms;clustering algorithms;heuristic algorithms robustness clustering algorithms complex networks algorithm design and analysis detection algorithms time complexity;robustness;network topological structure robust community detection dynamic graph complex networks dynamic network rcd sigmoid function;algorithm design and analysis	Many approaches have been proposed to identify communities on complex networks. However the current algorithms are sensitive to the variation of input data and parameters. In this paper, we propose a new community detection approach called robust community detection on dynamic network (RCD). The robustness of our algorithm lies in two aspects. Firstly, by adopting the offset of sigmoid function, RCD reduces dependency on the input cluster number. Therefore, RCD is insensitive to the man-made interference and the robustness is guaranteed. Secondly, RCD is not restricted to the type of input networks, because it only depends on the topological structure of network rather than requiring labels or other information of networks. Thus, the application robustness is ensured. RCD are evaluated on both the synthetic and realistic network data. The experiment result shows that by introducing sigmoid function, the error rate of misclassification and iterative times are decreased.	algorithm;complex network;interference (communication);iterative method;sigmoid function;synthetic intelligence	Dan Wu;Kai Niu;Zhiqiang He	2016	2016 First International Workshop on Sensing, Processing and Learning for Intelligent Machines (SPLINE)	10.1109/SPLIM.2016.7528393	mathematical optimization;computer science;theoretical computer science;machine learning	ML	-14.29715117834264	-42.247100490792015	41092
5045cb3ae3576c024c16dd5aaf355177f7d7700e	a navigation algorithm inspired by human navigation	social network services;routing;navigation;navigation humans routing principal component analysis peer to peer computing social network services labeling;principal component analysis;network pathfinding navigation algorithm human navigation spatial cognition landmark recognition network analytic technique network center;cognition;humans;peer to peer computing;network theory graphs;labeling;network theory graphs cognition	Human navigation has been a topic of interest in spatial cognition from the past few decades. It has been experimentally observed that humans accomplish the task of way-finding a destination in an unknown environment by recognizing landmarks. Investigations using network analytic techniques reveal that humans, when asked to way-find their destination, learn the top ranked nodes of a network. In this paper we report a study simulating the strategy used by humans to recognize the centers of a network. We show that the paths obtained from our simulation has the same properties as the paths obtained in human based experiment. The simulation thus performed leads to a novel way of pathfinding in a network. We discuss the performance of our method and compare it with the existing techniques to find a path between a pair of nodes in a network.	algorithm;cognition;experiment;pathfinding;simulation	M. Vijesh;Sudarshan Iyengar;S. M. Vijay Mahantesh;Amitash Ramesh;C. E. Veni Madhavan	2012	2012 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining	10.1109/ASONAM.2012.225	routing;labeling theory;navigation;simulation;cognition;computer science;artificial intelligence;machine learning;network simulation;principal component analysis	Robotics	-21.22058273349876	-40.73605724248411	41097
48d42c2109b337b32b81c313a7baa599c2fb2910	electricity based external similarity of categorical attributes	extraction information;analyse amas;random walks on graphs;analisis datos;distance measure;information extraction;data mining;data analysis;cluster analysis;fouille donnee;random walk;electrical circuit;analyse donnee;nearest neighbour;analisis cluster;marcha aleatoria;similarity function;categorical data;busca dato;extraccion informacion;marche aleatoire;donnee categorielle;dato categorico	Data mining tools use similarity or distance computations as a fundamental and critical data property. Categorical attributes abound in databases. For example, the Car Make, Gender , Occupation, etc. elds in a car insurance database contain a great deal of useful information that is encoded as categorical values. Sadly, categorical data is not easily amenable to similarity computations. Typically, a domain expert could manually specify some or all of the similarity relationships. This is error-prone and not feasible for attributes that take on many values, nor is it useful for cross-attribute similarities, such as between Gender and Occupation. External similarity functions de ne a similarity between, say, Car Makes by looking at how they co-occur with the other categorical attributes. In this paper we exploit a rich duality between random walks on graphs and electrical circuits to develop an external similarity function called REP. The only previously proposed external similarity function is ad-hoc while REP is theoretically grounded. To illustrate the usefulness of REP, we conduct two experiments. First, we cluster categorical attribute values to show the relationships inferred by REP. Second, we use REP e ectively as a nearest neighbour classi er.	categorical variable;cognitive dimensions of notations;computation;data mining;database;experiment;hoc (programming language);information;scalability;similarity measure;subject-matter expert	Christopher R. Palmer;Christos Faloutsos	2003		10.1007/3-540-36175-8_49	electrical network;categorical variable;computer science;machine learning;pattern recognition;data mining;database;mathematics;cluster analysis;data analysis;random walk;information extraction;statistics	DB	-8.953536991616502	-44.2651103664061	41113
2f90e50026d7815e199c57e0d0123da856e56503	collaborative filtering with the simple bayesian classifier	bayesian approach;simple bayesian classifier;supervised machine learning;collaborative filtering;user model	Many collaborative filtering enabled Web sites that recommend books, CDs, movies, videos and so on, have become very popular on Internet. They recommend items to a user based on the opinions of other users with similar tastes. In this paper, we discuss an approach to collaborative filtering based on the simple Bayesian classifier. The simple Bayesian classifier is one of the most successful supervised machine-learning algorithms. It performs well in various classification tasks in spite of its simplicity. In this paper, we define two variants of the recommendation problem for the simple Bayesian classifier. In our approach, we calculate the similarity between users from negative ratings and positive ratings separately. We evaluated these algorithms using a database of movie recommendations and joke recommendations. Our empirical results show that one of our proposed Bayesian approaches significantly outperforms a correlation-based collaborative filtering algorithm. The other model almost outperforms as well although it shows similar performance to the correlation-based approach in some parts of our experiments.	algorithm;bayesian network;book;collaborative filtering;data model;experiment;machine learning;missing data;naive bayes classifier;simple features;sparse	Koji Miyahara;Michael J. Pazzani	2000		10.1007/3-540-44533-1_68	user modeling;bayesian probability;computer science;collaborative filtering;machine learning;pattern recognition;data mining;recommender system	ML	-20.3218556589033	-48.90598448069024	41133
be2466c37003e4100f3b9f61776b2f3cf2739b55	j. friend and a. hickling, planning under pressure: the strategic choice approach (third edition), elsevier, amsterdam (2005) isbn 0-7506-6373-1		The invention relates to a vinyl polymer composition suitable for outdoor use in the sunlight. The heat buildup in articles made from the composition is lowered without changing the ultraviolet protection or the color of the articles. This is accomplished by employing in the composition a black infrared reflecting pigment, such as a mixture of Cr2O3 and Fe2O3, and other infrared reflecting pigments.	identification friend or foe;international standard book number	René Victor Valqui Vidal	2006	European Journal of Operational Research	10.1016/j.ejor.2005.02.017	regional science	Robotics	-32.53075112992624	-25.050531042784236	41149
e5ace8b456936929d1339aad780cc6b50f0f0d78	mining weighted association rules	association rules;data mining;weight;association rule;support	Association rules are useful for determining correlations between items and have applications in marketing, financial and retail sectors. Lots of algorithms have been proposed for finding the association rules in databases. Most of these algorithms treat each item as uniformity. However, in real applications, the user may have more interest in the rules that contain those fashionable items that occur frequently. Usually too many outdated items exist in databases, but they seldom occur recently. Those outdated items hamper us to find the interesting rules efficiently and effectively. Another case is the user sometimes may want to mine the association rules with more emphasis on some items. To solve these problems, in this paper, we propose the vertical and mixed weighted association rules. We can divide the database into several time intervals, and assign a weight for each interval. Furthermore, we also assign a weight for each item to identify the important items. We present an algorithm MWAR (Mixed Weighted Association Rules) to handle the problem of mining mixed weighted association rules. The experiments show that the rules from our methods have much better predictive ability on future data. We also demonstrate the efficiency of our methods on real data and synthetic datasets.		Songfeng Lu;Heping Hu;Fan Li	2001	Intell. Data Anal.	10.3233/ida-2001-5303	association rule learning;computer science;data science;machine learning;data mining;mathematics;apriori algorithm	AI	-4.764446798964156	-35.178916363043236	41150
f9cea1fbc70d52439037fb02a6b13f307c8054a4	picturesort: gamification of image ranking	information retrieval;gamification;image ranking	Human computation is a very powerful tool for solving tasks that cannot be solved by computers efficiently. One such problem is ranking images upon their relevance for a semantic query or upon how well they depict a semantic concept. In this paper we investigate a method to leverage human computation in a divide-and-conquer approach to create precise ranking models. We discuss the basic technique, our prototype client, its adoption to a gamification approach, and present the results of a study with the prototype. Results from the study indicate that with our method the ranking aggregated from the user input converges fast to an optimal ranking.	computer;gamification;human-based computation;prototype;relevance;semantic query	Mathias Lux;Mario Guggenberger;Michael Riegler	2014		10.1145/2594776.2594789	ranking;computer science;data mining;ranking svm;world wide web;information retrieval	Web+IR	-29.380853505658038	-48.84298548488857	41234
17f3235956dd86edca344144ea700509c33cc2dd	toward unsupervised correlation preserving discretization	tratamiento datos;unsupervised learning;extraction information;discretisation;data mining itemsets warehousing principal component analysis data compression data preprocessing classification tree analysis decision trees discrete transforms databases;analisis componente principal;discrete data;data compression;analisis datos;information extraction;dato que falta;discretization;data processing;traitement donnee;discretizacion;data compression unsupervised correlation preserving discretization pca based unsupervised algorithm data preprocessing technique continuous attributes discretization multivariate data sets piecewise correlation categorical attributes frequent itemset mining tasks data mining principal component analysis;apprentissage non supervise;almacen dato;indexing terms;data mining;index terms data preprocessing;data warehouses unsupervised learning principal component analysis data mining data compression pattern classification;donnee manquante;data analysis;fouille donnee;data compression index terms data preprocessing principal component analysis data mining summarization missing data;principal component analysis;estructura datos;data warehousing;pattern classification;analyse composante principale;frequent itemset mining;analyse donnee;structure donnee;data mining summarization;pretraitement;missing data;compresion dato;missing values;entrepot donnee;data warehouses;data warehouse;data preprocessing;data structure;busca dato;extraccion informacion;multivariate data;compression donnee;pretreatment;pretratamiento	Discretization is a crucial preprocessing technique used for a variety of data warehousing and mining tasks. In this paper, we present a novel PCA-based unsupervised algorithm for the discretization of continuous attributes in multivariate data sets. The algorithm leverages the underlying correlation structure in the data set to obtain the discrete intervals and ensures that the inherent correlations are preserved. Previous efforts on this problem are largely supervised and consider only piecewise correlation among attributes. We consider the correlation among continuous attributes and, at the same time, also take into account the interactions between continuous and categorical attributes. Our approach also extends easily to data sets containing missing values. We demonstrate the efficacy of the approach on real data sets and as a preprocessing step for both classification and frequent itemset mining tasks. We show that the intervals are meaningful and can uncover hidden patterns in data. We also show that large compression factors can be obtained on the discretized data sets. The approach is task independent, i.e., the same discretized data set can be used for different data mining tasks. Thus, the data sets can be discretized, compressed, and stored once and can be used again and again.	algorithm;association rule learning;data compression;data mining;discretization;hidden markov model;independent set (graph theory);interaction;missing data;preprocessor;text mining;unsupervised learning	Sameep Mehta;Srinivasan Parthasarathy;Hui Yang	2005	IEEE Transactions on Knowledge and Data Engineering	10.1109/TKDE.2005.153	missing data;computer science;machine learning;data warehouse;pattern recognition;discretization;data mining;database;discretization of continuous features;statistics	ML	-6.863171387198682	-37.01691123911247	41238
370be6b67f7d4b617c05a5920d9c130bda67588b	flood monitoring in smart cities based on fuzzy logic about urban open data	urban mobility;flood;urban mobility fuzzy flood smart cities tcp ip;smart cities fuzzy logic urban flood monitoring geographic map alerts remote sensing water level tcp ip protocol fuzzy rules inference mamdani model urban open data flood alert states georeferencing;smart cities;fuzzy;tcp ip;monitoring data models tcpip sensors smart cities fuzzy logic computer science;transport protocols alarm systems floods fuzzy logic geographic information systems inference mechanisms smart cities	A new method for urban flood monitoring based on fuzzy logic for issue alerts on a geographic map was showed. The model is designed to receive information from remote sensing water level over TCP/IP protocol and operate intelligently based on fuzzy rules with inference by Mamdani model from urban open data, providing free information access containing flood alert states and flooding with georeferencing that can help cities to become smart cities. The model was validated by case studies analysis with real sensors that generate a set of pre-planned test data. The issue alerts on geographical maps in real-time corroborated presented in this work for the acceptance of fuzzy logic in the urban monitoring flood with high performance, being able to act autonomously providing information to drivers for avoid undesirable routes.	flood;fuzzy logic;fuzzy rule;information access;map;real-time transcription;sensor;smart city;test data	Fabricio Silva Melo;Jose Lucas Matos Silva;Hendrik T. Macedo	2016	2016 8th Euro American Conference on Telematics and Information Systems (EATIS)	10.1109/EATIS.2016.7520161	fuzzy logic;computer science;data mining;internet protocol suite;internet privacy;computer security;flood myth	AI	-15.872247772453466	-30.56826128726228	41259
030fcf8d12b8784dbc903ac017b58e8a218e9b37	a close look at amoeboid locomotion: an integrated picture of a migrating, starvation-induced foraging unit of physarum polycephalum		Physarum polycephalum, cultivated on a glucose-deficient agar surface, forms disconnected foraging units (satellites). Our aim is to shed light onto the amoeboid locomotion of the slime mould, using satellites as reproducible and well-defined models and employing a wide range of techniques. This work was presented at PhysNet 2015.		Christina Oettmeier;Hans-Günther Döbereiner	2015			biology;communication;ecology	Robotics	-6.0112654508601695	-47.024184375952785	41275
9098e23412c3aed8ff95526385a09f24f7590998	rough set theory based user aware tv program and settings recommender	ubiquitous;context aware tv;recommendation engine;fuzzy logic;bayesian;rough sets;family preference;social status;core attributes	In this paper the authors are proposing a design of TV program and settings recommendation engine utilizing contextual parameters like personal, social, temporal, mood, and activity. In addition to the contextual parameters the system utilizes the explicit or implicit user ratings and watching history to resolve the conflict if any while recommending the services. The System is implemented exploiting AI techniques like fuzzy logic and Rough Sets Based Decision Rules. The motivation behind the proposed work is i) to improve the user's satisfaction level and ii) to improve the social relationship between user and TV. The context aware recommender utilizes social context data as an additional input to the recommendation task alongside information of users and TV programs. They have analyzed the recommendation process and performed a subjective test to show the usefulness of the proposed system for small families.	recommender system;rough set;set theory	S. G. ThyagarajuG.;U. P. Kulkarni	2012	IJAPUC	10.4018/japuc.2012040105	fuzzy logic;rough set;human–computer interaction;social status;bayesian probability;computer science;knowledge management;machine learning;data mining;multimedia;ubiquitous computing	ECom	-26.21872103335118	-43.30279161199646	41306
fd5770131f50756a55f8dd23733ef2d90989404d	multi-level visualization of interrelated data entities	information visualization;visualization techniques	Nowadays, electronic devices are part of our daily routines, resulting in information generation at virtually any time and context. Due to different styles of interaction, data produced by human activities is not only in considerable quantities, but it is also extremely rich, which makes it difficult to manage and analyze. Visualization has the potential to overcome this limitation: not only is it an excellent means to display large quantities of information, but it also alleviates cognitive load associated with data interpretation. We created an interactive multi-level layered visualization, in which time may be represented sequentially through layers. Data entities are displayed as circles with size proportional to a particular data feature we need to highlight, allowing immediate comparison between entities. By selecting an entity, we may see, through visual connectors, all the interrelated entities over the different time layers. User tests have shown that our visualization makes important information immediately perceivable, in a way that is easy to navigate and analyze.	entity;quantities of information	Sandra Gama;Daniel Gonçalves	2014		10.1145/2598153.2600043	information visualization;computer science;data mining;multimedia;creative visualization;world wide web	HCI	-32.0106491088156	-31.67848125063568	41338
2ff0fedf032946eec168ad81cbe4627c0b0f4c5a	temporal graph-based clustering for historical record linkage		Research in the social sciences is increasingly based on large and complex data collections, where individual data sets from different domains are linked and integrated to allow advanced analytics. A popular type of data used in such a context are historical censuses, as well as birth, death, and marriage certificates. Individually, such data sets however limit the types of studies that can be conducted. Specifically, it is impossible to track individuals, families, or households over time. Once such data sets are linked and family trees spanning several decades are available it is possible to, for example, investigate how education, health, mobility, employment, and social status influence each other and the lives of people over two or even more generations. A major challenge is however the accurate linkage of historical data sets which is due to data quality and commonly also the lack of ground truth data being available. Unsupervised techniques need to be employed, which can be based on similarity graphs generated by comparing individual records. In this paper we present results from clustering birth records from Scotland where we aim to identify all births of the same mother and group siblings into clusters. We extend an existing clustering technique for record linkage by incorporating temporal constraints that must hold between births by the same mother, and propose a novel greedy temporal clustering technique. Experimental results show improvements over non-temporary approaches, however further work is needed to obtain links of high quality.	cluster analysis;computer cluster;data quality;database;display resolution;es evm;family tree;file spanning;greedy algorithm;ground truth;linkage (software);linked data;public key certificate;the australian;unsupervised learning	Charini Nanayakkara;Peter Christen;Thilina Ranbaduge	2018	CoRR		record linkage;data mining;computer science;ground truth;data science;data quality;family tree;analytics;cluster analysis;complex data type;data set	DB	-12.54503988870093	-46.72073749698727	41343
af19ce99c32bcf19a58c57b1dda07592c31cf85f	the role of terrain modeling in lunar rover simulation	lunar rover;lunar terrain;lunar rover simulation;terrain modeling;space exploration initiative sei	This paper presents work being performed by Boeing on the next generation of lunar rovers as part of the Space Exploration Initiative (SEI). The current work has emphasized development of a lunar rover simulator. Such a simulator will be used for design and analysis of rover mobility system concepts and derivation of requirements for vehicle design and performance. The quality of rover design depends on the fidelity of the models that comprise the simulation tools. One of these models is a lunar terrain model that was developed in the course of work on the rover simulator. This model is the first step in the development of the rover mobility system simulation, for the design of the mobility system, which includes the drive, steering, and suspension systems. Mathematically modeling the interaction between the terrain and vehicle requires sound models of the terrain and the vehicle. This paper discusses the role of the lunar terrain model in rover simulation as part of the rover vehicle design process.	rover (the prisoner);simulation	Niranjan S. Rao;Matthew Appleby	1993	Simulation	10.1177/003754979306100107	aeronautics	Robotics	-23.01089366640532	-24.493016683613337	41417
8e51538715b296a057b5b963a40ea6b6bac27166	an offline framework for handling automatic passenger counting raw data	ridership data automatic passenger counting raw data handling service rearrangement italy cagliari bus operator ctm data records easy to read control dashboards bus frequencies offline framework apc data intelligible performance reports data validation bus stop data matching automatic passenger counting public transport companies operational planning bus routes;traffic engineering computing data handling intelligent transportation systems public transport;road transportation frequency planning global positioning system algorithm design and analysis;transit operations automatic passenger counting apc raw data matching algorithms	Knowledge of ridership data on bus routes is pivotal for the quality and efficient operational planning of public transport companies. Automatic passenger counting (APC) can represent a powerful resource for supporting this activity, because it can provide a databank of accurate counts. However, relevant challenges, such as the matching of data to the bus stop, data validation, tackling anomalies, and building intelligible performance reports, must be faced in order to make APC data a mainstream source of information. This paper proposes an offline framework for addressing these challenges. In order to illustrate a possible application of the framework, its use for setting bus frequencies is investigated. The results are represented by easy-to-read control dashboards composed of tables and graphs. The methodology is experimentally tested with data records provided by the bus operator CTM in Cagliari, Italy. Finally, we discuss the implications on service rearrangement.	data validation;experiment;information source;online and offline	Benedetto Barabino;Massimo Di Francesco;Sara Mozzoni	2014	IEEE Transactions on Intelligent Transportation Systems	10.1109/TITS.2014.2315573	embedded system;engineering;transport engineering;computer security	Visualization	-17.953395898071022	-31.659317228607296	41445
e9a1badf55695f956f4deb69ae8b4fae52965dc1	collaborative error-reflected models for cold-start recommender systems	modelizacion;explicit rate;prediction error;cold start problems;computer model;recommandation;useful information;informacion util;a froid;modelisation;estimation erreur;recommender system;collaborative filtering;error estimation;reflection model;estimacion error;recomendacion;en frio;recommendation;cold process;building model;modeling;recommender systems;information utile	Collaborative Filtering (CF), one of the most successful technologies among recommender systems, is a system assisting users to easily find useful information. One notable challenge in practical CF is the cold start problem, which can be divided into cold start items and cold start users. Traditional CF systems are typically unable to make good quality recommendations in the situation where users and items have few opinions. To address these issues, in this paper, we propose a unique method of building models derived from explicit ratings and we apply the models to CF recommender systems. The proposed method first predicts actual ratings and subsequently identifies prediction errors for each user. From this error information, pre-computed models, collectively called the error-reflected model, are built. We then apply the models to new predictions. Experimental results show that our approach obtains significant improvement in dealing with cold start problems, compared to existing work.	cold start;recommender system	Heung-Nam Kim;Abdulmotaleb El-Saddik;GeunSik Jo	2011	Decision Support Systems	10.1016/j.dss.2011.02.015	simulation;systems modeling;cold start;computer science;artificial intelligence;marketing;collaborative filtering;machine learning;mean squared prediction error;data mining;database;world wide web;statistics;recommender system	ECom	-19.910555325844896	-49.399004728238005	41455
c56c01eaf51621625181ef3d5b91cbb41ed901be	modeling traffic accidents caused by random misperception		Understanding the formation of accidents is of major importance to the automotive industry, its related businesses and policymakers. This is not a trivial task considering the current stream of innovations driven by the development of autonomous vehicles. Historical accident data are inadequate for gauging the safety of future traffic systems. To cope with this challenge, we propose a microscopic traffic model that introduces small errors due to random misperception as an omnipresent cause for accidents - an issue affecting both human drivers and control systems of autonomous vehicles. We model errors dynamically by stochastic processes and investigate their impact on the safety and the efficiency of traffic systems by Monte Carlo simulations. We focus on two case studies: a simple one-lane road segment and a t-junction with turning vehicles.		V. Berkhahn;Marcel Kleiber;Chris Schiermeyer;Stefan Weber	2018	2018 21st International Conference on Intelligent Transportation Systems (ITSC)	10.1109/ITSC.2018.8569483		Robotics	-18.267706087738418	-25.540181219876487	41456
7170fc45cc12cb3acd29aa433a7b47db72286226	information filtering in complex weighted networks	distributed application;measurement error;articulo;complex network;interaction strength;information filtering;weight distribution;statistical significance;network analysis;complex system;null model;tools and techniques	Many systems in nature, society, and technology can be described as networks, where the vertices are the system's elements, and edges between vertices indicate the interactions between the corresponding elements. Edges may be weighted if the interaction strength is measurable. However, the full network information is often redundant because tools and techniques from network analysis do not work or become very inefficient if the network is too dense, and some weights may just reflect measurement errors and need to be be discarded. Moreover, since weight distributions in many complex weighted networks are broad, most of the weight is concentrated among a small fraction of all edges. It is then crucial to properly detect relevant edges. Simple thresholding would leave only the largest weights, disrupting the multiscale structure of the system, which is at the basis of the structure of complex networks and ought to be kept. In this paper we propose a weight-filtering technique based on a global null model [Global Statistical Significance (GloSS) filter], keeping both the weight distribution and the full topological structure of the network. The method correctly quantifies the statistical significance of weights assigned independently to the edges from a given distribution. Applications to real networks reveal that the GloSS filter is indeed able to identify relevant connections between vertices.	aphasia, global;complex network;concentrate dosage form;information filtering system;interaction;largest;models, statistical;network theory;null value;null model;p-value;personnameuse - assigned;thresholding (image processing);vertex (geometry);vertex (graph theory);weight;weighted network	Filippo Radicchi;José J. Ramasco;Santo Fortunato	2011	Physical review. E, Statistical, nonlinear, and soft matter physics	10.1103/PhysRevE.83.046101	complex systems;combinatorics;null model;network analysis;weight distribution;mathematics;statistical significance;complex network;statistics;observational error	ML	-15.250742971602381	-39.76394727939774	41503
9217a40ca3160943158841e1425cf255cf31e43f	a new approach to predict user mobility using semantic analysis and machine learning	global positioning system (gps) coordinates;instantaneous prediction;markov chain model;mobility prediction;naïve bayesian classifier;short message service (sms)	Mobility prediction is a technique in which the future location of a user is identified in a given network. Mobility prediction provides solutions to many day-to-day life problems. It helps in seamless handovers in wireless networks to provide better location based services and to recalculate paths in Mobile Ad hoc Networks (MANET). In the present study, a framework is presented which predicts user mobility in presence and absence of mobility history. Naïve Bayesian classification algorithm and Markov Model are used to predict user future location when user mobility history is available. An attempt is made to predict user future location by using Short Message Service (SMS) and instantaneous Geological coordinates in the absence of mobility patterns. The proposed technique compares the performance metrics with commonly used Markov Chain model. From the experimental results it is evident that the techniques used in this work gives better results when considering both spatial and temporal information. The proposed method predicts user’s future location in the absence of mobility history quite fairly. The proposed work is applied to predict the mobility of medical rescue vehicles and social security systems.	algorithm;ambulances;bayesian network;drug vehicle;hoc (programming language);location-based service;matching;machine learning;markov chain;markov model;mobile health unit;mobile device;naive bayes classifier;privacy;randomness;rule (guideline);seamless3d;smart device;social security program;social media;solutions;winsock;sentence;standards characteristics	Roshan Fernandes;Rio G. L. D'Souza	2017	Journal of Medical Systems	10.1007/s10916-017-0837-x	computer security;mobile ad hoc network;data mining;wireless network;naive bayes classifier;short message service;location-based service;markov model;machine learning;mobility model;artificial intelligence;markov chain;medicine	HCI	-17.76857922904995	-33.85363939992003	41535
47efe0aee8d52b94eee1b3164ed2c98210614bf0	semi-automated driving: how does the supported task affect driver response?		In terms of impact on driving, typologies of automation have sometimes distinguished between quite coarse levels of the driving task, have tended not to focus specifically on the interaction between automation and the precise task being taken over by an automated system. An experiment in the UK project EASY allows an examination of the impact of automated support on different elements in vehicle control. Which aspect of vehicle control that was substituted, longitudinal or lateral control, had an impact on operator engagement in the driving task.	action selection;automation;autonomous car;lateral thinking;semiconductor industry	Oliver M. J. Carsten;Frank C. H. Lai;Yvonne Barnard	2010		10.3182/20100831-4-FR-2021.00074	embedded system;simulation;engineering;automotive engineering	Robotics	-19.44725798817934	-25.324065338449028	41546
44ab8fa978bdd8bc44e7a7c67cddf703ad4ac7fb	opinions analysis in social networks for cultural heritage applications		Social media provide a great amount of valuable information in the form of messages posted by users. Information extracted from posts can be considered like features giving insights about the preferences of users towards certain events. These features can be used to generate recommendations looking forward for upcoming events they might find interesting. In this work we present system for opinion analysis from tweets and recommendation of cultural heritage events. At this aim, we detect the events of interest from Tweets and propose a methodology for associating a sentiment degree with a tweet using NLP techniques.	social network	Flora Amato;Giovanni Cozzolino;Sergio Di Martino;Antonino Mazzeo;Vincenzo Moscato;Antonio Picariello;Sara Romano;Giancarlo Sperlì	2016		10.1007/978-3-319-39345-2_51	social science;industrial heritage;cultural heritage;political science;socioeconomics;cultural heritage management;anthropology	ML	-25.54837715307425	-48.005901607367505	41571
df1e3a5384df4d1865c42b5b6b4c88f45d01d058	toward quantitative measures for the semantic quality of polygon generalization	keywords;ucl;semantics;discovery;mesures;theses;conference proceedings;semantique;generalisation;quality assessment;digital web resources;mots cles;ucl discovery;open access;measures;ucl library;book chapters;open access repository;evaluation de la qualite;generalization;ucl research	Map generalization changes the semantics and geometry of map objects according to the context defined by users. How to evaluate and ensure the quality of generalization has become a major issue in contemporary digital cartography. The change in semantics after generalization has been studied much less than the other two aspects (geometry and topology). This research investigates the effect of generalization operations on the semantics of map objects. A set of quantitative measures for semantic change is put forward. A case study of a land-use map is implemented to illustrate the practical usefulness of these proposed measures, with a merging operation as an example of polygon generalization. The results indicate that these measures are not only sound in theory but also meaningful in practice.		Tao Cheng;Zhilin Li	2006	Cartographica	10.3138/0172-6733-227U-8155	generalization;geography;computer science;artificial intelligence;data mining;mathematics;semantics;cartographic generalization;cartography	Graphics	-9.011608131756292	-24.225861531431175	41688
5c2b641bd247645ff91a59fcae5587ea1f668569	a participant contribution trust scheme for crisis response systems		When a crisis occurs, an immediate response by rescue personnel is crucial. Decisions for a rescue plan are based solely on data about the crisis from the location. It stands to reason that increasing the amount of such data will result in a faster, efficient rescue response. To make this possible, a crisis response system accepts inputs from people near the crisis via their handheld sensor devices such as smartphones and tablets through a participatory sensing system. However, receiving data from the public could potentially result in corrupted and inaccurate data that will negatively impact the rescue plans. Given that risk, assessing the accuracy of the participant's data contribution becomes essential. In this paper, we present a Participant Contribution Trust (PCT) scheme. PCT aims to provide the crisis response system only with the trusted accurate contributions. The steps involved in filtering the contributions include splitting the crisis area into sectors, comparing the contributions with other intra- and inter-sector contributions and confirming the accuracy of the sensed data. Our experimental results show that PCT has a high detection rate for eliminating inaccurate contributions resulting in the delivery of the most accurate data to the crisis response system.	handheld game console;participatory sensing;smartphone;tablet computer	Mohannad A. Alswailim;Hossam S. Hassanein;Mohammad Zulkernine	2017	GLOBECOM 2017 - 2017 IEEE Global Communications Conference	10.1109/GLOCOM.2017.8253927	real-time computing;participatory sensing;computer science;mobile device	Mobile	-21.423819115662337	-27.5872367862258	41717
103a7ce833d601ef51e207b8295486d93319871a	syskill & webert: identifying interesting web sites	learning algorithm;web pages;learning;information retrieval;software agent;naive bayesian classifier;user profile;internet;machine learning;artificial intelligence;world wide web;s codes;algorithms;mathematics computers information science management law miscellaneous	We describe Syskill & Webert, a software agent that learns to rate pages on the Worm Wide Web (WWW), deciding what pages might interest a user. The user rates explored pages on a three point scale, and Syskill & Webert learns a user profile by analyzing the information on a page. The user profile can be used in two ways. First, it can be used to suggest which links a user would be interested in exploring. Second, it can be used to construct a LYCOS query to find pages that would interest a user. We compare four different learning algorithms and TF-IDF, an approach to weighting words used in information retrieval	algorithm;bayesian network;home page;information retrieval;machine learning;mega man network transmission;naive bayes classifier;overhead (computing);software agent;tf–idf;user profile;www;web search engine;world wide web	Michael J. Pazzani;Jack Muramatsu;Daniel Billsus	1996			web service;the internet;computer science;artificial intelligence;data science;software agent;machine learning;web navigation;web page;data mining;world wide web;web server	Web+IR	-29.738908582761358	-52.00458624853983	41782
ffc6e1a2d7fa5d7c7800f32162cafc9dd69b9e5c	web personalization and cohort information services for natural resource managers		Bing and Google are finely tuned to quickly serve the frequent and popular information needs of the masses. Topic specificity, customizability, and automatically pursuing the long term unique information needs of individual users are not among the strengths of current main stream search engines (Jansen, Spink, and Saracevic 2000) (Teevan, Dumais, and Horvitz 2005). This gap has inspired web personalization and collaborative information seeking tools such as Google Alerts and has encouraged topic-specific blogs and podcasts. Web personalization tools lie on a spectrum between individualized and fully coordinated searches, between short and long term information interests and between public and private information needs. Much research attention has recently focused on web personalization (Castellano and Torsello 2009) (Smyth et al. 2009) (Chu and Park 2009) (Memari, Amer, and Gmez 2010) (Stamou and Ntoulas 2009) (Lacomme, Demazeau, and Camps 2010) (Amin and Nayak 2010). We aim to address yet unanswered questions in web personalization by providing an integrated view of documents found through different tools, considering user confidentiality, emphasizing the benefits of client-side web personalization, and highlighting the power of social webpage recommendation when traditional information retrieval and collaborative filtering methods are used in conjunction. These principles define a framework which leverages groupings of users with overlapping interests called user cohorts.	bespoke;blog;client-side;collaborative filtering;collaborative information seeking;confidentiality;google alerts;information needs;information retrieval;personalization;personally identifiable information;podcast;sensitivity and specificity;web page;web search engine	Crystal Redman	2011			knowledge management;personalization;web intelligence;world wide web	Web+IR	-30.958721636923617	-48.93987234052173	41799
8e2d3a4ea1597452cad05f69508d280050465c64	ftw: fast similarity search under the time warping distance	databases;time warp;query processing;distance measure;search method;sampling;search cost;time series data;preprocessing;ip flows;dynamic time warping;similarity search	Time-series data naturally arise in countless domains, such as meteorology, astrophysics, geology, multimedia, and economics. Similarity search is very popular, and DTW (Dynamic Time Warping) is one of the two prevailing distance measures. Although DTW incurs a heavy computation cost, it provides scaling along the time axis. In this paper, we propose FTW (Fast search method for dynamic Time Warping), which guarantees no false dismissals in similarity query processing. FTW efficiently prunes a significant number of the search cost. Experiments on real and synthetic sequence data sets reveals that FTW is significantly faster than the best existing method, up to 222 times.	apache axis;computation;database;dynamic time warping;for the win;image scaling;similarity search;synthetic data	Yasushi Sakurai;Masatoshi Yoshikawa;Christos Faloutsos	2005		10.1145/1065167.1065210	sampling;computer science;theoretical computer science;machine learning;dynamic time warping;search cost;time series;data mining;preprocessor	DB	-4.911863353370446	-41.08528944970149	42031
2749a080779de86c7fdfa015673d1c5ac861f89c	fuzzy collaborative filtering approach based on semantic distance	fuzzy set;semantic distance;collaborative filtering	The problem of building recommender systems has attracted considerable attention in recent years. Collaborative Filtering (CF) is one of the most successful and widely used approaches in recommend system. Traditional collaborative filtering requires explicit user participation for providing his/her interest to the items. In this paper, we propose a novel collaborative filtering approach based on the fuzzy set theory, in which we originally introduced the fuzzy set and semantic distance metric to improve the sharp boundary problem of rating values fundamentally. The experimental results demonstrate that the proposed methods can solve the sharp boundary problem of rating items and achieve a much more desirable performance than the traditional CF.	algorithm;collaborative filtering;fuzzy set;recommender system;semantic similarity;set theory	Junhuai Li;Xue-song Li;Hailing Liu;Xi-jie Han;Jing Zhang	2009		10.1007/978-3-642-03664-4_21	mathematical optimization;artificial intelligence;collaborative filtering;machine learning;data mining;mathematics;recommender system	AI	-21.51174266834537	-48.06431031295179	42059
bd4d727c3c2a34d88785bdabab1cc27e605d136b	correlating mobile phone usage and travel behavior - a case study of harbin, china	information and communication technologies icts;human mobility;mobile phone;geographic knowledge discovery	Information and communication technologies (ICTs), such as mobile phones and the Internet, are increasingly pervasive in modern society. These technologies provide new resources for spatio-temporal data mining and geographic knowledge discovery. Since the development of ICTs also impacts physical movement of individuals in societies, much of the existing research has focused on examining the correlation between ICT and human mobility. In this paper, we aim to provide a deeper understanding of how usage of mobile phones correlates with individual travel behavior by exploring the correlation between mobile phone call frequencies and three indicators of travel behavior: (1) radius, (2) eccentricity, and (3) entropy. The methodology is applied to a large dataset from Harbin city in China. The statistical analysis indicates a significant correlation between mobile phone usage and all of the three indicators. In addition, we examine and demonstrate how explanatory factors, such as age, gender, social temporal orders and characteristics of the built environment, impact the relationship between mobile phone usage and individual	data mining;distance (graph theory);emergency response systems;entropy (information theory);geographic information science;geographic information system;individual mobility;inferential theory of learning;internet;location-based service;mobile app;mobile phone;p versus np problem;pervasive informatics;population;randomness;real-time locating system;simulation;supra, inc.	Yihong Yuan;Martin Raubal;Yu Liu	2012	Computers, Environment and Urban Systems	10.1016/j.compenvurbsys.2011.07.003	simulation;geography;advertising;internet privacy	HCI	-19.999012884601626	-34.609233446985264	42102
d7f88f17b5388ad560a1164953feaa440ed0863b	personalization of search results using interaction behaviors in search sessions	generic model;information retrieval;implicit feedback;data collection;user preferences;personalization;personalized search;prediction model;user interaction;information seeking;relevance feedback;task type;search behaviors;document usefulness	Personalization of search results offers the potential for significant improvement in information retrieval performance. User interactions with the system and documents during information-seeking sessions provide a wealth of information about user preferences and their task goals. In this paper, we propose methods for analyzing and modeling user search behavior in search sessions to predict document usefulness and then using information to personalize search results. We generate prediction models of document usefulness from behavior data collected in a controlled lab experiment with 32 participants, each completing uncontrolled searching for 4 tasks in the Web. The generated models are then tested with another data set of user search sessions in radically different search tasks and constrains. The documents predicted useful and not useful by the models are used to modify the queries in each search session using a standard relevance feedback technique. The results show that application of the models led to consistently improved performance over a baseline that did not take account of user interaction information. These findings have implications for designing systems for personalized search and improving user search experience.	baseline (configuration management);information retrieval;interaction information;personalization;personalized search;relevance feedback;session (web analytics);uncontrolled format string;user (computing);world wide web	Chang Liu;Nicholas J. Belkin;Michael J. Cole	2012		10.1145/2348283.2348314	semantic search;computer science;concept search;data mining;personalization;predictive modelling;search analytics;world wide web;information retrieval;search engine;statistics;data collection;human–computer information retrieval	Web+IR	-33.48087443463284	-52.03010104651927	42168
77a8bab31af39ce589e7fc0ff59234d4e41cac9b	twittener: listen to your twitter feed		Twitter is a popular social media site, as it allows users to get rapid u0026 concise information, and to follow the latest online trends u0026 topics. This project aims to improve user experience by proposing an alternative way to interact with Twitter, by allowing users to listen to interesting tweets, instead of the conventional way of reading them. This will allow users to get up to date with tweets from publicly-listed, categorized Twitter accounts, without needing to pay full attention to their screens. This could prove useful for populations with physical disabilities, visual impairments, the elderly and persons who multitask. A web application, called Twittener, has been developed to allow users to listen to tweets. Additionally, a console application periodically crawls through Twitter retrieving u0026 converting tweets from text to speech, thus making up the Twittener system.	categorization;computer multitasking;console application;population;social media;speech synthesis;user experience;web application	Yohan Fernandopulle;Rianne Wally Meurzec;Ng Hong Quan;Fairul Akmaruddin;Owen Noel Newton Fernando	2017		10.1145/3059454.3078707	console application;sentiment analysis;multimedia;web application;internet privacy;topic model;computer science;user experience design;social media;html5;speech synthesis	HCI	-27.28897348303321	-45.173741276745005	42176
b36652b6c34cf701c2c5e5af083f69927d2652e8	naturalistic driving data for a smart cloud-based abnormal driving detector		This paper examines a possible implementation of video and radar data into smart abnormal driving behavior detecting systems. A prevailing research is SafeDrive, which positions the application in a successful trajectory in identifying driving anomalies to improve societal transportation safety. However, there are limitations of road and environment data that could allow mobile phone-based applications to accurately evaluate driving abnormality. In this paper we propose utilizing external research from the Second Strategic Highway Research Program (SHRP2), which can provide video and radar data for the improvement of detecting and evaluating a driver's atypical behaviors. The collection of data allows a deep study on safety, renewal, capacity, and reliability in a vehicle's actions that could permit transportation organizations to efficiently assess security operatives. Additionally, the evaluation of gathered data encompasses tools that determine and discuss features of both a vehicle and its driver, which influence driving styles linked to the near-crash or crash events. The Naturalistic Driving Data (NDD), supplies detailed information and examination of a human-vehicle-interaction to better comprehend abnormal driving behavior and critical factors that lead to most traffic accidents.	anomaly detection;cloud computing;mobile phone;radar;sensor	Athina Rosales;Md. Zakirul Alam Bhuiyan;Guojun Wang;Tian Wang;Xiaofei Xing;Abdulhameed Alelaiwi	2017	2017 IEEE SmartWorld, Ubiquitous Intelligence & Computing, Advanced & Trusted Computed, Scalable Computing & Communications, Cloud & Big Data Computing, Internet of People and Smart City Innovation (SmartWorld/SCALCOM/UIC/ATC/CBDCom/IOP/SCI)	10.1109/UIC-ATC.2017.8397449	computer science;simulation;distributed computing;mobile phone;radar;cloud computing;abnormality;detector;crash	HCI	-18.997259798706228	-27.36726052764164	42241
b860334cf6a453f2a56d3d106de1581bef6b28e5	development of ar information system based on deep learning and gamification		Recently, several AR systems have been developed and used in various fields. However, in most AR systems, there are some restrictions caused by the usage of AR marker or location information. In this research, in order to solve these problems, AR information system that can recognize object itself based on deep learning was developed. In particular, this system was constructed using client-server model so that the machine learning can be updated while operating the system. In addition, the method of gamification was introduced to gather the learning data automatically from the users when they use the system. The prototype was applied to the AR zoo information system and the effectiveness of the proposed system was validated in the evaluation experiment.		Tetsuro Ogi;Yusuke Takesue;Stephan Lukosch	2018		10.1007/978-3-319-98530-5_41	deep learning;information system;machine learning;distributed computing;computer science;artificial intelligence	ML	-25.14094154448227	-42.89743929692597	42309
5cca126a0f859b93eab4214f646dfbaaa69cc115	automatic versus human navigation in information networks	browsing;search;navigation;wikispeedia;wikispedia	People regularly face tasks that can be understood as navigation in information networks, where the goal is to find a path between two given nodes. In many such situations, the navigator only gets local access to the node currently under inspection and its immediate neighbors. This lack of global information about the network notwithstanding, humans tend to be good at finding short paths, despite the fact that realworld networks are typically very large. One potential reason for this could be that humans possess vast amounts of background knowledge about the world, which they leverage to make good guesses about possible solutions. In this paper we ask the question: Are human-like high-level reasoning skills really necessary for finding short paths? To answer this question, we design a number of navigation agents without such skills, which use only simple numerical features. We evaluate the agents on the task of navigating Wikipedia, a domain for which we also possess large-scale human navigation data. We observe that the agents find shorter paths than humans on average and therefore conclude that, perhaps surprisingly, no sophisticated background knowledge or high-level reasoning is required for navigating the complex Wikipedia network.	high- and low-level;humans;numerical analysis;wikipedia	Robert West;Jure Leskovec	2012			navigation;simulation;computer science;artificial intelligence;machine learning;world wide web	Web+IR	-30.976606271533843	-46.94000704448807	42352
0b92f155a797a853900372aadd3b68e0450da2f3	on deriving tagsonomies: keyword relations coming from crowd	social bookmarking;information retrieval;parent child relationship;text classification;web based system;social tagging;user model	Many keyword-based approaches to text classification, information retrieval or even user modeling for adaptive web-based system could benefit from knowledge on relations between various keywords, which gives further possibilities to compare them, evaluate their distance etc. This paper proposes an approach how to determine keyword relations (mainly a parent-child relationship) by leveraging collective wisdom of the masses, present in data of collaborative (social) tagging systems on the Web. The feasibility of our approach is demonstrated on the data coming from the social bookmarking systems delicious and CiteULike.	algorithm;cognitive science;document classification;experiment;folksonomy;graph theory;information retrieval;spreading activation;tag (metadata);user modeling;web 2.0;web application;wordnet;world wide web	Michal Barla;Mária Bieliková	2009		10.1007/978-3-642-04441-0_27	user modeling;computer science;data mining;world wide web;information retrieval	AI	-27.183254539472593	-50.24205059492786	42396
f7099a705e263e213afb1ea83a7f16a630eab1f7	a data-driven study of influences in twitter communities	social networking online social aspects of automation;twitter communities integrated circuit modeling crawlers predictive models measurement;first influencer information diffusion model twitter community influences microblogging service user influence influence measurement service klout peerindex	This paper presents a quantitative study of Twitter, one of the most popular micro-blogging services, from the perspective of user influence. We crawl several datasets from the most active communities on Twitter and obtain 20.5 million user profiles, along with 420.2 million directed relations and 105 million tweets among the users. User influence scores are obtained from influence measurement services, Klout and PeerIndex. Our analysis reveals interesting findings of the structural properties of Twitter communities. Most importantly, we observe that whether a user retweets a message is strongly influenced by the first of his followees who posted that message. To capture such an effect, we propose the first influencer (FI) information diffusion model and show through extensive evaluation that compared to the widely adopted independent cascade model, the FI model is more stable and more accurate in predicting influence spreads in Twitter communities.	blog;user profile	Huy Nguyen;Rong Zheng	2014	2014 IEEE International Conference on Communications (ICC)	10.1109/ICC.2014.6883936	multimedia;internet privacy;world wide web	Metrics	-20.969553439601786	-44.89858964976931	42424
2fd80a588fc6a488d4140a9af15c41940e9afef9	visual perception in design and robotics	visual openness;human visual perception;visual perception;theoretical consideration;scene description;probabilistic process;perceptual robotics;visual openness measurement;visual information;visual attention	Studies on human visual perception are described. The visual perception is mathematically modelled as a probabilistic process obtaining and interpreting visual information from an environment. By means of this model some other vision related concepts, such as visual attention and visual openness, are also mathematically defined. The theoretical considerations are implemented in three applications, namely scene description by perception, visual openness measurement for design, and perceptual robotics.	autonomous robot;color vision;computation;industrial robot;list of code lyoko episodes;mathematical model;openness;perceptual robotics;portable document format;probabilistic automaton;prototype;real-time transcription;robotic mapping;statistical model;the circle (file system);virtual reality	Michael S. Bittermann;I. Sevil Sariyildiz;Özer Ciftcioglu	2007	Integrated Computer-Aided Engineering		computer vision;visual analytics;simulation;structural information theory;computer science;human visual system model;vision science	Robotics	-31.701058020796175	-27.45114992208776	42428
9cdc024e3bdac7fe735d820d2fe2349518bc48e0	competing memes propagation on networks: a case study of composite networks	competition;network science;composite networks;propagation	"""If a false rumor propagates via Twitter, while the truth propagates between friends in Facebook, which one will prevail? This question captures the essence of the problem we address here. We study the intertwined propagation of two competing """"memes"""" (or viruses, rumors, products etc.) in a composite network. A key novelty is the use of a composite network, which in its simplest model is defined as a single set of nodes with two distinct types of edges interconnecting them. Each meme spreads across the composite network in accordance to an SIS-like propagation model (a flu-like infection-recovery). To study the epidemic behavior of our system, we formulate it as a non-linear dynamic system (NLDS). We develop a metric for each meme that is based on the eigenvalue of an appropriately constructed matrix and argue that this metric plays a key role in determining the """"winning"""" meme. First, we prove that our metric determines the tipping point at which both memes become extinct eventually. Second, we conjecture that the meme with the strongest metric will most likely prevail over the other, and we show evidence of that via simulations in both real and synthetic composite networks. Our work is among the first to study the interplay between two competing memes in composite networks."""	dynamical system;meme;nonlinear system;norm (social);simulation;software propagation;synthetic intelligence	Xuetao Wei;Nicholas Valler;B. Aditya Prakash;Iulian Neamtiu;Michalis Faloutsos;Christos Faloutsos	2012	Computer Communication Review	10.1145/2378956.2378958	network science;competition;artificial intelligence	Web+IR	-17.414753797132306	-39.48796328925354	42469
d8031f037315f3b888c915fef0fe11f1a19d1965	evolving latent space model for dynamic networks		Networks observed in real world like social networks, collaboration networks etc., exhibit temporal dynamics, i.e. nodes and edges appear and/or disappear over time. In this paper, we propose a generative, latent space based, statistical model for such networks (called dynamic networks). We consider the case where the number of nodes is fixed, but the presence of edges can vary over time. Our model allows the number of communities in the network to be different at different time steps. We use a neural network based methodology to perform approximate inference in the proposed model and its simplified version. Experiments done on synthetic and real world networks for the task of community detection and link prediction demonstrate the utility and effectiveness of our model as compared to other similar existing approaches. To the best of our knowledge this is the first work that integrates statistical modeling of dynamic networks with deep learning for community detection and link prediction.	approximation algorithm;artificial neural network;deep learning;social network;statistical model;synthetic intelligence	Shubham Gupta;Gaurav Sharma;Ambedkar Dukkipati	2018	CoRR		generative grammar;computer science;artificial intelligence;machine learning;deep learning;artificial neural network;approximate inference;social network;statistical model	AI	-16.135429853099875	-42.20243372176134	42534
09b19e72c87e1243def763f395d89ca7a4b0aa47	efficient processing of similarity search under time warping in sequence databases: an index-based approach	time warp;distance function;computacion informatica;time warping distance;satisfiability;feature vector;multi dimensional;indexing;ciencias basicas y experimentales;indexation;synthetic data;sux tree;grupo a;sequence database;similarity search	This paper discusses an effective processing of similarity search that supports time warping in large sequence databases. Time warping enables finding sequences with similar patterns even when they are of different lengths. Previous methods for processing similarity search that supports time warping fail to employ multi-dimensional indexes without false dismissal since the time warping distance does not satisfy the triangular inequality. They have to scan all the database, thus suffer from serious performance degradation in large databases. Another method that hires the suffix tree, which does not assume any distance function, also shows poor performance due to the large tree size. In this paper, we propose a novel method for similarity search that supports time warping. Our primary goal is to enhance the search performance in large databases without permitting any false dismissal. To attain this goal, we devise a new distance function Dtw−lb that consistently underestimates the time warping distance and also satisfies the triangular inequality. Dtw−lb uses a 4-tuple feature vector that is extracted from each sequence and is invariant to time warping. For efficient processing of similarity search, we employ a multi-dimensional index that uses the 4-tuple feature vector as indexing attributes and Dtw−lb as a distance function. We prove that our method does not incur false dismissal. To verify the superiority of our method, we perform extensive experiments. The results reveal that our method achieves significant speedup up to 43 times with a data set containing real-world S&P 500 stock data sequences and up to 720 times with data sets containing a very large volume of synthetic data sequences. The performance gain becomes larger: (1) as the number of data sequences gets larger, (2) the average length of data sequences gets longer, and (3) as the tolerance in a query gets smaller. Considering the characteristics of real databases, these tendencies imply that our approach is suitable for practical applications.	elegant degradation;experiment;feature vector;information retrieval;sequence database;similarity search;social inequality;speedup;suffix tree;synthetic data	Sang Wook Kim;Sanghyun Park;Wesley W. Chu	2004	Inf. Syst.	10.1016/S0306-4379(03)00037-1	search engine indexing;feature vector;metric;computer science;theoretical computer science;machine learning;dynamic time warping;sequence database;data mining;database;satisfiability;synthetic data	DB	-5.427145280496502	-40.862309147902465	42624
a66b48b7587eff31405289a50c7288e31dd1c6a2	a 'pumping' model for the spreading of computer viruses	link analysis;computer viruses;web pages;directed graph;eigenvectors	We present qualitative arguments concerning the probable infection pattern in a directed graph under the (weak or strong)  influence of the outside world. This question is relevant for real computer viruses, which spread by following the (logical)  directed links formed by address lists. Our arguments build on previous work in two (seemingly unrelated) areas: epidemic  spreading on undirected graphs, and eigenvectors of directed graphs as applied to Web page ranking. More specifically, we  borrow a recently proven result (used to design a ’sink remedy’ for Web link analysis) and use it to argue for a threshold effect: that the effects of the outside world will not appear in the pattern of infection until the strength of the influence of  the outside world exceeds a finite threshold value. We briefly discuss possible tests of this prediction, and its implications.  	computer virus;pumping (computer systems)	Geoffrey Canright;Kenth Engø-Monsen	2007				Theory	-20.705252413926765	-40.046118844536736	42648
5f3f765e386665010bc70aa69c31f0f1ba438bc2	exploring spatiotemporal characteristics of intra-urban trips using metro smartcard records	town and country planning;sun transportation irrigation argon;irrigation;public transport;transportation data acquisition data mining geographic information systems geophysical techniques geophysics computing smart cards spatiotemporal phenomena town and country planning;data mining;argon;smartcard record;geophysics computing;smart cards;geographic information systems;transportation;sun;spatiotemporal phenomena;public transport smartcard record intra urban trip spatiotemporal pattern;public transport spatiotemporal characteristics intraurban trips metro smartcard records urban system urban planning spatiotemporal patterns shenzhen city china living habit working habit passenger volumes;intra urban trip;data acquisition;spatiotemporal pattern;geophysical techniques	Understanding the characteristics of intra-urban trips is essential to get a deep insight of the dynamic aspects of urban system and to make urban planning. We explore the spatiotemporal patterns of human intra-urban trips using metro smartcard records of Shenzhen city. Through statistics of millions of smartcard records, we found that the intra-urban trips: (a) have two significant peak hours over day; (b) are different between weekday and weekend; and (c) have significant periodicity. The temporal patterns owe to the living and working habit of the inhabitants. The result also shows that passengers' volumes, as well as the spatiotemporal patterns, are various for different stations, due to the land uses around stations. The method shows that metro smartcard records provide a powerful approach to understanding the dynamic of urban system.	emoticon;quasiperiodicity;smart card;spatiotemporal pattern	Yongxi Gong;Yu Liu;Yaoyu Lin;Jian Yang;Zhongyuan Duan;Guicai Li	2012	2012 20th International Conference on Geoinformatics	10.1109/Geoinformatics.2012.6270316	geography;transport engineering;cartography	ML	-17.901850011030845	-32.570832076707134	42697
ee2784ded34fe72db849f5937a97db0bad4172b3	analyzing dynamics of peer-to-peer communication -from questionnaire surveys to agent-based simulation	agent based simulation;agent based model;small world;information content;network analysis;questionnaire survey;scale free;quality of information;community networks;information exchange;survey data;peer to peer communication;word of mouth;peer to peer;dynamic properties	This paper discusses dynamic properties of peer-to-peer communication networks, which emerge from information exchanges among people. First, we gather activity data of communication among people through questionnaires in order to categorize both information (contents) and people, then we develop agent-based simulation models to examine implicit mechanisms behind the dynamics. The agent-based models enable us to discover the quality of information exchanged and the preferences of specific communication groups. The simulation results have suggested that 1) peer-to-peer communication networks have scale-free and small world properties, 2) the characteristics of contents and users are observed in word-of-mouth communications, and 3) the combination of real survey data and agent-based simulation is effective.	simulation	Shinako Matsuyama;Takao Terano	2006		10.1007/978-3-540-76539-4_3	questionnaire;word of mouth;simulation;information exchange;self-information;network analysis;computer science;scale-free network;survey data collection;multimedia;information quality;world wide web	Robotics	-20.039709729397007	-41.05011155608446	42804
2102b289042a6b55e69e0f4f65db1862850844dc	dynamic prediction of communication flow using social context	social context;prediction error;information roles;support vector regression;social network;social networks;communication flow;communication delay;information diffusion;feature selection;myspace;social networking sites	In this paper, we develop a temporally evolving representation framework for context that can efficiently predict communication flow in social networks between a given pair of individuals. The problem is important because it facilitates determining social and market trends as well as efficient information paths among people. We describe communication flow by two parameters: the intent to communicate and communication delay. To estimate these parameters, we design features to characterize communication and social context. Communication context refers to the attributes of current communication. Social context refers to the patterns of participation in communication (information roles) and the degree of overlap of friends between two people (strength of ties). A subset of optimal features of the communication and social context is chosen at a given time instant using five different feature selection strategies. The features are thereafter used in a Support Vector Regression framework to predict the intent to communicate and the delay between a pair of individuals. We have excellent results on a real world dataset from the most popular social networking site, www.myspace.com. We observe interestingly that while context can reasonably predict intent, delay seems to be more dependent on the personal contextual changes and other latent factors characterizing communication, e.g. 'age' of information transmitted and presence of cliques among people.	clique (graph theory);feature selection;information;latent variable;social network;support vector machine;traffic flow (computer networking)	Munmun De Choudhury;Hari Sundaram;Ajita John;Dorée D. Seligmann	2008		10.1145/1379092.1379105	computer science;machine learning;feature selection;world wide web;social network	HCI	-18.728499921077454	-43.950068843525045	42826
1b8d39e76bbd6e8ac91119d907d48631267b3654	hierarchical fuzzy spectral clustering in social networks using spectral characterization		An important aspect of community analysis is not only determining the communities within the network, but also sub-communities and hierarchies. We present an approach for finding hierarchies in social networks that uses work from random matrix theory to estimate the number of clusters. The method analyzes the spectral fingerprint of the network to determine the level of hierarchy in the network. Using this information to inform the choice of clusters, the network is broken into successively smaller communities that are attached to their parents via Jaccard similarity. The efficacy of the approach is examined on two well known real world social networks as well as a political social network derived from campaign finance data. Introduction Many real world networks are characterized by dense subnetworks that are commonly referred to as communities and are generally composed of groups of nodes that have elements in common with each other. Examples of networks that have community structure can be drawn from social (Fortunato 2009), biological (Power et al. 2011), gene expression (Zhang and Horvath 2005), and many other types of networks. Since the communities can represent fundamental properties of the network, their discovery is important for understanding the nature of the networks (Newman and Girvan 2004),(Flake et al. 2002). The primary focus of this paper is on social networks. To best represent the communities, a classification of the nodes into clusters should satisfy two important realities of many social networks: overlap and hierarchy. For the first, nodes within the network may belong to multiple communities. Much like in human social groups, an individual may belong to more than one community or have multiple affiliations (Zhang, Wang, and Zhang 2007). Hierarchy is another important aspect of some social networks wherein smaller communities together make up larger ones. Military, business, and political hierarchies are all examples where individual smaller groups combine into a larger group. ∗also affiliated with the National Institute on Money in State Politics Copyright c © 2015, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved. There is already a wealth of research on finding communities within networks. Some initial work focused on crisp splits of the network into non-overlapping, non-hierarchical communities (Newman and Girvan 2004), (Newman 2006). As part of this, a method for evaluating the quality of a partitioning of the data into clusters was developed called modularity. The idea behind modularity is to determine how well a community split describes the likelihood of the community as it relates to a null model, where each node keeps the same degree but is connected at random to other nodes. This is defined by Q = ∑	algorithm;artificial intelligence;cluster analysis;evolving networks;experiment;fingerprint;fuzzy set;hierarchical clustering;jaccard index;null model;power supply;samuel newman;social network;spectral clustering	Scott Wahl;John Sheppard	2015			machine learning;jaccard index;artificial intelligence;hierarchical clustering of networks;community structure;computer science;hierarchical clustering;hierarchy;null model;social group;social network	AI	-14.803799662096015	-40.8075152097099	42829
4aa2cb0882c4a6586f43725eed37a67c8794ebe5	a new concise representation method of generalized frequent itemsets	set theory;taxnomy;data mining;profile summary;generalized frequent itemset;set theory data mining;itemsets ip networks taxonomy data mining abstracts lattices;closed generalized itemset profile summary data mining taxonomy data generalized frequent itemset mining cgip summary method concise representation method;profile summary taxnomy generalized frequent itemset	Mining generalized frequent item sets is one of important research area in data mining. Because not only the taxonomy data is widely exist, but also the information provided by the generalized frequent item sets is richer and valuable than the traditional frequent item sets. Like the traditional mining, the number of the generalized frequent item set is also very large, which make it difficult to do further analysis. We propose a new method called CGIP-summary, which represent the whole frequent generalized item sets by a set profiles and the profiles used to more concise.	algorithm;data mining	Yuxing Mao;Chenghong Zhang;Hong Ling	2012	2012 IEEE 15th International Conference on Computational Science and Engineering	10.1109/ICCSE.2012.21	data science;data mining;database;mathematics;set theory	DB	-7.44711992049586	-38.11822687494281	42839
54dfe436992b6ebe2d83eacb59a38f93efd1a525	memorysense: reconstructing and ranking user memories on mobile devices	human episodic memory memorysense user memories reconstruction user memories ranking mobile devices user centric information prone to forget human memory virtual sensors physical sensors sensor data semantic reasoning;motion pictures;sensors;smart phones;storage management inference mechanisms knowledge based systems mobile computing sensor fusion;sensors global positioning system smart phones mobile communication conferences motion pictures;global positioning system;mobile communication;conferences	The richness of user-centric information gathered by modern devices can be used to keep track of memorable events, therefore acting as a prosthesis of the prone-to-forget human memory. We propose to combine virtual and physical sensors from mobile devices to infer digital memories of user activities in a semi-supervised fashion. In MemorySense, sensor data is processed by a space and energy efficient algorithm to recognize basic activities. We then use semantic reasoning to aggregate these activities into the digital equivalent of a human episodic memory.	aggregate data;algorithm;mobile device;semi-supervised learning;semiconductor industry;sensor	Karl Aberer;Michele Catasta;Horia Radu;Jean-Eudes Ranvier;Matteo Vasirani;Zhixian Yan	2014	2014 IEEE International Conference on Pervasive Computing and Communication Workshops (PERCOM WORKSHOPS)	10.1109/PerComW.2014.6815199	embedded system;mobile search;simulation;mobile telephony;global positioning system;computer science;sensor;multimedia;internet privacy;computer security	Robotics	-24.27815910197613	-44.32044748358297	42850
37ecfb998ff8ca6dea7345ac1e3d389b8ee32eeb	analysis and control of epidemics: a survey of spreading processes on complex networks	analytical models;cs si;complex networks;math oc;medical services;statistical analysis;stochastic processes;mathematical model;medical control systems complex networks diseases graph theory;diseases;predictive models;mathematical epidemiology epidemics analysis epidemic model control complex networks mathematical epidemic models diseases;physics soc ph;epidemics;medical services epidemics statistical analysis mathematical model predictive models complex networks diseases stochastic processes analytical models	"""This article reviews and presents various solved and open problems in the development, analysis, and control of epidemic models. The proper modeling and analysis of spreading processes has been a long-standing area of research among many different fields, including mathematical biology, physics, computer science, engineering, economics, and the social sciences. One of the earliest epidemic models conceived was by Daniel Bernoulli in 1760, which was motivated by studying the spread of smallpox [1]. In addition to Bernoulli, there were many different researchers also working on mathematical epidemic models around this time [2]. These initial models were quite simplistic, and the further development and study of such models dates back to the 1900s [3]-[6], where still-simple models were studied to provide insight into how various diseases can spread through a population. In recent years, there has been a resurgence of interest in these problems as the concept of """"networks"""" becomes increasingly prevalent in modeling many different aspects of the world today. A more comprehensive review of the history of mathematical epidemiology can be found in [7] and [8]."""	aerial photography;bsd;bernoulli polynomials;biological system;complex network;complexity;computational geometry;computer engineering;computer science;control theory;convex optimization;deterministic algorithm;distributed control system;dynamical system;electrical engineering;embedded system;grasp;hgnc;hybrid system;independence day: resurgence;information and computer science;malware;markov chain;mathematical optimization;network science;population;robotics;social network;stochastic process;systems engineering;unmanned aerial vehicle;warren abstract machine;world wide web	Cameron Nowzari;Victor M. Preciado;George J. Pappas	2016	IEEE Control Systems	10.1109/MCS.2015.2495000	stochastic process;computer science;artificial intelligence;mathematical model;mathematics;predictive modelling;operations research;complex network;statistics	Theory	-18.495683557917094	-39.32501448582755	42886
ceb109a06c67e2048eb5c58afeaf8794b5fe49d2	subspace search and visualization to make sense of alternative clusterings in high-dimensional data	topology;display algorithms h 2 8 database applications data mining h 3 3 information search and retrieval selection process i 3 3 picture image generation;pattern clustering;h 2 8 database applications data mining;search problems data analysis data reduction data visualisation pattern clustering;display algorithms;data visualisation;h 3 3 information search and retrieval selection process;data analysis;visualization;high definition video algorithm design and analysis visualization clustering algorithms topology data visualization educational institutions;data visualization;high definition video;i 3 3 picture image generation;clustering algorithms;search problems;inproceedings;data reduction;navigation facilities subspace search subspace visualization high dimensional data clusterings explorative data analysis high dimensional data space hd data space dimensionality reduction cluster analysis visual interactive methods visual mappings hd input data space visual analysis interestingness guided subspace search algorithm subspace similarity functions;algorithm design and analysis	In explorative data analysis, the data under consideration often resides in a high-dimensional (HD) data space. Currently many methods are available to analyze this type of data. So far, proposed automatic approaches include dimensionality reduction and cluster analysis, whereby visual-interactive methods aim to provide effective visual mappings to show, relate, and navigate HD data. Furthermore, almost all of these methods conduct the analysis from a singular perspective, meaning that they consider the data in either the original HD data space, or a reduced version thereof. Additionally, HD data spaces often consist of combined features that measure different properties, in which case the particular relationships between the various properties may not be clear to the analysts a priori since it can only be revealed if appropriate feature combinations (subspaces) of the data are taken into consideration. Considering just a single subspace is, however, often not sufficient since different subspaces may show complementary, conjointly, or contradicting relations between data items. Useful information may consequently remain embedded in sets of subspaces of a given HD input data space. Relying on the notion of subspaces, we propose a novel method for the visual analysis of HD data in which we employ an interestingness-guided subspace search algorithm to detect a candidate set of subspaces. Based on appropriately defined subspace similarity functions, we visualize the subspaces and provide navigation facilities to interactively explore large sets of subspaces. Our approach allows users to effectively compare and relate subspaces with respect to involved dimensions and clusters of objects. We apply our approach to synthetic and real data sets. We thereby demonstrate its support for understanding HD data from different perspectives, effectively yielding a more complete view on HD data.	cluster analysis;clustering high-dimensional data;dataspaces;dimensionality reduction;embedded system;information;interactivity;norm (social);numerical analysis;programming paradigm;search algorithm;similarity measure;synthetic intelligence;visual analytics	Andrada Tatu;Fabian Maass;Ines Färber;Enrico Bertini;Tobias Schreck;Thomas Seidl;Daniel A. Keim	2012	2012 IEEE Conference on Visual Analytics Science and Technology (VAST)	10.1109/VAST.2012.6400488	algorithm design;data reduction;visualization;computer science;theoretical computer science;machine learning;data mining;mathematics;cluster analysis;data analysis;data visualization;statistics	Visualization	-27.19241991965783	-34.42105307109158	42920
cb6e5c954f99e19feaba42a24e8005e6b9a3ec05	location-aware friend recommendation in event-based social networks: a bayesian latent factor approach	event based social network;friend recommendation;bayesian latent factor model	In this paper we study the friend recommendation problem in event-based social networks (EBSNs). Effective friend recommendation is of benefit to EBSNs, since it can promote user interaction and accelerate information diffusion for promoted events. Different from usual friend recommendations, the aim of making friends in EBSNs is to better participate offline events and enhance user experience. Meanwhile friend recommendation in EBSNs encounters three types of data, i.e. geographical information, implicate user rating, and user behavior. These differences imply that existing friend recommendation approaches are not adequate any more for EBSNs. Under this background, in this paper we propose a Bayesian latent factor model, which can jointly formulate above three types of data, for friend recommendation with better event promotion and user experience. Results on real-world datasets show the efficacy of our approach.	online and offline;social network;user experience	Yao Lu;Zhi Qiao;Chuan Zhou;Yue Hu;Li Guo	2016		10.1145/2983323.2983883	data mining;world wide web	ML	-22.331891886286908	-45.41942430159306	42943
27e3daafe773860ab73a3c12c2ca890fa7bb93c9	visualization of meteorological data using an interactive flight	multidimensional data meteorological data visualization interactive flight large data sets geovis geoscientific data glyphs surfaces animation virtual landscape;large data sets;multidimensional data;data visualisation;geophysics computing;visualization technique;data visualization meteorology displays animation land surface temperature postal services temperature dependence feedback graphics iris;computer animation;interactive systems;user interfaces;meteorology;computer animation meteorology data visualisation interactive systems user interfaces geophysics computing	Visualization offers useful tools for understanding large data sets. The visualization techniques in this work, realized in the program GeoVis, depict static as well as dynamic geoscientific data through glyphs, surfaces and animation. The flight over a virtual landscape (where multidimensional data are represented by abstract glyphs) proves to be useful for the quick exploration of coherencies as well as differences in the data compound.	glyph	Matthias König;Christian Lenz;Gitta Domik	1998		10.1109/CGI.1998.694292	simulation;information visualization;visualization;human–computer interaction;computer science;computer animation;user interface;data visualization;computer graphics (images)	Visualization	-28.640099135464208	-32.79132810295532	42956
8f6786c0e273a28094f070c303d0b30d95925d01	a moving context-aware and location-based paratransit system	disabilities;vehicular communications;disabled people;internet access;arrival status;device size;g sensor;vehicle passengers;gender;dsrc;holding mode;paratransit vehicles;context aware paratransit services;wave 47	In recent years, paratransit services have been a crucial development for serving people with disabilities. However, the operators face difficulties in efficiently monitoring a paratransit vehicle and passengers are difficult to know the arrival status of the vehicle. This study proposes a moving context-aware and location-based paratransit system. With the support of WAVE/DSRC vehicular communication systems and internet access, our system can integrate the paratransit operator centre, paratransit vehicle and passenger to provide real-time services. Moving context analysis is performed to evaluate the impact of gender, device size and the ways to hold the device and the results are integrated into the development of our prototype system. Visual and audio notification services can be provided adaptively to a passenger based on the behaviour state of the passenger and the location of the paratransit.	canonical account;context awareness;experiment;internet access;location-based service;network interface;prototype;real-time clock;smart device;social network;systems architecture	Chyi-Ren Dow;Po-Yu Lai;Jhen-He Ye	2015	IJIPT	10.1504/IJIPT.2015.074328	simulation;internet access;computer science;dedicated short-range communications;law;computer security;accelerometer	HCI	-20.286842138954924	-29.186224802261034	43094
dc6cf8d17935f9412f313120ac084e7bcd28c2a6	the structure analysis of the cscwd conference's collaboration network	graph theory;giant component;clustering coefficient cscwd conference collaboration network social network analysis sna framework cscwd conference paper co authorship network social structure time varying graph static cumulative network;pattern clustering;time varying;social sciences;collaboration;average distance;small world;sna;social network;visualization;clustering coefficient;clustering;clustering sna cscwd small world time varying collaboration;collaborative networks;cscwd;social network analysis;cumulant;social structure;network theory graphs;structure analysis;social sciences graph theory network theory graphs pattern clustering	Collaboration networks are among some of the social networks and offer us the opportunity to study the structure underlying the networks. In this paper, we utilize the social network analysis (SNA) framework to understand what characterizes the social structure of the CSCWD conference's paper co-authorship network. It can potentially provide us with an understanding of the individuals and the network. We consider two scientists to be connected if they have authored a paper together, system like the co-authorship network of the conference is inherently dynamic, and so we represent it as a time-varying graph. Each graph is a static cumulative network. We then give results for the average distance and the diameter they show that this network forms a “small world”. We then also give the clustering coefficient demonstrating the presence of clustering of the collaboration between the scientists, as well as the increasing proportion of the giant component, it can serve as an additional support that the community would work well if it is densely connected. Through those figures, we also want to find some potential actions that can be taken to further develop the conference and other similar conferences.	cluster analysis;clustering coefficient;embnet.journal;giant component;graph (discrete mathematics);social network analysis;social structure	Daoshu Li;Jianguo Li;Yong Tang;Jinjia Zheng;Jiemin Chen	2012	Proceedings of the 2012 IEEE 16th International Conference on Computer Supported Cooperative Work in Design (CSCWD)	10.1109/CSCWD.2012.6221897	social network analysis;visualization;computer science;dynamic network analysis;graph theory;data science;machine learning;social structure;data mining;clustering coefficient;structural analysis;cluster analysis;giant component;social network;cumulant;collaboration	DB	-17.509144234190796	-40.797362931784114	43118
1239d73586b7429b0c00fe02530cc067fd4c078b	on social networks reduction	matrix factorization;social network;computational complexity;social network analysis;formal concept analysis	Since the availability of social networks data and the range of these data have significantly grown in recent years, new aspects have to be considered. In this paper, we use combination of Formal Concept Analysis and well-known matrix factorization methods to address computational complexity of social networks analysis and clarity of their visualization. The goal is to reduce the dimension of social network data and to measure the amount of information, which has been lost during the reduction. Presented example containing real data proves the feasibility of our approach.	computational complexity theory;formal concept analysis;social network	Václav Snásel;Zdenek Horak;Jana Kocibova;Ajith Abraham	2009		10.1007/978-3-642-04125-9_56	organizational network analysis;social network analysis;computer science;dynamic network analysis;formal concept analysis;theoretical computer science;machine learning;data mining;matrix decomposition;computational complexity theory;social network	AI	-13.615632409293614	-43.4636148452676	43129
689ebd8c18e55b240b1072538f098f5fbf326c64	a refined filter for uhad to improve anomaly detection	clustering algorithm;anomaly detection;intrusion detection;refined filter	Filtering is used in intrusion detection to remove the insignificant events from a log to facilitate the analysis method to focus on the significant events and to minimize processing overhead. Generally, filtering is performed using filtering rules, which are framed using a set of data (training data), or the known facts on anomalous events. This knowledge-dependent nature confines the filterer to filter-in only the recognized anomalies in the logs, making the rest unavailable for further scrutiny. This problem has been addressed earlier by designing a filterer that manipulates the tested log data based on the patterns and volume of events to calculate the filtering threshold. Even though this filtering threshold was able to retain the anomalous events in most heterogeneous logs, it failed when such events were of high volume and also due to the inaccuracies in cluster formation. Therefore, this paper proposes a refined filterer for unsupervised heterogeneous anomaly detection that retains most anomalous events irrespective of its volume in the logs and also discusses the impact of the refined filterer in supporting the detection. The experiment conducted reveals that the refined filterer retained almost all the abnormal events thereby enabling the detection of maximum anomalies. Copyright © 2016 John Wiley & Sons, Ltd.	anomaly detection;intrusion detection system;john d. wiley;overhead (computing)	Asif Iqbal Hajamydeen;Nur Izura Udzir	2016	Security and Communication Networks	10.1002/sec.1514	intrusion detection system;anomaly detection;computer science;machine learning;pattern recognition;data mining;cluster analysis	ML	-14.533123272564556	-38.609354012549275	43161
09b78035c0ec1b228b16eb39e819ffc4ea00a5d6	macro-optimization of email recommendation response rates harnessing individual activity levels and group affinity trends	market research;electronic mail;remuneration;collaboration;aggregates;recommender systems;real time systems	Recommendation emails are among the best ways to re-engage with customers after they have left a website. While on-site recommendation systems focus on finding the most relevant items for a user at the moment (right item), email recommendations add two critical additional dimensions: who to send recommendations to (right person) and when to send them (right time). It is critical that a recommendation email system not send too many emails to too many users in too short of a time-window, as users may unsubscribe from future emails or become desensitized and ignore future emails if they receive too many. Also, email service providers may mark such emails as spam if too many of their users are contacted in a short time-window. Optimizing email recommendation systems such that they can yield a maximum response rate for a minimum number of email sends is thus critical for the long-term performance of such a system. In this paper, we present a novel recommendation email system that not only generates recommendations, but which also leverages a combination of individual user activity data, as well as the behavior of the group to which they belong, in order to determine each user's likelihood to respond to any given set of recommendations within a given time period. In doing this, we have effectively created a meta-recommendation system which recommends sets of recommendations in order to optimize the aggregate response rate of the entire system. The proposed technique has been applied successfully within CareerBuilder's job recommendation email system to generate a 50% increase in total conversions while also decreasing sent emails by 72%.	affinity analysis;aggregate data;email;mod (video gaming);optimizing compiler;recommender system;spamming	Mohammed Korayem;Khalifeh AlJadda;Trey Grainger	2016	2016 15th IEEE International Conference on Machine Learning and Applications (ICMLA)	10.1109/ICMLA.2016.0071	market research;html email;computer science;opt-in email;world wide web;collaboration	ML	-27.79075800405162	-48.363276877729966	43182
b1bfdd48ed7d87c8374c29782906632379a7df9e	a co-ranking framework to select optimal seed set for influence maximization in heterogeneous network		The rising popularity of social media presents new opportunities for one of the enterprise’s most important needs—selecting most influential individuals in viral marketing, which has attracted increasing attention in both academia and industry. Most recent algorithms of influence maximization have demonstrated remarkable successes, however their applications are limited to homogeneous networks. In this paper, we formulate the problem of influence maximization in heterogeneous network, and propose a co-ranking framework to simultaneously select seed sets with different types. This framework is flexible and could adequately takes advantage of additional information implicit in the heterogeneous structure. We conduct extensive experiments using the data collected from ACM Digital Library, and the experimental results show that both the quality and the running time of the proposed algorithm rival the existing algorithms.		Yashen Wang;Heyan Huang;Chong Feng;Xianxiang Yang	2015		10.1007/978-3-319-25255-1_12	mathematical optimization	ML	-16.488623222354256	-44.78594140822012	43200
8f615106b7d7addd9cf3c3f39f07cc194bca2ed8	improve top-k recommendation by extending review analysis	opinion mining;similarity criterion;collaborative filtering;top k recommendation	The Web has become the popular place for people to purchase product and acquire services, so collaborative filtering is one of the most important algorithms applied in e-commerce recommendation systems. Unfortunately, it is widely recognized that the traditional recommendation methods are inefficient when the user rating data is extremely sparse. In order to overcome the limitations, good recommendation tools are needed to help Web customers determine the products and satisfaction services. In this paper, we propose a multi-dimensional adaptive recommendation algorithm by extending opinion analysis to improve top-k recommendation. In the first step, the novel algorithm that uses extened opinion analysis, creatively combines three dimensional recommendation models: user-based, item-based and opinion-based collaborative filtering. It successfully integrates opinion mining technology with collaborative filtering algorithm. In the second step, we configured the dynamic measurement would help us determine the weight of three dimensions: user-based, item-based and opinion-based analysis, and hence get the final prediction result. The experimental results show that multi-dimensional recommendation can effectively alleviate the dataset sparsity problem and achieve better prediction accuracy compared to other traditional collaborative recommendation algorithms.		Qing Zhu;Zhe Xing;JingFan Liang	2012		10.1007/978-3-642-29253-8_37	computer science;collaborative filtering;machine learning;data mining;database;world wide web;information retrieval;sentiment analysis	ML	-21.574939960182203	-48.837693920684046	43213
23e8766f2a2a71c445e7759939021be9e6dec3c9	cofids: a belief-theoretic approach for automated collaborative filtering	homeland security;drugs;commerce electronique;filtering;evaluation performance;groupware;news;belief;electronic commerce;imperfect data;comercio electronico;dempster shafer ds theory;uncertainty modeling;performance evaluation;aplicacion medical;motion pictures;systeme aide decision;defecto;uncertainty;informacion incompleta;evaluacion prestacion;collaboration;recommandation;contextual information;prise de decision;inference mechanisms;indice aptitud;user preferences;sistema ayuda decision;ambiguous data;electrical and computer engineering;user preference modeling;cofids;incomplete information;indice aptitude;recommender systems belief maintenance electronic commerce groupware inference mechanisms;support system;decision support system;e commerce applications;recommender system;croyance;collaboration filtering algorithms recommender systems system performance information filtering information filters decision making decision support systems information retrieval user interfaces;teoria dempster shafer;collaborative filtering;capability index;decision making process;contexto;defect;dempster shafer theory;comportement utilisateur;information incomplete;defaut;contexte;medical decision support systems;knowledge discovery from partial data;recomendacion;dempster shafer;noticias;ambiguity;dempster shafer belief theoretic framework;recommendation;peritaje;medical application;contextual information recommender systems collaborative filtering dempster shafer ds theory imperfect data ambiguous data user preference modeling;belief maintenance;user behavior;expertise;creencia;toma decision;medical decision support systems cofids belief theoretic approach automated collaborative filtering recommender systems e commerce applications dempster shafer belief theoretic framework;actualites;automated collaborative filtering;ambiguedad;recommender systems;context;comportamiento usuario;electronic trade;theorie dempster shafer;belief theoretic approach;ambiguite;data models	"""Automated Collaborative Filtering (ACF) refers to a group of algorithms used in recommender systems, a research topic that has received considerable attention due to its e-commerce applications. However, existing techniques are rarely capable of dealing with imperfections in user-supplied ratings. When such imperfections (e.g., ambiguities) cannot be avoided, designers resort to simplifying assumptions that impair the system's performance and utility. We have developed a novel technique referred to as CoFiDS-Collaborative Filtering based on Dempster-Shafer belief-theoretic framework-that can represent a wide variety of data imperfections, propagate them throughout the decision-making process without the need to make simplifying assumptions, and exploit contextual information. With its DS-theoretic predictions, the domain expert can either obtain a """"hard” decision or can narrow the set of possible predictions to a smaller set. With its capability to handle data imperfections, CoFiDS widens the applicability of ACF to such critical and sensitive domains as medical decision support systems and defense-related applications. We describe the theoretical foundation of the system and report experiments with a benchmark movie data set. We explore some essential aspects of CoFiDS' behavior and show that its performance compares favorably with other ACF systems."""	acf;algorithm;benchmark (computing);clinical decision support system;collaborative filtering;e-commerce;experiment;recommender system;subject-matter expert;theory	Thanuka Wickramarathne;Kamal Premaratne;Miroslav Kubat;D. T. Jayaweera	2011	IEEE Transactions on Knowledge and Data Engineering	10.1109/TKDE.2010.88	dempster–shafer theory;computer science;artificial intelligence;machine learning;data mining;database;statistics;recommender system	DB	-15.60198649061264	-49.39961443700046	43216
d999177431dc4ef02f2b05d5439d3b12591054b3	universal network representation for heterogeneous information networks		Network representation aims to represent the nodes in a network as continuous and compact vectors, and has attracted much attention in recent years due to its ability to capture complex structure relationships inside networks. However, existing network representation methods are commonly designed for homogeneous information networks where all the nodes (entities) of a network are of the same type, e.g., papers in a citation network. In this paper, we propose a universal network representation approach (UNRA), that represents different types of nodes in heterogeneous information networks in a continuous and common vector space. The UNRA is built on our latest mutually updated neural language module, which simultaneously captures inter-relationship among homogeneous nodes and node-content correlation. Relationships between different types of nodes are also assembled and learned in a unified framework. Experiments validate that the UNRA achieves outstanding performance, compared to six other state-of-the-art algorithms, in node representation, node classification, and network visualization. In node classification, the UNRA achieves a 3% to 132% performance improvement in terms of accuracy.	algorithm;citation network;entity;experiment;graph drawing;language module;unified framework	Ruiqi Hu;Celina Ping Yu;Sai-Fu Fung;Shirui Pan;Haishuai Wang;Guodong Long	2017	2017 International Joint Conference on Neural Networks (IJCNN)	10.1109/IJCNN.2017.7965880	machine learning;weighted network;evolving networks;artificial intelligence;nervous system network models;network formation;network simulation;computer science;dynamic network analysis;hierarchical network model;interdependent networks	ML	-14.571741805702548	-46.429873488141695	43217
6de3d2f12217f41795fa1f5333b4304d9fd84c02	community structure and interaction locality in social networks	community;interaction locality;anomaly detection;social network	Research on social network analysis (SNA) has been actively pursued. Most SNAs focus on either social relationship networks (e.g., friendship and trust networks) or social interaction networks (e.g., email and phone call networks). It is expected that the social relationship network and social interaction network of a group should be closely related to each other. For instance, people in the same community in a social relationship network are expected to communicate with each other more frequently than with people in different communities. To the best of our knowledge, however, there is not much understanding on such interaction locality in large-scale online social networks. This paper aims to bridge the gap between intuition about interaction locality and empirical evidences observed in large-scale social networks. We investigate the strength of interaction locality in large-scale social networks by analyzing different types of data: logs of mobile phone calls, email messages, and message exchanges in a social networking service. Our results show that strong interaction locality is observed equally in the three datasets, and suggest that strength of the interaction locality is invariant with regard to the scale of the community. Moreover, we discuss practical implications as well as possible applications.	anomaly detection;email;experiment;interaction network;locality of reference;mesoscopic physics;mobile phone;social network analysis	Sho Tsugawa;Hiroyuki Ohsaki	2015	JIP	10.2197/ipsjjip.23.402	community;anomaly detection;computer science;social network	Web+IR	-19.39658075650762	-42.03445841071156	43243
ecd143283cb3df7eb93eff26161e0febc4c49acb	where did you go: personalized annotation of mobility records	semantic annotation;human mobility;social network;recommendation	Recent advances in positioning technology have generated massive volume of human mobility data. At the same time, large amount of spatial context data are available and provide us with rich context information. Combining the mobility data with surrounding spatial context enables us to understand the semantics of the mobility records, e.g., what is a user doing at a location, e.g., dining at a restaurant or attending a football game). In this paper, we aim to answer this question by annotating the mobility records with surrounding venues that were actually visited by the user. The problem is non-trivial due to high ambiguity of surrounding contexts. Unlike existing methods that annotate each location record independently, we propose to use all historical mobility records to capture user preferences, which results in more accurate annotations. Our method does not assume the availability to any training data on user preference because of the difficulties to obtain such data in the real-world setting. Instead, we design a Markov random field model to find the best annotations that maximize the consistency of annotated venues. Through extensive experiments on real datasets, we demonstrate that our method significantly outperforms the baseline methods.	baseline (configuration management);experiment;markov chain;markov random field;user (computing)	Fei Wu;Zhenhui Li	2016		10.1145/2983323.2983845	computer science;data mining;database;internet privacy;world wide web;information retrieval;social network	Web+IR	-22.920683267023957	-45.26447086584855	43308
26bc6225d04381d72ed495d6156eb0fbf98b14be	methods for engineering symbolic human behaviour models for activity recognition		Context-aware systems are becoming an important part of our everyday life and their ability to accurately recognise the user needs plays a crucial role in their performance. Assistive software would be greatly impaired, were it unable to recognise the current user state, as it would result in inability to correctly assist her. A typical approach in such situations is the employment of probabilistic models that describe the possible states and the probabilities for going from one state to another. Usually these models are handcrafted by the system engineer and the transition probabilities are learned to fit the specific problem. However, in order to build and learn the model, a training dataset has to be collected and annotated which in itself implies finding subjects to conduct an experiment, spending time for repeatedly conducting the experiment, and even more time for annotating it. This makes the building of such models not only expensive but also leads to generalisation problems, as the model is not guided by a domain structure but rather by the underlying sensor readings, which could cause suboptimal solutions. A different approach is to generate the probabilistic model from prior knowledge instead of learning it. One approach to generating probabilistic models could be the usage of human behaviour models that are later mapped onto a probabilistic model and an inference engine is used for estimating the user state. It exploits the additional advantage that the natural way of human thinking is based on causes and effects instead of probabilities. There are corresponding theories that it would be much easier for a system engineer to build a non-probabilistic model. Based on the above assumption, this work investigates the ability of symbolic models to encode context information that is later used for generating probabilistic models. It also analyses the problems arising from such approach and the need of a structured development process for model based activity recognition. As a consequence, the contributions of the work are as follows: (1) it shows that it is possible to successfully use symbolic models for activity recognition in the field of activities of daily living; (2) it provides a modelling toolkit that contains patterns for reducing the model complexity; (3) it proposes a structured development process for building and evaluating computational causal behaviour models. In general, the thesis provides a practical guide to implementing and using symbolic models for activity recognition and proposes a structured process for doing it – something that is often overlooked in the field of activity recognition.	activity recognition;assistive technology;behavioral modeling;causal filter;computation;context-aware pervasive systems;encode;experiment;inference engine;markov chain;statistical model;systems engineering;theory	Kristina Yordanova	2014				AI	-25.04091080258307	-27.30535237210281	43321
01dc08fe5dc05a1154c4fd50fbcccbdd3221ccaa	signed social networks: link prediction and overlapping community detection	social network services;k anonymity;recursive c l diversity;electronic mail;information systems;detection algorithms;social network services detection algorithms conferences information systems electronic mail measurement uncertainty;measurement uncertainty;alpha anonymization;social networks;social networking online;noise nodes;l diversity;conferences;fuzzy community detection algorithm signed social network link prediction overlapping community detection two phase approach intra node extra node	In this paper, we propose a new two-phase approach for finding overlapping communities in signed social networks. Moreover, we evaluate the importance of three node classes: extra, overlapping and intra. Results indicate that the overlapping nodes can competitively predict signs in comparison to intra and extra nodes. Finally, we propose extended frustration as a measure to evaluate errors for fuzzy community detection algorithms in signed social networks.	algorithm;social network;two-phase locking	Mohsen Shahriari;Ralf Klamma	2015	2015 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining (ASONAM)	10.1145/2808797.2809357	social science;computer science;data mining;mathematics;world wide web;information system;statistics;measurement uncertainty;computer network;social network	DB	-23.46097919760386	-42.545643640835124	43411
c9c4225a5346fcbd59976b88701e4545897af6e2	the impact analysis of traffic incident and prediction model on travel time under incident condition	road traffic;queueing theory;road vehicles global positioning system queueing theory road traffic;global positioning system;prediction model traffic incident impact analysis;roads vehicles predictive models global positioning system telecommunications queueing analysis;velocity information impact analysis traffic incident model travel time incident condition traffic prediction model decision makers urban traffic network pattern classification method queuing length variation gps position;road vehicles	Understanding the impact of traffic incidents, not only can help decision-makers choose a better strategy, but also provide travel recommendations for travelers. This paper uses real GPS data collected from probe vehicle to analyze the impact of incident in urban traffic network. Queuing length and incident duration are used to evaluate impact level incident. Then, a traffic incident pattern classification method based on queuing length variation is proposed to more clearly understand the characteristics of traffic incident. At last, we propose a prediction model on the time that a vehicle takes to pass through the location where traffic incident happens by using the GPS position and velocity information.	global positioning system;static program analysis;theory;velocity (software development)	Qi Wang;Haitao Yu;Tongyu Zhu;Ge Li	2013	2013 13th International Conference on ITS Telecommunications (ITST)	10.1109/ITST.2013.6685517	traffic generation model;simulation;floating car data;geography;vehicle information and communication system;traffic congestion reconstruction with kerner's three-phase theory;traffic flow;transport engineering;traffic wave;computer security	HPC	-17.159295575624117	-30.833705284046758	43455
de5dacd3bd87d5a1319fb9103fe103b67ee92025	agent-based web content engagement time (wcet) analyzer on e-publication system	software metrics;software;unique browser metric;return on investment;agent based;software robots;e publications web content engagement time agent technology web traffic analysis metrics pageviews metric unique browser metric visitor loyalty metric software robots web crawlers web statistics e magazines;calculators;publishing;data mining;software metrics internet publishing software agents;web crawler;software agents;web content engagement time;agent;e magazines;servers;e publication;internet;engagament time;web traffic analysis metrics;silicon compounds robots crawlers intelligent systems intelligent agent paper technology web sites statistical analysis statistics web server;e publication agent engagament time;robots;web sites;agent technology;traffic analysis;world wide web;humans;web crawlers;web statistics;pageviews metric;behavior analysis;visitor loyalty metric;e publications	This paper focuses on the adoption of Agent Technology to calculate and evaluate the Web Content Engagement Time (WCET). Traditional Web traffic analysis metrics such as pageviews, unique browser, visitor loyalty, etc have been used to analyze the web traffic behaviour for a long time since the birth of World Wide Web, but the emersion of software robots and web crawlers trigger a huge impact on the integrity and correctness of these traditional Web statistics. For advertisers, these statistics are not enough for them to evaluate the actual return-on-investment (ROI). For instance, large amount of pageviews but extremely short session duration will not have much impact for the advertisers to promote their products and brands. Web Content Engagement Time (WCET) for the reading on interactive Web content such as e-magazines and e-publications, which focuses on the page duration between each “page-flipping”, will give advertisers much more information and confidence on whether such eye-balls (i.e. attention) are actually focused on the Web content (and hence the eAds) or not, especially during the browsing of e-magazines and e-publications. But such indicator involves significant amount of calculation within the Web server, especially when over thousands of users are reading a popular e-publication at the same time. To tackle with this problem, a multi-agent based Web Content Engagement Time (WCET) Analyzer is proposed on e-publication system. From the experimental perspective, popular Chinese e-magazine “MingPaoWeekly”, with over 0.5 million readership in Hong Kong and oversea Chinese communities are tested over the IAToLife.com Web Channel platform, promising Web Content Engagement Time (WCET) are recorded, which provides not only integrity and confidence for the publishers and advertisers, but also shines a new light for the future agent-based target marketing and e-reader profile and reading behavior analysis.	agent-based model;correctness (computer science);e-reader;multi-agent system;multiple buffering;page view;region of interest;robot;server (computing);traffic analysis;web analytics;web content;web crawler;web server;web traffic;world wide web;worst-case execution time	Raymond S. T. Lee;James Nga-Kwok Liu;Karo S. Y. Yeung;Alan H. L. Sin;Dennis T. F. Shum	2009	2009 Ninth International Conference on Intelligent Systems Design and Applications	10.1109/ISDA.2009.189	web service;web development;web analytics;web design;computer science;web crawler;multimedia;internet privacy;world wide web;mashup	Web+IR	-24.208161625154858	-46.99918010152627	43635
af6c8e280946f019c7f632c8281a35ddf1fdc9b0	automatic making of sokoban problems	sokoban problems	This paper describes our program that makes Sokoban problems automatically. Sokoban is one of one-person puzzles invented in Japan. The program consists of three stages: generation, checking and evaluation. First, candidates for problems are generated randomly by a prototype and three templates . Second, unsolvable candidates are removed by the Sokoban solver. Finally trivial or uninteresting candidates are removed by the evaluator. The problems that the program made are judged good by human experts. Creation of art by computer is an important target of Arti cial Intelligence. Our work can be characterized one of the attempts to create some arts by computers.	computer;interpreter (computing);prototype;randomness;sokoban;solver	Yoshio Murase;Hitoshi Matsubara;Yuzuru Hiraga	1996		10.1007/3-540-61532-6_50	the arts;machine learning;artificial intelligence;computer science;making-of;solver	AI	-27.112433878737285	-24.61683459461597	43683
efd6896426c740668adc2519cf33794015ca2a9e	an extensible interactive 3d visualization framework for n-dimensional datasets used in heterogeneous software display environments	high-dimensional data;novel visualization system;domain practitioner;traditional interactive high-dimensional data;high-dimensional interactive data visualization;effective visualization tool;data visualization;visualization tool;visualization framework;heterogeneous software display environment;raw data	high-dimensional data;novel visualization system;domain practitioner;traditional interactive high-dimensional data;high-dimensional interactive data visualization;effective visualization tool;data visualization;visualization tool;visualization framework;heterogeneous software display environment;raw data		Nathaniel Rossol;L. Irene Cheng;John Berezowski;Iqbal Jamal	2011		10.1007/978-3-642-24028-7_47	software visualization;visual analytics;information visualization;interactive visual analysis;computer science;data science;data mining;world wide web	Visualization	-29.28230533986348	-31.64678052048417	43716
4ea384da61c70b6045d08248b65c6d89e855044e	litrec vs. movielens - a comparative study		Recommendation is an important research area that relies on the availability and quality of the data sets in order to make progress. This paper presents a comparative study between Movielens, a movie recommendation data set that has been extensively used by the recommendation system research community, and LitRec, a newly created data set for content literary book recommendation, in a collaborative filtering set-up. Experiments have shown that when the number of ratings of Movielens is reduced to the level of LitRec, collaborative filtering results degrade and the use of content in hybrid approaches becomes important.	collaborative filtering;movielens;recommender system	Paula Cristina Vaz;Ricardo Ribeiro;David Martins de Matos	2012			computer science;recommender system;data mining;collaborative filtering;movielens;data set	Web+IR	-23.20320940318944	-49.86423728088378	43717
1726417dbb37b1888e6ad22ce6e63803b609c79a	in search for relevant, diverse and crowd-screen points of interests		In this demo we present a prototype of an experimental platform for evaluating item recommendation algorithms. The application domain for our system is that of digital city guides. Our prototype implementation allows the user to explore different algorithms and compare their output. Among the algorithms implemented is MPG, which aims at providing a diverse set of recommendations better aligned with user preferences. MPG takes into consideration the user preferences (e.g., reach willing to cover, types of venues interested in exploring etc.), the popularity of the establishments as well as their distance from the current location of the user by combining them into a single composite score. We provide a web interface, which outputs on a map the recommended locations along with metadata (e.g., type and name of location, relevance and diversity scores, etc.). It also illustrates the potential of the Preferential Diversity approach on which MPG is based.	algorithm;application domain;application programming interface;mpeg-1;prototype;real-time computing;real-time locating system;recommender system;relevance;smart city;user (computing);user interface;venue (sound system)	Xiaoyu Ge;Samanvoy Panati;Konstantinos Pelechrinis;Panos K. Chrysanthis;Mohamed A. Sharaf	2017		10.5441/002/edbt.2017.74	database;application domain;information retrieval;computer science;metadata;popularity;user interface	Web+IR	-30.016804891321136	-45.86655546127531	43781
b120b0ad5527af93e086224c460c9d648523e574	active learning of model parameters for influence maximization	influence maximization;active learning;social network analysis	Previous research efforts on the influence maximization problem assume that the network model parameters are known beforehand. However, this is rarely true in real world networks. This paper deals with the situation when the network information diffusion parameters are unknown. To this end, we firstly examine the parameter sensitivity of a popular diffusion model in influence maximization, i.e., the linear threshold model, to motivate the necessity of learning the unknown model parameters. Experiments show that the influence maximization problem is sensitive to the model parameters under the linear threshold model. In the sequel, we formally define the problem of finding the model parameters for influence maximization as an active learning problem under the linear threshold model. We then propose a weighted sampling algorithm to solve this active learning problem. Extensive experimental evaluations on five popular network datasets demonstrate that the proposed weighted sampling algorithm outperforms pure random sampling in terms of both model accuracy and the proposed objective function.	expectation–maximization algorithm	Tianyu Cao;Xindong Wu;Xiaohua Hu;Song Wang	2011		10.1007/978-3-642-23780-5_28	mathematical optimization;social network analysis;entropy maximization;artificial intelligence;machine learning;mathematics;active learning;statistics	ML	-17.171488410670186	-44.319131696985785	43814
1adf9e220732828bd4bad4776d700ef16341ee9c	revisiting power-law distributions in spectra of real world networks		By studying a large number of real world graphs, we find empirical evidence that most real world graphs have a statistically significant power-law distribution with a cutoff in the singular values of the adjacency matrix and eigenvalues of the Laplacian matrix in addition to the commonly conjectured power-law in the degrees. Among these results, power-laws in the singular values appear more consistently than in the degree distribution. The exponents of the power-law distributions are much larger than previously observed. We find a surprising direct relationship between the power-law in the degree distribution and the power-law in the eigenvalues of the Laplacian that was theorized in simple models but is extremely accurate in practice. We investigate these findings in large networks by studying the cutoff value itself, which shows a scaling law for the number of elements involved in these power-laws. Using the scaling law enables us to compute only a subset of eigenvalues of large networks, up to tens of millions of vertices and billions of edges, where we find that those too show evidence of statistically significant power-laws.	adjacency matrix;degree distribution;fitts's law;image scaling;laplacian matrix;rca spectra 70;theory	Nicole Eikmeier;David F. Gleich	2017		10.1145/3097983.3098128	singular value;adjacency matrix;discrete mathematics;vertex (geometry);eigenvalues and eigenvectors;power law;scaling;degree distribution;laplacian matrix;mathematics	ML	-13.736679235023118	-40.17522882936567	43830
f0f700a162b932d24a12fe53dc7b603b136fb4f7	sentiment-enhanced multidimensional analysis of online social networks: perception of the mediterranean refugees crisis	data mining;media;urban areas;europe;twitter;tagging	We propose an analytical framework able to investigate discussions about polarized topics in online social networks from many different angles. The framework supports the analysis of social networks along several dimensions: time, space and sentiment. We show that the proposed analytical framework and the methodology can be used to mine knowledge about the perception of complex social phenomena. We selected the refugee crisis discussions over Twitter as a case study. This difficult and controversial topic is an increasingly important issue for the EU. The raw stream of tweets is enriched with space information (user and mentioned locations), and sentiment (positive vs. negative) w.r.t. refugees. Our study shows differences in positive and negative sentiment in EU countries, in particular in UK, and by matching events, locations and perception, it underlines opinion dynamics and common prejudices regarding the refugees.	gene ontology term enrichment;multidimensional analysis;real-time transcription;scalability;social network	Mauro Coletto;Claudio Lucchese;Cristina Ioana Muntean;Franco Maria Nardini;Andrea Esuli;Chiara Renso;Raffaele Perego	2016	2016 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining (ASONAM)	10.1109/ASONAM.2016.7752401	social science;media;computer science;data mining;social psychology;world wide web;sentiment analysis	DB	-25.51826473478004	-46.98520442715805	43969
05b640fa24aeb2aad96cd76e5f1352af787b57d9	route navigation in the urban grand challenge with compromised gps		The DARPA Urban Challenge is providing an opportunity for interested scientists to compete in designing and proving an unmanned vehicle.The autonomous vehicle must avoid collisions, operate in compromised conditions and be robust and independent of human operators. Navigation may be achieved by a varied number of methods. Most will rely on Global Positioning System (GPS) for waypoints, checkpoints and general travel. A route file will be provided for the test site that contains information related to GPS coordinates throughout the course. Vehicles must safely navigate to checkpoints while maintaining road ruleswithsafety.IntheeventthatGPSislostorcompromised,thevehiclesmuststillnavigate to the checkpoints while determining traversable pathways. Optional techniques have been developed in order to navigate without GPS. We build a map of all of the waypoints along with other route information. Whenever we need to navigate to a checkpoint or gate in the absence of GPS, we identify the location we want to head to and use that as a directional bias compared to our current location. We then follow road rules to get through correct gates to the checkpoint using modified orienteering techniques.	darpa grand challenge;global positioning system	John K. Johnson	2007	JACIC	10.2514/1.33309	simulation;engineering;transport engineering;computer security	HCI	-17.795395757991262	-28.254286631322852	44139
a175999cd1192c822028cf2f3562e9850e3e7e9b	estimating the spatial distribution of the population of riyadh, saudi arabia using remotely sensed built land cover and height data	population;g geography general;dwelling;riyadh;estimation;land cover	0198-9715/$ see front matter 2013 Elsevier Ltd. All rights reserved. http://dx.doi.org/10.1016/j.compenvurbsys.2013.06.002 ⇑ Corresponding author at: Geography and Environment, University of Southampton, Southampton SO17 1BJ, UK. Tel.: +44 (0) 23 8059 4617; fax: +44 (0) 23 8059 3295. E-mail addresses: mh_alahmadi@yahoo.com (M. Alahmadi), P.M.Atkinson@ soton.ac.uk (P. Atkinson), D.J.Martin@soton.ac.uk (D. Martin). Mohammed Alahmadi a,b,⇑, Peter Atkinson , David Martin a	algorithm;coefficient;cursor (databases);downscaling;fax;guinness world records;jsp model 2 architecture;object-based language;spatial analysis;stationary process;support vector machine	Mohammed Alahmadi;Peter Atkinson;David J. Martin	2013	Computers, Environment and Urban Systems	10.1016/j.compenvurbsys.2013.06.002	estimation;geography;mathematics;cartography;statistics;population	AI	-10.548244591794289	-26.30973443032007	44156
17d5c073d63a46866a168595f386aee4f484eacb	a scalable algorithm for detecting community outliers in social networks	community outlier;outlier detection;social networks	Outlier detection is an important problem that has been researched and applied in a myriad of domains ranging from fraudulent transactions to intrusion detection. Most existing methods have been specially developed for detecting global and (or) local outliers by using either content information or structure information. Unfortunately, these conventional algorithms have been facing with unprecedented challenges in social networks, where data and link information are tightly integrated. In this paper, a novel measurement named Community Outlying Factor is put forward for community outlier, besides its descriptive definition. A scalable community outliers detection algorithm (SCODA), which fully considers both content and structure information of social networks, is proposed. Furthermore, SCODA takes effective measures to minimize the number of input parameters down to only one, the number of outliers. Experimental results demonstrate that the time complexity of SCODA is linear to the number of nodes, which means that our algorithm can easily deal with very large data sets. © 2012 Springer-Verlag.		Tengfei Ji;Jun Gao;Dongqing Yang	2012		10.1007/978-3-642-32281-5_42	data science;machine learning;data mining	ML	-12.041534085295048	-38.196914930133076	44187
6c008a5a13e5c1ea6453abce1ad856c57c3f3405	mining negative association rules in multi-database	databases;itemsets;association rules;data mining;negative association;negative association rules;information and communication technology;decision making multidatabase mining negative association rules;distributed databases data mining decision making;multidatabase mining;distributed databases;correlation;data mining association rules itemsets databases decision making communications technology fuzzy systems information science mining industry technology management;algorithm design and analysis	Negative association rules (NARs) catch mutually exclusive correlations among items. They play important roles in decision-making. But nowadays the techniques of NARs mining focus on mono-database. With the rapid development of information and communication technologies, multi-database mining is becoming more and more important. Knowledge conflicts within databases may occur when mining both the positive and negative association rules simultaneously. This paper proposed synthesis correlation to resolve conflicts and a new algorithm PNAR_MDB for mining NARs in multi-database on base of previous work on multi-database mining. The experimental results demonstrate that the algorithm is correct and effective.	association rule learning;database;structure mining	Shiju Shang;Xiangjun Dong;Runian Geng;Long Zhao	2008	2008 Fifth International Conference on Fuzzy Systems and Knowledge Discovery	10.1109/FSKD.2008.120	concept mining;algorithm design;information and communications technology;association rule learning;computer science;data science;data mining;database;distributed database;correlation	DB	-4.690842374496629	-36.2224687575116	44231
bed9503c9e5d24f4291344ac15134a7ce6f0b6b0	partial restreaming approach for massive graph partitioning	silicon;streaming partitioning;electronic mail;data stream partial restreaming approach massive graph partitioning partial rest reaming partitioning hybrid streaming model;load modeling adaptation models silicon data mining electronic mail data models facebook;graph theory data handling;data mining;graph partitioning;facebook;big graph processing;big graph processing graph partitioning streaming partitioning;adaptation models;load modeling;data models	Graph partitioning is a challenging and highly important problem when performing computation tasks over large distributed graphs, the reason is that a good partitioning leads to faster computations. In this work, we introduce the partial rest reaming partitioning which is a hybrid streaming model allowing only several portions of the graph to be rest reamed while the rest is to be partitioned on a single pass of the data stream. We show that our method yields partitions of similar quality than those provided by methods rest reaming the whole graph (e.g. ReLDG, ReFENNEL), while incurring lower cost in running time and memory since only several portions of the graph will be rest reamed.	computation;computer cluster;graph partition;time complexity	Ghizlane Echbarthi;Hamamache Kheddouci	2014	2014 Tenth International Conference on Signal-Image Technology and Internet-Based Systems	10.1109/SITIS.2014.59	data modeling;real-time computing;graph bandwidth;computer science;graph partition;theoretical computer science;operating system;machine learning;database;distributed computing;silicon;graph database	DB	-8.637192740498326	-40.96764771210912	44399
38609da623ebcf1c74ca3c96b43d7177297b4ec3	contrasting the spread of misinformation in online social networks		The emergence of online social networks has revolutionized the way people seek and share information. Nowadays, popular online social sites as Twitter, Facebook and Google+ are among the major news sources as well as the most effective channels for viral marketing. However, these networks also became the most effective channel for spreading misinformation, accidentally or maliciously. The widespread diffusion of inaccurate information or fake news can lead to undesirable and severe consequences, such as widespread panic, libelous campaigns and conspiracies. In order to guarantee the trustworthiness of online social networks it is a crucial challenge to find effective strategies to contrast the spread of the misinformation in the network. In this paper we concentrate our attention on two problems related to the diffusion of misinformation in social networks: identify the misinformation sources and limit its diffusion in the network. We consider a social network where some nodes have already been infected from misinformation. We first provide an heuristics to recognize the set of most probable sources of the infection. Then, we provide an heuristics to place a few monitors in some network nodes in order to control information diffused by the suspected nodes and block misinformation they injected in the network before it reaches a large part of the network. To verify the quality and efficiency of our suggested solutions, we conduct experiments on several real-world networks. Empirical results indicate that our heuristics are among the most effective known in literature.	algorithm;approximation;cut (graph theory);directed graph;emergence;experiment;file spanning;google+;graph theory;heuristic (computer science);performance;regular expression;resident monitor;social network;threshold model;trust (emotion);unbalanced circuit	Marco Amoruso;Daniele Anello;Vincenzo Auletta;Diodato Ferraioli	2017			distributed computing;computer science;trustworthiness;panic;heuristics;node (networking);fake news;viral marketing;social network;misinformation	Web+IR	-16.87780960298955	-43.54650356046771	44421
4bbb4bca24d4580d33baefcad2679073a5409b12	continuous proximity detection via predictive safe region construction		Continuous proximity detection monitors the real-time positions of a large set of moving users and sends an alert as long as the distance of any matching pair is smaller than the threshold. Existing solutions construct either a static safe region with maximized area or a mobile safe region with constant speed and direction, which cannot not capture real motion patterns. In this paper, we propose a new type of safe region that relies on trajectory prediction techniques to significantly reduce the communication I/O. It takes into account the complex non-linear motion patterns and constructs a stripe to enclose the sequence of future locations as a predictive safe region. The stripe construction is guided by a holistic cost model with the objective of maximizing the expected time for the next communication. We conduct experiments on four real datasets with four types of prediction models and our method reduces the communication I/O by more than 30% in the default parameter settings.	analysis of algorithms;average-case complexity;experiment;holism;input/output;magnetic stripe card;nonlinear system;real-time clock;stripes	Ying Xu;Dongxiang Zhang;Meihui Zhang;Dongsheng Li;Xiaoling Wang;Heng Tao Shen	2018	2018 IEEE 34th International Conference on Data Engineering (ICDE)	10.1109/ICDE.2018.00063	data mining;predictive modelling;real-time computing;computer science;trajectory	DB	-15.947552189762026	-33.878224607601666	44422
896c1a8d509806b6929b4d2a8e19b8b0e569ee12	an interactive analytics tool for understanding location semantics and mobility of users using mobile network data	planning mobile communication mobile computing employment data mining manufacturing feature extraction;home and work place prediction population distribution urban development mobile phone records;mobile computing interactive systems;urban development;interactive analytics tool government statistics mobility profiles population distribution mobile network data;home and work place prediction;mobile phone records;population distribution	"""Knowledge about population distribution of planning areas helps in making urban development decisions. Two important criteria are: """"where do people live?"""" and """"where do they work?"""" In this paper we propose methods to find home and workplaces from mobile network data. Home and work places are essential for discovery of mobility profiles of users. Validation of home and workplace prediction is not straight forward. We validate our methods using correlation with external data. Validation results show that even though a single cellular provider has only a portion of the entire population as its users, distribution of home and work places predicted using its mobile network data match that of government statistics. On the basis of this matching, we can have faith in distributions of more difficult statistics extracted from mobile network data which are difficult to obtain from external sources. We implemented an interactive system to show various distributions such as people living and working in different planning areas, and people working in different job sectors such as manufacturing. Interesting relationships are found by calculating joint distributions, e.g., Where do people, living in a planning area, work, and vice versa. Planning areas are ranked by the average distance traveled from home to work. Another interesting fact we extract is balance. Balance of a planning area is high if people live and work there, it is low if people living in a planning area work in other planning areas. We extend these statistics to regions which consist of many planning areas. The goal of this interactive system is to understand location semantics and mobility of users to aid in making urban development decisions. A video recording with subtitles is uploaded in http://www.youtube.com/watch?v=mo-7-DsCymw."""	interactivity;video	Manoranjan Dash;Gim Guan Chua;Hai-Long Nguyen;Ghim-Eng Yap;Hong Cao;Xiaoli Li;Shonali Krishnaswamy;James Decraene;Amy Shi Nash	2014	2014 IEEE 15th International Conference on Mobile Data Management	10.1109/MDM.2014.50	mobile search;simulation;data mining;urban planning;database;multimedia;population density	HCI	-18.78417957080082	-32.13848274469361	44426
08c7061af28af0528fe2b98e4b535203ec36f752	information cascade on networks	information cascade;ising model;network;phase transition	In this paper, we discuss a voting model by considering three diff rent kinds of networks: a random graph, the Barabási-Albert(BA ) model, and a fitness model. A voting model represents the way in which pub lic perceptions are conveyed to voters. Our voting model is constru cted by using two types of voters–herders and independents–and two candi dates. Independents conduct voting based on their fundamental values; on t he other hand, herders base their voting on the number of previous votes. He nce, herders vote for the majority candidates and obtain information rel ating to previous votes from their networks. We discuss the difference betwee n th phases on which the networks depend. Two kinds of phase transitions, a information cascade transition and a super-normal transition, were ide ntified. The first of these is a transition between a state in which most voters m ake the correct choices and a state in which most of them are wrong. The se cond is a ∗[1] masato.hisakado@fsa.go.jp †[2] mori@sci.kitasato-u.ac.jp	barabási–albert model;bot herder;conditional (computer programming);fitness model (network theory);information cascade;java platform, standard edition;random graph	Masato Hisakado;Shintaro Mori	2015	CoRR		phase transition;ising model;physics;quantum mechanics;information cascade	AI	-21.023158378545265	-39.58738193668836	44444
2299f57e7a8bbf2c24c5a5303035925470df5821	episogram: visual summarization of egocentric social interactions	social network services;behaviorial sciences;electronic mail;information visualization computer graphics social interactions social media visualization visual summarization;social media visualization;computer graphics;shape analysis;information visualization;social sciences computing data visualisation interactive systems;data visualization;data visualization twitter data models behaviorial sciences electronic mail shape analysis social network services;visual summarization;social interactions;twitter;time varying tripartite network visual summarization egocentric social interaction social interaction data visualization user activities behavior pattern interactive visualization tool episogram social interaction process;data models	The key challenges of visualizing social interaction data include the difficulties of understanding the general structure of social interactions and representing the data in the context of various user activities to reveal different behavior patterns. The design of the proposed interactive visualization tool Episogram is based on an anatomy of social interaction process in which the actors and objects involved can be formally represented as a time-varying tripartite network. The authors show the effectiveness of the proposed technique using real-world datasets and user studies.	anatomic structures;area striata structure;imagery;interaction;interactive visualization;physical object;rem sleep behavior disorder;usability testing	Nan Cao;Yu-Ru Lin;Fan Du;Dashun Wang	2016	IEEE Computer Graphics and Applications	10.1109/MCG.2015.73	data modeling;information visualization;human–computer interaction;computer science;data mining;shape analysis;multimedia;computer graphics;world wide web;data visualization	Visualization	-27.90755212000917	-35.49909301505589	44454
db613a7dfccb15314135bb97782e98c1e3800969	when to recommend: a new issue on tv show recommendation	recommendation cost model;tv recommender system	Recommender systems have gained much attention in both research and industry communities, and have been actively researched for the last decade. However, recommendation techniques for TV shows have not been actively researched despite TV’s importance. It is because TV show recommendation has two unique and notable characteristics: (1) items (i.e., TV shows) are available only for a certain time period and (2) user cannot watch two different shows at the same time. Due to the different characteristics, TV recommender system should be able to recommend item in  online time , and  deciding the recommendation timing  becomes an important issue for TV show recommender system. Developing such a system raises several technical challenges: (1) Since the time conditions of TV shows such as watching time and remaining time affect on how much the user is attracted to the show, recommendation must consider the time conditions as well as users’ preferences on items. (2) The cost of inaccurate recommendations (or inaccurate timing) is higher than other domains, because a recommendation involves blocking a part of screen. This paper proposes a novel recommender system for TV shows called  ShowTime , which determines the timing as well as the items for recommendation. In our extensive experiments on a real-world data, the proposed TV show recommender system,  ShowTime , demonstrates promising results in terms of accuracy and the cost management.		Jinoh Oh;Sungchul Kim;Jinha Kim;Hwanjo Yu	2014	Inf. Sci.	10.1016/j.ins.2014.05.003	computer science;multimedia	AI	-24.656631954073955	-46.705120425744546	44516
645e3a9515edd179ceb4077a7834f7d03708d8b9	detecting anomalous longitudinal associations through higher order mining	anomaly detection;data mining;higher order;conference paper;data analysis	The detection of unusual or anomalous data is an important function in automated data analysis or data mining. However, the diversity of anomaly detection algorithms shows that it is often difficult to determine which algorithms might detect anomalies given any random dataset. In this paper we provide a partial solution to this problem by elevating the search for anomalous data in transaction-oriented datasets to an inspection of the rules that can be produced by higher order longitudinal/spatio-temporal association rule mining. In this way we are able to apply algorithms that may provide a view of anomalies that is arguably closer to that sought by information analysts.	algorithm;anomaly detection;association rule learning;data mining;information;sensor;universal quantification	Ping Liang;John F. Roddick	2007			anomaly detection;higher-order logic;computer science;data science;data mining;data analysis;information retrieval	ML	-6.465198010587843	-34.43866383796146	44621
c0346c7df9b1ba47f21a91e34becc3c7da6ffca1	rsim: simplifying an rdf graph at the visualization tier for non-expert users		Using a concept-map or a node-link diagram for representing knowledge can enhance the learning ability of users. However, the queried RDF graph can be complex and difficult for non-expert users to read, because many redundant triples entailed by RDFS and OWL rules are also included. Existing tools can rearrange, filter, highlight and summarize a graph for visualization but they require human effort. For this reason, this research attempts to use Semantic Web rules and schemas to simplify a graph automatically at the visualization tier. The prototype shows that the simplified graph is easier to read than the original one. In future, this method will be positioned as a plugin for other visualization tools in order to serve attractive RDF-based knowledge to users.	concept map;diagram;multitier architecture;prototype;rdf schema;resource description framework;semantic web	Rathachai Chawuthai;Hideaki Takeda	2015			computer science;diagram;data mining;semantic web;rdf;database;visualization;schema (psychology);plug-in;rdf schema;graph	HCI	-31.36581446193334	-31.733583031295957	44707
0b2052dc733b7563901582fe3c95cae4dcfa2ce5	influence efficiency maximization: how can we spread information efficiently?		Influence maximization problem, due to its popularity, has been studied extensively these years. It aims at targeting a set of seed nodes for maximizing the expected number of activated nodes at the end of the information diffusion process. During the process of information diffusion, an active node will try to influence its neighbors in the next iteration. Thus, it will cost several iterations before a node is activated except seed nodes, which is called propagation time delay. However, it is not discussed in influence maximization problem. Thus, there is a need to understand the influence efficiency in the network. Motivated by this demand, we propose a novel problem called Influence Efficiency Maximization problem, which takes the propagation time delay into consideration. We prove that the proposed problem is NP-hard under independent cascade model and the influence efficiency function is submodular. Furthermore, we also prove the computation of influence efficiency is #P-hard under independent cascade model. After that, several algorithms are proposed to solve the influence efficiency maximization problem. Finally, we conduct a series of experiment with real-world data sets to verify the proposed algorithms. The experimental results demonstrate the performance of the proposed algorithms.	entropy maximization	Xiang Zhu;Zhefeng Wang;Yu Kyung Yang;Bin Zhou;Yan Jia	2018	J. Comput. Science	10.1016/j.jocs.2017.11.001	mathematical optimization;submodular set function;propagation time;computation;expected value;data set;diffusion process;maximization;mathematics	Theory	-16.773892844558574	-43.776303872243	44734
b464943176d2f09ee5dc8acc1e2627f0070bd950	a system to capture and generation of traffic information from posted messages on social networks	facebook data mining twitter manuals bills of materials bayesian methods;road traffic;collaboration;data mining;social networking online data mining internet road traffic;collaboration social network data mining data extraction text classification;text classification;social network;data mining traffic information generation posted messages social networks internet intelligent system facebook;internet;data extraction;social networking online	The expansion of the Internet and the growing use of social networks, allowed the capture and use of data related to traffic. This article presents an application, based in an intelligent system that explores the cooperativity of Facebook users so that, by data mining, get a navigable map that points out the most recent transit events reported by users. Thus, it is expected to contribute with useful information that helps any user to take decisions about the best path to be performed for his locomotion, avoiding, for example, traffic jams or accidents that are blocking roads they normally use.		Elisa Hatsue Moriya Huzita;Tainan G. F. de Souza;Yan H. Kabuki	2012	2012 Brazilian Symposium on Collaborative Systems	10.1109/SBSC.2012.25	engineering;data mining;internet privacy;data stream mining;world wide web	Metrics	-25.760484289131526	-49.211959753986825	44758
860e5500838b1d4ecb059e69756c746fb36dae1e	bio-inspired pattern processing by cellular antomata				Arnold L. Rosenberg	2018	J. Cellular Automata		discrete mathematics;computational biology;mathematics	Theory	-8.15697562429981	-48.0122615190789	44783
a4e737e49c9a20a9768ffc5ba8382114444f3115	a new metric to find the most vulnerable node in complex networks		This paper addresses the problem of finding the most synchrony vulnerable node in complex networks, i.e. the node which removal has the maximum influence on synchronizability of the network. In large-scale networks, brute search techniques are often not computationally cost effective in identifying the most vulnerable node(s). Here, considering the eigenratio of the Laplacian matrix of a graph as the synchronizability metric, we propose a measure in order to approximately rank nodes based on their impact on the synchronizability. This metric is cost effective since it needs a single eigen-decomposition of the Laplacian matrix of the connection graph. Simulation results show that the proposed metric is accurate enough in predicting the most vulnerable node in synthetic networks with scale-free, Watts-Strogatz and Erdős-Rényi structures.	brute-force search;complex network;eigen (c++ library);erdős number;erdős–rényi model;heuristic;laplacian matrix;simulation;synthetic intelligence;watts humphrey	Ali Moradi Amani;Mahdi Jalili;Xinghuo Yu;Lewi Stone	2018	2018 IEEE International Symposium on Circuits and Systems (ISCAS)	10.1109/ISCAS.2018.8351133	robustness (computer science);laplacian matrix;computer science;control theory;eigendecomposition of a matrix;complex network;theoretical computer science;synchronization;graph	Arch	-14.057144533141145	-41.423081739846886	44814
074dad4fcf2aa68f2fc28af4bdd60fe36c21248f	probabilistic models for contextual agreement in preferences	user preference;contextual agreement;generative model	The long-tail theory for consumer demand implies the need for more accurate personalization technologies to target items to the users who most desire them. A key tenet of personalization is the capacity to model user preferences. Most of the previous work on recommendation and personalization has focused primarily on individual preferences. While some focus on shared preferences between pairs of users, they assume that the same similarity value applies to all items. Here we investigate the notion of “context,” hypothesizing that while two users may agree on their preferences on some items, they may also disagree on other items. To model this, we design probabilistic models for the generation of rating differences between pairs of users across different items. Since this model also involves the estimation of rating differences on unseen items for the purpose of prediction, we further conduct a systematic analysis of matrix factorization and tensor factorization methods in this estimation, and propose a factorization model with a novel objective function of minimizing error in rating differences. Experiments on several real-life rating datasets show that our proposed model consistently yields context-specific similarity values that perform better on a prediction task than models relying on shared preferences.	experiment;long tail;loss function;optimization problem;personalization;real life;user (computing)	Loc Do;Hady Wirawan Lauw	2016	ACM Trans. Inf. Syst.	10.1145/2854147	computer science;machine learning;data mining;database;generative model;world wide web;information retrieval	Web+IR	-18.701272135208615	-47.532398227822576	44880
e666e5577082cd33737c8723c25ee6aa1d2f02ef	unrest news amount prediction with context-aware attention lstm		Accurately predicting social unrest events is crucial to improve public security. Currently, with the large scale news event datasets available such as GDELT, we can use the amount of unrest news to estimate the risk of instability which is particularly helpful in resource allocation and policy making. Thus in this paper we propose a context-aware attention based long short-term memory (LSTM) prediction framework named CA-LSTM to accurately predict the amount of unrest news of each country or state in the future. Specifically, we first use LSTM to learn the hidden representation from the raw time series data, and then we employ a temporal attention mechanism to learn the importance weight of each time slot. Finally, a fully connected layer is adopted to predict the future unrest news amount by combining the context information and the time series embedding vectors. We conduct extensive experiments on the GDELT data of the United States, and the results demonstrate the effectiveness of the proposed framework.	long short-term memory;unrest	Xiuling Wang;Hao Chen;Zhoujun Li;Zhonghua Zhao	2018		10.1007/978-3-319-97310-4_42	computer science;time series;machine learning;artificial intelligence;embedding;importance weight;resource allocation;unrest	NLP	-15.686590471983084	-32.26063400309344	44953
b89cfb3cfb8558b6a718fec206c34f7f4e51a49e	individual mobility profiles: methods and application on vehicle sharing		In this paper we present a methodology for extracting mobility profiles of individuals from raw digital traces (in particular, GPS traces), and study criteria to match individuals based on profiles. We instantiate the profile matching problem to a specific application context, namely proactive car pooling services, and therefore develop a matching criterion that satisfies various basic constraints obtained from the background knowledge of the application domain. In order to evaluate the impact and robustness of the methods introduced we present an experiment which is performed on a massive dataset containing GPS traces of private cars.	application domain;context (computing);digital footprint;global positioning system;individual mobility;tracing (software)	Roberto Trasarti;Fabio Pinelli;Mirco Nanni;Fosca Giannotti	2012			data mining;global positioning system;robustness (computer science);simulation;application domain;individual mobility;pooling;application context;computer science	HCI	-17.93911699262774	-36.05687396609613	44968
cc9ea28ae3fac3acd5692bd47a0d26886f8fc9ef	ricochet: context and complementarity-aware, ontology-based pois recommender system		In this paper we propose a new approach for improving the personalization of POIs recommender system. Existing context-aware POIs recommender systems usually take into account only peripheral contextual variables. We present Ricochet, an ontology-based system that refines the recommendation results by implementing an inter-POI parameter that we call the “complementarity”. We show how this new parameter can generate more effective recommendations. Our experiments are grounded using data from the location-based social network (LBSN) Yelp.com.	complementarity (physics);complementarity theory;experiment;geosocial networking;peripheral;personalization;point of interest;recommender system;ricochet;social network	Chun Lu;Philippe Laublet;Milan Stankovic	2014			computer science;knowledge management;data mining;world wide web	AI	-26.873401436346494	-49.77614809399171	45005
07bf5d8e2959eb5a7d942d62b9341159ef850be1	query-driven data profiling with oceanprofile		Complex data analysis scenarios often require discovering and combining multiple data sources. Data scientists usually formulate a series of SQL queries building on each other, also called a session, to iteratively derive results. However, due to a lack of familiarity with data sources or the complexity of query results, it can be a hard task to decide on the next query iteration solely based on the results of the last one.  While existing approaches provide mechanisms to assess the results of a specific query, support for analyzing results in the context of the respective session remains mostly absent. Such approaches do also not seamlessly integrate with established tools and workflows.  To overcome these problems, we introduce OCEANProfile, a framework for session-based profiling of query results. Query results are intercepted at driver level and streamed into our framework for automated data profiling. Result profiles can be compared with those of previous queries and visualized in a companion app compatible with existing analysis tools. Visualizations are automatically ranked according to their usefulness in the context of the respective session.	algorithm;information retrieval;iteration;plug-in (computing);profiling (computer programming);sql;second screen;streaming media	Andreas M. Wahl;Christian Sauerhammer;Peter K. Schwab;Sebastian Herbst;Richard Lenz	2018		10.1145/3242153.3242154	data integration;database;software analytics;data mining;real-time enterprise;data profiling;profiling (computer programming);sql;computer science;workflow;complex data type	DB	-31.430947505188204	-31.482120895682687	45251
fdbe09c893321a3c2afd293769024698c45be8d5	satellite image retrieval using low memory locality sensitive hashing in euclidean space	locality sensitive hashing;time complexity;exact nearest neighbor;image;texture features;defense meteorological satellite program;feature vector;wavelet transform;item;hash table;texture feature vector and match set;nearest neighbor;satellite image;euclidean space;approximate nearest neighbor;satellite imagery;hash function;data structure;gaussian distribution	This paper presents the use of the Low Memory Locality Sensitive Hashing (LMLSH) technique operating in Euclidean space to build a data structure for the Defense Meteorological Satellite Program (DMSP) satellite imagery database. The LMLSH technique finds satellite image matches in sublinear search time. The texture feature vectors of the images are extracted using pyramid-structured wavelet transform coupled with Gaussian central moment technique. These feature vectors and families of hash functions, drawn randomly and independently from a Gaussian distribution, are used to build hash tables. Given a query, the hash tables are used to pull out the best matches to that query and this is done in a sublinear search time complexity. When tested, our algorithm has proven to be approximately twenty six times faster than the Linear Search (LS) algorithm. In addition, the LMLSH algorithm searches about two percent of the entire database randomly to find the possible matches to any given query without loss of accuracy compared to the absolute best matches returned by its LS counterpart.	image retrieval;locality of reference;locality-sensitive hashing	Ruben Buaba;Abdollah Homaifar;Mohamed Gebril;Eric A. Kihn;Mikhail N. Zhizhin	2011	Earth Science Informatics	10.1007/s12145-010-0076-x	normal distribution;time complexity;hash table;double hashing;hash function;feature vector;data structure;computer science;euclidean space;theoretical computer science;machine learning;image;pattern recognition;data mining;database;mathematics;programming language;k-nearest neighbors algorithm;locality-sensitive hashing;wavelet transform	Vision	-4.9601605630694	-41.714851044691066	45292
8f03d8d2b3d95f26604b622ff1a92407371058ec	visualizing web site comparisons	web site comparison;web pages;user interface;browsing;visualization;visualization technique;cluster system;business intelligence	The Web is increasingly becoming an important channel for conducting businesses, disseminating information, and communicating with people on a global scale. More and more companies, organizations, and individuals are publishing their information on the Web. With all this information publicly available, naturally companies and individuals want to find useful information from these Web pages. As an example, companies always want to know what their competitors are doing and what products and services they are offering. Knowing such information, the companies can learn from their competitors and/or design countermeasures to improve their own competitiveness. The ability to effectively find such business intelligence information is increasingly becoming crucial to the survival and growth of any company. Despite its importance, little work has been done in this area. In this paper, we propose a novel visualization technique to help the user find useful information from his/her competitors' Web site easily and quickly. It involves visualizing (with the help of a clustering system) the comparison of the user's Web site and the competitor's Web site to find similarities and differences between the sites. The visualization is such that with a single glance, the user is able to see the key similarities and differences of the two sites. He/she can then quickly focus on those interesting clusters and pages to browse the details. Experiment results and practical applications show that the technique is effective.	browsing;cluster analysis;countermeasure (computer);web page;world wide web	Bing Liu;Kaidi Zhao;Lan Yi	2002		10.1145/511446.511536	web service;web application security;web development;web modeling;web analytics;visualization;web mapping;web design;web standards;computer science;web navigation;web page;data mining;database;multimedia;business intelligence;web intelligence;web engineering;user interface;web 2.0;world wide web	Web+IR	-30.358814218204774	-50.61968466828755	45327
8e3163d97a69ebe5c75bda1f28a55076bf664f41	a visual interface technique for exploring olap data with coordinated dimension hierarchies	data cube;query refinement;olap;hierarchies;multi dimensional;interface;data exploration;visual interfaces	Multi-dimensional data occurs in many domains while a wide variety of text based and visual interfaces for querying such data exists. But many of these interfaces are not applicable to OLAP, as they do not support use of dimension hierarchies for selection and aggregation. We introduce an interface technique which supports visual querying of OLAP data, that has been implemented in the SGViewer tool. It is based on a data graph rather than a data cube representation of the data. Our interface presents each dimension hierarchy in a zoomable panel which supports selection and aggregation at multiple levels. Users explore data and query it by making selections in several dimension views. Three view coordinations are identified; progressive, global and result only. Our main contribution, the progressive view coordination provides better support for query refinement than existing interfaces, by helping users decide the next query step with intermediate result overviews, and by helping users change a previous selection decision with retained selection context views. Our interface technique is demonstrated with a web log dataset of visits organised into time, download, visitor and referrer address dimensions.	blog;data cube;digital zoom;download;online analytical processing;refinement (computing);text-based (computing)	Mark Sifer	2003		10.1145/956863.956966	online analytical processing;computer science;interface;data mining;database;programming language;world wide web;information retrieval;data cube;hierarchy	DB	-30.44648269951018	-34.11189856761525	45342
7860f8779bad96832e0e103a8f4cf043cf51f128	preference relation-based markov random fields for recommender systems	pairwise preference;markov random fields;collaborative filtering;preference relation;recommender systems	A preference relation-based Top-N recommendation approach is proposed to capture both second-order and higher-order interactions among users and items. Traditionally Top-N recommendation was achieved by predicting the item ratings first, and then inferring the item rankings, based on the assumption of availability of explicit feedback such as ratings, and the assumption that optimizing the ratings is equivalent to optimizing the item rankings. Nevertheless, both assumptions are not always true in real world applications. The proposed approach drops these assumptions by exploiting preference relations, a more practical user feedback. Furthermore, the proposed approach enjoys the representational power of Markov Random Fields thus side information such as item and user attributes can be easily incorporated. Comparing to related work, the proposed approach has the unique property of modeling both second-order and higher-order interactions among users and items. To the best of our knowledge, this is the first time both types of interactions have been captured in preference-relation based methods. Experimental results on public datasets demonstrate that both types of interactions have been properly captured, and significantly improved Top-N recommendation performance has been achieved.	computation;interaction;least squares;markov chain;markov random field;page view;parallel computing;recommender system;roland gs	Shaowu Liu;Gang Li;Truyen Tran;Yuan Jiang	2015	Machine Learning	10.1007/s10994-016-5603-7	computer science;knowledge management;collaborative filtering;machine learning;data mining;recommender system	AI	-18.987951754139985	-47.82021563610756	45424
b0914f682224d39eee0a9c0cd9b32afbc6d944ed	field selection for job categorization and recommendation to social network users	vectors recommender systems facebook linkedin support vector machines conferences;field selection;support vector machines;linkedin;job recommendation;cross matching strategy field selection job categorization job recommendation social network users web 2 0 compact formalization social network environments e recruitment problems;job categorization;social networking online internet job specification recruitment;vectors;facebook;linkedin job recommendation job categorization field selection svm facebook;svm;recommender systems;conferences	Nowadays, in the Web 2.0 reality, one of the most challenging task for companies that aim to manage and recommend job offers is to convey this enormous amount of information in a succinct and intelligent manner such to increase the performances of matching operations against users profiles/curricula and optimize the time/space complexity of these processes. With this goal, this paper presents a novel method to formalize the textual content of job offers that aims at identifying the most relevant information and fields expressed by them and leverage this compact formalization for job recommendation and profile matching in social network environments. This method has been then developed and tested in the industrial environment represented by Multiposting and Work4, world leaders in digital solutions of e-recruitment problems. In this study three classes of documents are considered: job offers, job categories and social network user profiles (as potential job candidates); each class contains several fields with textual information. The proposed representation method permits to dynamically identify those text fields, for each class, that could help a cross-matching strategy in order to preserve, from one hand, the matching/recommendation performances and, on the other hand, reduce the cost of these operations (due to a straightforward dimensionality reduction mechanism). We then evaluated and compared the presented approach showing significant improvements on both categorization and recommendation tasks by also drastically reducing their computational costs.	analysis of algorithms;categorization;dspace;dimensionality reduction;performance;social network;user profile;web 2.0;world wide web	Emmanuel Malherbe;Mamadou Diaby;Mario Cataldi;Emmanuel Viennet;Marie-Aude Aufaure	2014	2014 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining (ASONAM 2014)	10.1109/ASONAM.2014.6921646	support vector machine;computer science;knowledge management;machine learning;data mining;world wide web;job analysis;recommender system	AI	-26.011210843835503	-50.777461744110674	45479
8107855391f89232aca82170abe0ddb4c9a0fb64	dghpsim: : generic simulation of hospital performance	performance management;accident and emergency;healthcare systems modeling;performance improvement;healthcare system;waiting time;generic simulation;national health service;hospital modeling	The British National Health Service (NHS) has a performance management framework that aims to guarantee short waiting times for patients by including mandatory targets for hospitals. DGHPSim is a suite of four components that simulates the activities of an NHS general hospital to show the effect of different policies on waiting times in these hospitals. DGHPSim has a generic structure that is used to simulate a particular hospital by employing data appropriate to that hospital from available data sets. Two of the components of DGHPSim, the accident and emergency simulator and the outpatient simulator, may be used independently as stand-alone simulators of these hospital functions. The DGHPSim suite incorporates a novel way of simulating the multitasking behavior of clinicians and uses transition matrices, extracted from standard datasets, to represent the states through which patients pass and the wards in which they may be treated. As a whole, the DGHPSim suite may be used to investigate improvement options before their implementation or to investigate how a hospital has improved its performance. We show how DGHPSim is used to investigate reported performance improvements in an English general hospital.	computer multitasking;simulation	Murat M. Gunal;Michael Pidd	2011	ACM Trans. Model. Comput. Simul.	10.1145/2000494.2000496	performance management;simulation	AI	-16.561570325074467	-24.79234364157893	45619
d52c6a37ba27c5fc10814ba55357ab16521c99e1	hourly pedestrian population trends estimation using location data from smartphones dealing with temporal and spatial sparsity	pedestrian population trends estimation;gaussian kernel;traffic census	This paper describes a pedestrian population trend estimation method using location data of smartphone users. This technique is intended to be an alternative to traffic censuses using tally counters. Traffic censuses using tally counters are still commonly used to survey the number of pedestrians despite their cost and limitations in area and time.  The proposed approach can replace the traffic census by using smartphone users' location data accumulated on Yahoo! Japan. Moreover, it is low cost because it uses location data collaterally acquired from smartphone users, and it has no limits in terms of area or time. This means pedestrian population trends in arbitrary and times about which we want to know can be estimated.  The proposed technique is based on the assumption that the number of location data in an area is proportional to the population volume, but it also eliminates some data to increase pedestrian accuracy. In the elimination step, some location data that should not be counted as pedestrians are excluded by estimating transport modes from anteroposterior location data. The supplement step tackles the problem of data shortage when a target area is a small region by using a Gaussian kernel. The Gaussian kernel smoother is also used to deal with data interpolation in the time direction, and it enables us to estimate time-continuous pedestrian volumes in arbitrary areas.  To evaluate the approach, a manual traffic survey was conducted in five areas on 11 days and the ground truth data are acquired. Experimental result shows the approach successfully estimate pedestrian population trends in areas. The proposed method makes less than one-tenth the mean squared errors of hourly pedestrian number estimation than the conventional approach.	ground truth;interpolation;smartphone;sparse matrix	Kentaro Nishi;Kota Tsubouchi;Masamichi Shimosaka	2014		10.1145/2666310.2666391	simulation;computer science;data mining;gaussian function;computer security;cartography;statistics	HCI	-16.49038563252356	-33.80415668889306	45625
7880c6868168da4e4a41f6abf336e7fb936114e1	from microblogs to social images: event analytics for situation assessment	real time;situation;detection;analytics;multimedia data;control;twitter;situation assessment;microblogs	With the rising popularity of microblogging sites like Twitter and Jaiku, we are seeing huge volumes of user generated spatio-temporal-thematic data being created in real time. If combined effectively, this multimedia data can be used to detect events, and understand various 'situations' as they are evolving at different spatio-temporal granularity across the world. In this work, we demonstrate the use of a 'social pixel' based approach to situation assessment. Taking inspiration from traditional image pixels which represent aggregation of photon energies at a location, we consider aggregation of user interest levels at a different geo-locations as 'social pixels'. Combining such pixels spatio-temporally allows for creation of social images and video. We demonstrate how the use of relevant media operators upon such 'images', and use of domain based rules can be used to decide relevant control action decisions to be taken at both, micro and macro levels. The ideas are showcased using a Swine flu monitoring application which uses Twitter data.	crowdsourcing;humans;multimodal interaction;organizing (structure);pixel;sensor	Vivek K. Singh;Mingyan Gao;Ramesh Jain	2010		10.1145/1743384.1743460	analytics;computer science;microblogging;data mining;internet privacy;situation analysis;world wide web;scientific control	ML	-26.081540525906448	-45.43585836468125	45696
2a687e15b2bedfa341a6eb12667a93facf939f35	a refined immune systems inspired model for multi-robot shepherding	immune network;motion control;immune systems;immune system robots silicon biological system modeling;qr180 immunology;shepherding;multi robot system;mobile robots;q science general;action selection;simulation experiment;qa75 electronic computers computer science;multi robot systems;immune system;multi robot systems artificial immune systems mobile robots motion control;network theory;immune network immune systems multi robot shepherding;shepherd formation refined immune system multirobot shepherding biological immune system organism health state multirobot system immune network theory memory based immune network robot action selection process immune network t cell regulated with memory model robot dog;artificial immune systems;multi robot	In this paper, basic biological immune systems and their responses to external elements to maintain an organism's health state are described. The relationship between immune systems and multi-robot systems are also discussed. The proposed algorithm is based on immune network theories that have many similarities with the multi-robot systems domain. The paper describes a refinement of the memory-based immune network that enhances a robot's action-selection process. The refined model; which is based on the Immune Network T-cell-regulated—with Memory (INT-M) model; is applied onto the dog and sheep scenario. The refinements involves the low-level behaviors of the robot dogs, namely Shepherds' Formation and Shepherds' Approach. The shepherds would form a line behind the group of sheep and also obey a safe zone of each sheep, thus achieving better control of the flock. Simulation experiments are conducted on the Player/Stage platform.	action selection;algorithm;application domain;e-puck mobile robot;experiment;flock;high- and low-level;int (x86 instruction);refinement (computing);robot;scenario testing;simulation;vii	Sazalinsyah Razali;Qinggang Meng;Shuang-Hua Yang	2010	2010 Second World Congress on Nature and Biologically Inspired Computing (NaBIC)	10.1109/NABIC.2010.5716358	simulation;immune system;computer science;artificial intelligence	Robotics	-5.790284523553676	-48.94991796983564	45716
74f471c6f5694ee6018c318b0e0f51bc7063cb29	what to play next? a rnn-based music recommendation system		"""In the very recent years, development of music recommendation system has been a more heated problem due to a higher level of digital songs consumption and the advancement of machine learning techniques. Some traditional approaches such as collaborator filtering, has been widely used in recommendation systems, have helped music recommendation system to give music listeners a quick access to the music. However, collaborative filtering or model based algorithm have limitations in giving a better result with the ignorance of combination factor of lyrics and genre. In our paper, we will propose an improved algorithm based on deep neural network on measure similarity between different songs. The proposed method will make it possible that it could make recommendations in a large system to make comparisons by """"understand"""" the content of songs. In this paper, we propose an end-end model, which is based on recurrent neural network to predict user's next most possible song by similarity. We will make experiments and evaluations based on Million Song Dataset and demonstrate how it outperformed the traditional methods."""	algorithm;artificial neural network;collaborative filtering;deep learning;experiment;machine learning;random neural network;recommender system;recurrent neural network	Miao Jiang;Ziyi Yang;Chen Zhao	2017	2017 51st Asilomar Conference on Signals, Systems, and Computers	10.1109/ACSSC.2017.8335200	recommender system;mathematical optimization;ignorance;collaborative filtering;computer science;filter (signal processing);artificial neural network;lyrics;recurrent neural network;machine learning;artificial intelligence	AI	-18.779327185184993	-50.48302049718682	45717
86b68d234915818760da51a68a1a421a9c8092c1	vehicle activity segmentation from position data	automatic vehicle location;image segmentation;optimal method;traffic engineering computing data mining global positioning system image segmentation learning artificial intelligence;global position system;large mining operations vehicle activity segmentation electronic vehicle guidance systems global positioning system receivers wireless communication infrastructure machine learning techniques vehicle position data probabilistic activity segmentation model optimization methods;data mining;wireless communication;machine learning;mathematical models;global positioning system;traffic engineering computing;acceleration mathematical model vehicles driver circuits covariance matrix probabilistic logic data models;learning artificial intelligence	Electronic vehicle guidance systems have gained much popularity over the last years. The massive use of inexpensive global positioning system receivers, combined with the rapidly increasing availability of wireless communication infrastructure, suggests that large amounts of data combining both modalities will be available in a near future. The approach presented here draws on machine learning techniques and processes logs of vehicle position data to consistently infer activities and actions carried out by one or more vehicles. A fully probabilistic activity segmentation model is introduced and specific optimization methods are applied in order to learn the model parameters in a completely unsupervised manner. Experimental results with data from large mining operations are presented to validate the new model.	algorithm;global positioning system;ground truth;guidance system;high- and low-level;machine learning;mathematical optimization;visual inspection	Gabriel Agamennoni;Juan I. Nieto;Eduardo M. Nebot	2010	13th International IEEE Conference on Intelligent Transportation Systems	10.1109/ITSC.2010.5625151	simulation;engineering;machine learning;data mining	Robotics	-14.966993047610936	-33.12330427198403	45801
711b14ea4e52bbc93135f5679c9f42f0e50779a8	efficient algorithms for spatial skyline query with uncertainty	uncertainty;spatial skyline query	Given a set of points of interest (POIs), the spatial skyline query for a set of locations returns the POIs that are close to all locations. Answering spatial skyline query can find many applications in Geographical Information Systems. In this paper, we consider the problem of spatial skyline query with uncertainty. Two types of uncertainty are investigated. First, location uncertainty arises when query point (user) locations are not known exactly either due to privacy concerns or measurement limitations. Second, error margins can be used to model tolerance to distance measurement errors between POIs and query points. We devise efficient polynomial-time algorithms to address both types of uncertainty, and rigorously prove their correctness.	algorithm;correctness (computer science);geographic information system;pareto efficiency;point of interest;polynomial;time complexity	Khuong Vu;Rong Zheng	2013		10.1145/2525314.2525448	query optimization;web query classification;uncertainty;computer science;data mining;database;information retrieval;statistics;spatial query	DB	-8.169461362362474	-33.99764494795879	45922
4c99d0bec77a6cd61abccc9b5437932152076bfa	scout: a point of presence recommendation system using real user monitoring data		This paper describes, Scout, a statistical modeling driven approach to automatically recommend new Point of Presence (PoP) centers for web sites. PoPs help reduce a website’s page download time dramatically. However, where to build the new PoP centers given the current assets of existing ones is a problem that has rarely been studied in a quantitative and principled way before; it was mainly done through empirical studies or through applying industry experience and intuitions. In this paper, we propose a novel approach that estimates the impact of the PoP centers by building a statistical model using the real user monitoring data collected by the web sites and recommend the next PoPs to build. We also consider the problem of recommending PoPs using other metrics such as user’s number of page views. We show empirically that our approach works well, by experiments that use real data collected from millions of user visits in a major social network site.	recommender system;scout	Yang Yang;Liang Zhang;Ritesh Maheshwari;Zaid Ali Kahn;Deepak Agarwal;Sanjay Dubey	2016		10.1007/978-3-319-30505-9_16	embedded system;real-time computing;world wide web	Theory	-24.07192263027542	-46.771521755342384	46045
875204545726f5f334c214a4078a95b9e1912676	a genetic algorithm approach to interactive narrative generation	storytelling engines;interactive narrative;genetic algorithm;genetic algorithms	We discuss the design of the Hybrid Evolutionary-Fuzzy Time-based Interactive (HEFTI) storytelling engine. HEFTI uses genetic algorithms at its core to recombine and evaluate story components generated from a set of story templates. The system allows authors to rely on HEFTI to perform recombination, mutation and selection operations that generate logically congruent variants of the original story via traversal, generation and deletion of (links in) the story elements.	genetic algorithm;tree traversal	TeongJoo Ong;John J. Leggett	2004		10.1145/1012807.1012856	simulation;genetic algorithm;computer science;theoretical computer science;multimedia	AI	-29.372911641881178	-25.21274956422447	46091
2d1af5c3bbabd23a82dae8d14f63c3531ab5227f	cp-index: using clustering and pivots for indexing non-metric spaces	metric space;non metric distance;data collection;triangle inequality;sequential search;satisfiability;multimedia information retrieval;indexing;clustering;indexation;pivots;dynamic adaptation;similarity search	Most multimedia information retrieval systems use an indexing scheme to speed up similarity search. The index aims to discard large portions of the data collection at query time. Generally, these approaches use the triangular inequality to discard elements or groups of elements, thus requiring that the comparison distance satisfies the metric postulates. However, recent research shows that, for some applications, it is appropriate to use a non-metric distance, which can give more accurate judgments about the similarity of two objects. In such cases, the lack of the triangle inequality makes impossible to use the traditional approaches for indexing. In this paper we introduce the CP-index, a new approximate indexing technique for non-metric spaces that combines clustering and pivots. The index dynamically adapts to the conditions of the non-metric space using pivots when the fraction of triplets that break the triangle inequality is small, but sequentially searching the most promising candidates when the pivots becomes ineffective.	approximation algorithm;cluster analysis;color space;information retrieval;linear search;similarity search;social inequality	Victor Raul Sepulveda;Benjamin Bustos	2010		10.1145/1862344.1862356	m-tree;linear search;search engine indexing;combinatorics;mathematical analysis;discrete mathematics;topology;metric space;computer science;machine learning;triangle inequality;data mining;database;mathematics;geometry;cluster analysis;algorithm;statistics;satisfiability;data collection	DB	-5.787753059143969	-41.634604746402466	46131
4cf251f541fdfa0dbdc05e7166da661f350fa585	learning temporal context for activity recognition		Abstract. We present a method that allows to improve activity recognition using temporal and spatial context. We investigate how incremental learning of long-term human activity patterns improves the accuracy of activity classification over time. Two datasets collected over several months containing hand-annotated activity in residential and office environments were chosen to evaluate the approach. Several types of spatial and temporal models were evaluated for each of these datasets and the efficiency of each method was assessed by the way it improved activity classification. The results indicate that incremental learning of daily routines allows to dramatically improve activity classification. For example, a weak classifier deployed in a single-inhabited apartment for a period of three weeks was enhanced with a temporal model that increased its accuracy from 20% to 60%.	activity recognition;adaptive behavior;benchmark (computing);densely packed decimal;location-based service;mobile robot;performance;sparse matrix;statistical classification	Claudio Coppola;Tomás Krajník;Tom Duckett;Nicola Bellotto	2016		10.3233/978-1-61499-672-9-107	artificial intelligence;incremental learning;computer science;machine learning;temporal context;prior probability;activity recognition;pattern recognition	ML	-17.177382869944868	-33.33275741910877	46198
df10d64ece26e34ad8927426abb81b5675093d06	fast and differentially private algorithms for decentralized collaborative machine learning		Consider a set of agents in a peer-to-peer communication network, where each agent has a personal dataset and a personal learning objective. The main question addressed in this paper is: how can agents collaborate to improve upon their locally learned model without leaking sensitive information about their data? Our first contribution is to reformulate this problem so that it can be solved by a block coordinate descent algorithm. We obtain an efficient and fully decentralized protocol working in an asynchronous fashion. Our second contribution is to make our algorithm differentially private to protect against the disclosure of any information about personal datasets. We prove convergence rates and exhibit the trade-off between utility and privacy. Our experiments show that our approach dramatically outperforms previous work in the non-private case, and that under privacy constraints we significantly improve over purely local models.	algorithm;asynchronous i/o;coordinate descent;experiment;information sensitivity;machine learning;peer-to-peer;private case;telecommunications network	Aurélien Bellet;Rachid Guerraoui;Mahsa Taziki;Marc Tommasi	2017	CoRR		computer science;machine learning;data mining;distributed computing	ML	-8.735778517569353	-29.09052703369625	46227
c5857ffd068008659037cea2297105dc0c1e24c1	predicting cost escalation pathways and deviation severities of infrastructure projects using risk-based econometric models and monte carlo simulation		In the past decade, infrastructure-related legislation in the United States has consistently emphasized the need to measure the variation associated with infrastructure project cost estimates. Such cost variability is best viewed from the perspective of the project development phases and how the project cost estimate changes as it evolves across these phases. The article first identifies a few gaps in the cost overrun literature. Then it introduces a methodology that uses risk-based multinomial models and Monte Carlo simulation involving random draws to predict the probability that a project will follow a particular cost escalation pathway across its development phases and that it will incur a given level of cost deviation severity. The article then uses historical data to demonstrate how infrastructure agencies could apply the proposed methodology. Statistical models are developed to estimate the probability that a highway project will follow any specific cost escalation pathway and ultimately, a given direction and severity of cost deviation. The case study results provided some interesting insights. For a given highway functional class, larger project sizes are associated with lower probability of underestimating the final cost; however, such a trend is not exhibited by very large projects (total cost exceeding $30M). For a given project size, higher class roads were generally observed to have a lower probability of underestimating the final cost, compared to lower class roads and this gap in probability narrows as the project size increases. It was determined that a project’s most likely pathway of cost escalation is not a guarantee that it will yield any particular direction of cost deviation. The case study results also confirmed ∗To whom correspondence should be addressed. E-mail: labi@ purdue.edu. the findings of a few past studies that the probabilities of cost escalation pathways and the cost overruns differ significantly across highway districts, and attributed this to differences in administrative culture and work practices across the districts. Infrastructure managers can use the developed methodology to identify which projects are likely to experience a particular pathway of cost escalation, the direction and severity of cost deviation, and to develop more realistic project contingency estimates.	algorithm;contingency plan;discrete choice;econometric model;futures studies;gene regulatory network;heart rate variability;mixed logit;monte carlo method;multinomial logistic regression;privilege escalation;relevance;self-replicating machine;simulation;spatial variability;statistical model;value (ethics)	Abhishek Bhargava;Samuel Labi;Sikai Chen;Tariq Usman Saeed;Kumares C. Sinha	2017	Comp.-Aided Civil and Infrastruct. Engineering	10.1111/mice.12279	mathematical optimization;total cost;reliability engineering;econometrics;monte carlo method;cost contingency;engineering;project management;cost escalation;cost estimate;cost overrun;econometric model	SE	-10.31508294335857	-25.03017898474923	46269
371c273c39f985371e7548f24175ae32b9169fd8	game-based e-retailing in golem agent environments	multi agent system;social interaction;agent environments;e retailing;games;semantic web;social environment	We present a prototype multi-agent system whose goal is to support a 3D application for e-retailing. The prototype demonstrates how the use of agent environments can be amongst the most promising and flexible approaches to engineer e-retailing applications. We illustrate this point by showing how the agent environment GOLEM supports social interactions and how it combines them with semantic web technologies to develop the e-retailing application. We also describe the features of GOLEM that allow a user to engage in e-retailing activities in order to explore the virtual social environment by searching and dynamically discovering new agents, products and services.	autonomous robot;avatar (computing);entity;golem (ilp);intelligent agent;interaction;library (computing);multi-agent system;prototype;semantic web;virtual reality	Stefano Bromuri;Visara Urovi;Kostas Stathis	2009	Pervasive and Mobile Computing	10.1016/j.pmcj.2009.05.003	games;social environment;social relation;simulation;human–computer interaction;computer science;semantic web;multi-agent system;multimedia;agent-based social simulation	HCI	-33.68169941372732	-24.45655804415036	46288
28bdd1b551155203c782fba10e9b9404008d77ef	a trust-based service suggestion system using human plausible reasoning	anova;agent trust management;trust based recommender systems;human plausible reasoning;web search	Nowadays, there is a growing need to manage trust in open systems as they may contain untrustworthy service providers. Agent Trust Management (ATM) tries to address the problem of finding a set of the most trusted agents in multi agent systems. This paper presents ScubAA, a novel generic ATM framework based on the theory of Human Plausible Reasoning (HPR). For each user’s request, ScubAA determines a ranked list of the most trusted service agents, within the context of the request, and forwards the request to those trusted services only. ScubAA determines an agent’s degree of trust in terms of a single personalized value derived from several types of evidences such as user’s feedback, history of user’s interactions, context of the submitted request, references from third party users as well as from third party service agents, and structure of the society of agents. ScubAA is able to utilize more trust evidences towards a more accurate value of trust. We also propose a function to figure out how similar two users are in a given context. We apply the proposed HPR-based ATM framework to the domain of Web search. The resulting ATM system recommends to the user a list of the most trusted search engines ranked according to the retrieval precision of documents returned in response to the user’s query as well as the degree of trust of the search engines have gained by interacting with other related users within the context of the query. In addition, we conduct a statistical analysis of ScubAA based on ANOVA and by using a data set of forty queries in different domains. This analysis clearly reveals that ScubAA is able to successfully assess the trustworthiness of service agents.	atm turbo;interaction;personalization;proteomics;trust (emotion);trust management (information system);trust management (managerial science);web search engine	Sadra Abedinzadeh;Samira Sadaoui	2013	Applied Intelligence	10.1007/s10489-013-0495-8	analysis of variance;trust anchor;computer science;data mining;internet privacy;world wide web;computational trust;statistics	Web+IR	-23.840724887506212	-46.60229531931479	46296
1d6e5b471a414fb5efc03105f5ab51e62b868a30	fast-forwarding crowd simulations		The processing time to simulate crowds for games or simulations is a real challenge. While the increasing power of processing capacity is a reality in the hardware industry, it also means that more agents, better rendering and most sophisticated Artificial Intelligence (AI) methods can be used, so again the computational time is an issue. Despite the processing cost, in many cases the most interesting period of time in a game or simulation is far from the beginning or in a specific known period, but it is still necessary to simulate the whole time (spending time and processing capacity) to achieve the desired period of time. It would be useful to fast forward the time in order to see a specific period of time where simulation result could be more meaningful for analysis. This paper presents a method to provide time travel in Crowd Simulation. Based on crowd features, we compute the expected variation in velocities and apply that for time travel in crowd simulation.	artificial intelligence;computation;computer simulation;crowd simulation;fast forward;time complexity	Cliceres Mack Dal Bianco;Adriana Braun;Soraia Raupp Musse;Cláudio Rosito Jung;Norman I. Badler	2016		10.1007/978-3-319-47665-0_19	simulation;multimedia;rendering (computer graphics);crowds;computer science;time travel;crowd simulation	AI	-20.701661400585415	-25.523425826776695	46380
21a854316fb6fee692c9732e1c81eef6b58c2f5d	mining periodic behavior in dynamic social networks	social network services;graph theory;periodic interaction patterns periodic behavior mining dynamic social networks social interactions computational complexity;time scale;complexity theory;social interaction;probability density function;data mining;polynomials;dynamic social networks;pattern mining;upper bound;social network;pattern mining social networks;computational complexity;social networks;heuristic algorithms;interaction pattern;social networking online;social networking online data mining graph theory;human animation;network computing;data mining heuristic algorithms complexity theory polynomials upper bound social network services probability density function	Social interactions that occur regularly typically correspond to significant yet often infrequent and hard to detect interaction patterns. To identify such regular behavior, we propose a new mining problem of finding periodic or near periodic subgraphs in dynamic social networks. We analyze the computational complexity of the problem, showing that, unlike any of the related subgraph mining problems, it is polynomial. We propose a practical, efficient and scalable algorithm to find such subgraphs that takes imperfect periodicity into account. We demonstrate the applicability of our approach on several real-world networks and extract meaningful and interesting periodic interaction patterns.	cobham's thesis;computational complexity theory;ecology;file spanning;heuristic;hollywood;ibm notes;interaction;mined;one-pass algorithm;polynomial;pure function;quasiperiodicity;scalability;social network;time complexity;zebra patterning	Mayank Lahiri;Tanya Y. Berger-Wolf	2008	2008 Eighth IEEE International Conference on Data Mining	10.1109/ICDM.2008.104	computer science;graph theory;theoretical computer science;machine learning;data mining;mathematics;social network	DB	-11.552922576828273	-39.15761249639324	46461
d556f50b4cd41a140f52008860e3ab18552b4d6c	analyzing user modeling on twitter for personalized news recommendations	semantics;personalization;user modeling;twitter	How can micro-blogging activities on Twitter be leveraged for user modeling and personalization? In this paper we investigate this question and introduce a framework for user modeling on Twitter which enriches the semantics of Twitter messages (tweets) and identifies topics and entities (e.g. persons, events, products) mentioned in tweets. We analyze how strategies for constructing hashtag-based, entity-based or topic-based user profiles benefit from semantic enrichment and explore the temporal dynamics of those profiles. We further measure and compare the performance of the user modeling strategies in context of a personalized news recommendation system. Our results reveal how semantic enrichment enhances the variety and quality of the generated user profiles. Further, we see how the different user modeling strategies impact personalization and discover that the consideration of temporal profile patterns can improve recommendation quality.	blog;entity;gene ontology term enrichment;hashtag;personalization;recommender system;user modeling;user profile	Fabian Abel;Qi Gao;Geert-Jan Houben;Ke Tao	2011		10.1007/978-3-642-22362-4_1	user modeling;computer science;multimedia;internet privacy;world wide web	Web+IR	-26.190611901530094	-48.79969132344952	46463
b7778be6f5b471e0dbef55ea54af8ac49517df36	an efficient approach to updating closeness centrality and average path length in dynamic networks	directed graphs;time measurement;approximation algorithms;communication efficiency updating closeness centrality average path length dynamic networks apl measures all pair shortest path distances breadth first search method facebook edge counts cendy approach edge insertion edge deletion single source shortest path computations real world graph datasets specific vertex;length measurement;length measurement time measurement approximation methods joining processes approximation algorithms heuristic algorithms algorithm design and analysis;closeness centrality;computational complexity;heuristic algorithms;update algorithm;joining processes;average path length;approximation methods;dynamic networks closeness centrality average path length update algorithm;tree searching;tree searching computational complexity directed graphs network theory graphs;network theory graphs;algorithm design and analysis;dynamic networks	Closeness centrality measures the communication efficiency of a specific vertex within a network while the average path length (APL) measures that of the whole network. Since the nature of these two measurements is based on the computation of all-pair shortest path distances, one can perform the breadth-first search method starting at every vertex and obtain the two measurements. However, as the edge counts in the real-world networks like Facebook increase over time, this naive way is obviously inefficient. In this paper, we proposed CENDY, an efficient approach to updating Closeness centrality and average path length in Dynamic networks when there is an edge insertion or deletion. In CENDY, we derived some theoretical properties to quickly identify a set of vertices whose shortest path changed after an edge update, and then update the closeness centralities of those vertices only as well as the APL of the graph by a few of single-source shortest path computations. We conducted extensive experiments to show that, when compared to the existing methods of computing exact or approximate values, CENDY outperformed others in significantly low update time while providing exact values of the two measurements on various real-world graph datasets.	apl;approximation algorithm;average path length;breadth-first search;closeness centrality;computation;control theory;experiment;shortest path problem;vertex (geometry)	Chia-Chen Yen;Mi-Yen Yeh;Ming-Syan Chen	2013	2013 IEEE 13th International Conference on Data Mining	10.1109/ICDM.2013.135	algorithm design;random walk closeness centrality;combinatorics;discrete mathematics;directed graph;longest path problem;average path length;length measurement;computer science;machine learning;mathematics;centrality;shortest path problem;computational complexity theory;distance;approximation algorithm;time	DB	-10.250306989682738	-41.1088659063878	46541
b1ddd6986673f3d86650124795d99a3afa2de95a	dimension projection matrix/tree: interactive subspace visual exploration and analysis of high dimensional data	sub dimensional space;tree data visualization image color analysis correlation clustering algorithms algorithm design and analysis matrix high dimensional data hierarchical visualization sub dimensional space user interaction subspace;pattern clustering;tree;data visualization image color analysis correlation clustering algorithms algorithm design and analysis;algorithms computer graphics image enhancement image interpretation computer assisted information storage and retrieval user computer interface;dimension projection matrix;hierarchical visualization;dimension correlation;brushing;trees mathematics;journal;data clusters;subspace;data visualisation;trees mathematics data analysis data visualisation merging pattern clustering;data analysis;image color analysis;期刊论文;high dimensional data;data visualization;merging;clustering algorithms;matrix;correlation;dimension correlation dimension projection matrix interactive subspace visual exploration interactive subspace visual analysis high dimensional data scatterplot matrix dimension projection tree dimension projection plot automation user interaction merging brushing data clusters data correlation;data correlation;user interaction;algorithm design and analysis;dimension projection tree;automation;dimension projection plot	For high-dimensional data, this work proposes two novel visual exploration methods to gain insights into the data aspect and the dimension aspect of the data. The first is a Dimension Projection Matrix, as an extension of a scatterplot matrix. In the matrix, each row or column represents a group of dimensions, and each cell shows a dimension projection (such as MDS) of the data with the corresponding dimensions. The second is a Dimension Projection Tree, where every node is either a dimension projection plot or a Dimension Projection Matrix. Nodes are connected with links and each child node in the tree covers a subset of the parent node's dimensions or a subset of the parent node's data items. While the tree nodes visualize the subspaces of dimensions or subsets of the data items under exploration, the matrix nodes enable cross-comparison between different combinations of subspaces. Both Dimension Projection Matrix and Dimension Project Tree can be constructed algorithmically through automation, or manually through user interaction. Our implementation enables interactions such as drilling down to explore different levels of the data, merging or splitting the subspaces to adjust the matrix, and applying brushing to select data clusters. Our method enables simultaneously exploring data correlation and dimension correlation for data with high dimensions.	algorithm;anatomic node;application program interface;brushing and linking;data item;data visualization;dimensionality reduction;dimensions;imagery;interaction;matrix multiplication;node - plant part;optic nerve glioma, childhood;organic user interface;projections and predictions;silo (dataset);subgroup;the matrix;tree (data structure);usability testing;user interface device component;yang	Xiaoru Yuan;Donghao Ren;Zuchao Wang;Cong Guo	2013	IEEE Transactions on Visualization and Computer Graphics	10.1109/TVCG.2013.150	algorithm design;combinatorics;effective dimension;computer science;theoretical computer science;automation;machine learning;mathematics;cluster analysis;tree;data analysis;correlation;data visualization;matrix;statistics;clustering high-dimensional data	Visualization	-28.222965330227577	-34.017486665855415	46579
1244438d8842f01dcbe3a057f68dc0f8bcadf160	mining association rules from data with missing values by database partitioning and merging	pattern growth based algorithm;tree data structures;database partitioning;data mining;association rule mining;very large database association rule mining pattern growth based algorithm data mining tree structure database partitioning database merging;upper bound;very large database;very large databases data mining merging tree data structures;database merging;data mining association rules databases merging partitioning algorithms laboratories upper bound tree data structures diseases medical treatment;real world application;association rule;tree structure;merging;missing values;very large databases	Often, real world applications contain many missing values. In mining association rules from real datasets, treating missing values is an important problem. In this paper, we propose a pattern-growth based algorithm for mining association rules from data with missing values. No data imputations are performed. Each association rule is evaluated using all the data records with which attributes of it are not missing values. Our algorithm partitions the database so that the data record with which the same attributes contain missing values is assigned to the same database partition, and the algorithm mines association rules by combining these database partitions. We propose methods of reducing processing workload: estimating the upper bound of global support using local supports, reutilizing part of the constructed tree structure, and merging redundant database partitions. Our performance study shows that our algorithm is efficient and can always find all association rules	algorithm;association rule learning;missing data;partition (database);row (database);tree structure	Takahiko Shintani	2006	5th IEEE/ACIS International Conference on Computer and Information Science and 1st IEEE/ACIS International Workshop on Component-Based Software Engineering,Software Architecture and Reuse (ICIS-COMSAR'06)	10.1109/ICIS-COMSAR.2006.60	association rule learning;computer science;data science;data mining;database;imputation	DB	-4.644263826429789	-37.11945657809115	46591
4c3854599b83fb7d08a90e8b0962bffb088ae138	representation and identification of approximately similar event sequences		The MARS (Modelling Autonomous Reasoning System) project aims to develop a collaborative intelligent system combining the processing powers and visualisation provided by machines with the interpretive skills, insight and lateral thinking provided by human analysts. There is an increasing volume of data generated by online systems, such as internet logs, transaction records, communication records, transport network monitors, sensor networks, etc. Typically, these logs contain multiple overlapping sequences of events related to different entities. Information that can be mined from these event sequences is an important resource in understanding current behaviour, predicting future behaviour and identifying non-standard patterns. In this paper, we describe a novel approach to identifying and storing sequences of related events, with scope for approximate matching. The event sequences are represented in a compact and expandable sequence pattern format, which allows the addition of new event sequences as they are identified, and subtraction of sequences that are no longer relevant. We present an algorithm enabling efficient addition of a new sequence pattern. Examination of the sequences by human experts could further refine and modify general patterns of events.	approximation algorithm;artificial intelligence;automata theory;centrality;directed acyclic graph;directed graph;entity;finite-state machine;fuzzy sets and systems;fuzzy logic;fuzzy set;human dynamics;introduction to automata theory, languages, and computation;lateral thinking;mined;non-deterministic turing machine;reasoning system;regular expression;sethi–ullman algorithm;soft computing;tails;theoretical computer science;time complexity	Trevor P. Martin;Ben Azvine	2015		10.1007/978-3-319-26154-6_7	data mining;transport network;wireless sensor network;visualization;subtraction;the internet;reasoning system;computer science;lateral thinking;database transaction	AI	-15.279405506261886	-31.424545341718744	46645
e842f6a688fa9dfd3dab0418cd48d52eb8cbd81f	an efficient subset-lattice algorithm for mining closed frequent itemsets in data streams	closed frequent itemsets;data models data mining;sliding window association rules closed frequent itemsets data streams frequent itemsets;association rules;data mining;data streams;newmoment algorithm subset lattice algorithm closed frequent itemset mining data stream market analysis network security sensor network web tracking association rule mining frequent item set extraction sliding window model;frequent itemsets;itemsets lattices data models loading association rules heuristic algorithms;sliding window;data models	There are many applications of using association rules in data streams, such as market analysis, network security, sensor networks and web tracking. Mining closed frequent item sets is a further work of mining association rules, which aims to find the subsets of frequent item sets that could extract all frequent item sets. Formally, a closed frequent item set is a frequent item set which has no superset with the same support as it. One of well-known algorithms for mining closed frequent item sets based on the sliding window model is the New Moment algorithm. However, the New Moment algorithm could not efficiently mine closed frequent item sets in data streams, since they will generate closed frequent item sets and many unclosed frequent item sets. Moreover, when data in the sliding window is incrementally updated, the New Moment algorithm needs to reconstruct the whole tree structure. Therefore, we propose the Subset-Lattice algorithm which embeds the property of subsets into the lattice structure to efficiently mine closed frequent item sets over a data stream sliding window. Moreover, when data in the sliding window is incrementally updated, our Subset-Lattice algorithm will not reconstruct the whole lattice structure.	algorithm;association rule learning;crystal structure;network security;simulation;subsumption architecture;tree structure	Ye-In Chang;Chia-En Li;Wei-Hau Peng	2012	2012 Conference on Technologies and Applications of Artificial Intelligence	10.1109/TAAI.2012.12	computer science;pattern recognition;data mining;database;apriori algorithm	ML	-6.413397598809539	-36.9405048316075	46650
3653d7c4ee7803236a8b6d5462cf68728f836afa	monetizing user activity on social networks - challenges and experiences	user activity;contentextual ads;social network;intents;user profile;social networks;off topic noise;social networking sites;contentextual ads user activity social networks intents off topic noise	This work summarizes challenges and experiences in monetizing user activity on public forums on social network sites. We present a approach that identifies the monetization potential of user posts and eliminates off-topic content to identify the most relevant and monetizable keywords for advertising. Preliminary studies using data from MySpace and Facebook show that 52% of ad impressions generated using keywords from our system were more targeted compared to the 30% relevant impressions generated without using our system.	experience;impression (online media);monetization;off topic;social network	Meena Nagarajan;Kamal Baid;Amit P. Sheth;Shaojun Wang	2009	2009 IEEE/WIC/ACM International Joint Conference on Web Intelligence and Intelligent Agent Technology	10.1109/WI-IAT.2009.20	multimedia;internet privacy;world wide web;social network	HCI	-26.358312776495186	-47.69467034094697	46687
b47406b3d87ab81e7939033a00d1f615e61b6cee	editor's note: special section on data mining for smart cities		Data Mining and Knowledge Discovery is pleased to present this special section on Data Mining for Smart Cities, containing the following four papers: • “Mining urban events from the tweet stream through a probabilistic mixture model” by Joan Capdevila, Jesús Cerquides, and Jordi Torres • “Targeted interest-driven advertising in cities using Twitter” byAris Anagnostopoulos, Fabio Petroni, and Mara Sorella • “Data-driven generation of spatio-temporal routines in human mobility” by Luca Pappalardo and Filippo Simini • “Structural robustness and service reachability in urban settings” by Sofiane Abbar, Tahar Zanouda, and Javier Borge-Holthoefer	data mining and knowledge discovery;mixture model;reachability;smart city	Joan Capdevila;Jesús Cerquides;Filippo Simini	2018	Data Mining and Knowledge Discovery	10.1007/s10618-018-0567-9		ML	-18.32251384210898	-32.5118954726144	46692
b8300c6b4a43f68ac62dba6c30be0e2f31b735c3	managing multi robotic agents to avoid congestion and stampedes	crowd management;congestion;stampede	Crowd management is a complex, challenging and crucial task. Lack of appropriate management of crowd has, in past, led to many unfortunate stampedes with significant loss of life. To increase the crowd management efficiency, we deploy automated real time detection of stampede prone areas. Further, we use robotic agents for aiding the crowd management police in controlling the crowd in these stampede prone areas. Lastly, we simulate a multi agent system based on our model and use it to illustrate the utility and viability of robotic agents for detecting and reducing congestion.	knowledge management;multi-agent system;network congestion;robot;sensor;simulation	Garima Ahuja;Kamalakar Karlapalem	2015			simulation;computer security	AI	-20.306367771800954	-25.98605483305218	46695
3a38c7f40096ac4f3f6c7ebbdf40478b539fc2a1	chasers of the lost data: turning content management systems into gaming platforms	content management;sensors;information retrieval;game engine;iris recognition;contextual information;ubiquitous computing computer games indexing information retrieval meta data recommender systems;recommendation system content management system information retrieval system information indexing system game engine components chasers of the lost data pervasive games elements user context detection metadata;recommender system;engines;indexing;games;indexation;pervasive game;mobile handsets;content management system;ubiquitous computing;meta data;games context iris recognition engines mobile handsets real time systems sensors;point of view;computer games;recommender systems;context;real time systems	This paper briefly presents our Information Retrieval and Indexing System (IRIS), and how it adapts to support game engine components. We describe a conceptual game, Chasers of the Lost Data, to demonstrate how pervasive games elements interact with content and user context detection, enabling a broad range of game applications. The presented game combines physical, sensorial and contextual information with personal content and inject this information into the game world in forms of game chases. This game allows personal content of players to be enhanced by new sets of metadata from different point of views (other players). This result in an improved content management, search and recommendation system while being more resonant fun experiences for the users.	content management system;game engine;information retrieval;pervasive informatics;recommender system	Adrian Hornsby;Timo Aaltonen;Rod Walsh	2010	2010 2nd International IEEE Consumer Electronics Society's Games Innovations Conference	10.1109/ICEGIC.2010.5716883	game design;game development tool;level design;computer science;game mechanics;game art design;game developer;multimedia;internet privacy;algorithmic game theory;game design document;world wide web	DB	-31.513105795249444	-45.73521677634031	46709
3aee7b12234d18a4a0320033ebc44661243e4ec8	a review on application of data mining techniques to combat natural disasters	data mining;big data;natural disaster;twitter;india	Thousands of human lives are lost every year around the globe, apart from significant damage on property, animal life etc.due to natural disasters (e.g., earthquake, flood, tsunami, hurricane and other storms, landslides, cloudburst, heat wave, forest fire). In this paper, we focus on reviewing the application of data mining and analytical techniques designed so far for i) prediction ii) detection and iii) development of appropriate disaster management strategy based on the collected data from disasters. A detailed description of availability of data from geological observatories (seismological, hydrological), satellites, remote sensing and newer sources like social networking sites as twitter is presented. An extensive and in depth literature study on current techniques for disaster prediction, detection and management has been done and the results are summarized according to various types of disasters. Finally a framework for building a disaster management database for India hosted on open source Big Data platform like Hadoop in a phased manner has been proposed.	apache hadoop;big data;data center;data mining;data store;information source;intel dynamic acceleration;internet;open-source software;social media;subject matter expert turing test;unrest	Saptarsi Goswami;Sanjay Chakraborty;Sanhita Ghosh;Amlan Chakrabarti;Basabi Chakraborty	2016	CoRR	10.1016/j.asej.2016.01.012	big data;natural disaster;computer science;computer security	ML	-21.112724348691486	-33.43313622006334	46734
244aee69d1d9007c5d9a12e1f7db50ec86924d75	mining heterogeneous information networks by exploring the power of links	information network;heterogeneous information	Knowledge is power but for interrelated data, knowledge is often hidden in massive links in heterogeneous information networks. We explore the power of links at mining heterogeneous information networks with several interesting tasks, including link-based object distinction, veracity analysis, multidimensional online analytical processing of heterogeneous information networks, and rank-based clustering. Some recent results of our research that explore the crucial information hidden in links will be introduced, including ((1) Distinct for object distinction analysis, (2) TruthFinder for veracity analysis, (3) Infonet-OLAP for online analytical processing of information networks, and (4) RankClus for integrated ranking-based clustering. We also discuss some of our on-going studies in this direction.	cluster analysis;entity–relationship model;online analytical processing;sun one;veracity	Jiawei Han	2009		10.1007/978-3-642-04414-4_3	computer science;data science;machine learning;data mining	ML	-12.935019999700827	-39.38617214643261	46756
20ed5722b7f83c4da77a99d711fc83d0e89e7437	a feasibility study of poi recommendation based on bursts of visits	poi recommendation;bursts of visits;location based social networks	As the number of users of location based social networks (LBSNs) grows, a large volume of valuable data including check-in data have been stored in them and available to us. In this paper, we focus on bursts of visits and show a feasibility study of exploiting them for point-of-interest (POI) recommendation on LBSN. We extract bursts of visits from time series check-in data stored in LBSN and suppose them as a signal that events happened. In other words, the bursts could indicate the locations and durations of some events. We make use of the signals and visited locations of users whose check-in data are similar for simple POI recommendation. Our experimental results indicate that it would be valuable to take bursts of visits into account for POI recommendation.	location-based service;point of interest;social network;time series	Tetsuya Fukuda;Masayoshi Aritsugi	2015		10.1145/2837185.2837270	simulation;geography;advertising;world wide web	ML	-23.969620865020904	-45.35702165026458	46808
8be0d515de278e6303fc742a51820974d4f29aa2	a visualisation technique for large temporal social network datasets in hyperbolic space	temporal data;hyperbolic layout;visualisation;social networks	Visualisations of temporal social network datasets have the potential to be complex and require a lot of cognitive input. In this paper, we present a novel visualisation approach that depicts both relational and statistical information of evolving social structures. The underlying framework is implemented by the usage of Hyperbolic Geometry to support focus context rendering. The proposed method guarantees representing prominent social actors through scaling their representations, preserves user's mental map, and provides the user to reduce visual clutter by means of filtering.	social network	Uraz Cengiz Türker;Selim Balcisoy	2014	J. Vis. Lang. Comput.	10.1016/j.jvlc.2013.10.008	computer science;theoretical computer science;machine learning;data mining;temporal database;social network	DB	-28.172262926006646	-35.31907982024523	46822
46e80f38657c4151e0f5cec2227f853bc15a58e9	visualizing the spatial and temporal distribution of user interaction data collected in three-dimensional virtual worlds	libraries;social navigation;web links;spatiotemporal maps;usability information visualization online browser 3d virtual worlds web links user interaction spatiotemporal maps social navigation;data collection;web accessibility;collaboration;virtual community;auditory system;online browser;virtual reality;information visualization;data mining;design optimization;three dimensional;design evaluation;data visualisation;data analysis;navigation;graphical user interfaces;virtual reality graphical user interfaces interactive systems data visualisation;3d virtual worlds;spatio temporal maps;data visualization;software tools;work in progress;usability;user interaction;interactive systems;virtual worlds;data visualization navigation libraries design optimization usability data mining collaboration auditory system software tools data analysis	This paper reports work in progress on the analysis and visualization of the spatial and temporal distribution of user interaction data collected in threedimensional (3-D) virtual worlds. Two tools are introduced. The “WorldMapper” reads in a so-called propdump file and creates a 2-D clickable map showing the layout of the world as well as interaction possibilities such as teleports and clickable web links. The second tool visualizes user interaction data such as navigation, chatting, and Web access activity overlaid on the world map. Resulting visualizations are meant to support social navigation, design evaluation and optimization, and the study of virtual communities. Both tools are demonstrated on a 19-person information treasure hunt for information in a 3-D virtual world. The paper concludes with a discussion and an outlook.	clickable;image map;internet access;mathematical optimization;microsoft outlook for mac;online chat;virtual community;virtual world	Katy Börner;William R. Hazlewood;Sy-Miaw Lin	2002		10.1109/IV.2002.1028752	human–computer interaction;computer science;multimedia;world wide web	HCI	-33.442279559810316	-31.0111935286282	46958
167cdaf1f51f0dde04c317d30af325318f56898a	indexing metric spaces with m-tree	triangle inequality;metric space;distance function;access method;satisfiability;indexation;vector space	M-tree is a dynamic access method suitable to index generic “metric spaces”, where the function used to compute the distance between any two objects satisfies the positivity, symmetry, and triangle inequality postulates. The M-tree design fulfills typical requirements of multimedia applications, where objects are indexed using complex features, and similarity queries can require application of time-consuming distance functions. In this paper we describe the basic search and management algorithms of M-tree, introduce several heuristic split policies, and experimentally evaluate them, considering both I/O and CPU costs. Results also show that M-tree performs better than R∗-tree on highdimensional vector spaces.	algorithm;central processing unit;experiment;heuristic;input/output;m-tree;requirement;social inequality	Paolo Ciaccia;Marco Patella;Fausto Rabitti;Pavel Zezula	1997			convex metric space;injective metric space;fisher information metric;metric map;discrete mathematics;metric differential;metric tree;tight span;topology;equivalence of metrics;mathematics	DB	-5.846242564542789	-42.677931738577065	46966
2a34011ce3afd7b145351f7652aabe3c0d8f2ad7	dna-chart visual tool for topological higher order information from spatio-temporal trajectory dataset		With increasing amount of trajectory dataset being generated and collected, trajectory data has become a ubiquitous type of data important in many different application domains. Research challenges faced are to analyse and retrieve useful higher order information from trajectory datasets to deal with dynamic and “what-if” complex decision making problems. In this paper, we propose a new visualisation approach and quantitative metrics to model and analyse topological higher order information from trajectory datasets. The proposed higher order DNA chart can help decision makers to compare different topological higher order information from different trajectories. We also define higher order trajectory area that models a geometrical area representing the same higher order information. We introduce a higher order DNA impact factor that defines top-k higher order information, and the relationship between trajectory datasets and points-of-interest. A case study using trajectory data extracted from Flickr illustrates the applicability and usefulness of these proposed visual tools and metrics.		Ye Wang;Kyungmi Lee;Ickjai Lee	2018	Expert Syst. Appl.	10.1016/j.eswa.2018.04.036	data mining;machine learning;visualization;artificial intelligence;chart;computer science;trajectory;topology	Vision	-23.266781667384635	-34.856530204139595	46996
0215db1988556717e2ba796f26ab78b9fbf1958d	bayeswipe: a multimodal system for data cleaning and consistent query answering on structured bigdata	databases;web databases;uncertainty;query processing big data learning artificial intelligence;cleaning data models mathematical model big data query processing bayes methods;uncertainty databases web databases data cleaning query rewriting;data cleaning;database bayeswipe system data cleaning query answering structured big data data deduplication record matching data standardization attribute values correction bayesian generative model statistical error model learning;query rewriting	Recent efforts in data cleaning of structured data have focused exclusively on problems like data deduplication, record matching, and data standardization; none of these focus on fixing incorrect attribute values in tuples. Correcting values in tuples is typically performed by a minimum cost repair of tuples that violate static constraints like CFDs (which have to be provided by domain experts, or learned from a clean sample of the database). In this paper, we provide a method for correcting individual attribute values in a structured database using a Bayesian generative model and a statistical error model learned from the noisy database directly. We thus avoid the necessity for a domain expert or clean master data. We also show how to efficiently perform consistent query answering using this model over a dirty database, in case write permissions to the database are unavailable. We evaluate our methods over both synthetic and real data.	algorithm;baseline (configuration management);bayesian network;clean;data deduplication;database;distributed computing;end-to-end encryption;experiment;generative model;image rectification;mapreduce;multimodal interaction;online and offline;open-source software;plasma cleaning;probabilistic semantics;quality of results;rewriting;signal-to-noise ratio;subject-matter expert;synthetic intelligence	Sushovan De;Yuheng Hu;Yi Chen;Subbarao Kambhampati	2014	2014 IEEE International Conference on Big Data (Big Data)	10.1109/BigData.2014.7004207	data modeling;query optimization;boolean conjunctive query;computer science;database model;data mining;database;web search query;view;information retrieval;database design	DB	-8.24336854790016	-32.299963941774145	47025
0a7426282909d023eee1f0d7c15c2bac7b465ec1	decision tree-based contextual location prediction from mobile device logs		Contextual location prediction is an important topic in the field of personalized location recommendation in LBS (location-based services). With the advancement of mobile positioning techniques and various sensors embedded in smartphones, it is convenient to obtain massive human mobile trajectories and to derive a large amount of valuable information from geospatial big data. Extracting and recognizing personally interesting places and predicting next semantic location become a research hot spot in LBS. In this paper, we proposed an approach to predict next personally semantic place with historical visiting patterns derived from mobile device logs. To address the problems of location imprecision and lack of semantic information, a modified trip-identify method is employed to extract key visit points from GPS trajectories to a more accurate extent while semantic information are added through stay point detection and semantic places recognition. At last, a decision tree model is adopted to explore the spatial, temporal, and sequential features in contextual location prediction. To validate the effectiveness of our approach, experiments were conducted based on a trajectory collection in Guangzhou downtown area. ,e results verified the feasibility of our approach on contextual location prediction from continuous mobile devices logs.		Linyuan Xia;Qiumei Huang;Dongjin Wu	2018	Mobile Information Systems	10.1155/2018/1852861	geospatial analysis;data mining;big data;decision tree model;decision tree;global positioning system;distributed computing;computer science;mobile device	HCI	-16.705139465888994	-35.19052518990701	47036
147cbbfbbde78ec36020b40e25517ba306086ee2	a video game description language for model-based or interactive learning	software libraries;program control structures;planning artificial intelligence;software libraries computer games learning artificial intelligence multi agent systems ontologies artificial intelligence planning artificial intelligence program control structures search problems;ontologies artificial intelligence;multi agent systems;search problems;learning artificial intelligence;computer games;video game description language evolutionary search reinforcement learning algorithm game dynamics library usefulness visual observations abstract observations learning agents planning algorithms benchmark problems control structures ontology streamlined language design software library 2d video games high level description language pyvgdl computational games computational intelligence interactive learning;games ontologies avatars libraries syntactics benchmark testing visualization	We propose a powerful new tool for conducting research on computational intelligence and games. `PyVGDL' is a simple, high-level description language for 2D video games, and the accompanying software library permits parsing and instantly playing those games. The streamlined design of the language is based on defining locations and dynamics for simple building blocks, and the interaction effects when such objects collide, all of which are provided in a rich ontology. It can be used to quickly design games, without needing to deal with control structures, and the concise language is also accessible to generative approaches. We show how the dynamics of many classical games can be generated from a few lines of PyVGDL. The main objective of these generated games is to serve as diverse benchmark problems for learning and planning algorithms; so we provide a collection of interfaces for different types of learning agents, with visual or abstract observations, from a global or first-person viewpoint. To demonstrate the library's usefulness in a broad range of learning scenarios, we show how to learn competent behaviors when a model of the game dynamics is available or when it is not, when full state information is given to the agent or just subjective observations, when learning is interactive or in batch-mode, and for a number of different learning algorithms, including reinforcement learning and evolutionary search.	algorithm;bsd;batch processing;benchmark (computing);computational intelligence;control flow;game description language;high- and low-level;high-level programming language;library (computing);machine learning;open-source software;parsing;reinforcement learning;rich internet application	Tom Schaul	2013	2013 IEEE Conference on Computational Inteligence in Games (CIG)	10.1109/CIG.2013.6633610	error-driven learning;simulation;computer science;artificial intelligence;game mechanics;machine learning;multi-agent system;hyper-heuristic	AI	-26.935389573218757	-25.060168104060008	47065
1f4b602122421f3d2f65b35c7f2e110ea2491842	a hierarchical demand prediction method with station clustering for bike sharing system		Bike sharing system is widely used in many cities. However, the imbalanced usage pattern of bicycles causes over-demand issue which affects user experience. Bike demand prediction is necessary as it is the basis of bike pre-allocation which can satisfy people's demand in advance. In this paper, we propose a hierarchical traffic prediction model to predict bike check-out/in number of each station cluster. Firstly, we conduct station clustering with iterative spectral clustering algorithm, since the pattern of bike usage of several stations close to each other is more regular compared with that of a single station. Then, we adopt gradient boosting regression tree to predict the total check-out number of the whole bike sharing system. Thirdly, each cluster's check-out number is inferred based on its predicted proportion in the total check-out number. Fourthly, we propose inter-cluster transition proportion model which can describe the bike rent-return relationships between cluster pairs and predict check-in numbers of clusters. Finally, we evaluate our prediction model with data from Citi Bike System in New York City. Experiment results show that our prediction method can achieve more accurate and reasonable result compared with existing work.	algorithm;cluster analysis;decision tree learning;gradient boosting;iterative method;spectral clustering;user experience	Sijia Feng;Hao Chen;Chun Du;Jun Li;Ning Jing	2018	2018 IEEE Third International Conference on Data Science in Cyberspace (DSC)	10.1109/DSC.2018.00133	spectral clustering;gradient boosting;machine learning;data modeling;user experience design;decision tree;cluster analysis;artificial intelligence;computer science	ML	-16.628449770990002	-32.83322689721237	47073
c6c974828abeb87efc1dfe013ffefdefa8b0cefe	case-studies in mining user-generated reviews for recommendation		User-generated reviews are now plentiful online and they have proven to be a valuable source of real user opinions and real user experiences. In this chapter we consider recent work that seeks to extract topics, opinions, and sentiment from review text that is unstructured and often noisy.We describe and evaluate a number of practical case-studies for how such information can be used in an informationfiltering and recommendation context, from filtering helpful reviews to recommending useful products.	user-generated content	Ruihai Dong;Michael P. O'Mahony;Kevin McCarthy;Barry Smyth	2015		10.1007/978-3-319-18458-6_6	sentiment analysis;data mining;computer science	Web+IR	-23.657992339479613	-51.17284298342453	47116
131b250db751a6b6b8304d0573057b9c9631d33e	issues in modeling a national network of airports	aerospace computing;aerospace simulation;air traffic computer control;air traffic control;computational performance;data requirements;geographically dispersed airports;model robustness;modeling;national network of airports;portability;problem size;propagation of delays;sensitivity;statistical sampling;transparency	The subject of this paper is models of networks consisting of a large number of geographically-dispersed airports. The need for models of this type has become urgently clear recently as a result of growing systemwide congestion of air traffic, the propagation of delays from one airport to others and the desire, at the national policy level, to allocate intelligently scarce federal resources among competing alternatives and local airport projects. While research and development activities in this area will undoubtedly intensify in coming years, it is important to recognize some fundamental difficulties associated with network models of this type. Important issues include: problem size and data requirements; the probabilistic and dynamic nature of the airport system's demand and capacity; the combinatorially explosive number of possible network states and the resulting need for careful statistical sampling and analysis; the sensitivity of computational performance to the level of detail in the network model; the difficulty of preparing demand scenarios that predict future connections between pairs of airports; and user requirements for model robustness, portability and transparency. These issues are discussed and illustrated in some detail, including references to specific existing network models of the ATC system.	advanced transportation controller;analysis of algorithms;computation;level of detail;network congestion;network model;requirement;sampling (signal processing);software portability;software propagation;user requirements document	Amedeo R. Odoni	1991			simulation;computer science;engineering;technical report;stochastic modelling;user requirements document;network model;air traffic control;level of detail;transport engineering;world wide web	Metrics	-17.734140793913113	-24.60991453015802	47146
5a25909f76e9092b1cea29ea5b19ad84cc60376d	using online media sharing behavior as implicit feedback for collaborative filtering	browsing patterns;user preference;implicit feedback;conference;training;information filtering;collaboration;prediction algorithms;implicit feedback recommender systems collaborative filtering social media;social networking online information filtering;user preferences;model user preference;media;accuracy;youtube;recommender system;collaborative filtering;item based algorithm implicit feedback collaborative filtering recommender systems music book movie user behavior purchase history browsing patterns watching habits model user preference user online media sharing activities user preference youtube social video sharing sites;social networking online;social video sharing sites;user behavior;book;user online media sharing activities;social media;purchase history;music;recommender systems;movie;watching habits;media youtube training prediction algorithms accuracy collaboration recommender systems;item based algorithm	In many practical recommender systems, it is found difficult to obtain explicit feedback from users about the preference for a specific item, such as music, book, movie, etc. Most researches up to this point has focused on tracking various sources of implicit feedback from user behavior including purchase history, browsing patterns, and watching habits, in order to model user preference. In this paper, we investigate a method that uses information exploited from a user's online media sharing activities as a novel source of implicit feedback for recommendation system. We look into elements of media sharing behavior and suggest whether behaviors have the potentiality that could play a role as a predictor of users’ preference. Then in a specific domain, we choose appropriate behaviors by two criteria: abundance and observability. As a representative case, we focus on YouTube, one of the most popular social video sharing sites. By criteria we suggest, we select three behaviors including favorite, upload and view and formulate the simple item-based algorithm based on those behaviors. Through a series of experiments, we evaluate recommendation results obtained from our dataset by comparison with those from other reference algorithms. The results show that favorite and upload have possibility to be used as implicit feedback.	algorithm;categorization;collaborative filtering;computation;digital media;experiment;feedback;kerrison predictor;recommender system;upload	Geonhyeok Go;Joonhyuk Yang;Hyunwoo Park;Steve SangKi Han	2010	2010 IEEE Second International Conference on Social Computing	10.1109/SocialCom.2010.70	media;social media;computer science;collaborative filtering;music;multimedia;internet privacy;world wide web;statistics;recommender system;collaboration	HCI	-25.61985150194839	-47.82074932508361	47211
224e813c8d22e1fe6fc86a7a2666ded26061cb8a	assessing the quality of multilevel graph clustering	hierarchical clustering;graph clustering;graph hierarchies;multilevel modularity	“Lifting up” a non-hierarchical approach to handle hierarchical clustering by iteratively applying the approach to hierarchically cluster a graph is a popular strategy. However, these lifted iterative strategies cannot reasonably guide the overall nesting process precisely because they fail to evaluate the very hierarchical character of the clustering they produce. In this study, we develop a criterion that can evaluate the quality of the subgraph hierarchy. The multilevel criterion we present and discuss in this paper generalizes a measure designed for a one-level (flat) graph clustering to take nesting of the clusters into account. We borrow ideas from standard techniques in algebraic combinatorics and exploit a variable $$q$$ q to keep track of the depth of clusters at which edges occur. Our multilevel measure relies on a recursive definition involving variable $$q$$ q outputting a one-variable polynomial. This paper examines archetypal examples as proofs-of-concept; these simple cases are useful in understanding how the multilevel measure actually works. We also apply this multilevel modularity to real world networks to demonstrate how it can be used to compare hierarchical clusterings of graphs.	algorithm;cluster analysis;coefficient;exploit (computer security);ground truth;heuristic (computer science);hierarchical clustering;hoc (programming language);iterative compression;iterative method;lifting scheme;linear algebra;mathematical optimization;modularity (networks);polynomial;recursion;recursive definition	François Queyroi;Maylis Delest;Jean-Marc Fedou;Guy Melançon	2013	Data Mining and Knowledge Discovery	10.1007/s10618-013-0335-9	correlation clustering;combinatorics;discrete mathematics;fuzzy clustering;computer science;machine learning;data mining;clustering coefficient;mathematics;hierarchical clustering;statistics;hierarchical clustering of networks	AI	-9.242062953135637	-43.535862741132775	47488
3e385c7e62c8b1bbe1c311adb2ac8e6f7d74420d	indexing high-dimensional spaces: database support for next decade's applications	high-dimensional data;next decade;conventional database application;higher-dimensional data;database perspective;high-dimensional space;data warehousing;database support;indexing high-dimensional spaces;indexing technique;different approach;new database application	During recent years, a variety of new database applications has been developed which substantially differ from conventional database applications. For example, new database applications such as data warehousing produce very large relations which require a multidimensional view on the data, and in areas such as multimedia and CAD a content-based search is essential which is often implemented using some kind of feature vectors. All the new applications have in common that the underlying database system has to support the processing of queries on large amounts of high-dimensional data. Now, we may ask what the difference is between processing lowand high-dimensional data. A result of recent research activities is that basically none of the querying and indexing techniques, which provide good results on lowdimensional data, also performs sufficiently well on higher-dimensional data. The problem of dealing with high-dimensional spaces has therefore been addressed in a variety of recent database research projects. The goal of the tutorial is to spread the knowledge about high-dimensional spaces and the proposed techniques to a large community of both, researchers and practitioners  researchers who are interested in querying and indexing techniques for high-dimensional data, and practitioners who are interested in the state-of-the art of database support for their applications. Also, the tutorial will be very interesting for non-database computer scientists because the problem of dealing with high-dimensional spaces has a large number of other applications such as robot motion planning, optimization problems, and visualization techniques. Therefore, a large part of the tutorial is dedicated to convey the understanding of the effects occurring in these spaces.	computer scientist;computer-aided design;database;feature vector;mathematical optimization;motion planning;optimization problem;spaces	Stefan Berchtold;Daniel A. Keim	2000		10.1109/ICDE.2000.839502	computer science;data science;theoretical computer science;data mining;database	DB	-26.32864762013368	-30.943275795136294	47575
4c73158f90e61de04ee64867ebc976e5e9adc04b	ibump: smartphone application to detect car accidents	hidden markov models hmms;pattern recognition;accident detection;smartphone application;dynamic time warping dtw	Traffic accidents are a fact of life. While accidents are sometimes unavoidable, studies show that the long response time required for emergency responders to arrive is a primary reason behind increased fatalities in serious accidents. One way to reduce this response time is to reduce the amount of time it takes to report an accident. Smartphones are ubiquitous and with network connectivity are perfect devices to immediately inform relevant authorities about the occurrence of an accident. This paper presents the development of a system that uses smartphones to automatically detect and report car accidents in a timely manner. Data is continuously collected from the smartphone's accelerometer and analyzed using Dynamic Time Warping (DTW) to determine the severity of the accident, reduce false positives and to notify first responders of the accident location and owner's medical information. In addition, accidents can be viewed on the smartphone over the Internet offering instant and reliable access to the information concerning the accident. By implementing this application and adding a notification system, the response time required to notify emergency responders of traffic accidents can reduce the response time and perhaps help in reducing fatalities.	dynamic time warping;internet;notification system;response time (technology);smartphone	Fadi A. Aloul;Imran A. Zualkernan;Ruba Abu-Salma;Humaid Al-Ali;May Al-Merri	2014	2014 International Conference on Industrial Automation, Information and Communications Technology	10.1016/j.compeleceng.2015.03.003	embedded system;simulation;computer science;engineering;computer security	Mobile	-20.078933063820145	-30.07956326409294	47592
1981d037b22c9350e7d178e96fbe7db2f0e28adf	recommendation, trust and reputation management in a group online mentorship system		Existing online mentorship systems typically match mentors and mentees manually. Recommender systems can be used to match mentors and mentees and trust and reputation mechanisms can be used to improve the decision process. This paper discusses the state-of-the-art in online mentorship systems, recommender systems, and trust and reputation mechanisms. It further proposes a five-stage process for automatic matching groups of mentors and mentees in online mentorship systems.	recommender system;reputation management	Oluwabunmi Adewoyin;Julita Vassileva	2012			recommender system;knowledge management;business;mentorship;reputation	AI	-23.780877718043804	-42.49441443296241	47619
12dfaaeffe094633e4bc132c367147a3853d0cab	smell, think and act: a cognitive robot discriminating odours	tecnologia industrial tecnologia mecanica;mobile olfaction;anchoring;cognitive robotics;planning for perceptual actions;computer and information science;grupo de excelencia;online learning;discriminant function;odour discrimination;data och systemvetenskap;computer and systems science;electronic noses;tecnologias;electronic nose;data och informationsvetenskap	In this paper, we explore the integration of an electronic nose and its odour discrimination functionalities into a multi-sensing robotic system which works over an extended period of time. The robot patrols an office environment, collecting odour samples of objects and performing user requested tasks. By considering an experimental platforms which operates over an extended period of time, a number of issues related to odour discrimination arise such as the drift in the sensor data, online learning of new odours, and the correct association of odour properties related to objects. In addition to an electronic nose our robotic system consists of other sensing modalities (vision and sonar), behaviour-based control and a high level symbolic planner.	cognitive robotics;high-level programming language;robot;sonar (symantec)	Amy Loutfi;Silvia Coradeschi	2006	Auton. Robots	10.1007/s10514-006-7098-8	electronic nose;simulation;computer science;artificial intelligence;discriminant function analysis;anchoring;cognitive robotics	Robotics	-32.64787360962236	-40.7543860807872	47641
db3ab150909af9dab116701aa9f3e735bb1b76c3	on the evaluation of ship maneuvering for collision avoidance by using ozt	training;ships collision avoidance;navigation;ships;ship maneuvering;marine vehicles;ozt;collision avoidance;seamanship ship maneuvering collision avoidance obstacle zone by target;training ship maneuvering collision avoidance ozt;marine vehicles training navigation data models educational institutions;data models	Training facilities have recently introduced practical training that involves maneuvering simulators. The simulator helps the trainees realize so-called “Seamanship” which cannot be obtained only by the classroom lectures. However, it is very difficult to judge the trainees' skills through their maneuvering on the simulator. Therefore, in this study it is considered to use OZT when evaluating the results of simulation by using OZT. OZT is an abbreviation for “obstacle zone by target”, which was proposed by one of the authors. This paper shows the details of this consideration.	simulation	Jun Kayano;Ryo Matsui;Hayama Imazu;Akiya Shibata	2011	2011 IEEE International Conference on Systems, Man, and Cybernetics	10.1109/ICSMC.2011.6083665	data modeling;navigation;troy ounce;simulation;computer science	Robotics	-31.55754001789739	-37.6428697958422	47669
8dbd89150a1a585066ec439ca90a5ee5177bfd1e	bayesian time-series models: expert knowledge-driven inference and learning for engineering applications ; bayesiaanse tijdreeksmodellen: inferentie en leren gedreven door expertkennis voor ingenieurstoepassingen				Enrico Di Lello	2015				AI	-11.643117830897703	-29.314472525301586	47671
18fff5656201c4d1f70695d688ce9718dfa6985b	collaborative and structural recommendation of friends using weblog-based social network analysis	mining;graph	In this paper, we address the problem of link recommendation in weblogs and similar social networks. First, we present an approach based on collaborative recommendation using the link structure of a social network and content-based recommendation using mutual declared interests. Next, we describe the application of this approach to a small representative subset of a large real-world social network: the user/community network of the blog service LiveJournal. We then discuss the ground features available in LiveJournal’s public user information pages and describe some graph algorithms for analysis of the social network. These are used to identify candidates, provide ground truth for recommendations, and construct features for learning the concept of a recommended link. Finally, we compare the performance of this machine learning approach to that of the rudimentary recommender system provided by LiveJournal.	algorithm;blog;graph theory;ground truth;machine learning;recommender system;social network analysis	William H. Hsu;Andrew L. King;Martin S. R. Paradesi;Tejaswi Pydimarri;Tim Weninger	2006			artificial intelligence;computer science;machine learning;recommender system;social network analysis;ground truth;community network;user information;social network;graph	AI	-15.98368276270801	-44.9433192333999	47731
f83595ad7aaa6bfd2dc4192c9e0f4a01169b2485	anonymizing graphs against weight-based attacks with community preservation	anonymity;privacy preserving graph mining;weighted graph;weight anonymization	The increasing popularity of graph data, such as social and online communities, has initiated a prolific research area in knowledge discovery and data mining. As more real-world graphs are released publicly, there is growing concern about privacy breaching for the entities involved. An adversary may reveal identities of individuals in a published graph, with the topological structure and/or basic graph properties as background knowledge. Many previous studies addressing such attacks as identity disclosure, however, concentrate on preserving privacy in simple graph data only. In this paper, we consider the identity disclosure problem in weighted graphs. The motivation is that, a weighted graph can introduce much more unique information than its simple version, which makes the disclosure easier. We first formalize a general anonymization model to deal with weight-based attacks. Then two concrete attacks are discussed based on weight properties of a graph, including the sum and the set of adjacent weights for each vertex. We also propose a complete solution for the weight anonymization problem to prevent a graph from both attacks. In addition, we also investigate the impact of the proposed methods on community detection, a very popular application in the graph mining field. Our approaches are efficient and practical, and have been validated by extensive experiments on both synthetic and real-world datasets. Category: Smart and intelligent computing	adversary (cryptography);approximation algorithm;average path length;clustering coefficient;complexity;data anonymization;data mining;entity;experiment;graph (discrete mathematics);graph property;identity provider;increment and decrement operators;information;np-hardness;online community;spectral graph theory;structure mining;synthetic intelligence	Yidong Li;Hong Shen	2011	JCSE	10.5626/JCSE.2011.5.3.197	theoretical computer science;data mining;mathematics;internet privacy	ML	-12.589771031800762	-43.529409654239416	47740
e686d456afce311f37a84fce4b5c55d15218dc56	climate changes prediction system based on weather big data visualisation		The paper introduces a new approach to weather forecasting. Overall prediction process consisted of processing big data, turning processed data to visualization, and later this visualization has been used for enhancing forecasting methods using artificial neural networks. The following assumptions are proved: data visualization gives additional interpretation possibilities, it is possible to enhance weather forecasting by data visualization, neural networks can be used for visual weather data analysis, neural networks can be used for climate changes prediction.	big data;data visualization	Antoni Buszta;Jacek Mazurkiewicz	2015		10.1007/978-3-319-19216-1_8	meteorology;atmospheric sciences;climatology	ML	-24.36398672520782	-30.726707491193558	47820
ef8db0f78e035569e4085011fffcb8492f376a43	polygon mesh repairing: an application perspective	topology;systems;boundary representation;geometry;geometric algorithms;fixing;languages	Nowadays, digital 3D models are in widespread and ubiquitous use, and each specific application dealing with 3D geometry has its own quality requirements that restrict the class of acceptable and supported models. This article analyzes typical defects that make a 3D model unsuitable for key application contexts, and surveys existing algorithms that process, repair, and improve its structure, geometry, and topology to make it appropriate to case-by-case requirements.  The analysis is focused on polygon meshes, which constitute by far the most common 3D object representation. In particular, this article provides a structured overview of mesh repairing techniques from the point of view of the application context. Different types of mesh defects are classified according to the upstream application that produced the mesh, whereas mesh quality requirements are grouped by representative sets of downstream applications where the mesh is to be used. The numerous mesh repair methods that have been proposed during the last two decades are analyzed and classified in terms of their capabilities, properties, and guarantees. Based on these classifications, guidelines can be derived to support the identification of repairing algorithms best-suited to bridge the compatibility gap between the quality provided by the upstream process and the quality required by the downstream applications in a given geometry processing scenario.	3d modeling;algorithm;context (computing);digital 3d;downstream (software development);geometry processing;point of view (computer hardware company);polygon mesh;requirement;types of mesh	Marco Attene;Marcel Campen;Leif Kobbelt	2013	ACM Comput. Surv.	10.1145/2431211.2431214	simulation;computer science;theoretical computer science;database;system;t-vertices;boundary representation	Graphics	-23.568147219997766	-37.5547811171125	47824
0727ab6afcf51095bf861e805c4dd6663d7b8f21	modeling and querying uncertain spatial information for situational awareness applications	uncertain;video streaming;probability;retrieval;situation awareness;experimental evaluation;spatial information	Situational awareness (SA) applications monitor the real world and the entities therein to support tasks such as rapid decision-making, reasoning, and analysis. Raw input about unfolding events may arrive from variety of sources in the form of sensor data, video streams, human observations, and so on, from which events of interest are extracted. Location is one of the most important attributes of events, useful for a variety of SA tasks. In this paper, we propose an approach to model and represent (potentially uncertain) event locations described by human reporters in the form of free text. We analyze several types of spatial queries of interest in SA applications. Our experimental evaluation demonstrates the effectiveness of our approach.	entity;streaming media;unfolding (dsp implementation)	Dmitri V. Kalashnikov;Yiming Ma;Sharad Mehrotra;Ramaswamy Hariharan;Carter T. Butts	2006		10.1145/1183471.1183494	situation awareness;computer vision;computer science;data science;probability;data mining;database;mathematics;spatial analysis;statistics	AI	-23.87559804906654	-34.954676751347975	47836
0235c8697bf5ab8aef776d822746ce26fac0f7ba	lodex: a tool for visual querying linked open data		Formulating a query on a Linked Open Data (LOD) source is not an easy task; a technical knowledge of the query language, and, the awareness of the structure of the dataset are essential to create a query. We present a revised version of LODeX that provides the user an easy way for building queries in a fast and interactive manner. When a user decides to explore a LOD source, he/she can take advantage of the Schema Summary produced by LODeX (i.e. a synthetic view of the dataset’s structure) and he/she can pick graphical elements from it to create a visual query. The tool also supports the user in browsing the results and, eventually, in refining the query. The prototype has been evaluated on hundreds of public SPARQL endpoints (listed in Data Hub) and it is available online at http://dbgroup.unimo.it/lodex2. A survey conducted on 27 users has demonstrated that our tool can effectively support both unskilled and skilled users in exploring and querying LOD datasets.	data hub;graphical user interface;linked data;prototype;query language;sparql;synthetic intelligence	Fabio Benedetti;Sonia Bergamaschi;Laura Po	2015			data mining;linked data;database;data hub;query language;schema (psychology);computer science;sparql	HCI	-31.51408439414283	-31.269754784852868	47858
3325a7cfc5084b58b39090cc0a7bd15da59de0fe	micro textures with macro-notes		Viuhka is a compositional tool situated in PWGL. The system has been recently adapted in order to enhance our notation package. This paper contains a new notational short-hand, called macro-note, that can be used to realize short musical segments that have their lifespan within a macro-note. The system allows to generate various ornaments in the traditional sense, such as tremolos, trills, and arpeggios. More complex textures are possible using overlapping and recursive macro-note definitions.	recursion;situated	Mikael Laurson;Mika Kuuskankare	2005			engineering drawing;macro;computer science	Robotics	-27.487600946622987	-27.520502365201374	47872
f773ae775d02c8c217cf6149a90da927f64377df	centrality indices computation in dynamic networks	centrality indices dynamic networks;dynamic betweenness measures centrality indices computation dynamic indices dynamic networks dynamic closeness dynamic graph dynamic stress;centrality indices;network theory graphs;dynamic networks;equations heuristic algorithms mathematical model complexity theory stress algorithm design and analysis roads	The article introduces the notion of dynamic indices as centrality measures to analyse how the importance of nodes changes in future time in dynamic networks. In particular, the dynamic closeness, dynamic graph, dynamic stress and dynamic between ness measures are investigated. We develop some algorithms for computing these indices in the dynamic case when the costs are supposed to be integers. Finally, we present some experimental results exploring the algorithms' efficiency and illustrating the variation of the dynamic between ness index for some sample dynamic networks.	algorithm;centrality;computation;earthbound	Tatiana Tabirca;Sabin Tabirca;Laurence Tianruo Yang	2012	2012 IEEE 12th International Conference on Computer and Information Technology	10.1109/CIT.2012.60	network science;random walk closeness centrality;theoretical computer science;alpha centrality;machine learning;centrality	DB	-14.87924497991142	-41.285558386578856	47882
f8fc4491a6052dd3bee6728ee9de2dff78a55218	a new multi-platform modular software tool for wide-angle reflection/refraction seismic data processing and representation (waspar)	computadora;tratamiento datos;computers;software;traitement signal;software tool;seismic reflection;interfaces;platforms;logiciel;ordinateur;seismic refraction;articulo;data processing;traitement donnee;object oriented programming;data format;computer programs;algorithme;interfase;sismique refraction;object oriented;signal processing;interface;data access;oriente objet;algorithms;sismique reflexion;wide angle seismics;c programming language;metodo reflexion sismica;programa computador;plateforme;metodo refraccion sismica;programme ordinateur;plug in;algoritmo	WASPAR (Wide-Angle reflection–refraction Seismic data Processing And Representation) is a new free multi-platform software tool to process and display wide-angle seismic data. It has been designed to read different raw data formats, construct record sections, process them using existing and newly developed algorithms, pick seismic phases and generate graphic files using a single, user-friendly interface. The main characteristics of WASPAR are its flexibility and expandability. It has been designed in a modular way using a plug-in architecture to manage raw data access and processing functionalities. We thus obtain a stable base easily maintainable and expandable. We have chosen the Cþþ programming language in combination with an object oriented methodology to facilitate the development of a multiplatform software tool, which is already available on Linux and MS Windows. In order to allow its expansion and upgrade, the program will be freely distributed under the terms of GPL license. The philosophy of this software tool is to leave it open to external contributions. r 2007 Elsevier Ltd. All rights reserved.	algorithm;data access;linux;microsoft windows;modular programming;plug-in (computing);programming language;programming tool;usability	Iban Rodríguez Barbarin;Carine Simon;Valentí Sallarés;Alfonso Carlosena;Antoni Manuel Lázaro;Juan José Dañobeitia	2008	Computers & Geosciences	10.1016/j.cageo.2007.04.011	embedded system;data processing;computer science;operating system;signal processing;interface;database;programming language;object-oriented programming	SE	-27.795449463272465	-29.12438048497376	47994
87168f13acf2a7ac5c68d631ca255bcf46af403b	from local trend extraction to symbolization of time-series	time series	A methodology is proposed for the extraction of local trends from a time-series. It has been designed to suit the needs of interpretation-oriented visualization from raw data. After giving implementation details for efficient computation of local trends, a characteristic analysis span is determined for each time-series. The processing results in a rich visual interpretation and a framework for the local symbolization of a time-series in terms of its value and dynamics.	time series	Daniel Calvelo;Marie-Christine Chambrin;Denis Pomorski	2001	Intell. Data Anal.		computer science;time series;statistics	AI	-25.78709017494914	-33.05522175948685	48102
cc1e9961752ea371e0f03017b70d6096d0deeec5	when are tweets better valued? an empirical study		The increase in Twitter’s popularity has been phenomenal over time. Tweets are now not only a means of status update and one-on-one communication, but they are also widely used for trend setting and marketing. The probability that the user will see a Tweet when he was offline at the time it was tweeted is very low. In order to increase the Tweet impact, it is important to determine the number of individuals online so that maximum number of users see the Tweets. This research focuses on identifying the individual users from Saudi Arabia based on the parameters already set for the conduct of this study. The time-stamped data for 1000 selected individuals is retrieved from Twitter and is analyzed accordingly. The number of online users is observed by recording the ‘last seen’ status. The retrieval of data is based on a number of experiments that was run at same time on all days of the week to reduce the inconsistent patterns. The data is then analyzed to see the time slots where the online user percentage is higher as compared to other time slots. The results of the study are focused to identify and recommend the timings when the Tweets are better valued and the impact is considerable.	experiment;information and computer science;information science;online and offline	Esam Alwagait;Basit Shahzad	2014	J. UCS	10.3217/jucs-020-10-1511	computer science;data mining;world wide web	Web+IR	-24.786572979564124	-46.60291383824741	48224
13ed8b54509afda277738a7c0a387853dab7e70f	bittablefi: an efficient mining frequent itemsets algorithm	time series;data mining;frequent itemset;database compressing;bittable;frequent itemsets;data structure	Mining frequent itemsets in transaction databases, time-series databases and many other kinds of databases is an important task and has been studied popularly in data mining research. The problem of mining frequent itemsets can be solved by constructing a candidate set of itemsets first, and then, identifying those itemsets that meet the frequent itemset requirement within this candidate set. Most of the previous research mainly focuses on pruning to reduce the candidate itemsets amounts and the times of scanning databases. However, many algorithms adopt an Apriori-like candidate itemsets generation and support count approach that is the most time-wasted process. To address this issue, the paper proposes an effective algorithm named as BitTableFI. In the algorithm, a special data structure BitTable is used horizontally and vertically to compress database for quick candidate itemsets generation and support count, respectively. The algorithm can also be used in many Apriori-like algorithms to improve the performance. Experiments with both synthetic and real databases show that BitTableFI outperforms Apriori and CBAR which uses ClusterTable for quick support count.		Jie Dong;Min Han	2007	Knowl.-Based Syst.	10.1016/j.knosys.2006.08.005	data structure;computer science;data science;time series;data mining;database;statistics	ML	-5.265603103013993	-36.99872417103121	48295
482cb8745de9da690f656ce4b2b121361186ea8d	conformative filtering for implicit feedback data		Implicit feedback is the simplest form of user feedback that can be used for item recommendation. It is easy to collect and is domain independent. However, there is a lack of negative examples. Previous work tackles this problem by assuming that users are not interested or not as much interested in the unconsumed items. Those assumptions are often severely violated since non-consumption can be due to factors like unawareness or lack of resources. Therefore, non-consumption by a user does not always mean disinterest or irrelevance. In this paper, we propose a novel method called Conformative Filtering (CoF) to address the issue. The motivating observation is that if there is a large group of users who share the same taste and none of them have consumed an item before, then it is likely that the item is not of interest to the group. We perform multidimensional clustering on implicit feedback data using hierarchical latent tree analysis (HLTA) to identify user “taste” groups and make recommendations for a user based on her memberships in the groups and on the past behavior of the groups. Experiments on two real-world datasets from different domains show that CoF has superior performance compared to several common baselines.	exptime;entity–relationship model;experiment;feedback;latent variable;qed (text editor);relevance;social inequality	Farhan Khawar;Nevin Lianwen Zhang;Jinxing Yu	2017	CoRR		information retrieval;filter (signal processing);recommender system;baseline (configuration management);computer science;cluster analysis;machine learning;artificial intelligence	AI	-19.11674712662877	-48.00938924490126	48352
584e0923ff42b96d97532572926fd1fdf40c9ee8	geographic representation in spatial analysis	tratamiento datos;geographic information science;systeme information geographique;key words spatial analysis;informing science;data processing;traitement donnee;spatial variations;direction;geographic information systems;theory;variacion espacial;teoria;euclidean space;variation spatiale;geografia;spatial analysis;geographie;distance;theorie;geography	Spatial analysis mostly developed in an era when data was scarce and computational power was expensive. Consequently, traditional spatial analysis greatly simpli®es its representations of geography. The rise of geographic information science (GISci) and the changing nature of scienti®c questions at the end of the 20 century suggest a comprehensive re-examination of geographic representation in spatial analysis. This paper reviews the potential for improved representations of geography in spatial analysis. Existing tools in spatial analysis and new tools available from GISci have tremendous potential for bringing more sophisticated representations of geography to the forefront of spatial analysis theory and application.	computation;geographic information science;microsoft forefront;spatial analysis;ti-nspire series	Harvey J. Miller	2000	Journal of Geographical Systems	10.1007/s101090050030	data processing;geography;euclidean space;geospatial analysis;mathematics;spatial analysis;geographic information system;economic geography;distance;theory;cartography	HPC	-26.04991781900828	-29.56810754846437	48489
bb5e3aa988fd1f514c88b38f7a386eaa5252331c	automatic induction of domain-related information: learning descriptors type domains	informal learning	Learning in complex contexts often requires pure induction to be supported by various kinds of meta-information. Providing such information is a critical, difficult and error-prone activity. This paper proposes an algorithm to automatically identify types from observations, and studies its performance and robustness.	algorithm;cognitive dimensions of notations;mathematical induction;robustness (computer science)	Stefano Ferilli;Floriana Esposito;Teresa Maria Altomare Basile;Nicola Di Mauro	2004			computer science;artificial intelligence;machine learning	AI	-25.027416740412416	-27.329874662249964	48550
1374f8e4af3a50b32d3013bd35a31f50b6213530	cellular collective resolution in artificial neuro-agent networks.				Jean-Pierre Mano;Pierre Glize	2005			artificial intelligence;machine learning;computer science	HPC	-8.687505575964321	-47.84223100000174	48619
e1fb876211b62020c959655c8c2413fdebe33dc4	guidance in the human-machine analytics process		Abstract In this paper, we list the goals for and the pros and cons of guidance, and we discuss the role that it can play not only in key low-level visualization tasks but also the more sophisticated model-generation tasks of visual analytics. Recent advances in artificial intelligence, particularly in machine learning, have led to high hopes regarding the possibilities of using automatic techniques to perform some of the tasks that are currently done manually using visualization by data analysts. However, visual analytics remains a complex activity, combining many different subtasks. Some of these tasks are relatively low-level, and it is clear how automation could play a role—for example, classification and clustering of data. Other tasks are much more abstract and require significant human creativity, for example, linking insights gleaned from a variety of disparate and heterogeneous data artifacts to build support for decision making. In this paper, we outline the potential applications of guidance, as well as the inputs to guidance. We discuss challenges in implementing guidance, including the inputs to guidance systems and how to provide guidance to users. We propose potential methods for evaluating the quality of guidance at different phases in the analytic process and introduce the potential negative effects of guidance as a source of bias in analytic decision making.		Christopher Collins;Natalia V. Andrienko;Tobias Schreck;Jing Yang;Jaegul Choo;Ulrich Engelke;Amit Jena;Tim Dwyer	2018	Visual Informatics	10.1016/j.visinf.2018.09.003	data mining;automation;visual analytics;visualization;guidance system;cluster analysis;cons;human–machine system;analytics;computer science	Vision	-27.885251238109667	-31.274659976546882	48657
5bdeefe2f037f51668b6b977264c96543f9ad537	a bayes net toolkit for student modeling in intelligent tutoring systems	modelizacion;outil logiciel;evaluation performance;software tool;student model;computer assisted teaching;systeme tutoriel intelligent;performance evaluation;intelligent tutoring system;xml language;evaluacion prestacion;skill acquisition;tracing;ensenanza asistida por computador;acquisition connaissances;time series;user assistance;modelisation;lines of code;area under curve;assistance utilisateur;causalite;knowledge acquisition;asistencia usuario;serie temporelle;intelligent tutoring systems;tracage;serie temporal;time series data;adquisicion de conocimientos;educacion;herramienta software;modeling;langage xml;lenguaje xml;enseignement assiste ordinateur;student performance;trazado;causality;causalidad	This paper describes an effort to model a student’s changing knowledge state during skill acquisition. Dynamic Bayes Nets (DBNs) provide a powerful way to represent and reason about uncertainty in time series data, and are therefore well-suited to model student knowledge. Many general-purpose Bayes net packages have been implemented and distributed; however, constructing DBNs often involves complicated coding effort. To address this problem, we introduce a tool called BNTSM. BNT-SM inputs a data set and a compact XML specification of a Bayes net model hypothesized by a researcher to describe causal relationships among student knowledge and observed behavior. BNT-SM generates and executes the code to train and test the model using the Bayes Net Toolbox [1]. Compared to the BNT code it outputs, BNT-SM reduces the number of lines of code required to use a DBN by a factor of 5. In addition to supporting more flexible models, we illustrate how to use BNT-SM to simulate Knowledge Tracing (KT) [2], an established technique for student modeling. The trained DBN does a better job of modeling and predicting student performance than the original KT code (Area Under Curve = 0.610 > 0.568), due to differences in how it estimates parameters.	bayesian network;causality;general-purpose modeling;kosterlitz–thouless transition;pr/sm;petri net;simulation;source lines of code;time series;xml	Kai-min Chang;Joseph E. Beck;Jack Mostow;Albert T. Corbett	2006		10.1007/11774303_11	simulation;computer science;artificial intelligence;operating system;machine learning;time series;database;programming language;algorithm;statistics	AI	-33.05062055045857	-26.492456754337613	48672
3faa6a48486a0ce99fb4860a2d8350e9cd84dd03	the impact of first impressions on human- robot trust during problem-solving scenarios		With recent advances in robotics, it is expected that robots will become increasingly common in human environments, such as in the home and workplaces. Robots will assist and collaborate with humans on a variety of tasks. During these collaborations, it is inevitable that disagreements in decisions would occur between humans and robots. Among factors that lead to which decision a human should ultimately follow, theirs or the robot, trust is a critical factor to consider. This study aims to investigate individualsu0027 behaviors and aspects of trust in a problem-solving situation in which a decision must be made in a bounded amount of time. A between-subject experiment was conducted with 100 participants. With the assistance of a humanoid robot, participants were requested to tackle a cognitive-based task within a given time frame. Each participant was randomly assigned to one of the following initial conditions: 1) a working robot in which the robot provided a correct answer or 2) a faulty robot in which the robot provided an incorrect answer. Impacts of the faulty robot behavior on participantu0027s decision to follow the robotu0027s suggested answer were analyzed. Survey responses about trust were collected after interacting with the robot. Results indicated that the first impression has a significant impact on participantu0027s behavior of trusting a robotu0027s advice during a disagreement. In addition, this study discovered evidence supporting that individuals still have trust in a malfunctioning robot even after they have observed a robotu0027s faulty behavior.	experiment;humanoid robot;humans;human–robot interaction;initial condition;primacy of mind;problem solving;randomness;robotics;social robot;trust (emotion)	Jin Xu;Ayanna M. Howard	2018	2018 27th IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN)	10.1109/ROMAN.2018.8525669	task analysis;simulation;humanoid robot;behavior-based robotics;robot;first impression (psychology);artificial intelligence;computer science;human–robot interaction;robotics;cognition	Robotics	-31.32886063952975	-41.59366310118706	48734
01091d8910096f7fbf0dd375db1e50b8618ffb49	d-index: distance searching index for metric data sets	nearest neighbor queries;metric space;performance evaluation;index structure;search strategy;data type;similarity retrieval;dynamic environment;indexation;performanceevaluation;index structures;metric spaces;similarity search	In order to speedup retrieval in large collections of data, index structures partition the data into subsets so that query requests can be evaluated without examining the entire collection. As the complexity of modern data types grows, metric spaces have become a popular paradigm for similarity retrieval. We propose a new index structure, called D-Index, that combines a novel clustering technique and the pivot-based distance searching strategy to speed up execution of similarity range and nearest neighbor queries for large files with objects stored in disk memories. We have qualitatively analyzed D-Index and verified its properties on actual implementation. We have also compared D-Index with other index structures and demonstrated its superiority on several real-life data sets. Contrary to tree organizations, the D-Index structure is suitable for dynamic environments with a high rate of delete/insert operations.	cluster analysis;computation;computer data storage;disk space;dynamic data;experiment;inverted index;m-tree;optimal design;programming paradigm;real life;requirement;semantic similarity;similarity search;speedup	Vlastislav Dohnal;Claudio Gennaro;Pasquale Savino;Pavel Zezula	2003	Multimedia Tools and Applications	10.1023/A:1025026030880	m-tree;metric space;computer science;data mining;database;cover tree;nearest neighbor search;information retrieval	DB	-5.627284944137099	-41.09334109220594	48855
6d892f3c26a284748a3f0575d45c8e9696a6e9b9	users sleeping time analysis based on micro-blogging data	micro blogging;time zone;social networking services;sleeping time;time series	The emergence of new social network services, often labeled as Web 2.0, has permitted an amazingly increase of user generated content. In particular, Sina Weibo, a popular Chinese micro-blogging service is designed as platforms allowing users to generate contents that open to the public. From analyzing activates of submitting posts to Sina Weibo, some features of users can be estimated. This paper aims to contribute to this growing body of literature by studying how users' frequent activities reflect their sleeping time and living time zones. By mining a large set of users' activates data from Sina Weibo, we demonstrate its possible role to detect the sleeping time of users and find a new method for judging users' time zone.	blog;emergence;social network;user-generated content;web 2.0	Haoran Yu;Guangzhong Sun;Min Lv	2012		10.1145/2370216.2370428	time zone;computer science;microblogging;time series;internet privacy;world wide web;statistics	HCI	-23.86168906613317	-51.94032845289617	48969
64efbe28469bfc558a1b9a8b1ec572f714a58332	creating and maintaining chemical artificial life by robotic symbiosis	symbiosis;protocell;3d printer;artificial intelligence;droplet;symbiosis 3d printer artificial intelligence droplet protocell robot;robot	We present a robotic platform based on the open source RepRap 3D printer that can print and maintain chemical artificial life in the form of a dynamic, chemical droplet. The robot uses computer vision, a self-organizing map, and a learning program to automatically categorize the behavior of the droplet that it creates. The robot can then use this categorization to autonomously detect the current state of the droplet and respond. The robot is programmed to visually track the droplet and either inject more chemical fuel to sustain a motile state or introduce a new chemical component that results in a state change (e.g., division). Coupling inexpensive open source hardware with sensing and feedback allows for replicable real-time manipulation and monitoring of nonequilibrium systems that would be otherwise tedious, expensive, and error-prone. This system is a first step towards the practical confluence of chemical, artificial intelligence, and robotic approaches to artificial life.		Martin M. Hanczyc;Juan Manuel Parrilla Gutierrez;Arwen Nicholson;Kliment Yanev;Kasper Støy	2015	Artificial Life	10.1162/ARTL_a_00151	protocell;robot;biology;simulation;drop;computer science;artificial intelligence;symbiosis	AI	-6.063602432791448	-48.32452124789981	48974
5fbe31d66d166b1618e86b50aea75b4a24d3b51f	sqbc: an efficient subgraph matching method over large and dense graphs	graph theory;database;journal;algorithm;index strategy;large network;subgraph isomorphism	Recent progress in biology and computer science have generated many complicated networks, most of which can be modeled as large and dense graphs. Developing effective and efficient subgraph match methods over these graphs is urgent, meaningful and necessary. Although some excellent exploratory approaches have been proposed these years, they show poor performances when the graphs are large and dense. This paper presents a novel Subgraph Query technique Based on Clique feature, called SQBC, which integrates the carefully designed clique encoding with the existing vertex encoding [40] as the basic index unit to reduce the search space. Furthermore, SQBC optimizes the subgraph isomorphism test based on clique features. Extensive experiments over biological networks, RDF dataset and synthetic graphs have shown that SQBC outperforms the most popular competitors both in effectiveness and efficiency especially when the data graphs are large and dense.	approximation algorithm;clique (graph theory);experiment;locality of reference;maximal set;microsoft customer care framework;open research;subgraph isomorphism problem;synthetic data	Weiguo Zheng;Lei Zou;Xiang Lian;Huaming Zhang;Wei David Wang;Dongyan Zhao	2014	Inf. Sci.	10.1016/j.ins.2013.10.003	clique;block graph;split graph;combinatorics;cograph;universal graph;computer science;clique problem;graph theory;theoretical computer science;machine learning;clique-sum;subgraph isomorphism problem;mathematics;maximal independent set;graph isomorphism;induced subgraph isomorphism problem;maximum common subgraph isomorphism problem;treewidth;chordal graph;indifference graph;algorithm	AI	-9.627621253748964	-39.80204921973981	48977
480183387ab26b31f09fdcba408ed5eee871388a	interactive task learning with discrete and continuous features		Learning tasks from demonstration is key to the flexibility of robots and their accessibility to non-programmers. We present a task learning framework that combines the strengths of discrete and continuous representations. The robot learns a set of criteria and expectations to represent the goal of a demonstrated task. The task consists of performing actions that fulfill expectations on objects that meet the criteria. We propose modeling continuous criteria and expectations with Gaussian distributions. To deal with simultaneous demonstration of multiple tasks, we assume that expectations can be multi-modal and model them as mixtures of Gaussians. We present an implementation of this framework on the robot	accessibility;burrows–wheeler transform;mixture model;modal logic;programmer;robot;sorting	Crystal Chao;Maya Cakmak;Andrea Lockerd Thomaz	2010			machine learning;gaussian;artificial intelligence;computer science	Robotics	-33.49124301611863	-39.888499251982275	48979
8410412c7c615220aeda7ded4612a79cf724b2b0	exploring multi-view learning for activity inferences on smartphones	software;sensors;smart phones;computational modeling;feature extraction;data models;hardware	Inferring activities on smartphones is a challenging task. Prior works have elaborated on using sensory data from built-in hardware sensors in smartphones or taking advantage of location information to understand human activities. In this paper, we explore two types of data on smartphones to conduct activity inference: 1) Spatial-Temporal: reflecting daily routines from the combination of spatial and temporal patterns, 2) Application: perceiving specialized apps that assist the user's activities. We employ multi-view learning model to accommodate both types of data and use weighted linear kernel model to aggregate the views. Note that since resources of smartphones are limited, activity inference on smartphones should consider the constraints of resources, such as the storage, energy consumption, and computation power. Finally, we compare our proposed method with several classification methods on a real dataset to evaluate the effectiveness and performance of our method. The experimental results show that our approach outperforms other methods regarding the balance between accuracy, running time, and storage efficiency.	aim alliance;aggregate data;computation;high- and low-level;sensor;smartphone;spatial reference system;storage efficiency;time complexity	Gunarto Sindoro Njoo;Chien-Hsiang Lai;Kuo-Wei Hsu	2016	2016 Conference on Technologies and Applications of Artificial Intelligence (TAAI)	10.1109/TAAI.2016.7880160	real-time computing;simulation;computer science;data mining	AI	-14.417012401719196	-33.46211991110592	48980
c44c94c99e2c63ec6cd46a3d5a1ebde571cc13d9	a novel bipartite graph based competitiveness degree analysis from query logs	competitiveness degree;competitive intelligence;query logs;bipartite graph	Competitiveness degree analysis is a focal point of business strategy and competitive intelligence, aimed to help managers closely monitor to what extent their rivals are competing with them. This article proposes a novel method, namely BCQ, to measure the competitiveness degree between peers from query logs as an important form of user generated contents, which reflects the “wisdom of crowds” from the search engine users’ perspective. In doing so, a bipartite graph model is developed to capture the competitive relationships through conjoint attributes hidden in query logs, where the notion of competitiveness degree for entity pairs is introduced, and then used to identify the competitive paths mapped in the bipartite graph. Subsequently, extensive experiments are conducted to demonstrate the effectiveness of BCQ to quantify the competitiveness degrees. Experimental results reveal that BCQ can well support competitors ranking, which is helpful for devising competitive strategies and pursuing market performance. In addition, efficiency experiments on synthetic data show a good scalability of BCQ on large scale of query logs.	algorithm;algorithmic efficiency;entity;experiment;focal (programming language);scalability;social media;strategic management;synthetic data;the wisdom of crowds;web search engine	Qiang Wei;Dandan Qiao;Jin Zhang;Guoqing Chen;Xunhua Guo	2016	TKDD	10.1145/2996196	competitive intelligence;bipartite graph;computer science;machine learning;data mining;world wide web	AI	-17.713790239906903	-45.2852898206885	49084
b99f805739533c9a7af3671957c2d170f9dad617	learning from the ubiquitous language: an empirical analysis of emoji usage of smartphone users	cultural difference;data mining;emoji	"""Emojis have been widely used to simplify emotional expression and enrich user experience. As an interesting practice of ubiquitous computing, emojis are adopted by Internet users from many different countries, on many devices (particularly popular on smartphones), and in many applications. The """"ubiquitous"""" usage of emojis enables us to study and compare user behaviors and preferences across countries and cultures. We present an analysis on how smartphone users use emojis based on a very large data set collected from a popular emoji keyboard. The data set contains a complete month of emoji usage of 3.88 million active users from 212 countries and regions. We demonstrate that the categories and frequencies of emojis used by these users provide rich signals for the identification and the understanding of cultural differences of smartphone users. Users from different countries present significantly different preferences on emojis, which complies with the well-known Hofstede's cultural dimensions model."""	domain-driven design;emoji;smartphone;ubiquitous computing;user experience;whole earth 'lectronic link	Xuan Lu;Wei Ai;Xuanzhe Liu;Qian Li;Ning Wang;Gang Huang;Qiaozhu Mei	2016		10.1145/2971648.2971724	computer science;multimedia;internet privacy;world wide web	HCI	-26.006917685954324	-45.239764247610886	49126
40e04fedbe4a54f57a8a2b83ed0ee7295b151bf6	a taxonomic analysis of what world wide web activities significantly impact people's decisions and actions	web usability;information foraging;ecological validity;taxonomy;world wide web;parc	In this paper, we present three taxonomic classification schemes based on Web users' responses to what Web activities significantly impacted their decisions and actions. The taxonomic classifications focus on three variables: the Purpose of people's search on the Web, the Method people use to find information, and the Content of the information for which they are searching. These taxonomies are useful for understanding people's activity on the Web and for developing ecologically-valid tasks to be used when studying Web behavior.	ecology;taxonomic database;world wide web	Julie Bauer Morrison;Peter Pirolli;Stuart K. Card	2001		10.1145/634067.634167	web usability;web analytics;web standards;ecological validity;computer science;knowledge management;social semantic web;data mining;web intelligence;world wide web;taxonomy	Web+IR	-32.94131684365558	-51.172836074452	49141
af6a413190f64424f47c7c50e9e3dad650aeba15	high-speed clustering of regional photos using representative photos of different regions		In recent years, a huge number of photographs have been posted on SNS by many users, and users view photos posted by other users. When browsing photos, even if you find a photo of the scenery you want to see, it is difficult to go to that place if you were taken at a remote location such as overseas. Then, there are demands to search for areas that look like the photo in nearby places. To this end, there is a method of extracting representative photos for each area and clustering a large number of photos based on the representative ones. The k-medoids clustering method extracts representative objects called medoids and clusters them, so it coincides with this purpose, but it takes a large amount of computation time. In this paper, we aim to propose two methods of speeding up for k-medoids clustering utilizing representative photos in other areas which have been already extracted. In a method using representative photos of a single area, the clustering quality varies depending on the area to be used. It is difficult to know in advance the area that increases the clustering quality. In a method of selecting from representative photos in multiple regions, it is expected that highly accurate clustering results can be obtained because the representative photographs that minimize the objective function of the k-medoids method are selected across regions. In our experimental evaluation using large real datasets, we confirm that our proposed method works much faster than existing methods, greedy methods equipped with the lazy evaluation and the pivot pruning techniques, and obtains high quality.		Takayasu Fushimi;Ryota Mori	2018	2018 IEEE/WIC/ACM International Conference on Web Intelligence (WI)	10.1109/WI.2018.00-43	data mining;information retrieval;feature extraction;computation;cluster analysis;computer science;approximation algorithm;lazy evaluation;medoid;greedy algorithm;linear programming	AI	-14.168272664012008	-37.075204904822556	49241
051855906787e975d02f4c4c632976c57128b0e4	an interface for visualization and exploration of spatial distributions		This work details methods for visualizing and browsing a set of distributions of locational data derived from multi-modal analysis of a large video and audio dataset.	abstract data type;align (company);computation;data point;data structure;exemplification;modal logic;transcription (software)	George Shaw;Deb Roy	2011			computer vision;human–computer interaction;computer science;world wide web	Visualization	-31.117303645721613	-34.24725699717335	49314
d55424edabbd86af1599130096e5e3aec267916a	finding topic-specific trends and influential users in social networks		Social networks (SNs) have become an integral part of contemporary life, as they are increasingly used as a basic means for communication with friends, sharing of opinions and staying up to date with news and current events. The general increase in the usage and popularity of social media has led to an explosion of available data, which creates opportunities for various kinds of utilization, such as predicting, finding or even creating trends. We are thus interested in exploring the following questions: (a) Which are the most influential - popular internet publications posted in SNs, for a specific topic? (b) Which members of SNs are experts or influential regarding a specific topic? Our approach towards answering the above questions is based on the functionality of hashtags, which we use as topic indicators for posts, and on the assumption that a specific topic is represented by multiple hashtags. We present a neighborhood-based recommender system, which we have implemented using collaborative filtering algorithms in order to (a) identify hashtags, urls and users related with a specific topic, and (b) combine them with SN-based metrics in order to address the aforementioned questions in Twitter. The recommender system is built on top of Apache Spark framework in order to achieve optimal scaling and efficiency. For the verification of our system we have used data sets mined from Twitter and tested the extracted results for influential users and urls concerning specific topics in comparison with the influence scores produced by a state of the art influence estimation tool for SNs. Finally, we present and discuss the results regarding two distinct topics and also discuss the offered and potential utility of our system.	social network	Eleni Koutrouli;Karen Ballard;Aphrodite Tsalgatidou	2018		10.1007/978-3-030-01771-2_26	data science;recommender system;collaborative filtering;machine learning;artificial intelligence;the internet;spark (mathematics);computer science;social media;popularity;social network	ML	-23.882935682859387	-49.665195553019714	49347
e16e10921ebf4cc57850e2a54244063c609f639b	dynamic transition of scientific teams based on time slicing		Based on dynamic research perspectives of time slicing, this paper shows an endeavor on mining dynamic features of the scientific teams. Traditionally the static method of network structure analysis can successfully be used to analyze the distribution of network resource structure. But it cannot be used to explore the dynamic features of research groups, because of its lacks on the influence of some variables in research activities. These variables include researchers, research hotspots and research funds, etc. which are all in varying state due to the changing world. This paper proposes a new approach to analyze the dynamic characteristics of scientific teams, by using time slicing incorporated with traditional static method. KP(core members Keep-Rate) is used as an index of the dynamic transitions of scientific teams in two sequential time slices, and an algorithm is proposed to identify the successor team(s).	algorithm;hotspot (wi-fi);method (computer programming);preemption (computing);time slicing (digital broadcasting)	Yuyao Li;Yong Tang;Jiemin Chen;Guohua Chen;Jiacheng Liang	2017	2017 IEEE 21st International Conference on Computer Supported Cooperative Work in Design (CSCWD)	10.1109/CSCWD.2017.8066670	market research;slicing;algorithm design;dynamic priority scheduling;computer science;data mining	Visualization	-23.034610911713134	-35.02386699392746	49632
efe494cc50df87dade4fde79f41fe2a5089c01f6	exceptional contrast set mining: moving beyond the deluge of the obvious		Data scientists, with access to fast growing data and computing power, constantly look for algorithms with greater detection power to discover “novel” knowledge. But more often than not, their algorithms give them too many outputs that are either highly speculative or simply confirming what the domain experts already know. To escape this dilemma, we need algorithms that move beyond the obvious association analyses and leverage domain analytic objectives (aka. KPIs) to look for higher order connections. We propose a new technique Exceptional Contrast Set Mining that first gathers a succinct collection of affirmative contrast sets based on the principle of redundant information elimination. Then it discovers exceptional contrast sets that contradict the affirmative contrast sets. The algorithm has been successfully applied to several analytic consulting projects. In particular, during an analysis of a state-wide cancer registry, it discovered a surprising regional difference in breast cancer screening.		Dang Nguyen;Wei Luo;Dinh Q. Phung;Svetha Venkatesh	2016		10.1007/978-3-319-50127-7_39	engineering;data mining;cartography	ML	-9.847800739426795	-34.816936329483674	49639
a1934e27786e18701e58cd9e21981040d5641e6b	a simulation study of subterranean termites' territory formation	termite foraging territory;territorial competition;single cell;seasonality;simulation study;territory formation;subterranean termite;lattice model	The process through which the Formosan subterranean termite,  Coptotermes formosanus  Shiraki, establishes territory was simulated using a lattice model in order to understand how such territories are formed from their seeds-founding pairs that fall to the ground every year. The model incorporated, summer–winter cycles, and fourteen years were simulated. Simulated pairs fell to random sites within the lattice space at the beginning of every summer, and their territories grew during the summer season, and shrunk during the winter season. Fourteen years were sufficient for territory size and shape to become stable over time. The simulation revealed that only pairs introduced at  t  = 0 had established large territories by the end of the simulation ( t  = 14). Pairs that were introduced later expanded their territory a little at first, but ultimately shrunk back into a single-cell-sized or small-sized territory. This means that stable-state territory size is mostly determined by when that territory was initially established.	simulation	Sang-Hee Lee;Nan-Yao Su	2009	Ecological Informatics	10.1016/j.ecoinf.2009.02.001	biology;lattice model;ecology;seasonality;statistics	HCI	-14.886078527857554	-25.948487502158898	49694
6e3f1edb444df27160f89c29f0203466eef88f9e	towards qualitative and quantitative prediction and detection of parturition onset in sows using light barriers	gestating sow;light barrier;parturition prediction;precision livestock farming;parturition detection	Piglet mortality can be a large economic and animal welfare issue in breeding facilities. A system that predicts the parturition can help the breeder in economically organising staff assignments in order to achieve an optimal workload levelling. In the current study, light barriers at the head and torso region of a sow were used to measure and classify the activity increase of 34 sows related to their near parturition. Based on this data, 4 different activity frequency and activity duration based qualitative predictors for the near onset of parturition were developed retrospectively, utilising cumulative sum techniques and a global threshold approach. The threshold optimisation for the qualitative prediction was performed using a random set of 17 sows and validated with the remaining sows. The best performing qualitative prediction yielded a validated sensitivity of 88% at a precision of 88%. This prediction generated parturition alerts with a 25th percentile of 13 h and a 75th percentile of 20 h before the parturition started. Based on this indicator, a quantitative prediction of the time remaining until the onset of parturition could be developed. This prediction exhibited a mean prediction error of 0.5 h ± 2.6 h (SD) for 88% of the sows over a period of 13–24 h before the onset of parturition. At the same time 12% of the predictions were unusable with a mean prediction error of 12.5 h ± 6.9 h (SD). In addition, a method for detecting the parturition onset with an accuracy of ±4 h, a sensitivity of 88% and a precision of 97% for the head sensor could be obtained. With data from the torso sensor, the performance of the various indicators was generally lower and optimality was achieved with different thresholds. The present study follows other studies showing the general detectability of the parturition related increase in activity using video, light barriers and ultrasonic distance sensors. It is also closely based on earlier studies using accelerometers for individual qualitative parturition detection, with the explicit intent to reproduce these results using	activity recognition;breeder (cellular automaton);contactless smart card;cooperative breeding;decision support system;information security indicators;light pen;mathematical optimization;onset (audio);sensor;statement of work;usability	Christian Manteuffel;Eberhard Hartung;Mariana Schmidt;Gundula Hoffmann;Peter Christian Schön	2015	Computers and Electronics in Agriculture	10.1016/j.compag.2015.06.017	real-time computing;simulation;engineering	HCI	-17.37862271316019	-29.01890540442164	49707
c7a1e539cb0521278bd93da7629b3891af1d5a62	tag based collaborative filtering for recommender systems	three dimensional;online community;user profile;user profiling;recommender system;collaborative filtering;collaborative tagging;similarity measure;recommender systems	Collaborative tagging can help users organize, share and retrieve information in an easy and quick way. For the collaborative tagging information implies user’s important personal preference information, it can be used to recommend personalized items to users. This paper proposes a novel tag-based collaborative filtering approach for recommending personalized items to users of online communities that are equipped with tagging facilities. Based on the distinctive three dimensional relationships among users, tags and items, a new similarity measure method is proposed to generate the neighborhood of users with similar tagging behavior instead of similar implicit ratings. The promising experiment result shows that by using the tagging information the proposed approach outperforms the standard user and item based collaborative filtering approaches.	collaborative filtering;experiment;folksonomy;online community;personalization;recommender system;similarity measure	Huizhi Liang;Yue Xu;Yuefeng Li;Richi Nayak	2009		10.1007/978-3-642-02962-2_84	three-dimensional space;computer science;collaborative filtering;information filtering system;machine learning;data mining;world wide web;information retrieval;recommender system	Web+IR	-27.24630455191307	-50.188201572693615	49762
3aad167d63b84ab05bc7bdf0ff2e23b607fe3738	exploiting synergies between semantic reasoning and personalization strategies in intelligent recommender systems: a case study	content based methods;digital tv;user perception;personalization;recommender system;collaborative filtering;semantic reasoning;semantic web;experimental evaluation	0164-1212/$ see front matter 2008 Elsevier Inc. A doi:10.1016/j.jss.2008.05.009 q Work funded by the Ministerio de Educación y C research project TSI2007-61599, by the Consellería Universitaria (Xunta de Galicia) incentives file 2007/00 de Promoción Xeral da Investigación de Consellería Comercio (Xunta de Galicia) PGIDIT05PXIC32204PN. * Corresponding author. E-mail address: yolanda@det.uvigo.es (Y. Blanco-F Current recommender systems attempt to identify appealing items for a user by applying syntactic matching techniques, which suffer from significant limitations that reduce the quality of the offered suggestions. To overcome this drawback, we have developed a domain-independent personalization strategy that borrows reasoning techniques from the Semantic Web, elaborating recommendations based on the semantic relationships inferred between the user’s preferences and the available items. Our reasoningbased approach improves the quality of the suggestions offered by the current personalization approaches, and greatly reduces their most severe limitations. To validate these claims, we have carried out a case study in the Digital TV field, in which our strategy selects TV programs interesting for the viewers from among the myriad of contents available in the digital streams. Our experimental evaluation compares the traditional approaches with our proposal in terms of both the number of TV programs suggested, and the users’ perception of the recommendations. Finally, we discuss concerns related to computational feasibility and scalability of our approach. 2008 Elsevier Inc. All rights reserved.	personalization;recommender system;scalability;semantic web;synergy	Yolanda Blanco-Fernández;José Juan Pazos-Arias;Alberto Gil-Solla;Manuel Ramos Cabrer;Martín López Nores;Jorge García Duque;Ana Fernández Vilas;Rebeca P. Díaz Redondo	2008	Journal of Systems and Software	10.1016/j.jss.2008.05.009	computer science;collaborative filtering;semantic web;data mining;personalization;multimedia;world wide web;recommender system	AI	-22.244095474262334	-48.95905810279228	49786
23fdf1f82d8e685cd52ddd3518997cb5c6d9b8a9	automatic tagging of learning objects based on their usage in web portals		Data sets coming from the educational domain often suffer from sparsity. Hence, many learning objects are not accessible by the users as they are not able to find these objects using for example a text- based search. Furthermore, the lack of information makes it difficult or even impossible to recommend such hidden learning resources. In order to address the data sparsity problem, this paper presents a new way to enhance the objects' semantic representations. This is done by auto- matically assigning tags and classifications to learning objects offered by educational web portals. This way, we aim to increase the accessibility of the learning objects as well as to enable their recommendation. In contrast to popular tagging approaches that usually base the tagging of a learning object on its content or on the tags already assigned to it, the approach proposed in this paper is solely based on the objects' usage. Therefore, tags and classifications can be exchanged between the objects and also previously un-tagged objects that do not hold any textual con- tent can be automatically assigned with tags and classifications.	portals	Katja Niemann	2015		10.1007/978-3-319-24258-3_18	computer science;multimedia;world wide web;information retrieval	AI	-28.22867202214383	-50.659202498237875	49805
29cc067cd276b3323cbdc74b96e6a0409ef20aad	mining for spatially-near communities in geo-located social networks	position location;communications networks;communities;geography	Current approaches to community detection in social networks often ignore the spatial location of the nodes. In this paper, we look to extract spatially-near communities in a social network. We introduce a new metric to measure the quality of a community partition in a geolocated social networks called “spatially-near modularity” a value that increases based on aspects of the network structure but decreases based on the distance between nodes in the communities. We then look to find an optimal partition with respect to this measure which should be an “ideal” community with respect to both social ties and geographic location. Though an NP-hard problem, we introduce two heuristic algorithms that attempt to maximize this measure and outperform nongeographic community finding by an order of magnitude. Applications to counter-terrorism are also discussed.	academy;algorithm;geographic coordinate system;heuristic;np-hardness;orca;scalability;social network	Joseph Hannigan;Guillermo Hernández;Richard M. Medina;Patrick Roos;Paulo Shakarian	2013	CoRR		artificial intelligence;data mining;management science;community structure	Web+IR	-13.008831589916063	-41.29980026783839	49900
31fb2e6952156cea353535fc067776ab5b9a9ee5	application of competitive clustering to acquisition of human manipulation skills	human constrained motion manipulation skill;pattern clustering;manipulators;selected works;haptic rendered virtual environment;virtual reality;competitive agglomeration;fuzzy set theory;competitive fuzzy clustering algorithm;fuzzy clustering;a priori knowledge;haptic rendering;robot trajectory human constrained motion manipulation skill haptic rendered virtual environment competitive fuzzy clustering algorithm competitive agglomeration locally weighted regression;virtual reality fuzzy set theory manipulators pattern clustering regression analysis rendering computer graphics robot programming;number of clusters;bepress;humans haptic interfaces virtual environment robotic assembly clustering algorithms fuzzy sets robots application software torque predictive models;robot trajectory;regression analysis;positional information;prediction model;virtual environment;rendering computer graphics;locally weighted regression;robot programming	The work carried out to explore the feasibility of reconstructing human constrained motion manipulation skills is reported. This is achieved by tracing and learning the manipulation performed by a human operator in a haptic rendered virtual environment. The peg-in-hole insertion problem is used as a case study. In the developed system, position and contact force and torque as well as orientation data generated in the haptic rendered virtual environment combined with a priori knowledge about the task are used to identify and learn the skills in the newly demonstrated task. The data obtained from the virtual environment is classified into different cluster sets using a competitive fuzzy clustering algorithm called competitive agglomeration (CA). The CA algorithm starts with an over specified number of clusters which compete for feature points in the training procedure. Clusters with small cardinalities lose the competition and gradually vanish. The optimal number of clusters that win the competition is eventually determined. The clusters in the optimum cluster set are tuned using locally weighted regression (LWR) to produce prediction models for robot trajectory performing the physical assembly based on the force/position information received from the rig. A background on the work and its significance is provided. The approach developed is explained and the results obtained so far are presented	algorithm;cardinality (data modeling);cluster analysis;computer cluster;fuzzy clustering;haptic technology;vanish (computer science);virtual reality	Shen Dong;Fazel Naghdy	2005	International Conference on Computational Intelligence for Modelling, Control and Automation and International Conference on Intelligent Agents, Web Technologies and Internet Commerce (CIMCA-IAWTIC'06)	10.1109/CIMCA.2005.1631615	computer vision;a priori and a posteriori;simulation;local regression;fuzzy clustering;computer science;virtual machine;artificial intelligence;machine learning;virtual reality;predictive modelling;fuzzy set;regression analysis	Robotics	-29.85496987147583	-38.38752280658816	49920
9e462a81f28d8701cc5e5c683a4312605500639b	urban dynamics, fractals and generalized entropy	fractal dimension;region types;sprawl;lisbon metropolitan area;generalized entropy;urban growth	We explore the relation between the local fractal dimension and the development of the built-up area of the Northern Margin of the Metropolitan Area of Lisbon (NMAL), for the period between 1960 and 2004. To this end we make use of a Generalized Local Spatial Entropy (GLSE) function based on which urban areas can be classified into five different types. Our analysis of NMAL shows how some of the growth dynamics encountered can be linked to the plethora of social, economic and political changes that have taken place in NMAL (and Portugal), during the last 40 years, allowing for the establishment of urban planning measures to either inhibit or promote sprawl in urban areas.	fractal dimension	Sara Encarnação;Marcos Gaudiano;Francisco C. Santos;José António Tenedório;Jorge M. Pacheco	2013	Entropy	10.3390/e15072679	urban sprawl;mathematics;fractal dimension	HCI	-12.586361418759433	-24.60867908721343	50002
0557946aaf9be35fe1f8f4bd514264fa69504cb7	on the integration of graph exploration and data analysis: the creative exploration toolkit	incollection;bisoziation	To enable discovery in large, heterogenious information networks a tool is needed that allows exploration in changing graph structures and integrates advanced graph mining methods in an interactive visualization framework. We present the Creative Exploration Toolkit (CET), which consists of a state-of-the-art user interface for graph visualization designed towards explorative tasks and support tools for integration and communication with external data sources and mining tools, especially the data-mining platform KNIME. All parts of the interface can be customized to fit the requirements of special tasks, including the use of node type dependent icons, highlighting of nodes and clusters. Through an evaluation we have shown the applicability of CET for structure-based analysis tasks.	computer cluster;data mining;extensibility;graph drawing;interactive visualization;node (computer science);requirement;structural analysis;structure mining;user interface;wikipedia	Stefan Haun;Tatiana Gossen;Andreas Nürnberger;Tobias Kötter;Kilian Thiel;Michael R. Berthold	2012		10.1007/978-3-642-31830-6_21	human–computer interaction;computer science;theoretical computer science;data mining	HCI	-30.463416479472144	-31.386257738641735	50054
dcde7bc10a1963722694f234ce632a703e717752	understanding v2x communication dynamics through complex network science			complex network;network science	Nicholas Loulloudes;George Pallis;Marios D. Dikaiakos	2013	ERCIM News		computational biology;complex network;network dynamics;computer science	Theory	-18.38721651483859	-39.99099885855385	50063
17906484f1b9adebb8ef394b1e75cfefef6bc949	reasoning aspects in decision making for medical diagnosis	patient diagnosis;medical knowledge representation;logical relations;physical view reasoning aspects decision making medical diagnosis medical applications fuzzy relations symptoms description fuzzy set relations medical knowledge representation logical relations physical set properties mental set properties medical mental view;fuzzy set theory;medical mental view;medical computing;reasoning aspects;physical view;patient diagnosis decision making fuzzy set theory knowledge representation medical computing;fuzzy relations;knowledge representation;mental set properties;fuzzy set relations;symptoms description;physical set properties;medical applications;medical diagnosis	Summary form only given. Decision making is crucial aspect in medical applications. There are Fuzzy relations that are used in description of Symptoms. Fuzzy set and fuzzy relations are used to represent medical knowledge as network of symptoms and diseases connected with each other by logical relations. Like high temperature is related to fever diagnosis. For example each object in the domain knowledge has n scores reflecting the symptoms, one for each m attribute. For example a symptoms (object) has an attribute from physical set properties, (e.g., high temperature), and other attributes set is from mental set properties (e.g., stress high). Then for each attribute there is assorted list that list each symptoms with its attribute sorted by scores (fuzzy values). This can be evaluated and reasoned using monotone aggregation function or combining rules. This is because the decision making is aggregated on different ontologies that are using different knowledge layers to select the optimal alternatives due to selected criteria that have aggregation operators. These aggregation operators are used to model medical mental view and physical view in our model.	code smell;combining rules;fuzzy set;logical relations;ontology (information science);social network aggregation;monotone	Hamido Fujita	2012	2012 7th IEEE International Symposium on Applied Computational Intelligence and Informatics (SACI)	10.1109/SACI.2012.6249967	knowledge representation and reasoning;variable and attribute;computer science;artificial intelligence;machine learning;medical diagnosis;data mining;mathematics;fuzzy set	AI	-5.581234932697914	-24.48605066800673	50100
228c64f190bec6fd73d5cf32da11d84f677dee4f	research paper recommender systems on big scholarly data		Rapidly growing scholarly data has been coined Big Scholarly Data (BSD), which includes hundreds of millions of authors, papers, citations, and other scholarly information. The effective utilization of BSD may expedite various research-related activities, which include research management, collaborator discovery, expert finding and recommender systems. Research paper recommender systems using smaller datasets have been studied with inconclusive results in the past. To facilitate research to tackle the BSD challenge, we built an analytic platform and developed a research paper recommender system. The recommender system may help researchers find research papers closely matching their interests. The system is not only capable of recommending proper papers to individuals based on his/her profile, but also able to recommend papers for a research field using the aggregated profiles of researchers in the research field.	recommender system	Tsung Teng Chen;Maria R. Lee	2018		10.1007/978-3-319-97289-3_20	recommender system;computer science;collaborative filtering;data mining	ML	-24.577407475063698	-49.68377644312055	50102
14b9ee5255964a26153c55df08e9e62203b29aa7	effective information visualisation: a study of graph drawing aesthetics and algorithms	graph layout aesthetics;human performance;graph drawing;graph layout algorithms;relational information visualisation;graph layout;user experimentation;point of view;280104 computer human interaction;computational efficiency;700199 computer software and services not elsewhere classified;graph drawings;information visualisation	Information visualisation systems which generate diagrams representing discrete relational information must consider potential users if they are to be effective. Many algorithms which render an abstract graph structure as a diagram are valued for their conformance to aesthetic criteria (e.g. reducing the number of edge crossings, maximising symmetry), or for computational ef®ciency. They are not usually judged on their ability to produce diagrams that maximise human performance. This paper presents the results of experiments investigating the relative worth (from an HCI point of view) of graph drawing aesthetics and algorithms using a single graph. The results indicate that while some individual aesthetics affect human performance, it is dif®cult to say that one algorithm is `better' than another from a relational understanding point of view. Designers of automatic layout algorithms, and the systems which embody such algorithms, can bene®t from this study and this human-centred approach, by adapting their methods to focus on user concerns, rather than computational ones. q 2000 Elsevier Science B.V. All rights reserved.	algorithm;automatic layout;computation;conformance testing;crossing number (graph theory);diagram;experiment;graph (discrete mathematics);graph drawing;human reliability;human–computer interaction;information visualization;interpreter (computing);point of view (computer hardware company);s/pdif;on-line system	Helen C. Purchase	2000	Interacting with Computers	10.1016/S0953-5438(00)00032-1	wait-for graph;information visualization;computer science;artificial intelligence;theoretical computer science;machine learning;graph;graph drawing;graph database	AI	-30.140629316425578	-36.4430653308928	50116
3dba360334f4551b3c1b62d1e071d46b38a8d843	evolving figurative images using expression-based evolutionary art		The combination of a classifier system with an evolutionary image generation engine is explored. The framework is composed of an object detector and a general purpose, expressionbased, genetic programming engine. Several object detectors are instantiated to detect faces, lips, breasts and leaves. The experimental results show the ability of the system to evolve images that are classified as the corresponding objects. A subjective analysis also reveals the unexpected nature and artistic potential of the evolved images.	evolutionary art;genetic programming;glossary of computer graphics;learning classifier system;sensor	João Correia;Penousal Machado;Juan Romero;Adrián Carballal	2013			natural language processing;evolutionary art;literal and figurative language;artificial intelligence;computer science	Vision	-27.759694796688475	-24.28399673228037	50134
3fed18c90a68369c9c06b0545830f9dbf81b805e	cluster based bit vector mining algorithm for finding frequent itemsets in temporal databases	efficient algorithm;association rule mining;frequent itemset;temporal database;association rule	In this paper, we introduce an efficient algorithm using a new technique to find frequent itemsets from a huge set of itemsets called Cluster based Bit Vectors for Association Rule Mining (CBVAR). In this work, all the items in a transaction are converted into bits (0 or 1). A cluster is created by scanning the database only once. Then frequent 1-itemsets are extracted directly from the cluster table. Moreover, frequent k-itemsets, where k 2 are obtained by using Logical AND between the items in a cluster table. This approach reduces main memory requirement since it considers only a small cluster at a time and as scalable for any large size of database. The overall performance of this method is significantly better than that of the previously developed algorithms for effective decision making.	algorithm;association rule learning;bit array;computation;computer cluster;computer data storage;dspace;experiment;scalability;synthetic data;temporal database;time complexity	M. Krishnamurthy;Arputharaj Kannan;Ramachandran Baskaran;M. Kavitha	2011		10.1016/j.procs.2010.12.086	gsp algorithm;association rule learning;computer science;machine learning;pattern recognition;data mining;database	DB	-5.152572151305786	-37.314406706569514	50164
b761c56b624c1c56c50dd0d06f9aa79fd7c7c7d0	less effort, more outcomes: optimising debt recovery with decision trees	software;financial data processing;debt recovery repayment schedule decision trees data mining social security out bound phone call;decision tree;debt recovery data mining application decision tree;out bound phone call;data mining;real world application;debt recovery repayment schedule;data mining application;schedules;predictive models;financial data processing data mining decision trees;decision trees data models data mining predictive models security software schedules;social security;decision trees;security;conference proceeding;historical data;data models;debt recovery	This paper presents a real-world application of data mining techniques to optimise debt recovery in social security. The traditional method of contacting a customer for the purpose of putting in place a debt recovery schedule has been an out-bound phone call, and by and large, customers are chosen at random. This obsolete and inefficient method of selecting customers for debt recovery purposes has existed for years and in order to improve this process, decision trees were built to model debt recovery and predict the response of customers if contacted by phone. Test results on historical data show that, the built model is effective to rank customers in their likelihood of entering into a successful debt recovery repayment schedule. If contacting the top 20 per cent of customers in debt, instead of contacting all of them, approximately 50 per cent of repayments would be received.	data mining;decision tree model;predictive modelling;social security	Yanchang Zhao;Hans Bohlscheid;Shanshan Wu;Longbing Cao	2010	2010 IEEE International Conference on Data Mining Workshops	10.1109/ICDMW.2010.114	actuarial science;computer science;information security;machine learning;decision tree;data mining	DB	-8.179832635941477	-30.32152583276282	50200
18b1e3408a0db7874f02162bfc3187d5fd9ff5d9	towards a tag-based user model: how can user model benefit from tags?	social tagging;collaborative tagging;user model	Social tagging is a kind of social annotation by which users label resources, typically web objects, by means of keywords with the goal of sharing, discovering and recovering them. In this paper we investigate the possibility of exploiting the user tagging activity in order to infer knowledge about the user. Up to now the relation between tagging and user modeling seems not to be investigated in depth. Given the widespread diffusion of web tools for collaborative tagging, it is interesting to understand how user modeling can benefit from this feedback.	folksonomy;ontology (information science);tag (metadata);user modeling;xml	Francesca Carmagnola;Federica Cena;Omar Cortassa;Cristina Gena;Ilaria Torre	2007		10.1007/978-3-540-73078-1_62	user modeling;computer science;internet privacy;world wide web;information retrieval	Web+IR	-27.30352618485124	-50.10292550517962	50235
78e435eb0d2803eae328a871484010ce385efc2f	an output and 3d visualization concept for the msaas system mars		When running complex and large-scale multi agent simulations, the result preparation and presentation is of high importance to make efficient use of the generated data. In addition to conventional visual analytics dashboards, many use-cases could also benefit from 3D visualization approaches – especially when dealing with spatial-related simulation scenarios. This paper presents a result output and visualization concept for the MARS (Multi-Agent Research and Simulation) simulation platform. The entire process from output selection and generation up to aggregation and 3D presentation is outlined. In order to facilitate a uniform user experience, the visualization is integrated into the existing MARS web suite and runs directly in the web browser. Because of MARS’ suitability for large-scale scenarios with high agent counts and terrains with vast extents, many big data challenges have to be faced in this context. As a proof-of-concept, details from the implementation are showcased at the end of this paper.	algorithm;big data;feedback;graphical user interface;interpolation;mathematical optimization;refinement (computing);requirement;simulation;unity;usability;user experience;visual analytics;visualization (graphics)	Jan Dalski;Christian Hüning;Thomas Clemen	2017			computer science;visualization;visual analytics;user experience design;terrain rendering;big data;dashboard (business);simulation;mars exploration program;level of detail	Visualization	-30.69968287350752	-30.882850490048547	50255
9144ca7e192965beac861c75aa1b85f3f100548e	video-based pedestrian intention recognition and path prediction for advanced driver assistance systems		Advanced driver assistance systems (ADAS) play a very important role in manufacturing future vehicles to enhance safety for human drivers, passengers and vulnerable road users like pedestrians and cyclists. These systems try to avoid collisions in dangerous situations involving an inattentive driver and pedestrian by triggering an autonomous emergency braking. Due to the high variability in pedestrian movement behavior, existing systems are designed in a conservative way by decreasing benefit in order to reduce false activation rates in scenarios where pedestrians are suddenly stopping and deescalating the situation. To overcome this problem, a reliable pedestrian intention recognition and path prediction are of great value. This work presents the overall processing chain of a stereo-video based system for pedestrian intention recognition and path prediction in daily traffic scenarios to be integrated into a function for automatic emergency braking. As one of three major parts, first, a real-time method is proposed that tries to localize pedestrian heads and to estimate their poses in low resolution gray value images including complex highly dynamic inner-city scenarios. Single frame based estimates are derived using confidence outputs of eight trained head pose classifiers applied at the image region of a pedestrian candidate. Further robustness in head localization is achieved by incorporating stereo depth information. Furthermore, head positions and head poses are tracked over time by implementing a particle filter. For the task of intention recognition, the use of a robust and highly performing machine learning approach is investigated in different scenarios. This approach is able to model the intrinsic sub-structure of a specific intention class while additionally capturing extrinsic dynamics between different intention classes in time-series. Powerful features are integrated namely pedestrian dynamics by means of estimated lateral and longitudinal velocity components resulting from a pedestrian detection and tracking system as well as the pedestrian’s awareness of an oncoming vehicle indicated by the human head pose. Finally, a method for path prediction is developed that controls the prediction steps of a multiple motion-model filter for a time horizon of approximately one second by incorporating the estimated pedestrian intentions. By helping the filter to choose the appropriate motion model, the resulting path prediction error can be reduced by a significant amount. A wide range of scenarios is addressed including lateral crossing or stopping pedestrians or pedestrians that initially are walking along the sidewalks but then suddenly bend in towards the road.		Andreas Schulz	2017			computer vision;simulation;advanced driver assistance systems;multimedia	AI	-19.67988134191015	-27.388494328243137	50353
fb577e13480df04228aa4d6ed1c2278ceb050913	tpass: dynamic, discrete-event simulation and animation of a toll plaza	new jersey;user interface;waiting time;software package;technical report;air quality;discrete event simulation	This paper describes the development of a software package that simulates and animates the operation of a toll plaza. The Toll Plaza Animation/Simulation System (TPASS) gives transportation authorities the ability to experiment with various toll plaza configurations and traffic characteristics in order to determine the resulting queuing, wait times, and toll revenue. TPASS was designed to consider all of the important operating parameters of a toll plaza. All of these parameters can be varied by the user via a complete, menu-driven user interface. The combination of simulation and animation in TPASS provides transportation engineers and planners with a well-rounded engineering tool. The simulation portion allows them to make quantitative comparisons of experimental data sets while the animations present information that is visual and allows them to evaluate the “reasonableness” of the simulations. TPASS is being used by transportation authorities in the New York and New Jersey region. One recent application involved studying the Verrazano Narrows Bridge Toll Plaza in order to determine the plaza’s impact on the air quality. Andrew J. Junga Applied Systems Modeling, Ltd. P.O. BOX 1239 Anderson, Indiana 46015 U.S.A. best technological options can be challenging since the state-of-the-art is changing almost daily. Recent passage of the Inter-modal Surface Transportation Efficiency Act of 1991 (H.R. 2950) has opened up opportunities for transportation authorities to study and implement new technologies, including Intelligent Vehicle Highway Systems (IVHS), and specifically, Automatic Vehicle Identification (AVI). Science Applications International Corporation (SAIC) has been developing systems devoted to increasing the efficiency of roadways since 1985. These systems include toll collection systems that use AVI. In parallel to this effort, SAIC has been developing a dynamic, computer-driven simulation of the operation of a toll plaza. This software tool, the Toll Plaza Animation/Simulation System (TPASS), is used by SAIC and its customers to increase the efficiency of current operations and to assess the benefits of new transportation technologies. An earlier description of the TPASS model was reported at the 1990 Winter Simulation Conference (Junga, 1990). The current paper summarizes that work and presents an up-to-date description of the ongoing development and application of the software package. 2 MODEL DESIGN CONSIDERATIONS	automatic number plate recognition;complete (complexity);emergence;modal logic;modeling language;programming tool;simulation;software development;systems modeling;user interface	Robert T. Redding;Andrew J. Junga	1992		10.1145/167293.167917	air quality index;simulation;human–computer interaction;computer science;engineering;technical report;discrete event simulation;user interface;world wide web;computer graphics (images)	Robotics	-21.63861725682439	-24.02359521239261	50542
17a34ce5690477980f7c892b6db2401bb44df686	improving driver's behavior using context-aware systems		Abstract   This paper discuses a Context-Aware System, which links drivers to the physical environment to assist and improve their driving behavior and decisions in critical situations. Driving tasks are complex enough and need immediate and appropriate decisions. Using sensors to propose an alert system, which is made up of a collection of functions such as Blind Spot Warning and Traffic Sign recognition, is necessary to give drivers a sense of the physical environment.	context-aware pervasive systems	Wael Alghamdi	2012		10.1016/j.procs.2012.06.176	simulation;computer security	HCI	-21.33450909215087	-26.92358072520675	50564
f635e96bc59e5b513c398393db2ebea04cb9db59	fuzzy effectiveness evaluation for intelligent user interfaces to gis visualization	intelligent interfaces;intelligent user interface;fuzzy set;geographic information system;data interpretation;user interface;spatial relation;visualization technique	Current Geographic Information Systems (GIS) offer powerful cartographic and visualization techniques, but they do not contain the knowledge necessary to use them effectively. This gap can be closed by GIS user interfaces which help users create effective visualizations of their data. This paper introduces an effectiveness evaluation scheme supporting such intelligent interfaces. Visualization effectiveness is represented using fuzzy sets because they can express the ambiguity, fuzziness and uncertainty inherent in visualization rules. The evaluation scheme estimates the effectiveness of complex visualizations with regard to the data interpretation aims of the user. The evaluation scheme has been implemented as part of VIZARD, a system for guiding users in GIS visualization. VIZARD employs fuzzy effectiveness evaluation to support and guide users in creating 2-D visualizations of spatially-related data.	cartography;fuzzy set;geographic information system;intelligent user interface	Volker Jung	1996		10.1145/258319.258360	spatial relation;user interface design;human–computer interaction;computer science;data mining;database;geographic information system;fuzzy set;data analysis;user interface;remote sensing	HCI	-30.698340962253233	-32.77115534294997	50614
21f40e64a6d85919310bffc2f8b67236d4f50701	friendship prediction based on the fusion of topology and geographical features in lbsn	social network services;analytical models;topology;support vector machines;data mining;network topology;topology network topology predictive models social network services support vector machines analytical models data mining;predictive models;online offline interaction lbsns friendship prediction social topology geographical features	Friendship prediction in social networks is useful for various applications, such as friend/place recommendation and privacy management. In this paper, we propose a friendship prediction approach by fusing the topology and geographical features in location based social networks (LBSNs). We investigate the features of users' relationship both online and offline and quantify the contributions of selected features through information gain metric. Three key features are selected, namely user social topology, location category, and check-in location. Friendship is predicted based on the fusion of the selected online/offline features. Three inference models are selected to infer the friendship, including Random Forests, Support Vector Machine (SVM), and Naive Bayes. The proposed approach is validated by intensive empirical evaluations using the collected Foursquare and Jiepang datasets.	activity recognition;algorithm;friend of a friend;incremental backup;information gain in decision trees;interaction;kullback–leibler divergence;location-based service;naive bayes classifier;network processor;network topology;online and offline;random forest;scalability;social network;support vector machine	Hui Luo;Bin Guo;Zhiwen Yu;Zhu Wang;Yun Feng	2013	2013 IEEE 10th International Conference on High Performance Computing and Communications & 2013 IEEE International Conference on Embedded and Ubiquitous Computing	10.1109/HPCC.and.EUC.2013.319	support vector machine;computer science;data science;machine learning;data mining;predictive modelling;network topology	Robotics	-21.560723061560367	-44.72316548921608	50753
5b77a7b7ee5032c6e47c85e498c17f82e493a896	adaptations of the k-means algorithm to community detection in parallel environments	complex networks;generators;electronic mail;measurement;image edge detection;clustering algorithms;benchmark testing	In this paper we present preliminary results for a fast parallel adaptation of the well-known k-means clustering algorithm to graphs. We are going to use our method to detect communities in complex networks. For testing purposes we will use the graph generator of Lancichinetti et al., and we are going to compare our method with the OSLOM, CPM, and hub percolation overlapping community detection methods.	algorithm;cluster analysis;complex network;experiment;k-means clustering;parameter (computer programming);percolation;randomness;simulated annealing;usb hub;whole earth 'lectronic link	András Bóta;Miklós Krész;Bogdan Zavalnij	2015	2015 17th International Symposium on Symbolic and Numeric Algorithms for Scientific Computing (SYNASC)	10.1109/SYNASC.2015.54	benchmark;computer science;theoretical computer science;machine learning;distributed computing;cluster analysis;complex network;measurement	Logic	-14.329036993967811	-42.90341646369266	50766
ed5f120285a0e71a5c68cda4cffbf36068b7a335	music with unconventional computing: towards a step sequencer from plasmodium of physarum polycephalum		The field of computer music has evolved in tandem with advances made in computer science. We are interested in how the developing field of unconventional computation may provide new pathways for music and related technologies. In this paper, we outline our initial work into harnessing the behaviour of the biological computing substrate Physarum polycephalum for a musical step sequencer. The plasmodium of Physarum polycephalum is an amorphous unicellular organism, which moves like a giant amoeba as it navigates its environment for food. Our research manipulates the organism’s route-efficient propagation characteristics in order to create a growth environment for musical/sound arrangement. We experiment with this device in two different scenarios: sample triggering and MIDI note triggering using sonification techniques.	accessibility;amoeba;computation;computer programming;computer science;experiment;midi;microsequencer;programming paradigm;software propagation;sonification;unconventional computing;wetware (brain)	Edward Braund;Eduardo Reck Miranda	2015		10.1007/978-3-319-16498-4_2	biology;botany;communication	AI	-5.949271429506295	-48.53491548202404	50854
7f3851e45c366992af9362427c28241efade8eb1	graph size estimation		Many online networks are not fully known and are often studied via sampling. Random Walk (RW) based techniques are the current state-of-the-art for estimating nodal attr ibu es and local graph properties, but estimating global properti es remains a challenge. In this paper, we are interested in a fun damental property of this type — the graph size N , i.e., the number of its nodes. Existing methods for estimating N are (i) inefficient and (ii) cannot be easily used with RW sampling due to dependence between successive samples. In this paper, we address both problems. First, we proposeIE (Induced Edges), an efficient technique for estimatingN from an independence sample of graph’s nodes.IE exploits the edges induced on the sampled nodes. Second, we introduce SafetyMargin, a method that corrects estimators for dependence in RW samples. Finally, we combine these two stand-alone techniques to obtain a RW-based graph size estimator. We evaluate our approach in simulations on a wide range of real-life topologie s, and on several samples of Facebook. IE with SafetyMargin typically requires at least 10 times fewer samples than the state-of-the-art techniques (over 100 times in the case of Facebook) for the same estimation error.	graph property;read-write memory;real life;sampling (signal processing);simulation	Maciej Kurant;Carter T. Butts;Athina Markopoulou	2012	CoRR		mathematical optimization;combinatorics;mathematics;random geometric graph;statistics	Metrics	-10.88327084656966	-43.222844499929586	50875
d7e7a0d5999a059f277188b41f5f41133cb66556	a spatio-temporal framework for related topic search in micro-blogging	temporal information	With the rapid development of Web 2.0, micro-blogging such as twitter is increasingly becoming an important source of up-to-date topics about what is happening in the world. By analyzing topic trends sequences and identifying relations among topics we have opportunities to gain insights into topic associations and thereby provide better services for micro-bloggers. This paper proposes a novel framework that mines the associations among topic trends in twitter by considering both temporal and location information. The framework consists of the extraction of topics’ spatio-temporal information and the calculation of the similarity among topics. The experimental results show that our method can find the related topics effectively and accurately.		Shuangyong Song;Qiudan Li;Nan Zheng	2010		10.1007/978-3-642-15470-6_8	computer science;data science;data mining;world wide web;information retrieval	Web+IR	-23.963685452288715	-51.0518544394606	50917
888d3feb64d44d57d1bfcfe87bc30ac84b4f877c	volume catcher	volume graphics;user interface;segmentation	It is difficult to obtain a specific region within unsegmented volume data (region of interest, ROI). The user must first segment the volume, a task which itself involves significant user intervention, and then chooses a desired target within the 3D space. This paper proposes a simple and intuitive user interface for the task: the user traces the contour of the target region using a 2D free form stroke on the screen, and the system instantly returns a plausible 3D region inside the stroke by applying a segmentation algorithm. The main contribution is that the system infers the depth information of the ROI automatically by analyzing the data, whereas existing systems require the user to provide the depth information explicitly. Our system first computes the 3D location of the user-specified 2D stroke based on the assumption that the user traced the silhouette of the ROI, that is, the curve where the gradient is perpendicular to the viewing direction. The system then places constraint points around the 3D stroke to guide the following segmentation. Foreground constraints are placed inside the stroke and background constraints are placed outside the stroke. We currently use the statistical region-merging algorithm of Nock et al. [Nock and Nielsen 2004a] to perform the segmentation. We tested our system with real-world examples to verify the effectiveness of our approach.	algorithm;gradient;region of interest;statistical region merging;tracing (software);user interface;viewing cone	Shigeru Owada;Frank Nielsen;Takeo Igarashi	2005		10.1145/1053427.1053445	computer vision;simulation;computer science;artificial intelligence;user interface;segmentation;computer graphics (images)	Graphics	-32.47359886155358	-36.001693619793365	50923
42b8e30e0127a2b96a9f3ab374a2945019ae2046	community classification on decentralized social networks based on 2-hop neighbourhood information	social networking online;pattern classification;social networking online pattern classification;single feature classifier community classification decentralized social networks 2 hop neighbourhood information dsn research and development centralized services data limitation decentralized architectures centralized algorithms social networking functions community detection limited local topology information constraint common neighbours adamic adar score personalized pagerank cn measure aa measure ppr measure large scale social networking service sns area under the roc curve;communities observers social network services topology network topology accuracy servers	Decentralized Social Network (DSN) has attracted a lot of research and development interest in recent years. It is believed to be the solution to many problems of centralized services. Due to the data limitation imposed by common decentralized architectures, centralized algorithms that support social networking functions need to be re-designed. In this work, we tackle the problem of community detection for a given user under the constraint of limited local topology information. This naturally yields a classification formulation for community detection. As an initial study, we focus on a specific type of classifiers - classification by thresholding against a proximity measure between nodes. We investigated four proximity measures: Common Neighbours (CN), Adamic/Adar score (AA), Page Rank (PR), Personalized PageRank (PPR). Using data collected from a large-scale Social Networking Service (SNS) in practice, we show that PPR can outperform the others with a few pre-known labels (37.5% to 64.97% relative improvement in terms of Area Under the ROC Curve). We further carry out extensive numerical evaluation of PPR, showing that more pre-known labels can linearly increase the capability of the single-feature classifier based on PPR. Users can thus seek for a trade-off between labeling cost and classification accuracy.	algorithm;centralized computing;numerical analysis;pagerank;portland pattern repository;receiver operating characteristic;social network;thresholding (image processing)	Pili Hu;Wing Cheong Lau	2013	2013 21st IEEE International Conference on Network Protocols (ICNP)	10.1109/ICNP.2013.6733622	computer science;machine learning;data mining;world wide web;computer network	ML	-14.22753246812198	-43.311352131107924	50960
27edf6f58c584615dd39aae44d6c82cf62fcbd91	a dialogue approach to learning object descriptions and semantic categories	humanoid robot;learning;humanoid robots;natural environment;knowledge acquisition;interactive learning;dialogue management;visual perception;dialogue manager;object model;approaches to learning	Acquiring new knowledge through interactive learning mechanisms is a key ability for humanoid robots in a natural environment. Such learning mechanisms need to be performed autonomously, and through interaction with the environment or with other agents/humans. In this paper, we describe a dialogue approach and a dynamic object model for learning semantic categories, object descriptions, and new words acquisition for object learning and integration with visual perception for grounding objects in the real world. The presented system has been implemented and evaluated on the humanoid robot Armar III. Published by Elsevier B.V.	algorithm;categorization;dialog system;experiment;finite-state machine;humanoid robot;information needs;knowledge acquisition;knowledge base;object type (object-oriented programming);principle of abstraction;protologism;speech recognition;user identifier	Hartwig Holzapfel;Daniel Neubig;Alexander H. Waibel	2008	Robotics and Autonomous Systems	10.1016/j.robot.2008.08.012	natural language processing;robot learning;computer vision;error-driven learning;computer science;humanoid robot;artificial intelligence	Robotics	-33.292978983767405	-40.71423975412894	50991
3bd5eed3b806adca58776b31631a7f17937168ce	a multi-scale approach to exploring urban places in geotagged photographs	flickr;volunteered geographic information vgi;geotagged photographs gtp;user generated content ugc;multi resolution;local log odds ratio	User-generated content (UGC) that contains spatial references, often referred to by the more bounded concept of Volunteered Geographic Information (VGI), is often touted as a potentially revolutionary data source for geographical research. This paper explores the capacity of one increasingly prevalent source of these data, geographically encoded photographs, to capture spatial expressions of place in an urban environment. Geotagged photographs were obtained from the Flickr API to build a geographic database of photographs for the city of Vancouver, Canada from 2001-2012. These data were aggregated to multiple geographic units represented as hexagonal lattices. Spatial patterns of photo aggregation were examined for tessellations that ranged from 0.25 ha to 1024 ha. Tags associated with each photo were also explored through the notion of ‘tag-space’ at multiple resolutions, or “scales”, of analysis through local log-odds ratios. Results indicate a significant interaction between tag-space semantics and spatial aggregation which suggests that consideration of scale effects should be integral to analysis of this type of tagged VGI for exploring citizens’ sensing of urban environments. The results indicate further that we may have to reconsider the interaction between encoded meaning, the methods used for extracting such meaning from tag-space, and exogenous and endogenous spatial scales of spatial UGC.	geotagging	Rob Feick;Colin Robertson	2015	Computers, Environment and Urban Systems	10.1016/j.compenvurbsys.2013.11.006	geography;data mining;volunteered geographic information;database;internet privacy;world wide web;cartography;remote sensing	HCI	-20.627648655106547	-34.04155357554621	51049
26064c9ae928b06958f64cb23c5deefab2ade942	research on the relationship between mishap risk and time margin for control: a case study for carrier landing of aircraft	pedestrian safety;poison control;injury prevention;safety literature;time margin;traffic safety;injury control;aircraft carrier landing;home safety;injury research;safety abstracts;human factors;mishap;occupational safety;safety;risk assessment;safety research;accident prevention;violence prevention;bicycle safety;poisoning prevention;falls;ergonomics;suicide prevention;system safety	The engineering intuitive judgments indicate that the risk levels of many mishaps, including the carrier-landing mishap, are directly related to the time available to correct the abnormal system state. The meaning of “time margin” and its relationship with the mishap risks is described in this paper. A conceptual model of risk is built, including three variables: mishap probability, mishap severity, and time margin. In a case study of the carrier-landing process, the relationship between mishap risk and carrier-landing time margin for control was investigated using data from 1,978 samples. Statistical analysis shows that in most cases (80 % approximately), both mishap probability and mishap severity of carrier landing are negatively correlated with the time margin. Based on these findings, the minimum time margin pilots have to correct possible deviations are quantified in order to minimize the risk during carrier-landing processes.		Jin Tian;Ying Dai	2013	Cognition, Technology & Work	10.1007/s10111-013-0262-y	risk assessment;simulation;medicine;engineering;suicide prevention;human factors and ergonomics;injury prevention;forensic engineering;system safety;computer security	AI	-18.96672497580988	-26.771921415169366	51053
fe1b176fdd43c607c294f4218a4885ff1bde7839	applying feature selection combination-based rough set classifiers to forecast credit rating status	financial management;rough set theory;credit ratings;predictive models data mining accuracy support vector machines banking investments data models;bankscope database feature selection combination based rough set classifier application forecast credit rating status financial scandals financial market stability financial status asian banks operational competence random forest rf rough set exploration system rses key attributes extraction data dimensions lem2 algorithm;random forest credit ratings feature selection rough set theory;random forest;feature selection;rough set theory financial management	When banks experience financial scandals or insolvency, panic typically ensues and, in the worst case, leads to systemic banking crises, they are clearly vital to financial market stability, particularly large bank. Therefore, developing an indicator that represents the financial status and operational competence of Asian banks is urgently needed for parties interested in investing in Asia. This study proposes a stepped model that first organizes random forest (RF) and reducts and core of rough set exploration system (RSES) to construct various combinations of extracted key attributes for reducing data dimensions. Accordingly, the rough set LEM2 algorithm is employed as evaluation method to test the various combinations. for verification, a practical dataset comprising 1,327 samples is collected from the BANKSCOPE database, comprising Asian banks covered the period 1993¡V2007. the experimental results indicate that the proposed model outperforms the listing models in terms of accuracy and its standard deviation.	algorithm;best, worst and average case;feature selection;radio frequency;random forest;rough set;statistical classification	You-Shyang Chen;Ching-Hsue Cheng;Da-Ren Chen;Wei-Yu Chen	2012	2012 Sixth International Conference on Genetic and Evolutionary Computing	10.1109/ICGEC.2012.67	random forest;credit rating;rough set;actuarial science;computer science;machine learning;data mining;feature selection;dominance-based rough set approach	Robotics	-8.098194731699326	-30.085570353463048	51081
8f4aa600262b8027f9ebbd997ea73db989ea5940	flexiq: a flexible interactive querying framework by exploiting the skyline operator	decision tree;0807 library and information studies;query refinement;swinburne;user feedback;datasets;refinement;skyline operator;output semantics;dt;centre for applied informatics;algorithms;0806 information systems;queries	Skyline operator has gained much attention in the last decade and is proved to be valuable for multi-criteria decision making. This paper presents a novel Flexible Interactive Querying (FlexIQ) framework for user feedback-based Select-Project-Join (SPJ) query refinement in databases. In FlexIQ, the user feedback is used to discover the query intent. In addition, we have used the skyline operator to confine the search space of the proposed query refinement algorithms. The user feedback consists of both unexpected information currently present in the query output and expected information that is missing from the query output. Once the feedback is given by the user, our framework refines the initial query by exploiting the skyline operator to minimize the unexpected information as well as maximize the expected information in the refined query output. In our framework, the user can also control different quality metric such as quality of results (e.g., false positive rates, false negative rates and accuracy) and complexity (i.e., quantified as the number of subqueries) in the refined query. We have validated our framework both theoretically and experimentally. In particular, we have demonstrated the effectiveness of our proposed framework by comparing its performance with the naı̈ve decision tree based query refinement.	algorithm;database;decision tree model;experiment;quality of results;refinement (computing);sql;skyline operator	Md. Saiful Islam;Chengfei Liu;Rui Zhou	2014	Journal of Systems and Software	10.1016/j.jss.2014.07.011	online aggregation;sargable;query optimization;query expansion;web query classification;boolean conjunctive query;computer science;decision tree;data mining;database;refinement;rdf query language;programming language;web search query;information retrieval;query language	DB	-26.8557294686146	-35.698440598965675	51126
706d39eeed22f430163a61b268f3c78c40376498	discovering business process model from unstructured activity logs	hidden markov models business clustering algorithms noise markov processes probabilistic logic noise measurement;unstructured activity logs;emerging market;hidden markov model;hidden markov models process mining business process discovery;service delivery centers;process mining;noise measurement;business process model;hidden markov models business process re engineering;gaussian mixture model;hidden markov models;gaussian mixture models;business;hidden markov models business process model unstructured activity logs service delivery centers process discovery gaussian mixture models;process discovery;clustering algorithms;markov processes;probabilistic logic;business process re engineering;business process;noise;business process discovery;service delivery	Many real world business processes are executed without explicit orchestration and hence do not generate structured execution logs. This is particularly true for the class of business processes which are executed in service delivery centers in emerging markets where rapid changes in processes and in the people executing the processes are common. In such environments, the process execution logs are usually a mix of human entered activity log of actions performed and the auto-generated logs by various tools used during the process execution. Process discovery from unstructured execution logs has been a relatively unexplored research area. In this paper, we propose an approach for process discovery from unstructured logs using gaussian mixture models and hidden markov models. We apply this approach to the logs generated by a real-world business process used in a service delivery center and demonstrate that the results obtained are comparable to an approach of manually labeling the logs followed by a best known process discovery algorithm in literature. The approach proposed is generic and applicable to a wide range of business process execution settings.	activity recognition;algorithm;business process;concurrency (computer science);experiment;hidden markov model;itil;markov chain;mixture model;orchestration (computing);statistical model	Rahul Kumar;Chiranjib Bhattacharyya;Virendra Varshneya	2010	2010 IEEE International Conference on Services Computing	10.1109/SCC.2010.78	computer science;artifact-centric business process model;data science;machine learning;data mining;process mining;business process discovery;business process modeling	Visualization	-12.243580249292982	-33.807207126267336	51181
4e69c87e2b933a1ee451dd01b4d590cdfd8d8229	on-demand generalization of guide maps with road networks and category-based web search results		The production of strokes according to the perceptual grouping of arcs in a road network provides a good basis for the generalization of road networks, but a large amount of time is required for their creation and selection, and they lack associations with the map objects along them. In this study, we propose a system for generalizing a guide map with road networks and category-based web search results on demand in response to a user request, or a triplet of an area, a size, and a category. The main features of the proposed system are as follows. (1) It constructs a database of strokes and refines the strokes by considering the actual movements of people. It also introduces a data structure called a “fat-stroke,” which combines web search results with the strokes. Pre-construction of the fat-stroke database facilitates the generalization of a guide map on demand to satisfy a user request. (2) It ranks the strokes in order of significance in a guide map according to the web search results combined with the strokes, as well as their length. (3) It determines the number of strokes that need to be drawn on a map based on the map scale and the proportion of road area relative to the whole area in the map. We developed a prototype of the proposed system and a preliminary evaluation demonstrated that pre-construction of the fat-stroke database reduced the response time for guide map generalization to less than 1 s, and thus it can be applied to web map services.	web search engine	Masaki Murase;Daisuke Yamamoto;Naohisa Takahashi	2015		10.1007/978-3-319-18251-3_4	computer science;artificial intelligence;machine learning;data mining	ML	-31.161834090533652	-35.54181188121746	51246
5cd576580eeedcd6af4761d1eee1ed65795035f8	autonomous vehicle guidance on braunschweig's inner ring road within the stadtpilot project	vehicles roads trajectory driver circuits optimization acceleration testing;stadtpilot project;autonomous driving;road traffic;mobile robots;testing;traffic flow;acceleration;vehicle guidance system;trajectory;darpa urban challenge event;roads;autonomous driving autonomous vehicle guidance braunschweig inner ring road darpa urban challenge event traffic flow traffic rules leonie vehicle real urban traffic stadtpilot project vehicle guidance system;leonie vehicle;driver circuits;traffic engineering computing;optimization;traffic rules;vehicles;traffic engineering computing mobile robots road traffic road vehicles;real urban traffic;autonomous vehicle guidance;braunschweig inner ring road;road vehicles	With the “Stadtpilot”-Project the Technische Universit ät Braunschweig transfers the knowledge gained from its participation in the DARPA Urban Challenge Event to the real urban environment of Braunschweig's inner ring road. The goal is to drive fully autonomously in the traffic flow and to behave according to traffic rules. On October 8th, 2010, the first “Stadtpilot”-vehicle called “Leonie” has shown its abilities to the public while driving fully autonomously on a selected part in the northeast of the ring road. This paper introduces the vehicle guidance system of “Leonie” that has proven its functionality on several hundred kilometers in real urban traffic by the end of 2010. The overall system functionality is shown as well as several driving situations that can be handled fully autonomously. In addition, the limitations of the current system are also discussed.	autonomous car;darpa grand challenge (2007);guidance system;stadtpilot;vii	Falko Saust;Jörn-Marten Wille;Bernd Lichte;Markus Maurer	2011	2011 IEEE Intelligent Vehicles Symposium (IV)	10.1109/IVS.2011.5940568	simulation;engineering;automotive engineering;transport engineering	Robotics	-21.331009464431766	-25.843049733411885	51253
562b6974880b169b3b1a9a77581e3cc7639a4677	visbiz: a simplified visualization of business operation	future;region 2;data visualization region 6 data analysis region 2 laboratories information analysis credit cards;region 6;data analysis;visualization;data visualization;techniques;information analysis;credit cards;hardware	In this poster, we present a new technique, VisBiz, for interactively visualizing business operations. The basic idea of this technique is to visually mining relationships between important operation parameters (attributes) and to map the parameters into visualizations. VisBiz simplifies the complexity by partitioning the operation into multiple attribute circular graphs. VisBiz allows the analysis of business data as follows:	interactivity	Ming C. Hao;Daniel A. Keim;Umeshwar Dayal	2004	IEEE Visualization 2004	10.1109/VISUAL.2004.109	computer science;data science;data mining;data analysis;world wide web;data visualization;statistics	Visualization	-27.44048609271773	-33.073858957089726	51285
bb67750e5043d7102048a6d7c23eacc72c309814	revealing of the underlying mechanism of different node centralities based on oscillation dynamics on networks		In recent years, with the rapid development of the Internet and cloud computing, an enormous amount of information is exchanged on various social networking services. In order to handle and maintain such a mountain of information properly by limited resources in the network, it is very important to comprehend the dynamics for propagation of information or activity on the social network. One of many indices used by social network analysis which investigates the network structure is “node centrality”. A common characteristic of conventional node centralities is that it depends on the topological structure of network and the value of node centrality does not change unless the topology changes. The network dynamics is generated by interaction between users whose strength is asymmetric in general. Network structure reflecting the asymmetric interaction between users is modeled by a directed graph, and it is described by an asymmetric matrix in matrix-based network model. In this paper, we showed an oscillation model for describing dynamics on networks generated from a certain kind of asymmetric interaction between nodes by using a symmetric matrix. Moreover, we propose a new extended index of well-known two node centralities based on the oscillation model. In addition, we show that the proposed index can describe various aspect of node centrality that considers not only the topological structure of the network, but also asymmetry of links, the distribution of source node of activity, and temporal evolution of activity propagation by properly assigning the weight of each link. The proposed model is regarded as the fundamental framework for different node centralities. key words: oscillation dynamics, node centrality, social network analysis	activity tracker;centrality;cloud computing;directed graph;information;internet;network model;social network analysis;software propagation	Chisa Takano;Masaki Aida	2018	IEICE Transactions		oscillation;computer science;distributed computing	Metrics	-16.12565736261229	-41.10445949423775	51317
34d30fbb9b3b787e2c7dcd5278fd1d253202bc75	characterizing user interest using heterogeneous media	topic modeling;user interest;social media	It is often hard to accurately estimate interests of social media users because their messages do not have additional information, such as a category. In this paper, we propose an approach that estimates user interest from social media to provide personalized services. Our approach employs heterogeneous media to map social media onto categories. To describe the categories, we propose a hybrid method that integrates a topic model with TF-ICF for extracting both explicitly presented and implicitly latent features. Our evaluation result shows that it gives the highest performance, compared to other approaches. Thus, we expect that the proposed approach is helpful in advancing personalization of social media services.	personalization;social media;topic model;windows firewall	Jonghyun Han;Hyunju Lee	2014		10.1145/2567948.2577346	social media;computer science;multimedia;internet privacy;topic model;world wide web	AI	-25.19524287684074	-48.69782177822552	51323
511b0dcd90db9c6d8ee417a8728a1d054cf701d4	influence maximization in social networks with genetic algorithms		We live in a world of social networks. Our everyday choices are often influenced by social interactions. Word of mouth, meme diffusion on the Internet, and viral marketing are all examples of how social networks can affect our behaviour. In many practical applications, it is of great interest to determine which nodes have the highest influence over the network, i.e., which set of nodes will, indirectly, reach the largest audience when propagating information. These nodes might be, for instance, the target for early adopters of a product, the most influential endorsers in political elections, or the most important investors in financial operations, just to name a few examples. Here, we tackle the NP-hard problem of influence maximization on social networks by means of a Genetic Algorithm. We show that, by using simple genetic operators, it is possible to find in feasible runtime solutions of high-influence that are comparable, and occasionally better, than the solutions found by a number of known heuristics (one of which was previously proven to have the best possible approximation guarantee, in polynomial time, of the optimal solution). The advantages of Genetic Algorithms show, however, in them not requiring any assumptions about the graph underlying the network, and in them obtaining more diverse sets of feasible solutions than current heuristics.	expectation–maximization algorithm;genetic algorithm;social network	Doina Bucur;Giovanni Iacca	2016		10.1007/978-3-319-31204-0_25	quality control and genetic algorithms	AI	-16.79551226631245	-43.700089398054004	51326
43a256db62cf251e3861174c27c4c522226046c0	financial time series segmentation based on specialized binary tree representation	data analysis;time series;trend analysis;binary tree	Segmentation is one of the fundamental components in time series data mining. One of the uses of the time series segmentation is trend analysis - to segment the time series into primitive trends like uptrend and downtrend. In this paper, a time series segmentation method based on a specialized binary tree representation scheme is proposed; this representation scheme is customized for financial time series to cater for its unique behaviors. The proposed segmentation method is based on the concept of data point importance and the location of the cutting points is already encoded in the representation scheme. Therefore, no additional effect is needed to determine the cutting points. One may find it particularly attractive in applications like stock data analysis. The unique behavior of the proposed segmentation method is demostrated by applying to financial time series.	binary tree;time series	Tak-Chung Fu;Korris Fu-Lai Chung;Chak-man Ng	2006			order statistic tree;binary tree;trend analysis;machine learning;time-series segmentation;artificial intelligence;pattern recognition;computer science	Vision	-25.59505040186204	-32.801442405003854	51453
00e95bbcd255a6da9288e7895225fd7055634a31	assessing solar lantern usage in uganda through qualitative and sensor-based methods	solar lights;remote sensors;reporting bias	Solar lanterns have been shown to be a promising technology for providing reliable lighting access in off-grid communities or areas with intermediate power, and these technologies have shown significant market uptake in communities in Uganda. In this study, we examine the usage patterns and behaviors of existing d.light S20 and Firefly Mobile solar lantern customers in peri-urban and rural Uganda using interviews and sensor-based data collection. At the start of the study, semi-structured interviews were administered to solar lantern users to establish baseline demographic information and understand the user preference model, and users were provided an instrumented solar lantern in exchange for their current solar lantern. After a 10-day usage period, a follow-up survey was administered to assess the usage of the lantern and the instrumented product was recollected. These user responses, when compared to the data collected from the instrumentation, were shown to over-report product usage with an average error of 141%.	baseline (configuration management);firefly;semiconductor industry	Amit Gandhi;Victor Lesniewski;Daniel Frey	2016	2016 IEEE Global Humanitarian Technology Conference (GHTC)	10.1109/GHTC.2016.7857329	simulation;engineering;advertising;cartography	HCI	-20.200602729758387	-32.93727706474945	51487
8e6d8010b163b1913efa41bd464bdfd3176e738b	semantic explanations of predictions.		The main objective of explanations is to transmit knowledge to humans. This work proposes to construct informative explanations for predictions made from machine learning models. Motivated by the observations from social sciences, our approach selects data points from the training sample that exhibit special characteristics crucial for explanation, for instance, ones contrastive to the classification prediction and ones representative of the models. Subsequently, semantic concepts are derived from the selected data points through the use of domain ontologies. These concepts are filtered and ranked to produce informative explanations that improves human understanding. The main features of our approach are that (1) knowledge about explanations is captured in the form of ontological concepts, (2) explanations include contrastive evidences in addition to normal evidences, and (3) explanations are user relevant.	computation;data point;information;machine learning;multi-label classification;ontology (information science);random forest;relevance;test data;test point;user profile	Freddy Lécué;Jiewen Wu	2018	CoRR		data mining;computer science;ontology;data point;ontology (information science);ranking	AI	-17.08165593757102	-50.73124639369716	51529
c1a2a640da8a0a4b026e00611ed8341c161f49fb	a personal privacy preserving framework: i let you know who can see what		The booming of social networks has given rise to a large volume of user-generated contents (UGCs), most of which are free and publicly available. A lot of usersu0027 personal aspects can be extracted from these UGCs to facilitate personalized applications as validated by many previous studies. Despite their value, UGCs can place users at high privacy risks, which thus far remains largely untapped. Privacy is defined as the individualu0027s ability to control what information is disclosed, to whom, when and under what circumstances. As people and information both play significant roles, privacy has been elaborated as a boundary regulation process, where individuals regulate interaction with others by altering the openness degree of themselves to others. In this paper, we aim to reduce usersu0027 privacy risks on social networks by answering the question of Who Can See What. Towards this goal, we present a novel scheme, comprising of descriptive, predictive and prescriptive components. In particular, we first collect a set of posts and extract a group of privacy-oriented features to describe the posts. We then propose a novel taxonomy-guided multi-task learning model to predict which personal aspects are uncovered by the posts. Lastly, we construct standard guidelines by the user study with 400 users to regularize usersu0027 actions for preventing their privacy leakage. Extensive experiments on a real-world dataset well verified our scheme.	artificial neural network;benchmark (computing);categorization;computer multitasking;experiment;internet privacy;location awareness;multi-task learning;nonlinear system;openness;personalization;social network;spectral leakage;taxonomy (general);usability testing;user-generated content	Xuemeng Song;Xiuli Wang;Liqiang Nie;Xiangnan He;Zhumin Chen;Wei Liu	2018		10.1145/3209978.3209995	data mining;computer science;social network;social media;openness to experience	Web+IR	-25.11995002415511	-44.23106141803575	51530
0c0b7d90da07226bf0720ab5c920ed995d29b090	a random walk approach to modeling the dynamics of the blogosphere	blogosphere;temporal dynamics;generic model;random walks;scale free;random walk;temporal properties;network science	It is important to develop intuitive and tractable generative models to simulate the topological and temporal dynamics of the blogosphere because these models provide insights about its structural evolution. In such generative models, independent instances of individual bloggers are initiated and these instances interact with each other to simulate the evolution of the blogosphere. Existing generative models of the blogosphere have certain limitations: (1) they do not simultaneously consider the topological and temporal properties, or (2) they utilize the global information about the blogosphere that is typically not available. In this paper, we propose a novel generative model for the blogosphere based on the random walk process that simultaneously considers both the topological and temporal properties and does not utilize the global information about the blogosphere. The results of our experiments show that the proposed random walk based model successfully captures the scale-free nature of both topological and temporal dynamics of the blogosphere.	blog;blogosphere;cobham's thesis;experiment;extrapolation;generative model;parameter (computer programming);simulation	Muhammad Zubair Shafiq;Alex X. Liu	2011		10.1007/978-3-642-20757-0_23	computer science;data science;machine learning;data mining	AI	-16.203082038733555	-42.048111409939565	51531
02d392a99ebfd36c8c3f6766372457ce78fd53c0	on querying and exploring activities on a user's desktop	query language;management system;data mining organizing computer science object oriented modeling context modeling database languages data visualization user interfaces educational institutions snow;snow;data mining;method integration;object oriented;organizing;data visualization;computer science;context modeling;user interfaces;database languages;object oriented modeling	Many desktop query and management systems offer an object oriented view of a computer, where the emphasis is on describing the information relevant to an object. However, objects may be related to each other in different ways and in different contexts. In this paper, we argue that users create and modify data as a function of activities that they are involved in. We develop methods to explore objects on a desktop through activities. Our methods integrate discovered relationships between data objects based on their participation in different activities as well as other properties. Our activity model is well suited to support a query language that is able to alter the context and the definition of an activity to easily visualize complex relationships in data. We show that this new organization makes many new interesting desktop functionalities a reality.	activity recognition;algorithm;browsing;desktop computer;function model;information system;interaction;prototype;query language;relevance feedback	Sibel Adali;Shawn Pearce;Maria Luisa Sapino	2006		10.1109/ICDEW.2006.103	computer science;data mining;database;world wide web;data visualization;query language	HCI	-30.07130329353676	-32.119449544309454	51640
a53e2a14033c961982263396712390312c075058	methodology for identifying activities from gps data streams		Abstract: When the global positioning system became available for civil uses in the early 1990s, there was an enthusiasm and anticipation that information stored in GPS data streams would replace the traditional data collection methods, especially in the transportation field. Despite the wealth of GPS surveys available to practitioners to work with, the existing studies have not made much progress to deliver models for identification of activities from GPS data streams. The lack of models for identifying activities prevents the reconstruction of activity patterns stored in GPS data streams. The present study proposes a methodology for the identification of activities using a rule-based and discrete choice modeling. This novel approach uses a rule-based model that implements the properties of home-based tours in the form of the feedback loop in order to allow identification of home activities. This model is inert to the presence of travel characteristics as it can be applied to most multi-day GPS data sets, and not just prompted recall surveys. In regard to the non-home activities, a discrete choice model is calibrated to Transportation Tomorrow Survey (TTS), for identification of work and other activities. The estimated results are positive, as they are compared against the TTS, and are consistent with the observed patterns.	global positioning system	Vladimir Usyukov	2017		10.1016/j.procs.2017.05.289	data mining;data collection;data stream mining;global positioning system;computer science;data set;discrete choice;feedback loop	Mobile	-17.235289568412348	-31.06305221179283	51666
17492cc1b9c357fde6c761c0b2b50d0d5378a3bf	crowdfill: a system for collecting structured data from the crowd	data collection;crowdsourcing	CrowdFill is a system for collecting structured data from the crowd. Unlike a typical microtask-based approach, CrowdFill shows an entire partially-filled table to all participating workers; workers collaboratively complete the table by filling in empty cells, as well as upvoting and downvoting data entered by other workers, using CrowdFill's intuitive data entry interface. CrowdFill ensures data entry is leading to a final table that satisfies prespecified constraints, and its compensation scheme encourages workers to submit useful, high-quality work. We demonstrate how CrowdFill collects structured data from the crowd, from the perspective of a user as well as from the perspective of workers.	data model	Hyunjung Park;Jennifer Widom	2014		10.1145/2567948.2577029	computer science;data mining;internet privacy;world wide web;crowdsourcing;data collection	HCI	-28.648351112157762	-45.66679410949105	51714
beceab4352be32e1e751619c218643327c04a9a0	a concept grounding approach for glove-based gesture recognition	clustering ensembles gesture recognition concept grounding data glove;data glove;gesture recognition fingers grounding hidden markov models robot sensing systems machine learning;user manipulation concept grounding approach glove based gesture recognition hand motion finger sensor user interaction;data gloves;gesture recognition data gloves;clustering ensembles;concept grounding;gesture recognition	Glove-based systems are an important option in the field of gesture recognition. They are designed to recognize meaningful expressions of hand motion. In our daily lives, we use our hands for interacting with the environment around us in many tasks. Our glove-based gesture recognition is focused on developing technologies for studying the motion and interaction with a data glove which can augment the capabilities of some users to perform some tasks. This idea is relevant to many research areas, for example: design and manufacturing, information visualization, robotics, sign language understanding, medicine and health Care. In this paper, we proposed a new concept grounding approach for glove-based gesture recognition. We record the data from finger sensors and then abstract and extract concepts from the data. This allow us to construct conceptual levels which we can use to study interaction and manipulation for users during their activities.	association rule learning;cluster analysis;data mining;effective method;gesture recognition;information visualization;interaction;java;machine learning;natural language understanding;pattern recognition;robotics;sensor;springer (tank);text mining;wired glove	Yu Huang;Dorothy Ndedi Monekosso;Hui Wang;Juan Carlos Augusto	2011	2011 Seventh International Conference on Intelligent Environments	10.1109/IE.2011.51	computer vision;engineering;artificial intelligence;gesture recognition;communication	Robotics	-26.79825598983923	-41.36875847278826	51784
9c0a14577bee7f763d17c42b3de86bf23e4da466	searching for important but neglected content from community-type-content	content management;sns;community;computed tomography;circuit faults;current transformers;content neglected content content hole search community;fault currents;content hole search online community type content sns blogs;online community type content;neglected content;online community;search;internet;chromium;content;web sites;web sites content management;content hole;copper;blogs;conferences;content hole search	"""In online community-type content such as SNSs and blogs, users occasionally do not understand the theme of the content from multiple viewpoints, and much of the information is often lost. Because the discussion in a community is concentrated, the viewpoint narrows. We believe that it is necessary to provide information about the lack of awareness of a user to the users of community-type content. Information about which a user is unaware is called as a """"content hole,"""" and searching for such holes is called as """"content hole search."""" In this paper, as a first step toward developing a technique for searching for content holes, we attempt to extract and represent important but neglected content from online community-type content based on isolated and non-related degrees. This content is information that nobody from the community is interested in, but that may be of interest to many people outside the community."""	blog;online community	Akiyo Nadamoto;Eiji Aramaki;Takeshi Abekawa;Yohei Murakami	2008	2008 IEEE International Conference on Signal Image Technology and Internet Based Systems	10.1109/SITIS.2008.54	community;chromium;content management;computer science;multimedia;internet privacy;computed tomography;copper;world wide web	Mobile	-31.552100286354886	-46.08455761853121	51836
93bd5de7516af4ecedb40a2f4f25425857fdd491	inferring topic-dependent influence roles of twitter users	influential users;twitter;multi view	Twitter, as one of the most popular social media platforms, provides a convenient way for people to communicate and interact with each other. It has been well recognized that influence exists during users' interactions. Some pioneer studies on finding influential users have been reported in the literature, but they do not distinguish different influence roles, which are of great value for various marketing purposes. In this paper, we move a step forward trying to further distinguish influence roles of Twitter users in a certain topic. By defining three views of features relating to topic, sentiment and popularity respectively, we propose a Multi-view Influence Role Clustering (MIRC) algorithm to group Twitter users into five categories. Experimental results show the effectiveness of the proposed approach in inferring influence roles.	algorithm;interaction;social media	Chengyao Chen;Dehong Gao;Wenjie Li;Yuexian Hou	2014		10.1145/2600428.2609545	internet privacy;world wide web	Web+IR	-22.383065263766863	-45.545112417178714	51889
0959153b27dfcfeaf157a6ab875a3d2a4c146b63	learning and generalising semantic knowledge from object scenes	robot learning;inductive logic programming;ripple down rules;motion segmentation;feature extraction;concept learning;word learning;speech recognition;human robot communication	The robot described in this paper learns words that relate to objects and their attributes, and also learns concepts, which may be recursive, that involve relationships between several objects. Once the system is explicitly taught some words by a human teacher it finds new objects that might help to refine its concepts. Once it has found a new object, it tries to generalise its concepts to include the new object and asks the teacher for feedback. The robot learns further properties of objects by interacting with them, by touching them or walking around them to gain a new perspective. The system learns semantic knowledge from spoken interactions, using speech recognition and generation, motion segmentation, feature extraction from images using Ripple Down Rules and generalisation using Inductive Logic Programming. © 2008 Elsevier B.V. All rights reserved.	aibo;active learning (machine learning);concept learning;exception handling;experiment;feature extraction;inductive logic programming;interaction;job stream;machine learning;marvin (robot);need to know;nonlinear gameplay;print job;prototype;recursion;restrictive design rules;ripple;robot;software deployment;speech recognition	Claire D'Este;Claude Sammut	2008	Robotics and Autonomous Systems	10.1016/j.robot.2008.08.006	natural language processing;robot learning;computer vision;concept learning;feature extraction;computer science;artificial intelligence;machine learning	AI	-32.94683680779646	-40.76533364980815	51920
eceaf4f5d83db6fac9e29ead90dd5d8f3e893a12	research directions of olap personalizaton		In this paper we have highlighted five existing ap proaches for introducing personalization in OLAP: preference constructors, d ynamic personalization, visual OLAP, recommendations with user session analysis an d recommendations with user profile analysis and have analyzed research papers within these directions. We have provided an evaluation in order to point out i) per sonalization options, described in these approaches, and its applicability to OLAP sch ema elements, aggregate functions, OLAP operations, ii) the type of constra ints (hard, soft or other), used in each approach, iii) the methods for obtaining user pr ferences and collecting user information. The goal of our paper is to systematiz e he ideas proposed already in the field of OLAP personalization to find out further p ossibility for extending or developing new features of OLAP personalization.	aggregate data;aggregate function;online analytical processing;personalization;user profile	Natalija Kozmina;Laila Niedrite	2010		10.1007/978-1-4419-9790-6_28	online analytical processing;computer science;data mining;database;world wide web	DB	-29.5679936902888	-48.55954565590081	51979
6c1c2e606108de8c51f9a1dafbc4ed5084c836be	pavement surface condition estimation based on geospatial modelling	pavement surface condition;geospatial data;geospatial modelling	ABSTRACTAll transportation management agencies face the yearly challenge of inspecting the condition of myriad miles of road surface. With routinely acquired and publicly available geospatial data and geospatial modelling techniques, there is potential to substantially reduce the number of survey sites required to characterize overall pavement surface distress condition. Using roadway pavement assets in the State of New Mexico as an example, this study investigated if overall pavement surface conditions could be estimated based on geospatial modelling. A total of 17 explanatory variables, which were extracted from three types of geospatial data, including traffic volumes, environmental conditions and topography, were used to estimate overall pavement surface distress conditions. Results show that overall pavement surface conditions can be effectively (R2 > 0.9) estimated based on the extent of geospatial data and inferential modelling techniques with fewer survey sites, substantially reducing the cost and...		Su Zhang;Christopher D. Lippitt;Susan M. Bogus	2017	Annals of GIS	10.1080/19475683.2017.1325404	environmental engineering;geography;civil engineering;data mining	EDA	-14.69464391800885	-27.607834342452996	52009
fc03441d77ee583ad9e6d02ea4d932265e5e3360	making the most cost-effective decision in online paid q&a community: an expert recommender system with motivation modeling and knowledge pricing		Recommending proper experts to knowledge buyers is a significant problem in online paid Q&A community (OPQC). Existing approaches for online expert recommendation have been mainly focused on exploiting semantic similarities and social network influence, while personalizing recommendation according to individuals’ motivations has not received much attention. In this paper, we propose a personalized expert recommender system, which integrates buyer’s motivation for knowledge, social influence, and money in a unified framework. As an innovative application of cognitive computing, our recommender system is capable of providing users with the best matching experts so as to help them make the most cost-effective choice in OPQC. To this end, Paragraph Vector technique is implemented to construct domain knowledge base (KB) in a multilayer information retrieval (IR) framework. Then we perform knowledge pricing based on buyer’s query and bid in the context of bilateral monopoly knowledge market. After that, a Markov Chain based method with user motivation learning is introduced to find the best matching experts. Finally, we evaluate the proposed approach using datasets collected from two OPQC. The experimental results show encouraging success as effectively offering reasonable personalization options. As an innovative approach to solve the expert matching problem in OPQC, this research provides flexibility in customizing the recommendation heuristics based on user motivation, and demonstrate its contribution to a higher rate of optimal knowledge seller-buyer matching. CCS CONCEPTS •Information systems → Recommender System;•Computing methodologies →Knowledge representation and reasoning	bilateral filter;cognitive computing;expert system;heuristic (computer science);information retrieval;knowledge base;knowledge market;knowledge representation and reasoning;markov chain;monopoly;personalization;recommender system;social network;unified framework	Yunhao Zheng;Xi Zhang;Yuting Xiao	2018		10.1145/3184558.3186349	personalization;recommender system;data mining;domain knowledge;knowledge market;social network;markov chain;computer science;heuristics;cognitive computing	AI	-19.26369467538621	-49.592516818567084	52054
0a92f3192f064df6c99705ba57dbf797cf9d8870	group recommender systems: combining individual models	multiple criteria;affective state;recommender system;user model	This chapter shows how a system can recommend to a group of use rs by aggregating information from individual user models and mo delling the users affective state. It summarizes results from previous research in t is area. It also shows how group recommendation techniques can be applied when rec ommending to individuals, in particular for solving the cold-start proble m and dealing with multiple criteria.	cold start;recommender system	Judith Masthoff	2011		10.1007/978-0-387-85820-3_21	computer science;knowledge management;data mining;world wide web	ML	-29.923784754064336	-48.44367084320529	52073
f5995b649db4b5469b66af209491806ddd635887	mobility patterns of human population among university campuses	wireless application protocol;feature extraction;probability distribution;statistics;ieee 802 11 standard;sociology	Uncovering human mobility patterns is of vital importance to the widely practical applications ranging from urban planning to epidemic controlling. Although numerous previous studies regarding human mobility patterns have been carried out to statistically characterize the dynamics of human mobility in both empirical analysis and modelling approach, research on the level of driving factors of mobility behaviors is still limited. In this paper, we focus on two types of human mobility behaviors which are Non-Spontaneous Mobility and Spontaneous Mobility, respectively. Based on the Wi-Fi access records collected from a university campus, statistical distinctions have been uncovered between these two types of mobility behaviors, where non-spontaneous mobility behaviors display a less heterogeneous but more periodic pattern with a smaller activity range, suggesting the necessity of embedding these two types of behaviors when modelling human mobility.	spontaneous order	Shu-Min Zhang;Xiang Li	2016	2016 IEEE Asia Pacific Conference on Circuits and Systems (APCCAS)	10.1109/APCCAS.2016.7803893	probability distribution;simulation;wireless application protocol;telecommunications;feature extraction;computer science;mobility model;statistics	HCI	-19.284029324336007	-34.62918138203284	52085
99ac4b8d3c8790a50a468d8268cff00651cb65b6	scalable anomaly ranking of attributed neighborhoods		Given a graph with node attributes, what neighborhoods1 are anomalous? To answer this question, one needs a quality score that utilizes both structure and attributes. Popular existing measures either quantify the structure only and ignore the attributes (e.g., conductance), or only consider the connectedness of the nodes inside the neighborhood and ignore the cross-edges at the boundary (e.g., density). In this work we propose normality, a new quality measure for attributed neighborhoods. Normality utilizes structure and attributes together to quantify both internal consistency and external separability. It exhibits two key advantages over other measures: (1) It allows many boundaryedges as long as they can be “exonerated”; i.e., either (i) are expected under a null model, and/or (ii) the boundary nodes do not exhibit the subset of attributes shared by the neighborhood members. Existing measures, in contrast, penalize boundary edges irrespectively. (2) Normality can be efficiently maximized to automatically infer the shared attribute subspace (and respective weights) that characterize a neighborhood. This efficient optimization allows us to process graphs with millions of attributes. We capitalize on our measure to present a novel approach for Anomaly Mining of Entity Neighborhoods (AMEN). Experiments on real-world attributed graphs illustrate the effectiveness of our measure at anomaly detection, outperforming popular approaches including conductance, density, OddBall, and SODA. In addition to anomaly detection, our qualitative analysis demonstrates the utility of normality as a powerful tool to contrast the correlation between structure and attributes across different graphs.	anomaly detection;conductance (graph);linear separability;mathematical optimization;null model	Bryan Perozzi;Leman Akoglu	2016		10.1137/1.9781611974348.24	combinatorics;discrete mathematics;machine learning;data mining;mathematics;statistics	ML	-13.716230400391364	-41.095412149679696	52104
808cd472e72af4c982f6f8b3146161dca771f652	finding targets with the nearest favor neighbor and farthest disfavor neighbor by a skyline query	query processing;data points;dominance rules;farthest neighbors;spatial database;skyline query;skyline query processing;nearest neighbors;houses;experiments;algorithms;synthetic data	Finding the nearest neighbors and finding the farthest neighbors are fundamental problems in spatial databases. Consider two sets of data points in a two-dimensional data space, which represent a set of favor locations F, such as libraries and schools, and a set of disfavor locations D, such as dumps and gambling houses. Given another set of data points C in this space as houses for rent, one who needs to rent a house may need a recommendation which takes into account the favor and disfavor locations. To solve this problem, a new two-dimensional data space is employed, in which dimension X describes the distance from a data point c in C to its nearest neighbor in D and dimension Y describes the distance from c to its farthest neighbor in F. Notice that the larger value is preferred in dimension X while the smaller value is preferred in dimension Y. Following the above dominance rule, the recommendation for the house renting can be achieved by a skyline query. A naïve method to processing this query is 1) to find the nearest neighbor from D and the farthest neighbor from F for each data point in C and then 2) to construct a new two-dimensional data space based on the results from 1) and to apply any of the existing skyline algorithms to get the answer. In this paper, based on the quad-tree index, we propose an efficient algorithm to answer this query by combining the above two steps. A series of experiments with synthetic data and real data are performed to evaluate this approach and the experiment results demonstrate the efficiency of the approach.	algorithm;data point;dataspaces;experiment;library (computing);naivety;pareto efficiency;quadtree;spatial database;synthetic data	Jason Yao-Tsu Lin;En Tzu Wang;Chieh-Feng Chiang;Arbee L. P. Chen	2014		10.1145/2554850.2554863	data point;computer science;machine learning;data mining;database;nearest neighbor search;fixed-radius near neighbors;spatial database;statistics;synthetic data	DB	-5.296892594984091	-41.9407279048107	52125
84b5415f88dfd17629b45ba6928c29ed89b09ca2	natural language generation and fuzzy sets: an exploratory study on geographical referring expression generation	pragmatics;pragmatics fuzzy sets natural languages uncertainty geography fuzzy logic data models;uncertainty;natural languages;fuzzy sets;fuzzy logic;qa75 electronic computers computer science;conference item;perception related techniques natural language generation fuzzy sets knowledge acquisition nlg word related techniques linguistic data description geographical referring expression generation;natural language processing fuzzy set theory knowledge acquisition linguistics;data models;geography	We explore how the problem of uncertainty and imprecision in natural language generation (NLG) could be addressed through the use of fuzzy sets. We propose bringing together standard empirical procedures for knowledge acquisition in NLG and computing with words/perceptions related techniques (with a special focus on linguistic description of data) to address an open challenge in NLG: the generation of geographical referring expressions. Following this methodology, we present an exploratory experiment which provides some insights about how human subjects refer to geographical expressions and discuss how the obtained results might relate to the use of fuzzy sets.		Alejandro Ramos-Soto;Nava Tintarev;Rodrigo de Oliveira;Ehud Reiter;Kees van Deemter	2016	2016 IEEE International Conference on Fuzzy Systems (FUZZ-IEEE)	10.1109/FUZZ-IEEE.2016.7737740	fuzzy logic;natural language processing;data modeling;uncertainty;computer science;artificial intelligence;neuro-fuzzy;data mining;fuzzy set;natural language;pragmatics	Robotics	-5.246549821306586	-24.113846944588477	52127
1cabd98c5019c8a6632106ba59b038dc03f3b6ac	identifying k primary corridors from urban bicycle gps trajectories on a road network	gps trajectory;road network;lower bound filtering;spatial data mining;network hausdorff distance;bicycle primary corridors;urban data mining	Given a set of GPS tracks on a road network and a number k, the K-Primary-Corridor (KPC) problem aims to identify k tracks as primary corridors such that the overall distance from all tracks to their closest primary corridors is minimized. The KPC problem is important to domains such as transportation services interested in finding primary corridors for public transportation or greener travel (e.g., bicycling) by leveraging emerging GPS trajectory datasets. However, the problem is challenging due to the large amount of shortest path distance computations across tracks. Related trajectory mining approaches, e.g., density or frequency based hot-routes, focus on anomaly detection rather than identifying representative corridors minimizing total distances from other tracks, and thus may not be effective for the KPC problem. Our recent work proposed a k-Primary Corridor algorithm that precomputes a column-wise lookup table of network Hausdorff distances. This paper extends our recent work with a new computational algorithm based on lower bound filtering. We design lower bounds of network Hausdorff distances based on the concept of track envelopes and propose three different track envelope formation strategies based on random selection, overlap, and Jaccard coefficient respectively. Theoretical analysis on proof of correctness as well as computational cost models are provided. Extensive experiments and case studies show that our new algorithm with lower bound filtering significantly reduces the computational time of our previous algorithm, and can help effectively determine primary bicycle corridors.	global positioning system	Zhe Jiang;Michael R. Evans;Dev Oliver;Shashi Shekhar	2016	Inf. Syst.	10.1016/j.is.2015.10.009	simulation	DB	-15.870729804565238	-34.496662664730245	52178
2905d551bbc9d69b7ce6fe7f73ac704b81575c4f	tri-rank: an authority ranking framework in heterogeneous academic networks by mutual reinforce	authority ranking;measurement correlation data mining libraries bibliometrics joining processes bipartite graph;directed graphs academic libraries digital libraries;directed graph tri rank framework authority ranking framework heterogeneous academic networks mutual reinforcement venue information graph based ranking framework author co ranking paper co ranking venue co ranking data collection acm digital library;mutual reinforce authority ranking heterogeneous network;mutual reinforce;heterogeneous network	Recently, authority ranking has received increasing interests in both academia and industry, and it is applicable to many problems such as discovering influential nodes and building recommendation systems. Various graph-based ranking approaches like PageRank have been used to rank authors and papers separately in homogeneous networks. In this paper, we take venue information into consideration and propose a novel graph-based ranking framework, Tri-Rank, to co-rank authors, papers and venues simultaneously in heterogeneous networks. This approach is a flexible framework and it ranks authors, papers and venues iteratively in a mutually reinforcing way to achieve a more synthetic, fair ranking result. We conduct extensive experiments using the data collected from ACM Digital Library. The experimental results show that Tri-Rank is more effective and efficient than the state-of-the-art baselines including PageRank, HITS and Co-Rank in ranking authors. The papers and venues ranked by Tri-Rank also demonstrate that Tri-Rank is rational.	digital library;experiment;pagerank;recommender system;synthetic intelligence;triangular function;venue (sound system)	Zhirun Liu;Heyan Huang;Xiaochi Wei;Xianling Mao	2014	2014 IEEE 26th International Conference on Tools with Artificial Intelligence	10.1109/ICTAI.2014.80	ranking;heterogeneous network;computer science;data mining;world wide web;information retrieval	DB	-17.46637934406147	-46.2534012342362	52265
5fbb96e320351196f097e71e90960f3ea7d6aee8	extracting topic maps from web histories by clustering with web structure and contents	tutoring;hierarchical clustering;motohiro mase;web browsing history;structure based hierarchical clustering method;isis 2007 proceedings of the 8th symposium on advanced intelligent systems;information retrieval;topic maps;multiple user interface;character agent;한국지능시스템학회;history web pages visualization data mining clustering methods organizing tree graphs iso standards iec standards intelligent agent;sokendai;web structure clustering method;online front ends;internet;educational interface;seiji yamada;topic map extraction;clustering method;e learning;katsumi nitta;korean institute of intelligent systems;contents similarity topic map extraction web browsing history web structure clustering method structure based hierarchical clustering method;web browsing;extracting topic maps from web pages by clustering with web structure and contents;contents similarity;online front ends information retrieval internet	In this paper, we propose a clustering method to extract Topic Maps from the Web browsing history. We improve the structure-based hierarchical clustering method using the contents similarity of the pages and the weight by the types of links and the hierarchical difference of the directories in which the pages are located. The topic maps show the topics that user has seen or not in Web browsing and the relationships between the topics. Using the Web browsing history, we experimentally extract the topic map and evaluate it.	cluster analysis;experiment;hierarchical clustering;map;topic maps;world wide web	Motohiro Mase;Seiji Yamada	2006	2006 IEEE/WIC/ACM International Conference on Web Intelligence and Intelligent Agent Technology Workshops	10.1109/WI-IATW.2006.71	topic maps;the internet;web mapping;computer science;artificial intelligence;data science;hierarchical clustering;world wide web;information retrieval	Web+IR	-29.710990860433174	-50.2244448990177	52345
0ffbbfc6cb9a1e9efd68c51b1fa3561e38b3c27b	discovery of information disseminators and receptors on online social media	digg;information roles;social interaction;information disseminators;information dissemination;social network analysis;information diffusion;social media	"""Today, there is significant sharing of information artifacts among users on various social media sites, including Digg, Twitter and Flickr. An interesting consequence of such rich and extensive social interaction is the evolving nature of """"roles"""" that are acquired by users over time, in the context of variegated communication activities, such as commenting, replying, uploading a media artifact and so on. In this paper, we investigate the discovery of two roles that define information dissipation: disseminators and receptors. We propose a computational framework based on factorization of stacked representation of activities and test the outcomes on a dataset from Digg. Experiments show that our approach can, interestingly, reveal correlations with user activities occurring at a future point in time."""	experiment;flickr;non-negative matrix factorization;social media;upload	Munmun De Choudhury	2010		10.1145/1810617.1810674	social relation;social network analysis;social media;computer science;multimedia;internet privacy;world wide web	Web+IR	-20.622038693001283	-43.636990912462075	52369
e2052390a3078b945a4a43f61deca7bb84f65cab	prediction of user demographics from music listening habits		Online activities such as social networking, shopping, and consuming multi-media create digital traces often used to improve user experience and increase revenue, e.g., through better-fitting recommendations and targeted marketing. We investigate to which extent the music listening habits of users of the social music platform Last.fm can be used to predict their age, gender, and nationality. We propose a TF-IDF-like feature modeling approach for artist listening information and artist tags combined with additionally extracted features. We show that we can substantially outperform a baseline majority voting approach and can compete with existing approaches. Further, regarding prediction accuracy vs. available listening data we show that even one single listening event per user is enough to outperform the baseline in all prediction tasks. We conclude that personal information can be derived from music listening information, which indeed can help better tailoring recommendations.	algorithm;baseline (configuration management);categorization;deep learning;digital footprint;experiment;feature model;last.fm;machine learning;microsoft outlook for mac;online music store;personally identifiable information;recommender system;tf–idf;user experience	Thomas Krismayer;Markus Schedl;Peter Knees;Rick Rabiser	2017		10.1145/3095713.3095722	user experience design;active listening;computer science;informational listening;social network;personally identifiable information;demographics;revenue;multimedia	ML	-19.7537977244347	-51.43810830227104	52414
516ec4243395a7106ae6209a49284705d1177b47	supervised rank aggregation approach for link prediction in complex networks	graph theory;complex networks;bibliographic database;supervised rank aggregation;complex network;link prediction;supervised machine learning;rank aggregation;computational social choice	In this paper we propose a new topological approach for link prediction in dynamic complex networks. The proposed approach applies a supervised rank aggregation method. This functions as follows: first we rank the list of unlinked nodes in a network at instant t according to different topological measures (nodes characteristics aggregation, nodes neighborhood based measures, distance based measures, etc). Each measure provides its own rank. Observing the network at instant t+1 where some new links appear, we weight each topological measure according to its performances in predicting these observed new links. These learned weights are then used in a modified version of classical computational social choice algorithms (such as Borda, Kemeny, etc) in order to have a model for predicting new links. We show the effectiveness of this approach through different experimentations applied to co-authorship networks extracted from the DBLP bibliographical database. Results we obtain, are also compared with the outcome of classical supervised machine learning based link prediction approaches applied to the same datasets.	algorithm;bibliographic database;complex network;dbl-browser;machine learning;performance;supervised learning	Manisha Pujari;Rushed Kanawati	2012		10.1145/2187980.2188260	computer science;graph theory;machine learning;pattern recognition;data mining;complex network	AI	-15.162305264759993	-41.911350719236374	52450
6601d6a69c44586c0884a23f71cbc3651f9890b0	analysis and applications of smartphone user mobility	mobile devices;user interfaces;markov processes;predictive models;location based services;mobile computing;wireless communication;measurement;accuracy	Users around the world have embraced new generation of mobile devices such as the smartphones at a remarkable rate. These devices are equipped with powerful communication and computation capabilities and they enable a wide range of exciting location-based services, e.g., location based ads, content prefetching etc. Many of these services can benefit from a better understanding of the smartphone user mobility, which may differ significantly from the general user mobility. Hence, previous works on understanding user mobility models and predicting user mobility may not directly apply to smartphone users. To overcome this, in this paper we analyze data from two popular location based social networks, where the users are real smartphone users and the places they check-in represent the typical locations where they use their smartphone applications. Specifically, we analyze how individual users move across different locations. We identify several factors that affect user mobility and their relative significance. We then leverage these factors to perform individual mobility prediction. We further show that our mobility prediction yields significant benefit to two important location based applications: content prefetching and shared ride recommendation.	cpu cache;computation;ibm notes;individual mobility;location-based service;mobile app;mobile device;smartphone;social network	Swati Rallapalli;Wei Dong;Gene Moo Lee;Yi-Chao Chen;Lili Qiu	2013	2013 IEEE Conference on Computer Communications Workshops (INFOCOM WKSHPS)	10.1109/INFCOMW.2013.6562914	computer science;operating system;location-based service;mobile device;accuracy and precision;predictive modelling;internet privacy;markov process;mobility model;user interface;mobile computing;world wide web;computer security;wireless;measurement;statistics	Mobile	-18.59460342010869	-35.22645775506844	52484
cd4d3f10f36911da70aee3f07244ff034d3465a2	dynamic network motifs: evolutionary patterns of substructures in complex networks	complex network;statistical significance;web service;social dynamic;link analysis;subgraph mining;dynamic networks	"""We propose an entirely new approach to understanding complex networks; called """"dynamic network motifs (DNMs)."""" We define DNMs as statistically significant local evolutionary patterns of a network. We find such DNMs in the networks of two web services, Yahoo Answers and Flickr, and discuss the social dynamics of these services as indicated by their DNMs."""	complex network	Yutaka Kabutoya;Kyosuke Nishida;Ko Fujimura	2011		10.1007/978-3-642-20291-9_33	web service;social dynamics;link analysis;computer science;machine learning;data mining;statistical significance;world wide web;complex network;statistics	ML	-17.445288170350988	-41.175270587591996	52488
2cd10d84a837c2f295716bd6ed3ec8fdf7263b12	complex network community detection based on swarm aggregation	community detection;hierarchical community structure;complex networks;complex network;hierarchical community structure complex network community detection swarm aggregation data mining swarm aggregation collective behavior neighbors angle agreement;community detection swarm aggregation complex networks;data mining;complex network community detection;collective behavior;indexes;large scale;neighbors angle agreement;community structure;complex networks graph theory large scale systems robustness computer networks mathematics computer science data mining ip networks web sites;classification algorithms;mathematical model;book reviews;communities;swarm aggregation collective behavior;algorithm design and analysis;swarm aggregation	Finding communities in complex networks is not a trivial task. It not only can help to understand topological structure of large scale networks, but also is useful for data mining. In this paper, we propose a community detection technique based on the collective behavior of swarm aggregation, where all nodes are arranged on a circumference and each of them is assigned a angle at a random. The angles are gradually updated according to node's neighbors angle agreement. Finally, a stable state is reached and nodes belonging to the same community are aggregated together. By repeating this process, hierarchical community structure of input network can be obtained. The proposed technique is robust and efficient. Moreover, it is able to deal with both weighted and un-weighted networks.	algorithm;ant colony optimization algorithms;british informatics olympiad;complex network;data mining;robustness (computer science);swarm intelligence;weighted network	Tatyana B. S. de Oliveira;Liang Zhao	2008	2008 Fourth International Conference on Natural Computation	10.1109/ICNC.2008.324	computer science;data science;machine learning;data mining;community structure	Robotics	-14.955218110446308	-42.6380376860271	52566
96e15ffbb138108894ef40a4ad027cdbe78785da	visible-c a simple visualisation system for c data structures	data structure		data structure	William J. Rogers	1996		10.1145/369585.369592	computer vision;visualization;artificial intelligence;data structure;computer science	Theory	-33.1777753221869	-32.10743679226116	52682
19d5bb0fcedb6bbc6621b1437a01051f5216cb60	improving atm coverage area using density based clustering algorithm and voronoi diagrams		Facility location is a problem of paramount importance and optimizing business operations without affecting customer service is very challenging. In the case of banking services, the location of bank branches and ATMs must match the service demands (turn around time for service, reachability etc) of the customers’ and the expected quality of service is determined by the socioeconomic background of the customer. Therefore, it is necessary to formulate the optimization problem so as to reflect the customers’ expectations and tolerance for quality of service in a given geographical region. The ability to do so requires clustering people living in the region into several smaller areas called service areas. An ideal clustering algorithm should consider the social behavior of people living in the service area and the uncertainty associated with their social behavior. In this paper, we propose a modification to generalized density based clustering algorithm (GDBSCAN) to deal with fuzziness in the values describing the population demographics and the preferences for ATM location among customers utilizing the ATM services. The modified version of GDBSCAN clustering algorithm, which we call GFDBSCAN, is used to cluster people around key socio-economic parameters. GFDBSCAN can also be used to cluster geographical regions based on the requirement and preferences expressed by the customers for services like business outlets, ATMs, bank branch operations, public utilities, etc. We apply the proposed algorithm ∗Corresponding author Email addresses: nraghukisore@gmail.com (N. Raghu Kisore), balu12mcmb28@gmail.com (CH. B Koteswaraiah) Preprint submitted to Nuclear Physics B October 5, 2016	atm turbo;algorithm;circuit complexity;cluster analysis;coefficient;data recovery;davies–bouldin index;dunn index;email;geographic coordinate system;mathematical optimization;optimization problem;purchasing;quality of service;reachability;silhouette (clustering);voronoi diagram	N. Raghu Kisore;Ch. B. Koteswaraiah	2017	Inf. Sci.	10.1016/j.ins.2016.09.058	mathematical optimization;fuzzy clustering;artificial intelligence;machine learning;data mining	Web+IR	-18.3392932476263	-32.59701032515904	53006
239814b651bd4633a036d2f10894d59a45746ebe	evaluating the relative performance of collaborative filtering recommender systems		Past work on the evaluation of recommender systems indicates that collaborative filtering algorithms are accurate and suitable for the top-N recommendation task. Further, the importance of performance beyond accuracy has been recognised in the literature. Here, we present an evaluation framework based on a set of accuracy and beyond accuracy metrics, including a novel metric that captures the uniqueness of a recommendation list. We perform an in-depth evaluation of three well-known collaborative filtering algorithms using three datasets. The results show that the user-based and item-based collaborative filtering algorithms have a high inverse correlation between popularity and diversity and recommend a common set of items at large neighbourhood sizes. The study also finds that the matrix factorisation approach leads to more accurate and diverse recommendations, while being less biased toward popularity.	algorithm;collaborative filtering;computer user satisfaction;e-commerce;experiment;long tail;monoid factorisation;online shopping;recommender system;spike-triggered average;the matrix;user experience	Humberto Jesús Corona Pampín;Houssem Jerbi;Michael P. O'Mahony	2015	J. UCS		data mining;collaborative filtering;recommender system;information retrieval;computer science	Web+IR	-22.315457822561463	-47.81665943516115	53068
b595684228a2c152eca3885a45463b091d0f2f07	qagview: interactively summarizing high-valued aggregate query answers		Methods for summarizing and diversifying query results have drawn significant attention recently, because they help present query results with lots of tuples to users in more informative ways. We present QAGView (Quick AGgregate View), which provides a holistic overview of high-valued aggregate query answers to the user in the form of summaries (showing high-level properties that emerge from subsets of answers) with coverage guarantee (for a user-specified number of top-valued answers) that is both diverse (avoiding overlapping or similar summaries) and relevant (focusing on high-valued aggregate answers). QAGView allows users to view the high-level summaries as clusters, and to expand individual clusters for their constituent result tuples. Users can fine-tune the behavior of QAGView by specifying a number of parameters according their preference. To help users choose appropriate parameters interactively, QAGView employ a suite of optimizations that enable quick preview of how the quality of the summaries changes over wide ranges of parameter settings, as well as real-time visualization of how the summaries evolve in response to parameter updates.	aggregate data;aggregate function;high- and low-level;holism;information;interactivity;real-time locating system	Yuhao Wen;Xiao-Dan Zhu;Sudeepa Roy;Jun Yang	2018		10.1145/3183713.3193566	tuple;computer science;data mining;visualization;cluster analysis	DB	-27.211651425667245	-34.85990264847717	53082
afbc839fa7bca52945eb94b8af4f5d4b3726c879	can social annotation support users in evaluating the trustworthiness of video clips?	trustworthiness;support system;chat;video sharing web site;social annotation	We propose a novel support system for evaluating the trustworthiness of video clips on a video sharing Web site. Our system is used for analyzing comments, posted by users, of a video clip and generating visuals for aiding a user in judging if a video clip is trustworthy or not. Our system is used for representing the changes in the positive and negative levels of comments by generating two types of time-related graphs. One is related to playback time, and the other is related to the date of a posted comment. We realized the prototype system and discussed the capability of our system.	feedback;graph (discrete mathematics);prototype;trust (emotion);video clip	Satoshi Nakamura;Makoto Shimizu;Katsumi Tanaka	2008		10.1145/1458527.1458542	trustworthiness;computer science;multimedia;internet privacy;world wide web	HCI	-29.38817115162007	-49.471308066179475	53151
dd71712af8f9201e1264870118dc43a330ea77f2	data mining for image/video processing: a promising research frontier	frequent pattern;high dimensionality;video analysis;video retrieval;video processing;data mining;data analysis;image and video processing;pattern analysis;collaborative research;sequential pattern;data retrieval;similarity search	Image and video data contains abundant, rich information for data miners to explore. On one hand, the rich literature on image and video data analysis will naturally provide many advanced methods that may help mining other kinds of data. On the other hand, recent research on data mining will also provide some new, interesting methods that may benefit image and video data retrieval and analysis. In this talk we explore the latter, and discuss whether the new results obtained in data mining research could be useful in image and video data retrieval and analysis. Our discussion will be focused on the following aspects: (1) how frequent pattern, sequential pattern, and structural pattern analysis methods may help image and video data analysis; (2) how data mining may help construction of effective and efficient indexing and similarity search mechanisms for image and video retrieval; (3) how discriminative pattern-based classification methods may shed new light on image and video classification; and (4) how pattern-based analysis methods may help high-dimensional clustering in image and video analysis. Our goal is to promote collaborative research between these two research communities.	cluster analysis;data mining;data retrieval;pattern recognition;similarity search;structural pattern;video content analysis;video processing	Jiawei Han	2008		10.1145/1386352.1386353	computer vision;computer science;video tracking;data mining;video processing;data analysis;data retrieval;information retrieval	ML	-14.754818002692167	-51.7921462865458	53157
55ce0742fd9808c95b64a5c03e8e76b33f915a69	definition of image interpretation strategies in apl	image interpretation strategy	"""In many scientific and technical environments observational data are often collected in the form of digital images. For example, physicians observe their patients via CT devices [Ca87], while astronomers exploit CCD devices [Ac89b] and environment or agricultural experts exploit Landsat images [Ta87). In all these cases data are collected and organized as digital images, which are finite bidimensional arrays of integer numbers. It is important to note that looking at an array as a digital image means to look at its elements as picture elements (or pixels) whose meaning is determined not only by their numeric values, but even by their (mutual) positions, Le. their topological and geometrical properties. Jt bas loll8 been recognized that APL is the obvious tool for the definition and description of the algorithms computing these properties and used in such activities as ima&e proce:;sing [Br80), analysis of pictorial data [Bi81) or vision experiments [Fe88]. In this paper we argue, on the basis of our experience (Ac89a] [Cu84] (De84], that APL notation (in our case an adaptation of the a-w notation of APU) allows the combination of tools to derme image interpretation strategies which detect significant entities appearill8 in an lmase and classify them as the· tracks of objects in the real world. In a digital image the significant entities appear as eets of •similarpixels (numbers), ealled structures. In order to define an interpretation activity one has to specifY what •stmilar"""" means (i.e. what properties have to be taken into acc::ount) and set up an interpretation strategy as the mherent mmbination of elementary operations which detects and describes the structures. Obviously, in any scientific or technical environment, 'similar' denotes a different set of topological, seometrical"""	apl;algorithm;charge-coupled device;digital image;entity;experiment;jt (visualization format);pixel	Paolo Bottoni;Piero Mussio;Marco Protti	1990		10.1145/97808.97822	computer science	Graphics	-27.393500094805418	-30.94375844145856	53161
c2c0dc721485b77bca1dd5c0c9ccf150c6e3df7b	outlaw: using geo-spatial associations for outlier detection and visual analysisof cargo routes		U.S. Customs deals with a huge number of cargo trucks and shipments crossing borders by air, water and land. In this paper, we present a system for Outlier analysis by measuring waywardness, called OUTLAW. It distinguishes abnormal and wayward behavior of cargo or goods from that of normal. This wayward behavior can appear to be normal due to lack of correlation. Our aim will be to combine disparate data in meaningful ways by utilizing such parameters as spatial proximity, spatial correlation, and association. Use of thematic map coloring, geographic visualization of individual variables can be very effective for identifying correlations between the variables, week spots, loop holes, wayward routes or vagrants etc. Based on the correlation of the data a predictive model can be generated to detect an index of measuring the waywardness. OUTLAW employs an N-step mechanism to detect vagrants or outliers in the normal scheme of events.	anomaly detection;geovisualization;graph coloring;map coloring;predictive modelling;thematic map	Vandana Pursnani Janeja;Vijayalakshmi Atluri;Nabil R. Adam	2002				AI	-17.064672381332464	-31.899933219536145	53191
c699c1a26bd0af801cbd3daeb8b56cddfc5f9214	cdna: a context-aware notification system for driver interruption		Inopportune driver notifications are a real problem that may cause distractions and interruptions in traffic, and hence accidents. Notifications on mobile devices are one of the ways by which drivers are interrupted, reaching extremely high amounts in a normal day. Despite that, notifications are valued by users and they are part of the common use of smartphones. Therefore, how to lessen the interruptive potential of notifications without eliminating them completely? To mitigate this problem, the present work proposes a context-aware notification system with the identification of opportune and inopportune moments for drivers notification. The proposed system uses smartphone sensors (gyroscope and GPS) to infer if the driver may be interrupted in a specific moment to receive a notification. Preliminary experiments were performed with people in real driving situations to verify if the system could identify opportune and inopportune moments, and found results indicate that is possible to identify these moments with a general accuracy of 88%.		A D da Silva;Lucas Borges;Vaninha Vieira	2018		10.1145/3274192.3274203	human–computer interaction;global positioning system;notification system;mobile computing;mobile device;gyroscope;computer science;context awareness	HCI	-20.175961405392314	-29.96112731034381	53223
265b28ae5769abbf1780f0e35ed04119bf33f53f	a neural attention model for urban air quality inference: learning the weights of monitoring stations		Urban air pollution has attracted much attention these years for its adverse impacts on human health. While monitoring stations have been established to collect pollutant statistics, the number of stations is very limited due to the high cost. Thus, inferring fine-grained urban air quality information is becoming an essential issue for both government and people. In this paper, we propose a generic neural approach, named ADAIN, for urban air quality inference. We leverage both the information from monitoring stations and urban data that are closely related to air quality, including POIs, road networks and meteorology. ADAIN combines feedforward and recurrent neural networks for modeling static and sequential features as well as capturing deep feature interactions effectively. A novel attempt of ADAIN is an attention-based pooling layer that automatically learns the weights of features from different monitoring stations, to boost the performance. We conduct experiments on a real-world air quality dataset and our approach achieves the highest performance compared with various state-of-the-art solutions.	artificial neural network;deep learning;experiment;feedforward neural network;interaction;point of interest;recurrent neural network	Weiyu Cheng;Yanyan Shen;Yanmin Zhu;Linpeng Huang	2018			machine learning;computer science;artificial intelligence;air quality index;inference	AI	-15.664284585558434	-32.22223399567992	53257
8847815dc1ace6df12091abab8b3829afe95b216	non-myopic active learning for recommender systems based on matrix factorization	recommender systems accuracy bayesian methods collaboration prediction algorithms predictive models training;optimisation;matrix factorization;query processing;query processing nonmyopic active learning recommender systems matrix factorization web users optimization prediction model;active learning;training;collaboration;prediction algorithms;recommender systems learning artificial intelligence matrix decomposition optimisation query processing;bayesian methods;user preferences;information overload;statistical model;bayesian method;optimization problem;accuracy;real world application;recommender system;collaborative filtering;matrix decomposition;waiting time;predictive models;prediction model;learning artificial intelligence;recommender systems	Recommender systems help Web users to address information overload. However, their performance depends on the number of provided ratings by users. This problem is amplified for a new user because he/she has not provided any ratings. In this paper, we consider the new user problem as an optimization problem and propose a non-myopic active learning method to select items to be queried from the new user. The proposed method is based on Matrix Factorization (MF) which is a strong prediction model for recommender systems. First, the proposed method explores the latent space to get closer to the optimal new user parameters. Then, it exploits the learned parameters and slightly adjusts them. The results show that beside improving the accuracy of recommendation, MF approach also results in drastically reduced user waiting times, i.e., the time that the users wait before being asked a new query. Therefore, it is an ideal choice for using active learning in real-world applications of recommender systems.	active learning (machine learning);information overload;mathematical optimization;optimization problem;recommender system	Rasoul Karimi;Christoph Freudenthaler;Alexandros Nanopoulos;Lars Schmidt-Thieme	2011	2011 IEEE International Conference on Information Reuse & Integration	10.1109/IRI.2011.6009563	bayesian probability;computer science;data science;machine learning;data mining;database;predictive modelling;matrix decomposition;world wide web;statistics;recommender system	Robotics	-19.080522244449217	-48.68562197271023	53323
6ddf73a2a5157170811ce8e59cc947d4cd36e0e3	construct a bipartite signed network in youtube	video network;summarization;youtube;期刊论文;sentiment analysis;topic participant network	Nowadays, the video-sharing websites are becoming more and more popular, which leads to latent social networks among videos and users. In this work, results are integrated with the data collected from YouTube, one of the largest user-driven online video repositories, and are supported by Chinese sentiment analysis which excels the state of art. Along with it, the authors construct two types of bipartite signed networks, video network (VN) and topic participant network (TPN), where nodes denote videos or users while weights of edges represent the correlation between the nodes. Several indices are defined to quantitatively evaluate the importance of the nodes in the networks. Experiments are conducted by using YouTube videos and corresponding metadata related to two specific events. Experimental results show that both the analysis of social networks and indices correspond very closely with the events’ evolution and the roles that topic participants play in spreading Internet videos. Finally, the authors extend the networks to summarization of a video set related to an event. Construct a Bipartite Signed Network in YouTube	internet television;sentiment analysis;social network;video clip	Tianyuan Yu;Liang Bai;Jinlin Guo;Zheng Yang	2015	IJMDEM	10.4018/IJMDEM.2015100104	computer science;multimedia;internet privacy;world wide web;sentiment analysis	Web+IR	-21.482385519036193	-44.026034387280774	53341
5867297bb0c86bf8c4f27f7ea6019c241fadcebb	creating a mobile-phone based geographic surveillance system for avian influenza	surveillance influenza diseases humans animals pathogens agriculture databases capacitive sensors yarn;databases;animal health;animals;yarn;geographic information system;user generated content avian influenza geographic information systems surveillance system;surveillance;surveillance system;avian influenza;influenza;medical computing;mobile phone;simulated outbreak situation;medical computing geographic information systems;information transfer;highly pathogenic avian influenza;geographic mapping system;geographic information systems;simulated outbreak situation geographic surveillance system highly pathogenic avian influenza mobile phone geographic mapping system;geographic surveillance system;diseases;agriculture;humans;user generated content;capacitive sensors;pathogens	Highly pathogenic avian influenza (HPAI) is not only a global thread to human and animal health but also disproportionately impacts poor livestock keepers in southern countries. While billions have been spent on the disease, response to the epidemic remains fragmented and information channels slow. As such, this demonstration details a geographic mapping system at the global and local levels to aid information transfer among policy makers, practitioners and the poor themselves regarding the control of this disease. The demonstration will include hands on case studies in which conference attendees will be asked to both make decisions and use the tool in a simulated outbreak situation.	mobile phone	Yibo Lin;Claire Heffernan	2009	2009 International Conference on Information and Communication Technologies and Development (ICTD)	10.1109/ICTD.2009.5426729	agriculture;simulation;information transfer;environmental engineering;computer science;geographic information system;computer security	Robotics	-20.990523471593377	-30.689648756605884	53350
c554bdc276571b9c1791d2fffab7315951bad050	optimizing the distance computation order of multi-feature similarity search indexing		Multi-feature search is an effective approach to similarity search. Unfortunately, the search efficiency decreases with the number of features. Several indexing approaches aim to achieve efficiency by incrementally reducing the approximation error of aggregated distance bounds. They apply heuristics to determine the distance computations order and update the object's aggregated bounds after each computation. However, the existing indexing approaches suffer from several drawbacks. They use the same computation order for all objects, do not support important types of aggregation functions and do not take the varying CPU and I/O costs of different distance computations into account. To resolve these problems, we introduce a new heuristic to determine an efficient distance computation order for each individual object. Our heuristic supports various important aggregation functions and calculates cost-benefit-ratios to incorporate the varying computation costs of different distance functions. The experimental evaluation reveals that our heuristic outperforms state-of-the-art approaches in terms of the number of distance computations as well as search time.		Marcel Zierenberg;Ingo Schmitt	2015		10.1007/978-3-319-25087-8_8	mathematical optimization;theoretical computer science;machine learning;mathematics	DB	-5.585056891459594	-40.51100679607936	53361
3f7f427e36edd02368667e8bb8e0964d3ad083b3	personalized web content provider recommendation through mining individual users' qos	search engine;prediction error;decision tree;conference_paper;web content provider recommendation;optimal connection route selection;personalized recommendation;data mining;user qos mining;route selection;waiting time;user experience;neural network group;ranking algorithm;quality of service;neural network	We propose an optimal web content provider recommendation algorithm based on mining QoS (quality of service) information of the Internet. The QoS refers principally to the network bandwidth and waiting time (for a connection to be established). For contents replicated over multiple sites, our algorithm recommends a list of webpages having the desired content and ranked according to their QoSs for any specific user. The recommendation is generated through a data mining procedure based on known QoSs of connections between pairs of computers. Our user QoS mining procedure incrementally constructs a neural network group for QoS prediction based on clustering over the prediction errors. An accompanying decision tree algorithm is then used to select the most appropriate neural network among the neural network group to predict the QoS for a particular user connection. Based on our proposed recommendation algorithm, we have implemented a user-oriented search engine which can identify similar web content providers and make a ranked recommendation based on the prediction over the QoS experienced by individual users. Experiment results have verified that our QoS-based personal web content provider ranking algorithm can indeed produce a recommendation that improves the QoS experienced by individual users.	algorithm;artificial neural network;cluster analysis;computer;data mining;decision tree;list of algorithms;quality of service;web content;web search engine	Songhua Xu;Hao Jiang;Francis C. M. Lau	2009		10.1145/1593254.1593267	mobile qos;computer science;data mining;database;world wide web	ML	-29.61143041570153	-51.74559075077551	53364
79f9414b74cfe90635d0528d1ae634415ea997e7	characterizing social networks based on interior processes of nodes	social network services;social network services frequency modulation context internet monitoring systematics context modeling;frequency modulation;systematics;web design graph theory network theory graphs social networking online statistical analysis;internet;monitoring;conceptual model online social networks characteristics modeling analysis;context modeling;context;online social network interior node process website policies website design next generation infrastructure content distribution systems graph based statistical network characterizations social phenomenon	Over the last few years, efforts have been made to describe and analyze the structure and properties of social networks. Analyzing how users behave when they connect to online networks is important for improving design and policies of websites and crucial for social studies as well as for reshaping next-generation infrastructure and content distribution systems. Most work in this direction has focused on graph-based statistical characterizations of networks, ignoring internal structure of individual nodes; however, in this type of social phenomenon, statistics are not completely satisfactory in the sense that they cannot account for individual events. This paper proposes a structural characterization of the interiors of individual nodes in terms of six generic and mutually exclusive processes: creation, release, transfer, arrival, acceptance, and processing of the artifacts that flow among and within nodes. This produces new categories of nodes such as creators of data, receivers/senders (bus boys), processors (responders), etc. Accordingly, we analyze a sample online social network in terms of these roles of nodes.	central processing unit;digital distribution;fm broadcasting;social network;software system	Sabah S. Al-Fedaghi;Heba Al Meshari	2014	The 9th International Conference for Internet Technology and Secured Transactions (ICITST-2014)	10.1109/ICITST.2014.7038808	network science;evolving networks;computer science;dynamic network analysis;theoretical computer science;hierarchical network model;distributed computing;world wide web	Metrics	-19.991878628098103	-42.71965918954212	53455
fc13ab54a518649ed7bc491aa176e93cca70f563	detection, tracking, and visualization of spatial event clusters for real time monitoring	observers;monitoring;joining processes;clustering algorithms;visual analytics;algorithm design and analysis;real time systems	Spatial events, such as lightning strikes or drops in moving vehicle speed, can be conceptualized as points in the space-time continuum. We consider real time monitoring scenarios in which the observer needs to detect significant (i.e., sufficiently big) spatio-temporal clusters of events as soon as they occur and track the further evolution of these clusters. Isolated spatial events and small clusters are of no interest (i.e., treated as noise) and should be hidden from the observer to avoid attention distraction and perceptual overload. The existing methods for stream clustering cannot enable on-the-fly separation of event clusters from the noise and immediate presentation of significant clusters and their evolution. We propose a novel algorithm tailored to this specific task and a visual analytics system that supports event stream monitoring by presenting detected event clusters and their evolution to the observer in real time.	algorithm;cluster analysis;java;real-time clock;triune continuum paradigm;visual analytics	Natalia V. Andrienko;Gennady L. Andrienko;Georg Fuchs;Salvatore Rinzivillo;Hans-Dieter Betz	2015	2015 IEEE International Conference on Data Science and Advanced Analytics (DSAA)	10.1109/DSAA.2015.7344880	real-time computing;simulation;computer science;data mining	DB	-23.418639408937597	-34.22320950551515	53538
74d792d63941e943eadcf7ea48e44834492de84c	triangle counting in large networks: a review		Counting and enumeration of local topological structures, such as triangles, is an important task for analyzing large real-life networks. For instance, triangle count in a network is used to compute transitivity—an important property for understanding graph evolution over time. Triangles are also used for various other tasks completed for real-life networks, including community discovery, link prediction, and spam filtering. The task of triangle counting, though simple, has gained wide attention in recent years from the data mining community. This is due to the fact that most of the existing algorithms for counting triangles do not scale well to very large networks with millions (or even billions) of vertices. To circumvent this limitation, researchers proposed triangle counting methods that approximate the count or run on distributed clusters. In this paper, we discuss the existing methods of triangle counting, ranging from sequential to parallel, single-machine to distributed, exact to approximate, and off-line to streaming. We also present experimental results of performance comparison among a set of approximate triangle counting methods built under a unified implementation framework. Finally, we conclude with a discussion of future works in this direction.rnrnFor further resources related to this article, please visit the WIREs website.		Mohammad Al Hasan;Vachik S. Dave	2018	Wiley Interdiscip. Rev. Data Min. Knowl. Discov.	10.1002/widm.1226	data mining;theoretical computer science;filter (signal processing);machine learning;artificial intelligence;vertex (geometry);enumeration;ranging;computer science;graph	AI	-11.019371814361785	-39.567894006854566	53574
20823884e20cd47434058b287bb1dd255db07d5c	actively learning to rank semantic associations for personalized contextual exploration of knowledge graphs		Knowledge Graphs (KG) represent a large amount of Semantic Associations (SAs), i.e., chains of relations that may reveal interesting and unknown connections between different types of entities. Applications for the contextual exploration of KGs help users explore information extracted from a KG, including SAs, while they are reading an input text. Because of the large number of SAs that can be extracted from a text, a first challenge in these applications is to effectively determine which SAs are most interesting to the users, defining a suitable ranking function over SAs. However, since different users may have different interests, an additional challenge is to personalize this ranking function to match individual users’ preferences. In this paper we introduce a novel active learning to rank model to let a user rate small samples of SAs, which are used to iteratively learn a personalized ranking function. Experiments conducted with two data sets show that the approach is able to improve the quality of the ranking function with a limited number of user interactions.	knowledge graph;learning to rank	Federico Bianchi;Matteo Palmonari;Marco Cremaschi;Elisabetta Fersini	2017		10.1007/978-3-319-58068-5_8	learning to rank;active learning;data mining;computer science;data set;machine learning;artificial intelligence;graph;ranking	AI	-19.972939606176098	-48.583810916341484	53697
4c4005df818605305c11fc8b0c343f8b18cef1b5	mining closed partially ordered patterns, a new optimized algorithm	sequential patterns;data mining;partially ordered patterns	Nowadays, sequence databases are available in several domains with increasing sizes. Exploring such databases with new pattern mining approaches involving new data structures is thus important. This paper investigates this data mining challenge by presenting OrderSpan, an algorithm that is able to extract a set of closed partially ordered patterns from a sequence database. It combines well-known properties of prefixes and suffixes. Furthermore, we extend OrderSpan by adapting efficient optimizations used in sequential pattern mining domain. Indeed, the proposed method is flexible and follows the sequential pattern paradigm. It is more efficient in the search space exploration, as it skips redundant branches. Experiments were performed on different real datasets to show (1) the effectiveness of the optimized approach and (2) the benefit of closed partially ordered patterns with respect to closed sequential patterns. 2015 Elsevier B.V. All rights reserved.	algorithm;data mining;data structure;information retrieval;mathematical optimization;performance evaluation;programming paradigm;sequence database;sequential pattern mining;synthetic intelligence;temporal database;turing completeness	Mickaël Fabrègue;Agnès Braud;Sandra Bringay;Florence Le Ber;Maguelonne Teisseire	2015	Knowl.-Based Syst.	10.1016/j.knosys.2014.12.027	computer science;data mining;database;algorithm	DB	-6.117293442270141	-37.855672920668404	53746
3266ea15f019f35ac03633b6abce0ceeeccda0f3	a multiprocessor system for real-time robotic control	construccion modular;canal bus;multiprocessor;commande;multiprocessor systems;articulation;real time;relacion hombre maquina;canal colector;man machine relation;robotics;articulacion;servomechanism;algorithme;algorithm;servomecanisme;robot control;construction modulaire;temps reel;robotica;servomecanismo;tiempo real;bus channel;control;robotique;relation homme machine;modular construction;joint;multiprocesador;algoritmo;multiprocesseur	Abstract   SIERA (System for Implementing and Evaluating Robotic Algorithms) is a multiprocessor system that has been developed at the Laboratory for Engineering Man/Machine Systems (LEMS) at Brown University. It incorporates a tightly coupled bus-based system (the Real Time Servo System, or RTSS) and a loosely coupled link-oriented network (the Armstrong Multiprocessor System). SIERA is capable of controlling many types of commercially available robots because the modular construction of its hardware and software has minimized robot dependences. Support routines have been created to yield a powerful robotic algorithm development system. This includes a custom real-time operating system for the RTSS and special processes for the Armstrong system. These facilities allow a researcher to interactively modify or replace any algorithm related to the operation of the robot. A compliant control example is used to illustrate SIERA's capabilities. The algorithm presented in this example may be applied to unconstrained motion as well as compliant motion and is the topic of further research.	multiprocessing;real-time transcription;robot	Peter Kazanzides;Hamid A. Wasti;William A. Wolovich	1988	Inf. Sci.	10.1016/0020-0255(88)90003-5	joint;embedded system;multiprocessing;simulation;computer science;artificial intelligence;servomechanism;robot control;robotics;algorithm;scientific control	Robotics	-32.90943771961728	-37.925668074500074	53793
2278f7da861e72c4c8db3a426247c7ab172dd789	mining frequent itemsets with partial enumeration	high density;k prefix partitioning;conditional databases;frequent itemset;frequent itemsets;partial enumeration	In this paper, we present an algorithm of mining frequent itemsets using partial enumeration and the FP-growth function with reduced depth of recursion. The experimental results show that our algorithm outperforms the original FP-growth algorithm without partial enumeration for the databases with high density.	algorithm;database;recursion	Peiyi Tang;Markus P. Turkia	2006		10.1145/1185448.1185489	data mining;database;algorithm	ML	-5.449815606863388	-37.786579612356626	53805
8339cb798795e6fdb1b64b957e9626805b7d7894	maxent: consistent cardinality estimation in action	maximum entropy principle;query optimization;consistent estimator;relational database management system;multivariate statistics;cardinality bias;maximum entropy;selectivity estimation	When comparing alternative query execution plans (QEPs), a cost-based query optimizer in a relational database management system needs to estimate the selectivity of conjunctive predicates. To avoid inaccurate independence assumptions, modern optimizers try to exploit multivariate statistics (MVS) that provide knowledge about joint frequencies in a table of a relation. Because the complete joint distribution is almost always too large to store, optimizers are given only partial knowledge about this distribution. As a result, there exist multiple, non-equivalent ways to estimate the selectivity of a conjunctive predicate. To consistently combine the partial knowledge during the estimation process, existing optimizers employ cumbersome ad hoc heuristics. These methods unjustifiably ignore valuable information, and the optimizer tends to favor QEPs for which the least information is available. This bias problem yields poor QEP quality and performance. We demonstrate MAXENT, a novel approach based on the maximum entropy principle, prototyped in IBM DB2 LUW. We illustrate MAXENT's ability to consistently estimate the selectivity of conjunctive predicates on a per-table basis. In contrast to the DB2 optimizer's current ad hoc methods, we show how MAXENT exploits all available information about the joint column distribution and thus avoids the bias problem. For some complex queries against a real-world database, we show that MAXENT improves selectivity estimates by orders of magnitude relative to the current DB2 optimizer, and also show how these improved estimate influence plan choices as well as query execution times.	database transaction;existential quantification;heuristic (computer science);hoc (programming language);mathematical optimization;principle of maximum entropy;query optimization;relational database management system;selectivity (electronic)	Volker Markl;Marcel Kutsch;Tam Minh Tran;Peter J. Haas;Nimrod Megiddo	2006		10.1145/1142473.1142586	query optimization;boolean conjunctive query;computer science;principle of maximum entropy;pattern recognition;data mining;database	DB	-7.6271721730023385	-32.733095827105856	53871
a216aa9d810c8eb8f0b21505c2c4e5ba35cb43e5	a short introduction to local graph clustering methods and software		Graph clustering has many important applications in computing, but due to the increasing sizes of graphs, even traditionally fast clustering methods can be computationally expensive for real-world graphs of interest. Scalability problems led to the development of local graph clustering algorithms that come with a variety of theoretical guarantees [1]. Rather than return a global clustering of the entire graph, local clustering algorithms return a single cluster around a given seed node or set of seed nodes. These algorithms improve scalability because they use time and memory resources that depend only on the size of the cluster returned, instead of the size of the input graph. Indeed, for many of them, their running time grows linearly with the size of the output. In addition to scalability arguments, local graph clustering algorithms have proven to be very useful for identifying and interpreting small-scale and meso-scale structure in large-scale graphs [2,3]. As opposed to heuristic operational procedures, this class of algorithms comes with strong algorithmic and statistical theory. These include statistical guarantees that prove they have implicit regularization properties [4,5]. One of the challenges with the existing literature on these approaches is that they are published in a wide variety of areas, including theoretical computer science, statistics, data science, and mathematics. This has made it difficult to relate the various algorithms and ideas together into a cohesive whole. We have recently been working on unifying these diverse perspectives through the lens of optimization [6] as well as providing software to perform these computations in a cohesive fashion [7]. In this note, we provide a brief introduction to local graph clustering, we provide some representative examples of our perspective, and we introduce our software named Local Graph Clustering (LGC).	algorithm;analysis of algorithms;cluster analysis;computation;data science;heuristic;mathematical optimization;matrix regularization;mesoscopic physics;scalability;theoretical computer science;time complexity	Kimon Fountoulakis;David F. Gleich;Michael W. Mahoney	2018	CoRR		machine learning;statistical theory;artificial intelligence;scalability;computation;computer science;software;heuristic;clustering coefficient;cluster analysis;graph	ML	-12.784734062864727	-40.90303068339363	53881
33e8cd4abaed22717126fd4de2ec6e1a97429402	drivescover: a tourism recommender system based on external driving factors		In this paper, we present the design and implementation of DrIveSCOVER, a recommender system for places and events in case of an in-car use, where the driving conditions such as weather and local traffic are taken into account. We integrate multiple data sources using semantic technologies and we devise recommending functions that are presented in a web-based application. Data is organized according to five root classes: accommodation, car amenity, events, gastronomy and points of interest. An interest score is calculated from the weighted user inputs in terms of preferences of classes and driving conditions. The application is available at http://drivescover.eurecom.fr/.	point of interest;recommender system;web application	Benjamin Klotz;Pasquale Lisena;Raphaël Troncy;Daniel Wilms;Christian Bonnet	2017			computer science;recommender system;data mining;tourism;driving factors	ML	-27.293150558317375	-44.31302881107326	53905
02d6ac62b8668a14ae5cea2b6dd2adb3a74dfda6	efficient media exploitation towards collective intelligence	social context;contextual information;social dynamic;information sharing;content analysis;collective intelligence;user interaction;semantic analysis	In this work we propose intelligent, automated content analysis techniques for different media to extract knowledge from the multimedia content. Information derived from different sources/modalities will be analyzed and fused, in terms of spatiotemporal, personal and even social contextual information. In order to achieve this goal, semantic analysis will be applied to the content items, taking into account the content itself (e.g., text, images and video), as well as existing personal, social and contextual information (e.g., semantic and machine-processable metadata and tags). The above process exploits the so-called “Media Intelligence” towards the ultimate goal of identifying “Collective Intelligence”, emerging from the collaboration and competition among people, empowering innovative services and user interactions. The utilization of “Media Intelligence” constitutes a departure from traditional methods for information sharing, since semantic multimedia analysis has to fuse information from both the content itself and the social context, while at the same time the social dynamics have to be taken into account. Such intelligence provides added-value to the available multimedia content and renders existing procedures and research efforts more efficient.	collective intelligence;interaction;media intelligence;rendering (computer graphics);semantic analysis (compilers);social dynamics	Phivos Mylonas;Vassilios Solachidis;Andreas Geyer-Schulz;Bettina Hoser;Sam Chapman;Fabio Ciravegna;Steffen Staab;Pavel Smrz;Yiannis Kompatsiaris;Yannis S. Avrithis	2008		10.1007/978-3-642-01044-6_66	computer science;knowledge management;multimedia;world wide web	Web+IR	-28.287973646349023	-49.0958062860046	53907
5d224b8bc766c8cdd5a9fdf5369797412dce56ec	subjective collaborative filtering	user preferences;data mining;association rule;collaborative filtering	We present an item-based approach for collaborative filtering. We determine a list of recommended items for a user by considering their previous purchases. Additionally other features of the users could be considered such as page views, search queries, etc. . . In particular we address the problem of efficiently comparing items. Our algorithm can efficiently approximate an estimate of the similarity between two items. As measure of similarity we use an approximation of the Jaccard similarity that can be computed by constant time operations and one bitwise OR. Moreover we improve the accuracy of the similarity by introducing the concept of user preference for a given product, which both takes into account multiple purchases and purchases of related items. The product of the user preference and the Jaccard measure (or its approximation) is used as a score for deciding whether a given product has to be recommended.	approximation algorithm;bitwise operation;collaborative filtering;jaccard index;page view;purchasing;time complexity;web search query	Fabrizio Caruso;Giovanni Giuffrida;Calogero G. Zarba	2011	CoRR		association rule learning;computer science;collaborative filtering;machine learning;data mining;database;world wide web;information retrieval	Web+IR	-21.26207351878577	-49.63730030894785	53927
82029e095f29b882b204fc626ed98cc1661c1d9f	reconstructing uncertain pedestrian trajectories from low-sampling-rate observations		The ever-greater number of technologies providing location-based services has given rise to a deluge of trajectory data. However, most of these trajectories are low-sampling-rate and, consequently, many movement details are lost. Due to that, trajectory reconstruction techniques have been created to infer the missing movement details and reduce uncertainty. Nevertheless, most effort has been put into reconstructing vehicle trajectories. Therefore, we study the reconstruction of pedestrian trajectories by using road network information. We compare a simple technique that only uses road network information with a more complex technique that, besides the road network, uses historical trajectory data. Additionally, we use three different trajectory segmentation settings to analyze their influence over reconstruction. Our experiment results show that, with the limited pedestrian trajectory data available, a simple technique that does not use historical data performs considerably better than a more complex technique that does use it. Furthermore, our results also show that trajectories segmented in such a way as to allow a greater distance and time span between consecutive points obtain better reconstruction results in the majority of the cases, regardless of the technique used.	location-based service;sampling (signal processing)	Ricardo Miguel Puma-Alvarez;Alneu de Andrade Lopes	2017			statistics;sampling (signal processing);pedestrian;computer science	HCI	-16.01981624074886	-34.06528209039004	53962
4988dba5ce380446185ba257d405c12af843b854	distributed event identification for wsns in non-stationary environments		This paper proposes a novel scheme to estimate the percentage contribution of different attributes in a detected event (a process termed as event identification) for streaming multi-attribute data in WSNs. The proposed event detection and identification algorithm takes into account correlation among sensed attributes as well as the spatio-temporal correlations with similar attributes measured by neighboring nodes. Moreover we update our statistical parameters in an iterative manner such that the dynamics of non- stationary environments are taken into account. We test our leave one out (LOO) event identification approach with simulations on both synthetic and real data sets and an implementation on off-the- shelf WizziMotes. The experimental results show that our detection scheme outperforms state of the art schemes by showing detection rates (DRs) of more than 98\% and false positive rates (FPRs) of less that 2\%. Moreover, our event identification approach effectively determines the contribution of both correlated and uncorrelated attributes in an event of interest. The identification has also been shown to be in strong agreement with previous computationally complex benchmark PCA based event identification approaches.	algorithm;anomaly detection;benchmark (computing);identification scheme;iterative method;principal component analysis;simulation;stationary process;synthetic intelligence;ti msp430	Kamran Ali;S. B. Ali;Ijaz Haider Naqvi;M. A. Lodhi	2014	2015 IEEE Global Communications Conference (GLOBECOM)	10.1109/GLOCOM.2014.7417216	market research;computer science;machine learning;pattern recognition;data mining;mathematics;cluster analysis;correlation	Vision	-11.24280701384739	-35.00452526558977	53981
7cf691b7c317d3dd82d44c544e339cd07963cb98	evaluation of uncertainty visualization techniques for information fusion	decision support;human computer interaction;usability testing;usability testing uncertainty visualization techniques information fusion uncertainty representations;technology;information visualization;uncertainty data visualization human computer interaction information analysis application software decision making computer displays informatics usability testing;teknik;data visualisation;sensor fusion data visualisation;visualization technique;decision support uncertainty information visualization human computer interaction hci;user experience;information fusion;sensor fusion	This paper highlights the importance of uncertainty visualization in information fusion, reviews general methods of representing uncertainty and presents perceptual and cognitive principles from Tufte, Chambers and Bertin as well as users experiments documented in the literature. Examples of uncertainty representations in information fusion are analyzed using these general theories. These principles can be used in future theoretical evaluations of existing or newly developed uncertainty visualization techniques before usability testing with actual users.	experiment;usability testing	Maria Riveiro	2007	2007 10th International Conference on Information Fusion	10.1109/ICIF.2007.4408049	computer vision;visual analytics;information visualization;human–computer interaction;computer science;data mining	Robotics	-30.716955980875955	-32.719761686761856	54107
481c7a31d76f58037efe6ce8e7ffd08e7ec96c6a	data mining and visualization: meteorological parameters and gas concentration use case		Knowledge extraction from big data is one of the important subjects now and in future. Mining in the big data needs many steps, which must be implemented very carefully. The final step in big data mining is visualizing the results or summarizing the results numerically. This paper aims to mining the big data recorded by environmental station. These stations are recording the concentrations of some gases and meteorological parameters. The 2D and 3D data visualization is used to evaluate the capability of visualization in determining the effect of meteorological parameters on some gases that caused pollution. The results showing the visualization is a very important tool, and visualization can be used in mining big data, by showing the concentrations of gases. The paper recommends using big data visualization periodically as an alarming tool for monitoring the levels of pollution gases concentration.	big data;data mining;data visualization;diagram;e-book;numerical analysis	Yas A. Alsultanny	2017			data mining;visualization;computer science	ML	-23.675039147758483	-30.879894863501775	54142
ba35dccc5f539dfdfa46ebcc3e8a5357538ce45d	application of the spatial data mining methodology and gamification for the optimisation of solving the transport issues of the “varsovian mordor”		The objective of the paper was to develop a specialised knowledge base using data mining methods, as the basis for and expert, decision making support system, created for the needs of development of action against negative spatial phenomena, which occur within the biggest office district of the capital of Poland. After collecting representative answers to a questionnaire from responders, who are professionally involved with this area, the authors “enriched the data” with commonly accessible spatial information and analysed the resulting dataset using artificial, regression and classification neural networks, CART decision trees and created fuzzy inference systems. Inference rules, developed with the use of the knowledge base and a limited amount of accessible information allow to specify highly probable types of social problems important for particular employees of this district. Using data mining techniques, the authors transformed collected data into information and knowledge, diagnosing main infrastructural and spatial problems in “Varsovian Mordor”. Generalisation of inference rules, developed as a result of knowledge acquisition allowed the authors to propose unique, social gamification techniques, precisely dedicated for particular groups of inhabitants and employees of “the Mordor”.		Robert Olszewski;Agnieszka Turek	2016		10.1007/978-3-319-40973-3_10	simulation;data mining;management science	ML	-9.29572776670648	-24.865492026286624	54163
8647790cba00f1c5c0f023932e781e0e6f13f6dd	sensitivity of community structure to network uncertainty		Community detection constitutes an important task for investigating the internal structure of networks, with a plethora of applications in a wide range of disciplines. A particularly important point, which is rarely taken into account while developing community detection algorithms, is their sensitivity (or stability) to network uncertainty. In many cases, the input graph data is incomplete or noisy (e.g., due to noise introduced during the collection of the data or for privacy preserving reasons). Then, the following question arises: how stable are the results produced by an algorithm with respect to the uncertainty (i.e., noise level) of the input data? In this paper, we propose a quantitative way to address this problem. We have considered several graph perturbation models to introduce uncertainty to the graph. Then, we examine the sensitivity of an algorithm, with respect to functional and structural characteristics of the detected communities under various perturbation levels. We have studied the performance of some of the most widely used community detection algorithms in practice, and our experimental results indicate that random walk based community detection algorithms tend to be robust under various conditions of network uncertainty.	algorithm;noise (electronics);perturbation theory (quantum mechanics)	Marc Mitri;Fragkiskos D. Malliaros;Michalis Vazirgiannis	2017		10.1137/1.9781611974973.39	computer science;artificial intelligence;machine learning;community structure	DB	-13.46740475615195	-40.598978725167605	54228
2dc4a4694c1e7a479ff955cc11fdc4a56b0600e4	extracting communities from complex networks by the k-dense method	graph theory;efficient algorithm;complex network;decomposition method;large scale;structure and function;computational complexity;community structure;knowledge acquisition;large scale systems computational complexity graph theory knowledge acquisition;coarse grained;k clique method k dense method large scale complex network blog trackback word association k core method;extraction method;large scale systems;complex networks data mining large scale systems computer networks laboratories web sites communities technological innovation assembly information services	To understand the structural and functional properties of large-scale complex networks, it is crucial to efficiently extract a set of cohesive subnetworks as communities. There have been proposed several such community extraction methods in the literature, including the classical k-core decomposition method and, more recently, the k-clique based community extraction method. The k-core method, although computationally efficient, is often not powerful enough for uncovering a detailed community structure and it produces only coarse-grained and loosely connected communities. The k-clique method, on the other hand, can extract fine-grained and tightly connected communities but requires a substantial amount of computational load for large-scale complex networks. In this paper, we present a new notion of a subnetwork called k-dense, and propose an efficient algorithm for extracting k-dense communities. We applied our method to the two different types of networks assembled from real data, namely, from blog trackbacks and word associations, demonstrated that the k-dense method could extract communities almost as efficiently as the k-core method, while the qualities of the extracted communities are comparable to those obtained by the k-clique method	algorithm;algorithmic efficiency;blog;clique (graph theory);complex network;computation;degeneracy (graph theory);subnetwork;trackback	Kazumi Saito;Takeshi Yamada	2006	Sixth IEEE International Conference on Data Mining - Workshops (ICDMW'06)	10.1109/ICDMW.2006.76	decomposition method;computer science;graph theory;theoretical computer science;machine learning;data mining;mathematics;computational complexity theory;girvan–newman algorithm;community structure;complex network	DB	-14.610515149098264	-42.72578912278092	54232
42c550d011f3fd8b9d4d97666a60368b039c092a	analysis of travel time patterns in urban using taxi gps data	weighted moving average;travel time;global positioning system data analysis;time series;trajectory global positioning system data mining time series analysis educational institutions data models market research;data analysis;trajectory mining;global positioning system;beijing travel time analysis global positioning system taxi gps data travel time data is based weighted moving average;weighted moving average travel time trajectory mining time series	Travel time is the basic information to city life. Accurate travel time information can help people plan travel schedule and improve work efficiency. This paper proposes a method to discover travel-time patterns which can evaluate the travel efficiency in the city. The travel time data is based on the trajectories extracted from taxi GPS data. First we propose a method to recognize popular paths between origin-destination pairs, and cluster the same trajectories together meanwhile the abnormal trajectories are discarded. We treat the travel time data as time series, and Weighted Moving Average (WMA) is used to extract the normal travel time pattern. In the final part of the paper, the model is validated through the taxi GPS data of Beijing. We recognize different travel time patterns and some real examples of different paths are analyzed.	global positioning system;numerical weather prediction;time series	Mengdan Gao;Tongyu Zhu;XueJin Wan;Qi Wang	2013	2013 IEEE International Conference on Green Computing and Communications and IEEE Internet of Things and IEEE Cyber, Physical and Social Computing	10.1109/GreenCom-iThings-CPSCom.2013.101	simulation;global positioning system;time series;moving average;data analysis;statistics	Robotics	-16.88165065767615	-32.341998744699225	54364
da75eb85fea123be5613c1c413a9fa74b9d19830	pattern detection and discovery	pattern detection;data mining;large data;statistical modelling;large data set;underlying theoretical base;modelling approach;data mining lead;theoretical base;future development;traditional modelling methodology	Data mining comprises two subdisciplines. One of these is based on statistical modelling, though the large data sets associated with data mining lead to new problems for traditional modelling methodology. The other, which we term pattern detection, is a new science. Pattern detection is concerned with defining and detecting local anomalies within large data sets, and tools and methods have been developed in parallel by several applications communities, typically with no awareness of developments elsewhere. Most of the work to date has focussed on the development of practical methodology, with little attention being paid to the development of an underlying theoretical base to parallel the theoretical base developed over the last century to underpin modelling approaches. We suggest that the time is now right for the development of a theoretical base, so that important common aspects of the work can be identified, so that key directions for future research can be characterised, and so that the various different application domains can benefit from the work in other areas. We attempt describe a unified approach to the subject, and also attempt to provide theoretical base on which future developments can stand.	application domain;data mining;pattern recognition;sensor;statistical model	Zbyszek Struzik	2002		10.1007/3-540-45728-3	statistical model;computer science;artificial intelligence;data mining;data analysis;information extraction;algorithm;statistics	ML	-23.59666244575118	-32.49008586289457	54366
22cf3f92b238ebd00c38a08a400f14c6549eeede	mining large graphs and streams using matrix and tensor tools	streams;fundamental matrix;data mining;large scale;tensors	Coevolving streams of numerical measurements, as well astime evolving graphs, can well be represented as tensors. Here we review the fundamental matrix and tensors tools forthe analysis and mining of large scale streams and graphs.	fundamental matrix (computer vision);graph (discrete mathematics);numerical analysis;streams	Christos Faloutsos;Tamara G. Kolda;Jimeng Sun	2007		10.1145/1247480.1247647	tensor;computer science;data science;machine learning;data mining;fundamental matrix;streams	ML	-11.500899684345047	-38.877405064772695	54411
6987e35cd4202d37995499e9863382af205a3a6b	digital forensics infovis: an implementation of a process for visualisation of digital evidence	digital forensics;implementation infovis digital forensics;electronic mail;computer forensics;infovis;implementation;information filtering;information overload;data visualization correlation digital forensics visualization electronic mail information filters;proof of concept;data visualisation;visualization;data visualization;data visualisation computer forensics;digital evidence;correlation;information filters;proof of concept implementation digital forensics infovis digital evidence visualisation data detectives formalised process explore process investigate process correlate process	Infovis enables us to combine the language of the eyes with the language of the mind, empowering all manner of people to be data detectives. Formalised processes for the integration of infovis techniques within the digital forensics domain are few and far between. One such process, the Explore, Investigate and Correlate process has been developed and provides a series of phases and key principles on which to build systems that integrate infovis techniques within the digital forensics investigative workflow. This paper presents refinements to this process and a proof-of-concept implementation. How the implementation achieves the goals of the process, the techniques it uses and how it helps to reduce information overload within the digital forensics domain are examined.	categorization;content-control software;earth inductor compass;high-level programming language;information overload;information visualization;interactive visualization;music visualization;process modeling;usability testing	Grant Osborne;Jill Slay	2011	2011 Sixth International Conference on Availability, Reliability and Security	10.1109/ARES.2011.36	computer science;multimedia;internet privacy;world wide web	DB	-29.752140807226542	-29.66911920752309	54475
f1ec11281f157e488a6385dbdb823a54cb6f79c6	crowdsourced poi labelling: location-aware result inference and task assignment	conference_paper;spatial database;social networking online inference mechanisms;crowdsourcing platform location aware result inference task assignment points of interest location based services raw labels artificial algorithms low quality labels bad user experiences best fit computer hard tasks crowdsourced poi labelling tasks correct labels online task assigner inference model measures spatial distance poi influence;labeling crowdsourcing computational modeling random variables computer science mobile radio mobility management reliability;crowdsourcing	Identifying the labels of points of interest (POIs), aka POI labelling, provides significant benefits in location-based services. However, the quality of raw labels manually added by users or generated by artificial algorithms cannot be guaranteed. Such low-quality labels decrease the usability and result in bad user experiences. In this paper, by observing that crowdsourcing is a best-fit for computer-hard tasks, we leverage crowdsourcing to improve the quality of POI labelling. To our best knowledge, this is the first work on crowdsourced POI labelling tasks. In particular, there are two sub-problems: (1) how to infer the correct labels for each POI based on workers' answers, and (2) how to effectively assign proper tasks to workers in order to make more accurate inference for next available workers. To address these two problems, we propose a framework consisting of an inference model and an online task assigner. The inference model measures the quality of a worker on a POI by elaborately exploiting (i) worker's inherent quality, (ii) the spatial distance between the worker and the POI, and (iii) the POI influence, which can provide reliable inference results once a worker submits an answer. As workers are dynamically coming, the online task assigner judiciously assigns proper tasks to them so as to benefit the inference. The inference model and task assigner work alternately to continuously improve the overall quality. We conduct extensive experiments on a real crowdsourcing platform, and the results on two real datasets show that our method significantly outperforms state-of-the-art approaches.	algorithm;apache poi;crowdsourcing;curve fitting;experience;experiment;information processing;location-based service;point of interest;regular expression;usability;work breakdown structure	Huiqi Hu;Yudian Zheng;Zhifeng Bao;Guoliang Li;Jianhua Feng;Reynold Cheng	2016	2016 IEEE 32nd International Conference on Data Engineering (ICDE)	10.1109/ICDE.2016.7498229	computer science;data science;data mining;database;world wide web;crowdsourcing;spatial database	DB	-22.90085846018184	-45.34379158763055	54541
0834e74304b547c9354b6d7da6fa78ef47a48fa8	line: large-scale information network embedding	dimension reduction;会议论文;information network embedding;feature learning;scalability	This paper studies the problem of embedding very large information networks into low-dimensional vector spaces, which is useful in many tasks such as visualization, node classification, and link prediction. Most existing graph embedding methods do not scale for real world information networks which usually contain millions of nodes. In this paper, we propose a novel network embedding method called the ``LINE,'' which is suitable for arbitrary types of information networks: undirected, directed, and/or weighted. The method optimizes a carefully designed objective function that preserves both the local and global network structures. An edge-sampling algorithm is proposed that addresses the limitation of the classical stochastic gradient descent and improves both the effectiveness and the efficiency of the inference. Empirical experiments prove the effectiveness of the LINE on a variety of real-world information networks, including language networks, social networks, and citation networks. The algorithm is very efficient, which is able to learn the embedding of a network with millions of vertices and billions of edges in a few hours on a typical single machine. The source code of the LINE is available online\footnote{\url{https://github.com/tangjianpku/LINE}}.	algorithm;citation graph;experiment;global network;graph (discrete mathematics);graph embedding;loss function;optimization problem;sampling (signal processing);social network;stochastic gradient descent	Jian Tang;Meng Qu;Mingzhe Wang;Ming Zhang;Jun Yan;Qiaozhu Mei	2015		10.1145/2736277.2741093	feature learning;scalability;evolving networks;computer science;theoretical computer science;machine learning;database;distributed computing;world wide web;dimensionality reduction	Web+IR	-11.975468839267753	-42.125015101564145	54542
4c11c1f115cbb3bf7b6f4908c78fe459abde6b1c	exploiting spatio-temporal user behaviors for user linkage		Cross-device and cross-domain user linkage have been attracting a lot of attention recently. An important branch of the study is to achieve user linkage with spatio-temporal data generated by the ubiquitous GPS-enabled devices. The main task in this problem is twofold, i.e., how to extract the representative features of a user; how to measure the similarities between users with the extracted features. To tackle the problem, we propose a novel model STUL (Spatio-Temporal User Linkage) that consists of the following two components. 1) Extract users - spatial features with a density based clustering method, and extract the users - temporal features with the Gaussian Mixture Model. To link user pairs more precisely, we assign different weights to the extracted features, by lightening the common features and highlighting the discriminative features. 2) Propose novel approaches to measure the similarities between users based on the extracted features, and return the pair-wise users with similarity scores higher than a predefined threshold. We have conducted extensive experiments on three real-world datasets, and the results demonstrate the superiority of our proposed STUL over the state-of-the-art methods.	cluster analysis;discretization;experiment;global positioning system;google map maker;linkage (software);mixture model;scott continuity;universality probability	Wei Chen;Hongzhi Yin;Weiqing Wang;Lei Zhao;Wen Hua;Xiaofang Zhou	2017		10.1145/3132847.3132898	data mining;discriminative model;mixture model;computer science;cluster analysis	AI	-17.15753380704398	-36.101805463857524	54564
100f6c476b14cfc57d5cd93f0f1c2eb506666850	imgwordle: image and text visualization for events in microblogging services	information visualization;visual analysis;microblogging;tag cloud	With the wide usage of microblogging services, microposts grow at high rate and provide a rich source of information related to important social events and trends. However, analyzing microposts is challenging due to its high complexity and large volume. In this paper, we present ImgWordle, an interactive visualization prototype to help people perceive and analyze the image and text information in microblogging services. The prototype extends tag cloud by involving images as well as words, and provides multiple coordinated views for a given event, including keywords of various topics, representative images, geographic sentiments and amounts of microposts, and popular microposts over time. We implement ImgWordle on Sina Weibo, the most popular microblogging service in China, and illustrate the usefulness of this visual interface.	information source;interactive visualization;prototype;tag cloud	Chong Kuang;Jiayu Tang;Zhiyuan Liu;Maosong Sun	2014		10.1145/2598153.2600041	information visualization;computer science;microblogging;data mining;multimedia;internet privacy;world wide web;tag cloud	HCI	-25.86923108681219	-45.5195921039555	54645
b3f6f001a3792a55bf8e7a47cc7e1f2f21b45655	exploration of virtual and augmented reality for visual analytics and 3d volume rendering of functional magnetic resonance imaging (fmri) data	anatomic context virtual reality augmented reality 3d volume rendering functional magnetic resonance imaging data fmri data statistical analysis schizophrenia interactive visual analytics network diagrams data visualisations mouse and keyboard input;data visualization three dimensional displays rendering computer graphics correlation visual analytics clutter;statistical analysis augmented reality biomedical mri data visualisation interactive systems medical image processing rendering computer graphics	Statistical analysis of functional magnetic resonance imaging (fMRI), such as independent components analysis, is providing new scientific and clinical insights into the data with capabilities such as characterising traits of schizophrenia. However, with existing approaches to fMRI analysis, there are a number of challenges that prevent it from being fully utilised, including understanding exactly what a 'significant activity' pattern is, which structures are consistent and different between individuals and across the population, and how to deal with imaging artifacts such as noise. Interactive visual analytics has been presented as a step towards solving these challenges by presenting the data to users in a way that illuminates meaning. This includes using circular layouts that represent network connectivity and volume renderings with 'in situ' network diagrams. These visualisations currently rely on traditional 2D 'flat' displays with mouse-and-keyboard input. Due to the constrained screen space and an implied concept of depth, they are limited in presenting a meaningful, uncluttered abstraction of the data without compromising on preserving anatomic context. In this paper, we present our ongoing research on fMRI visualisation and discuss the potential for virtual reality (VR) and augmented reality (AR), coupled with gesture-based inputs to create an immersive environment for visualising fMRI data. We suggest that VR/AR can potentially overcome the identified challenges by allowing for a reduction in visual clutter and by allowing users to navigate the data abstractions in a 'natural' way that lets them keep their focus on the visualisations. We present exploratory research we have performed in creating immersive VR environments for fMRI data.	augmented reality;circular layout;clutter;diagram;glossary of computer graphics;immersion (virtual reality);independent component analysis;plover;resonance;virtual reality;visual analytics;volume rendering	Michael de Ridder;Younhyun Jung;Robin Huang;Jinman Kim;David Dagan Feng	2015	2015 Big Data Visual Analytics (BDVA)	10.1109/BDVA.2015.7314293	computer vision;computer science;multimedia;computer graphics (images)	Visualization	-29.509063389803284	-34.45838351859314	54716
b5283f7457f328b31851e3046611123546c8d5a5	user demographics prediction based on mobile data	mobile;ensemble;demographics;cost sensitive classification;feature construction;multi task learning	Demographics prediction is an important component of user profile modeling. The accurate prediction of users' demographics can help promote many applications, ranging from web search, personalization to behavior targeting. In this paper, we focus on how to predict users' demographics, including ''gender'', ''job type'', ''marital status'', ''age'' and ''number of family members'', based on mobile data, such as users' usage logs, physical activities and environmental contexts. The core idea is to build a supervised learning framework, where each user is represented as a feature vector and users' demographics are considered as prediction targets. The most important component is to construct features from raw data and then supervised learning models can be applied. We propose a feature construction framework, CFC (contextual feature construction), where each feature is defined as the conditional probability of one user activity under the given contexts. Consequently, besides employing standard supervised learning models, we propose a regularized multi-task learning framework to model different kinds of demographics predictions collectively. We also propose a cost-sensitive classification framework for regression tasks, in order to benefit from the existing dimension reduction methods. Finally, due to the limited training instances, we employ ensemble to avoid overfitting. The experimental results show that the framework achieves classification accuracies on ''gender'', ''job'' and ''marital status'' as high as 96%, 83% and 86%, respectively, and achieves Root Mean Square Error (RMSE) on ''age'' and ''number of family members'' as low as 0.69 and 0.66 respectively, under the leave-one-out evaluation.		Erheng Zhong;Ben Tan;Kaixiang Mo;Qiang Yang	2013	Pervasive and Mobile Computing	10.1016/j.pmcj.2013.07.009	ensembl;multi-task learning;computer science;data science;operating system;mobile technology;machine learning;data mining;computer security	HCI	-22.25017656410588	-45.56923206722589	54755
cead74e154c14913c2b73d5c7dba91dcd114726f	real-time video highlights for yahoo esports		Esports has gained global popularity in recent years and several companies have started offering live streaming videos of esports games and events. This creates opportunities to develop large scale video understanding systems for new product features and services. We present a technique for detecting highlights from live streaming videos of esports game matches. Most video games use pronounced visual effects to emphasize highlight moments; we use CNNs to learn convolution filters of those visual effects for detecting highlights. We propose a cascaded prediction approach that allows us to deal with several challenges arise in a production environment. We demonstrate our technique on our new dataset of three popular game titles, Heroes of the Storm, League of Legends, and Dota 2. Our technique achieves 18 FPS on a single CPU with an average precision of up to 83.18%. Part of our technique is currently deployed in production on Yahoo Esports.	central processing unit;convolution;deployment environment;dota 2;floating point systems;information retrieval;real-time transcription;sensor;streaming media;visual effects	Yale Song	2016	CoRR		computer vision;simulation;computer science;machine learning;multimedia	HCI	-13.933605583447987	-51.48585470158394	54765
97ca407d09c9304b593504536379273b7ce4fd7a	multimedia hashing and networking	multimedia;information retrieval;multimedia information networks;learning systems;data analysis;visualization;hashing;machine learning;big data;multimedia communication;networking	This department discusses multimedia hashing and networking. The authors summarize shallow-learning-based hashing and deep-learning-based hashing. By exploiting successful shallow-learning algorithms, state-of-the-art hashing techniques have been widely used in high-efficiency multimedia storage, indexing, and retrieval, especially in multimedia search applications on smartphone devices. The authors also introduce Multimedia Information Networks (MINets) and present one paradigm of leveraging MINets to incorporate both visual and textual information to reach a sensible event coreference resolution. The goal is to make deep learning practical in realistic multimedia applications.	algorithm;deep learning;hash function;machine learning;programming paradigm;smartphone	Wei Liu;Tongtao Zhang	2016	IEEE MultiMedia	10.1109/MMUL.2016.39	hash function;big data;visualization;computer science;multimedia;data analysis;world wide web;information retrieval	DB	-14.687825337362508	-51.74019060702112	54786
39ccbec03a61e00cf1df071d3c73d57fd8f6bdee	the topological viewshed: embedding topological pointers into digital terrain models to improve gis capability for visual landscape analysis	topology;visibility;viewshed;analysis;landscape	The effort to develop a Digital Earth has made dramatic progress in terms of visualisation and visual data integration for use-cases which demand semantically rich analysis. To provide this analysis and ensure legitimate representations of the spatial data from which visualisation are derived, it is necessary to provide more comprehensive analytical capabilities of the view. Questions of aesthetic valuation of landscape require a richer analytical response than simply ‘whether and possibly how much of’ an object or area of land can be seen. It requires interrogation of the scene as it appears and to distinguish between transient visual effects and those locally invariant to view point change. This paper explores a data structure to support scene analytics. As such, it first reviews the existing techniques from the fields of GIS and computer graphics as to their potential and limitations in providing a qualitatively more nuanced visual analysis. It then introduces a new method of encoding visually apparent relationships into terrain models. A prototype implementation is presented based on the Quad-Edge Triangular Irregular Network, though it is believed that raster or vector implementation would be possible. Although developed primarily with landscape analysis in mind, the method could have wider applicability. ARTICLE HISTORY Received 7 December 2015 Accepted 17 May 2016	computation;computer graphics;current divider;darpa grand challenge;data structure;digital elevation model;freedom of information laws by country;geographic information system;geomatics;information visualization;mash-1;macaulay;naivety;natural language;network topology;norm (social);orthographic projection;prototype;quad-edge;raster graphics;relevance;requirement;triangulated irregular network;value (ethics);visibility graph analysis;visual effects	N. Sang;C. Gold;Donald Miller	2016	Int. J. Digital Earth	10.1080/17538947.2016.1192229	computer vision;viewshed analysis;simulation;geography;geology;visibility;analysis;data mining;landscape;remote sensing	Visualization	-24.103535679079922	-31.31396736526506	54817
70e61fa5ef8400586a11d0f361c9deac41864311	scalable and fast root cause analysis using inter cluster inference	graph theory;pattern clustering;scalable root cause analysis small scale dependency graphs duplicated nodes dependency graph cluster decomposition fault diagnosis techniques communication networks intercluster inference fast root cause analysis;bayes methods;clustering fault diagnosis bayesian network inference process;inference mechanisms;bayes methods quality of service complexity theory inference mechanisms delays fault diagnosis;pattern clustering bayes methods computational complexity fault diagnosis graph theory inference mechanisms;computational complexity;fault diagnosis	The capability to diagnose the root cause of an observed problem precisely and quickly is a desirable feature for large communication networks. However, the design of a technique that is at the same time fast, scalable and accurate is a challenging task. In this paper, we propose a novel method based on inter-cluster inference to overcome the usual limits of fault diagnosis techniques. The approach is based on two important concepts: a cluster decomposition of the dependency graph in order to ensure scalability, and the introduction of duplicated nodes aiming at preserving the end-to-end network view. The evaluation of the proposed approach has demonstrated a significant reduction in the complexity and the computation time of the root cause analysis, since it is based on a set of small-scale dependency graphs.	computation;end-to-end principle;scalability;telecommunications network;time complexity	Leila Bennacer;Laurent Ciavaglia;Samir Ghamri-Doudane;Abdelghani Chibani;Abdelhamid Mellouk	2013	2013 IEEE International Conference on Communications (ICC)	10.1109/ICC.2013.6655104	computer science;graph theory;theoretical computer science;machine learning;data mining;computational complexity theory;statistics	Robotics	-13.53232849105384	-41.996341440269205	54905
cd0673f2201b59a6448dfe7b3695028c011e413f	personalized recommendations based on time-weighted overlapping community detection	dynamic user interests;time weighted association rules;recommender system;overlapping community;personalized recommendations	Capturing and understanding user interests are an important part of social media analytics. Users of social media sites often belong to multiple interest communities, and their interests are constantly changing over time. Therefore, modeling and predicting dynamic user interests poses great challenges to providing personalized recommendations in social media analytics research. We propose a novel solution to this research problem by developing a temporal overlapping community detection method based on time-weighted association rule mining. We conducted experiments using MovieLens and Netflix datasets, and our experimental results show that our proposed approach outperforms several existing methods in recommendation precision and diversity. 2015 Elsevier B.V. All rights reserved.	algorithm;association rule learning;experiment;long tail;movielens;personalization;social media analytics	Haoyuan Feng;Jin Tian;Harry J. Wang;Minqiang Li	2015	Information & Management	10.1016/j.im.2015.02.004	computer science;engineering;data mining;multimedia;world wide web;recommender system	AI	-22.975056294374017	-48.16009491726237	55020
0dceca6bb3ac648c611f7097cf52a9b7f59be6f9	an egocentric look at video photographer identity		Egocentric cameras are being worn by an increasing number of users, among them many security forces worldwide. GoPro cameras already penetrated the mass market, reporting substantial increase in sales every year. As headworn cameras do not capture the photographer, it may seem that the anonymity of the photographer is preserved even when the video is publicly distributed. We show that camera motion, as can be computed from the egocentric video, provides unique identity information. The photographer can be reliably recognized from a few seconds of video captured when walking. The proposed method achieves more than 90% recognition accuracy in cases where the random success rate is only 3%. Applications can include theft prevention by locking the camera when not worn by its rightful owner. Searching video sharing services (e.g. YouTube) for egocentric videos shot by a specific photographer may also become possible. An important message in this paper is that photographers should be aware that sharing egocentric video will compromise their anonymity, even when their face is not visible.	convolutional neural network;data descriptor;elegant degradation;lpc;lock (computer science);optical flow;time-invariant system	Yedid Hoshen;Shmuel Peleg	2016	2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)	10.1109/CVPR.2016.464	computer vision;multimedia;internet privacy	Vision	-28.508447182752	-42.61170784523387	55026
15bf12c70418c1f9998ea6ad21a1abcca0f99f25	apprentissage de représentations pour la prédiction de propagation d'information dans les réseaux sociaux. (representation learning for information diffusion prediction in social network)		In this thesis, we study information diffusion in online social networks. Websites like Facebook or Twitter have indeed become information medias, on which users create and share a lot of data. Most existing models of the information diffusion phenomenon relies on strong hypothesis about the structure and dynamics of diffusion. In this document, we study the problem of diffusion prediction in the context where the social graph is unknown and only user actions are observed. — We propose a learning algorithm for the independant cascades model that does not take time into account. Experimental results show that this approach obtains better results than time-based learning schemes. — We then propose several representations learning methods for this task of diffusion prediction. This let us define more compact and faster models. — Finally, we apply our representation learning approach to the source detection task, where it obtains much better results than graph-based approaches.		Simon Bourigault	2016				ML	-20.462894927361702	-45.48724510224131	55051
08a9e06242def2da45c7c8d5e7cc18d42f34866c	walknet: a neural-network-based interactive walking controller		We present WalkNet, an interactive agent walking movement controller based on neural networks. WalkNet supports controlling the agent’s walking movements with high-level factors that are semantically meaningful, providing an interface between the agent and its movements in such a way that the characteristics of the movements can be directly determined by the internal state of the agent. The controlling factors are defined across the dimensions of planning, affect expression, and personal movement signature. WalkNet employs Factored, Conditional Restricted Boltzmann Machines to learn and generate movements. We train the model on a corpus of motion capture data that contains movements from multiple human subjects, multiple affect expressions, and multiple walking trajectories. The generation process is real-time and is not memory intensive. WalkNet can be used both in interactive scenarios in which it is controlled by a human user and in scenarios in which it is driven by another AI component.	artificial neural network;sneakernet	Omid Alemi;Philippe Pasquier	2017		10.1007/978-3-319-67401-8_2	control theory;artificial neural network;multimedia;boltzmann machine;motion capture;machine learning;expression (mathematics);computer science;artificial intelligence	Robotics	-29.807797035680828	-39.68912434920959	55090
1d192ff6afb606d6a708607af00fce95e134c129	biology - elucidating laws of the unruly jungle with computational approaches to complex ecological networks	network effect;tree algorithm;computer architecture;species interaction;complex system;high performance computer;many body simulation;self organization;cosmological simulation;reconfigurable processor;ecological networks	Ecological networks comprised of diverse species interacting within habitats describe iconic self-organized complex systems. Their nodes are dynamic, highly heterogeneous and constantly evolving in response to their changing environment. Yet, these ungoverned highly diverse and complex ecological networks remain remarkably robust despite catastrophes that destroy huge fractions of the nodes and cause permanent alterations of the environment. Recent work to model these system employs network informatics, visualizations, and high performance computing simulations. Exploring these models demands that the parameters are both fit using rigorous informatics and also varied in innumerable combinations using efficient and powerful computer architectures. This presentation will describe the mechanics of this endeavor as well as several of the most interesting research results including the robustness enhancing roles of network architecture and organism's size and behavioral nonlinearities as well as network effects of species' loss and invasions. A particular future for such endeavors will also described with special attention to implications for general network science.	catastrophe theory;complex systems;computer architecture;habitat;informatics;interaction;network architecture;network science;self-organization;simulation;supercomputer	Neo D. Martinez	2006		10.1145/1188455.1188512	self-organization;simulation;ecological network;computer science;artificial intelligence;theoretical computer science;network effect;biological interaction	ML	-5.629184946543997	-47.64132964567965	55108
85e90f7711aff37b2fe699804c9c1e602822788c	the complexity of influence maximization problem in the deterministic linear threshold model	inapproximation;social network;deterministic model	The influence maximization is an important problem in the field of social network. Informally it is to select few people to be activated in a social network such that their aggregated influence can make as many as possible people active. Kempe et al. gave a $(1-{1 \over e})$ -approximation algorithm for this problem in the linear threshold model and the independent cascade model. In addition, Chen et al. proved that the exact computation of the influence given a seed set is #P-hard in the linear threshold model. Both of the two models are based on randomized propagation, however such information might be obtained by surveys and data mining techniques. This will make great difference on the complexity of the problem. In this note, we study the complexity of the influence maximization problem in deterministic linear threshold model. We show that in the deterministic linear threshold model, there is no n 1?? -factor polynomial time approximation for the problem unless P=NP. We also show that the exact computation of the influence given a seed set can be solved in polynomial time.	expectation–maximization algorithm;threshold model	Zaixin Lu;Wei Zhang;Weili Wu;Joonmo Kim;Bin Fu	2012	J. Comb. Optim.	10.1007/s10878-011-9393-3	mathematical optimization;combinatorics;machine learning;deterministic system;p versus np problem;mathematics;social network	Theory	-16.717105449020302	-43.78152332368049	55140
9a47c388c591a14d0544b852a1682344bdc86744	a semi-supervised method for topic extraction from micro postings	text analysis;information systems world wide web web applications social networks;mathematics of computing discrete mathematics graph algorithms;topic models;visual analytics;information systems information retrieval document representation document topic models;social media	Social networking services have become amajor channel for the digital society to share content, opinions, experiences on activities or events, as well as on products, services and brands. Evaluating digital feedback on the latter can be a valuable asset for companies seeking product and consumer insights. However, the analysis of short, noisy, fragmented, and often subjective textual data still remains a challenge. Typically, the human analyst needs to be actively involved during extraction and modeling to resolve ambiguities that will inevitable arise in such data and to put the model into context. This paper proposes a visual analytics approach that enables a first intuition and exploration of topics appearing in the text corpus, and facilitates the interactive-iterative refinement of the overall topic model describing the stream of tweets. A second contribution is the discussion of efficient graph community detection algorithms to extract initial topics as the starting point of interactive analysis that complement approaches such as LDA. The applicability and utility of the proposed approach is shown for a real-world use case: the analysis of product insights and topic-driven social networks analysis for a specific product line for an international hair styling and cosmetics company.	algorithm;application domain;authentication;disjunctive normal form;download;experience;graph partition;hashtag;information source;iterative method;iterative refinement;natural language processing;refinement (computing);semi-supervised learning;semiconductor industry;social media;social network;structure mining;text corpus;topic model;visual analytics	Georg Fuchs;Hendrik Stange;Ahmad Samiei;Gennady L. Andrienko;Natalia V. Andrienko	2015	it - Information Technology	10.1515/itit-2014-1078	visual analytics;social media;document clustering;computer science;data science;topic model;world wide web;information retrieval	NLP	-24.333910677709387	-51.5502674601158	55172
86cb522b6b5a9b936fe5f5a3b48be45a9573f40d	link sharing on twitter during popular events: implications for social navigation on websites	media twitter navigation web pages awards activities facebook tag clouds;tweets link sharing twitter popular events social navigation websites social media data web page recommendation;social networking online;social networking online recommender systems;recommender systems	"""The goal of this research is to explore how social media data can be used to help users find information on websites. This paper presents the first stage in this line of research and focuses on the characteristics of links (i.e. website URLs) shared on social media to recommend relevant and popular web pages within the website to others. Specifically, the paper reports on a study of Twitter messages (""""tweets"""") during four different events. Tweets were collected and those containing links were analyzed. The findings from this study encourage us to proceed to the next stage of the research which is to develop and test a social navigation tool on websites incorporating information from social media in order to improve navigation within a website."""	social media;web page	Naureen Nizam;Carolyn R. Watters;Anatoliy A. Gruzd	2014	2014 47th Hawaii International Conference on System Sciences	10.1109/HICSS.2014.222	social web;social media;social media optimization;computer science;multimedia;internet privacy;world wide web;recommender system	HCI	-26.0078756110448	-48.95090729175018	55253
b1df80988b6d9fedd8ea476b9e30a98313ed74cc	beyond who and what: data driven approaches for user characterization		Social media and technology have drastically transformed the social and information networks around us. They have impacted how we communicate with others, search for information, and even how we express our personal opinions. Further, in this era of big data, not only are the online services collecting vast variety of user data, but we, as users, are also readily divulging significant amounts of information. Together, massive datasets obtained from diverse sources such as organizations and user generated content give us the opportunity to explore and understand complex behavior of both individuals and communities. This proposal aims at designing generalizable and scalable data-driven frameworks to gain a deeper understanding of the users, explain their actions and preferences, and infer personal traits. The proposed models will enable us to move beyond asking the conventional questions of who and what, and reveal answers about how and why. Given the varying digital persona of users motivated by their personal preferences and social attributes, we characterize users in two distinct domains: online health and peace studies. The models are designed to solve various real-world challenges to maximize their broader impact.	avatar (computing);big data;e-services;scalability;social media;user-generated content	Aastha Nigam	2018		10.1145/3159652.3170455	data mining;user modeling;user-generated content;persona;computer science;scalability;big data;social media;data-driven	Web+IR	-26.126928106529956	-46.820412496315036	55268
35ca53ed70fa42545f566cb6dfc86e2abb2b9c61	collaborative filtering process in a whole new light	ikee lib auth gr;conference proceedings articles;βκπ;collaborative filtering system;information retrieval;e commerce;information filtering;ικee;websearch;data mining;bkp;recommender system;auth;collaboration information filtering information filters recommender systems information retrieval data mining performance evaluation informatics electronic commerce motion pictures;collaborative filtering;βιβλιοθήκη και κέντρο πληροφόρησης;data mining collaborative filtering system recommender system e commerce application information retrieval;nearest neighbor;information filters data mining information filtering;ιδρυματικό καταθeτήριο;e commerce application;απθ;information filters;library and information center;aristotle university of thessaloniki ικee;ikee;institutional repository	"""Collaborative filtering (CF) systems are gaining widespread acceptance in recommender systems and e-commerce applications. These systems combine information retrieval and data mining techniques to provide recommendations for products, based on suggestions of users with similar preferences. Nearest-neighbor CF process is influenced by several factors, which were not examined carefully in past work. In this paper, we bring to surface these factors in order to identify existing false beliefs. Moreover, by being able to view the """"big picture"""" from the CF process, we propose new approaches that substantially improve the performance of CF algorithms. For instance, we obtain more than 40% percent increase in precision in comparison to widely-used CF algorithms. We perform an extensive experimental evaluation, with several real data sets, and produce results that invalidate some existing beliefs and illustrate the superiority of the proposed extensions"""	algorithm;bl (logic);baseline (configuration management);collaborative filtering;computation;data mining;e-commerce;hierarchical state routing;information retrieval;online and offline;recommender system;run time (program lifecycle phase);scalability;similarity measure;singular value decomposition;sparse matrix;undefined behavior	Panagiotis Symeonidis;Alexandros Nanopoulos;Apostolos N. Papadopoulos;Yannis Manolopoulos	2006	2006 10th International Database Engineering and Applications Symposium (IDEAS'06)	10.1109/IDEAS.2006.55	computer science;collaborative filtering;data mining;database;world wide web;k-nearest neighbors algorithm;information retrieval;recommender system	DB	-20.55392796756924	-48.76199881451378	55283
2255e3a14210b732628ecfb5722e570786bb7628	users' reading habits in online news portals	click behavior;user modeling;news category	The aim of this study is to survey reading habits of users of an online news portal. The assumption motivating this study is that insight into the reading habits of users can be helpful to design better news recommendation systems. We estimated the transition probabilities that users who read an article of one news category will move to read an article of another (not necessarily distinct) news category. For this, we analyzed the users' click behavior within plista data set. Key findings are the popularity of category local, loyalty of readers to the same category, observing similar results when addressing enforced click streams, and the case that click behavior is highly influenced by the news category.	click fraud;markov chain;portals;recommender system	Cagdas Esiyok;Benjamin Kille;Brijnesh J. Jain;Frank Hopfgartner;Sahin Albayrak	2014		10.1145/2637002.2637038	user modeling;computer science;multimedia;world wide web	Web+IR	-25.454929910791314	-47.992133360247436	55298
b6acc22ae8222c2cc03375cf04680ed58619103a	mobile information service adapted to social, temporal and dynamic situational requirements of individuals	prior probability;model generation;bayes methods;rough set theory;bayesian rough set model;rough vague sets;social preference mobile information service human thinking personal preference short term preference long term preference dynamic preference static preference;books motion pictures mobile handsets mobile computing computer industry systems engineering and theory humans prototypes wireless communication hardware;variable precision rough set;rough set;mobile computing information services;pawlak rough set model	Human thinking may vary according to the situation. Consequently, the requirements also change according to the situation. In everyday life, we find some requirements are changeable such as: cuisine, refreshment. Some requirements are not changeable such as: type of book, movies genre. Furthermore, people often make choices not only based on their personal preference but also opinions or choices of other people such as their companion. From various requirements, we need a service that can provide desired information for the user depending on the prevailing situation on each occasion. In this paper, we have proposed information service adapted to three dimensions of the user requirements which are temporal: short term and long term preference, dynamic: dynamic and static preference, and social preference: the user and companion preference. This study also creates rules, algorithm to this service.	algorithm;requirement;user requirements document	Sineenard Pinyapong;Hiroko Shoji;Toshikazu Kato	2007	The 2nd IEEE Asia-Pacific Service Computing Conference (APSCC 2007)	10.1109/APSCC.2007.56	rough set;computer science;artificial intelligence;machine learning;data mining;dominance-based rough set approach	Visualization	-29.955895237785732	-24.582439804018218	55352
007b87d74009b0cc1397417bc9aa834f3e200e82	transfer learning with graph co-regularization	nmf;feature extraction knowledge transfer optimization matrix decomposition data mining robustness bridges;graph theory;matrix factorization;statistical property;information technology and systems;learning;text mining;text analysis graph theory image classification knowledge management learning artificial intelligence matrix decomposition;negative transfer;latent factors;knowledge management;public text datasets;feature extraction or construction computing methodologies artificial intelligence learning knowledge acquisition information technology and systems database management database applications;bridges;image classification;text analysis;data mining;database management;matrix factorization models;classifier;domain difference;gtl;labeled data;matrix decomposition;knowledge structure;feature extraction;knowledge acquisition;input data;source domain;classifier labeled data source domain knowledge structure input data domain difference graph coregularized transfer learning matrix factorization models gtl latent factors knowledge transfer statistical property geometric structure nmf nmtf public text datasets image datasets;transfer learning;nmtf;knowledge transfer;artificial intelligence;robustness;optimization;database applications;graph coregularized transfer learning;learning artificial intelligence;feature extraction or construction;graph regularization;image datasets;computing methodologies;geometric structure	Transfer learning is established as an effective technology to leverage rich labeled data from some source domain to build an accurate classifier for the target domain. The basic assumption is that the input domains may share certain knowledge structure, which can be encoded into common latent factors and extracted by preserving important property of original data, e.g., statistical property and geometric structure. In this paper, we show that different properties of input data can be complementary to each other and exploring them simultaneously can make the learning model robust to the domain difference. We propose a general framework, referred to as Graph Co-Regularized Transfer Learning (GTL), where various matrix factorization models can be incorporated. Specifically, GTL aims to extract common latent factors for knowledge transfer by preserving the statistical property across domains, and simultaneously, refine the latent factors to alleviate negative transfer by preserving the geometric structure in each domain. Based on the framework, we propose two novel methods using NMF and NMTF, respectively. Extensive experiments verify that GTL can significantly outperform state-of-the-art learning methods on several public text and image datasets.	baseline (configuration management);experiment;gunning transceiver logic;information privacy;latent variable;non-negative matrix factorization;real life	Mingsheng Long;Jianmin Wang;Guiguang Ding;Dou Shen;Qiang Yang	2012	IEEE Transactions on Knowledge and Data Engineering	10.1109/TKDE.2013.97	text mining;computer science;artificial intelligence;machine learning;pattern recognition;data mining;database;matrix decomposition	AI	-14.828233663368442	-47.67708310697099	55355
d8b7a36933881312a6ce24e9a91be15cffcb5e3b	hetpathmine: a novel transductive classification algorithm on heterogeneous information networks		Transductive classification (TC) using a small labeled data to help classifying all the unlabeled data in information networks. It is an important data mining task on information networks. Various classification methods have been proposed for this task. However, most of these methods are proposed for homogeneous networks but not for heterogeneous ones, which include multi-typed objects and relations and may contain more useful semantic information. In this paper, we firstly use the concept of meta path to represent the different relation paths in heterogeneous networks and propose a novel meta path selection model. Then we extend the transductive classification problem to heterogeneous information networks and propose a novel algorithm, named HetPathMine. The experimental results show that: (1) HetPathMine can get higher accuracy than the existing transductive classification methods and (2) the weight obtained by HetPathMine for each meta path is consistent with human intuition or real-world situations.	algorithm;data mining;knowledge engineering;symbolic computation;type system	Chen Luo;Renchu Guan;Zhe Wang;Chenghua Lin	2014		10.1007/978-3-319-06028-6_18	computer science;machine learning;pattern recognition;data mining	ML	-14.379028632837626	-47.2185681742978	55391
7cc066539a0d44af05a62309a94cae3137278a91	design and analysis of novel similarity measure for clustering and classification of high dimensional text documents	commonality;feature vector;similarity;feature set	The main idea of this research is to first design the similarity measure which can be used to of find the similarity between any two text documents and use the same to perform clustering. The similarity measure designed is analyzed to study the behavior in the best case, average case and worst case situations. The drawback of Euclidean, Cosine, Jaccard similarity measures are overcome using the proposed measure. The similarity measure is evaluated considering reuters-21578 dataset. The results show that the proposed measure overcomes other measures.	best, worst and average case;cluster analysis;jaccard index;similarity measure	G. SureshReddy;T. V. Rajinikanth;A. Ananda Rao	2014		10.1145/2659532.2659615	semantic similarity;similarity;feature vector;computer science;pattern recognition;normalized compression distance;data mining;similarity;jaccard index;information retrieval	Web+IR	-5.0832995645426955	-42.86095813053751	55395
091c08ce65e7c21d2340ae2d0159c41a2565e2c3	community detection in social network: an experience with directed graphs			social network	Soumya Banerjee;Sumit Singh;Eiman Tamah Al-Shammari	2014		10.1007/978-1-4614-6170-8_49	machine learning;communication;social psychology	Theory	-19.921616712728536	-41.8795822697315	55416
ebcbda249c55189b25b2d43f3dfcd71fbae2ca9c	discovering burst areas in fast evolving graphs	haar wavelet;evolving graphs;sensor network;social network;burst areas;high speed	Evolving graphs are used to model the relationship variations between objects in many application domains such as social networks, sensor networks, and telecommunication. In this paper, we study a new problem of discovering burst areas that exhibit dramatic changes during some periods in evolving graphs. We focus on finding the top-k results in a stream of fast graph evolutions. This problem is challenging because when the graph evolutions are coming in a high speed, the solution should be capable of handling a large amount of evolutions in short time and returning the top-k results as soon as possible. The experimental results on real data sets show that our proposed solution is very efficient and effective.	computation;haar wavelet;social network;wavelet tree	Zheng Liu;Jeffrey Xu Yu	2010		10.1007/978-3-642-12026-8_15	wireless sensor network;computer science;theoretical computer science;machine learning;social network	ML	-9.060878387764312	-38.3490962197389	55483
660e4e9f7797c393a57fb981b15a04e98680dc49	recommendations for web service composition by mining usage logs		Web service composition has been one of the most researched topics of the past decade. Novel methods of web service composition are being proposed in the literature include Semantics-based composition, WSDLbased composition. Although these methods provide promising results for composition, search and discovery of web service based on QoS parameter of network and semantics or ontology associated with WSDL, they do not address composition based on usage of web service. Web Service usage logs capture time series data of web service invocation by business objects, which innately captures patterns or workflows associated with business operations. Web service composition based on such patterns and workflows can greatly streamline the business operations. In this research work, we try to explore and implement methods of mining web service usage logs. Main objectives include Identifying usage association of services. Linking one service invocation with other, Evaluation of the causal relationship between associations of services.	adobe streamline;association rule learning;business object;causality;mike lesser;quality of service;recommender system;service composability principle;time series;web services description language;web service	R. Vivek;Prasad Mirje;N. Sushmitha	2016	CoRR	10.5121/ijdkp.2016.6207	web service;web application security;web mining;web development;web modeling;web analytics;web mapping;web standards;postback;computer science;service delivery framework;ws-policy;data mining;database;web 2.0;world wide web	Web+IR	-26.8740754788133	-49.26438894167019	55506
03d09018b004d899fba9d9794c67246ed766ab1d	maximizing a record’s standing in a relation	asia europe	Given a database table with records that can be ranked, an interesting problem is to identify selection conditions for the table, which are qualified by an input record and render its ranking as high as possible among the qualifying tuples. In this paper, we study this standing maximization problem, which finds application in object promotion and characterization. After showing the hardness of the problem, we propose greedy methods, which are experimentally shown to achieve high accuracy compared to exhaustive enumeration, while scaling very well to the problem input size. Our contributions include a linear-time algorithm for determining the optimal selection range for an ordinal attribute and techniques for choosing and prioritizing the most promising selection predicates to apply. Experiments on real datasets confirm the effectiveness and efficiency of our techniques.	approximation algorithm;database;duality (optimization);entropy maximization;experiment;greedy algorithm;heuristic (computer science);image scaling;information;np-hardness;ordinal data;predicate (mathematical logic);symmetric multiprocessing;table (database);time complexity;usability	Yu Tang;Yilun Cai;Nikos Mamoulis	2015	2016 IEEE 32nd International Conference on Data Engineering (ICDE)	10.1109/ICDE.2016.7498409	computer science;machine learning;data mining;database;algorithm;statistics	DB	-6.791512463237835	-34.97690889351738	55557
88f66a39f4fe53270fd1afe00f3e76bc27ac728e	on the complexity of package recommendation problems	top-k recommendation;top-k item;query language;model recommendation system;package recommendation problem;adjustment recommendation;compatibility constraint;selection criterion;item selection;top-k package;express compatibility constraint;complexity;point of interest;recommender system;upper and lower bounds;satisfiability	Recommendation systems aim to recommend items that are likely to be of interest to users. This paper investigates several issues fundamental to such systems.  We model recommendation systems for packages of items. We use queries to specify multi-criteria for item selections and express compatibility constraints on items in a package, and use functions to compute the cost and usefulness of items to a user. We study recommendations of points of interest, to suggest top-k packages. We also investigate recommendations of top-k items, as a special case. In addition, when sensible suggestions cannot be found, we propose query relaxation recommendations to help users revise their selection criteria, or adjustment recommendations to guide vendors to modify their item collections. We identify several problems, to decide whether a set of packages makes a top-k recommendation, whether a rating bound is maximum for selecting top-k packages, whether we can relax the selection query to find packages that users want, and whether we can update a bounded number of items such that the users' requirements can be satisfied. We also study function problems for computing top-k packages, and counting problems to find how many packages meet the user's criteria. We establish the upper and lower bounds of these problems, all matching, for combined and data complexity. These results reveal the impact of variable sizes of packages, the presence of compatibility constraints, as well as a variety of query languages for specifying selection criteria and compatibility constraints, on the analyses of these problems.	function problem;linear programming relaxation;matching (graph theory);point of interest;query language;recommender system;requirement;utility	Ting Deng;Wenfei Fan;Floris Geerts	2012		10.1145/2213556.2213592	library science;computer science;operations research	DB	-11.464876831294706	-36.80786446426005	55570
33f90ecc435eb211b7cfe2093acdc3970c73da79	a recommendation approach dealing with multiple market segments	market segments online dating network recommendation;social networking online gaussian processes human factors mixture models;online dating network;gaussian processes;receivers tensile stress boosting training testing social network services statistics;human factors;recommendation approach dealing gmm gaussian mixture model recommendation strategies user need customisation partner recommendation dating network online dating social networks market segments;social networking online;recommendation;market segments;mixture models	A new community and communication type of social networks - online dating - are gaining momentum. With many people joining in the dating network, users become overwhelmed by choices for an ideal partner. A solution to this problem is providing users with partners recommendation based on their interests and activities. Traditional recommendation methods ignore the users' needs and provide recommendations equally to all users. In this paper, we propose a recommendation approach that employs different recommendation strategies to different groups of members. A segmentation method using the Gaussian Mixture Model (GMM) is proposed to customize users' needs. Then a targeted recommendation strategy is applied to each identified segment. Empirical results show that the proposed approach outperforms several existing recommendation methods.	google map maker;mixture model;social network	Lin Chen;Richi Nayak	2013	2013 IEEE/WIC/ACM International Joint Conferences on Web Intelligence (WI) and Intelligent Agent Technologies (IAT)	10.1109/WI-IAT.2013.13	engineering;marketing;advertising;world wide web	AI	-20.21265570730853	-50.17228287139332	55665
a40a64e3c5e7589811c5c9990a1b3b7504d31b70	a tree-based approach for event prediction using episode rules over event streams	event stream;efficient algorithm;continuous query;minimal occurrence;episode rules;tree structure;prediction	Event prediction over event streams is an important problem with broad applications. For this problem, rules with predicate events and consequent events are given, and then current events are matched with the predicate events to predict future events. Over the event stream, some matches of predicate events may trigger duplicate predictions, and an effective scheme is proposed to avoid such redundancies. Based on the scheme, we propose a novel approach CBS-Tree to efficiently match the predicate events over event streams. The CBS-Tree approach maintains the recently arrived events as a tree structure, and an efficient algorithm is proposed for the matching of predicate events on the tree structure, which avoids exhaustive scans of the arrived events. By running a series of experiments, we show that our approach is more efficient than the previous work for most cases.		Chung-Wen Cho;Ying Zheng;Yi-Hung Wu;Arbee L. P. Chen	2008		10.1007/978-3-540-85654-2_24	prediction;discrete event simulation;machine learning;pattern recognition;data mining;tree structure;event tree;statistics	ML	-6.644845131055541	-36.384573158028935	55677
26ff2d164cf5fbfeb6605d6b75374b114030f1a9	efficient computation of the weighted clustering coefficient		The clustering coefficient of an unweighted network has been extensively used to quantify how tightly connected is the neighbor around a node and it has been widely adopted for assessing the quality of nodes in a social network. The computation of the clustering coefficient is challenging since it requires to count the number of triangles in the graph. Several recent works proposed efficient sampling, streaming and MapReduce algorithms that allow to overcome this computational bottleneck. As a matter of fact, the intensity of the interaction between nodes, that is usually represented with weights on the edges of the graph, is also an important measure of the statistical cohesiveness of a network. Recently various notions of weighted clustering coefficient have been proposed but all those techniques are hard to implement on large-scale graphs.	clustering coefficient;computation	Silvio Lattanzi;Stefano Leonardi	2014		10.1007/978-3-319-13123-8_4	correlation clustering;k-medians clustering;canopy clustering algorithm;cure data clustering algorithm;cluster analysis	NLP	-12.417551554271862	-41.33052740583607	55706
5353d71edbdef617c1407b4324c45c185bed9119	whom should i trust?: the impact of key figures on cold start recommendations	science general;trust network;cold start problem;user profile;social preferences;recommender system;collaborative filtering	Generating adequate recommendations for newcomers is a hard problem for a recommender system (RS) due to lack of detailed user profiles and social preference data. Empirical evidence suggests that the incorporation of a trust network among the users of the RS can leverage such 'cold start' (CS) recommendations. Hence, new users should be encouraged to connect to the network as soon as possible. But whom should new users connect to? Given the impact this choice has on the delivered recommendations, it is critical to guide newcomers through this early stage connection process. In this paper, we identify key figures in the trust network (in particular mavens, connectors and frequent raters) and investigate their influence on the coverage and accuracy of a collaborative filtering RS. Using a dataset from Epinions.com, we demonstrate that the generated recommendations for new user are more beneficial if they connect to an identified key figure compared to a random user.	cold start;collaborative filtering;recommender system;user profile	Patricia Victor;Chris Cornelis;Ankur Teredesai;Martine De Cock	2008		10.1145/1363686.1364174	cold start;computer science;knowledge management;social preferences;artificial intelligence;collaborative filtering;machine learning;data mining;database;management;world wide web;computer security;recommender system	ECom	-19.878968764351576	-45.9176465174098	55723
52b6c41194d3082ab676a49014c1a1dc072ebe60	icme 2016 image recognition grand challenge	mars;image recognition;dogs image recognition search engines mars visualization training measurement;measurement;search engines;dogs;training;msr irc msr image recognition challenge real world large scale image retrieval real world large scale image recognition clickture dataset large scale real world image click data web image dog related image subset dog breed recognition open platform prajna hub;visualization;image retrieval image recognition;dog breed recognition grand challenge image recognition challenge prajna hub clickture	This paper summarizes the MSR Image Recognition Challenge (IRC) running with ICME 2016 Grand Challenges. Since 2013, Microsoft Research has hosted a series of IRCs to motivate the academic and industrial community to solve real-world large-scale image retrieval and recognition problems. This IRC in ICME 2016 continually leveraged the Clickture dataset [1], a large-scale real-world image click data consisting of 40M web images, and a derived subset of 95K dog-related images for the challenge of dog breed recognition. To conduct fair and efficient evaluation, and make the recognition result more reproducible and accessible, the contest runs on an open platform, Prajna Hub, which can help convert a research algorithm into an online service with minimal effort of just a few hours. As part of the ICME 2016 Grand Challenges, more than 30 teams participated this year's MSR IRC and 10 teams successfully finished the task. More details of data, system, metrics, process, and result are described in this paper.	algorithm;clickstream;computer vision;grand challenges;image retrieval;internet relay chat;microsoft research;online service provider;open platform;world file	Yuxiao Hu;Jin Li;Sanjeev Mehrotra	2016	2016 IEEE International Conference on Multimedia & Expo Workshops (ICMEW)	10.1109/ICMEW.2016.7574663	computer vision;mars exploration program;simulation;visualization;telecommunications;computer science;machine learning;data mining;face recognition grand challenge;world wide web;measurement	Robotics	-13.50041279800664	-51.565649488185436	55737
aae712791971e1603a5f1743104503256c6a8176	efficient probabilistic supergraph search	probabilistic logic search problems upper bound synchronization time factors australia electronic mail	"""Given a query graph <inline-formula><tex-math notation=""""LaTeX"""">$q$</tex-math><alternatives> <inline-graphic xlink:type=""""simple"""" xlink:href=""""zhang-ieq1-2499201.gif""""/></alternatives></inline-formula>, retrieving the data graphs <inline-formula><tex-math notation=""""LaTeX"""">$g$</tex-math><alternatives> <inline-graphic xlink:type=""""simple"""" xlink:href=""""zhang-ieq2-2499201.gif""""/></alternatives></inline-formula> from a set <inline-formula> <tex-math notation=""""LaTeX"""">$D$</tex-math><alternatives><inline-graphic xlink:type=""""simple"""" xlink:href=""""zhang-ieq3-2499201.gif""""/> </alternatives></inline-formula> of data graphs such that <inline-formula><tex-math notation=""""LaTeX"""">$q$</tex-math> <alternatives><inline-graphic xlink:type=""""simple"""" xlink:href=""""zhang-ieq4-2499201.gif""""/></alternatives></inline-formula> contains <inline-formula><tex-math notation=""""LaTeX"""">$g$</tex-math><alternatives> <inline-graphic xlink:type=""""simple"""" xlink:href=""""zhang-ieq5-2499201.gif""""/></alternatives></inline-formula>, namely supergraph containment search, is fundamental in graph data analysis with a wide range of real applications. It is very challenging due to the NP-Completeness of subgraph isomorphism testing. Driven by many real applications, in this paper, we study the problem of probabilistic supergraph search; that is, given a set <inline-formula><tex-math notation=""""LaTeX"""">$D$ </tex-math><alternatives><inline-graphic xlink:type=""""simple"""" xlink:href=""""zhang-ieq6-2499201.gif""""/></alternatives></inline-formula> of uncertain data graphs, a certain query graph <inline-formula><tex-math notation=""""LaTeX"""">$q$</tex-math><alternatives> <inline-graphic xlink:type=""""simple"""" xlink:href=""""zhang-ieq7-2499201.gif""""/></alternatives></inline-formula> and a probability threshold <inline-formula><tex-math notation=""""LaTeX"""">$\theta$</tex-math><alternatives> <inline-graphic xlink:type=""""simple"""" xlink:href=""""zhang-ieq8-2499201.gif""""/></alternatives></inline-formula>, we retrieve the data graphs <inline-formula><tex-math notation=""""LaTeX"""">$g^{u}$</tex-math><alternatives> <inline-graphic xlink:type=""""simple"""" xlink:href=""""zhang-ieq9-2499201.gif""""/></alternatives></inline-formula> from <inline-formula> <tex-math notation=""""LaTeX"""">$D$</tex-math><alternatives><inline-graphic xlink:type=""""simple"""" xlink:href=""""zhang-ieq10-2499201.gif""""/> </alternatives></inline-formula> such that the probability of <inline-formula><tex-math notation=""""LaTeX"""">$q$</tex-math> <alternatives><inline-graphic xlink:type=""""simple"""" xlink:href=""""zhang-ieq11-2499201.gif""""/></alternatives></inline-formula> containing <inline-formula><tex-math notation=""""LaTeX"""">$g^{u}$</tex-math><alternatives> <inline-graphic xlink:type=""""simple"""" xlink:href=""""zhang-ieq12-2499201.gif""""/></alternatives></inline-formula> is not smaller than <inline-formula><tex-math notation=""""LaTeX"""">$\theta$</tex-math><alternatives> <inline-graphic xlink:type=""""simple"""" xlink:href=""""zhang-ieq13-2499201.gif""""/></alternatives></inline-formula>. We show that besides the NP-Completeness of subgraph isomorphism testing, the problem of calculating probabilities is #P-Complete; thus, it is even more challenging than the supergraph containment search. To tackle the computational hardness, we first propose two novel pruning rules, based on probabilistic connectivity and features, respectively, to efficiently prune non-promising data graphs. Then, efficient verification algorithms are developed with the aim of sharing computation and terminating non-promising computation as early as possible. Extensive performance studies on both real and synthetic data demonstrate the efficiency and effectiveness of our techniques in practice."""	algorithm;computation;np-completeness;newman's lemma;p-complete;sharp-p-complete;subgraph isomorphism problem;synthetic data;uncertain data;xlink	Wenjie Zhang;Xuemin Lin;Ke Zhu;Gaoping Zhu	2016	IEEE Transactions on Knowledge and Data Engineering	10.1109/ICDE.2016.7498415	computer science;artificial intelligence;theoretical computer science;data mining	DB	-7.372711093152885	-37.47713796657104	55786
ba5875031968109e5ab726621aa4c397d2934e8f	hybrid meta-filtering system for cultural monument related recommendations		A two-phase monument recommendation concept is presented. The system ranks the alternative destinations by using the point and click technique during the process. The core of the system is a hybrid image filtering mechanism, which utilize both collaborative and content-based filtering. At first, the user profile is modelled in the form of a distance matrix, exploiting the user’s annotations over a small set of descriptive images. At the same time, user’s profile is compared to other profiles; the closest profiles are utilized to refine the distance matrix. Then, the system provides relevant images to the user asking him/her to select few. The selected images are used in order to rank the alternative monuments.	distance matrix;exploit (computer security);feature vector;filter (signal processing);international association of privacy professionals;point and click;profiling (computer programming);recommender system;semiconductor industry;supervised learning;two-phase commit protocol;user profile	Eftychios Protopapadakis;Nikolaos D. Doulamis;Athanasios Voulodimos	2017		10.5220/0006347104360443	geography;archaeology;physical geography	AI	-26.963959158967917	-50.50893846852931	55844
93eb4a69f82fea88c48b9c44a2f83eb90edf1e1b	mining frequent tree-like patterns in large datasets	frequent pattern;large dataset;sequential patterns;dynamic program;frequent patterns;data mining;system integration;tree structure;tree like patterns;world wide web;simulation analysis;sequential pattern mining;sequential pattern	Sequential pattern mining is crucial to data mining domains. This paper proposes a novel data mining approach for exploring hierarchical tree structures, named tree-like patterns, representing the relationships for a pair of items in a sequence. Using tree-like patterns, the relationships for a pair of items can be identified in terms of the cause and effect. A novel technique that efficiently counts support values for tree-like patterns using a queue structure is proposed. In addition, this paper addresses an efficient scheme for determining the frequency of a tree-like pattern in a sequence using a dynamic programming approach. Each tree-like pattern embedded in a sequence is considered to have a certain valuable meaning or the degree of importance used in different applications. Two addressed formulas are applied to determine the degree of significance for a specific sequence, which denotes the degree of consecutive items in a tree-like pattern for a sequence. The larger the degree of significance a tree-like pattern has, the more the tree-like pattern is compacted in the sequence. The characteristics differentiating the explored patterns from those obtained with other schemes are discussed. A simulation analysis of the proposed data mining approach is utilized to demonstrate its efficacy. Finally, the proposed approach is designed and implemented in a data mining system integrated into a novel e-learning platform.		Tzung-Shi Chen;Shih-Chun Hsu	2007	Data Knowl. Eng.	10.1016/j.datak.2006.07.003	sequential pattern mining;computer science;bioinformatics;data science;data mining;tree structure;system integration	ML	-5.9831633802536555	-35.91166913072367	55864
7774757fbd58a13e53560535ec7952f7ea426410	input modeling for hospital simulation models using electronic messages	electronic messaging;health care;comprehensive data source;electronic communication exchanges;electronic messages;health care organizations;hospital simulation models;hospital simulations;patient flow paths;resource allocation	Health care organizations function in a complex, non-integrated setting, yet the coordination of information, tasks, and equipment across multiple units is essential for productive operations. A variety of simulation models of hospitals exist; however, few reflect resource sharing across multiple departments. Furthermore few models capture the inherent heterogeneity of a hospital's patient mix which plays a crucial role in determining how care is delivered and resources allocated. Patient flow paths can be used as input data to provide systematic insight into resource allocation processes and medical care within a hospital. To date, flow path approaches to studying hospital operations have been hindered by lack of a comprehensive data source. This tutorial describes how electronic communication exchanges between hospital departments are used to create an input model for hospital simulations.	simulation	Renata A. Konrad;Mark A. Lawley	2009	Proceedings of the 2009 Winter Simulation Conference (WSC)		shared resource;data modeling;simulation;resource allocation;computer science;knowledge management;resource management;simulation modeling;information system;health care	HCI	-16.706968008374297	-24.413499994230243	56088
12ed44db5ef8237d9c495cbedda5b1e30317ca4a	a model-based approach to attributed graph clustering	attributed graph clustering;community detection;distance measure;graph clustering;model based approach;drntu engineering computer science and engineering;data mining;probabilistic inference;bayesian method;conference paper;probabilistic model;model based clustering	Graph clustering, also known as community detection, is a long-standing problem in data mining. However, with the proliferation of rich attribute information available for objects in real-world graphs, how to leverage structural and attribute information for clustering attributed graphs becomes a new challenge. Most existing works take a distance-based approach. They proposed various distance measures to combine structural and attribute information. In this paper, we consider an alternative view and propose a model-based approach to attributed graph clustering. We develop a Bayesian probabilistic model for attributed graphs. The model provides a principled and natural framework for capturing both structural and attribute aspects of a graph, while avoiding the artificial design of a distance measure. Clustering with the proposed model can be transformed into a probabilistic inference problem, for which we devise an efficient variational algorithm. Experimental results on large real-world datasets demonstrate that our method significantly outperforms the state-of-art distance-based attributed graph clustering method.	algorithm;attributed graph grammar;cluster analysis;data mining;graph (discrete mathematics);statistical model;variational principle	Zhiqiang Xu;Yiping Ke;Yi Wang;Hong Cheng;James Cheng	2012		10.1145/2213836.2213894	correlation clustering;statistical model;constrained clustering;data stream clustering;null model;k-medians clustering;fuzzy clustering;bayesian probability;computer science;canopy clustering algorithm;machine learning;consensus clustering;pattern recognition;cure data clustering algorithm;data mining;clustering coefficient;hierarchical clustering;cluster analysis;brown clustering;community structure;affinity propagation;clustering high-dimensional data;conceptual clustering	DB	-13.905762680157963	-45.552367511627004	56173
79ee42aa1203e20f89b2324e865611374c9e6ed6	grasp: a matlab toolbox for graph signal processing	graph signal processing	The GraSP toolbox aims at processing and visualizing graphs and graphs signal with ease. In the demo, we show those capabilities using several examples from the literature and from our own experiments.	experiment;matlab;signal processing	Benjamin Girault;Shrikanth (Shri) Narayanan;Antonio Ortega;Paulo Gonçalves;Eric Fleury	2017	2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)	10.1109/ICASSP.2017.8005300	computer science;theoretical computer science;machine learning;distributed computing	Robotics	-32.53748484011634	-31.562639783589017	56200
e13f7e3abf70680bc5eaec5b806678d0b0ed99d6	towards social-aware ridesharing group query services	social acquaintance location based services query processing ridesharing group queries;vehicles social network services cities and towns algorithm design and analysis indexes silicon query processing	With the deep penetration of smartphones and geo-locating devices, ridesharing is envisioned as a promising solution to transportation-related problems in metropolitan cities, such as traffic congestion and air pollution. Despite the potential to provide significant societal and environmental benefits, ridesharing has not so far been as popular as expected. Notable barriers include social discomfort and safety concerns when traveling with strangers. To overcome these barriers, in this paper, we propose a new type of Social-aware Ridesharing Group (SaRG) queries which retrieve a group of riders by taking into account their social connections and spatial proximities. While SaRG queries are of practical usefulness, we prove that, however, the SaRG query problem is NP-hard. Thus, we design an efficient algorithm with a set of powerful pruning techniques to tackle this problem. We also present several incremental strategies to accelerate the search speed by reducing repeated computations. Moreover, we propose a novel index tailored to our problem to further speed up query processing. Experimental results on real datasets show that our proposed algorithms achieve desirable performance.	approximation algorithm;computation;database;np-hardness;network congestion;personalization;smartphone;speedup	Yafei Li;Rui Chen;Lei Chen;Jianliang Xu	2017	IEEE Transactions on Services Computing	10.1109/TSC.2015.2508440	data mining;speedup;computer science;algorithm design;distributed computing;traffic congestion	DB	-14.241725536143843	-36.61454314022487	56263
1f3cca3426db167d067ebb9b72375508972c0e50	collaborative resource discovery in social tagging systems	lsi;resource discovery;semantic representation;conference_paper;tucker decomposition;tensor;search;svd;latent semantic indexing;experimental evaluation;social tagging;point of view;data structure;semantic association	Social tagging systems which allow users to create, edit and share collections of internet resources associated with tags in a collaborative fashion are growing in popularity in recent years. The rapidly growing amount of shared data in these folksonomies, i.e., taxonomies created by the folk, presents new technical challenges involved with discovering resources which are likely of interest to the user. Social tags which reflect the meaning of resources from the user's points of view provide an opportunity to enhance the quality of retrieval. In this paper, we introduce a novel framework to search relevant resources to the user query by incorporating information obtained from folksonomies' underlying data structures consisting of a set of user/tag/resource triplets. In contrast to traditional retrieval and recommendation techniques which represent a collection by a matrix, we represent our data as a third-order tensor on which a novel Cube Latent Semantic Indexing (CubeLSI) technique is proposed to capture latent semantic associations between tags. With the latent semantic representation we show how to rank relevant resources according to their relevance to user queries. The excellent performance of the method is demonstrated by an experimental evaluation on the deli.cio.us dataset.	cube;data structure;folksonomy;relevance;taxonomy (general)	Bin Bi;Lifeng Shang;Ben Kao	2009		10.1145/1645953.1646265	natural language processing;latent semantic indexing;tensor;data structure;computer science;data mining;database;probabilistic latent semantic analysis;singular value decomposition;world wide web;tucker decomposition;information retrieval;statistics	Web+IR	-25.704789983919508	-50.687486399927366	56277
241ec5fd45edb0c50ab9780a1822afd34dd2083e	learning the information diffusion probabilities by using variance regularized em algorithm	complexity theory;learning;maximum likelihood estimation;regularization;maximum likelihood estimation independent cascade model regularization learning;independent cascade model;mathematical model;twitter equations mathematical model complexity theory maximum likelihood estimation;variance regularization scheme information diffusion probabilities variance regularized em algorithm popular social network website twitter model complexity independent cascade model approximation solution;twitter;social networking online approximation theory computational complexity probability	In this paper we address the problem of learning the information diffusion probabilities when there is no sufficient data of information diffusion. By observing the information diffusion behavior on the popular social network web-site Twitter, we find that the evidence of information diffusion is extremely sparse. Less than one percent of tweets are retweeted, which is considered as the most important form of information diffusion evidence on Twitter. Previous research on predicting information diffusion probabilities has failed under such scenarios because the problem of over fitting. To overcome this problem, we first propose to use the variance of the diffusion probabilities as a measure of model complexity for the independent cascade model. After that, we propose two regularization schemes to reduce model complexity. The first scheme is based on regularizing the variance of the diffusion probabilities directly. The second scheme is based on regularizing the mean absolute deviation of the logarithm of the diffusion probabilities. We are able to derive an approximation solution for the first scheme and analytical solution to the second scheme. We conduct experiments by simulating information diffusion on six social network datasets. Experimental results show that the variance regularization scheme outperforms the baseline by a noticeable margin. The mean absolute deviation regularization scheme is better than the baseline.	approximation error;baseline (configuration management);expectation–maximization algorithm;experiment;matrix regularization;neural coding;overfitting;random graph;simulation;social network;sparse matrix;verification and validation	Hai-Guang Li;Tianyu Cao;Zhao Li	2014	2014 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining (ASONAM 2014)	10.1109/ASONAM.2014.6921596	regularization;econometrics;computer science;machine learning;mathematical model;mathematics;maximum likelihood;statistics	ML	-17.375900901184643	-44.46992942298946	56473
2ddf396680f4c24b8c37dbec93216c8c91b198ff	"""discussion on the paper """"analysis of spatio-temporal mobile phone data: a case study in the metropolitan area of milan"""" by p. secchi, s. vantini and v. vitelli"""			mobile phone	Wenceslao González-Manteiga;Rosa M. Crujeiras	2015	Statistical Methods and Applications	10.1007/s10260-015-0318-7	telecommunications	HCI	-19.959898761892955	-33.21445074112709	56489
d8b41784476fa8ffcc8ec0bb301823e0948a166b	finding semantically valid and relevant topics by association-based topic selection model		Topic modelling methods such as Latent Dirichlet Allocation (LDA) have been successfully applied to various fields, since these methods can effectively characterize document collections by using a mixture of semantically rich topics. So far, many models have been proposed. However, the existing models typically outperform on full analysis on the whole collection to find all topics but difficult to capture coherent and specifically meaningful topic representations. Furthermore, it is very challenging to incorporate user preferences into existing topic modelling methods to extract relevant topics. To address these problems, we develop a novel personalized Association-based Topic Selection (ATS) model, which can identify semantically valid and relevant topics from a set of raw topics based on the semantical relatedness between users’ preferences and the structured patterns captured in topics. The advantage of the proposed ATS model is that it enables an interactive topic modelling process driven by users’ specific interests. Based on three benchmark datasets, namely, RCV1, R8, and WT10G under the context of information filtering (IF) and information retrieval (IR), our rigorous experiments show that the proposed ATS model can effectively identify relevant topics with respect to users’ specific interests, and hence to improve the performance of IF and IR.	benchmark (computing);coherence (physics);embedded system;experiment;information filtering system;information retrieval;latent dirichlet allocation;personalization;text corpus;topic model;user (computing)	Yang Gao;Yuefeng Li;Raymond Y. K. Lau;Yue Xu;Md. Abul Bashar	2017	ACM TIST	10.1145/3094786	machine learning;latent dirichlet allocation;data mining;information retrieval;topic model;artificial intelligence;computer science	Web+IR	-26.144516556361413	-51.10045173570746	56521
df39a8089fbab2e820fc4bdff442b347566b12c3	dynamic sketching over distributed data streams	sampling methods big data distributed processing mathematical operators query processing;sketch approximate answering big data data streams fast data;query response time improvement distributed data streams query response time dynamic sketching framework out of order data arrival error guaranteed estimation schema uniform sampling exponential from exponential sampling one pass streaming data data organization ξ δ approximation aggregation operators quantile operators sum operator count operator median operator sketch splitting sketch merging throughput improvement;distributed databases big data time factors merging sparks throughput estimation	Plentiful emerging applications need strict requirement on query response time for different operators over distributed streaming data. As a result, approximate answering approach with accurate sketch has become an important solution to process the fast arrival streams. In this paper, we propose a dynamic sketching framework, which can sample elements from streams with out-of-order data arrival and provide an error-guaranteed estimation schema for many different operators. Within the sketch, we first extract characteristics of uniform sampling and exponential sampling from one-pass streaming data and organize them to support (ξ, δ)-approximation for different operators, such as aggregation operators (e.g., sum, count) and quantile operators (e.g., quantiles, median). Moreover, we construct the sketch in an accuracy lossless and dynamic manner by such operations as sketch splitting and sketch merging without any pori knowledge. The experimental results indicate that when compared to big data analytic systems (Spark, BlinkDB), our approach can achieve 3 times of throughput improvement and 2 orders of magnitude improvement in query response time.	approximation algorithm;big data;lossless compression;response time (technology);sampling (signal processing);stream (computing);throughput;time complexity	Guangjun Wu;Siyu Jia;Binbin Li;Shupeng Wang;Xiuguo Bao;Qingsheng Yuan	2016	2016 IEEE Conference on Computer Communications Workshops (INFOCOM WKSHPS)	10.1109/INFCOMW.2016.7562250	computer science;theoretical computer science;data mining;database	DB	-7.5724693700325325	-34.49395937349807	56526
0378e4c7c668b4945bc8cee47b5684cd18ffa975	diachronic visualization simulation for disaster accident management using robotic system		Disaster accidents have become worse and worse. For saving more people, robotic technologies have been applied to disaster accident reaction. As one of related approaches, we have researched information visualization of robotic system for disaster accident management. In this paper, we proposed a concept of diachronic visualization and showed simplified simulation. We focused two constraints. First, operators should be protected from information overload. Second, the system should be designed to minimize cost of operators' recognition.	information overload;information visualization;robot;simulation	Dong Yeop Kim;Yo Han Jung;Young-Ouk Kim;Jung-Hoon Hwang	2017	2017 14th International Conference on Ubiquitous Robots and Ambient Intelligence (URAI)	10.1109/URAI.2017.7992659	data visualization;operator (computer programming);visualization;simulation;information visualization;accident management;robot kinematics;engineering	Robotics	-19.637220698848548	-26.51604171357535	56544
726fdc4cbd6cbe0ff118095fac0d0ae904710752	clustering and singular value decomposition for approximate indexing in high dimensional spaces	continual computation;high dimensionality;prefetching;singular value decomposition;indexation;decision theory;bandwidth;cost benefit analysis	High-dimensionality indexing of feature spaces is critical for many data-intensive applications such as content-based retrieval of images or video from multimedia databases and similarity retrieval of patterns in data mining. Unfortunately, the performance of nearest neighbor (NN) queries, which are required for similarity search, deteriorates rapidly with the increase in the number of dimensions. We propose the Clustering with Singular Value Decomposition (CSVD) method, which combines clustering and singular value decomposition (SVD) to reduce the number of index dimensions, while maintaining a reasonably high precision for a given value of recall. In the proposed CSVD method, homogeneous points are grouped into clusters such that the points in each cluster are more amenable to dimensionality reduction than the original dataset. Experiments with texture vectors extracted from satellite images show that CSVD achieves signi cantly higher dimensionality reduction than SVD for the same fraction of total variance preserved. Conversely, for the same compression ratio CSVD results in an increase in preserved total variance with respect to SVD (e.g., a 70% increase for a 20:1 compression ratio). This translates to a higher e ciency in processing approximate NN queries, as quanti ed through experimental results.	approximation algorithm;cluster analysis;data mining;data-intensive computing;database;dimensionality reduction;similarity search;singular value decomposition	Alexander Thomasian;Vittorio Castelli;Chung-Sheng Li	1998		10.1145/288627.288658	mathematical optimization;decision theory;cost–benefit analysis;theoretical computer science;singular value decomposition;bandwidth;statistics	DB	-5.263351035697499	-41.08028552638089	56766
adbb69ece45661a99cba6f973aad0604bfc9a512	using rating matrix compression techniques to speed up collaborative recommendations	collaborative filtering;identifier assignment;recommender systems;rating matrix compression	Collaborative filtering is a popular recommendation technique. Although researchers have focused on the accuracy of the recommendations, real applications also need efficient algorithms. An index structure can be used to store the rating matrix and compute recommendations very fast. In this paper we study how compression techniques can reduce the size of this index structure and, at the same time, speed up recommendations. We show how coding techniques commonly used in Information Retrieval can be effectively applied to collaborative filtering, reducing the matrix size up to 75 %, and almost doubling the recommendation speed. Additionally, we propose a novel identifier reassignment technique, that achieves high compression rates, reducing by 40 % the size of an already compressed matrix. It is a very simple approach based on assigning the smallest identifiers to the items and users with the highest number of ratings, and it can be efficiently computed using a two pass indexing. The usage of the proposed compression techniques can significantly reduce the storage and time costs of recommender systems, which are two important factors in many real applications.	algorithm;approximation algorithm;arithmetic coding;code;collaborative filtering;data compression;identifier;information retrieval;k-nearest neighbors algorithm;period-doubling bifurcation;recommender system;requirement;scale (map);the matrix	Vreixo Formoso;Diego Fernández;Fidel Cacheda;Victor Carneiro	2012	Information Retrieval	10.1007/s10791-012-9213-0	computer science;collaborative filtering;machine learning;data mining;world wide web;information retrieval;recommender system	Web+IR	-6.6536960537962235	-42.09906762481329	56813
92496cb05fb281538ee39f3f46cf750e467db41e	power tags as tools for social knowledge organization systems		Web services are popular which allow users to collaboratively index and describe web resources with folksonomies. In broad folksonomies tag distributions for every single resource can be observed. Popular tags can be understood as “implicit consensus” where users have a shared understanding of tags as best matching descriptors for the resource. We call these high-frequent tags “power tags”. If the collective intelligence of the users becomes visible in tags, we can conclude that power tags obtain the characteristics of community controlled vocabulary which allows the building of a social knowledge organization system (KOS). The paper presents an approach for building folksonomy-based social KOS and results of a research project in which the relevance of assigned tags for particular URLs in the social bookmarking system delicious has been evaluated. Results show which tags were considered relevant and whether relevant tags can be found among power tags.		Isabella Peters	2010		10.1007/978-3-642-24466-7_29	bioinformatics;knowledge management;data mining	HCI	-27.383700998665663	-50.109902731620835	56851
e3c0ef687aec0a80094e08799dde307c9bf17c6c	predicting web user behavior using learning-based ant colony optimization	ant colony optimization;multi agent simulation;web usage mining;text preferences	An ant colony optimization-based algorithm to predict web usage patterns is presented. Our methodology incorporates multiple data sources, such as web content and structure, as well as web usage. The model is based on a continuous learning strategy based on previous usage in which artificial ants try to fit their sessions with real usage through the modification of a text preference vector. Subsequently, trained ants are released onto a new web graph and the new artificial sessions are compared with real sessions, previously captured via web log processing. The main results of this work are related to an effective prediction of the aggregated patterns of real usage, reaching approximately 80%. In the second place, this approach allows the obtaining of a quantitative representation of the keywords that influence the navigational sessions. & 2011 Elsevier Ltd. All rights reserved.	algorithm;ant colony optimization algorithms;artificial ants;blog;mathematical optimization;web content;webgraph	Pablo S. Loyola;Pablo E. Román;Juan D. Velásquez	2012	Eng. Appl. of AI	10.1016/j.engappai.2011.10.008	web mining;ant colony optimization algorithms;computer science;machine learning;data mining;world wide web	AI	-26.039082601115904	-48.842392369345895	56860
a3681022a419f6e5cd7c6e211843518609c36225	a context-based information agent for supporting education on the web	domain knowledge;information agent	In this paper, we present an attempt to support education on the Web. We take advantage of information that can be taken directly during a learning session in order to update domain knowledge. A new technique to structure domain knowledge is presented. We represent domain knowledge as a hierarchy of concepts. Each concept consists of some dominant meanings, and each of those is linked with some chunks (segments of information) to define it. Based on this structure, we define a context-based information agent that can monitor conversations among a community of on-line learners, interpret the learners' inputs, and then assess the current context of the session. It is able to build a new query to get updated information from the Web. Then, it can filter the results, organizing, and presenting information useful to the learners in their current activities. We claim that specifying the context of a search better can significantly improve search results. An important task, therefore, is to assess the context based on dominant meaning space. That is a new set based measure to evaluate the closeness between queries and documents. Our experiments show that the proposed method greatly improves retrieval effectiveness, in terms of average overall accuracy.		Mohammed Abdel Razek;Claude Frasson;Marc Kaltenbach	2003		10.1007/3-540-44839-X_19	computer science;knowledge management;artificial intelligence;machine learning;data mining;database;world wide web;domain knowledge	AI	-32.5001267959311	-49.92810423162643	56890
1fe59e72d049892c8b82ca76e26fa815e3764739	a 3d visual analysis tool in support of the sandf's growing ground based air defence simulation capability	3d visualisation;battlefield visualisation;3d visualization;virtual reality;system of systems;presentation;command and control visualisation;system performance;computer graphic;command and control;visual analysis;situation awareness;ground based air defence system;visual feedback;analysis;systems simulation;three dimensional graphics and realism;battle field visualisation;state transition;open source	A 3D visual analysis tool has been developed to add value to the SANDF's growing Ground Based Air Defence (GBAD) System of Systems simulation capability. A time based XML interface between the simulation and analysis tool, via a TCP connection or a log file, allows individual simulation objects to be wholly updated or partially modified. Live pause and review of the simulation action is supported by employing data key frames and compressed XML for enhanced performance. An innovative configurable filter tree allows visual clutter to be reduced as required and an open source scene graph (OpenSceneGraph) manages the 3D scene representation and rendering.  A visualisation capability is developed for the effective presentation of the dynamic air defence system behaviour, system state transitions and inter-system communication. The visual analysis tool has successfully been applied in support of system performance experiments, tactical doctrine development and simulation support during training and live field exercises. The 3D visualisation resulted in improved situational awareness during experiment analysis, in increased involvement of the SANDF in experiment analysis and in improved credibility of analysis results presented during live or after action visual feedback sessions.	clutter;conceptual system;experiment;inter-process communication;key frame;open-source software;openscenegraph;positive feedback;scene graph;subject matter expert turing test;subject-matter expert;system of systems;systems simulation;three-dimensional integrated circuit;timeline;visualization (graphics);windows aero;xml	Bernardt Duvenhage;J. P. Delport;Anita Louis	2007		10.1145/1294685.1294692	command and control;situation awareness;computer vision;real-time computing;simulation;visualization;system of systems;computer science;artificial intelligence;operating system;machine learning;systems simulation;analysis;virtual reality;multimedia;computer graphics (images)	Robotics	-32.893077067941185	-32.219654870494914	56954
05d28cc7263a0e22cc9a7884112808afa010073e	low-cost realtime horizontal curve detection using inertial sensors of a smartphone	support vector machines;sensors;training;noise measurement;roads;feature extraction;data models	Fatal accidents occur frequently on low-volume rural roads, and the accident rates are up to 4 times higher at curves. It is thus of paramount importance to perform road inventory of rural roads to develop safety plans. However, most states in U.S. face a challenge to maintain a database for low-volume rural roads due to limited funds for road inventory. In this paper, we propose to significantly reduce the cost for road inventory specifically focusing on horizontal curve detection by developing a mobile road inventory system based on off-the-shelf smartphones. The proposed system is capable of accurately detecting various kinds of horizontal curves by synthesizing heterogeneous smartphone sensor data to generate curve models by exploiting a machine learning technique. We implemented the system on iOS-based smartphones and tested with more than 400-miles of field data. We demonstrate that the proposed system achieves a median of 93.8% curve identification accuracy with a median of 5% false positive rates.	crowdsourcing;edge detection;machine learning;median of medians;real-time computing;sensor;smartphone;ios	Shaohu Zhang;Myounggyu Won;Sang Hyuk Son	2016	2016 IEEE 84th Vehicular Technology Conference (VTC-Fall)	10.1109/VTCFall.2016.7881077	embedded system;data modeling;support vector machine;simulation;feature extraction;computer science;engineering;sensor;noise measurement;operating system;computer security	Mobile	-17.65126115255441	-30.015156646326954	56968
2ef052b6fa42613ca8af6bf0665a96290c4967c7	mining confident minimal rules with fixed-consequents	data mining;association rule mining;association rule;tree searching data mining very large databases;precision agriculture;very large databases;tree searching;large data sets fixed consequent association rule mining market basket research minimal confident rules;data mining association rules computer science operations research agriculture artificial intelligence	Association rule mining (ARM) finds all the association rules in data, that match some measures of interest such as support and confidence. In certain situations where high support is not necessarily of interest, fixed-consequent association-rule mining for confident rules might be favored over traditional ARM. The need for fixed consequent ARM is becoming more evident in a number of applications such as market basket research (MBR) or precision agriculture. Highly confident rules are desired in all situations; however, support thresholds fluctuate with the applications and the data sets under study, as we shall show later. We propose an approach for mining minimal confident rules in the context of fixed-consequent ARM that relieves the user from the burden of specifying a minimum support threshold. We show that the framework suggested herein is efficient and can be easily expanded by adding new pruning conditions pertaining to specific situations.	association rule learning	Imad Rahal;Dongmei Ren;Weihua Wu;William Perrizo	2004	16th IEEE International Conference on Tools with Artificial Intelligence	10.1109/ICTAI.2004.85	association rule learning;computer science;data science;machine learning;data mining	DB	-5.314516896807618	-29.850855378611307	56992
b93a5412d66fe9274cde2cff947f3fc6c148cef4	linking user online behavior across domains with internet traffic.		We are facing an era of Online With Offline (OWO) in the smart city almost everyone is using various online services to connect friends, watch videos, listen to the music, download resources, and so on. Our online behaviors are separated by different domains, which may cause serious problem in the area of cross-domain recommendation, advertising, and criminal tracking in online and offline world, since it is a very challenging task to link user online behaviors belonging to the same natural person. Existing methods usually tackle user online behavior linkage problem by estimating the profile content similarity between two different online services. However, the profile contents in heterogeneous online services are unreliable or misaligned, and 1 Corresponding author. Journal of Universal Computer Science, vol. 24, no. 3 (2018), 277-301 submitted: 3/10/17, accepted: 5/3/18, appeared: 28/3/18 © J.UCS	algorithm;computer science;data science;decision tree;digital identity;download;e-services;fingerprint;linkage (software);online and offline;smart city	Yuanyuan Qiao;Yan Wu;Yaobin He;Libo Hao;Wenhui Lin;Jie Yang	2018	J. UCS		internet traffic;data mining;computer science	Web+IR	-23.781086235363734	-48.26018297613906	57009
cae925db6ec3b2c4e22de3a276ea058457ebfce2	fuzzy statistics and computation on the lexical semantics how much do you think? and how many?	human cognition;lexical semantics;fuzzy logic;conference paper;sample survey;statistical analysis	In this paper, we investigated the fuzzy statistics analysis in lexical semantics and apply the fuzzy logic to compute some uncertain and ambiguous problems. The fuzzy propositional computation for the cognitive semantics can account for the degree of typicality and similarity. Which provide a more precise expression in human thought and human cognition. Some essential definitions for fuzzy statistics are proposed to implement these procedures. The empirical results by a sampling survey and fuzzy statistical analysis suggests that the fuzzy statistics and computation are potentially powerful heuristics in analyzing lexical semantics.	cognition;computation;fuzzy concept;fuzzy logic;heuristic (computer science);operational semantics;sampling (signal processing)	Berlin Wu;Ching-Min Sun	1996			fuzzy logic;natural language processing;t-norm fuzzy logics;fuzzy cognitive map;membership function;type-2 fuzzy sets and systems;fuzzy classification;computer science;neuro-fuzzy;machine learning;data mining;fuzzy control language	AI	-4.868264708931328	-24.522619505223027	57011
1fc12caa5911e7c75bfb556caae78b379a398994	human-humanoid interaction: is a humanoid robot perceived as a human?	cognitive robotics;human interaction;social robot;interference;neuroscience;humanoid robot;face;humanoid robots;internet;human robot interaction	As humanoid robots become more commonplace in our society, it is important to understand the relation between humans and humanoid robots. In human face-to-face interaction, the observation of another individual performing an action facilitates the execution of a similar action, and interferes with the execution of differmi action. This phenomenon has been explained by the existence of shared internal representations for the execution and perception of actions, which would be automatically activated by the perception of another individual¿s action. In one interference experiment. null interference was reported when subjects observed a robotic ann perform the incongruent task, suggesting that this effect may be specific to interacting with other humans. This experimental paradigm, designed to investigate motor interference in human interactions, was adapted to investigate how similar the implicit perception of a humanoid robot is to a human agent. Subjects performed rhythmic movements while ohsening either a human agent or humanoid robot performing either congruent or incongruent movements. The variance of the executed movements was used as a measure of the amount of interference in the movements. Both the human and humanoid agents produced significant interference effect. These results suggest that observing the action of humanoid robot and human agent may rely on similar perceptual processes. Furthermore, the ratio of the variance in incongruent to congruent conditions varied between the human agent and humanoid robot. We speculate this ratio describes how the implicit perception of a robot is similar to that of a human, so that this paradigm could provide an objective measure of the reaction to different types of robots and be used to guide the design of humanoid robots interacting with humans.	catastrophic interference;computation;humanoid robot;humans;human–robot interaction;interference (communication);programming paradigm	Erhan Öztop;David W. Franklin;Thierry Chaminade;Gordon Cheng	2004	4th IEEE/RAS International Conference on Humanoid Robots, 2004.	10.1142/S0219843605000582	human–robot interaction;computer vision;cog;simulation;computer science;humanoid robot;artificial intelligence;social robot	Robotics	-30.748598968661764	-40.89085540636528	57157
10dfc84269a45e7aa5c7c95f9ead9cde92667bb0	mobidict: a mobility prediction system leveraging realtime location data streams	location based services;mobility behaviour;realtime mobility prediction	Mobility prediction is becoming one of the key elements of location-based services. In the near future, it will also facilitate tasks such as resource management, logistics administration and urban planning. To predict human mobility, many techniques have been proposed. However, existing techniques are usually driven by large volumes of data to train user mobility models computed over a long duration and stored in a centralized server. This results in inherently long waiting times before the prediction model kicks in. Over this large training data, small time bounded user movements are shadowed, due to their marginality, thus impacting the granularity of predictions. Transferring highly sensitive location data to third party entities also exposes the user to several privacy risks. To address these issues, we propose MobiDict, a realtime mobility prediction system that is constantly adapting to the user mobility behaviour, by taking into account the movement periodicity and the evolution of frequently visited places. Compared to the existing training approaches, our system utilises less data to generate the evolving mobility models, which in turn lowers the computational complexity and enables implementation on handheld devices, thus preserving privacy. We test our system using mobility traces collected around Lake Geneva region from 168 users and demonstrate the performance of our approach by evaluating MobiDict with six different prediction techniques. We find a satisfactory prediction accuracy as compared to the baseline results obtained with 70% of the user dataset for majority of the users.	baseline (configuration management);centralized computing;computational complexity theory;entity;location-based service;logistics;mobile device;privacy;quasiperiodicity;server (computing);tracing (software)	Vaibhav Kulkarni;Arielle Moro;Benoît Garbinato	2016		10.1145/3003421.3003424	simulation;geography;mobility model;world wide web;computer security	Mobile	-17.597585098126228	-34.5475100668098	57275
0fb9dacf0254fbc0dae210179e6879cb74cfb6fc	modeling customer engagement from partial observations	deficient data;structured learning;user networks;feature learning;loyalty programs	It is of high interest for a company to identify customers expected to bring the largest profit in the upcoming period. Knowing as much as possible about each customer is crucial for such predictions. However, their demographic data, preferences, and other information that might be useful for building loyalty programs is often missing. Additionally, modeling relations among different customers as a network can be beneficial for predictions at an individual level, as similar customers tend to have similar purchasing patterns. We address this problem by proposing a robust framework for structured regression on deficient data in evolving networks with a supervised representation learning based on neural features embedding. The new method is compared to several unstructured and structured alternatives for predicting customer behavior (e.g. purchasing frequency and customer ticket) on user networks generated from customer databases of two companies from different industries. The obtained results show 4% to 130% improvement in accuracy over alternatives when all customer information is known. Additionally, the robustness of our method is demonstrated when up to 80% of demographic information was missing where it was up to several folds more accurate as compared to alternatives that are either ignoring cases with missing values or learn their feature representation in an unsupervised manner.	database;evolving networks;feature learning;machine learning;missing data;purchasing;unsupervised learning	Jelena Stojanovic;Djordje Gligorijevic;Zoran Obradovic	2016		10.1145/2983323.2983854	voice of the customer;feature learning;simulation;computer science;artificial intelligence;machine learning;data mining;database;customer intelligence;structured prediction;world wide web	ML	-19.59229689972336	-50.188656049845676	57276
20a9af02b2aca6887bc5f997202d07d7014cd263	clustering traffic flow patterns by fuzzy c-means method: some preliminary findings		In this paper, performance of fuzzy c-means clustering method in specifying flow patterns, which are reconstructed by a macroscopic flow model, is sought using microwave radar data on fundamental variables of traffic flow. Traffic flow is simulated by the cell transmission model adopting a two-phase triangular fundamental diagram. Flow dynamics specific to the selected freeway test stretch are used to determine prevailing traffic conditions. The performance of fuzzy c-means clustering is evaluated in two cases, with two assumptions. The procedure fuzzy clustering method follows is systematically dynamic that enables the clustering, and hence partitions, over the fundamental diagram specific to selected temporal resolution. It is seen that clustering simulation with dynamic pattern boundary assumption performs better for almost all the steps of data expansion when considered to simulation with the corresponding static case.		Mehmet Ali Silgu;Hilmi Berk Celikoglu	2015		10.1007/978-3-319-27340-2_93	database;computer network	ML	-13.990413624239416	-31.465664825322794	57302
3cff93c0f40137375e8346261d85a9c67b55db28	maintaining preference networks that adapt to changing preferences		Decision making can be more difficult with an enormous amount of information, not only for humans but also for automated decision making processes. Although most user preference elicitation models have been devel- oped based on the assumption that user preferences are stable, user preferences may change in the long term and may evolve with experience, resulting in dy- namic preferences. Therefore, in this paper, we describe a model called the dy- namic preference network (DPN) that is maintained using an approach that does not require the entire preference graph to be rebuilt when a previously-learned preference is changed, with efficient algorithms to add new preferences and to delete existing preferences. DPNs are shown to outperform existing algorithms for insertion, especially for large numbers of attributes and for dense graphs. They do have some shortcomings in the case of deletion, but only when there is a small number of attributes or when the graph is particularly dense.		Ki Hyang Lee;Scott Buffett;Michael W. Fleming	2013		10.1007/978-3-642-38457-8_8	machine learning;data mining	ECom	-8.223044085302408	-37.39751772670825	57394
f0f753d1ee494899cbaafc7fb2bc61db1894776f	computer-aided compositional design and verification for modular robots		To take full advantage of the flexibility of a modular robot system, users must be able to create and verify new configurations and behaviors quickly. We present a design framework that facilitates rapid creation of new configurations and behaviors through composition of existing ones, and tools to verify configurations and behaviors as they are being created. New configurations are created by combining existing sub-configurations, for example combining four legs and a body to create a walking robot. Behaviors are associated with each configuration, so that when sub-configurations are composed, their associated behaviors are immediately available for composition as well. We introduce a new motion description language (Series-Parallel Action Graphs) that facilitates the rapid creation of complex behaviors by composition of simpler behaviors. We provide tools that automatically verify configurations and behaviors during the design process, allowing the user to identify problems early and iterate quickly. In addition to verification, users can evaluate their configurations and behaviors in a physics-based simulator.	iteration;mobile robot;self-reconfiguring modular robot;simulation	Tarik Tosun;Gangyuan Jing;Hadas Kress-Gazit;Mark Yim	2015		10.1007/978-3-319-51532-8_15	theoretical computer science;computer-aided;self-reconfiguring modular robot;engineering design process;robot;modular design;graph	HCI	-30.03039493544165	-26.43222315516673	57438
b58d381f9f953bfe24915246b65da872aa94f9aa	recommending new links in social networks using face recognition	betaface;flickr;social networking online face recognition;new links recommendation social networks face recognition;flickr social network new contacts face recognition betaface facebook;social network;face recognition;social networking online;facebook;new contacts;face face recognition facebook databases algorithm design and analysis testing	The main task of our work is to help a new user of a social network find new contacts. In the current situation mainly text data are used for these purposes. In our work we focus on information that is saved in images of the faces of potential users of a social network. Since there are hundreds of photos from almost every user of a social network online, if we find a way to analyze them effectively then we can suggest to the user new contacts. These new contacts will be more relevant than these which come from current methods for friend suggestions. The experimental algorithm for the new way of suggestions is described in this paper. The algorithm uses tools that are freely available for any user, which was one of our main targets. The results of the testing show that our algorithm is successful during new contact suggestions.	algorithm;facial recognition system;social network;text corpus	Petr Saloun;Jakub Stonawski;Ivan Zelinka	2013	2013 8th International Workshop on Semantic and Social Media Adaptation and Personalization	10.1109/SMAP.2013.13	psychology;multimedia;internet privacy;world wide web	Web+IR	-23.33440118199828	-49.293291271094326	57474
2ce7ba29936f1ab74a4f0beb320085f5873c591d	finding and using implicit structure in human-organized spatial layouts of information	emergent structure;exploratory analysis;spatial structure;information management;information system;structural similarity	Many interfaces allow users to manipulate graphical objects, icons representing underlying data or the data themselves, against a spatial backdrop or canvas. Users take advantage of the flexibility offered by spatial manipulation to create evolving lightweight structures. We have been investigating these implicit organizations so we can support user activities like information management or exploratory analysis. To accomplish this goal, we have analyzed the spatial structures people create in diverse settings and tasks, developed algorithms to detect the common structures we identified in our survey, and experimented with new facilities based on recognized structure. Similar recognitionbased functionality can be used within many common applications, providing more support for users’ activities with less attendant overhead.	algorithm;backdrop cms;graphical user interface;information management;overhead (computing)	Frank M. Shipman;Catherine C. Marshall;Thomas P. Moran	1995		10.1145/223904.223949	computer science;knowledge management;data science;structural similarity;data mining;information management;information system	HCI	-30.423732533497567	-32.18583540924472	57531
ad206c06e16329482acd79b14b681d908f6bf6de	comparison between a prescribed and a permissive process in computer assisted training in decision making				B. Varet;F. Allorent;J. P. Levy;N. Salame;F. M. Blondel;J. F. Boyer	1977			machine learning;simulation;artificial intelligence;permissive;computer science	Vision	-8.211058668356394	-26.961191779323283	57624
f8e6176a42a03ff2d05c94365601b61162ec052b	roadrank: traffic diffusion and influence estimation in dynamic urban road networks	influential roads;swinburne;road networks;traffic diffusion	With the rapidly growing population in urban areas, these days the urban road networks are expanding at a faster rate. The frequent movement of people on them leads to traffic congestions. These congestions originate from some crowded road segments, and diffuse towards other parts of the urban road networks creating further congestions. This behavior of road networks motivates the need to understand the influence of individual road segments on others in terms of congestion. In this work, we propose RoadRank, an algorithm to compute the influence scores of each road segment in an urban road network, and rank them based on their overall influence. It is an incremental algorithm that keeps on updating the influence scores with time, by feeding with the latest traffic data at each time point. The method starts with constructing a directed graph called influence graph, which is then used to iteratively compute the influence scores using probabilistic diffusion theory. We show promising preliminary experimental results on real SCATS traffic data of Melbourne.	algorithm;directed graph;experiment;network congestion;traffic exchange	Tarique Anwar;Chengfei Liu;Hai L. Vu;Md. Saiful Islam	2015		10.1145/2806416.2806588	simulation	AI	-17.726831590032198	-34.899381027667005	57654
615950c335438fd4704753c48d118d7f19a9f4a3	a bayesian network and analytic hierarchy process based personalized recommendations for tourist attractions over the internet	bayesian network;analytic hierarchy process;user feedback;personalized recommendation;web service;satisfiability;recommender system;tourist attractions;intelligent system;travel behavior;ontology	Selecting tourist attractions to visit at a destination is a main stage in planning a trip. Although various online travel recommendation systems have been developed to support users in the task of travel planning during the last decade, few systems focus on recommending specific tourist attractions. In this paper, an intelligent system to provide personalized recommendations of tourist attractions in an unfamiliar city is presented. Through a tourism ontology, the system allows integration of heterogeneous online travel information. Based on Bayesian network technique and the analytic hierarchy process (AHP) method, the system recommends tourist attractions to a user by taking into account the travel behavior both of the user and of other users. Spatial web services technology is embedded in the system to provide GIS functions. In addition, the system provides an interactive geographic interface for displaying the recommendation results as well as obtaining users’ feedback. The experiments show that the system can provide personalized recommendations on tourist attractions that satisfy the user. 2007 Elsevier Ltd. All rights reserved.	analytical hierarchy;artificial intelligence;bayesian network;embedded system;experiment;geographic information system;internet;personalization;recommender system;web service	Yuxia Huang;Ling Bian	2009	Expert Syst. Appl.	10.1016/j.eswa.2007.10.019	web service;analytic hierarchy process;simulation;computer science;machine learning;ontology;bayesian network;travel behavior;world wide web;recommender system;satisfiability	AI	-29.742821997994316	-47.412414125126034	57665
19831e61b6dc4daedc9ec29026096c6435412eb3	traversal optimizations and analysis for large graph clustering	communities electronic mail collaboration social network services data mining clustering algorithms semantics;pattern clustering data mining electronic mail graph theory optimisation;parameter free graph clustering traversal optimizations versatile data structure graph mining task collaborative similarity measure csm personalized e mail community detection nontrivial graph traversals shortest path graph traversals shortest path overlapped region spore sp trees confined subgraph traversals	Graph is an extremely versatile data structure in terms of its expressiveness and flexibility to model a range of real life phenomenon, such as social, biological, sensor, and computer networks. Finding groups of vertices based on their similarity is the fundamental graph mining task to get useful insights. The existing methods suffer from scalability issues due to enormous computations of an exact similarity estimation. Therefore, we introduce Collaborative Similarity Measure (CSM) based on shortest path strategy, instead of all paths, to define structural and semantic relevance among vertices efficiently. We evaluate this measure for personalized email community detection as an application scenario. However, an abundance of structural information has resulted in non-trivial graph traversals. Shortcut construction is among the utilized techniques implemented for efficient shortest path (SP) traversals on graphs. The shortcut construction, being a computationally intensive task, required to be exclusive and offline, often produces unnecessary auxiliary data. To overcome this issue, we present Shortest Path Overlapped Region (SPORE), a performance-based initiative that improves the shortcut construction performance by exploiting SP overlapped regions. Path overlapping with empirical analysis has been overlooked by shortcut construction systems. SPORE avails this opportunity and provides a solution by constructing auxiliary shortcuts incrementally, using SP trees during traversals, instead of an exclusive step. SPORE is exposed to a graph clustering task, which requires extensive graph traversals to group similar vertices together, for realistic implications. We further suggest an optimization strategy to accelerate the performance of the clustering process using confined subgraph traversals. Leveraging the SPORE with multiple SP computations consistently reduces the latency of the entire clustering process. A parameter-free graph clustering with scalable graph traversal strategy for a billion scale graph remain an open issue.	cluster analysis;computation;data structure;email;graph (discrete mathematics);graph traversal;keyboard shortcut;logical equality;mathematical optimization;online and offline;overhead (computing);personalization;random graph;real life;relevance;scalability;sensor;shortest path problem;similarity measure;spore;structure mining;time complexity;tree traversal;unified extensible firmware interface	Waqas Nawaz	2015	2015 31st IEEE International Conference on Data Engineering Workshops	10.1109/ICDEW.2015.7129587	graph bandwidth;null graph;computer science;theoretical computer science;machine learning;graph traversal;data mining;database;distance-hereditary graph;distributed computing;graph;path;complement graph;graph database;strength of a graph	DB	-10.156832403102827	-40.572203867783735	57798
45a735812617585d68cd9aee5c6bc6da98d2f8dc	time series rule discovery: tough, not meaningless	extraction information;ombre;analisis estadistico;analisis datos;information extraction;time series data mining;fractal geometry;invarianza;estiramiento;time series;probabilistic approach;data mining;effet dimensionnel;etirage;invariance;statistical physics;data analysis;sombra;scale space;statistical analysis;drawing;shadow;fouille donnee;enfoque probabilista;approche probabiliste;size effect;decouverte connaissance;analyse statistique;serie temporelle;defaillance;failure mechanism;serie temporal;reference data;fractal;rule discovery;invariante;descubrimiento conocimiento;analyse donnee;peritaje;failures;expertise;efecto dimensional;fallo;busca dato;extraccion informacion;invariant;scale invariance;knowledge discovery	'Model free' rule discovery from data has recently been subject to considerable criticism, which has cast a shadow over the emerging discipline of time series data mining. However, other than in data mining, rule discovery has long been the subject of research in statistical physics of complex phenomena. Drawing from the expertise acquired therein, we suggest explanations for the two mechanisms of the apparent 'meaning-lessness' of rule recovery in the reference data mining approach. One reflects the universal property of self-affinity of signals from real life complex phenomena. It further expands on the issue of scaling invariance and fractal geometry, explaining that for ideal scale invariant (fractal) signals, rule discovery requires more than just comparing two parts of the signal. Authentic rule discovery is likely to look for the possible 'structure' pertinent to the failure mechanism of the (position and/or resolution-wise) invariance of the time series analysed. The other reflects the redundancy of the 'trivial' matches, which effectively smoothes out the rule which potentially could be discovered. Orthogonal scale space representations and appropriate redundancy suppression measures over autocorrelation operations performed during the matches are suggested as the methods of choice for rule discovery.	time series	Zbigniew R. Struzik	2003		10.1007/978-3-540-39592-8_6	fractal;computer science;artificial intelligence;data mining;mathematics;information extraction;algorithm;statistics	ML	-4.642922427379607	-31.66163616705149	57839
50f1bc14d8b16ea00e18b280ec8979d6f0d28c1a	techniques for finding similarity knowledge in olap reports	similarity knowledge;olap;data mining;clustering;unit of analysis;mds;on line analytical processing	0957-4174/$ see front matter 2010 Elsevier Ltd. A doi:10.1016/j.eswa.2010.09.033 ⇑ Corresponding author. E-mail address: s1443007@cc.ncu.edu.tw (M.Z. Li) On-line analytical processing (OLAP) is a common solution that modern enterprises use to generate, monitor, share, and administrate their analysis reports. When daily, weekly, and/or monthly reports are generated or published by the OLAP operators, all analyses on the contents of reports are left for the report readers. To discover hidden rules, similar reports, or trend inside the potentially huge amount of reports, the report readers can only rely on their smart eyes to find out any rules of such kinds. Data mining is a well-developed field for finding hidden rules inside the data itself. However, there are few techniques focus on finding hidden rules, similarity, or trend using OLAP reports as the unit of analysis. In this paper, we explore how to use data mining techniques on OLAP reports in order to automatically and effectively find the similarity knowledge of OLAP reports. We also address the appropriate presentation of this similarity knowledge to OLAP users. We compare the difference between traditional data mining and finding similarity knowledge from OLAP reports. We then proposed three methods (called OLAP_MDS, OLAP_CLU, and OLAP_M+C in this paper) to explore the effectiveness of discovering similarity knowledge from OLAP reports. Finally, we compare the pros and cons of the proposed three methods with experiments and conclude that the OLAP_M+C method should be the best in most cases. 2010 Elsevier Ltd. All rights reserved.	data mining;experiment;monte carlo method;online analytical processing	Kevin Chihcheng Hsu;Ming-Zhong Li	2011	Expert Syst. Appl.	10.1016/j.eswa.2010.09.033	online analytical processing;computer science;data science;data mining;database;cluster analysis;unit of analysis	DB	-23.627234519087004	-51.63758650657713	57862
2e2828fef59f29959b6792be28ef55dee2fe41d5	the research of land use change based on gis and ca model: taking the jinzhou city as an example	analytical models;land use data;complex dynamics;biological system modeling construction industry data models analytical models automata predictive models geographic information systems;driving force;causal relationship;bottom up;spatial correlation problem;dynamic model;biological system modeling;construction industry;economic data;land use change;space time;jinzhou city;automata;spatial correlation problem land use change gis ca model cellular automata jinzhou city dynamic simulation modeling space time interaction causal relationship land use data economic data;land use planning cellular automata geographic information systems;spatial correlation;gis;land use;complex system;geographic information systems;land use change ca model gis;ca model;dynamic simulation;predictive models;simulation analysis;cellular automata;land use planning;space time interaction;temporal change;global change;data models;dynamic simulation modeling	"""The analysis of Land-use change trends and its driving forces is one of the hot issues of global change research, the core of research is how to forecast the tendency of land-use change reasonably and accurately. The dynamic land-use change is very complicated, the traditional GIS method can solve part of the spatial correlation problem well, but it is hard to simulate complex dynamics in spatial and temporal change of geographical phenomena. Cellular automata (CA) is a kind of """"bottom-up"""" dynamic simulation modeling framework, whose time, space, states are discrete, and it is a space time interaction and causal relationships for the local dynamic model of grid, and has an ability to simulate spatial and temporal evolution of complex systems. CA model that integrated with GIS will improve the environment of CA simulation and make the results of the simulation analysis more accurate. This paper take Jinzhou of Liaoning Province as an example, we study the land use status of the research region based on land use data and economic data and achieve the main direction of land use change in the last few years, which can provided a basis for establishing a CA model. Then taking the TM image data in the years of 00 and 07 as the basic and test data to debug, evaluate and test the parameters of the CA model. Finally the model could be predicted on the land use state of the research area in 2015. The results of experiment showed that the CA model can simulate complex land use structure accurately through simple local transition rules."""	automata theory;causality;cellular automaton;complex dynamics;complex systems;dynamic simulation;geographic information system;global change;mathematical model;production (computer science);test data	Liang Pei;Xin Ye;Jiaqiang Ren	2010	2010 18th International Conference on Geoinformatics	10.1109/GEOINFORMATICS.2010.5568050	simulation;geography;cartography	Robotics	-13.797993842669863	-25.06135418402616	57871
2a38bc4c15a34aa36b7842de900ec2f2b2b7993f	identifying region-wide functions using urban taxicab trajectories	region wide functions;social networks;taxicab trajectories;vehicular networks;urban computing	With the urban development and enlargement, various regions such as residential zones and administrative districts now appear as parts of cities. People exhibit different mobility patterns in each region, which is closely relevant to region-wide functions. In this article, we propose a scheme to discover region-wide functions using large-scale Shanghai taxicab trajectories that capture enormous traces for more than 13,000 taxicabs over a period of about 3 years. We investigate these taxicab trajectories and conduct an extensive preliminary study. Then, we divide the city into disjointed regions using Voronoi decomposition. By incorporating people's pick-up and drop-off information, we refine the Voronoi partitioning results to identify region-wide functional areas. Finally, we study people's movement frequency on weekdays and weekends for every kind of urban functional regions. We also look into human mobility within or across the identified urban functional regions. Experimental results show that human movement is bounded with the function of urban regions, and more than 90% of people visit neighboring (less than 20km travel distance) functional regions with high probability.	hotspot (wi-fi);preprocessor;taxicab geometry;tracing (software);voronoi diagram;with high probability	Daqiang Zhang;Jiafu Wan;Zongjian He;Shengjie Zhao;Ke Fan;Sang Oh Park;Zhibin Jiang	2016	ACM Trans. Embedded Comput. Syst.	10.1145/2821507	vehicular ad hoc network;simulation;social network	HCI	-18.99909363945494	-34.8263670218649	57906
860b8df29187e3f39f054f409152fb054b76a276	resolving entity on a large scale: determining linked entities and grouping similar attributes represented in assorted terminologies	big data;web data;entity resolution;linked open data;hierarchical blocking;rough set theory;meta-blocking;query processing	The tremendous growth of the World Wide Web (WWW) accumulates and exposes an abundance of unresolved real-world entities that are exposed to public Web databases. Entity resolution (ER) is the vital prerequisite for leveraging and resolving Web entities that describe the same real-world objects. Data blocking is a popular method for addressing Web entities and grouping similar entity profiles without duplication. The existing ER techniques apply hierarchical blocking to ease dimensionality reduction. Canopy clustering is a pre-clustering method for increasing processing speed. However, it performs a pairwise comparison of the entities, which results in a computationally intensive process. Moreover, conventional data-blocking techniques have limited control over both the block size and overlapping blocks, despite the significance of blocking quality in many potential applications. This paper proposes a Real-Delegate (Resolving Entity on A Large scale: DEtermining Linked Entities and Grouping similar Attributes represented in assorted TErminologies) that exploits attribute-based unsupervised hierarchical blocking as well as meta-blocking without relying on pre-clustering. The proposed approach significantly improves the efficiency of the blocking function in three phases. In the initial phase, the Real-Delegate approach links the multiple sets of equivalent entity descriptions using Linked Open Data (LOD) to integrate multiple Web sources. The next phase employs attribute-based unsupervised hierarchical blocking with rough set theory (RST), which considerably reduces superfluous comparisons. Finally, the Real-Delegate approach eliminates a redundant entity by employing a graph-based meta-blocking model that represents a redundancy-positive block and removes overlapping profiles effectively. The experimental results demonstrate that the proposed approach significantly improves the effectiveness of entity resolution compared with the token blocking method in a large-scale Web dataset.	block size (cryptography);blocking (computing);canopy clustering algorithm;cluster analysis;database;dimensionality reduction;entity;intel matrix raid;linked data;motorola canopy;rough set;set theory;www;world wide web;xslt/muenchian grouping	K. A. Vidhya;T. V. Geetha	2017	Distributed and Parallel Databases	10.1007/s10619-017-7205-1	linked data;computer science;big data;data mining;dimensionality reduction;block size;information retrieval;security token;canopy clustering algorithm;pairwise comparison;rough set	Web+IR	-7.90310621757185	-41.602005761949606	57958
