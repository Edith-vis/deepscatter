id	title	keywords	abstract	entities	authors	year	journal	doi	fos	area	x	y	ix
5e0c2df7d61817a006a05739f59fdbe1f6394835	a www facilitated rapid system prototyping class	software prototyping;cedcc web server;reference material;world wide web prototypes field programmable gate arrays hardware costs circuits manufacturing laboratories software prototyping temperature control;electronic system design hierarchy;chip;integrated circuit design;rapid prototyping;pilot project;internet;tutorials;application specific integrated circuits;system design;rapid system prototyping class;electronic engineering education;cedcc web server www facilitated system rapid system prototyping class penn state ee department design methodology prototyping tradeoffs electronic system design hierarchy students tutorials homework assignments reference materials;reference materials;homework assignments;circuit cad;penn state ee department;teaching internet software prototyping electronic engineering education integrated circuit design circuit cad application specific integrated circuits;prototyping tradeoffs;graduate student;students;teaching;www facilitated system;design methodology	A Rapid System Prototyping course was developed in the Penn State EE Department under the auspices of our Electronics Manufacturing pilot project; this pilot project is described in a separate MSE’97 paper [l]. Our course emphasizes design methodology, techniques, and practical prototyping tradeo@ (design time cost speed power area) as applied to the entire electronic system design hierarchy (system module chip circuit). A major goal of the class is to provide senior and entry graduate students experience with a design experience using a range ,of techniques and methodologies for rapid prototyping of electronic systems. The course was facilitated by extensive use of W&W resources; all course “handouts”, tutorials, homework assignments, and refe,rence materials were provided to students on the CEDCC web server.	prototype;rapid prototyping;server (computing);systems design;www;web server	David L. Landis;Paul T. Hulina	1997		10.1109/MSE.1997.612565	education;embedded system;simulation;computer science;systems engineering;engineering;electrical engineering;operating system;certified reference materials;computer engineering	EDA	-54.71605974578074	4.394297945425246	13457
e496f0da1cd9fb722a574f637fb6bb3cb65ce6a2	ontology-services to facilitate agents’ interoperability	vocabulaire;ontologie;multiagent system;acuerdo;multi agent system;interoperabilite;interoperabilidad;vocabulary;semantics;conversacion;vocabulario;semantica;semantique;agreement;contexto;conversation;contexte;ontologia;interoperability;sistema multiagente;ontology;context;accord;systeme multiagent	Ontology has an important role in Multi-Agent Systems communication once it provides a vocabulary to be used in the communication between agents. It is hard to find out two agents using precisely the same vocabulary. They usually have a heterogeneous private vocabulary defined in their own private ontology. In order to provide help in the conversation among different agents, we are proposing what we call ontology-services to facilitate agents’ interoperability. More specifically, in the context of the work we are doing, we intend to include these ontology-services in the framework of an Electronic Institution. Our ontology-based services will be provided through such an Electronic Institution and will be responsible for providing structural and semantic relationships between different vocabularies, useful advices on how to negotiate specific items, leading to appropriate conversations and making agreements	interoperability;multi-agent system;ontology (information science);systems architecture;vocabulary	Andreia Malucelli;Eugénio C. Oliveira	2003		10.1007/978-3-540-39896-7_15	interoperability;computer science;knowledge management;artificial intelligence;ontology;multi-agent system;database;semantics;world wide web	AI	-39.30167423469583	14.185328026863752	13464
73c650788be368542d87d711a9e8fd634b5eca34	expert system based on an ontology method to analyze types of arabica coffee beans		In the past few decades, the use of ontologies in information systems has become popular in many fields, such as website development, database integration, and natural language processing. Because many kinds of coffee beans can be used in coffee shops, the prospective coffee house entrepreneur meets obstacles in terms of choosing the right coffee beans because of multiple unique characteristics. In order to help this cohort make decisions, our study proposed a simulation ontology-based matching for coffee bean selection by inserting three parameters—aroma, flavor, and sour level—as inputs on the website. Arabica coffee bean is used as the principal object in this study and t he outputs would be the beans matched with the parameters that had been inserted. In this study, t he system model gained from the ontology method is shown in the implementation by using an example . Key Words— Arabica coffee beans, Ontology, OWL, Protege, SPARQL	expert system	Michelle Angelica;Friska Natalia Ferdinand	2017	iJES		computer science;real-time computing;database;protégé;ontology;sparql;data mining;information system;data integration;ontology (information science);coffee bean;expert system	NLP	-37.87894348798211	8.346202127459941	13470
abf15cdec859f10fd7e46c6c849258e4d6101e74	model-driven estimation approach for system reliability using integrated tasks and resources	reliability estimation;software modeling;timing failures;qa75 electronic computers computer science;quality analysis	The increasing complexity of software systems in embedded systems or industrial business domains has led to the importance of reliability analysis for current systems. Reliability analysis has become a crucial part of the system development life cycle, and a new approach is needed to enable an early analysis for reliability estimation, especially for the system under design. However, the existing approach neglects the correlation between system resource and system task for estimating system reliability. This subsequently restricts accuracy of the estimation as well as causing difficulties in identifying critical resources and tasks during the design phase. This paper proposes a model-driven system reliability estimation using a scenario-based approach to estimate system reliability and identify its critical resources and system tasks during the design phase. This model is based on the PerFAM model, which can specifically view timing failures through a system scenario. The proposed approach is validated by the application of a sensitivity analysis into one case study. The case study demonstrates an essential relationship between system reliability, as well as both resources and tasks, which ultimately becomes the integral part for a system reliability estimation assessment.	embedded system;floor and ceiling functions;markov chain;model-driven architecture;model-driven integration;petri net;reliability engineering;requirement;software deployment;software development process;software system;systems development life cycle;unified modeling language	M. A. Isa;Dayang N. A. Jawawi;Mohd Z. M. Zaki	2013	Software Quality Journal	10.1007/s11219-013-9209-z	reliability engineering;availability;simulation;systems engineering;engineering;operations management;modeling language	EDA	-57.42276634133992	26.771281529810796	13488
a48bbd3f4e3b2c4d5464d4995ca49901654ad863	the xoem+owl-based semantic exchange method and architecture on the heterogeneous product information	xml;product information exchange;keywords step;owl-based semantic exchange method;schema graph;system realization method;knowledge representation languages;semantic web;ontologies (artificial intelligence);product information;heterogeneous workspace;xoem+owl-based semantic exchange method;semantic exchange;product information sharing;heterogeneous product information	With the process of the system realization method, the XOEM+OWL-based semantic exchange method and architecture on the product information are put forward. It can solve the questions of the heterogeneous workspace, system and information, and meet the requirement of dynamic and agility.	realization (systems);workspace	Chengfeng Jian;Yue Ying	2007	Third International Conference on Semantics, Knowledge and Grid (SKG 2007)	10.1109/SKG.2007.10	xml validation;xml encryption;xml;semantic integration;semantic web rule language;streaming xml;computer science;artificial intelligence;semantic web;social semantic web;semantic web stack;database;world wide web;owl-s;information retrieval;efficient xml interchange	DB	-39.750032507450605	7.127523622471433	13491
7397025939124f9bc08224fd70a69287726376c4	a web service-oriented architecture for implementing web information systems	web information systems;rdf s;web services	Web services are one of the most popular ways for building distributed Web Information Systems (WIS). In this paper we propose a distributed implementation of the Hera methodology, a methodology based on models that specify the different aspects of a WIS. The Web services used in the implementation are responsible for capturing the required data transformations built around specific Hera models. A service orchestrator coordinates the different Web services so that the required WIS presentation is built. Based on the degree of support of the user interaction with the system two architectures are identified: one for the construction of static applications, and another one for the building of dynamic applications.	information system;java;loose coupling;need to know;programming language;service-oriented architecture;service-oriented device architecture;user profile;web services discovery;web service;world wide web	Flavius Frasincar;Geert-Jan Houben;Peter Barna	2006			web service;web application security;web development;web modeling;data web;web analytics;web mapping;web-based simulation;web design;web standards;computer science;ws-policy;web navigation;social semantic web;web page;data mining;ws-addressing;database;web intelligence;web 2.0;world wide web;mashup	Web+IR	-41.30785733459115	10.534911235150176	13514
98315c302f1b65f6eddf4c78b404ead619da100f	qos-enhanced broker for composite web service selection	business and management;graph theory;quality of service web services ontologies silicon planning shortest path problem availability;service composition;formal specification;quality of service web service service selection service composition;service selection;web service;web services;quality of service;quality of service qos enhanced broker web service selection composition service specification functional requirements nonfunctional requirements generic composition graph bpel constructors biobjective shortest path problem;web services formal specification graph theory quality of service	"""The paper proposes a layered system for web service composition. The input for the system is the specification of the desired service, including both functional and non-functional requirements. The composition operation takes as input a generic composition graph defined based on the functional requirements. Then, the set of potential compositions is identified based on """"hard"""" non-functional requirements. This set is represented in terms of an extended version of the composition graph that permits to take into account the different BPEL constructors. Finally, best composition(s) are identified by solving a biobjective shortest path problem on the transformed composition graph."""	business process execution language;executable;functional programming;functional requirement;layered system;non-functional requirement;quality of service;service composability principle;shortest path problem;software deployment;web service	Salem Chakhar	2012	2012 Eighth International Conference on Signal Image Technology and Internet Based Systems	10.1109/SITIS.2012.83	web service;service level requirement;service level objective;service product management;differentiated service;computer science;graph theory;service delivery framework;ws-policy;database;distributed computing;world wide web	SE	-46.53698700821648	16.559135004010205	13563
8f690a3f53d80f6a61c6007bbca82fedeeb8889c	context-based knowledge creation and sharing in cross-cultural collaborative communities	cross cultural collaborative communities;3d knowledge spaces;process modelling;virtual collaborative work;context	Virtual communities rely primarily on ICT to connect their members to work together, and to share knowledge and practices. The importance of virtual collaborative work is increasing not only because of its economical and environmental benefits, but also due to its flexibility for establishing dynamically new cross-organizational and cross-cultural innovative teams. Virtual collaborative spaces should support their joint activities. In order to design and realize such spaces, an understanding of the tasks to be carried out by the virtual community is necessary, as well as an understanding of the related processes, contexts, and knowledge. In our paper, we introduce a reference model of a Cross-Cultural Cyber Space (CCS) for context-based knowledge creation and sharing between the members of the cross-cultural collaborative community. We also describe the prototype implementation of the CCS, a 3D cross-cultural art museum system.	knowledge-based systems	Anneli Heimbürger;Hannu Jaakkola;Shiori Sasaki;Naofumi Yoshida;Yasushi Kiyoki	2009		10.3233/978-1-60750-477-1-76	collaborative learning;systems engineering;engineering;knowledge management;multimedia	HCI	-61.773501319222945	12.714536023301653	13603
3aa7e8d5665526dc6a2d5268282f6c911f2dc2c9	algebraic specification-based performance analysis of communication protocols	computer science;communication protocol		algebraic specification;profiling (computer programming)	Nihal Nounou;Yechiam Yemini	1984				HPC	-35.79530979727459	32.10318244588827	13608
f7cb19ea64f5c9da00ce7247be4488eed38cf963	retrieving and matching rdf graphs by solving the satisfiability problem	graph theory;semantic representation;computability;semantic web computability electronic data interchange graph theory meta data pattern matching;resource description framework;resource description framework graph;satisfiability;pattern matching;semantic web;meta data;semantic representation satisfiability problem resource description framework graph;sat solver;satisfiability problem;electronic data interchange;resource description framework computer science logic testing information resources laboratories software standards prototypes semantic web world wide web system testing	The resource description framework (RDF) has been accepted as a standard for semantic representation of resources. Efficient methods and tools are needed to solve problems emerging from RDF based systems, for example, checking equality of two RDF graphs and retrieving subgraphs from another RDF graph. This paper proposes a method that encodes these problems into satisfiability (SAT) instances and solves them by employing efficient SAT solvers. A prototype tool is implemented and preliminary experimental results are given	boolean satisfiability problem;experiment;procedural generation;prototype;resource description framework;solver;subroutine	Sheng Liu;Jian Zhang	2006	2006 IEEE/WIC/ACM International Conference on Web Intelligence (WI 2006 Main Conference Proceedings)(WI'06)	10.1109/WI.2006.150	cwm;semantic web rule language;semantic grid;computer science;sparql;graph theory;theoretical computer science;social semantic web;data mining;database;boolean satisfiability problem;programming language;world wide web;semantic analytics;rdf schema	Robotics	-44.100124762269104	14.364373927499386	13662
470f6d91f067800ca584ce75c2faf55fed90fc22	a web-based process planning optimization system for distributed design	design model;tecnologia electronica telecomunicaciones;computacion informatica;service orientation;grupo de excelencia;operating system;ciencias basicas y experimentales;web based system;tabu search;process planning;tecnologias;geographic distribution;concurrent engineering;distributed design	In this paper, a process planning module, which can optimize the selection of machining resources, determination of set-up plans and sequencing of machining operations to achieve optimized process plans, has been wrapped as services and deployed in the Internet to support distributed design and manufacturing analysis. The module includes four intelligent approaches, and a Tabu search-based approach is chosen to be explained to illustrate the optimization process. A Webbased prototype system has been setup for users to carry out visualization-based manipulations and process planning of design models by invoking the services remotely. Through effective utilizations of the Web and Java technologies, this system is operation system-independent, scalable and service-oriented, and can be used for a design team geographically distributed to organize a concurrent engineering design activity effectively.	engineering design process;java;mathematical optimization;operating system;prototype;scalability;service-oriented device architecture;tabu search;world wide web	W. D. Li;Soh-Khim Ong;Andrew Y. C. Nee	2005	Computer-Aided Design	10.1016/j.cad.2004.09.019	tabu search;computer science;systems engineering;engineering;distributed design patterns;engineering drawing;concurrent engineering	EDA	-54.04489000014676	12.836148732542982	13737
082f093cb61cfefaf20df068e5d8708de6dd6ac6	generating reduced finite state machine from concurrent scenarios using static partial order method	digital tv;program verification;software engineering;automatic generation;formal method;message sequence chart;partial order reduction;static analysis;reduction method;behavior analysis;finite state machine;embedded software;partial order	Finite state machine (FSM) representation is widely used to perform behavioural analysis and generate test cases from a set of hierarchically organized scenarios written in Message Sequence Charts (MSCs). Brute-force approach of translating MSCs into FSM is impractical, especially when scenarios are executed concurrently. In this paper, we describe how to identify a sequence of message exchanges that are semantically equivalent and apply partial order method to reduce the number of transitions in the FSM. We demonstrate that the proposed technique is scalable by describing the results of a case study in which reduced FSM was automatically generated from a partial specification of digital TV software. ACM Classification: D.2.4: (Software-Software, Engineering-Software/Program, VerificationFormal methods)	acm computing classification system;finite-state machine;formal verification;message sequence chart;scalability;software engineering;test case	Nam Hee Lee;Sung Deok Cha	2004	Journal of Research and Practice in Information Technology		partially ordered set;reliability engineering;partial order reduction;real-time computing;formal methods;embedded software;computer science;theoretical computer science;operating system;database;finite-state machine;programming language;static analysis;message sequence chart;algorithm	SE	-42.42199170371339	31.17887057539525	13826
36944dfdf75548792d54f1ac7d97ba95c21737a8	integrated specification and analysis of functional, temporal, and resource requirements	timed systems;system models;system verification;state space exploration;state space methods;formal specification;information science;system modeling;functional requirements;simulation;graphical communicating shared resources;resource management;operational semantics;graphical languages;space exploration;telecommunication computing;formal semantics;program verification;specification language;production cell case study;real time systems algebra information analysis state space methods space exploration delay resource management telecommunication computing information science specification languages;visual languages;production cell case study requirements specification functional requirements temporal requirements resource requirements graphical communicating shared resources specification language operational semantics real time systems run time system models scheduling formal semantics simulation system verification equivalence checking state space exploration;algebra;requirements specification;systems analysis;specification languages;scheduling;temporal requirements;resource requirements;run time;equivalence checking;program verification formal specification specification languages systems analysis visual languages real time systems scheduling;information analysis;real time systems	The Graphical Communicating Shared Resources, GCSR, is a specification language with a precise, operational semantics for the Specification and analysis of real-time systems. GCSR allows a designer to integrate the functional and temporal requirements of a real-tame system along with its run-time resource requirements. The integration is orthogonal in the sense that it produces system models that are easy to modify, e.g., to reflect different resource requirements, allocations and scheduling disciplines. In addition, it renders the verification of resource related requirements natural and straightforward. The formal semantics of GCSR allows the simulation of a system model and the thorough verification of system requirements through equivalence checking and state space exploration. This paper reviews GCSB and reports our experience with the production cell case study.	formal equivalence checking;graphical user interface;operational semantics;real-time clock;real-time computing;rendering (computer graphics);requirement;scheduling (computing);semantics (computer science);simulation;specification language;state space;system requirements;tame;turing completeness;verification (spaceflight)	Hanêne Ben-Abdallah;Insup Lee;Young-Si Kim	1997		10.1109/ISRE.1997.566870	systems analysis;software requirements specification;real-time computing;systems modeling;specification language;information science;computer science;resource management;theoretical computer science;space exploration;software engineering;system requirements specification;formal semantics;formal specification;formal equivalence checking;data analysis;programming language;operational semantics;scheduling;functional requirement	Embedded	-37.34418015845898	32.06624116588394	13831
bcbfe1b252d70e3025a0f5e7a09639059f660ecf	selecting skyline web services from uncertain qos	uncertain systems;uncertainty;web services possibility theory quality of service uncertain systems;skyline;qos;web services quality of service possibility theory time factors uncertainty educational institutions software algorithms;time factors;possibility theory web services skyline qos;web services;software algorithms;possibility theory;quality of service;nec dominant skyline skyline web service selection uncertain qos attributes quality of service possibility distribution pos dominant skyline	Quality of service (QoS) has been considered as a significant criterion for selecting among functionally similar Web services. Recent approaches focus on computing the skyline over a set of QoS attributes. This can completely free users from assigning weights to QoS attributes. However, these approaches are not sufficient in a dynamic Web service environment where the delivered QoS by a Web service is inherently uncertain. In this paper, we tackle the problem of skyline on uncertain QoS. We represent each QoS attribute of a Web service using a possibility distribution and introduce two skyline extensions on uncertain QoS called pos-dominant skyline and nec-dominant skyline. We then develop appropriate algorithms to efficiently compute both the pos-dominant skyline and nec-dominant skyline. Finally, we present our experimental results that show both the effectiveness of the introduced skyline extensions and the efficiency of the proposed algorithms.	algorithm;distribution (mathematics);point of sale;quality of service;service composability principle;web service	Karim Benouaret;Djamal Benslimane;Allel HadjAli	2012	2012 IEEE Ninth International Conference on Services Computing	10.1109/SCC.2012.84	mobile qos;computer science;data mining;database;world wide web	DB	-45.309324781449526	14.978273259532267	13855
6ab28618cd82021f812541a75d36f89c1c0c4ac6	automatic wsdl-guided test case generation for proper testing of web services		With web services already being key ingredients of modern web systems, automatic and easy-to-use but at the same time powerful and expressive testing frameworks for web services are increasingly important. Our work aims at fully automatic testing of web services: ideally the user only specifies properties that the web service is expected to satisfy, in the form of input-output relations, and the system handles all the rest. In this paper we present in detail the component which lies at the heart of this system: how the WSDL specification of a web service is used to automatically create test case generators that can be fed to PropEr, a property-based testing tool, to create structurally valid random test cases for its operations and check its responses. Although the process is fully automatic, our tool optionally allows the user to easily modify its output to either add semantic information to the generators or write properties that test for more involved functionality of the web services.	quickcheck;test automation;test case;web services description language;web service	Leonidas Lampropoulos;Konstantinos Sagonas	2012		10.4204/EPTCS.98.3	web service;web development;web modeling;web design;web standards;ws-policy;ws-addressing;database;programming language;ws-i basic profile;world wide web;mashup	SE	-40.721648439905906	11.799548333104553	13906
596dd3bbef715f2c11fda793c9584f23f43d66e6	variability modeling with the integrated variability modeling language (ivml) and easy-producer		EASy-Producer is an open-source research toolset for engineering product lines, variability-rich software ecosystems, and dynamic software product lines. In this tutorial, we will focus on its (textual) variability modeling capabilities as well as its configuration and validation functionality. Further, we will provide an outlook on how EASy-Producer can be applied to variability instantiation.	heart rate variability;microsoft outlook for mac;modeling language;open-source software;software ecosystem;software product line;spatial variability;universal instantiation	Klaus Schmid;Christian Kröher;Sascha El-Sharkawy	2018		10.1145/3233027.3233057	control engineering;modeling language;systems engineering;computer science;software	SE	-53.69832847412072	25.788237421877124	13938
eed2024e2c8c61dfed804fd02116e4e8036a7298	uml qos profile exploration for the specifications of a generic qos metamodel for designing and developing good quality web services		The work developed and reported in this thesis aims at contributing to research rnrelated to the Quality of Service (QoS) for the web services field. More specifically, rnthis work investigates the possibility of using the Unified Modeling Language (UML) rnas a specification language for QoS requirements. We started this research by rnreviewing the state-of-the-art on the use of UML as a metalanguage for QoS rndescription and specification. This research provided a comprehensive review and rndescription of the QoS specifications that comprise some already existing factors rncontributing to the QoS and some newly proposed ones. These include availability, rnaccessibility, reliability, integrity, service time, security, performance, transaction, rnexecution price, capacity, regulatory and reputation. Furthermore, the research has rnproposed a QoS metamodel as a lightweight extension to the Web Service rnDescription Language (WSDL) to incorporate the selected QoS specifications into rnweb servicesu0027 functionalities. The main question this research is trying to answer is, rnWhat makes a web service better than other web services providing the same rnfunctionality? Hence, the aim of this research is two fold, first it helps designers and rndevelopers to provide better web services and second, it helps web services users to rnselect the best web service for their applications.rnThe QoS metamodel illustrates what functionalities and how they can be rnextended with the proposed QoS specifications. The basic WSDL specification rnconsists of definition element as the root, and other elements that include types, rnmessage, portType, binding, service and import. All of these elements describe the rnfunctionality of a web service. This research sees the possibility of extending the rnWSDL specification to include a set of QoS specification to describe the non- rnfunctional requirement of a web service. These QoS specifications are vital as an rnaugmentation to the existing WSDL specification to assure high quality web services rndevelopment and implementation. The QoS metamodel could be used to realize the rnincorporation of the selected QoS specifications into the WSDL. Both the QoS rnspecifications and the QoS metamodel can be used as reference model for service rnproviders, designers, developers and users on how to provide, use and select good rnquality web services. The QoS metamodel is meant to be general and flexible. Therefore, it is not to restrict specific service providers or the use of a certain rntechnique, language or implementation approach.rnWe have illustrated a possible use of the QoS specifications and rnimplementation of the model by using a case study. However, we do not provide a full rnimplementation of the web services in the case study, as we do not intent to manage rna real Electronic Commerce (EC) application that deal with the actual business rnactivity. Time constraints, inadequate sources and technical problems were the rnfactors behind this limitation. Alternatively, we have conducted controlled rnexperiments that involved novice and experienced users as the validation method to rngive a practical experience to users in designing high quality web services. The rnresults from the validation and evaluation processes have shown that the research rncontributions are important and practical in nature. The outcome from the research rngives many advantages including encouraging the inclusion of quality requirements in rnthe design to help service providers to design and develop better quality web rnservices through the WSDL extension at the initial stage. We conclude by stating that rnwe have achieved the research objectives, come out with an original contributions rnand added knowledge to the web services QoS field.	metamodeling;quality of service;unified modeling language;web service	Wan Nurhayati Wan Ab. Rahman	2010			web standards;mobile qos;web modeling;service provider;web service;quality of service;ws-i basic profile;systems engineering;computer science;ws-policy	Theory	-48.210946494377545	17.925559275038903	13940
54308c752b46379dfa2abab79d1aa70d2d159404	overview of the air vehicle training systems demonstration project		STARS is an ARPA project aimed at advancing the management, quality, adaptability, and reliability of DoD software intensive systems. Over the years, the STARS project has gradually focused on enabling a paradigm shift of DoD software practices to megaprogramming. The central concept is a process-driven, two-life- cycle approach to software development. One life-cycle spans the creation and enrichment of an organizationu0027s capabilities for a family of related products, or domain engineering. The other life-cycle spans the construction and delivery of individual products from the domain, or application engineering. This approach may provide substantial opportunities for leveraged reuse, that is, planned use of adapted software components in multiple products. Much of the effort to date has been for developing tools and processes that support megaprogramming. The STARS project is now in a transition and demonstration phase. One of the demonstration projects is in the domain of simulator-based training, speci...		David C. Gross;Lynn D. Stuckey	1994	Simulation	10.1177/003754979406300509	simulation;engineering;automotive engineering;transport engineering	Robotics	-62.55600695919548	20.500832796379424	13942
938b03139329d4f817c48bb25cd1e3f40faae8b7	from user demand to software service: using machine learning to automate the requirements specification process		Bridging the gap between informal, imprecise, and vague user requirements descriptions and precise formalized specifications is the main task of requirements engineering. Techniques such as interviews or story telling are used when requirements engineers try to identify a user's needs. The requirements specification process is typically done in a dialogue between users, domain experts, and requirements engineers. In our research, we aim at automating the specification of requirements. The idea is to distinguish between untrained users and trained users, and to exploit domain knowledge learned from previous runs of our system. We let untrained users provide unstructured natural language descriptions, while we allow trained users to provide examples of behavioral descriptions. In both cases, our goal is to synthesize formal requirements models similar to statecharts. From requirements specification processes with trained users, behavioral ontologies are learned which are later used to support the requirements specification process for untrained users. Our research method is original in combining natural language processing and search-based techniques for the synthesis of requirements specifications. Our work is embedded in a larger project that aims at automating the whole software development and deployment process in envisioned future software service markets.	bridging (networking);embedded system;machine learning;nl (complexity);natural language processing;ontology (information science);requirement;requirements engineering;search-based software engineering;sequence diagram;service (systems architecture);software as a service;software deployment;software development;test bench;usage data;user requirements document;vagueness	Lorijn van Rooijen;Frederik Simon Bäumer;Marie Christin Platenius;Michaela Geierhos;Heiko Hamann;Gregor Engels	2017	2017 IEEE 25th International Requirements Engineering Conference Workshops (REW)	10.1109/REW.2017.26	non-functional testing;business requirements;requirement;requirements management;software requirements specification;requirements elicitation;requirements analysis;systems engineering;system requirements specification;computer science	SE	-57.60632646639912	24.3935377492886	13948
0eaef682f4c55f604a766c446c7a4505f44285d3	a product domain model based software product line engineering for web application	uml software product line engineering product domain model instance product dependency injection;maintainability product domain model based software product line engineering web application sple software product diversity software intensive systems industrial products transactional logic development cost design method application architecture uml based meta model variability notation dependency injection technology instance product banking products;uml;unified modeling language banking formal logic internet software cost estimation software maintenance software product lines;product domain model;software product line engineering;dependency injection;unified modeling language software business object oriented modeling banking design methodology computer architecture;instance product	Software product line engineering (SPLE) is a methodology for developing a diversity of software products and software intensive systems at lower costs, in shorter time, and with higher quality. SPLE is widely known to develop industrial products such as embedded system. However, for applying SPLE to develop Web applications which have to provide transactional logics for products such as financial products, the biggest issue is the lack of design method and application architecture to execute concurrently for a whole product line on the same runtime. Therefore development cost still tends to increase with frequent changes of the business requirements. We proposed two noble approaches to apply SPLE each for design method and application architecture. Firstly, for design method, we redefined the design scope of product as Product Domain Model, and designed a UML based meta-model which adds the notations of variability. Secondly, for application architecture, we adopted dependency injection technology to execute transaction logics for product line. We also defined a unit of logics for product line as Instance Product. To generate a plenty of resources regarding Instance Product, we created a generator which inputs Product Domain Model. In this paper, we introduce our approaches and evaluation by the pilot development of banking products. The results show that with our approaches, the issue of Web application development can be solved effectively, as well as the additional issue of maintainability.	applications architecture;business requirements;definition;dependency injection;domain model;embedded system;metamodeling;requirement;software product line;spatial variability;traceability;unified modeling language;web application development	Takashi Nerome;Masayuki Numao	2014	2014 Second International Symposium on Computing and Networking	10.1109/CANDAR.2014.105	domain analysis;reliability engineering;uml tool;computer science;systems engineering;product lifecycle;software development;software design description;product design specification;requirement;software engineering;domain engineering;product design;resource-oriented architecture;software measurement;new product development;feature model;product engineering;systems design	SE	-56.44276596738047	26.9572684174657	13983
73017c735b768a282d795aebba2972d452dbf233	towards iot platforms' integration semantic translations between w3c ssn and etsi saref		Several IoT ontologies have been developed lately to improve the semantic interoperability of IoT solutions. The most popular of these ontologies, the W3C Semantic Sensor Network (SSN), is considered an ontological foundation for diverse IoT initiatives, particularly OpenIoT. With characteristics similar to SSN, the ETSI Smart Appliances REFerence (SAREF) ontology evolved from the needs of smart home solutions to common requirements of IoT. Some IoT solutions rely on platform-specific ontologies and their integration requires mechanisms to align these ontologies. In this paper we discuss the ontology alignment between SSN and SAREF, identifying mapping alternatives and proposing basic mappings that can be re-used to define more complex ones. We introduce here an initial specification of the semantic translations from the main elements of SSN to SAREF, which includes classes, object properties and data properties. The alignment will be used in a semantic matching process leveraging the semantic mediator component of the INTER-IoT project. An initial evaluation of the translation was executed by translating the wind sensor (Vaisala WM30), an example provided by the W3C, from SSN to SAREF. This initial evaluation demonstrates the coherence and feasibility of the proposed mappings. University of Twente, Enschede, The Netherlands. {j.luizrebelomoreira@utwente.nl, l.ferreirapires@utwente.nl, m.j.vansinderen}@utwente.nl Netherlands Organisation for Applied Scientific Research, TNO. laura.daniele@tno.nl Systems Research Institute, Polish Academy of Sciences, Warsaw, Poland {katarzyna.wasielewska, pawel.szmeja, maria.ganzha, marcin.paprzycki}@ibspan.waw.pl §Faculty of Mathematics, Physics, and Informatics, University of Gdańsk, Poland w.pawlowski@inf.ug.edu.pl CCS Concepts •Information systems → Semantic web description languages;	academy;align (company);dmz (computing);home automation;informatics;iteration;language industry;ontology (information science);ontology alignment;platform-specific model;requirement;semantic sensor web;semantic web;semantic integration;semantic interoperability;semantic matching;semantic translation;subscriber identity module	João L. R. Moreira;Laura Daniele;Luís Ferreira Pires;Marten van Sinderen;Katarzyna Wasielewska;Pawel Szmeja;Wieslaw Pawlowski;Maria Ganzha;Marcin Paprzycki	2017			ontology alignment;semantic interoperability;data mining;wireless sensor network;semantic matching;computer science;home automation;semantics;interoperability;theoretical computer science;ontology (information science)	AI	-42.79286588497742	4.820931824652002	13987
228e874085a59d331571946ea94980383c6cac82	neuroinformatic modelling of oculomotor system	neuroinformatics;oculomotor system;modeling			Piotr Walecki	2009	Bio-Algorithms and Med-Systems			Robotics	-54.43263592733567	7.424105666880409	14004
54c8e27b41baba72fc8befe7fb136c5322ff2eea	knowledge acquisition, consistency checking and concurrency control for gene ontology (go)	knowledge base management system;knowledge acquisition;functional genomics;concurrency control;consistency checking;biological data;gene ontology	MOTIVATION A critical element of the computational infrastructure required for functional genomics is a shared language for communicating biological data and knowledge. The Gene Ontology (GO; http://www.geneontology.org) provides a taxonomy of concepts and their attributes for annotating gene products. As GO increases in size, its ongoing construction and maintenance becomes more challenging. In this paper, we assess the applicability of a Knowledge Base Management System (KBMS), Protégé-2000, to the maintenance and development of GO.   RESULTS We transferred GO to Protégé-2000 in order to evaluate its suitability for GO. The graphical user interface supported browsing and editing of GO. Tools for consistency checking identified minor inconsistencies in GO and opportunities to reduce redundancy in its representation. The Protégé Axiom Language proved useful for checking ontological consistency. The PROMPT tool allowed us to track changes to GO. Using Protégé-2000, we tested our ability to make changes and extensions to GO to refine the semantics of attributes and classify more concepts.   AVAILABILITY Gene Ontology in Protégé-2000 and the associated code are located at http://smi.stanford.edu/projects/helix/gokbms/. Protégé-2000 is available from http://protege.stanford.edu.	checking (action);concurrency (computer science);concurrency control;critical graph;functional genomics;gene ontology;graphical user interface;knowledge acquisition;knowledge base;management system;protégé;taxonomy (general);user interface device component	Iwei Yeh;Peter D. Karp;Natalya Fridman Noy;Russ B. Altman	2003	Bioinformatics	10.1093/bioinformatics/19.2.241	functional genomics;biological data;computer science;bioinformatics;concurrency control;data mining;database	AI	-40.43152721570281	10.71003992854764	14035
f0332661201e702d0be13e39432dbb34f526a643	a deontic logic semantics for licenses composition in the web of data	data licensing;semantic web	In the Web of Data, the absence of clarity about the licensing terms under which the data is released prevents data reuse, and thus data publication and interlinking at the expenses of the Web of Data itself. In addition, even when terms are clear, the absence of automated processing of the licenses prevents scaling data reuse and integration. In this paper, we provide a semantic model of licenses for the Web of Data. The key idea of our approach consists first in verifying the compatibility and compliance of the licensing terms associated to the data queried by the consumer, and second, if compatibility arises, in composing the single licenses into a unique license which provides the terms of reuse for the whole data consumed during the query solving. In particular, we propose a deontic logic semantics which is able to (i) formally define the deontic components of the licenses, i.e., Permissions, Obligations, and Prohibitions, and reason over them, (ii) verify the compatibility of the elements composing the single licenses, and return those elements which can be included into the composite license, and (iii) provide a formal account of the heuristics proposed to guide the composition.	deontic logic;heuristic (computer science);image scaling;semantic web;verification and validation;world wide web	Antonino Rotolo;Serena Villata;Fabien L. Gandon	2013		10.1145/2514601.2514614	computer science;artificial intelligence;semantic web;data mining;database;world wide web	Web+IR	-39.420782543085906	8.924078938326623	14054
1a7aef9b7fb4d5f8f66ab027ade4ec2b1727bbb3	bazaar: a conceptual framework for physical space applications	sensibilidad contexto;developpement logiciel;modelizacion;distributed system;base donnee;systeme reparti;context aware;informatique mobile;activite humaine;pervasive computing;database;base dato;aplicacion espacial;contextual information;conceptual framework;programming model;informatica difusa;modelisation;sistema repartido;informatique diffuse;desarrollo logicial;contexto;software development;contexte;ubiquitous computing;actividad humana;sensibilite contexte;mobile computing;modeling;human activity;context;application spatiale;space application	In ubiquitous computing era, the notion of context-awareness will play an important role. An application should be aware of its operating context for supporting and enriching human activities. Such contextual information is required to be extracted as seamlessly as possible through interaction between users and surrounding environments. This leads to the need for dealing with a wide variety of contextual information from a physical world. In this paper, we propose a conceptual framework, Bazaar, for modeling the physical world and for manipulating the model. It constructs the model with self-descriptive objects represented as a set of triples. Additionally, it provides a programming model for a developer so that he/she can intuitively manipulate the model and develop an application. We also report experiences with building a sample application.	context awareness;programming model;the cathedral and the bazaar;ubiquitous computing	Kaori Fujinami;Tetsuo Yamabe;Tatsuo Nakajima	2004		10.1007/11526858_14	simulation;systems modeling;human–computer interaction;computer science;artificial intelligence;software development;conceptual framework;programming paradigm;ubiquitous computing	HCI	-37.1240702637268	18.61697560026913	14096
deec0c5ab530bc35a2385308b181620ae700182d	cloud computing for global software development: opportunities and challenges	global software development gsd;risk analysis;risk management;it systems management;cloud computing	The cloud computing paradigm offers an innovative and promising vision concerning Information and Communications Technology. Actually, it provides the possibility of improving IT systems management and is changing the way in which hardware and software are designed and purchased. This paper introduces challenges in Global Software Development (GSD) and application of cloud computing platforms as a solution to some problems. Even though cloud computing provides compelling benefits and cost-effective options for GSD, new risks and difficulties must be taken into account. Thus, the paper presents a study about the risk issues involved in cloud computing. It highlights the different types of risks and how their existence can affect GSD. It also proposes a new risk management process model. The risk model employs new processes for risk analysis and assessment. Its aim is to analyse cloud risks quantitatively and, consequently, prioritise them according to their impact on different GSD objectives. Cloud Computing for Global Software Development: Opportunities and Challenges	cloud computing;financial risk modeling;it risk management;process modeling;programming paradigm;software development;systems management	Thamer Al-Rousan	2015	IJCAC	10.4018/ijcac.2015010105	simulation;systems engineering;engineering;software engineering	SE	-59.93426293524899	20.275029524467257	14109
6b0a4008d306e7264304e1c8674eb7417a2c9694	standardization of high-level languages	programming language;cobol;fortran;high level language	"""The terms """"compatibility"""", commonality,"""" and """"transferability"""" are used in discussing the mobility of programs and programmers. The common element essential to such mobility is the establishment of standards for programs, programmers, and documentation. The adoption of high-level programming languages such as COBOL, FORTRAN, ALGOL, and JOVIAL is a required element of such standards. The high-level languages are innately self-documenting---an essential for transferability. Thus, their use provides assistance in the transfer of programs among activities; the conversion from one computer generation to another; the conversion from one computer manufacturer to another; and the transfer of programs for back-up and readiness."""	algol;backup;cobol;computer compatibility;fortran;high- and low-level;high-level programming language;history of computing hardware;jovial;programmer;self-documenting code;software documentation	Grace M. Hopper	1969		10.1145/1476793.1476890	object-based language;computer science;third-generation programming language;software engineering;computer programming;programming language;second-generation programming language;high-level programming language	PL	-50.39098703222487	32.03192668574411	14146
08905ae3f3a7d986f3d935e089ca52b603fb055e	model transformation based on meta templates	model transformation;metamodeling;modeling;model driven engineering;life span;software engineering	Model-Driven Engineering (MDE) is a model-centric software engineering approach which aims at improving the quality and life span of software artifacts by focusing on the design models instead of code. Model transformation is a key aspect of MDE system. In this paper, we introduce a model transformation framework based on Hierarchical Relational Metamodel (HRM). Its design motivation and details are discussed and related work is presented for comparison.	human race machine;metamodeling;model transformation;model-driven engineering;model-driven integration;prototype;software engineering;unified modeling language	Hongming Liu;Lizhang Qin;Xiaoping Jia;Adam Steele	2006			metamodeling;template;model transformation;domain model;model-driven architecture;systems engineering;engineering	SE	-51.87479560700913	26.29429468026032	14171
d9f30a6730ebdae02fe36995bd9754476e318565	supporting production strategies as refinements of the production process	artefacto;developpement logiciel;variabilidad;comercializacion;artefact;production process;commercialisation;refinement method;marketing;desarrollo logicial;software development;processus fabrication;software package;estructura producto;progiciel;methode raffinement;variability;software product line;variabilite;metodo afinamiento;structure produit;paquete programa;product structure;proceso fabricacion	The promotion of a clear separation between artifact construction and artifact assembling is one of the hallmarks of software product lines. This work rests on the assumption that the mechanisms for producing products considerably quicker, cheaper or at a higher quality, rest not only on the artifacts but on the assembling process itself. This leads to promoting production processes as “first-class artifacts”, and as such, liable to vary to accommodate distinct features. Production process variability and its role to support either production features or production strategies are analyzed. As prove of concept, the AHEAD Tool Suite is used to support a sample application where features require variations on the	apache ant (another neat tool);artifact (software development);heart rate variability;process specification;programmer;software product line;sourceforge	Oscar Díaz;Salvador Trujillo;Felipe I. Anfurrutia	2005		10.1007/11554844_23	engineering;software development;scheduling	SE	-62.2932945494031	22.022899183666333	14180
d140810676679dd27ec5e98bee46668659f6661c	geo-social model: a conceptual framework for real-time geocollaboration		Synchronous geocollaboration helps geographically dispersed people to work together in a shared geospatial environment. Its real-time nature, multiple users’ interaction and diversity of work context impose some special social, organizational and technological requirements, making the development of such realtime geocollaboration systems a challenging task. A conceptual framework is therefore needed to specify and describe what synchronous geocollaboration is, considering its social, spatial and technical aspects. The geo-social model presented in this article describes a conceptual framework for synchronous geocollaboration systems addressing the above aspects, identifies the core elements of the system and describes how these elements collaborate with each other. This model is presented using application-level ontology and is then applied to a multi-agent system based prototype in which multiple users can interact and negotiate in a shared 3D geospatial environment.	agent communications language;artificial intelligence;behavior model;blackwell (series);computer science;data model;data recovery;graphics;human–computer interaction;java;logic programming;machine to machine;multi-agent system;multi-user;ontology (information science);prototype;public participation geographic information system;real-time clock;real-time locating system;real-time transcription;requirement;requirements analysis;simulation;situated;social welfare model;systems design;systems theory;vehicle tracking system;whole earth 'lectronic link;xml	Zheng Chang;Songnian Li	2013	Trans. GIS	10.1111/j.1467-9671.2012.01352.x	simulation;computer science;knowledge management;artificial intelligence;database;management science	HCI	-49.19353585219861	9.816210929349717	14181
7767c32733e7558960a1dae8817ec492f091e0e9	behavioral consistency measurement and analysis of ws-bpel processes	bpel processes;behavioral consistency;bpel program dependence graph;会议论文;process alignment	With the development of services and cloud computing, service-based business processes (e.g., WS-BPEL processes) are paid more attention by practitioners. Business parties usually keep their BPEL processes in a process repository. In order to facilitate the retrieval, maintenance, and reuse of BPEL processes in the repository, we need an appropriate measurement criterion to analyze the behavioral consistency between BPEL processes. In this paper, we propose a novel measurement criterion and corresponding analysis approach to determine the behavioral consistency between two BPEL processes quantitatively. Our measurement and approach are based on BPEL program dependence graphs (BPDGs). We have faithfully implemented our approach in a prototype tool which is used to analyze the behavioral consistency of BPEL processes.	business process execution language	Xuewei Zhang;Wei Song;Jianchun Xing;Qiliang Yang;Hongda Wang;Wenjia Zhang	2013		10.1007/978-3-642-38562-9_63	computer science;knowledge management;data mining;database	Metrics	-56.02203577046629	20.67221266124018	14206
1855d93775aed26debf9454752457bec83403a3b	aspect-oriented modeling of ubiquitous web applications: the aspectwebml approach	context aware;information systems;application software;aspect oriented modeling;model adaptation;bridges;customization functionality aspect oriented modeling ubiquitous web application aspectwebml approach web modeling languages;object oriented programming;development process;software engineering;context of use;modeling language;ubiquitous computing internet object oriented programming specification languages;proof of concept;domain specific modeling language;ubiquitous web application;internet;aspectwebml approach;specification languages;web modeling languages;domain specific language;ubiquitous web applications;ubiquitous computing;crosscutting concerns;aspect oriented;application software context aware services context modeling bridges software engineering service oriented architecture internet interactive systems information systems educational institutions;point of view;customization functionality;service oriented architecture;context modeling;interactive systems;reference architecture;context aware services	Ubiquitous Web applications (UWA) are required to be customizable, meaning their services need to be adaptable towards the context of use, e.g., user, location, time, and device. Considering UWA 's from a software engineering point of view, a systematic development on basis of models is crucial. Current Web modeling languages, however, often disregard the crosscutting nature of customization potentially affecting all parts of a Web application, and often mingle core and customization functionality. This leads to inefficient development processes, high maintenance overheads, and a low potential for reuse. We regard customization as a crosscutting concern in the sense of the aspect-oriented paradigm. As a proof of concept, we extend the prominent Web modeling language WebML on basis of our reference architecture for aspect-oriented modeling. This allows for a clear separation between the core and customization functionality, and - as a spin-off - demonstrates how to bridge existing (domain-specific) modeling languages with aspect-oriented concepts	aspect-oriented software development;cross-cutting concern;domain-specific modeling;modeling language;programming paradigm;reference architecture;software engineering;web application;web modeling;webml	Andrea Schauerhuber;Manuel Wimmer;Wieland Schwinger;Elisabeth Kapsammer;Werner Retschitzegger	2007	14th Annual IEEE International Conference and Workshops on the Engineering of Computer-Based Systems (ECBS'07)	10.1109/ECBS.2007.20	reference architecture;application software;web modeling;the internet;aspect-oriented programming;computer science;domain-specific language;service-oriented architecture;database;context model;modeling language;programming language;object-oriented programming;proof of concept;world wide web;ubiquitous computing;software development process;information system	SE	-47.98006282390914	19.35868042700132	14227
6255f991a503578d4e697f934719777036a7df65	using uml models and formal verification in model-based testing	unified modeling language formal verification program testing theorem proving;uml b;formal model;event b;theorem provers;uml b test generator tool;behavior modeling;semantics;system under test;testing;event b uml b uml based testing model based testing;theorem provers uml models formal verification model based testing approach qtronic test generator tool uml b test generator tool system under test mathematical semantics event b specifications;event b specifications;modeling language;theorem proving;mathematical semantics;model based testing approach;theorem prover;computational modeling;adaptation model;formal verification;program testing;qtronic test generator tool;unified modeling language;uml models;mathematical model;test generation;model based testing;uml based testing;unified modeling language formal verification system testing automatic testing visualization mobile handsets conferences systems engineering and theory computer science information technology;data models	In this paper we present a model-based testing approach where we integrate UML, UML-B and the Qtronic test generator tool, with the purpose of increasing the quality of models used for test generation via formal verification. The architectural and behavioral models of the system under test (SUT) are specified in UML and UML-B, respectively. UMLB provides UML-like visualization with precise mathematical semantics. UML-B models are developed in a stepwise manner which are then automatically translated into Event-B specifications that can be proved using theorem provers. Once the formal models are proved, they are transformed into QML which is a modeling language used by the test generation tool.	b-method;denotational semantics;formal verification;model-based testing;qml;sequal framework;stepwise regression;system under test;unified modeling language	Qaisar A. Malik;Dragos Truscan;Johan Lilius	2010	2010 17th IEEE International Conference and Workshops on Engineering of Computer Based Systems	10.1109/ECBS.2010.13	uml tool;computer science;theoretical computer science;applications of uml;semantics;automated theorem proving;programming language;algorithm	SE	-45.66577622512718	31.3997661778191	14230
0a021881a2a8dfa5cafb0587e837abad7aa72ec6	the role of context in exception-driven rework		Exception-driven rework occurs commonly in software development. In this paper, we describe a simple refactoring process, showing the use of the exception-driven rework exception handling pattern within it. We also discuss the important role that context plays in supporting the user during rework in helping the user keep track of the tasks being worked on and to facilitate resumption of normal activities upon completion of the exception handling work. The example process is specified in the Little-JIL process definition language. The use of context information in supporting the user is illustrated using a Data Derivation Graph (DDG), a graph that is automatically generated to document the ways in which artifact values are evolved during execution of a Little-JIL process.	code refactoring;duckduckgo;exception handling;graph (discrete mathematics);rework (electronics);software development	Xiang Zhao;Barbara Lerner;Leon J. Osterweil	2012	2012 5th International Workshop on Exception Handling (WEH)		computer science;systems engineering;database;programming language	HCI	-53.611572149428774	29.44580086633942	14232
5172cca2237bdad0d63c645f120cd47af10b7b8e	architectural concerns when selecting an in-house integration strategy - experiences from industry	corporate acquisitions;investments;mathematics;software systems;consumer electronics;industrial electronics;computer industry;computer industry electronics industry investments computer science consumer electronics industrial electronics mathematics software systems corporate acquisitions data models;electronics industry;computer science;point of view;data models	Consider the scenario where two or more software systems have been developed in-house, for different purposes. Over time, the systems have been evolved to contain more functionality, until a point where there is some overlap in functionality and purpose. The same situation occurs, only more drastically, as a result of company acquisitions and mergers. A new system combining the functionality of the existing systems would improve the situation both from an economical and maintenance point of view, and from the point of view of users, marketing and customers.	overlap (term rewriting);point of view (computer hardware company);software system	Rikard Land;Laurens Blankers;Stig Larsson;Ivica Crnkovic	2005	5th Working IEEE/IFIP Conference on Software Architecture (WICSA'05)	10.1109/WICSA.2005.13	electronics;computer science;systems engineering;engineering;software engineering	Robotics	-62.01598496475864	22.8692101061793	14235
3c3b00b8f0d9a87d4151300da70bb43bd3ea16af	a survey of context-aware cross-digital library personalization	cross digital library personalization;theoretical computer science;computer science all;user model interoperability;user profile;interoperability approaches;user context	The constant interaction of users with different Digital Libraries (DLs) and the subsequent scattering of user information across them raise the need not only for Digital Library interoperability but also for cross-Digital Library personalization. The latter calls for sharing and combining of user-information across different DL systems so that a DL system may take advantage of data from others. To achieve this goal, DL systems should be able to maintain compliant and interoperable user models and profiles that enable propagation and reconciliation of user information across different DLs. In this paper, we motivate the need for cross-Digital Library personalization, we define and examine user model, profile, and context interoperability, and we survey and discuss existing user model interoperability approaches.	digital library;interoperability;personalization;privacy;semiconductor consolidation;software propagation;user modeling;user profile	Ana Nika;Tiziana Catarci;Yannis E. Ioannidis;Akrivi Katifori;Georgia Koutrika;Natalia Manola;Andreas Nürnberger;Manfred Thaller	2010		10.1007/978-3-642-27169-4_2	semantic interoperability;computer science;data mining;multimedia;world wide web	HCI	-43.12878783024332	9.004004099657822	14246
63aff9e39ca55237bfed1cbc1102f6cd08e6bd1b	a novel artificial life ecosystem environment model	modelizacion;information communication;artificial ecosystem;ecosysteme artificiel;modelo 3 dimensiones;traitement flux donnee;two dimensions;ecosistema artificial;modele 3 dimensions;localization;espacio 3 dimensiones;three dimensional model;mesure niveau;information space;localizacion;flow models;three dimensional;grid;modelisation;modele ecoulement;informal communication;communication information;information flow;vie artificielle;localisation;modelo 2 dimensiones;rejilla;espace 3 dimensions;automate cellulaire;data flow processing;three dimensional space;level measurement;modele 2 dimensions;comunicacion informacion;grille;modeling;cellular automaton;artificial life;two dimensional model;medicion nivel;automata celular	This paper presents information flow model and a novel artificial life grid model to construct artificial life computer ecosystem environment. The life grid model is a three-dimensional information space: (time, artificial life node, and location). The former two dimensions identify the contents or function of artificial life systems, and the third-dimension identifies the location where an artificial life system exists. We depart the artificial life node architecture into four levels: artificial life system application level, engine library level, sensor level, and the connectivity level. In information flow model, we present the ALife information definition, characteristic and four kinds of information communication mechanisms (broad-diffuse, Multi-diffuse, uni-diffuse and anydiffuse).	artificial life;ecosystem;information flow (information theory);organizing (structure);self-organization;simulation	Zhengyou Xia;Yichuan Jiang	2004		10.1007/978-3-540-30479-1_67	cellular automaton;three-dimensional space;simulation;computer science;artificial intelligence;mathematics;algorithm	HCI	-37.61267913747081	17.214403835507035	14321
8fa8b8ded9c25e73322ad6fdf0063d60e20de463	metaphor processing for learning terminology on the web	systeme intelligent;knowledge based system;web pages;red www;learning;sistema inteligente;lengua extranjera;base connaissance;langue etrangere;corpus linguistic;aprendizaje;apprentissage;metafora;computational linguistic;knowledge acquisition;intelligent system;world wide web;base conocimiento;reseau www;foreign language;metaphor;langage xml;metaphore;knowledge base	An approach for the usage of metaphors in learning terminology in a foreign language is presented. The approach integrates ideas from the metaphor theory of Lakoff and Johnson [6] with techniques from corpus-based computational linguistics, advanced markup languages on the web (XML and XSL), and knowledge acquisition and processing. Metaphors are identified by semi-automatic methods and are annotated accordingly to domain and metaphor ontologies. The corpus with annotated metaphors, together with the domain and metaphor ontologies are used for dynamically generation of personalized web pages.	computational linguistics;interface metaphor;knowledge acquisition;knowledge-based systems;markup language;ontology (information science);personalization;semiconductor industry;standard generalized markup language;text corpus;web page;world wide web;xml	Stefan Trausan-Matu	2000		10.1007/3-540-45331-8_22	foreign language;natural language processing;knowledge base;computer science;artificial intelligence;web page;database	NLP	-37.68402256797625	11.583411546125266	14418
d7934513e2b62d99b328f747fd1227edcd42cac7	similarity measures for skill-profile matching in enterprise knowledge management	knowledge management;similarity measure	At DaimlerChrysler’s truck plant in Wörth, we are currently implementing a comprehensive IT solution for integrated and synergistic processes in personnel development. In this paper, we sketch some ontologybased software modules – as well as their interdependencies and synergies – which support streamlined and integrated, comprehensive personnel-development processes. A central element in the software architecture is ontology-based similarity assessment for skill-profile matching which is exemplarily discussed for software-supported project staffing.	interdependence;knowledge management;software architecture;synergy	Ernst Biesalski;Andreas Abecker	2006			computer science;knowledge management;pattern recognition;data mining	SE	-58.56819384581528	13.59269360981616	14455
421078d29d7f21cf341864b1a058dd1938a9c7b8	towards a business-centric definition of access control policies	authorisation;unified modeling language authorisation business data processing;access control policy;business data processing;unified modeling language;access control unified modeling language medical services context adaptation models object oriented modeling;security policies design business centric definition access control policies security requirements business requirements forensic rules business logic functional requirements uml bpmn business processes engineering	Security requirements are part of business requirements, either because they derive from forensic rules, or because they derive from the business logic that should be translated into functional requirements to guaranty that a system meets its users' needs. Extending several notations such as the UML and the BPMN has been proposed as a means to bridge the gap between business processes engineering, security policies design and system engineering. However, a gap remains between these extensions on the one hand and between the large number of access control models on the other hand. Business logic, system engineering and security design thus remain separated when they should be intertwined. In this paper, we address this issue by defining a metamodel for access control to gather the different aspects of access control. We then introduce extensions to the UML et to BPMN that we derive from this metamodel and show that from a business-centric perspective, we can derive functional requirements, and model security to generate actual security policies.	access control;business logic;business process;business requirements;control engineering;enterprise javabeans;experiment;functional requirement;generic programming;graphical user interface;java platform, enterprise edition;metamodeling;systems engineering;transformers;ubiquitous computing;unified modeling language;usability;xacml	Aurélien Faravelon;Christine Verdier;Agnès Front	2011	2011 FIFTH INTERNATIONAL CONFERENCE ON RESEARCH CHALLENGES IN INFORMATION SCIENCE	10.1109/RCIS.2011.6006835	unified modeling language;semantics of business vocabulary and business rules;business requirements;goal modeling;computer science;systems engineering;knowledge management;artifact-centric business process model;software engineering;data mining;database;business process model and notation;authorization;business rule;new business development;business process modeling	DB	-55.79422751281531	19.250883820634872	14488
888ecda4acc7aa35b29b012e5fa67397f8619246	indexing semi-structured documents for context-based information retrieval in a medical information system	database indexing;page description languages;qualifying process semi structured document indexing context based information retrieval medical information system information retrieval models sgml like structured documents medical informatics patient record document structuration process a priori structure authoring tool embedded information qualifiers sgml like dtd retrieval process patient records collection;indexing information retrieval medical diagnostic imaging diseases medical information systems postal services frequency calculus text analysis xml;information retrieval;information retrieval model;information retrieval medical information systems database indexing authoring systems thesauri page description languages;thesauri;authoring systems;electronic documents;patient record;medical information systems;pattern matching;medical information system;indexation;medical informatic;structured documents;authoring tool	Most of Information Retrieval models for documents are intended for SGML-like structured documents. In the context of medical informatics, the Patient Record document needs a looser structuration process as an a priori structure can hardly be defined. Thus we first propose an authoring tool that allows to annotate embedded information, i.e. to give them a context, with qualifiers that are stored in a thesaurus rather than in SGML-like DTD. The retrieval process in the Patient Records collection takes into account the flexibility of the qualifying process while reformulating the queries.	embedded system;informatics;information retrieval;information system;logical unit number;loose coupling;partial template specialization;pattern matching;performance rating;standard generalized markup language;thesaurus	Frédérique Laforest;Anne Tchounikine	1999		10.1109/DEXA.1999.795252	database index;computer science;pattern matching;data mining;database;programming language;world wide web;information retrieval	Web+IR	-39.62087652539895	5.951607826175226	14642
d25eebc45ecfbbf1ec90a0bac7a91f0de0357563	architecture-centric derivation of products in a software product line		It is essential to architecture-centric product line development that product line architecture can be used to drive activities specific to product line development, such as product derivation. This requires a mechanism that can automatically derive the architecture and code of a product instance from the customization of product line architecture. In this paper, we analyze the insufficiency of two existing solutions in this area and present an architecture-centric approach that meets the requirement. The approach can support product line differences in platforms and functions, and generate both product line code and product code. It is based on a product line implementation mechanism that combines a code generation and separation pattern with an architecture-based code annotation technique. We have implemented the approach, and finished a preliminary evaluation with a chat application.	software product line	Cuong Cu;Yongjie Zheng	2016		10.1109/MiSE.2016.013	multilayered architecture;reference architecture;computer science;systems engineering;product design specification;software engineering;solution architecture;software architecture description;product design;engineering drawing;feature model;product engineering;systems design	Theory	-55.44522002937588	27.7188700827147	14660
1112e89a33ba5dda6c28bc5dd16c5a4b8a0839f0	workflow similarity measure for process clustering in grid	cluster algorithm;pattern clustering;grid workflow process clustering;eca rules;grid services;data mining;event condition action rule;process design;grid resources;grid service;event condition action;workflow similarity measure;pattern clustering data mining grid computing;grid computing;similarity measure;event condition action rule workflow similarity measure grid services grid resources grid workflow process clustering knowledge discovery;atomic measurements process design clustering algorithms pattern analysis databases computer science knowledge engineering ontologies merging workflow management software;knowledge discovery	In grid environment, workflow process can be seen as not only cooperative approach of grid services and resources, but also reusable and sharable knowledge to settle specific problem. The research of grid workflow process clustering can promote knowledge discovery and reuse in grid. In this paper, we put forward a grid workflow process design method using event-condition-action (ECA) rule, and propose a new process similarity measure approach. Then, we use a case to prove the feasibility of the approach and show how to revise present clustering algorithm with the similarity measure approach briefly.	algorithm;cluster analysis;event condition action;similarity measure	Yi Wang;Minglu Li;Jian Cao;Xinhua Lin;Feilong Tang	2007	Fourth International Conference on Fuzzy Systems and Knowledge Discovery (FSKD 2007)	10.1109/FSKD.2007.618	process design;computer science;data science;data mining;database;knowledge extraction;workflow management system;grid computing;workflow technology	HPC	-45.027929000380034	7.543210873593539	14673
b20e56473bf597f180c64aca5d366b0685f35223	towards a pattern science for the semantic web	cognitive science;linked data;frames;semantic web;knowledge patterns;contexts	With the web of data, the semantic web can be an empirical science. Two problems have to be dealt with. The knowledge soup problem is about semantic heterogeneity, and can be considered a difficult technical issue, which needs appropriate transformation and inferential pipelines that can help making sense of the different knowledge contexts. The knowledge boundary problem is at the core of empirical investigation over the semantic web: what are the meaningful units that constitute the research objects for the semantic web? This question touches many aspects of semantic web studies: data, schemata, representation and reasoning, interaction, linguistic grounding, etc.	inferential programming;knowledge management;named graph;pipeline (computing);programming paradigm;regular expression;semantic web;semantic heterogeneity	Aldo Gangemi;Valentina Presutti	2010	Semantic Web	10.3233/SW-2010-0020	natural language processing;semantic interoperability;semantic similarity;semantic computing;web modeling;semantic search;semantic grid;web standards;computer science;knowledge management;semantic web;social semantic web;linked data;data mining;semantic web stack;semantic equivalence;web intelligence;semantic technology;semantic analytics	AI	-39.37796182901293	5.330665198880121	14780
6056143bd3d638334f909210faeb8ff5cdd188df	a multi-agent system based approach to intelligent process automation systems	task performance;monitoring operation;supervisory control;multi agent system;fault tolerant;software agent;software systems;control operation;agent;software architecture;process monitoring;agent technology;distributed planning;automation system	A more promising technology to integrate existing software systems and their functionalities and to add assistant systems for the shop floors is to be found in software agents. Concerning with the applications of agent technology to intelligent process automation systems, a flexible and extensible approach based on multi-agent system (MAS) and distributed planning technique to reach for increased flexibility and fault-tolerance in process monitoring and control operations is proposed. The monitoring operations are aimed at combining information from different sources depending on the monitoring tasks. The control operations are supervisory control tasks performing either in both sequential and iterative forms. The agent layer is used for monitoring the operations of the lower-level automation systems and reconfiguring its control logic. It operates as a distributed planning and plan execution system to increase the operational flexibility of the whole process automation systems. The software architecture and its functionalities and components for the implementation of the proposed approach are also presented. The design strategy and the discussion on the proposed approach are provided.	automated planning and scheduling;automation;fault tolerance;iteration;multi-agent system;software agent;software architecture;software system	Vu Van Tan;Myeong-Jae Yi	2009		10.1007/978-3-642-11161-7_30	agent architecture;embedded system;software architecture;fault tolerance;real-time computing;computer science;artificial intelligence;process automation system;software agent;multi-agent system;real-time control system software;supervisory control;totally integrated automation;software system	Robotics	-54.12453733242278	11.652630059353404	14803
add5467af48732887ef2bdf47379cc8e07bcdaa9	conversation protocols: a formalism for specification and verification of reactive electronic services	top down method;methode descendante;realizabilidad;red www;asynchrone;top down;maquina estado finito;specification;web accessibility;reseau web;service web;conversacion;automaton;web service;asynchronisation;electronic services;automata;col;asynchronism;internet;specification and verification;especificacion;metodo descendente;finite state automata;asynchronous communication;automate;envoi message;conversation;message passing;realizability;world wide web;machine etat fini;finite state machine;asincronia;asincrono;realisabilite;asynchronous;servicio web	This paper focuses on the realizability problem of a framework for modeling and specifying the global behavior of reactive electronic services (e-services). In this framework, Web accessible programs (peers) communicate by asynchronous message passing, and a virtual global watcher listens silently to the network. The global behavior is characterized by a conversation, which is the infinite sequence of messages observed by the watcher. We show that given a Buchi automaton specifying the desired set of conversations, called a conversation protocol, it is possible to implement it using a set of finite state peers if three realizability conditions are satisfied. In particular, the synthesized peers will conform to the protocol by generating only those conversations specified by the protocol. Our results enable a top-down verification strategy where: (1) A conversation protocol is specified by a realizable Buchi automaton, (2) The properties of the protocol are verified on the Buchi automaton specification, (3) The peer implementations are synthesized from the protocol via projection.	semantics (computer science)	Xiang Fu;Tevfik Bultan;Jianwen Su	2003		10.1007/3-540-45089-0_18	computer science;artificial intelligence;theoretical computer science;operating system;asynchronous communication;database;distributed computing;automaton;finite-state machine;programming language;world wide web;computer security;algorithm	Security	-40.03690772440091	24.925687731325006	14850
2c1e1f83a286fcb763a1b53a58424cd60b1806cb	identification of versions in databases of software components	software component	1 Introduction Evolution of software systems during all stages of development and maintenance requires some sort of management of diierent versions (variants or revisions) of software components as well as of whole systems. Software connguration management (SCM) involves applying various methods, possibly supported by specialized tools. One special, but very frequent situation is that the development of a software system is supported by some CASE tool. In such a case, all kinds of documents (not only source text units, but also their descriptions, speciication diagrams etc.) are stored in a database (repository) that the CASE tool operates upon. On the one hand, the fact that all the components are available in a database (i.e., in electronic form with a deened organization) creates a very favourable condition for managing their versions in an automated way. On the other hand, application of SCM methods and tools in a CASE supported development is connected with several problems. In the paper, we analyze some of the problems connected with integrating SCM with CASE. We concentrated mainly on connguration identiication as one of the most fundamental SCM processes 1]. We propose a technique of identifying versions of software system process models as described by data ow diagrams. We report on a rst experience with applying the technique.	component-based software engineering;computer-aided software engineering;database;diagram;document;entity;experiment;maximal set;requirement;smoothing;software system;systems engineering;version control	Pavol Návrat;Mária Bieliková	1997			actuator;database;lock (computer science);coil spring;computer science;detent	SE	-51.18816794614044	22.88040376992983	14887
293ae4bea226e8d137fdf439ab5837a301487bf9	toward engineered, useful use cases	use case	We explore common problems that exist in the practice of use case modeling: lack of consistency in defining use cases, misalignment between the UML metamodel and the textual representations of use cases expounded in the literature, and the lack of a semantics that allows use cases to be executable and analyzable. We propose an engineering approach to the issues that can provide a precise foundation for use case development. We next discuss four potential uses of such a foundation and identify the research problems that must be addressed to support these applications.	executable;metamodeling;unified modeling language	Clay Williams;Matthew Kaplan;Tim Klinger;Amit M. Paradkar	2005	Journal of Object Technology	10.5381/jot.2005.4.6.a4	use case;use-case analysis;computer science;systems engineering;data mining;management science	SE	-55.86984662617341	23.361412812636313	14893
89c89f2f1ceee546ad312f964f0238bf36642e5c	web gis for multiple representation data	multiple representation;open geospatial consortium;spatial data;web map service;web map service web gis multiple representation data geospatial information internet web services archeological objects open geospatial consortium web feature service;geographic information systems spatial databases web services visual databases size measurement data visualization service oriented architecture object oriented databases web and internet services standards publication;web service;web feature service;spatial database;archeological objects;internet;geospatial information;geographic information systems;levels of abstraction;web services;spatial representation;internet geographic information systems;web gis;multiple representation data	"""This paper explains the concepts that deal with integrating and managing different levels of abstraction of spatial data within GIS and Web services; """"distributing geospatial information on the Internet is an motivating factor for information providers"""", and also it presents the applications of Web services utilizing a multiple representations database, which could be described as a spatial database, and can also be used to store the same real world phenomenon at different levels of semantic and geometric details. Certain spatial phenomena are represented more than once in different databases, while the content depends on the intention of the data collector. Different applications and situations require alternative information and also visualizations of the data that the user should be able to choose within the alternative representations. This paper will also focus on Web services, which will be used to solve the problems in the spatial representation of archeological objects. Tire widespread architectural system for accessing and serving spatial data includes standard interfaces that is published by the open geospatial consortium (OGC), like Web feature service (WFS) and Web map service (WMS) which is designed for single represented data that include only one single representation per object, and also this paper will point out how to use a multiple representation of spatial data into Web architecture."""	geographic information system;internet;music visualization;principle of abstraction;spatial analysis;spatial database;web feature service;web map service;web service	El-Hadi Khoumeri;Djamal Benslimane	2007	2007 2nd International Conference on Digital Information Management	10.1109/ICDIM.2007.4444221	web service;sensor web;distributed gis;spatial data infrastructure;web development;web modeling;data web;web mapping;web standards;computer science;geospatial analysis;web navigation;social semantic web;data mining;database;web intelligence;law;world wide web;spatial database;web feature service;web coverage service	DB	-36.1649683268889	9.937806714125973	14912
39521c98598ba14510f3a5277ffd50c00d32d71d	simulation-based verification of system requirements: an integrated solution		Modeling of system properties deals with formally expressing constraints and requirements that influence and determine the structure and behavior of a system. System Property Models enable the verification of system properties through real or simulated experiments so as to support their evaluation during system design and their monitoring during system operation. However, several challenges should be addressed to effectively handle systems properties with the support of an integrated tool-chain. In this context, the paper presents the concrete experimentation of a promising solution that enables the formal modeling of requirements in Modelica and their subsequent simulation-based verification. The solution is applied to evaluate different design variants of a trailing-edge high-lift system. In particular, two ways to feed the requirements model are explored: in an early phase, data series are used to evaluate the requirements themselves; then a co-simulation of the requirements model with the 3D-model of the system is used to evaluate and identify what design variants best meet the system requirements.	co-simulation;experiment;requirement;simulation;system requirements;systems design;toolchain;verification (spaceflight)	Francesco Aiello;Alfredo Garro;Yves Lemmens;Stefan Dutré	2017	2017 IEEE 14th International Conference on Networking, Sensing and Control (ICNSC)	10.1109/ICNSC.2017.8000180	electro-mechanical modeling;control engineering;non-functional testing;object-oriented modeling;data modeling;non-functional requirement;systems design;systems engineering;modelica;computer science;system requirements	SE	-43.91365631183771	31.956083596525723	14934
36109e6aa3ce640ac6370cb2293c3fadfe771169	structured natural language requirements in nuclear energy domain towards improving regulatory guidelines	finnish public authority guidelines safety critical application domains public authorities structured natural language templates ears nuclear energy domain power companies;nuclear power;control systems;fission reactor theory;natural languages;companies;requirements engineering;control system;authority requirements;ear;syntactics;structured natural language requirements requirements engineering authority requirements regulatory compliance nuclear energy;requirement engineering;natural language;safety;ear safety natural languages inductors control systems companies syntactics;structured natural language requirements;inductors;fission reactor safety;nuclear power fission reactor safety fission reactor theory;regulatory compliance;nuclear energy	Requirements of a system are gathered from various stakeholders, but especially in safety critical application domains, such as the nuclear energy domain, public authorities also impose requirements. Major parts of requirements are often written in natural language. Despite being widely applied and a convenient means, natural language requirements have deficiencies such as impreciseness and vagueness. One approach to improve especially existing requirements is to rewrite the requirements applying structured natural language templates such as Easy Approach to Requirements Syntax (EARS). In this paper, we describe results of an initial quasi-experimental study of applying EARS to nuclear energy domain requirements. The initial results were assessed by stakeholders from public authorities and power companies, and show improvement and utility of applying EARS. Finally, we describe our planned future work to apply EARS to parts of Finnish public authority guidelines for nuclear safety (YVL), which are currently undergoing major rework.	application domain;experiment;natural language;requirement;rework (electronics);rewrite (programming);syntax highlighting;vagueness	Eero J. Uusitalo;Mikko Raatikainen;Tomi Männistö;Teemu Tommila	2011	2011 Fourth International Workshop on Requirements Engineering and Law	10.1109/RELAW.2011.6050274	requirements analysis;requirements management;business requirements;systems engineering;engineering;requirements elicitation;mechanical engineering	SE	-55.86202502612197	22.798295451401557	14956
81b0b299aa7ca599b0f5f9b6f4a0b55ff62a4cf8	common and domain-specific metamodel elements for problem description in simulation problems	analytical models;analytical models object oriented modeling vehicle dynamics vehicles supply chains;system design domain specific metamodel elements problem description simulation problems multiagent system complex systems modelling complex systems simulations application domains simulation models multiagent simulations crowd dynamics traffic transportation electricity power engineering supply chain logistic;supply chains;vehicles;multi agent systems digital simulation;object oriented modeling;vehicle dynamics	It is well known that the multi-agent system paradigm is well suited for modelling and developing simulations of complex systems belonging to several application domains. Simulation study aims at developing simulation models useful for representing, studying and analyzing entities and their behavior in a system according to specific purposes. With our work we are trying to understand what are the right elements to be considered and included in the description of a simulation problem. In order to root our resulting metamodel in the state of the art of multi-agent simulations we started from the study of twelve papers dealing with four different application domains: Crowd Dynamics, Traffic and Transportation, Electricity Power Engineering and Supply Chain and Logistic. From this study we obtained a metamodel that may be used by an analyst as a guideline and concept repository for facing a new system design. The metamodel is the result of a well defined approach that is described together with the obtained results consisting in one core metamodel containing elements that are common to all the four application domains and some domain extension contents. These latter contain the elements that are specific of each of the studied domains and are not present in the others.	agent-based model;agent-based social simulation;complex systems;display resolution;entity;metamodeling;multi-agent system;problem domain;programming paradigm;systems design	Valeria Seidita;Patrizia Ribino;Carmelo Lodato;Salvatore Lopes;Massimo Cossentino	2014	2014 Federated Conference on Computer Science and Information Systems	10.15439/2014F298	vehicle dynamics;simulation;supply chain	DB	-40.77493657986399	22.053442123016804	15005
f985aec687692449a39259e19c4d57b3686ffe70	protocol engineering	formal description technique;complete formal description;communication protocol;various description technique;protocol engineering;xdt protocol;main description approach;fundamental description method;test description language ttcn;computer network	"""A protocol is a set of rules that govern the interaction of concurrent processes in distributed systems. Few people know that the term """"protocol"""" was coined in 1967 by R. A. Scatlebury and K. A. Bartlett from the National Physical Laboratory I (in their paper """"A protocol for use in the WeL data communication network). Since then, """"protocol"""" became prevalent, specially by its use by the Am'A net community. However protocols existed before the term itself, under the denomination of """"procedure ''2."""	bartlett's bisection theorem;concurrent computing;distributed computing;telecommunications network	Stanislaw Budkowski;Elie Najm	2000	Annales des Télécommunications	10.1007/BF02997767		Networks	-38.485548109007006	28.273105350800467	15067
9252bf7193b462d9e8cc9705de5583aa50bb6035	dependency analysis in ontology-driven content-based systems	dependency analysis;contentbasedsystems;ontology driven content based systems;software engineering;content based systems;change impact analysis	Ontology-driven content-based systems are content-based systems (ODCBS) that are built to provide a better access to information by semantically annotating the content using ontologies. Such systems contain ontology layer, annotation layer and content layer. These layers contain semantically interrelated and interdependent entities. Thus, a change in one layer causes many unseen and undesired changes and impacts that propagate to other entities. Before any change is implemented in the ODCBS, it is crucial to understand the impacts of the change on other ODCBS entities. However, without getting these dependent entities, to which the change propagates, it is difficult to understand and analyze the impacts of the requested changes. In this paper we formally identify and define relevant dependencies, formalizing them and present a dependency analysis algorithm. The output of the dependency analysis serves as an essential input for change impact analysis process that ensures the desired evolution of the ODCBS.	algorithm;dependence analysis;entity;freedom of information laws by country;graph (discrete mathematics);interdependence;ontology (information science)	Yalemisew M. Abgaz;Muhammad Javed;Claus Pahl	2012		10.1007/978-3-642-29350-4_1	computer science;data mining;world wide web;information retrieval;change impact analysis;dependence analysis	SE	-40.1929638629277	8.961536590349942	15086
bbd89e4c83f98f97a77decf8274236cf2934df02	formalizing ontology modularization through the notion of interfaces	ontology development;development time;formal ontology	In this paper, we propose a new formalism for modular ontologies, which exploits the notion of interfaces as well as epistemic queries. In the proposed formalism, each ontology module both employs and realizes two distinct sets of interfaces. The axioms in each interface form the public section of the ontology module, while its ABox and TBoxes are private and can only be accessed through epistemic queries. This formalism permits the separation of configuration and development time manipulation tasks of a modular ontology development process. Hence, ontology modules can be developed independently of each others’ signature and description language.	abox;ontology (information science);ontology modularization;semantics (computer science)	Faezeh Ensan	2008		10.1007/978-3-540-87696-0_9	upper ontology;ontology alignment;ontology components;ontology inference layer;computer science;knowledge management;ontology;theoretical computer science;data mining;ontology-based data integration;process ontology;suggested upper merged ontology	AI	-40.62858146482504	14.565511262632656	15145
0040c81990a5d9f2df2277cbe3c9b50b435cf52f	modeling and realizing automatic design of complex mechanism using structure-grouping method	complex mechanism design;systematics;probability density function;mapping function;data mining;conceptual design;computational modeling;kinetic theory;design;structure grouping method;object oriented modeling;design methodology	Using Structure-grouping method, this paper presents a model to realize the automation of designing complex mechanism at the phase of conceptual design. In the process of carrying out this model, several key techniques, namely, representing basic structures, mapping function to structures, assembling basic structures, computerizing and displaying symbolic solutions have been discussed. The effectiveness of this model has also been shown through a case study.	xslt/muenchian grouping	Dian-hua Zhu;Wei Guo	2009		10.1109/CSIE.2009.87	kinetic theory;design;probability density function;computer science;artificial intelligence;theoretical computer science;data mining;conceptual design;systematics;statistics	Robotics	-56.693260371670604	10.751702927598052	15189
82856211057504563479c7b080f6f48b7c2e9bdc	a css integration model for declarative 3d	html5;dom;materials;xml3d;css;dec3d	Declarative 3D (Dec3D) implementations, most notably XML3D and X3DOM, have enabled a seamless integration of 3D and 2D content on the same web page. Yet one of the major web technologies, Cascading Style Sheets (CSS), has not been integrated. The usage of CSS for 3D content has always been envisaged but never fully approached, because only polyfills for declarative 3D implementations exist and only recent developments have made custom CSS properties available.  In this paper we will present a deep integration and adaption of CSS for Dec3D content and, hence, provide the final component necessary to fully integrate 3D content into the web technology stack. Our integration model allows for appearance definitions, such as visibility and materials, at a novel level of expressiveness. CSS-Selectors, inheritance, as well as media types provide unique means to change a scene's final appearance in a flexible and powerful way. Using CSS, it is possible to define the appearance of a 3D object dependent on the DOM hierarchy position or the screen resolution and orientation without a single line of JavaScript. The integration of CSS further enables the use of browser debugging facilities that have not been usable before. Because the requirements of 3D content are different compared to those of 2D content, we will point out existing limitations and necessary future additions to improve the interoperability of CSS with 3D content.	cascading style sheets;debugging;declarative programming;display resolution;document object model;interoperability;javascript;requirement;seamless3d;solution stack;web page;x3d	Jan Sutter;Kristian Sons;Philipp Slusallek	2015		10.1145/2775292.2775295	computer science;database;multimedia;world wide web	Web+IR	-40.65294242770679	9.951244380895904	15241
0d3eeeb640fa087c0678ae9977ef7e7e3c4a1fb7	test-driven migration towards a hardware-abstracted platform	test driven development;java hardware buffer storage software smart cards memory management software engineering;test driven development software reusability;software reusability	Platform-based development is one of the most successful paradigms in software engineering. In embedded systems, the reuse of software on several processor families is often abandoned due to the multitude of compilers, processor architectures and instruction sets. In practice, we experienced that a lack of hardware abstraction leads to non-reusable test cases. We will demonstrate a re-engineering process that follows test-driven development practices which fits perfectly for migration activities. Moreover, we will introduce a process that provides trust for the test cases on a new hardware.	compiler;correctness (computer science);domain-specific language;embedded system;fits;fundamental fysiks group;hardware abstraction;junit;legacy system;overhead (computing);parallels desktop for mac;programmer;semiconductor;serialization;software engineering;test case;test stub;test-driven development	Wolfgang Raschke;Massimiliano Zilli;Johannes Loinig;Reinhold Weiss;Christian Steger;Christian Kreiner	2015	2015 International Conference on Pervasive and Embedded Computing and Communication Systems (PECCS)		embedded system;test-driven development;reusability;personal software process;computer architecture;verification and validation;real-time computing;software engineering process group;computer science;package development process;backporting;social software engineering;software framework;component-based software engineering;software development;operating system;software construction;hardware architecture;systems development life cycle;software walkthrough;resource-oriented architecture;software deployment;goal-driven software development process;software development process;software system;avionics software	SE	-51.8464553148861	30.13113748841773	15279
f4a1f252ab69e60133204941513a91dd94105cb4	usable collaborative email requirements using activity theory	interface design;requirement analysis;activity theory	Email is the most common collaborative tool in use today. Although originally designed as an asynchronous communication tool, it is being used increasingly for information management, coordination and collaboration tasks. For effective collaborative work, email must be designed that meets users’ needs and their experience. The traditional approach to designing interfaces has been increasingly criticised because of the gaps between research results and practical design, especially concerning requirements. Requirements elicitation is a key to the success of the development of all email applications. Activity theory incorporates the notions of intentionality, history, mediation, motivation, understanding, culture and community into design. In particular, it provides a framework in which the critical issue of context can be taken into account. This paper describes the use of activity theory for the requirements analysis of a collaborative email system for a manufacturing company, XBC Ltd. Povzetek: Predstavljena je uporaba elektronske pošte za skupne aktivnosti.	collaborative software;email;information management;intentionality;requirement;requirements analysis;requirements elicitation;xbc	Lorna Uden;Aravind Kumaresan;Kimmo Salmenjoki	2007	Informatica (Slovenia)		requirements analysis;activity theory;human–computer interaction;computer science;interface design;software engineering;world wide web	HCI	-62.4423415937167	18.756335443642303	15304
93cf63c1e05e11bcd1e41a02751993357cffa282	agent protocols for peer-to-peer architectures		In this paper we present a technique which enables agents to participate in peer-to-peer (P2P) systems, such as file-sharing networks. Our technique is founded on the definition of lightweight protocols which specify the interactions required by the agent for a specific P2P network. The protocols that we define are executable specifications and can be directly implemented and independently verified. We present a definition of our MAP language for expressing protocols, and show how it can be used to enable participation in a simple P2P file-sharing system.	executable;file sharing;interaction;peer-to-peer	Christopher Walton	2005			knowledge management;computer science;peer-to-peer	PL	-42.15592698671345	19.551967534215933	15309
201536bf788dd25377326655469dc9e17186ebe0	using situation calculus for e-business agents	e business;automated agents;e commerce;software agent;internet;agent systems;situation calculus	As the Internet grows, it is becoming less feasible for customers and merchants to manually visit each web site, analyze the information there, and make sound business decisions regarding the trading of goods or services. To cope with this evolution, software agents can be designed that are capable of automating the more routine, tedious, and time-consuming tasks involved in current trading processes. At a higher level agents may also be able to negotiate and make autonomous decisions and commitments on behalf of their owners. This paper describes an agent implementation using the situation calculus, which offers a possibly unifying paradigm for dynamic agents. Interesting applications are currently being developed. Our contribution is a situation calculus agent system developed for e-business. Ongoing work is focused on implementing this system in an open marketplace environment. q 2003 Elsevier Science Ltd. All rights reserved.	autonomous robot;electronic business;internet;programming paradigm;situation calculus;software agent	Conan C. Albrecht;Douglas L. Dean;James V. Hansen	2003	Expert Syst. Appl.	10.1016/S0957-4174(02)00188-4	e-commerce;the internet;computer science;knowledge management;artificial intelligence;software agent;electronic business;situation calculus	AI	-50.293857428708414	12.297513146634822	15313
2b6612d99db2389c5f03a87cc09886af69305dc6	framework description using concern-specific design patterns composition	object oriented design;object oriented framework;object oriented frameworks;object oriented;design pattern;ny;object oriented composition;object oriented design patterns	This paper proposes an approach to object-oriented framework description. Frameworks are described using concern-speci c design patterns and their composition. The frameworks understandability is achieved by the separate description of concern variations and by the description of inter-concern combinations of those variations. Both descriptions are independent of implementation details. The technical innovations are based on using design patterns for describing concern variations and on using design patterns compositions for describing variations compositions.	design pattern	António Rito Silva;Francisco Assis Rosa;Teresa Gonçalves	2000	ACM Comput. Surv.	10.1145/351936.351952	object model;computer science;object-oriented design;design pattern;programming language;object-oriented programming;object definition language	SE	-49.55657190195836	27.00638639217698	15354
35ffd1873807e83fd99855700f947c230f6e4316	forming system requirements for software development using semantic technology		Requirements Engineering (RE) is one of the most important phases in the software development process, more than fifty percent of the projects failed due to lack of RE. Therefore, most of the developers in order to achieve high software quality they need to satisfy user’s requirement without errors (i.e. specific, clear, precise, …etc.). In this regard, this paper presents system requirement formulation from user’s stories based on previous similar verified requirements with semantic analysis. After semantic verification, the English written requirements are verified by a Case Based Reasoning Engine to be formulated as a standard requirements form. The generated requirements should support the decisions and resolutions of problems arising from new requirements.		Passent M. ElKafrawy;Mohamed S. Khalaf	2017		10.1007/978-3-319-64861-3_71	requirement;systems engineering;requirements engineering;software requirements;software design;software requirements specification;database;social software engineering;computer science;system requirements;requirements analysis	SE	-56.14033791410478	23.359384327935054	15361
83b668bb3155bf4a8f8924323d103832c6b661d9	design for all as a challenge for hypermedia engineering	user needs;functional programming;design for all;design technique;functional language	Design for All is an important challenge for hypermedia engineering. We analyze this challenge and show that it is necessary to find a way of describing partially designed hypermedia documents that can then be transformed into different hypermedia applications according to user needs and call this concept “semi-documents”. We sketch similarities and differences to existing formalisms and conclude that there are three areas in which functional languages can make a contribution: the development of an embedded special-purpose language for describing semi-documents, the building of generators which produce hypermedia applications from semi-documents, and the realization of support tools for the development of semi-documents.	computer science;embedded system;functional programming;hypermedia;prototype;semiconductor industry;xml schema	Volker Mattick	2002	J. UCS	10.3217/jucs-008-10-0881	design for all;computer science;theoretical computer science;software engineering;programming language;functional programming;world wide web	PL	-47.80818657704426	24.385490658205573	15388
1e2417dee4bb706c7ade5766970b2951431b36ff	code generation from aadl to a real-time operating system: an experimentation feedback on the use of model transformation	aadl start;verification tools;aadl model;mda;aadl;formal specification;high level description translation;code generation;model transformation;real time operating system;real time embedded system;program verification;software architecture;real time systems operating systems feedback code standards reluctance generators embedded system context modeling design engineering embedded computing aerospace electronics;osek vdx;c code code generation real time operating system model transformation uml marte profile aadl start real time embedded system verification tools high level description translation correct executable code code generators black boxes model driven architecture aadl model;unified modeling language;c code;black boxes;software tools;uml marte profile;code generators;program compilers;mda aadl code generation osek vdx;model driven architecture;correct executable code;unified modeling language formal specification program compilers program verification software architecture software tools	Several approaches, such as the UML MARTE profile or AADL start to reach maturity for the design of Real-Time Embedded System (RTES). The use of such formalisms and their associated verification tools relies on the confidence of the designer in the successful translation of these high- level descriptions into correct executable code. Part of this translation is performed by code generators. However, code generators are often black boxes or difficult to customize. This fact conflicts with the specific needs of the development of RTES where different code generation strategies could be involved. Recently, Model Driven Architecture (MDA) has offered sophisticated tools for model transformation. This paper presents an experimentation: code generation from an AADL model to C code using MDA tools. Based on this experimentation, statements on the interest of MDA tools for this purpose are given. Beyond this feedback, a set of open questions emerged about the need of flexibility of code generators and the different ways for setting this flexibility in MDA tools.	black box;capability maturity model;code generation (compiler);embedded system;model transformation;model-driven architecture;modeling and analysis of real time and embedded systems;real-time operating system;real-time transcription;subroutine;unified modeling language	Matthias Brun;Jérôme Delatour;Yvon Trinquet	2008	13th IEEE International Conference on Engineering of Complex Computer Systems (iceccs 2008)	10.1109/ICECCS.2008.19	unified modeling language;software architecture;computer architecture;black box;real-time computing;real-time operating system;computer science;operating system;software engineering;formal specification;programming language;code generation	Embedded	-48.413683515927104	31.450785851117423	15428
15fd7c85dcf7b0cb3f3e6981c95bd4aeb5bc8653	e-service emergence: a bio-inspired method of composition	emergence modeling;service composition;melay state machine;biological immune system;mobile agents;automata analysis emergence modeling e service composition biological neuroendocrine system biological immune system mobile agents biological operation melay state machine;state machine;automata analysis;dynamic environment;biological neuroendocrine system;biological operation;e service composition;immune system;message passing;mobile agents automata theory message passing;automata theory;mobile agent;educational institutions immune system mobile agents automata textile technology web services sun biological system modeling educational technology runtime;service quality	In this paper, we introduce an emergence modeling approach to the study of e-service composition, which is inspired by the characteristics of emergence and self-evolution in biological neuroendocrine and immune system. E-services are represented by autonomous bio-entities (mobile agents with biological operation), each bio-entity is described by a Melay state machine. The request of integrating complex processes is translated to an automata analysis problem. Bio-entities establish emergent network based on the matching message to provide e-service composition. Affinity is a parameter which can measure the message matching ability of the bio-entity integrally, it depends on three factors, namely, the matching strength of message, the e-service quality score, and the trust. In this way, the method completes a series of work from composition to management autonomously. The simulation results show that the approach can significantly improve the e-service composition performance. It adapts well to the changes of dynamic environments	automata theory;automaton;autonomous robot;british informatics olympiad;e-services;emergence;entity;experiment;finite-state machine;iterative and incremental development;mealy machine;mobile agent;ontology (information science);problem solving;service composability principle;simulation	Hongbin Sun;Yongsheng Ding	2007	First International Conference on Complex, Intelligent and Software Intensive Systems (CISIS'07)	10.1109/CISIS.2007.20	simulation;computer science;theoretical computer science;distributed computing	Robotics	-43.190498669505985	18.07247650059834	15435
8422d9859b1fd2d9c8577e6cfb9d0cf555621534	model-based contract testing of graphical user interfaces			graphical user interface;model-based testing	Tugkan Tuglular;Can Arda Muftuoglu;Fevzi Belli;Michael Linschulte	2015	IEICE Transactions		model-based testing;computer science;theoretical computer science;data mining;graphical user interface testing	HCI	-49.145878070334604	29.66077467457036	15445
57b7b2ff7bf8ef4ceb80bf9c9590d52f26c26319	shiva: a framework for graph based ontology matching	international journal of computer applications ijca	Since long, corporations are looking for knowledge sources which can provide structured description of data and can focus on meaning and shared understanding. Structures which can facilitate open world assumptions and can be flexible enough to incorporate and recognize more than one name for an entity. A source whose major purpose is to facilitate human communication and interoperability. Clearly, databases fail to provide these features and ontologies have emerged as an alternative choice, but corporations working on same domain tend to make different ontologies. The problem occurs when they want to share their data/knowledge. Thus we need tools to merge ontologies into one. This task is termed as ontology matching. This is an emerging area and still we have to go a long way in having an ideal matcher which can produce good results. In this paper we have shown a framework to	database;interoperability;ontology (information science);ontology alignment;open world	Iti Mathur;Nisheeth Joshi;Hemant Darbari;Ajai Kumar	2014	CoRR	10.5120/15678-4435	computer science;knowledge management;artificial intelligence;data mining;database	AI	-46.483119099904805	5.514723215204218	15455
a157a0ae7c15c5d1b63f296f739a7ea6dadae3c4	rsl-pl: a linguistic pattern language for documenting software requirements	requirements development activity;clearness criteria;pragmatics;information extraction;information retrieval;requirements linguistic patterns;semantics;pragmatics information retrieval syntactics pattern matching semantics best practices;software engineering;requirements engineering;linguistic analysis;information extraction requirements engineering linguistic analysis requirements linguistic patterns;completeness criteria;software requirements documentation;syntactics;pattern matching;best practices;consistency criteria;natural language requirements;rsl pl linguistic pattern language;computational linguistics;linguistic pattern;software engineering computational linguistics natural language processing;nl requirements;natural language processing;completeness criteria rsl pl linguistic pattern language software requirements documentation natural language requirements requirements development activity linguistic pattern nl requirements clearness criteria consistency criteria	Software requirements are traditionally documented in natural language (NL). However, despite being easy to understand and having high expressivity, this approach often leads to well-known requirements quality problems. In turn, dealing with these problems warrants a significant amount of human effort, causing requirements development activities to be error-prone and time-consuming. This paper introduces RSL-PL, a language that enables the definition of linguistic patterns typically found in well-formed individual NL requirements, according to the field's best practices. The linguistic features encoded within RSL-PL patterns enable the usage of information extraction techniques to automatically perform the linguistic analysis of NL requirements. Thus, in this paper we argue that RSL-PL can improve the quality of requirements specifications, as well as the productivity of requirements engineers, by mitigating the continuous effort that is often required to ensure requirements quality criteria, such as clearness, consistency, and completeness.	best practice;cognitive dimensions of notations;expressive power (computer science);extensibility;information extraction;nl (complexity);natural language;pattern language;raise;renderman shading language;requirement;software documentation;software requirements;well-formed element;well-formed formula	David de Almeida Ferreira;Alberto Rodrigues da Silva	2013	2013 3rd International Workshop on Requirements Patterns (RePa)	10.1109/RePa.2013.6602667	natural language processing;requirements analysis;software requirements specification;requirements management;requirement prioritization;business requirements;computer science;requirement;system requirements specification;requirements elicitation;linguistics;non-functional testing;programming language;non-functional requirement;requirements traceability	SE	-53.51198625760289	21.707919445621716	15459
1ac24bd5ad7f9a90aaeacb19f49440fc978179e6	bdi-agent plan selection based on prediction of plan outcomes	software agents meta data;metadata;context metadata computer architecture predictive models companies maintenance engineering airplanes;maintenance engineering;companies;computer architecture;airplanes;predictive models;context;software agents bdi agent plan selection bdi architecture plan selection algorithm meta model	The agent technology arises as a solution that provides flexibility and robustness to address dynamic and complex domains. Such flexibility can be achieved by the adoption of existing agent-based approaches, such as the BDI architecture, which provides agents with the mental attitudes of beliefs, desires and intentions. This architecture is highly customisable, leaving gaps to be fulfilled in particular applications. One of these gaps is the plan selection algorithm that is responsible for selecting a plan to be executed by an agent to achieve a goal, having an important influence on the overall agent performance. Thus, in this paper, we propose a plan selection approach, which is able to learn plans that provide possibly best outcomes, based on a current context and agent's preferences. Our approach is composed of a meta-model, which must be instantiated to specify plan metadata, and a technique that uses such metadata to learn and predict plan outcomes. We evaluated our approach experimentally, and results indicate it is effective.	agent-based model;experiment;metamodeling;selection algorithm	João Guilherme Faccin;Ingrid Nunes	2015	2015 IEEE/WIC/ACM International Conference on Web Intelligence and Intelligent Agent Technology (WI-IAT)	10.1109/WI-IAT.2015.58	maintenance engineering;computer science;knowledge management;artificial intelligence;data mining;predictive modelling;metadata;world wide web	AI	-43.14523465005607	14.95776149674893	15465
74ea1cc1911681390bb0cdab33f66230df70951e	the formal definitions of semantic web services and reasoning	description logic;satisfiability;semantic web services	Description logic is used as the formal theoretical foundation of semantic web services, the paper analyzed description language of Semantic Web Services OWL-S, WSDL-S, WSML and SWSL. Give a formal definition of description about semantic web services, further Web services is interpreted with the semantic of description logic. The satisfiability and subsumption in description logic can be applied to inferring semantic web services. For further research semantic annotation of web services, relation between web services and services, reasoning problems for semantic web services, our work was important and fundamental. © 2011 Springer-Verlag.	semantic web service	Duan Yuexing	2011		10.1007/978-3-642-24273-1_42	semantic computing;semantic grid;web standards;semantic web;social semantic web;semantic web stack;reasoning system;semantic analytics	AI	-42.646428256350895	13.573420826993356	15477
158814738a2c653d2ba753ddf3f9fcc87cc4f3c5	semantic web and multiple-agents in scm	multi agent system;data format;information sharing;artificial intelligent;decision support system;semantic web;supply chain;management information system;supply chain management	In recent years, many researches about how to efficiently handling information on logistics in supply chain have been proposed. Some focus on applying artificial intelligence to solving the problem. Most of the above approaches, however, usually consider multiple agents and simulation systems in single companies. Besides, they seldom consider using semantics to allow flexible information query with different linguistic terms. In this paper, we have proposed a framework for an e-SCM multiple-agents decision support system (called e-SCM multi-agents system), which combines ontology, to efficiently integrate data and information in supply chains. There are five layers in the system, including access layer, communication layer, application layer, ontology layer and database layer. These layers are linked together to integrate different access tools, data formats, management information systems, semantic web and databases. Different agents execute different tasks in each layer to achieve the purpose of integration and communication in a supply chain with less human intervention. Our approach emphasizes on the transparent connection manner among businesses. The proposed system can assist in business data and information sharing in a complex supply chain management.	artificial intelligence;database;decision support system;logistics;management information system;osi model;semantic web;simulation	Wei-Shuo Lo;Tzung-Pei Hong;Shyue-Liang Wang;Yu-Hui Tao	2004	IJEBM		computer science;knowledge management;management information systems;database;world wide web;information system	AI	-48.0117779877758	9.218923134089879	15504
0f955664ee3b5400d8e45d614fa758ef9ac30cf2	an ameliorated methodology to design normalized relations	databases;functional dependencies;design methodology relational databases computer science guidelines algorithm design and analysis data engineering design engineering computer applications computer aided instruction data models;formal specification;design engineering;dependency matrix;bcnf;probability density function;computer aided instruction;functional requirements;data engineering;data mining;framed algorithm;functional dependency;boyce codd normal form normalized relations database design functional dependencies software requirements specification abstracted attributes forward engineering functional requirements database relations random structural composition dependency matrix framed algorithm;computer applications;forward engineering;boyce codd normal form;guidelines;database relations;functional dependency attribute relation bcnf dependency matrix;matrix function;normalized relations;random structural composition;relational databases;computer science;software requirements specification;abstracted attributes;functional requirement;database design;relational databases formal specification;relation;attribute;algorithm design and analysis;data models;design methodology	In Database design, the attributes and their functional dependencies are abstracted from the software requirements specification (SRS) by the forward engineering process. The abstracted attributes from a forward engineering process are structured depending on the functional requirements. Then, the database relations are composed, by the related attributes and their functional dependencies, based on the structures defined by Codd. Any random structural composition of relations leads to INSERT, DELETE and UPDATE anomalies This paper presents a simple methodology that blends the analytical approach and the synthetic approach, to constitute the relations from a set of attributes and minimally covered functional dependencies, through the use of a dependency matrix to get the desired manipulation. The distinct attribute(s) from a set of functional dependencies is identified for a separate relation. All the dependencies are preserved and the lossless join is ensured by the framed algorithm. Further, the Boyce-Codd Normal Form (BCNF) is persuaded on each relation by revamping the determinant attributes to candidatekey.	algorithm;boyce–codd normal form;database design;design structure matrix;functional dependency;functional requirement;insert (sql);lossless compression;model-driven architecture;software requirements specification;synthetic intelligence	Ajeet A. Chikkamannur;Shivanand M. Handigund	2009	2009 IEEE/ACS International Conference on Computer Systems and Applications	10.1109/AICCSA.2009.5069431	information engineering;dependency theory;boyce–codd normal form;computer science;theoretical computer science;data mining;database;functional dependency;programming language;superkey;functional requirement	DB	-47.77326961460576	27.972483396764638	15512
377313b27796f35a01f562b45c68385b0d939e34	e-government service generator use case project e-government montenegro	design forms;service generator;design forms service generator reusing multi language import service;reusing;multi language;e government service generator tool e government service generator case project e government montenegro it infrastructure e service solution;electronic government generators xml standards html portable document format;import service;public administration	Different authorities, government and municipalities, use to develop their own solution for delivering e-services to citizens and other subjects. As every authority has different priorities to solve, culture, knowledge, IT infrastructure, and sometimes different law, standards and policy, developed solutions could hardly communicated between each other. Also, already developed e-service solution could hardly be applied in another E-Government project, as there are no standard tools for importing already developed solution. Therefore , in this article , we described E-Government Service Generator Tool which could be used for delivering standardized E-Services, that could be easily exported and reused, or even copied in another E-Government project, which is developed by the same tool .	e-government;e-services	Milan Maric	2012	2012 Proceedings of the 35th International Convention MIPRO		service level requirement;service delivery framework;service design;service guarantee;reuse;database;world wide web;computer security	HPC	-50.584703411930285	15.518451979064531	15529
c3c1e490a1d03fd9ad64a67851a1baab08479b71	re-implementing apache thrift using model-driven engineering technologies: an experience report		In this paper we investigate how contemporary model-driven engineering technologies such as Xtext, EMF and Epsilon compare against mainstream techniques and tools (C++, flex and Bison) for the development of a complex textual modelling language and family of supporting code generators (Apache Thrift). Our preliminary results indicate that the MDE-based implementation delivers significant benefits in term of conciseness, coupling and cohesion.	apache thrift;c++;cohesion (computer science);eclipse modeling framework;model-driven architecture;model-driven engineering;modeling language	Sina Madani;Dimitrios S. Kolovos	2016			software engineering;mainstream;flex;model-driven architecture;cohesion (chemistry);engineering	SE	-53.76794042813015	25.590340240117506	15585
b812ba522893d1c0957277f61b4df2b42677030e	architectural issues in network-centric computing	network centric computing;computer model;software systems;software architecture;mobile agent;configuration management	The widespread use of the Internet has led to great changes in traditional computational models. The concept of the network-centric computing is becoming more and more popular. Software architecture, as an emerging discipline, focuses on the high-level structures of large complex software systems. With the critical challenges from the new computational model, many open issues of software architectures emerge. In this paper, we present some requisite technologies that are still not completely settled and offer some suggestions based on a survey of relevant study experience to date.	computational model;grid computing;high- and low-level;internet;software architecture;software system	Xiaochun Xu;Guanghui Xu;YongSen Xu	2002	ACM SIGSOFT Software Engineering Notes	10.1145/566493.1148030	computer simulation;reference architecture;software architecture;computing;architectural pattern;computer science;systems engineering;engineering;backporting;software design;social software engineering;software framework;component-based software engineering;software development;software design description;software engineering;software construction;software as a service;mobile agent;software architecture description;configuration management;software analytics;resource-oriented architecture;software deployment;software system;computer engineering	SE	-60.47578632520243	21.412273883406343	15612
d4d185e1776136a57219519c3ef0b8b813477dc6	a combined approach for concern identification in kdm models	simulation and modeling;data structures;computer science general;computer system implementation;operating systems	Systems are considered legacy when their maintenance costs raise to unmanageable levels, but they still deliver valuable benefits for companies. One intrinsic problem of this kind of system is the presence of crosscutting concerns in their architecture, hindering its comprehension and evolution. Architecture-driven modernization (ADM) is the new generation of reengineering in which models are used as main artifacts during the whole process. Using ADM, it is possible to modernize legacy systems by remodularizing their concerns in a more modular shape. In this sense, the first step is the identification of source code elements that contribute to the implementation of those concerns, a process known as concern mining. Although there exist a number of concern mining approaches in the literature, none of them are devoted to ADM, leading individual groups to create their own ad hoc proprietary solutions. In this paper, we propose an approach called crosscutting-concern knowledge discovery meta-model (CCKDM) whose goal is to mine crosscutting concerns in ADM context. Our approach employs a combination of a concern library and a K-means clustering algorithm. We have conducted an experimental study composed of two analyses. The first one aimed to identify the most suitable levenshtein values to apply the clustering algorithm. The second one aimed to check the recall and precision of our approach when compared to oracles and also to two other existing mining techniques (XScan and Timna) found in literature. The main result of this work is a combined mining approach for KDM that enables a concern-oriented modernization to be performed. As a secondary and more general result, this work shows that it is possible to adapt existing concern mining code-level approaches for being used in ADM processes and maintain the same level of precision and recall. By using the approach herein presented, it was possible to conclude the following: (i) it is possible to automate the identification of crosscutting concerns in KDM models and (ii) the results are similar or equal to other approaches.	algorithm;architecture-driven modernization;cluster analysis;code refactoring;cross-cutting concern;domain driven data mining;existential quantification;experiment;hoc (programming language);k-means clustering;kde display manager;legacy system;metamodeling;oracle machine;precision and recall	Daniel S. M. Santibáñez;Rafael Serapilha Durelli;Valter Vieira de Camargo	2015	Journal of the Brazilian Computer Society	10.1186/s13173-015-0030-3	simulation;data structure;computer science;marketing;operating system;software engineering;data mining;programming language;management;cartography	SE	-58.158375698453234	31.17893815168718	15630
504c0f96143a38c7dae0fd402d20079a0a7e3571	architecture of a system for context-based adaptation in m-learning	specific user;context-based adaptation;spare time;previous action;suitable activity;personal feature;available device;software architecture;system management;internet;system architecture;collaboration;electronic learning;mobile computing;environmental management	In this paper, the architecture of a system that supports context-based adaptation for m-learning is presented. This system manages data about users and activities so that the most suitable activities to be accomplished at each time are proposed to each user. This decision is not only based on the user's personal features, preferences or previous actions but also on information about the specific user's context, including spare time, location and available devices		Estefanía Martín;Nuria Andueza;Rosa M. Carro	2006	Sixth IEEE International Conference on Advanced Learning Technologies (ICALT'06)	10.1109/ICALT.2006.79	software architecture;the internet;systems management;simulation;human–computer interaction;computer science;operating system;multimedia;mobile computing;management;law;collaboration	Robotics	-50.29840278292286	14.240192317692223	15654
b27fa5de7122c38e6565b54be7f04f48c3e3dfce	design of distributed simulation environments: a unified system-theoretic and logical processes approach	simulation ordinateur;distributed system;algoritmo paralelo;systeme reparti;systeme evenement discret;parallel algorithm;teoria sistema;system theory;time;algorithme parallele;sistema acontecimiento discreto;discrete event system;sistema repartido;systems theory;causalite;theorie systeme;algorithme reparti;processus logique;algoritmo repartido;simulacion computadora;distributed;devs;distributed simulation;distributed algorithm;computer simulation;logical process;causality;causalidad	This article presents a framework for distributed simulation that is based on system-theoretic and logical-process concepts. The framework describes a three-part worldview for developing simulation models. These are modeling formalisms, abstract simulators, and computational environments. A unified view of time and causality allows for the application of system-theoretic notions of causality within a distributed simulation environment. Within this framework, the authors introduce a unified notion of causality for use in parallel simulations. Furthermore, they describe an approach for developing distributed simulation models that evolve from modeling constructs to simulation algorithms and their implementations. The framework is exemplified using the discrete event system specification (DEVS) modeling formalism, its abstract simulator, and a parallel algorithm that implements the abstract simulator.	causality;devs;distributed computing;parallel algorithm;semantics (computer science);simulation;theory	James J. Nutaro;Hessam S. Sarjoughian	2004	Simulation	10.1177/0037549704050919	computer simulation;distributed algorithm;simulation;computer science;theoretical computer science;systems theory;algorithm	HPC	-38.33767712630789	25.19986492170542	15707
57bc8d8e00c0d6074af1b54abb01b3197595b709	keymantic: a keyword-based search engine using structural knowledge	search engine	Traditional techniques for query formulation need the knowledge of the database contents, i.e. which data are stored in the data source and how they are represented. In this paper, we discuss the development of a keyword-based search engine for structured data sources. The idea is to couple the ease of use and flexibility of keyword-based search with metadata extracted from data schemata and extensional knowledge which constitute a semantic network of knowledge. Translating keywords into SQL statements, we will develop a search engine that is effective, semantic-based, and applicable also when instance are not continuously available, such as in integrated data sources or in data sources extracted from the deep web.	dark web;database;deep web;ibm tivoli storage productivity center;information retrieval;mathematical optimization;response time (technology);sql;semantic web;semantic network;usability;web search engine	Francesco Guerra;Sonia Bergamaschi;Mirko Orsini;Antonio Sala;Claudio Sartori	2009			database search engine;metasearch engine;computer science;search analytics;search engine	DB	-35.198182138386706	4.453804616249245	15773
2940f85b4abbbd6c065426e5322777ee15ed33e5	analysis and design of physical and social contexts in multi-agent systems using uml	verification;time triggered;multiagent system;social context;multi agent system;analysis and design;automotive;integration;theorem proving;model based software engineering;agent technology	Multi-agent technology promises to provide the ability to adapt to changing external contexts. To tap this potential, context needs to play a central role in the analysis and design of multi-agent systems. In this paper, a pragmatic approach to the classification and modeling of the relevant contexts is presented, focusing on a useful operational description rather than epistemological correctness. We then show how our approach supports the analysis and design of physical and social contexts for embedded multi-agent systems using the UML, providing a number of different examples.	multi-agent system;unified modeling language	Florian Stallmann;Holger Giese	2005	ACM SIGSOFT Software Engineering Notes	10.1145/1082983.1082969	social environment;verification;simulation;computer science;systems engineering;knowledge management;applications of uml;multi-agent system;automated theorem proving	SE	-43.123891657905276	21.75304775550418	15782
a6676dfbdac3fd815e8125d813ca54194842ecf9	structural testing of component-based systems	component based systems;structural testing;engineering and technology;teknik och teknologier	Component based development of software systems needs to devise effective test management strategies in order fully achieve its perceived advantages of cost efficiency, flexibility, and quality in industrial contexts. In industrial systems with quality demands, while testing software, measures are employed to evaluate the thoroughness achieved by execution of a certain set of test cases. Typically, these measures are expressed in the form of coverage of different structural test criteria, e.g., statement coverage. However, such measures are traditionally applicable only on the lowest level of software integration (i.e., the component level). As components are assembled into subsystems and further into full systems, general measures of test thoroughness are no longer available. In this context, we formalize the added test effort and show to what extent the coverage of structural test criteria are maintained when components are integrated, in three representative component models. This enables focusing on testing the right aspects of the software at the right level of integration, and achieves cost reduction during testing — one of the most resource-consuming activities in software engineering.	code coverage;component-based software engineering;continuation;cost efficiency;emoticon;fault coverage;functional testing;hoc (programming language);software system;software testing;system integration;test case;test effort;test management;white-box testing	Daniel Sundmark;Jan Carlson;Sasikumar Punnekkat;Andreas Ermedahl	2008		10.1007/978-3-540-87891-9_12	test strategy;reliability engineering;black-box testing;regression testing;test data generation;software performance testing;white-box testing;manual testing;system integration testing;integration testing;computer science;systems engineering;engineering;acceptance testing;software reliability testing;software engineering;functional testing;software construction;risk-based testing;software testing;programming language;test case;test management approach	SE	-57.85775372766058	28.697610182213168	15827
2e0b396caf209a8b3e6a07b277c2c185943cafcc	amadeus: a holistic service-oriented environment for grid workflows	service orientation;qos aware service oriented component;workflow management software grid computing quality of service software quality;constraint based service negotiation;qos aware workflow reduction amadeus component qos aware grid workflow qos constraint qos aware service oriented component constraint based service negotiation workflow optimization;qos aware workflow reduction;amadeus component;workflow management software;qos constraint;experimental evaluation;qos aware grid workflow;quality of service;grid computing;software quality;quality of service grid computing constraint optimization strategic planning contracts scientific computing aerodynamics high performance computing instruments financial management;workflow optimization	In this paper, we present Amadeus, which is a holistic service-oriented environment for QoS-aware grid workflows. Amadeus considers user's requirements, in terms of QoS constraints, during workflow specification, planning, and execution. Within the Amadeus environment, workflows and the associated QoS constraints are specified at a high-level using an intuitive graphical notation. A set of QoS-aware service-oriented components is provided for workflow planning to support automatic constraint-based service negotiation and workflow optimization. For improving the efficiency of workflow planning, we introduce a QoS-aware workflow reduction technique. By following either a static or a dynamic planning strategy the workflow is executed using the selected services in the manner that the specified user's requirements are met. For each phase of the workflow lifecycle we experimentally evaluate the corresponding Amadeus components	automated planning and scheduling;experiment;graphical user interface;high- and low-level;holism;mathematical optimization;quality of service;reactive planning;requirement;service-oriented device architecture;service-oriented software engineering	Ivona Brandic;Sabri Pllana;Siegfried Benkner	2006	2006 Fifth International Conference on Grid and Cooperative Computing Workshops	10.1109/GCCW.2006.17	workflow;real-time computing;quality of service;computer science;database;distributed computing;windows workflow foundation;workflow management system;software quality;workflow engine;grid computing;computer network;workflow technology	HPC	-46.95240201915378	16.55648017160806	15868
f0f7a35ed213f6e06e94b1162dc76c9728be0f27	cloud computing for agent-based urban transportation systems	mulitagent systems;engineering;transportation cloud computing mobile agents urban areas traffic control intelligent transportation systems;urban transportation;multiagent system;sistema de transporte;informatique dans les nuages;transportation cloud computing mobile agents traffic information systems;intelligent transport system;agent based;transporte urbano;technology;mobile agents;intelligent transportation systems;computer science artificial intelligence;traffic control;urban traffic;intelligence artificielle;traffic management;agent based traffic management systems;urban areas;mobile multiagent technology cloud computing urban transportation systems traffic management systems mass transport data traffic control;science technology;traffic information systems;transport urbain;transportation;intelligent systems;intelligent system;systeme transport;urban area;artificial intelligence;inteligencia artificial;computer science;mulitagent systems intelligent transportation systems intelligent systems agent based traffic management systems mobile agents urban traffic;mobile agent;sistema multiagente;engineering electrical electronic;transportation system;computacion en nube;urban transport;traffic signal control;systeme multiagent;cloud computing	Agent-based traffic management systems can use the autonomy, mobility, and adaptability of mobile agents to deal with dynamic traffic environments. Cloud computing can help such systems cope with the large amounts of storage and computing resources required to use traffic strategy agents and mass transport data effectively. This article reviews the history of the development of traffic control and management systems within the evolving computing paradigm and shows the state of traffic control and management systems based on mobile multiagent technology.	agent-based model;cloud computing;mobile agent;programming paradigm	Zhenjiang Li;Cheng Chen;Kai Wang	2011	IEEE Intelligent Systems	10.1109/MIS.2011.10	simulation;intelligent decision support system;cloud computing;computer science;artificial intelligence;cloud testing;mobile agent;utility computing;computer security;advanced traffic management system;autonomic computing;technology	HPC	-38.638809193897316	16.216749701827567	15876
55d00c0d7a1d8b4df9137842376897342e914d40	an enhanced evaluation model for search-based product line architecture design				Yenisei Delgado Verdecia;Thelma Elita Colanzi;Silvia Regina Vergilio	2017			systems engineering;architecture;computer science	EDA	-61.33215054828776	26.59533819582568	15899
83dbc6a7607c00762fb33b5e953d506ba80d5124	the implication of different learning styles on the modeling of object-oriented systems (poster)	computer science education computer aided software engineering object oriented programming specification languages;case tools;object oriented modeling unified modeling language testing computer aided software engineering software tools permission computer science software engineering educational products systems engineering education;learning style;learning styles;object oriented programming;system modelling;software engineering education;object oriented systems;computer science education;computer aided software engineering;unified modelling language uml;specification languages;case tool;unified modeling language;software engineering education learning styles object oriented systems thinking styles learning modalities uml system modelling unified modeling language case tools;work in progress	This poster reports on work in progress on the implication of thinking and learning styles on the modelling of Object-Oriented Systems. In particular, analyses of learning modalities are presented and then considered in light of using the Unified Modelling Language (UML) as a tool for system modelling. The results of testing UML CASE tool learners will be available before the conference.	unified modeling language	Lynda Thomas	2000		10.1145/337180.337630	computer science;systems engineering;software engineering;applications of uml;programming language;computer-aided software engineering	Robotics	-50.56307323892749	29.09250084578047	15913
ece4730dfbb209ccaabf7b35ed9922c1af1ee1f1	enhancing project management for periodic data production management	distributed system;gestion informacion;gestion memoire;architecture systeme;systeme reparti;project management;gestion production;recoleccion dato;data gathering;project manager;storage management;date echeance;production management;production process;information gathering;gestion memoria;sistema repartido;internet;gestion produccion;information management;due date;processus fabrication;calidad produccion;fecha vencimiento;production planning;gestion projet;arquitectura sistema;identificateur;systeme gestion base donnee;information system;gestion information;system architecture;collecte donnee;qualite production;sistema gestion base datos;production quality;database management system;systeme information;identificador;proceso fabricacion;gestion proyecto;identifier;sistema informacion	When data itself is the product, the management of data production is quite different from traditional goods production management. Production status, the quality of the products, product identifiers, deviations, and due dates are defined in terms of volatile data and are handled strictly to enable the resulting reports within the allotted time. This paper outlines how the information gathering process for a data production management system can be automated. The system’s architecture is based upon ideas of project management. Milestones are enriched with production information. The major benefits are the following. Operators understand easily this management. They can concentrate on production itself, but are provided with reliable management information without manual effort. Additionally, with this solution a production plan is automatically created in advance.		Anja Schanzenberger;Dave R. Lawrence;Thomas Kirsche	2005		10.1007/11575863_5	project management;the internet;identifier;data management;computer science;effort management;applied engineering;scheduling;risk management information systems;structure of management information;information management;programming language;project management triangle;operations research;information system;data collection	DB	-36.284331520241764	16.29043501155055	15914
7c72d34d23a785315b8e43a3b8d02c147c9ab4b1	etl process model for a manufacture cells production line integration	data mart;etl process model;software;causal analysis;instruments;personal software;standards;software development project;cmmi;causal resolution;olap;product line;delta modulation;software engineering;function point analysis;production engineering computing;manufacture cells production line integration;etl;software factory;decision support system;production control;capability maturity model integration;manufacturing processes virtual manufacturing delta modulation decision support systems capability maturity model production control production planning management information systems programming data mining;decision support systems;software development;distributed databases;management information systems;personal software process;production planning;process model;mis;capability maturity model integration etl process model manufacture cells production line integration causal analysis causal resolution production control production planning management information systems mis software development project personal software software factory decision support system;management information system;programming;cmmi fpa etl olap data mart;software engineering decision support systems management information systems production control production engineering computing production planning;fpa;historical data	This article describes a Causal Analysis and Resolution of a problem for the elaboration of a Data Mart – DM specialized in Production Control and Planning – PCP. The unified information in the proposed DM is loaded form Management Information Systems – MIS, with historic data from software development project. To allow the integrated load from different data sources, it was developed a Extract, Transform and Load – ETL process, whose implementation has integrated data from the MIS of Function Point Analysis and Personal Software Process – PSP in a software factory. That allowed the construction of a Decision Support System – DSS over the constructed DM. This DSS allows the use of Online Analytical Processing – OLAP to support quantitatively the Process Areas of Measurement and Analysis – MA of Capability Maturity Model Integration – CMMi.	capability maturity model integration;causality;data mart;decision support system;function point;management information system;online analytical processing;personal software process;software development;software factory	Harison Pereira Bila de Carvalho;Danilo Battaglia;Denis Ávila Montini;Gabriel de Souza Pereira Moreira;Luiz Alberto Vieira Dias;Paulo Marcelo Tasinaffo	2010	2010 Seventh International Conference on Information Technology: New Generations	10.1109/ITNG.2010.86	computer science;capability maturity model integration;software engineering;management information systems	Robotics	-56.520515787858535	15.641139933160535	15946
efc765a4443f15a2674243efa0f061012316a96c	architecting iot context storage management for context-as-a-service platform		Context-awareness in IoT applications is an emerging research field with profound impact on smartness, relevance, adaptability, dependability and flexibility of such applications. Relatively few substantial R&D projects have been carried out on how IoT-scale context can be stored, indexed, retrieved and provisioned to various IoT services. This paper addresses the challenge of building IoT context storage management system (CSMS) as a core component of Context-as-a-Service (CoaaS) platform which is a major focus of IoT-EPI project bIoTope. Motivation and conceptual architecture of context storage management system are presented and discussed. Elements of the reference architecture are also proposed. The paper concludes with highlighting the urgent need for developing CSMS and ways for architecting and implementing it.	application programming interface;context awareness;data retrieval;dependability;document-oriented database;experiment;hierarchical storage management;in-memory database;interoperability;log analysis;management system;middleware;prototype;query language;reference architecture;relevance	Alexey Medvedev;Maria Indrawan;Pari Delir Haghighi;Alireza Hassani;Arkady B. Zaslavsky;Prem Prakash Jayaraman	2017	2017 Global Internet of Things Summit (GIoTS)	10.1109/GIOTS.2017.8016228	computer science;adaptability;systems engineering;computer security;reference architecture;architecture;management system;biotope;knowledge management;conceptual architecture;provisioning;dependability	DB	-46.51014454203557	9.740087692367235	15960
ede59418ffbe75987c9bf0d188b635955e24a3e0	context-sensitive query expansion over the bipartite graph model for web service search	web documents;search engine;query processing;web service;service discovery;query expansion;service oriented architecture;bipartite graph;space application	"""As Service Oriented Architecture (SOA) matures, service consumption demand leads to an urgent requirement to service discovery. Unlike web documents, services are intended to be executed to achieve objectives and/or desired goals of users, which means to realize application requirements. This leads to the notion that service discovery should take into account the """"application requirement"""" of service with service content (descriptions) which have been well explored. Content is defined by service developers, e.g.WSDL file and context is defined by service users, which is service usages to application requirement. We find context(application) information is more useful for query generation, especially for non-expert users. So in this paper, we propose to do context-sensitive query processing to resolve application-oriented queries for web service search engine. Context is modeled by a bipartite graph model to represent the mapping relationship between application space and service space. Application-oriented queries are resolved by query expansion based on the topic sensitive bipartite graph. The experiments verify the efficiency of our idea."""	query expansion;web service	Rong Zhang;Koji Zettsu;Yutaka Kidawara;Yasushi Kiyoki	2011		10.1007/978-3-642-20149-3_31	web service;query expansion;web query classification;bipartite graph;computer science;service-oriented architecture;data mining;database;service discovery;data as a service;web search query;world wide web;information retrieval;search engine	Web+IR	-45.037713671948225	13.207077608049019	16008
9b42663e6186f6f2f9fdc41012f040e588784fba	decisions as a service for application centric real time analytics	software;servers;engines;data models;real time systems	The need for application-level intelligence cannot be easily satisfied with existing architectures or methodologies that separate methods and tools for application developers and data scientists. We aim, therefore, to develop a framework (an architecture and a methodology) to make it possible to add intelligence capabilities to existing applications (decision-enablement) and to facilitate building new decision-enabled applications. The proposed approach starts by instrumenting the existing code with logging and instrumented decision points. The execution of the application produces information that is initially used to reengineer its behavior and then the decision points are used to conduct search-based experimentation to optimize its behavior. This lightweight instrumentation allows the application developer and data scientist to fully exploit their capabilities, with the framework providing the glue needed to put their work together easily and transparently. In particular, the analytic capabilities, such as analysis of operational data, are better dealt with in the decision-making part, without complicating the mechanics of how the application functions. We plan to apply this framework to decision enable existing systems and to build new systems from scratch and measure the effectiveness of the approach and of the resulting products.	data science;experiment;instrumentation (computer programming);online and offline;software framework	Patrick Tendick;Audris Mockus	2016	2016 IEEE/ACM 2nd International Workshop on Big Data Software Engineering (BIGDSE)	10.1145/2896825.2896826	real-time computing;simulation;computer science;data mining	SE	-34.77866247169211	19.70256370774268	16054
d50a00d5f681a49f1a6248dce118d3fc56ada0a3	integration testing of components guided by incremental state machine learning	integration testing;state based component model;formal specification;formal specification component integration testing incremental state machine learning algorithm complex system design cots distributed architecture test generation technique state based component model;complex system design;state machine;internal structure;component integration testing;incremental state machine learning algorithm;object oriented programming;finite state machines;program testing;machine learning;complex system;systems analysis;system integration;integrated software;test generation;systems analysis finite state machines formal specification integrated software learning artificial intelligence object oriented programming program testing software packages;cots;learning artificial intelligence;machine learning system testing inference algorithms assembly systems documentation telecommunication services machine learning algorithms software design software systems web and internet services;test generation technique;software packages;distributed architecture	The design of complex systems, e.g., telecom services, is nowadays usually based on the integration of components (COTS), loosely coupled in distributed architectures. When components come from third party sources, their internal structure is usually unknown and the documentation is insufficient. Therefore, the system integrator faces the problem of providing a required system assembling COTS whose behaviour is barely specified and for which no model is usually available. In this paper, we address the problem of integration testing of COTS. It combines test generation techniques with machine learning algorithms. State-based models of components are built from observed behaviours. The models are alternatively used to generate tests and extended to take into account observed behaviour. This process is iterated until a satisfactory level of confidence in testing is achieved	algorithm;complex systems;distributed operating system;documentation;integration testing;iteration;loose coupling;machine learning;systems integrator	Keqin Li;Roland Groz;Muzammil Shahbaz	2006	Testing: Academic & Industrial Conference - Practice And Research Techniques (TAIC PART'06)	10.1109/TAIC-PART.2006.15	real-time computing;computer science;systems engineering;computer engineering	SE	-48.58106573550001	31.6286928349167	16103
d88ce5febb55b020faeadac2a77416e9fb9bec63	applying case-based reasoning for product configuration in mass customization environments	case base reasoning;mass customization;satisfiability;product differentiation;market orientation;case based reasoning;bill of material;feature tree;product configuration;new products	Product variation and customization is a trend in current market-oriented manufacturing environment. Companies produce products in order to satisfy customer’s needs. In the customization environment, the R&D sector in an enterprise should be able to offer differentiation in product selection after they take the order. Such product differentiation should meet the requirement of cost and manufacturing procedure. In the light of this, how to generate an accurate bill of material (BOM) that meets the customer’s needs and gets ready for the production is an important issue in the intensely competitive market. The purpose of this study is to reduce effectively the time and cost of design under the premise to manufacture an accurate new product. In this study, the Case-Based Reasoning (CBR) algorithm was used to construct the new BOM. Retrieving previous cases that resemble the current problem can save a lot of time in figuring out the problem and offer a correct direction for designers. When solving a new problem, CBR technique can quickly help generate a right BOM that fits the present situation. q 2005 Elsevier Ltd. All rights reserved.	algorithm;browser object model;case-based reasoning;cluster analysis;fits;knowledge-based configuration;national supercomputer centre in sweden;simulation	Hwai-En Tseng;Chien-Chen Chang;Shu-Hsuan Chang	2005	Expert Syst. Appl.	10.1016/j.eswa.2005.06.026	case-based reasoning;mass customization;computer science;artificial intelligence;product differentiation;new product development;product engineering	AI	-59.471313485787995	10.839957273343092	16129
bfe9f55a9134a72c187f9cf29ac2fb0d7199e124	computer integrated manufacture for the engineering industry by the strathclyde institute ft business information ltd, 1990, 121 pages, no index (£195)	indexation;computer integrated manufacturing			Tony Owen	1992	Robotica	10.1017/S0263574700008055	engineering management;computer science;engineering;industrial engineering;computer-integrated manufacturing	DB	-60.070937169671915	5.76497956906318	16134
439d42248cf0c5f8bdb78c80f74701e01cda33ab	using composite act frame technique to model the rule of origin knowledge representations in e-government services		The rule of origin, globally applied to determine the eligibility for trade preference, is a vital instrument for an international trade, as it defines the country origin of products. The unified rule of origin ontology and knowledge representations is a vital key to promote interoperability and effective rule of origin verification services that could bring about trust amongst stakeholders and trading partners. This paper aims to lay down a rule of origin knowledge representations model using the composite act frame technique extended from the frame-based ontology of law proposed by van Kralingen and Visser. To prove the generic and extendibility aspect of the model, an assessment test with different criteria for the rule of origin is conducted. The implementation of the rule of origin knowledge representations to support the web-based e-government services is accomplished through the system called “Rule of Origin VERification Systems: ROVERs”. The rule of origin knowledge representation in this paper represents a generic model that may be applied and extended to other rule of origin agreement for modeling purposes.	e-government;interoperability;knowledge representation and reasoning;web application	Wanchai Varavithya;Vatcharaporn Esichaikul	2005			knowledge management;e-government;computer science;composite number	AI	-49.82113203143852	11.909422458807638	16137
4c8a734d0d5ec283fb82c6f5fba4b4d61f226f7e	survey-based analysis of the proposed component-based development process		The concept of component-based development (CBD) is widely practiced in software (SW) development. CBD is based on reuse of the existing components with the new ones. The objective of this paper is to propose a novel process model for CBD. Importance of repository has also been discussed. A survey has been conducted to evaluate the proposed model. The results of the survey show that proposed process model can be efficiently implemented for CBD projects.	component-based software engineering;process modeling	M. Rizwan Jameel Qureshi;M. E. Sandhu	2012	CoRR		systems engineering;engineering	SE	-59.33394327415197	26.07936197350081	16138
37ecb768816b1f9681fd9f42d2a49ac3f0464a0e	semantic-based similarity decisions for ontologies	directed acyclic graph;information retrieval;computational complexity;tree structure;homeland security;semantic similarity;data representation;data mining	Many data representation structures, such as web site categories and domain ontologies, have been established for semantic-based information search and retrieval on the web. These structures consist of concepts and their interrelationships. Approaches to determine the similarity in semantics among concepts in data representation structures have been developed in order to facilitate information retrieval and recommendation processes. Some approaches are only suitable for similarity computations in pure tree structures. Other approaches designed for the Directed Acyclic Graph structures yield high computational complexity for online similarity decisions. In order to provide efficient similarity computations for data representation structures, we propose a geometry-based solution. Similarity computations are based on geometric properties. The similarity model is based on the proposed geometry-based solution, and the online similarity computation is performed in a constant time.	computation;computational complexity theory;data (computing);directed acyclic graph;information retrieval;ontology (information science);time complexity	Anne Yun-An Chen;Dennis McLeod	2005				Web+IR	-38.56353193058167	5.090456654506843	16165
c4e7c7a1bd959039bbd18641dcade0b5a6668c63	supporting scenario-based requirements engineering	libraries;financial system case study;verification;developpement logiciel;modelizacion;financial data processing;sistema experto;problematic event patterns;formal specification;bibliographies formal specification systems analysis software tools object oriented programming financial data processing software reusability software performance evaluation;use case approaches;software assistant tool;validacion;reutilizacion;software performance evaluation;bibliographies;use cases;sociotechnical systems;object oriented modeling humans software tools software engineering libraries event detection sociotechnical systems concrete animation inspection;intelligence artificielle;event detection;ingenieria logiciel;object oriented programming;scenario based re;inspection;software engineering;reuse;requirements engineering;specification formelle;scenario;modelisation;especificacion formal;scenario based requirements engineering;problematic event patterns scenario based requirements engineering scenario based re software assistant tool use case approaches object oriented development financial system case study abstract models application classes exception types generic requirements reuse scenario paths normal event sequences abnormal events human error system failure rule based frames;argumento;systems analysis;desarrollo logicial;requirement engineering;software reusability;animation;software development;script;abnormal events;genie logiciel;normal event sequences;artificial intelligence;validation;system failure;software tools;humans;object oriented development;patterns;inteligencia artificial;systeme expert;verificacion;scenario generation;human error;scenario paths;scenarios;modeling;application classes;use case;object oriented modeling;reutilisation;rule based frames;concrete;generic requirements reuse;exception types;expert system;abstract models	Scenarios have been advocated as a means of improving requirements engineering yet few methods or tools exist to support scenario-based RE. The paper reports a method and software assistant tool for scenario-based RE that integrates with use case approaches to object-oriented development. The method and operation of the tool are illustrated with a financial system case study. Scenarios are used to represent paths of possible behavior through a use case, and these are investigated to elaborate requirements. The method commences by acquisition and modeling of a use case. The use case is then compared with a library of abstract models that represent different application classes. Each model is associated with a set of generic requirements for itsmodels that represent different application classes. Each model is associated with a set of generic requirements for its class, hence, by identifying the class(es) to which the use case belongs, generic requirements can be reused. Scenario paths are automatically generated from use cases, then exception types are applied to normal event sequences to suggest possible abnormal events resulting from human error. Generic requirements are also attached to exceptions to suggest possible ways of dealing with human error and other types of system failure. Scenarios are validated by rule-based frames which detect problematic event patterns. The tool suggests appropriate generic requirements to deal with the problems encountered. The paper concludes with a review of related work and a discussion of the prospects for scenario-based RE methods and tools.	human error;logic programming;requirement;requirements engineering;wizard (software)	Alistair G. Sutcliffe;Neil A. M. Maiden;Shailey Minocha;Darrel Manuel	1998	IEEE Trans. Software Eng.	10.1109/32.738340	use case;use-case analysis;reliability engineering;simulation;computer science;systems engineering;scenario;operating system;software engineering;requirements engineering;programming language;scenario analysis	SE	-46.669449989611444	28.524619239999012	16171
fc875b4e9fdb3d349393e629ba3af8c87054c882	ontology matching with knowledge rules		Ontology matching is the process of automatically determining the semantic equivalences between the concepts of two ontologies. Most ontology matching algorithms are based on two types of strategies: terminology-based strategies, which align concepts based on their names or descriptions, and structure-based strategies, which exploit concept hierarchies to find the alignment. In many domains, there is additional information about the relationships of concepts represented in various ways, such as Bayesian networks, decision trees, and association rules. We propose to use the similarities between these relationships to find more accurate alignments. We accomplish this by defining soft constraints that prefer alignments where corresponding concepts have the same local relationships encoded as knowledge rules. We use a probabilistic framework to integrate this new knowledge-based strategy with standard terminology-based and structure-based strategies. Furthermore, our method is particularly effective in identifying correspondences between complex concepts. Our method achieves better F-score than the state-of-the-art on three ontology matching domains.	ontology alignment	Shangpu Jiang;Daniel Lowd;Sabin Kafle;Dejing Dou	2016	T. Large-Scale Data- and Knowledge-Centered Systems	10.1007/978-3-662-53455-7_4	upper ontology;ontology alignment;computer science;knowledge management;ontology;machine learning;data mining;process ontology	AI	-43.33827014286625	7.3380987994553335	16208
a38ff7b7af1d5211b5ad71436403f89d7b6307cc	integrating graphical and natural language specifications to support analysis and testing		The ongoing trend towards distributed development activities causes a growing need for specification activities and techniques. Each component leads to a large number of specification documents being exchanged, change managed and committed. The quality of the specifications influences the timing, costs and success of the development task. However, the quality of such specifications is often far from optimal, exhibiting gaps, inconsistencies, redundancies, and unbalanced structures. At every release or delivery milestone, acceptance and integration testing take place. Therefore, test-cases have to be created from the requirements exchanged. This paper presents a model-based approach for improving the quality of comprehensive requirements sets. The presented solution is based on a combination of a graphical notation and natural language and can be used to drive model-based testing. The approach has been implemented using state-of-the-art tools. We present experience from field application in the automotive industry.	document;formal specification;graph operations;graphical user interface;grid north;integration testing;model-based testing;nl (complexity);natural language;requirement;requirements management;semiconductor industry;test case;unbalanced circuit;vergence	Christopher L. Robinson-Mallett;Robert Mark Hierons	2017	2017 IEEE 25th International Requirements Engineering Conference Workshops (REW)	10.1109/REW.2017.50	redundancy (engineering);notation;distributed development;market research;integration testing;natural language;semantics;automotive industry;systems engineering;computer science	SE	-57.34517370185644	30.147579730248935	16280
52488cb80b33f4cef7a8246897afe5dce870629c	generative programming - principles and techniques of software engineering based on automated configuration and fragment-based component models		Current object-oriented (OO) and component technologies suffer from several problems such as the lack of analysis and design methods for the development for reuse, lack of effective techniques for dealing with many variants of components, loss of design knowledge due to the semantic gap between domain abstractions and programming language features, and runtime performance penalties for clean and flexible design. This thesis proposes Generative Programming (GP) as a comprehensive software development paradigm to achieving high intentionality, reusability, and adaptability without the need to compromise the runtime performance and computing resources of the produced software. In the area of analysis and design for GP, we investigate Domain Engineering (DE) methods and their integration with OO analysis and design (OOA/D) methods. The main difference between DE methods and OOA/D methods is that the first are geared towards developing whole families of systems while the latter focus on developing single systems. We identify feature modeling as the main contribution of DE to OOA/D. Feature models represent the configurability aspect of reusable software at an abstract level, i.e. without committing to any particular implementation technique such as inheritance, aggregation, or parameterized classes. We give a precise and extended formulation of the feature diagram notation and investigate the relationship between feature modeling, OO modeling and AspectOriented Programming. In the area of implementation for GP, we study various metaprogramming technologies. We identify modularly extensible programming environments as the ideal programming platform for GP, which allows implementing domain-specific optimizations, domain-specific displaying and editing, domain-specific debugging and code analysis, new composition mechanisms, etc., in a scalable way. We also propose new implementation techniques such as configuration generators based on mixin models with automatic configuration and configuration repositories and make several contribution to template metaprogramming. Based on the analysis of the areas mentioned above, we propose a new Domain Engineering method for the development of algorithmic reusable libraries (DEMRAL), which integrates various DE, OO, and AOP concepts. We validate the method by applying it to the domain of matrix computations, which results in the development of the Generative Matrix Computation Library (GMCL). We provide two implementation GMCL, one using generative programming techniques in C++ and another one in Intentional Programming (an modularly extendible programming environment). In addition to validating the usefulness of DEMRAL, the GMCL case study provides a concrete comparison of two generative implementation technologies. The C++ implementation of the matrix component (which is a part of C++ GMCL) comprises only 7500 lines of C++ code, but it is capable of generating more than 1840 different kinds of matrices. Despite the large number of provided matrix variants, the performance of the generated code is comparable with the performance of manually coded variants. The application of template metaprogramming allowed a highly intentional library API and a highly efficient library implementation at the same time. The implementation of GMCL within the Intentional Programming system (IP) demonstrates the advantages of IP, particularly in the area of debugging and displaying.	''the legend of zelda:;application programming interface;automatic programming;c++;computation;debugging;diagram;domain engineering;extensibility;extensible programming;feature model;geforce 7 series;integrated development environment;intentional programming;intentionality;library (computing);mixin;numerical linear algebra;programming language;programming paradigm;run time (program lifecycle phase);scalability;software development;software engineering;static program analysis;template metaprogramming;the matrix	Krzysztof Czarnecki	1999				SE	-52.8515223715042	30.697954917736215	16286
18f93207261b856ed41c95fe065b1e5ebf2dedde	a user perspective of qos for ubiquitous collaborating systems	groupware;multi agent system;ethnography;computer supported cooperative work;cscw integration;collaborative system;user perspective;qos;artificial intelligent;user profile;multi agent systems;intelligent agents;collaboration quality of service collaborative work humans pervasive computing intelligent agent ubiquitous computing chaotic communication multiagent systems application software;human factors;internet;artificial intelligent agents;intelligent agent;user requirements;quality of service qos;cscw systems;ubiquitous computing;ubiquitous collaborating systems;artificial intelligent agents user perspective qos ubiquitous collaborating systems cscw integration web technology quality of service ethnography multiagent systems;quality of service;web technology;ubiquitous computing groupware human factors internet multi agent systems quality of service;mental model;ethnography quality of service qos cscw systems intelligent agents;multiagent systems	While we have seen a successful move towards a rapid proliferation of CSCW integration through Web technology including artificial intelligence techniques, still a significant work needs to be done in order to provide quality of service (QoS), particularly addressing the issues of QoS in terms of user requirements. In this paper, we present an approach based on ethnography and multi-agents systems to address these issues in an effective way by mapping a user mental model onto agents. We apply ethnographic approach in order to understand and explain the semantics, functionality and detailed user requirements of CSCW systems. Secondly, we employ artificial intelligent agents for communication and collaboration purposes based on user profile and preferences. In this paper, we also demonstrate the use/illness of this approach by presenting a real life case study of two CSCW (computer supported cooperative work) systems	artificial intelligence;computer-supported cooperative work;intelligent agent;mental model;quality of service;real life;requirement;user profile;user requirements document;utility	Rahat Iqbal;Nazaraf Shah;Anne E. James;Muhammad Younas;Kuo-Ming Chao	2006	2006 10th International Conference on Computer Supported Cooperative Work in Design	10.1109/CSCWD.2006.253219	quality of service;human–computer interaction;computer science;knowledge management;artificial intelligence;multi-agent system	Robotics	-46.8893507517558	12.064272082009895	16296
2fb0afba92ed73901668656d07cc921ef1b461c2	integration, management and communication of heterogeneous design resources with www technologies	concepcion asistida;multiobjective programming;extensible markup language;programmation multiobjectif;computer aided design;concepcion ingenieria;legacy software;engineering design;red www;conception ingenierie;xml language;information technology;reseau web;gear;data exchange;integrated management;technologie information;integrated design;concepcion integrada;logiciel patrimonial;internet;programa aplicacion;application program;team work;programme application;logicial herencia;conception assistee;travail equipe;advanced technology;trabajo equipo;world wide web;engrenage;ingenierie simultanee;ingenieria simultanea;collaborative design;technologie avancee;tecnologia informacion;institutional repository research archive oaister;common object request broker architecture;conception integree;langage xml;lenguaje xml;concurrent engineering;tecnologia avanzada;engranaje;programacion multiobjetivo	Recently, advanced information technologies have opened new possibilities for collaborative designs. In this paper, a Web-based collaborative design environment is proposed, where heterogeneous design applications can be integrated with a common interface, managed dynamically for publishing and searching, and communicated with each other for integrated multi-objective design. The CORBA (Common Object Request Broker Architecture) is employed as an implementation tool to enable integration and communication of design application programs; and the XML (eXtensible Markup Language) is used as a common data descriptive language for data exchange between heterogeneous applications and for resource description and recording. This paper also introduces the implementation of the system and the encapsulating issues of existing legacy applications. At last, an example of gear design based on the system is illustrated to identify the methods and procedure developed by this research.	centralized computing;client (computing);common object request broker architecture;global variable;heterogeneous computing;human-readable medium;markup language;operating system;peer-to-peer;programming language;requirement;server (computing);www;xml	Shuyan Ji;Daizhong Su;Jiansheng Li	2005		10.1007/11686699_42	xml;human–computer interaction;computer science;knowledge management;artificial intelligence;operating system;software engineering;database;information technology;world wide web;mechanical engineering	EDA	-38.15610976152229	14.04032042349278	16315
c94c9c6181b99009e9584e07fd479e2c8966a3f6	extending engineering data model for web-based fuzzy information modeling	engineering data modeling;fuzzy xml model;fuzzy express g data model;transformation	Being an information modeling language to support the STEP Standard for Exchange of Product Model Data, \linebreak EXPRESS has been developed to share and exchange product design, manufacturing and production data in product life cycle. Also being the de-facto standard of data representation and exchange over the Web, XML eXtensible Markup Language has been widely applied in Web-based engineering applications for product data exchange and share. It is essential to integrate EXPRESS data model and XML data model in engineering data modeling. EXPRESS-G is the graphical representation of EXPRESS and can serve as the conceptual design of Web-based engineering data models. Fuzzy engineering information is inherent in many engineering activities. In order to explicitly represent and handle fuzzy engineering information, this paper introduces an extended EXPRESS-G data model for different kinds of fuzziness modeling. After presenting the formal descriptions and corresponding representations of the fuzzy EXPRESS-G data model, the paper investigates the formal transformation from the fuzzy EXPRESS-G data model to the fuzzy XML model. The formal transformation approaches proposed in the paper are demonstrated with engineering application examples.	data model;information model;web application	Li Yan;Zongmin Ma	2013	Integrated Computer-Aided Engineering	10.3233/ICA-130440	transformation;data exchange;idef1x;data modeling;web modeling;semi-structured model;data model;information model;computer science;data science;data mining;database;logical data model	DB	-56.51521468365564	12.596752355970683	16333
e96504f443b507d552ad06d180098de9165f5083	extended techniques for flexible modeling and execution of data mashups	ad hoc data integration;data mashups;sensor data;patterns;data flow	Today, a multitude of highly-connected applications and information systems hold, consume and produce huge amounts of heterogeneous data. The overall amount of data is even expected to dramatically increase in the future. In order to conduct, e.g., data analysis, visualizations or other value-adding scenarios, it is necessary to integrate specific, relevant parts of data into a common source. Due to oftentimes changing environments and dynamic requests, this integration has to support ad-hoc and flexible data processing capabilities. Furthermore, an iterative and explorative trial-and-error integration based on different data sources has to be possible. To cope with these requirements, several data mashup platforms have been developed in the past. However, existing solutions are mostly non-extensible, monolithic systems or applications with many limitations regarding the mentioned requirements. In this paper, we introduce an approach that copes with these issues (i) by the introduction of patterns to enable decoupling from implementation details, (ii) by a cloud-ready approach to enable availability and scalability, and (iii) by a high degree of flexibility and extensibility that enables the integration of heterogeneous data as well as dynamic (un-)tethering of data sources. We evaluate our approach using runtime measurements of our prototypical implementation.	cloud computing;coupling (computer programming);document structure description;domain-specific language;dynamic web page;emoticon;extensibility;hoc (programming language);information system;iterative method;mashup (web application hybrid);provisioning;requirement;scalability;simulation;stateless protocol;subdivision surface	Pascal Hirmer;Peter Reimann;Matthias Wieland;Bernhard Mitschang	2015		10.5220/0005558201110122	data flow diagram;real-time computing;computer science;data virtualization;data mining;database;pattern;world wide web	DB	-41.69913693224802	10.761464459719454	16340
7bb58734fbeef29b3f5350502ea56e87910becf9	salsa - a framework for context-sensitive service discovery in mobile commerce applications			mobile commerce;salsa;service discovery	Colin Atkinson;Philipp Bostan;Thomas Butter	2008	J. Mobile Multimedia			Mobile	-48.53608842963222	13.933085353919962	16433
e23b04f9a7311323efbd87448aed3acff9fa946a	development of the instituto de investigaciones electricas integrate system of financial information	integrable system	I.I.E. has been, since 1975, an organization encharge of developing and promoting scientific research, experimental development and technological problems related to the improvement and development of the electrical industry. Its structure has as basic elements divisions, which in turn are divided into departments. Its administration is based on the development and the control of projects related to subprograms and working groups. In the development of computation I.I.E. has a great repertory of programs. Those related to research and technical support, became a valuable library of approximately 200 programs.	computation;subroutine;technical support	Gabriel Ruiz Huerta;Eliza González de Lule	1984		10.1145/800018.800562	integrable system;mathematical analysis;simulation;computer science;pure mathematics;mathematics	SE	-60.481889267999534	4.332104295784277	16484
3a21618351c1680fb4e2ba6858ceb43fe0944b74	a look around the corner: the pi-calculus	business process;direct comparison;petri net;advanced control flow pattern;business process management;formal foundation;service interaction pattern;different formalization;bisimulation technique;leading role	While Petri nets play a leading role as a formal foundation for business process management (BPM), other formalizations have been explored as well. This chapter introduces the π-calculus as a formal foundation for BPM. The approach presented is pattern-centric, thus allowing for direct comparisons between the π-calculus and different formalizations. In particular, selected basic and advanced control flow patterns as well as service interaction patterns are discussed. The chapter furthermore introduces the application of bisimulation techniques for proving soundness properties of business processes.	advanced process control;amiga walker;beam propagation method;bisimulation;business process;calculus of communicating systems;coloured petri net;communicating sequential processes;compiler;control flow;dynamical system;formal specification;hoare logic;information and computation;interaction;jensen's inequality;jones calculus;late binding;lecture notes in computer science;linear algebra;linearizability;mobile agent;rewriting;springer (tank);state space;turing completeness;π-calculus	Frank Puhlmann;Mathias Weske	2009	Trans. Petri Nets and Other Models of Concurrency	10.1007/978-3-642-00899-3_4	computer science;systems engineering;algorithm	SE	-39.875911122369814	29.509243355622615	16496
26303060f446feec4997fbbaae620d8abc27f36e	automated verification and test case generation for input validation	software testing;software verification;automated verification;test case generation;empirical based property;input validation;source code;open source	Input validation is essential for any software that deals with input from its external environment. It forms a major part of such software that has intensive interaction with its environment. Through the integration of invariant and empirical properties for implementing input validation, this paper proposes a novel approach for the automation of the following tasks from processing the source code of a program: (1) verification of existence of input validation; (2) generation of test cases to test and demonstrate all the input validations; (3) classification of each validation into the various types defined along with its test case generated. All the empirical properties in the theory have been validated statistically based on open source systems. Our evaluation shows that the proposed approach can help in both testing of input validation features and verifying the adequacy of input control.	data validation;formal verification;open-source software;test case;verification and validation	Hui Liu;Hee Beng Kuan Tan	2006		10.1145/1138929.1138936	reliability engineering;verification and validation;verification and validation of computer simulation models;software verification;computer science;software engineering;data validation;database;software testing;programming language;validation rule;source code	SE	-56.9950992933389	32.30084120503047	16497
6ba1d241cd7ea4c886ced10684cb1cd581f8126f	enhancing business process automation by integrating rfid data and events	event calculus;swinburne;performance improvement;object oriented;radio frequency identification;middleware;business rules;business process	Business process automation is one of the major benefits for utilising Radio Frequency Identification (RFID) technology. Through readers to RFID middleware systems, the information and the movements of tagged objects can be used to trigger business transactions. These features change the way of business applications for dealing with the physical world from mostly quantitybased to object-based. Aiming to facilitate business process automation, this paper introduces a new method to model and incorporate business logics into RFID edge systems from an object-oriented perspective with emphasises on RFID’s event-driven characteristics. A framework covering business rule modelling, event handling and system operation invocations is presented on the basis of the event calculus. In regard to the identified delayed effects in RFIDenabled applications, a two-block buffering mechanism is proposed to improve RFID query efficiency within the framework. The performance improvements are analysed with related experiments.	automation;business logic;business process;event (computing);event calculus;event-driven architecture;experiment;mathematical optimization;middleware;object-based language;query optimization;radio frequency;radio-frequency identification;real-time locating system	Xiaohui Zhao;Chengfei Liu;Tao Lin	2009		10.1007/978-3-642-05148-7_18	real-time computing;business domain;engineering;knowledge management;artifact-centric business process model;business process management;operations management;business case;business process model and notation;process management;business process;business software;business process discovery;business rule;business process modeling;business activity monitoring;business architecture	DB	-55.432486712444074	17.146329256715582	16498
823c710a288a0b7ad3b1c250597afba2c246ab53	coherent user interfaces for language-based editing systems	developpement logiciel;interfase usuario;programming environment;user interface;implementation;sistema informatico;relacion hombre maquina;man machine relation;computer system;systeme integre;sistema integrado;pan;prototipo;medio ambiente programacion;ejecucion;desarrollo logicial;software development;interface utilisateur;systeme informatique;relation homme machine;integrated system;prototype;lenguaje formal;edicion texto;formal language;environnement programmation;text editing;edition texte;langage formel	Many kinds of complex documents, including programs, are based on underlying formal languages. Language-based editing systems exploit knowledge of these languages to provide services beyond the scope of traditional text editors. To be effective, these services must use the power of language-based information to broaden the options available to the user, but without revealing complex linguistic and implementation models. Users understand complex documents in terms of many overlapping structures, only some of which are related to linguistic structure. Communications with the user concerning document structures must be based on models of document structure that are natural, convenient, and coherent to the user. Pan is a language-based editing and browsing system designed to support development and maintenance of complex software documents. Pan uses a variety of mechanisms to help users understand and manipulate complex documents effectively, in terms of underlying language when necessary, but always in the framework of a coherent, user-oriented interface. A fully functional prototype is in regular use. It serves as a testbed for ongoing research on a wide variety of tools to aid document comprehension, as well as on language-based analysis methods.	coherent	Michael L. Van de Vanter;Susan L. Graham;Robert A. Ballance	1992	International Journal of Man-Machine Studies	10.1016/0020-7373(92)90004-5	formal language;human–computer interaction;computer science;artificial intelligence;software development;operating system;prototype;user interface;implementation	Arch	-36.33142523568241	24.76786438532264	16526
e1eed148632c2976db1acf4ea9a5be309ca72a53	using bitstream structure descriptions for the exploitation of multi-layered temporal scalability in h.264/avc's base specification	estensibilidad;multimedia;metadata;perforation;generacion automatica;xml language;automatic generation;generation automatique;technology and engineering;metadonnee;extensibilite;metadatos;scalability;langage xml;lenguaje xml	In this paper, attention is paid to the automatic generation of XML-based descriptions containing information about the high-level structure of binary multimedia resources. These structural metadata can then be transformed in order to reflect a desired adaptation of a multimedia resource, and can subsequently be used to create a tailored version of the resource in question. Based on this concept, two technologies are presented: MPEG-21 BSDL and a modified version of XFlavor being able to create BSDL compatible output. Their usage is elaborated in more detail with respect to the valid exploitation of multi-layered temporal scalability in H.264/MPEG-4 AVC’s base specification, and in particular with a focus on a combined usage of the sub-sequence coding technique and Supplemental Enhancement Information (SEI) messages. Some performance measurements in terms of file sizes and computational times are	bitstream;boundary scan description language;h.264/mpeg-4 avc;high- and low-level;level structure;mpeg-21;scalability;software engineering institute;xml	Wesley De Neve;Davy Van Deursen;Davy De Schrijver;Koen De Wolf;Rik Van de Walle	2005		10.1007/11581772_56	xml validation;xml encryption;scalability;xml;computer science;artificial intelligence;theoretical computer science;operating system;database;distributed computing;programming language;metadata;world wide web;computer security;algorithm	HPC	-40.542686982499156	12.54206917621171	16564
43e41bbcaec45be994b4ac21852fff2bba4ab084	exploiting fine grained parallelism for acceleration of web retrieval	busqueda informacion;parallelisme;web pages;red www;information retrieval;reseau web;service web;web service;parallelism;internet;paralelismo;recherche information;retard;web retrieval;world wide web;retraso;servicio web	Dynamic Web content is gaining in popularity over traditional static HTML as the means of providing Web users with personalized and dynamic information. To enable dynamic content, various technologies have been developed for embedding of script code blocks into static HTML files in order to perform various forms of tasks such as session tracking, bank transactions, financial calculations, products catalog generation, dynamic image generation, or even fetching information from remote servers. In this way, static HTML pages are transformed into dynamic web pages. Typically, dynamic Web pages include a number of tasks that are executed in a serial manner by current Web servers. In this paper, we propose a back-end, finer-grained parallel approach for dynamic content generation, and elaborate on how it affects the design and performance of Web servers. We have developed a prototype Web server that supports the parallel processing of tasks involved in the dynamic content generation with improved throughput as compared to the classical (serial) approach.	code::blocks;dynamic web page;glossary of computer graphics;html;parallel computing;personalization;prototype;response time (technology);server (computing);shell script;throughput;web content;web server	Junli Yuan;Chi-Hung Chi;Qibin Sun	2005		10.1007/11527725_14	web service;web modeling;the internet;computer science;web page;database;distributed computing;multimedia;world wide web;information retrieval	Web+IR	-34.82800571818287	17.797283860057263	16589
cc0f43c669486bdca88e33b4aa53dee79d395dca	semantic wiki refactoring. a strategy to assist semantic wiki evolution		The content and structure of a wiki evolve as a result of the collaborative e ort of the wiki users. In semantic wikis, this also results in the evolution of the ontology that is implicitly expressed through the semantic annotations. Without proper guidance, the semantic wiki can evolve in a chaotic manner resulting in quality problems in the underlying ontology, e.g. inconsistencies. As the wiki grows in size, the detection and solution of quality problems become more di cult. We propose an approach to detect quality problems in semantic wikis and assist users in the process of solving them. Our approach is inspired by the key principles of software refactoring, namely the cataloging and automated detection of quality problems (bad smells), and the application of quality improvement transformations (refactorings). In this paper we discuss the problem of evolving semantic wikis, present the core model of our approach, and introduce an extensible catalog of semantic wiki bad smells and an extensible toolkit of semantic wiki refactorings.	agile software development;categorization;code refactoring;code smell;open road tolling;software bug;software engineering;unit testing;wiki	Martin Rosenfeld;Alejandro Fernández;Alicia Díaz	2010			ontology;quality management;cataloging;code refactoring;extensibility;database;computer science;semantic web stack	SE	-54.92877418932635	29.640146309641338	16592
0741b64650b05b3ca7021590eb1fed47aeb1339c	ompijava: a tool for development of high-performance reasoning applications for the semantic web	data centric applications;high performance computing	The World Wide Web has naturally been evolving towards processing extra-large data volumes, such as collected by Linked Life Data or Open PHACTS repositories, capable of hosting billions of information entities (e.g., RDF triples used in Semantic Web) and beyond. In view of the explosive data growth along with excessive QoS requirements on scalability and processing time constraints, the Web is expected to dominate the data-centric computing already in the next decade. On the other hand, most of the current HPC infrastructures, both academic and industrial, do not support parallel Web applications, e.g., developed in the Hadoop framework, due to their service-oriented implementation in the Java programming language, which is (and will surely remain) prevalent for the Web programming. As a reaction to novel challenges of promoting data-centric supercomputing to the Web, we present a solution that introduces the Message Passing Interface (MPI) bindings to Java, seamlessly integrated in one of the most popular current MPI implementations - Open MPI. Our implementation enables Java-based Semantic Web applications to be successfully ported to the most of modern HPC systems. We also discuss the design features of Open MPI that enable the proliferation of MPI into Java applications. Finally, we present a pilot Semantic Statistics scenario implemented with MPI, Random Indexing, and discuss future work in terms of promising Semantic Web applications, such as Reasoning.	apache hadoop;entity;java;message passing interface;open mpi;programming language;quality of service;random indexing;requirement;scalability;semantic web;service-oriented device architecture;supercomputer;web application;world wide web	Alexey Cheptsov	2012		10.1145/2389656.2389659	web service;web development;web modeling;data web;web mapping;web-based simulation;web design;web standards;computer science;theoretical computer science;web api;semantic web;web navigation;social semantic web;linked data;semantic web stack;database;web intelligence;web engineering;web 2.0;world wide web	HPC	-39.15095740396685	7.720626646135829	16602
c937633296f54dd7cc9d85d0a42b7e7e4b4644b8	argumentative agents to handle the conflicts between web services: a prototype	service provider;limiting factor;b2b;agent based;software agent;web service;satisfiability;software agents;web services;on the fly;network architecture;profitability;coordination	Web service is considered as the de facto standard to develop various business applications, due to the independence from the associated network, architecture, platform, and organization. However, Web service is still dependent to various internal factors (e.g., the availability of trucks is a limiting factor for the shipping Web service) for satisfying the requirements of customers. The unavailability of such underlying factors affect the existing business agreements made with other service providers, which result in conflict between the service partners. Web service has to handle the conflicts automatically to retain its customers and to improve the business profit. This demo paper illustrates an argumentative agents based approach to handle conflicts between Web services on the fly, using a case study of purchase order scenario.	interaction;on the fly;prototype;requirement;unavailability;web service	Sattanathan Subramanian;Guttorm Sindre	2009		10.1145/1643823.1643906	service provider;web service;web application security;service level requirement;service level objective;web development;web modeling;application service provider;business service provider;differentiated service;web standards;computer science;artificial intelligence;service delivery framework;software agent;operating system;ws-policy;service-oriented architecture;service design;data mining;database;law;world wide web;computer security	Web+IR	-48.1476109636624	15.866974132747986	16678
0eb09c45e3e4c0b63974d62c94edd4797cc4d095	towards competency question-driven ontology authoring	description logics;requirements;ontology	Ontology authoring is a non-trivial task for authors who are not proficient in logic. It is difficult to either specify the requirements for an ontology, or test their satisfaction. In this paper, we propose a novel approach to address this problem by leveraging the ideas of competency questions and test-before software development. We first analyse real-world competency questions collected from two different domains. Analysis shows that many of them can be categorised into patterns that differ along a set of features. Then we employ the linguistic notion of presupposition to describe the ontology requirements implied by competency questions, and show that these requirements can be tested automatically.	requirement;software development	Yuan Ren;Artemis Parvizi;Chris Mellish;Jeff Z. Pan;Kees van Deemter;Robert Stevens	2014		10.1007/978-3-319-07443-6_50	natural language processing;upper ontology;requirements analysis;description logic;bibliographic ontology;computer science;knowledge management;ontology;artificial intelligence;ontology;data mining;ontology-based data integration;process ontology;suggested upper merged ontology	NLP	-47.539464943804795	6.249111394878989	16691
3548f8f0ae735a57e65f58574ab06091c564a7ac	service level management in dynamic value networks		This paper presents a framework for Service Level Management in dynamic, heterogeneous environments for service composition. Compositions are selected based upon previously observed performance and the associated risk derived from such observations. The architecture of a framework is introduced and its implementation by means of a case study is described.	itil;service composability principle;value network	Wibke Michalk;Simon Caton	2010			service delivery framework;process management;service level objective;service provider;service product management;service design;service level requirement;business;service system;customer service assurance	HPC	-57.354160106489196	16.92127856397816	16717
68466797f856d790bc10048af90ad2106ca4b4f1	towards a real-time coordination model for mobile computing	real-time coordination model;new coordination model;mobile host;mobile computing;automatic motorway application challenge;novel extension;current coordination model;monterey workshop;limited support	Current coordination models offer limited support for applications in which mobile hosts not only must coordinate their actions, but must also coordinate when those actions will be taken. This paper describes the design of TNM, a new coordination model based on timed futures - a novel extension to current coordination models through which mobile hosts can propose and negotiate which actions they will take and when. We discuss the use and advantages of this new coordination model in the context of the automatic motorway application challenge problem posed for the 2005 Monterey Workshop.	mobile computing;real-time transcription	Gregory Hackmann;Christopher D. Gill;Gruia-Catalin Roman	2005		10.1007/978-3-540-71156-8_10	simulation;engineering;artificial intelligence;operations management	SE	-53.07029805403976	10.723115719298873	16747
e66862e7d5c3dfb27cf6b3219c7aaacc9b019647	algorithms for complete, efficient, and scalable alignment of large ontologies			algorithm;ontology (information science);scalability	Uthayasanker Thayasivam	2013			ontology alignment;scalability;theoretical computer science;data mining;ontology (information science);wordnet;computer science	AI	-39.09071160758402	6.1831811993263095	16750
8af4c0b8e0222f0c0bbc1a18281ca95460feeeeb	use of geospatial analyses for semantic reasoning	owl;spatial knowledge reasoning;spatial functions;built ins;swrl;spatial database;gis system	This work focuses on the integration of the spatial analyses for semantic reasoning in order to compute new axioms of an existing OWL ontology. To make it concrete, we have defined Spatial Built-ins, an extension of existing Built-ins of the SWRL rule language. It permits to run deductive rules with the help of a translation rule engine. Thus, the Spatial SWRL rules are translated to standard SWRL rules. Once the spatial functions of the Spatial SWRL rules are computed with the help of a spatial database system, the resulting translated rules are computed with a reasoning engine such as Racer, Jess or Pellet.	business rules engine;geographic information system;jess;knowledge base;ontology (information science);semantic web rule language;semantic reasoner;spatial analysis;spatial database;web ontology language	Ashish Karmacharya;Christophe Cruz;Frank Boochs;Franck Marzani	2010		10.1007/978-3-642-15387-7_61	computer science;data mining;database;information retrieval	AI	-37.55970371187615	7.071299270605117	16761
6f49b2b3ad25ca69dbe6fd44f32b7a3ee7e63a9a	automatic ontology mapping for agent communication in an e-commerce environment	thesaurus;commerce electronique;analyse lexicale;lexical semantics;ontologie;multiagent system;comercio electronico;conceptualization;correspondance ontologie;ontology mapping;analisis estructural;e commerce;teoria sistema;logica descripcion;semantics;agent communication;semantica;semantique;conceptualizacion;large scale;semantic mapping;lenguaje descripcion;internet;estudio caso;systems theory;heterogeneidad;tesaurus;theorie systeme;etude cas;ontologia;description logic;analyse structurale;analisis semantico;analyse semantique;sistema multiagente;structural analysis;ontology;correspondencia ontologia;analisis lexical;conceptualisation;lexical analysis;langage description;electronic trade;heterogeneity;semantic analysis;heterogeneite;structure analysis;systeme multiagent;logique description;description language	Internet-based e-commerce provides a high level of flexibility and openness though presenting many drawbacks due to the heterogeneity of the exchanged information. Ontologies are a key technology to solve many of the problems of e-commerce, in fact many companies use ontologies as a method of exchanging meaning between different agents. As ontology usage becomes more prevalent, the need for ontology reconciliation increases. In fact, ontology mapping methods can contribute to solve the problem of knowledge communication and interchange.#R##N##R##N#In this paper we present an automatic method for ontology mapping. The method is made up of two phases: a lexical-semantic analysis based on the WordNet thesaurus and a structural analysis based on a matching algorithm that finds semantic mappings between two ontologies expressed in Attributive Language with Number description ($\mathcal{ALN}$) Description logic. The mapped ontologies describe the same conceptualization through a set of rules that join related concepts. We deployed the proposed approach in a prototype system that currently is employed for large scale experiments. A simple experiment with a case study domain has shown a good correspondence with human mapping manually conducted and the system provided results.	e-commerce;semantic integration	Marina Mongiello;Rodolfo Totaro	2005		10.1007/11545163_3	e-commerce;natural language processing;upper ontology;conceptualization;ontology alignment;ontology components;bibliographic ontology;ontology inference layer;computer science;ontology;artificial intelligence;ontology;data mining;database;semantics;structural analysis;ontology-based data integration;process ontology;suggested upper merged ontology	AI	-38.38716154506205	12.412069983803594	16764
27e8b3c15cee8c894bfc00954f4ed3fbdb7d37ee	a metadata-driven approach for aspect-oriented requirements analysis	requirement analysis	This paper presents a metadata-driven approach based on aspect-oriented requirements analysis. This approach has been defined in cooperation with the European Space Agency in the context of the “Aspect Specification for the Space Domain” (ASSD) project. ASSD aims at assessing the applicability and usefulness of aspect-orientation for the space domain (ground segment software projects in particular), focusing on the early stages of the software development life cycle. This paper describes a rigorous representation of requirements analysis concepts, refines a method for handling early aspects, and proposes a client/server architecture based on a metadata repository.	aspect-oriented software development;client–server model;documentation;metadata repository;requirement;requirements analysis;server (computing);software architecture;software development process	Sérgio Agostinho;Ana Moreira;André Marques;João Araújo;Isabel Sofia Brito;Ricardo Ferreira;Ricardo Raminhos;Jasna Kovacevic;Rita Almeida Ribeiro;Philippe Chevalley	2008			requirements analysis;requirements management;requirement prioritization;computer science;requirement;software engineering;needs analysis;management;functional requirement;non-functional requirement;requirements traceability	SE	-54.17180670061491	24.515383844958738	16766
e9797985ae3aa0013e1d5395e45a27f8c5a9faf6	a generic architecture for the conversion of document collections into semantically annotated digital archives	semantic annotation;digital archive	Mass digitization of document collections with further processing and semantic annotation is an increasing activity among libraries and archives at large for preservation, browsing and navigation, and search purposes. In this paper we propose a software architecture for the process of converting high volumes of document collections to semantically annotated digital libraries. The proposed architecture recognizes two sources of knowledge in the conversion pipeline, namely document images and humans. The Image Analysis module and the Correction and Validation module cover the initial conversion stages. In the former information is automatically extracted from document images. The latter involves human intervention at a technical level to define workflows and to validate the image processing results. The second stage, represented by the Knowledge Capture modules requires information specific to the particular knowledge domain and generally calls for expert practitioners. These two principal conversion stages are coupled with a Knowledge Management module which provides the means to organise the extracted and acquired knowledge. In terms of data propagation, the architecture follows a bottom-up process, starting with document image units, called terms, and progressively building meaningful concepts and their relationships. In the second part of the paper we describe a real scenario with historical document archives implemented according to the proposed architecture.	archive;arkanoid;bottom-up parsing;business process;core image;digital library;extrapolation;fax;generic programming;historical document;image analysis;image processing;knowledge management;knowledge representation and reasoning;library (computing);linear algebra;programming paradigm;scalability;semiconductor industry;software architecture;software propagation	Josep Lladós;Dimosthenis Karatzas;Joan Mas Romeu;Gemma Sánchez	2008	J. UCS	10.3217/jucs-014-18-2912	computer science;data mining;world wide web;information retrieval;design document listing	Web+IR	-43.19934994286065	4.561662612671881	16769
5a3ce178dea9fc132ac87e472ffbfcedd14b6d9e	a space-efficient protocol for consistency of external view maintenance on data warehouse systems: a proxy approach	database views;proxy based solutions;data warehouse construction;data warehouse;flexiblie query	The materialized view approach is widely adopted in implementations of data warehouse systems in or-der for efficiency purposes. In terms of the construction of a materialized data warehouse system, some managerial problems still exist to most developers and users in the view resource maintenance area in particular. Resource redundancy and data inconsistency among materialized views in a data warehouse system is a problem that many developers and users struggle with. In this article, a space-efficient protocol for materialized view maintenance with a global data view on data warehouses with embedded proxies is proposed. In the protocol set, multilevel proxy-based protocols with a data compensating mechanism are provided to certify the consistency and uniqueness of materialized data among data resources and materialized views. The authors also provide a set of evaluation experiences and derivations to verify the feasibility of proposed protocols and mechanisms. With such protocols as proxy services, the performance and space utilization of the materialized view approach will be improved. Furthermore, the consistency issue among materialized data warehouses and heterogeneous data sources can be properly accomplished by applying a dynamic compensating and synchronization mechanism. The trade-off between efficiency, storage consumption, and data validity for view maintenance tasks can be properly balanced.		Shi-Ming Huang;David C. Yen;Hsiang-Yuan Hsueh	2007	J. Database Manag.	10.4018/jdm.2007070102	materialized view;computer science;data warehouse;data mining;database;view;information retrieval	DB	-33.76002586860272	10.651742300920526	16796
4e73a913fe94bf7e85b7897c0f56e938c484e96b	pipe+verifier - a tool for analyzing high level petri nets		High level Petri nets (HLPNs) have been widely used to model complex systems; however, their high expressive power costs their analyzability. Model checking techniques have been exploited in analyzing high level Petri nets, but have limited success due to either undecidability problem or state explosion problem. Bounded model checking (BMC) is a promising analysis method that explores state space within a predefined bound. BMC sacrifices the completeness of traditional model checking but becomes more practical and often effective to analyze large models. In our prior work, we have developed a method based on BMC and a supporting tool PIPE+Verifier to analyze high level Petri nets using a state of the art satisfiability modulo theories (SMT) solver Z3 as the backend engine. Our experiment results have been very encouraging. In this paper, we present the design, implementation, and use of PIPE+Verifier, as well as show additional improvements to make PIPE+Verifier more efficient. KeywordsPetri Net, Model Checking, Bounded Model Checking.	complex systems;high-level programming language;intelligent platform management interface;model checking;modulo operation;open-source software;petri net;satisfiability modulo theories;solver;state space;undecidable problem;z3 (computer)	Su Liu;Xudong He	2015		10.18293/SEKE2015-60	reliability engineering;real-time computing;engineering drawing	SE	-42.22318304189882	31.532029393383805	16816
707faa91e63b8b73afa2670b871ae99b8402d9b2	implicit hierarchical meta-modeling. in search of flexible inter-operability for manufacturing and business systems	flexible inter-operability;implicit hierarchical meta-modeling;business systems;meta model	There are numerous proposals worldwide to represent data models and services for the main business and manufacturing activities. This paper suggests an architecture and methodology for the design and development of new integrated models, extending the use of existent standard-based protocols as a basis for the development of implicit models, avoiding “yet another model ”. These models are built on top of existent components, supported by a hierarchical architecture developed at a model’s meta-level and offering several degrees of flexibility. The work results from the Research and Development done by the authors during the last years under the umbrella of a cluster of Ru0026D international projects.	metamodeling;operability	Ricardo Jardim-Gonçalves;Adolfo Steiger-Garção	2002			simulation;knowledge management;operations management;business	Robotics	-57.688587623837854	14.411969402107015	16822
bbcc209a1b2f6c894c5b01f199ecf24ba96e934a	computing path similarity relevant to xml schema matching	xml schema;data integrity;path similarity;dynamic program;schema matching;node context;query answering;structural similarity	Similarity plays a crucial role in many research fields. Similarity serves as an organization principle by which individuals classify objects, form concepts. Similarity can be computed at different layers of abstraction: at data layer, at type layer or between the two layers (i.e. similarity between data and types). In this paper we propose an algorithm context path similarity, which captures the degree of similarity in the paths of two elements. In our approach, this similarity contributes to determine the structural similarity measure between XML schemas, in the domain of schema matching. We essentially focus on how to maximize the use of structural information to derive mappings between source and target XML schemas. For this, we adapt several existing algorithms in many fields, dynamic programming, data integration, and query answering to serve computing similarities.		Amar Zerdazi;Myriam Lamolle	2008		10.1007/978-3-540-88875-8_25	semantic similarity;computer science;document structure description;normalized compression distance;data mining;xml schema;database;information retrieval	DB	-36.84272516224697	4.94658700058327	16824
2b30dc8cbf95028585bc74682adc9ef5ef0d8cd6	event driven multi-context trust model	trust;multiagent system;multi agent system;trust update event driven multi context trust model agent reasoning multiagent system trust principle reputation principle agent decisioning hierarchical model;trust modelling;inference mechanisms;trust model;trust principle;software agents;trust update;large scale;multi agent systems;agent decisioning;computational modeling;cognition;mathematical model;hmtc trust trust modelling multi context trust event driven trust model;event driven trust model;software agents inference mechanisms multi agent systems;event driven multi context trust model;peer to peer computing;point of view;context peer to peer computing context modeling computational modeling equations mathematical model cognition;multi context trust;hmtc;context modeling;reputation principle;context;agent reasoning;hierarchical model;trust and reputation	Agent reasoning in large scale multi-agent systems requires techniques which often work with uncertainty and probability. In our research, we use trust and reputation principles to support agent reasoning and decisioning. Information about agents past behaviour and their qualities are transformed to multi-context trust. It allows to view a single agent from different point of views, because agents are judged in different aspects — contexts. In this paper we describe event driven multi-context trust model as extension of Hierarchical Model of Trust in Contexts (HMTC), when different types of events causes trust updates. This extension of HMTC also provides some solutions for avoiding conflicts which may appear in previous HMTC.	hierarchical database model;multi-agent system	Ondrej Malacka;Jan Samek;Frantisek Zboril	2010	2010 10th International Conference on Intelligent Systems Design and Applications	10.1109/ISDA.2010.5687071	cognition;computer science;knowledge management;artificial intelligence;software agent;multi-agent system;mathematical model;data mining;context model;trustworthy computing;computational model;computational trust;hierarchical database model	AI	-42.64886684880432	16.47344511234096	16843
e4408a7e1e6e9503c8ae8045fbb90586e4fd9bc1	perspective: a standards-based system for manufacturing information integration	decision support;video streaming;information retrieval;manufacturing information;information integration;distributed environment;indexation;multimedia data;interoperability;information system;content based retrieval	This paper presents an infrastructure and a prototype system for a manufacturing information system, which is distributed its nature and is able to store, index, manage, retrieve and present business data, inventory data, and manufacturing processes data. The system works with all kinds of information, such as continuous (i.e., stream oriented) data, production (e.g., decision support) data, legacy data, and multimedia data (say, drawings, pictures, audio signals, voice annotations, and video streams). A key criterion is support for content-basedinformation retrieval across all application areas. The main objective is to provide support for automated information transactions. The prototype of our architecture uses JAVA, STEP (ISO 10303) standard, the Internet, and CORBA. A fully functional system, calledPerspective , for retrieval of part and manufacturing process has been designed and implemented in a distributed environment. Among other capabilities, the system can retrieve a set of parts or manufacturing processes based on similarity to some desired criteria.	collaborative working environment;common object request broker architecture;data mining;decision support system;experimental system;heterogeneous database system;iso 10303;image;information exchange;information retrieval;information system;internet;java;mind;prototype;software system;streaming media;vrml;volume rendering	Forouzan Golshani;Youngchoon Park	1999	Journal of Intelligent and Robotic Systems	10.1023/A:1008120707621	interoperability;decision support system;computer science;information integration;management information systems;data mining;database;computer-integrated manufacturing;data retrieval;information retrieval;information system;distributed computing environment;human–computer information retrieval	DB	-47.85721614364241	10.168561152271431	16872
737e97b5e837ce69ff70aa729d8021c46b91e2a4	managing complexity in activity specifications by separation of concerns	activity specification;business process modeling;subject oriented bpm;subject oriented task models;cooperative task execution;workflow specification	The specification of activities of the different stakeholders is an important activity for software development. Currently, a lot of specification languages like task models, activity diagrams, state charts, and business specifications are used to document the results of the analysis of the domain in most projects. The paper discusses the aspect of reusability by considering generic submodels. This approach increases the quality of models. Additionally, the separation of concerns of cooperation and individual work by subjectoriented specifications is discussed. It will be demonstrated how task models can be used to support subject-oriented specification by so called team models and role models in a more precise way than S-BPM specifications. More precise restrictions on instances of roles can be specified.	activity diagram;beam propagation method;chart;sequal framework;separation of concerns;software development;state diagram	Peter Forbrig;Gregor Buchholz	2016	CSIMQ	10.7250/csimq.2016-8.04	reliability engineering;real-time computing;computer science;systems engineering	SE	-54.91333345525318	23.445863262700062	16929
48f368466d0919fb71a6618e8404016da1792b83	preserving software quality characteristics from requirements analysis to architectural design	artefacto;presentacion documento;developpement logiciel;data transmission;patron conception;architectural design;exigence;document analysis;securite;reutilizacion;document layout;patron concepcion;requirement;reuse;presentation document;artefact;requirement analysis;software architecture;analyse documentaire;metamodel;metamodele;metamodelo;desarrollo logicial;transmission donnee;design pattern;software development;safety;exigencia;utilisabilite;analisis documental;concepcion arquitectural;architectural pattern;problem frame;usabilidad;conception architecturale;usability;seguridad;qualite logiciel;software quality;architecture logiciel;transmision datos;reutilisation;architectural style	In this paper, we present a pattern-based software development method that preserves usability and security quality characteristics using a role-driven mapping of requirements analysis documents to architectural design artifacts. The quality characteristics usability and security are captured using specialized problem frames, which are patterns that serve to structure, characterize, and analyze a given software development problem. Each problem frame is equipped with a set of appropriate architectural styles and design patterns reflecting usability and security aspects. Instances of these architectural patterns constitute solutions of the initially given software development problem. We illustrate our approach by the example of a chat system.	architectural pattern;design pattern;functional requirement;jackson;problem frames approach;requirement;requirements analysis;scalability;software development;software engineer;software quality;usability	Holger Schmidt;Ina Wentzlaff	2006		10.1007/11966104_14	software security assurance;usability goals;metamodeling;software architecture;requirements analysis;software design pattern;usability;architectural pattern;computer science;engineering;software development;requirement;software engineering;reuse;database;design pattern;software quality;data transmission	SE	-42.461017682676975	25.61025948116784	16943
6ec4138cb5bc402026bcb6516edd98d084c2907a	development and application of a model for analysis and design phases of web-based system development	web system;analysis and design;software development methodology;web based software development methodology;software development;public project;web based system;design;analysis;software life cycle;web based software development methodology software life cycle analysis design;software life cycle analysis design web based software development methodology;web development	Despite a short history of the Web development, Web-related technologies are rapidly developing. However, the Web application quality is improving slowly, which requires efficient methods for developing Web systems. This study presents a model for Web-based software development for analysis and design phases based on the ISO/IEC 12207 standard. It describes the methods used to define processes and entities in order to reflect the contents in Web applications. It applies the methodology of Web-Road Map by KCC Information and Technology using this model to the public project. As a result, Web-Road Map is proven to be an efficient model to analyze and design Web-applications.	entity;history of the world wide web;iso/iec 12207;korea computer center;software development;web application;web development	Byung-Kwon Jung;Dong-Soo Kim;Seok-Min Yoon;Gyu-Sang Shin;Chong-Sun Hwang	2003	Science in China Series F: Information Sciences	10.1360/02yf0058	verification and validation;web development;web modeling;web design;web standards;computer science;package development process;component-based software engineering;software development;software construction;systems development life cycle;web application development;resource-oriented architecture;world wide web;software development process	SE	-49.51036180197934	20.719258766210665	16968
400568eac151b7751081207ab7b7440702e144a5	a distributed generative csp framework for multi-site product configuration	site productivity;distributed generators	"""Today’s configuratorsare centralizedsystemsand do not allow manufacturersto cooperateon-line for offer-generation or sales-configuration. However, supplychainintegrationof configurableproductsrequiresthecooperationof theconfigurationsystems from the differentmanufacturersthat jointly offer solutionsto customers.As a consequence, thereis a high potentialfor methodsthat enablethe computationof suchconfigurationsby independent specializedagents.Severalapproaches to centralizedconfigurationtasks arebasedon constraintsatisfactionproblem(CSP)solving.Most of themextendthe traditionalCSPapproachin orderto comply to the specificexpressi vity anddynamismrequirementsfor configuration andsimilar synthesistasks. The distributed generati ve CSP (DisGCSP)framework proposed herebuilds on a CSPformalism that encompasses the generative aspectof variablecreationandextensibledomainsof problemvariables.It alsobuilds on thedistributedCSP(DisCSP)framework, allowing for approaches to configurationtaskswheretheknowledgeis distributedoverasetof agents.Notably, thenotionsof constraintand nogoodaregeneralizedto anadditionallevel of abstraction,extending inferencesto typesof variables.Theusageof thenew framework is exemplifiedby describingmodificationsto somecompletealgorithmsfor DisCSPwhentargetingDisGCSPs. 1 Intr oduction/Background Theparadigmof mass-customization allowscustomersto tailor (configure)a productor serviceaccordingto their specificneeds,i.e. the customercanselectbetweenseveralfeaturesandoptionsthatshould beincludedin theconfiguredproductandcandeterminethephysical componentstructureof the personalizedproductvariant.Typically, thereareseveraltechnicalandmarketingrestrictionson thelegalparameterconstellationsandthephysicallayout.This led manufacturers to develop supportfor checkingthe feasibility of userrequirementsandfor computinga consistentsolution.This functionality is providedby productconfigurationsystems(configurators),whereby they have shown to bea successful applicationareafor differentAI techniques[15] suchasdescriptionlogics [8], or rule-based[1] and constraint-basedsolvingalgorithms.[4] describesthe industrialuse of constrainttechniquesfor the configurationof large andcomplex systemssuchastelecommunicationswitchesand[7] is an example of a powerful tool basedon ConstraintSatisfactionavailableon the market. However, companiesfind themselves in dynamically determined coalitions with other highly specializedsolution providers that jointly offer customizedsolutions.This high integration aspectof ComputerScienceand Manufacturing, Universiẗat Klagenfurt, Universitätsstrasse65-67,9020Klagenfurt,Austria.e-mail: felfernig, friedrich, jannach,zanker @ifit.uni-klu.ac.at todaysdigital marketsimplies that softwaresystemssupportingthe sellingandconfigurationtaskmustno longerbeconcei ved asstandalonesystems.A productconfiguratorcanbe thereforeseenasan agentwith privateknowledgethatactson behalfof its company and cooperateswith otheragentsto solveaconfigurationtask.Thispaper abstractsthecentralizeddefinitionof a configurationtaskin [16] to a moregeneraldefinitionof a generativeCSPthat is alsoapplicable to thewider rangeof synthesisproblems.Furthermore,we propose aframework thatallows to addressdistributedconfigurationtasksby extendingDisCSPswith the innovative aspectsof local generati ve CSPs: 1. The constraints(and nogoods)are generalizedto a form where they can dependon typesratherthan on identitiesof variables. Thisalsoenablesaneleganttreatmentof thenext aspects. 2. Thenumberof variablesof certaintypesthatareactivein thelocal CSPof an agent,may vary dependingon the stateof the search process.In the DisCSPframework, the external variablesexisting in thesystemarepredetermined, but herethesetof variables definingtheproblemis determineddynamically. 3. The domainof the variablesmay vary dynamically. Somevariablesmodel possibleconnectionsand they dependon the existenceof componentsthatcouldbecomeconnected. We also describethe interestingimpact of the previously mentionedchangesonasynchronous algorithms.In thefollowing wemotivateour approachwith anexample,Section3 definesa generati ve CSPandin Section4 distributedgenerati ve CSPis formalizedand extensionsto currentDisCSPframeworksarepresented. 2 Moti vating example For the purposeof illustration of our approachwe choseasexample domainthe well known N-queensproblem.The characteristics of a distributedconfigurationproblemor similar distributedsynthesis tasksareintegratedinto our N-queensscenario:(a) partsof the problem(i.e., variables)aresharedamongagentsand(b) the problem is dynamicallyextended(i.e.,N is increased), if no solutioncan be found.Adding additionalproblemvariablesleadsto domainextensionsandthusto a largersearch-andsolutionspace.Thegoal is to place queenson distinct squaresin an chessboard, where no two queensthreateneachother [17]. We formalize the problemby making eachrow of the boarda problemvariable , wherethesubscript ensuresuniquevariablenames.In a distributed settingwe employ threeagents,eachowning a fraction of the constraintsnecessaryto solve the N-queensproblem.Furthermore,we want to show thegenerativeaspectof problemsolving in theexample, whereagentsstartwith a representationof a 0-queensproblem andspecificrequirementson thefinal solutioncomingfrom outside. Oncetheagentsdeterminethata solutioncannotbefound,they extendtheproblemspaceby addinganadditionalrow which in consequenceenlargesthe domainof row variablesby one.Sincethe exact numberof problemvariablesis not known from the beginning, constraintscannotbe directly formulatedon concretevariables.Instead,comparableto programminglanguages,variable typesexist that allow to associatea newly createdvariablewith a domainand we can specify relationshipsin termsof generic constraints. [16] definea genericconstraint as a constraintschema,wheremetavariables actasplaceholdersfor concretevariablesof a specific type . In ourexamplethreetypesof problemvariablesexist, representingtheeven( ) andtheunevenrows ( ) aswell asa type( ) of countervariables( ) for thenumberof instantiationsof each type,which allows us to distribute theN-queensconstraintsamong the agents.Therefore,eachagent posessesa setof privateconstraints ! , i.e., """" $#&%('! !) +* ) , ) ) .0/ , """" !12%('! 3 ) +4 ) ) .0/ and !52%6'7 8 ) +9 ) ) . / , thataredefinedasfollows: ;:=< > ?@ BA C % < +>D?@ @E C0F < > ?@ A C % < > ?@ @E C0GIH , where< > ?@ C is a predicatethatgivestheassignedvalueof variable . Informally, the numberof uneven rows may exceedthe numberof evenrowsbyone. * :=< > ?J A CLK % < > ?J E C Notwoqueensonanevenandanunevenrowareallowedto take the samecolumnvalue. , : NM!OP?JQR S?@ JTVUNW! X?J A C+Y JTVUNW! X?J @E C C+YZH0C[K %\ NM!OP? < > ?J A C+Y < > ?J ] E C C , where ^TVUNW0 _?@ C returnsa number indicatingthat is the @` variableof its typeand NM!OP?@T C is a predicatethat returnsthe absolutevalueof T . No two queenson an evenandan unevenrow are allowedto beon thesamediagonal. 3 : A K %a A *cb < > ?J A CLK % < > ?J A * C . No two queenson unevenrowsare allowedto take thesamecolumn value. 4 : A K %d A *eb NM7Of?JQI g?@ ^T UNW! X?J A C;Y JTVUNW! X?J A * C C ChK % NM!OP? < > ?J A CXY < > ?J A * C C . Notwoqueensonunevenrowsare allowedto beon thesamediagonal. 8 : @E K %a @E * b < > ?J @E C[K % < > ?J @E * C . No two queenson evenrowsare allowedto take the samecolumn value. +9 : @E K %i @E * b NM!OP?JQj a?@ ^TVUNW! X?J @E CLY JTVUNW! X?J @E * C CaK % NM!OP? < > ?J @E CkY < > ?J @E * C C . Notwoqueensonevenrowsareallowedto beonthesamediagonal. :=< > ?J l A Cnm @E G AVo . :=< +>D?J l E Cpm @E G A o Thelatter two constraintsdelimit thedomainof row variablesto the total numberof rows. Figure1 depictsthe initial situation,with a 0-queensproblem.The customerequestsagent to satisfytherequirementof findingasolution containingat leasttwo unevenrows: N $q : Asr Q o Having added $q to thesetof privateconstraintsof agent , the searchprocessstartsandthesolutionspaceis continuouslyextended by the instantiationof additionalproblemvariables,until a solution is found for a 4-queensproblemthat satisfiesall local constraints of theagents.Thelinks betweentwo agentsindicatethat they share variables,which is describedin moredetail later on. Thus,a solution to a generati ve constraintsatisfactionproblemrequiresnotonly finding valid assignmentsto variables,but alsodeterminingthe exactsizeof theproblemitself. In thesequelof thepaperwe definea * Theexactsemanticsof genericconstraintsis given in Definition 2 in Section 3. modelfor thelocalconfiguratorsandwedetailextensionsto DisCSP algorithms. Agent a 1 Agent a 1 x t u x t t e x t t c"""	algorithm;business architecture;distributed constraint optimization;knowledge-based configuration;moti yung;programming language	Markus Zanker;Dietmar Jannach;Marius-Calin Silaghi;Gerhard Friedrich	2008		10.1007/978-3-540-85834-8_12	computer science;artificial intelligence;theoretical computer science	NLP	-52.03063075587349	13.29856814676317	16975
3683f3e0e88bda14c5c3cde8af8334fc7c38fa3e	effective web data extraction with standard xml technologies	web data extraction;extensible markup language;error recovery;web databases;wrappers;web crawler;semistructured data;data extraction;software framework;product quality;deep web;markup language;data validation;crawling	We describe an Extensible Markup Language (XML)-based methodology for Web data extraction that extends beyond simple “screen scraping”. An ideal data extraction process can digest target Web databases that are visible only as Hypertext Markup Language (HTML) pages, and create a local replica of those databases as a result. What is needed is more than a Web crawler and set of Web site wrappers. A comprehensive data extraction process must deal with such obstacles as session identifiers, HTML forms, client-side JavaScript, incompatible datasets and vocabularies, and missing and conflicting data. Proper data extraction also requires solid data validation and error recovery to handle data extraction failures. Our ANDES software framework helps solve these problems and provides a platform for building a production–quality Web data extraction process. Key aspects of ANDES are that it uses XML technologies for data extraction, including Extensible HTML and Extensible Stylesheet Language Transformations, and provides access to the “deep Web”.	xml	Jussi Myllymaki	2002	Computer Networks	10.1016/S1389-1286(02)00214-1	data exchange;web service;xhtml;static web page;web development;web modeling;xml;data web;synchronized multimedia integration language;web mapping;html;web design;html5;web standards;computer science;software framework;web crawler;semantic web;data validation;web navigation;crawling;web page;data mining;pcdata;database;markup language;progressive enhancement;world wide web;website parse template;information extraction;deep web	Web+IR	-39.72491628627883	10.224523708214624	16977
8037a801fe6429cdd0317efa6f7410ba4bc05e9a	algorithms for semi-automatic web service composition	web service composition;sawsdl;semantic annotations;dissertation;service suggestion;data mediation		algorithm;semiconductor industry;service composability principle;web service	Rui Wang	2011			web service;computer science;social semantic web;semantic web stack;database;world wide web;information retrieval	Web+IR	-40.139003554335744	7.116614300671599	16991
ff20fbc654551c15fcfef076c962860b3de2b966	modeling systems of systems as nested actor systems based on petri nets	petri net	Modern software systems are frequently characterized as systems of systems. Agentorientation as a software engineering paradigm exhibits a high degree of qualification for addressing many of the accompanying challenges. However, systems of systems demand for means of hierarchical/recursive decomposition that are not inherently rooted in the agent-oriented paradigm. We present a model that still relies on the actor metaphor, but shifts the focus to collective agency. We propose a universal model of a system unit that both embeds system actors and is itself embedded as a collective system actor in surrounding system units. Consequently, we can apply our model of a system unit at arbitrary levels of a system of systems and compose the overall system by means of nested actor hierarchies. (High Level) Petri nets as our modeling technique supply precise operational semantics for the functioning of these kind of systems. In addition, we offer abstraction mechanisms that allow for rather high-level or low-level views and smooth transitions between them.	actor model;embedded system;high- and low-level;operational semantics;petri net;programming paradigm;recursion;software engineering;software system;system of systems	Matthias Wester-Ebbinghaus;Daniel Moldt;Simon Adameit	2010			system of systems;petri net;stochastic petri net;distributed computing;process architecture;computer science	SE	-42.32188593493649	21.490750873826094	16998
499893c17a6c80de4edf5372b5b926f658b0e322	a model for versioning control mechanism in component-based systems	life cycle;object oriented design;component based systems;version control tools;satisfiability;software components;development tool;component framework;system design;software component;version management;source code;version model;quality of service;version control;visual version control tool vvct;monitoring and control;object oriented design ood	Component-based systems provide a better reuse of software components, greater flexibility, scalability and higher quality of services. Component development generally takes place due to the process of creating and propagating changes in requirement definitions, system designs, program source code, documentation and test data. As a result, multiple versions of constituent components come into existence. Thus, there is a need to keep the track of multiple versions of same component. To handle multiple versions of constituent components, a version-control tool named as Visual Version Control Tool (VVCT), for the management of life-cycle evolution of component, is developed. The developed tool satisfies all the conditions required for version control in component-based systems. The parameters required for uniform version management as well as component frameworks are also satisfied by the developed tool. To monitor and control the versioning system, an example model is tested along with the set of proposed metrics. This paper also incorporates issues like component configuration, component evolution, component framework, component version tree and version-control metrics.	component-based software engineering;scalability;software documentation;test data;version control	Parminder Kaur;Hardeep Singh	2011	ACM SIGSOFT Software Engineering Notes	10.1145/2020976.2020988	reliability engineering;component-based usability testing;common component architecture;computer science;systems engineering;component-based software engineering;component;database;programming language;presentation–abstraction–control	SE	-54.38085046753916	29.168912025418756	17016
185cc5c780d850829cc7684dbed3e95f6e8a4275	a software fault tree key node metric	software metrics;fault tree;embedded control system;product line;software fault trees;software safety;lessons learned;safety critical software;software metric;software product line;software product lines;system safety	Analysis of software fault trees exposes failure events that can impact safety within safety-critical software product lines. This paper presents a software fault tree key node safety metric for measuring software safety within product lines. Fault tree structures impacting the metric’s composition are provided, and the mathematical basis for the metric is defined. The metric is applied to an embedded control system as well as to a series of experiments expected to either improve or degrade system safety. The effectiveness of the metric is analyzed, and lessons learned during the application of the metric are discussed. 2007 Elsevier Inc. All rights reserved.	control system;embedded system;experiment;fault tree analysis;metric;software product line;system safety	D. M. Needham;S. A. Jones	2007	Journal of Systems and Software	10.1016/j.jss.2007.01.042	reliability engineering;long-term support;verification and validation;real-time computing;software sizing;software verification;computer science;systems engineering;backporting;software development;software design description;software construction;software testing;life-critical system;software fault tolerance;software metric;software system;avionics software	Embedded	-62.37951773880986	30.81533722399592	17019
7833fbf87ff2a5c2b3a92f139213ecfea74bc2b3	operating guidelines - an automata-theoretic foundation for the service-oriented architecture	service composition;information services;automata service oriented architecture service composition operating guidelines matching;automata theoretic approach service oriented architecture soa service providers service requesters service brokers operating guidelines communication instructions;guidelines service oriented architecture system recovery automata automatic control protocols information management software quality publishing concrete;automata;matching;operating guidelines;automata theory;open systems information services automata theory;service oriented architecture;open systems;theoretical foundation	In the service-oriented architecture (SOA), we distinguish three roles of service owners: service providers, service requesters, and service brokers. Each service provider publishes information to the broker about how requesters can interact with its service. Thus, the broker can assign a fitting service provider to a querying requester. We propose the information published to the broker to be operating guidelines. Operating guidelines are essentially communication instructions for the service requester. We present an automata-theoretic approach that is centered around operating guidelines and is capable of implementing all tasks arising in the SOA.	automata theory;automaton;directed acyclic graph;matching (graph theory);service-oriented architecture;service-oriented device architecture;transition system	Peter Massuthe;Karsten Wolf	2005	Fifth International Conference on Quality Software (QSIC'05)	10.1109/QSIC.2005.47	service provider;matching;service level requirement;service level objective;service catalog;service product management;differentiated service;computer science;knowledge management;service delivery framework;service-oriented architecture;service design;automata theory;database;service;distributed computing;automaton;open system;service desk;data as a service;information system	HPC	-46.87868732255058	16.92377091473473	17040
559ccd1a22d8bb110082176b2e1c83125d570693	a framework for testing soa applications	research outputs;research publications;computing	Test driven development (TDD) is emerging as one of the most successful developer productivity aids. A key feature of TDD is the construction of a robust test harness before implementing code, enabling the creation of a “virtual contract”. The semantics of that contract are the fully enumerated set of test conditions for the system under construction. Service Oriented Architecture (SOA) raises a particular challenge in that there exists no unified method for testing an SOA application, which not only looks at individual artefact of the SOA application but also the complete application. Further, in SOA, the flexibility and connectivity provided by loosely coupled services increases both the opportunity for errors and the complexity of the testing. Given this situation, this paper describes a unified test-driven approach to a ground-up implementation of an SOA application where testing is seen as central to the development process. The paper proposes a framework that focuses on process-, configuration-, and service-oriented testing that provides relatively complete and flexible viewpoints of an SOA artefact’s health. A critical evaluation of our approach is presented in the context of the development of SOA applications that support core Higher Education business processes.	business process;iteration;loose coupling;quality of service;requirement;service-oriented architecture;service-oriented infrastructure;test case;test harness;test-driven development;visual artifact	Samia Oussena;Balbir S. Barn;Dan Sparks	2009			computing;computer science;knowledge management;operating system;software engineering;data mining	SE	-59.43917092700034	21.357108224256383	17082
ad61ee7abd000afb0bfb1ab9ee71a54470fce06f	model-driven business performance management	metric computation;key performance indicator;and situation detection;runtime engines monitoring software performance event detection data mining logic programming java load modeling delay;real time;code generation;java code;business environment;hybrid compilation interpretation approach;customer engagement efforts;business data processing;it enabled enterprise;customer engagement efforts model driven business performance management it enabled enterprise meta model hybrid compilation interpretation approach metric computation and situation detection java code code generation;meta data;business performance management;program compilers;monitoring and control;model driven business performance management;meta model;program compilers business data processing java meta data;dynamic loading;java	In this paper, we present a model-driven approach to business performance management (BPM). BPM is a new frontier in IT-enabled enterprise that supports the monitoring and control of business operations. BPM solutions must be able to efficiently process business events, compute business metrics, detect business situations, and provide the real-time visibility of key performance indicators. In addition, system support is required for the rapid development of BPM solutions and the adaptation of the solutions to the dynamic business environment. We have adopted a meta-model, dubbed the observation meta-model, for capturing the business requirements for BPM, which frees solution developers from low-level programming concerns. We have also used a hybrid compilation-interpretation approach to map an observation model to the runtime executable. First, we extract and refactor the data aspect of the observation model to facilitate runtime access. Second, we compile the operational aspect of the model, such as logic for metric computation and situation detection, into Java code. Third, we develop a runtime engine that interprets the refactored model and dynamically loads the generated code, according to the meta-model. Our framework further enables the evolution and hot deployment of the observation model and provides the platform for several on-going customer engagement efforts	beam propagation method;business engineering;business requirements;code refactoring;compiler;complex event processing;computation;customer relationship management;dynamic loading;exptime;electronic business;exception handling;executable;high- and low-level;java platform, enterprise edition;low-level programming language;map;mathematical optimization;metamodeling;model-driven architecture;model-driven integration;real-time locating system;requirement;scalability;situation calculus;software deployment;system dynamics;transformer;typename	Liangzhao Zeng;Hui Lei;Michael J. Dikun;Henry Chang;Kumar Bhaskaran	2005	IEEE International Conference on e-Business Engineering (ICEBE'05)	10.1109/ICEBE.2005.89	metamodeling;real-time computing;business domain;computer science;artifact-centric business process model;business process management;operating system;performance indicator;software engineering;business case;database;business process model and notation;java;metadata;business rule;world wide web;computer security;business process modeling;code generation;business activity monitoring	SE	-55.4021858834176	17.31915030409218	17083
86654809d33b291a76895513ec82227c76d12df4	aplicando linked data na publicação de dados do enem		The present article describes the experiment performed with the National Examination of Secondary Education (ENEM) data set, in the year of 2008, which were published in the principles of linked data. To this end, the data set were first treated in a database, performed consolidation and represented by an ontology. Then, with the use of tools, the data set were converted to a RDF format, linked to the data of DBPedia and published in a triple store. Lastly, a Web application was built to allow visualization of the data with the aid of SPARQL consultations. The experiment allowed us to establish a workflow for publication of linked geographical data, allowing of analysis and discovery of new knowledge. Resumo. Este artigo descreve o experimento realizado com os dados do Exame Nacional do Ensino Médio (ENEM), do ano de 2008, que foram publicados nos princípios do Linked Data. Para tal, os dados foram primeiramente tratados em um banco de dados relacional, realizadas consolidações; e os dados, representados por uma ontologia. Em seguida, com o uso de ferramentas, foram convertidos para o formato RDF, ligados aos dados da DBPedia e publicados em um servidor de triplas. Por fim, uma aplicação Web foi construída para a visualização dos dados com auxílio de consultas SPARQL. O experimento permitiu estabelecer um fluxo para publicação de dados geográficos, possibilitando a descoberta de novos conhecimentos. 1 Introdução O Ministério da Educação (MEC) tem aplicado anualmente o ENEM, cujos resultados, para o governo, são tidos como um instrumento de avaliação e promoção de melhorias na educação e, para o secundarista, como a possibilidade de acesso às universidades públicas. Os dados obtidos com o exame ficam disponíveis para que a sociedade converta-os de forma tal que sejam entendidos também pelas máquinas e possam ser ligados a outros conjuntos de dados, permitindo complemento das informações. Na tentativa de avaliar o desempenho do secundarista e a qualidade do ensino médio, o MEC criou em 1998, o ENEM (CASAGRANDE, 2009). Posteriormente, o exame passou por reestruturações e foi utilizado, também, como forma de acesso de novos estudantes a universidades públicas brasileiras através do SiSU (Sistema de	dbpedia;dr-dos;em (typography);flow-following, finite-volume icosahedral model;linked data;numerical aperture;ontology (information science);power-on reset;resource description framework;sparql;semiconductor consolidation;serial digital video out;triplestore;unified model;web application	Samuel Pierri Cabral;Nitay Batista Beduschi;Airton Zancanaro;José Leomar Todesco;Fernando Alvaro Ostuni Gauthier	2012			linked data;world wide web;sparql;computer science	ML	-40.18556052693025	4.245367418355171	17107
d9775c6587bb768766653a31ce9f900b43c6805e	ontology-based integration of data sources	databases;data schema mapping;data schema integration;information systems;ontology mapping;decision aid;query processing;internal databases;application software;database management systems;external databases;constitution;schema integration;data mining;ontologies artificial intelligence;computer networks;semantic heterogeneity;data semantics;information integration;open systems database management systems ontologies artificial intelligence;research and development;ontologies databases data mining information systems research and development computer networks constitution application software warehousing query processing;semantics change;warehousing;ontology based integration;semantic heterogeneity problems;global ontology mapping;global ontology mapping ontology based integration multiple heterogeneous data sources internal databases external databases semantics change semantic heterogeneity problems data schema integration;information integration interoperability data semantics data schema mapping ontology mapping;schema mapping;ontologies;information fusion;interoperability;open systems;multiple heterogeneous data sources;heterogeneous data sources	Many applications, e.g., data/information fusion, data mining, and decision aids, need to access multiple heterogeneous data sources. These data sources may come from internal and external databases. They have to evolve due to requirement changes. Any change in an application domain induces semantics change in the data sources. The integration of these data sources raises several semantic heterogeneity problems. This has traditionally been the subject of data/schema integration and mapping. However, many heterogeneity conflicts remain in information integration due to lack of semantics. Therefore, richer semantics of data are needed to resolve the heterogeneity problems. Ontological approaches now offer new solution avenues to this interoperability limitation. In this perspective, we propose an ontology- based information integration with a local to global ontology mapping as an approach to the integration of heterogeneous data sources.	application domain;artificial intelligence;data mining;database;entry point;internet;interoperability;markup language;ontology (information science);ontology alignment;ontology-based data integration;requirement;soap;semantic heterogeneity;semantic integration;vocabulary;web language;web ontology language;web services description language;web services discovery;web interoperability;web service;xml	Michel Gagnon	2007	2007 10th International Conference on Information Fusion	10.1109/ICIF.2007.4408086	semantic integration;computer science;information integration;data integration;data mining;database;ontology-based data integration;information retrieval;enterprise information integration	DB	-38.534351577483534	5.896410690203534	17116
9635417a4fbc063112a2021f97a7558e4cc41ac7	vgpm: using business process modeling for videogame modeling and code generation in multiple platforms		Lately, the use of mobile applications in Smartphones has grown considerably. One of the most popular types of applications is videogames. As classic videogame development is a costly process several editors and tools to make this process quicker and easier have appeared. Although these editors allow the definition of various aspects of the videogame they do not include, in general, capabilities for modeling the logic of the game loop. In this research we propose VGPM, a specific notation based in the BPMN approach to define several important characteristics of the game logic, trying to reduce the cost of traditional videogame development.	business process;code generation (compiler);process modeling	Jaime Solis Martinez;Jordán Pascual Espada;Natalia Garcia-Menendez;B. Cristina Pelayo García-Bustelo;Juan Manuel Cueva Lovelle	2015	Computer Standards & Interfaces	10.1016/j.csi.2015.04.009	simulation;computer science;theoretical computer science;operating system;computer security	EDA	-44.79394594483393	28.567905576994484	17118
16df622e9f47c3f2fde68f0d3f102bf321a461a2	distribution and composition of collaborative business processes through peer-to-peer networks	peer to peer network;point of view;business process	Collaborative business processes are a special kind of (conventional) business processes. Both describe the synchronization  of a set of activities that are distributed over different units. In the conventional case, these units all belong to the  same organization. Here the purpose is to increase the degree of transparency up to a maximal degree (that makes sense from  an economical point of view). At the end the organization can decide how to set up itself in order to comply in the best possible  way to its objectives, often to increase customer benefit or efficiency.  	peer-to-peer	Dirk Werth;Philipp Walter;Peter Loos	2008		10.1007/978-3-642-00328-8_60	economics;knowledge management;artifact-centric business process model;marketing;distributed computing;business process;business process discovery;management;business process modeling	ML	-52.29787660662879	13.019633119848482	17159
a1777175bb1091f7a16c039b05f0fef2e4d2faf7	computer support for agile human-to-human interactions with social protocols	human interaction;social network;workflow system;cost efficiency	Despite many works in CSCW, groupware, workflow systems and social networks, computer support for human-to-human interactions is still insufficient, especially support for agility, i.e. the capability of a group of human beings, collaborators, to rapidly and cost efficiently adapt the way they interact to changes. In this paper, requirements for computer support for agile H2H interactions are presented. Next, the concept of social protocol is proposed as a novel model supporting agile H2H interactions. A social protocol consists of an extended social network and a workflow model.	agile software development;collaborative software;computer-supported cooperative work;entity;interaction;multitier architecture;prototype;refinement (computing);requirement;social network;technical support;web service	Willy Picard	2009		10.1007/978-3-642-01190-0_11	interpersonal relationship;human–computer interaction;computer science;systems engineering;knowledge management;workflow management system;cost efficiency;social network;workflow technology	AI	-50.16080116092701	13.863136317459437	17182
77060db4adaba3539b0a941aae83c3205463e852	ordit: a new methodology to assist in the process of eliciting and modelling organizational requirements	alison blyth;intelligent assistance;information technology;information filtering;task model;organizational memory;dr margaret strens;modifiability;trialability;eprints newcastle university;modelling language;requirement engineering;open access;emeritus professor john dobson;context sensitivity;enterprise modelling	Requirements engineering from an organisational perspective needs to be viewed as social engineering, Thus in this paper a modelling language will be presented, which is visual in nature, and with which we assert that it is possible to diagrammatically represent and reason about the impact that an information technology system may have on an organisation, and thus derive organisational requirements.	modeling language;requirement;requirements engineering;social engineering (security)	Andrew Blyth;J. Chudge;John E. Dobson;Ros Strens	1993		10.1145/168555.168580	computer science;artificial intelligence;operations research	SE	-59.6212693419772	16.099651578397093	17188
a8a09bef536a5b93e7466f9af9484a214ed3b8d7	a comparison of deontic matrices, maps and activity diagrams for the construction of situational methods	activity diagram;situational method engineering;process model;conference proceeding	Several approaches have been proposed to support situational method engineering (SME), each of them providing different techniques and using different basic concepts. In this work, we propose a framework for comparing SME approaches based on a generic SME process model. Three approaches are presented and compared by using this framework.	activity diagram;map;method engineering;process modeling	Valeria Seidita;Jolita Ralyté;Brian Henderson-Sellers;Massimo Cossentino;Nicolas Arni-Bloch	2007			activity diagram;computer science;systems engineering;artificial intelligence;software engineering;process modeling	SE	-55.16360692251535	21.50173784314818	17192
37ca92181e68da7bea6a62481feb5cf1ab132b02	a goal-oriented analysis to guide the development of a user feedback ontology		Nowadays, developers and service providers put a lot of effort on collecting and analyzing user feedback with the purpose of improving their applications and services. This motivates the proposal of new tools to collect and analyze feedback. In our work, we develop a user feedback ontology, aimed at clarifying the concepts of this domain. For that, we follow a goal-oriented methodology to identify the competency questions that represent the ontology requirements. In this paper, we discuss an excerpt of the goal model used to guide the development of our ontology. Moreover, we present examples of competency questions identified through the analysis, and the corresponding fragment of the user feedback ontology.	feedback;newton's method;requirement;web ontology language	Renata S. S. Guizzardi;Itzel Morales-Ramirez;Anna Perini	2014			process ontology;ontology;service provider;goal orientation;goal modeling;suggested upper merged ontology;competence (human resources);knowledge management;computer science	Web+IR	-49.21806743028073	17.03310379864161	17244
7280e4353efdd0e68c8c7a73ca4f45d0f2dc411c	supporting adaptation patterns in the event-driven business process modeling paradigm	swinburne	The event-driven business process modeling has been emerged as an alternative paradigm to the traditional workflow-based business process-modeling paradigm. One of the influencing factors for using this new paradigm is the flexibility and the agility it provides in supporting business process change. Weber et al. have proposed 14 high-level adaptation patterns that need to be supported by a flexible process-aware information system irrespective of the chosen paradigm. In this paper we investigate whether the event-driven paradigm can satisfactorily support these adaptation patterns; if so, how an event-driven approach should support these adaptation patterns. We also point to the future research directions that this work can lead to.	business process;event-driven programming;process modeling;programming paradigm	Malinda Kapuruge;Jun Han;Alan W. Colman	2013		10.1007/978-3-642-41154-0_22	computer science;knowledge management;artifact-centric business process model;process modeling;management science	Robotics	-58.68958200231919	16.990757590513287	17271
8b10a6b5aa4b0f34568bc580572be3bed3d05a18	nested forms with dynamic suggestions for quality rdf authoring		Knowledge acquisition is a central issue of the Semantic Web. Knowledge cannot always be automatically extracted from existing data, thus domain experts are required to manually produce it. On the one hand, learning formal languages such as RDF represents an important obstacle to non-IT experts. On the other hand, well-known data input interfaces, such as forms, do not address well the relational nature and flexibility of RDF. Furthermore, it is difficult to maintain data quality through time, and across contributors. We propose FORMULIS, a form-based interface for guided RDF authoring. It completely hides RDF notations , addresses the relational aspects with nested forms, and guides users by computing intelligent filling suggestions. Two user experiments show that FORMULIS helps users maintain good data quality, and can be used by users without Semantic Web knowledge.		Pierre Maillot;Sébastien Ferré;Peggy Cellier;Mireille Ducassé;Franck Partouche	2017		10.1007/978-3-319-64468-4_3	database;knowledge acquisition;computer science;rdf;data mining;rdf schema;obstacle;notation;semantic web;formal language;data quality	HCI	-36.907099305995835	6.801036913369821	17280
fdb060cc262f534ff44d48c0f797612ae0236778	web service = e + f + i	web services context aware services multiagent systems software agents proposals spatial databases monitoring mediation companies simple object access protocol;interaction;web service;companies;software agents web service contextual definition peer to peer computing ontology;ontologies artificial intelligence;feature interaction;software agents;monitoring;mediation;environment;spatial databases;web services;feature;interaction web service environment feature;web services ontologies artificial intelligence peer to peer computing software agents;peer to peer computing;simple object access protocol;proposals;ontology;contextual definition;multiagent systems;context aware services	This paper presents the E, F, I approach for the development of a contextual definition of a Web service. E, F, and I stand for environment, feature, and interaction, respectively. By default, a Web service resides in an environment E where it acts and reacts. In this environment E, the Web service exposes its features F to peers or other components for awareness and visibility purposes. Finally, the Web service gets engaged with peers in common activities by coordinating their interactions I. The contextual definition of a Web service is established using the components that make up each dimension of the E, F, I approach	interaction;quality of service;requirement;web service;world wide web	Emad Bataineh;Zakaria Maamar;Djamal Benslimane;Chirine Ghedira	2006	15th IEEE International Workshops on Enabling Technologies: Infrastructure for Collaborative Enterprises (WETICE'06)	10.1109/WETICE.2006.74	web service;computer science;ontology;multi-agent system;data mining;database;law;world wide web	Web+IR	-43.825778046289734	16.357074806770672	17333
3431288f6b06eae7cdff286886eb2046a317edbd	choosy and picky: configuration of language product lines	settore inf 01 informatica;language composition;language product lines	Although most programming languages naturally share several language features, they are typically implemented as a monolithic product. Language features cannot be plugged and unplugged from a language and reused in another language. Some modular approaches to language construction do exist but composing language features requires a deep understanding of its implementation hampering their use. The choose and pick approach from software product lines provides an easy way to compose a language out of a set of language features. However, current approaches to language product lines are not sufficient enough to cope with the complexity and evolution of real world programming languages. In this work, we propose a general light-weight bottom-up approach to automatically extract a feature model from a set of tagged language components. We applied this approach to the Neverlang language development framework and developed the AiDE tool to guide language developers towards a valid language composition. The approach has been evaluated on a decomposed version of Javascript to highlight the benefits of such a language product line.	feature model;javascript;programming language;software product line;top-down and bottom-up design	Thomas Kühn;Walter Cazzola;Diego Mathias Olivares	2015		10.1145/2791060.2791092	natural language processing;language identification;fourth-generation programming language;first-generation programming language;natural language programming;very high-level programming language;universal networking language;language primitive;object language;specification language;data control language;computer science;programming language implementation;domain-specific language;low-level programming language;modeling language;programming language;language technology;programming language specification;high-level programming language	PL	-47.53166340876065	26.054655846168387	17363
04d2bd16fcc7d652190f23756dfe9dd43f33a7ea	relating decisions in enterprise architecture using decision design graphs	graph theory;decision capturing;decision design graph enterprise architecture decision relationships design rationale decision capturing;decision design graph;computer architecture;software architecture;visualization;decision support systems;design rationale;decision relationships enterprise architecture decision design graphs ea modeling languages archimate language enterprise business products enterprise services it infrastructure it applications information technology architectural designs ea anamnesis approach business domain application domain technology domain software architecture architectural rationales decision relationship metamodel;computer architecture insurance software architecture visualization decision making educational institutions;software architecture decision support systems graph theory;decision relationships;enterprise architecture;insurance	Enterprise Architecture (EA) modeling languages, such as ArchiMate, describe an enterprise holistically. In doing so, they show an enterprise's business products and services, and how these are realized by IT infrastructure and applications. However, EA modeling languages lack the capability to capture design rationales for decisions that lead to specific architectural designs. In our previous work we presented the EA Anamnesis approach for capturing decision details behind EA models. In doing so, we focused on capturing individual architectural decisions (in terms of alternatives, decision criteria, et cetera). In this paper we present an approach for relating architectural decisions. Using decision design graphs, we make explicit how decisions from different enterprise domains (Business, Application, Technology) relate to each other. For example, how decisions taken on a business level affect IT decisions and vice versa. Our approach is inspired by well-known mechanisms for capturing architectural rationales in software architecture. Specifically we contribute: (1) a decision relationship metamodel for enterprise architecture, with a focus on recording the impact of decisions (2) the notion of a Decision Design Graph for enterprise architecture, a visual representation of this metamodel, and (3) an illustrative example illustrating the potential usefulness of capturing decision relationships.	archimate;architectural decision;decision analysis;decision problem;decision tree;design rationale;enterprise architecture;holism;metamodeling;modeling language;software architecture;theory	Georgios Plataniotis;Sybren de Kinderen;Henderik Alex Proper	2013	2013 17th IEEE International Enterprise Distributed Object Computing Conference	10.1109/EDOC.2013.23	enterprise architecture framework;functional software architecture;reference architecture;software architecture;visualization;enterprise software;nist enterprise architecture model;insurance;decision analysis;decision engineering;computer science;systems engineering;knowledge management;architecture domain;applications architecture;graph theory;service-oriented modeling;software engineering;enterprise architecture management;solution architecture;management science;enterprise architecture;enterprise integration;view model;design rationale;enterprise information security architecture;business decision mapping;data architecture;business architecture;enterprise life cycle	SE	-56.91806348926006	18.342355928161453	17369
ffceeb3c11dc590e953ffb82e53d09f0fdf9a93c	a unified simulation framework for spatial stochastic models	simulation;simulation framework;object oriented framework;design and implementation;object oriented programming languages;spatial stochastic models;stochastic geometry;spatial stochastic model;java	For spatial stochastic models, a lot of programs exist which deal with the simulation of specific models. But, combining them is not that easy and usually requires greater effort. This paper presents an object-oriented framework, i.e. a set of collaborating abstract and concrete classes, dealing with the simulation of such models. The selected fundamental models are only illustrating examples for the general concept. From the Java implementation of this framework, two code examples are shown, which could also be implemented similarly in any other object-oriented programming language. All interfaces and a lot of concrete classes can be implemented dimension-independent. The design and implementation problems arising in the context of static and dynamic plus sampling are specifically discussed. 2004 Elsevier B.V. All rights reserved.	java;programming language;sampling (signal processing);simulation;stochastic process	Johannes Mayer;Volker Schmidt;Franz Schweiggert	2004	Simulation Modelling Practice and Theory	10.1016/j.simpat.2004.02.001	real-time computing;simulation;computer science;theoretical computer science;object-oriented programming;java;stochastic geometry	AI	-34.03863084145349	27.280460584560153	17379
0f8fd77bd5bf3138460afb3b3dc9599066d1e5d8	alignment of misuse cases with security risk management	information systems security;misuse case ontology;security risk management;information systems;security of data risk management;information security;risk analysis;information system security risk management;job shop scheduling;availability;reference model;risk management;misuse cases;misuse case ontology information system security risk management meeting scheduler;risk management information security management information systems job shop scheduling risk analysis protection availability unified modeling language ontologies guidelines;information systems security risk management misuse cases requirements engineering;requirements engineering;protection;guidelines;requirement engineering;unified modeling language;management information systems;system development;ontologies;information system;meeting scheduler;use case;security of data	It is recognised that security has to be addressed through the whole system development process. However current practices address security only in late stages, i.e., development or maintenance. Due to the success of UML use cases, misuse cases have been accepted by industry as a means to tackle security. However misuse cases, firstly, lack a precise application process, secondly, are too general which results in under-definition or misinterpretation of their concepts. In this paper we examine misuse cases in the light of a reference model for information system security risk management (ISSRM). Using the well-known meeting scheduler example we show how misuse cases can be used to follow a security risk management process. Next we check the misuse case ontology according to the concepts found in current risk management standards. The paper suggests improvements for the conceptual appropriateness of misuse cases for the security risk domain.	information system;misuse case;norm (social);reference model;risk management;scheduling (computing);unified modeling language;whole earth 'lectronic link	Raimundas Matulevicius;Nicolas Mayer;Patrick Heymans	2008	2008 Third International Conference on Availability, Reliability and Security	10.1109/ARES.2008.88	reliability engineering;security management;security information and event management;knowledge management;scenario;business;computer security;information security management	Security	-58.11789974264592	21.697375780563675	17389
3ee15d5cd57c00580b755d5350a5d208976cf341	maximize system reliability for long lasting and continuous applications		In this paper, we use software rejuvenation as a preventive and proactive fault-tolerance technique to maximize the level of reliability for continuous and safety critical systems. We take both transient faults caused by software aging effects and network transmission faults into consideration and mathematically analyze the optimal software rejuvenation period that maximizes system’s reliability. The theoretical result is verified through empirical studies.	backup;fault tolerance;mega man network transmission;software aging;software rejuvenation;theory	Chunhui Guo;Hao Wu;Xiayu Hua;Shangping Ren;Jerzy Nogiec	2015		10.1007/978-3-319-16486-1_59	software rejuvenation;reliability engineering;empirical research;software aging;life-critical system;computer science	SE	-62.819899913996785	31.977972408323428	17403
80c6e48425cbfa6213b73d7ac295ba2fcf404f56	extending the delosdlms by the fast annotation service		DelosDLMS [9] is a prototype of a next-generation Digital Library Management System (DLMS) , jointly developed by partners of the EU-funded project DELOS 1 (a Network of Excellence on Digital Libraries). The goal of DelosDLMS is to combine text and audio-visual searching, to offer personalized browsing using new information visualization and relevance feedback tools, to allow retrieved information to be annotated and processed, to integrate and process sensor data streams, and finally, from a systems engineering point of view, to be easily configured and adapted while being reliable and scalable. The DelosDLMS prototype is currently being built by integrating digital library functionality provided by DELOS and non-DELOS partners into the OSIRIS/ISIS platform, a middleware environment developed by ETH Zürich and now being extended at the University of Basel. OSIRIS (Open Service Infrastructure for Reliable and Integrated process Support) has been chosen as basis for integration since it follows a service-oriented architecture and thus allows to seamlessly add more functionality which is provided behind a (Web) service interface. ISIS (Interactive SImilarity Search) consists of a set of DL services that are built on top of OSIRIS. The ISIS services provide content-based retrieval of images, audio and video content, and the combination of any of these media types with sophisticated text retrieval. From a content point of view, DelosDLMS has been extended in first integration activities by support for contentbased retrieval of 3D objects 2 and advanced audio features 3. Moreover, a new visualization by aSelf-Organizing Map (SOM) representation of high-dimensional feature spaces 4	digital library;digital video;document retrieval;isis;information visualization;management system;middleware;operating system;point of view (computer hardware company);prototype;scalability;service-oriented architecture;service-oriented device architecture;systems engineering	Maristella Agosti;Gert Brettlecker;Nicola Ferro;Paola Ranaldi;Heiko Schuldt	2007			architecture;information retrieval;world wide web;visualization;digital library;data stream mining;information visualization;relevance feedback;computer science;annotation;middleware	Web+IR	-47.39253371439282	11.029548202657699	17418
5387590ea9af241d65fdbfb9feb88ec0f03d2db1	software agents to support administration in asynchronous team environments.	software agent		software agent	Roger Tagg	2003			real-time computing;computer science;knowledge management;artificial intelligence;software agent;distributed computing	HCI	-41.97968958707545	17.967206278353174	17424
8f474d7c23c73db4cac34403ca3f8d76f9b18a5e	describing software specification by combining sysml with the b method	abstract machine notations software specification sysml diagram b method system modelling language;specification;unified modeling language software modeling abstracts educational institutions vehicles;b method;sysml finite automata formal specification;software development;sysml;software development sysml b method specification	This paper shows a methodology to describe software specifications combining SysML with the B method. Modeling languages of a system such as SysML do not guarantee the correctness of the specification. In addition, formal methods including the B method are generally difficult to use for describing software specifications from ambiguous requirements at the start of the development, because it is not easy for software developers to denote the formal notations. Our methodology redeems those shortcomings by iterating processes which translate SysML diagrams to the abstract machine notations of the B method. At the last part of this paper, we showed the effectiveness of our methodology with an example.	abstract machine;b-method;correctness (computer science);diagram;formal methods;formal specification;requirement;software developer;systems modeling language	Satoko Kinoshita;Hidekazu Nishimura;Hiroki Takamura;Daichi Mizuguchi	2014	2014 IEEE International Symposium on Software Reliability Engineering Workshops	10.1109/ISSREW.2014.66	b-method;software requirements specification;systems modeling language;computer science;systems engineering;engineering;software development;software engineering;programming language;specification	SE	-45.005211622552835	28.966275423706012	17470
cf1cd4c443062195b31875540f7c774f606bded5	what are the used activity diagram constructs? a survey	software;uml constructs activity diagram constructs uml activity diagrams unified modelling language;empirical study uml usage survey;software engineering;unified modeling language tutorials object oriented modeling educational institutions software software engineering jacobian matrices;tutorials;unified modeling language;jacobian matrices;object oriented modeling	UML Activity diagrams offer a very large set of constructs, however many of them seem scarcely used or even their existence is not known. Here, we present a precise view of the usage levels of these constructs by means of a survey, covering preliminarily books, courses, tutorials, and tools about UML. Results show that, among the 47 Activity diagrams constructs, a large majority of them seem to be scarcely used, while, only nine result widely used. This work is part of a larger project aimed at investigating the usage level of the UML diagrams and their constructs, also by means of a personal opinion survey intended for UML users. UML is really a huge notation, and as consequence, on one hand, it is difficult and time consuming to master it, and on the other hand, people tend, naturally, to consider only a part of it; by means of this empirical study we want to assess what are the most/less used UML diagrams/constructs.	activity diagram;applicative programming language;book;control flow;swim lane;unified modeling language	Gianna Reggio;Maurizio Leotta;Filippo Ricca;Diego Clerissi	2014	2014 2nd International Conference on Model-Driven Engineering and Software Development (MODELSWARD)		unified modeling language;uml state machine;communication diagram;systems modeling language;uml tool;computer science;systems engineering;theoretical computer science;software engineering;applications of uml;class diagram;database;shlaer–mellor method;diagramming software;programming language;node;object constraint language	SE	-58.336150940179095	29.858166366565108	17548
ed636f309f7c7e5908fb5548115bc0b82f39e61a	a specification and validation approach for business process integration based on web services and agents	web service	In this paper, we present a new approach for business processes integration. Our approach is based on interaction protocols that enable autonomous, distributed business process modules to integrate and collaborate. In our case, the business processes integration is modelled using AUML and specified using BPEL4WS. Furthermore and to increase the reliability of interaction protocols at design time, our approach presented in this paper can validate the BPEL4WS specification with business constraints (specified by means of OCL). The validated BPEL4WS specification is considered as a specification language for expressing the interaction protocols of the multi-agents system, which can then intelligently adapt to changing environmental conditions.	autonomous robot;autonomy;business process execution language;business process interoperability;interaction protocol;object constraint language;software agent;specification language;validator;web service;world wide web	Djamel Benmerzoug;Mahmoud Boufaïda;Fabrice Kordon	2007			reliability engineering;business process execution language;systems engineering;artifact-centric business process model;ws-policy;business process model and notation;process management;services computing;ws-i basic profile	SE	-45.66815432747989	18.69736783885604	17565
359c5ac63abda292491508e464bcb3099ebfb46a	agents and complex systems	complex system	Traditional objects can be thought of as passive, because they wait for a message before performing an operation. Then, once invoked, they execute their method and go back to “sleep” until the next message. A trend in many systems now is to design objects that react to events in their environment, as well as be proactive. In UML 2.0, these are known as active objects; in the agent community, they are known as agents. Whether they are called active objects or agents, this new direction is going to radically change how we design systems. The biggest challenge, however, that we face is the degree of complexity that we are about to unleash. Imagine setting free a million proactive entities to run a supply chain. We are no longer choreographing their every movement as we would with traditional agents; instead, they decide when and how to execute their methods. This is both liberating and scary. We can create complex systems, but we will not always know how to control them. In complex systems: designing the parts is not the same as designing the whole.	agent-based model;book;code refactoring;complex adaptive system;complex systems;critical mass (sociodynamics);emergence;entity;flock;interaction;jam;organizing (structure);parallel computing;proactive parallel suite;self-organizing map;systems design;unified modeling language	James Odell	2002	Journal of Object Technology	10.5381/jot.2002.1.2.c3	complex systems;computer science	AI	-39.08619228548371	20.815610468235654	17570
daab9932e0f588eb41982aa72c973dbddd37042b	human-in-the-loop control processes in gas turbine maintenance		In this applied research paper, we describe an architecture for seamlessly integrating factory workers in industrial cyber-physical production environments. Our human-in-the-loop control process uses novel input techniques and relies on state-of-the-art industry standards. Our architecture allows for real-time processing of semantically annotated data from multiple sources (e.g., machine sensors, user input devices) and real-time analysis of data for anomaly detection and recovery. We use a semantic knowledge base for storing and querying data (http://www.metaphacts.com) and the Business Process Model and Notation (BPMN) for modelling and controlling the process. We exemplify our industrial solution in the use case of the maintenance of a Siemens gas turbine. We report on this case study and show the advantages of our approach for smart factories. An informal evaluation in the gas turbine maintenance use case shows the utility of automated anomaly detection and handling: workers can fill in paper-based incident reports by using a digital pen; the digitised version is stored in metaphacts and linked to semantic knowledge sources such as process models, structure models, business process models, and user models. Subsequently, automatic maintenance and recovery processes that involve human experts are triggered.		Michael Barz;Peter Poller;Martin Schneider;Sonja Zillner;Daniel Sonntag	2017		10.1007/978-3-319-64635-0_19	software engineering;input device;anomaly detection;industry 4.0;incident report;business process modeling;business process model and notation;human-in-the-loop;process modeling;computer science	Robotics	-53.39175366069125	16.256203665121802	17581
6bdfebc82317bd9eb5e9665fa352485019e01e3e	an embedded system for extracting keystroke patterns using pressure sensors	individual typing patterns;keystroke analysis;biometrics;physical security;embedded systems;password security;knn;behaviometrics;pattern recognition;typing dynamics;k nearest neighbour;pressure sensors;classifier performance;keystroke patterns;classification accuracy	Popular biometric security technologies include fingerprint and iris recognition systems. These technologies are extremely accurate because the patterns associated with an individual's finger or eye are very unique and static. However, when these technologies are used for physical access control they inform the potential adversary that specific characteristics are required to gain access. Behaviometrics aims to develop new strategies to enhance physical security via covert monitoring of distinct behavioral patterns. This research presents a novel stand-alone behaviometric prototype that incorporates standard password security with unique pressure characteristics to covertly analyse individual typing patterns. The prototype is evaluated under a controlled setting with 62 human subjects and nine classification algorithms. The kNN algorithm produced the highest classification rate of 94%. This research is one of the few papers that empirically substantiates biometric performance with a large-scale human subject trial, and also identifies several critical design considerations that impact classifier performance.	embedded system;event (computing);sensor	Christopher S. Leberknight;Michael L. Recce	2015	IJBM	10.1504/IJBM.2015.071948	speech recognition;computer science;archaeology;pressure sensor;data mining;k-nearest neighbors algorithm;computer security;biometrics;password strength	HCI	-51.264301453192736	6.489707184333997	17635
2e01322e72b772ebe1eb177d2eb9e577ec6a9c13	package surface blueprints: visually supporting the understanding of package relationships	package relationships;inheritance structure;argouml;compact visualization;package surface blueprints;object oriented programming;object oriented;inheritance structure package surface blueprints object oriented applications compact visualization argouml squeak package relationships;squeak;object oriented applications;packaging visualization software packages application software containers open source software collaborative software unified modeling language shape software systems	Large object-oriented applications are structured over large number of packages. Packages are important but complex structural entities that may be difficult to understand since they play different development roles (i.e., class containers, code ownership basic structure, architectural elements...). Maintainers of large applications face the problem of understanding how packages are structured in general and how they relate to each others. In this paper, we present a compact visualization, named Package Surface Blueprint, that qualifies the relationships that a package has with its neighbours. A Package Surface Blueprint represents packages around the notion of package surfaces: groups of relationships according to the packages they refer to. We present two specific views one stressing the references made by a package and another showing the inheritance structure of a package. We applied the visualization on two large case studies: ArgoUML and Squeak.	argouml;blueprint;entity;focus (computing);gestalt psychology;interactivity;recurrent neural network;squeak;usability	Stéphane Ducasse;Damien Pollet;Mathieu Suen;Hani Abdeen;Ilham Alloui	2007	2007 IEEE International Conference on Software Maintenance	10.1109/ICSM.2007.4362622	package diagram;computer science;package development process;theoretical computer science;programming language;package;object-oriented programming;engineering drawing	Visualization	-53.67792704164236	30.901315106346672	17674
4c910ab93522327900a02fa8ebd333a73c415764	multimedia tools and architectures for hardware/software co-simulation of reconfigurable systems	remote access;reconfigurable system;training and education;hardware software codesign;hardware software cosimulation;education multimedia tools hardware software cosimulation reconfigurable system design graphical objects animation management virtual simulation real world physical objects remotely accessible prototyping system engineering training;reconfigurable system design;reconfigurable architectures;virtual reality;engineering training;multimedia systems;virtual simulation;multimedia tools;multimedia systems computer architecture hardware software tools management training engineering management animation software prototyping virtual prototyping design engineering;virtual reality computer animation hardware software codesign multimedia systems reconfigurable architectures;hardware design;graphical objects animation management;computer animation;remotely accessible prototyping system;real world physical objects;design methodology	The paper describes novel multimedia tools and architectures for hardware/software co-simulation of reconfigurable systems. The main contributions are provided in the following three areas: 1) multimedia tools making it possible to manage animated graphical objects for virtual simulation of real world physical objects in the scope of reconfigurable system design; 2) a remotely accessible prototyping system, which is very helpful for both solving the problems of hardware design and supporting multimedia systems which can be used in vast varieties of practical applications, the most important of which are engineering training and education; 3) design methodology based on physical circuits and virtual objects. A number of illustrative examples demonstrating capabilities of the proposed approach are presented and discussed.	co-simulation;graphical user interface;reconfigurable computing;simulation;systems design	Valery Sklyarov;Iouliia Skliarova;Bruno Figueiredo Pimentel;Manuel Almeida	2008	21st International Conference on VLSI Design (VLSID 2008)	10.1109/VLSI.2008.70	embedded system;computer architecture;simulation;design methods;computer science;virtual reality;computer animation;computer engineering	EDA	-53.786522143032606	4.800318794830172	17705
3eac2179a489ed410a2700ec6b95794162589524	aspect-oriented web service composition with ao4bpel	gestion integrada;dynamic change;gestion integree;gestion entreprise;business process execution language;modele entreprise;processus metier;separation of concern;orientado aspecto;service web;firm management;integrated management;web service;modelo empresa;orientado servicio;web service composition;business process model;business model;internet;aspect oriented programming;algorithme reparti;proceso oficio;administracion empresa;algoritmo repartido;aspect oriented;oriente service;information system;distributed algorithm;systeme information;business process;oriente aspect;servicio web;service oriented;sistema informacion	Web services have become a universal technology for integration of distributed and heterogeneous applications over the Internet. Many recent proposals such as the Business Process Modeling Language (BPML) and the Business Process Execution Language for Web Services (BPEL4WS) focus on combining existing web services into more sophisticated web services. However, these standards exhibit some limitations regarding modularity and flexibility. In this paper, we advocate an aspect-oriented approach to web service composition and present AO4BPEL, an aspect-oriented extension to BPEL4WS. With aspects, we capture web service composition in a modular way and the composition becomes more open for dynamic change.		Anis Charfi;Mira Mezini	2004		10.1007/978-3-540-30209-4_13	web service;web application security;distributed algorithm;web development;web modeling;business process execution language;data web;aspect-oriented programming;web design;web standards;computer science;ws-policy;service-oriented architecture;web navigation;ws-addressing;services computing;web intelligence;web engineering;programming language;ws-i basic profile;web 2.0;law;world wide web;universal description discovery and integration	Web+IR	-40.83973701064485	23.858819940068933	17720
26c41a8377d151f10ca20f9eba4acae1d3c39bd6	synergies between the common criteria and process improvement	classification;it security;quality assessment;maturity;common criteria;capability maturity model integration;quality;system development;evaluation;process improvement;product quality;security;capability;assessment;categorization	This paper summarizes multifaceted synergies discovered between the ISO/IEC 15408 (Common Criteria) IT Security Evaluation standard, software product quality evaluation standards and the Capability Maturity Model Integration (CMMI®). In addition to serving research motivated interest, the usefulness of the synergies is demonstrated through case studies related to significant systems development projects.	capability maturity model integration;common criteria;software development process;synergy;utility	Miklós Biró;Bálint Molnár	2007		10.1007/978-3-540-75381-0_4	standard cmmi appraisal method for process improvement;reliability engineering;systems engineering;engineering;operations management	SE	-61.17875956107131	26.063585619538554	17741
4c1cdc1f2ca53a591763986803b215c763de2f97	assisting requirements engineering with semantic document analysis	document analysis;domain knowledge;incomplete information;qa75 electronic computers computer science;requirement engineering;software life cycle;structured documents;natural language processing;semantic analysis	Requirements engineering is the first stage in the software life-cycle and is concerned with discovering and managing a software system's services, constraints and goals. Requirements engineers frequently face the task of extracting domain knowledge and recovering requirements from large documents. This is needed to complement the often incomplete information elicited from the people who will use or otherwise have a stake in the system to be developed. The documents that have to be analysed may vary from structured documents, such as specifications of work processes, to unstructured, verbatim reports of interviews or workplace observations. This paper shows that tools exploiting natural language processing techniques, in particular semantic analysis, are able to assist in retrieval from these documents.	natural language processing;requirement;requirements engineering;semantic analysis (compilers);software release life cycle;software system	Paul Rayson;Roger Garside;Peter Sawyer	2000			natural language processing;requirements analysis;computer science;requirement;data mining;database	SE	-58.011316633701625	23.55423598733966	17760
6941f3507c1eaa4e7517f69ef81b37a7dcad1081	fuego—an open-source framework for board games and go engine based on monte carlo tree search	go engine;open source software framework;games decision trees algorithm design and analysis instruction sets open source software;computer go;game engine;monte carlo tree search;software frameworks;software frameworks computer game playing computer go fuego man machine matches monte carlo tree search open source software;public domain software;man machine matches;full information two player board games fuego go program go engine monte carlo tree search open source software framework;game of go;games;computer game playing;software framework;tree searching computer games monte carlo methods public domain software;fuego;tree searching;fuego go program;computer games;reusable component;decision trees;algorithm design and analysis;monte carlo methods;full information two player board games;computer game;open source software;instruction sets;open source	FUEGO is both an open-source software framework and a state-of-the-art program that plays the game of Go. The framework supports developing game engines for full-information two-player board games, and is used successfully in a substantial number of projects. The FUEGO Go program became the first program to win a game against a top professional player in 9 × 9 Go. It has won a number of strong tournaments against other programs, and is competitive for 19 × 19 as well. This paper gives an overview of the development and current state of the FUEGO project. It describes the reusable components of the software framework and specific algorithms used in the Go engine.	algorithm;game engine;monte carlo tree search;open-source software;software framework	Markus Enzenberger;Martin Müller;Broderick Arneson;R. Segal	2010	IEEE Transactions on Computational Intelligence and AI in Games	10.1109/TCIAIG.2010.2083662	combinatorial game theory;simulation;computer science;theoretical computer science;software framework;distributed computing;monte carlo tree search	Logic	-48.121516606549	12.333404692015183	17784
d8091bbe487e4024bf140c1e6dc6f04e209e4c47	gp-based approach to comprehensive quality-aware automated semantic web service composition		Comprehensive quality-aware semantic web service composition aims to optimise semantic matchmaking quality and Quality of service (QoS) simultaneously. It is an NP-hard problem due to its huge search space. Therefore, heuristics have to be employed to generate near-optimal solutions. Existing works employ Evolutionary Computation (EC) techniques to solve combinatorial optimisation problems in web service composition. In particular, Genetic Programming (GP) has shown its promise. The tree-based representation utilised in GP is flexible to represent different composition constructs as inner nodes, but the semantic matchmaking information can not be directly obtained from the representation. To overcome this disadvantage, we propose a tree-like representation to directly cope with semantic matchmaking information. Meanwhile, a GP-based approach to comprehensive quality-aware semantic web service composition is proposed with explicit support for our representation. We also design specific genetic operation that effectively maintain the correctness of solutions during the evolutionary process. We conduct experiments to explore the effectiveness and efficiency of our GP-based approach using a benchmark dataset with real-world composition tasks.	semantic web service;service composability principle	Chen Wang;Hui Ma;Aaron Chen;Sven Hartmann	2017		10.1007/978-3-319-68759-9_15	web service;web modeling;social semantic web;machine learning;semantic computing;semantic web;semantic analytics;semantic grid;computer science;semantic web stack;artificial intelligence	Web+IR	-45.56490726005554	14.683024271576466	17787
5b55d7f3a0f257c4af60b3c74d6904263c777a96	a bpmn extension for modeling cyber-physical-production-systems in the context of industry 4.0		Industry 4.0 denotes a recent trend that aims at exploiting Cyber Physical Systems (CPS), based on IoT (Internet of Things) and cloud computing technologies, to obtain increased degrees of cooperation and communication in production systems, thus leading to what is referred to as Cyber Physical Production Systems (CPPS) or “Smart Factories”.	business process model and notation;cloud computing;control unit;executable;industry 4.0;internet of things;metamodeling;model-driven architecture;risk management;scalability;sensor;simulation	Paolo Bocciarelli;Andrea D'Ambrogio;Andrea Giglio;Emiliano Paglia	2017	2017 IEEE 14th International Conference on Networking, Sensing and Control (ICNSC)	10.1109/ICNSC.2017.8000159	industry 4.0;unified modeling language;business process model and notation;cyber-physical system;cloud computing;systems engineering;computer science;process modeling;internet of things	EDA	-57.0484541483102	16.6364142385946	17818
82995f7ac0204263327c72b87b9e6d6ae8bb5ade	hierarchical progression analysis: a development and verification methodology		Hierarchical progression analysis (HPA) is a methodology which provides traceability through a software system by relating the data and control flows between the various disciplines needed to develop and verify a system. Although HPA was originally intended as a development tool, the methodology can also be applied when verifiying and documenting existing systems.	color gradient	Betty J. Andrews	1984	Inf. Process. Manage.	10.1016/0306-4573(84)90057-8	computer science	SE	-45.63023660190382	30.101354792095847	17829
84f7ae05dad9a3fe8f8c9906e58a9a007f08439f	an agent-based framework for petroleum information services from distributed heterogeneous data resources	databases;production transducers information technology australia distributed databases web sites information retrieval petroleum industry software engineering application software;petroleum production;application software;agent based;information retrieval;information technology;transducers;heterogeneous data;object oriented programming;software engineering;gaia methodology;open agent architecture;petroleum industry object oriented programming distributed databases;complex system;distributed heterogeneous data resources petroleum production databases gaia methodology open agent architecture agent based technique software engineering;080309 software engineering;web sites;petroleum industry;distributed databases;distributed heterogeneous data resources;agent based technique;production;world wide web;information service;conference proceeding;australia	For making good decisions in the area of petroleum production, it is becoming a big problem how to timely gather sufficient and correct information, which may be stored in databases, data files, or on the World Wide Web. In this paper, Gaia methodology and Open Agent Architecture were employed to contribute a framework to solve above problem. The framework consists of three levels, namely, role mode, agent type, and agent instance. The model with five roles is analyzed. Four agent types are designed. Six agent instances are developed for constructing the system of petroleum information services. The experimental results show that all agents in the system can work cooperatively to organize and retrieve relevant petroleum information. The successful implementation of the framework shows that agent-based technology can significantly facilitate the construction of complex systems in distributed heterogeneous data resource environment.	agent communications language;agent-based model;complex systems;database;gaia hypothesis;multi-agent system;open agent architecture;world wide web	Chengqi Zhang;Chunsheng Li;Zili Zhang	2002		10.1109/APSEC.2002.1183095	application software;transducer;computer science;petroleum industry;engineering;software engineering;data mining;database;object-oriented programming;information technology;world wide web	AI	-45.57824137635559	7.979532751607973	17852
13bab80dcb494ca29aaaceacf25fe922e7a4a351	integrating planning and scheduling in workflow domains	time window;planning and scheduling;automatic generation;business process model;makespan minimisation;object oriented;workflow management system;workflow management systems;business process reengineering;ai planning;modeling tool;time windows	One of the main obstacles in applying AI planning techniques to real problems is the difficulty to model the domains. Usually, this requires that people that have developed the planning system carry out the modeling phase since the representation depends very much on a deep knowledge of the internal working of the planning tools. On some domains such as Business Process Reengineering (BPR), there has already been work on the definition of languages that allow non-experts entering knowledge on processes into the tools. We propose here the use of one of such BPR languages to enter knowledge on the organisation processes to be used by planning tools. Then, planning tools can be used to semi-automatically generate business process models. As instances of this domain, we will use the workflow modeling tool SHAMASH, where we have exploded its object oriented structure to introduce the knowledge through its user-friendly interface and, using a translator transform it into predicate logic terms. After this conversion, real models can be automatically generated using a planner that integrates Planning and Scheduling, IPSS. We present results in a real workflow domain, the TELEPHONE INSTALLATION (TI) domain.	automated planning and scheduling;business process;code refactoring;domain theory;electronic data processing;estimation of signal parameters via rotational invariance techniques;kasparov's gambit;knowledge-based systems;logic programming;microsoft windows;scheduling (computing);semiconductor industry;shamash;usability	María Dolores Rodríguez-Moreno;Daniel Borrajo;Amedeo Cesta;Angelo Oddi	2007	Expert Syst. Appl.	10.1016/j.eswa.2006.05.027	automated planning and scheduling;workflow;computer science;knowledge management;business process management;process management;business process modeling;workflow management system;workflow engine;workflow technology	AI	-53.41979258928248	19.45042204063774	17921
82f4aef0a60808acda58a79aa3924867a7eb7b2b	aspectlisa: an aspect-oriented compiler construction system based on attribute grammars	compiler construction;attribute grammars;compiler generators;attribute grammar;object oriented;aspect oriented programming;object oriented approach;aspect oriented;article	The use of object-oriented techniques and concepts, like encapsulation and inheritance, greatly improves language specifications towards better modularity, reusability and extensibility. Additional improvements can be achieved with aspect-oriented techniques since semantic aspects also crosscut many language constructs. Indeed, aspect-oriented constructs have been already added to some language specifications. The LISA compiler construction system follows an object-oriented approach and has already implemented mechanisms for inheritance, modularity and extensibility. Adding aspects to LISA will lead to more reusable language specifications. In the paper, aspectoriented attribute grammars are introduced, and the underlying ideas are incorporated into AspectLISA, an aspect-oriented compiler generator based on attribute grammars.	aspect-oriented programming;aspect-oriented software development;attribute grammar;compiler;compiler-compiler;extensibility;init;lisa;lexicon;programming language;software propagation	Damijan Rebernak;Marjan Mernik;Pedro Rangel Henriques;Maria João Varanda Pereira	2006	Electr. Notes Theor. Comput. Sci.	10.1016/j.entcs.2006.10.003	natural language processing;compiler;l-attributed grammar;aspect-oriented programming;compiler correctness;computer science;theoretical computer science;compiler construction;programming language;functional compiler	PL	-47.15188102281291	26.236942882101236	17952
f8e966ad66157ff37e3425a3d6f4864401623fec	decomposition /generalization methodology for object-oriented programming	verification;herencia;generalizacion;definition differee;mise a jour;metodologia;decomposition;programmation;heritage;selection;ingenieria logiciel;object oriented programming;software engineering;methodologie;analyse descendante;programacion;generalisation;object oriented;rafinement;genie logiciel;oriente objet;puesta al dia;verificacion;descomposicion;seleccion;methodology;c;inheritance;orientado objeto;programming;generalization;updating	Abstract   The object-oriented paradigm is often connected with bottom-up programming, which is characterized by steps of composition and specialization. The opposite of bottom up is the top-down paradigm, based on steps of decomposition and generalization. In most projects, a free exchange between top-down and bottom-up methods is the best mode of operation. This article presents a variant of the top-down paradigm called the decomposition/generalization methodology, which is based on stepwise refinement. Decomposition consists of selection, refinement, class membership for deferred functions, code update, and verification. Generalization consists of the establishment of inheritance relations and the sliding of member functions to the base class. Although the language used here is C + +, the same methodology can be easily adapted to object-oriented PASCAL, SMALLTALK, and other object-oriented languages.		Václav Rajlich	1994	Journal of Systems and Software	10.1016/0164-1212(94)90078-7	generalization;computer science;artificial intelligence;theoretical computer science;programming language;object-oriented programming;management;algorithm	PL	-38.261906759403	24.677033977766754	18004
e6c8ce4e294c77fead36ade17e2641dd5550ccb0	safety-related application conditions - a balance between safety relevance and handicaps for applications	process for defining and complying with sacs;safety related application conditions;conditions for defining sacs;sac quality;quality criteria	Railway standards prescribe the use of Safety-related Application Conditions (SACs). SACs are demands to be observed when using a safety related system or a sub-system. The use of SACs can, however, easily be associated with difficulties. SACs of sub-systems can imply high efforts regarding their fulfillment at system level. Furthermore, SACs at sub-system level may become very obstructive for the user of the sub-system, if the safe application on system level has strong restrictions. Additionally, a large number of SACs may be very difficult to manage. In this way, SACs may obstruct the introduction of a system or a sub-system into the field. Particular hazards could arise from SACs, if they are formulated ambiguously, so that the originally intended safety-related measures are not taken at all. This paper presents the objectives and benefits of SACs and depicts difficulties and challenges associated with the use of SACs. The paper not only explains what should be the SAC content but also the quality criteria, the conditions for SAC creation and SAC fulfillment are described. The SAC management process introduced at Thales Rail Signalling Solutions GmbH is outlined. On the one hand, this process shall support the quality of SACs and on the other hand reduce the effort for SAC creation, fulfillment and evidence.	hazard (computer architecture);relevance;requirement;sac;semiconductor consolidation;system lifecycle	Friedemann Bitsch;Ulrich Feucht;Huw Gough	2009		10.1007/978-3-642-04468-7_4	engineering;transport engineering	SE	-56.80344086171942	23.655086870366198	18011
803a7837a730a263c118237ccae7b0d6d7aad30b	efficiently compositing and optimizing the quality of heterogeneous services	quality of services;simulated annealing;web services;automatics service composition;local search	The emerging service-oriented computing bring various services together to a 'market' for clients to request, enabling the integration of services across the distributed, heterogeneous, and wide area networks. By encapsulating diverse implementations of physical and software resources in the interface that standardizes the functions, loosely coupled services have show great potential to support a versatile integration platform for complex applications. Existing techniques can successfully support integrating services from different providers to provide applications with more complex user requirements. However, to automatically composite services with guaranteed QoS is not trivial. In this paper, the authors propose Q-SAC, a QoS optimized service automatic composition model. Two main features of Q-SAC include automatic service composition, and multidimensional QoS optimization for the composition plan. The authors show that the problem of Q-SAC QoS optimization is NP-hard, and design a heuristic simulated annealing algorithm. Through simulation the authors show that this design is practical and efficient.	compositing;optimizing compiler	Hanhua Chen;Hai Jin	2014	Int. J. Web Service Res.	10.4018/ijwsr.2014070104	web service;mobile qos;simulated annealing;computer science;local search;data mining;database;services computing;world wide web	Web+IR	-46.137689282217416	15.120005618022363	18033
0fd56bf0d0fc17f71e5b76d691f4b6f143ca4600	a conceptual design environment for micromechanisms	knowledge based system;cad;micromechanisms;fem;sysfund;conceptual design;micromechanical devices;functional decomposition;performance analysis;knowledge sharing;accelerometers design engineering finite element methods process design performance analysis multimedia systems fabrication computational modeling algorithm design and analysis acceleration;fea system;electronic engineering computing;finite element analysis;knowledge representation;cad micromechanical devices finite element analysis knowledge representation knowledge based systems electronic engineering computing;knowledge sharing environment;sysfund micromechanisms knowledge based system knowledge sharing environment knowledge representation functional decomposition finite element analysis fea system fem;knowledge based systems;support function	This paper presents the use of a knowledge based system and a knowledge sharing environment to support the design of micromechanisms. Based on the experience of a design project, we discuss knowledge representation concerning the function and behavior for supporting functional decomposition. For the knowledge sharing environment, we have extended a finite element analysis system to allow the designer to perform analysis over the network.	finite element method;knowledge representation and reasoning;knowledge-based systems	T. Kiriyama;N. Nakajima;Shinobu Yoshimura;S. Burgess;D. Moore;N. Shibaike	1996		10.1109/EDTC.1996.494339	simulation;engineering;engineering drawing;mechanical engineering	AI	-56.41657074671974	10.630008439544305	18043
488bb3cbb8ca1b9020e2292efa4b449d627b1021	keywords-to-sparql translation for rdf data search and exploration		Linked Data is the most common practice for publishing and sharing information in the Data Web. As new data become available, their exploration is a fundamental step towards integration and interoperability. However, typical search methods as SPARQL queries require knowing both the SPARQL syntax and the vocabulary used in the data. For this reason, keyword-based search has been proposed, allowing an intuitive way for searching an RDF dataset. In this paper, we present a novel approach for keyword search on graph-structured data, and in particular temporal RDF graph, i.e. RDF data that involve temporal properties. Our method, instead of providing answers directly from the RDF data graph, automatically generates a set of candidate SPARQL queries that try to capture users information need as expressed by the keywords used. To support temporal exploration, our method is enriched with temporal operators allowing the user to explore data within predefined time ranges. To evaluate our approach, we perform an effectiveness study using two real-world datasets.	sparql	Katerina Gkirtzou;Kostis Karozos;Vasilis Vassalos;Theodore Dalamagas	2015		10.1007/978-3-319-24592-8_9	sparql;database;rdf query language;information retrieval;rdf schema	NLP	-34.93624939762491	4.481333345635671	18051
6e642e64872236a7c8a18da4ea8e35bed1671e4f	benchmark requirements for microservices architecture research		Microservices have recently emerged as a new architectural style in which distributed applications are broken up into small independently deployable services, each running in its own process and communicating via lightweight mechanisms. However, there is still a lack of repeatable empirical research on the design, development and evaluation of microservices applications. As a first step towards filling this gap, this paper proposes, discusses and illustrates the use of an initial set of requirements that may be useful in selecting a community-owned architecture benchmark to support repeatable microservices research.	benchmark (computing);distributed computing;microservices;open-source software;requirement;software architecture	Carlos M. Aderaldo;Nabor das Chagas Mendonça;Claus Pahl;Pooyan Jamshidi	2017	2017 IEEE/ACM 1st International Workshop on Establishing the Community-Wide Infrastructure for Architecture-Based Software Engineering (ECASE)	10.1109/ECASE.2017.4	microservices;architectural style;empirical research;software;architecture;software architecture;benchmark (computing);systems engineering;engineering	SE	-60.13251042507198	21.765700252026633	18082
1fce03d3c626f4686eb62a51cff28aa5f8db8689	case tool support for co-operative work in information system design	case tool;information system design	The need for asynchronous co-operative work in design is shown by many surveys of CASE tool use and research on design. MetaEdit+ is a metaCASE environment that allows multiple simultaneous modellers to work together on designing information systems and also information systems design methods. We describe the automatic locking strategies that enable MetaEdit+ to offer a high level of concurrency whilst guaranteeing consistency, enabling effective co-operative work. In particular we describe a new collection data structure that allows high concurrency of updates even at small sizes, fulfilling the need in CASE for largest growth of design information at the start of a project. Finally, we evaluate MetaEdit+’s collaboration support and performance as teamware, comparing it with several CASE tools.		Steven Kelly	1998		10.1007/978-0-387-35347-0_3	executive information system;systems engineering;knowledge management;management information systems	HCI	-61.20288506127422	13.51407480909407	18098
5155055746ec3f3e64a4fda4193c519db012e3a9	towards a formal model for view maintenance in data warehouses	formal model;multi party computation;byzantine agreement;broadcast;quantum signatures;data warehouse;public key infrastructure	As the capability for storing data increases, there is a greater need for developing analysis tools that provide aggregation and summarization capabilities. In the context of databases, a new class of query processing referred to as OLAP (OnLine Analytical Processing) has emerged for aggregating and summarizing vast amount of data. A typical example of an OLAP query is to identify total sales for a product type in a geographic region over a specific period of time. As this example illustrates, since OLAP queries need to scan the data for aggregation, executing them on traditional DBMSs will adversely impact the OLTP (OnLine Transaction Processing) workload, which typically consists of short update transactions. Furthermore, enterprise wide data is typically stored on multiple database repositories. Such geographical distribution leads to expensive distributed processing for OLAP queries which demand interactive response times. Unlike the OLTP workloads where up-todate data is mandatory, OLAP queries typically involve historical data which need not be absolutely up-to-date. This property of OLAP queries has resulted in the emergence of the notion of data warehouses. Data warehouses exploit the lack of strict currency requirement of OLAP queries by creating a redundant view of the data that is derived from the data repositories or multiple DBMSs comprising an enterprise. In the context of relational DBMSs, this view is specified in terms of an SPJ-expression (select-project-join) over the multiple relations contained in the data repositories. Once the view is created, a critical issue is how to keep the view both consistent as well as approximately current with respect to the changes that occur in the data sources from which the view is derived. One possibility is to re-compute the entire view periodically, e.g., daily, weekly, or monthly. However, such re-computation is unnecessary and wasteful. Instead the view can be maintained incrementally. That is, a view is created initially. Subsequently, whenever changes occur at	computation;database;distributed computing;emergence;mathematical model;online analytical processing;online transaction processing;product type	Achour Mostéfaoui;Michel Raynal;Matthieu Roy;Divyakant Agrawal;Amr El Abbadi	2002		10.1145/571825.571845	computer science;public key infrastructure;data warehouse;data mining;database;computer security	DB	-34.82221736539077	15.459676245918667	18107
e18a92c11a5348e05c7b82821729a3001b31fdf4	definition of a component selection process based on qos criteria and its application to self-adaptive software systems	selection model;software engineering object oriented programming quality of service;unified modeling language quality of service monitoring utility theory context modeling feedback loop computational modeling;computer model;selection;software systems;object oriented programming;software engineering;proof of concept;context model;strategy;computational modeling;anamoc module component selection process qos criteria self adaptive software systems feedback loops multiattribute utility theory quality of service;monitoring;feedback loop;unified modeling language;adaptive system;model;dynamic adaptation selection model strategy;multi attribute utility theory;quality of service;dynamic adaptation;context modeling;utility theory	Nowadays, self-adaptive systems use the concept of feedback loops. This approach is based on the selection of components that conform to the expected requirements. The selection became increasingly complex in such systems due to the variety of criteria. This paper proposes a process for dynamic selection of components using multi-attribute utility theory based on Quality of Service (QoS) criteria. Furthermore, it defines a model that can be used to represent the current needs of an application, and that is used by the proposed selection process for evaluating the candidate components. As a proof of concept, it's presented the AnaMoC module that performs the selection of components based on the proposed process.	adaptive system;feedback;quality of service;requirement;software system;utility	Daniel Cunha da Silva;Adilson B. Lopes;Jair C. Leite;Felipe A. P. Pinto;Carlos Eduardo da Silva	2011	2011 Fifth Brazilian Symposium on Software Components, Architectures and Reuse	10.1109/SBCARS.2011.10	reliability engineering;computer science;systems engineering;management science	SE	-56.44385158580054	26.983000109311433	18140
6abec4cdf9823a0f604645eb4d990f6422ba73c0	automated analysis of stateflow models		Stateflow is a widely used modeling framework for embedded and cyberphysical systems where control software interacts with physical processes. In this work, we present a framework and a fully automated safety verification technique for Stateflow models. Our approach is two-folded: (i) we faithfully compile Stateflow models into hierarchical state machines, and (ii) we use automated logic-based verification engine to decide the validity of safety properties. The starting point of our approach is a denotational semantics of Stateflow. We propose a compilation process using continuation-passing style (CPS) denotational semantics. Our compilation technique preserves the structural and modal behavior of the system. The overall approach is implemented as an open source toolbox that can be integrated into the existing Mathworks Simulink/Stateflow modeling framework. We present preliminary experimental evaluations that illustrate the effectiveness of our approach in code generation and safety verification of industrial scale Stateflow models.		Hamza Bourbouh;Pierre-Loïc Garoche;Christophe Garion;Arie Gurfinkel;Temesghen Kahsai;Xavier Thirioux	2017			model checking;compiler;finite-state machine;continuation-passing style;denotational semantics;theoretical computer science;software;stateflow;code generation;computer science	SE	-39.80446697260941	31.1203521785276	18197
accf125a5cf10b73bacf05ae6b0c0e7d6b3a43c0	web services and formal methods	web service;software engineering;formal method;user interface;human computer interaction;information system	Recent trends in formal models of web services description languages and session types focus on the asynchronicity of communications. In this paper, we study a core of these models that arose from our modelling of the Sing# programming language, and demonstrate correspondences between Sing# contracts, asynchronous session behaviors, and the subclass of communicating automata with two participants that satisfy the half-duplex property. This correspondence better explains the criteria proposed by Stengel and Bultan for Sing# contracts to be reliable, and possibly indicate useful criteria for the design of WSDL. We moreover establish a polynomial-time complexity for the analysis of communication contracts under arbitrary models of asynchronicity, and we investigate the model-checking problems against LTL formulas.	automata theory;duplex (telecommunications);formal methods;model checking;polynomial;programming language;time complexity;web services description language;web service	Benôıt Masson;Löıc Hélouët;Albert Benveniste	2011		10.1007/978-3-642-29834-9	web service;web application security;web development;business process execution language;data web;web standards;ws-policy;service-oriented architecture;semantic web;social semantic web;ws-addressing;services computing;web intelligence;ws-i basic profile	AI	-46.04054539448583	18.92188276712922	18200
d54509cd099ee6e81e9afabdc460e3e3283b284e	disciplined composition of aspects using tests	tests;test driven development;banking system;software evolution;aspect oriented programming;software development	A large part of the software development effort is typically spent on maintenance and evolution, namely on adding new and unanticipated features. As aspect-oriented programming (AOP) can be easily used to compose software in non-planned ways, many researchers are investigating AOP as a technique that can play an important role in this particular field. However, unexpected interactions between aspects are still a major problem that compromise AOP's applicability, especially in large projects where many developers, often including new team members, are involved in the process. This paper addresses the issues of aspect conflicts and interactions and proposes a technique to help compose aspects in a disciplined way using a test-driven development approach. A simple example for a banking system helps on illustrating the technique.	aspect-oriented programming;interaction;software development;test-driven development	André Restivo;Ademar Aguiar	2008		10.1145/1404953.1404961	simulation;systems engineering;engineering;operations management;software development	SE	-61.86238671909802	26.324706138065796	18216
cb44f24667f75afd165e4b4c51087577e6a282f8	managing variability of erp ecosystems: research issues and solution ideas from microsoft dynamics ax	variability management;articulo;erp ecosystems;product line;erp system;product family;product line engineering;software product line;managing variability of erp ecosystems research issues and solution ideas from microsoft dynamics ax;microsoft dynamics ax	Systematic reuse of artifacts and a clear understanding of the variability within a product family are key success concepts within diverse industrial domains. Nevertheless, there are still many open issues regarding adapting and tailoring of software product line engineering approaches to specialized domains. The nature of ERP systems would suggest the application of product line techniques, but the limitations and constraints within this domain makes this a challenging task from the viewpoint of a partner company. In this paper we discuss ERP domain constraints and provide first conceptual solutions on how to adapt and extend software product line techniques for this particular context. Furthermore, we present a first tool prototype to support sales consultants at ERP partner companies.	erp;ecosystem;enterprise resource planning;heart rate variability;microsoft dynamics ax;prototype;software product line;spatial variability	Markus Nöbauer;Norbert Seyff;Deepak Dhungana;Reinhard Stoiber	2012		10.1145/2110147.2110150	systems engineering;engineering;knowledge management;operations management;software engineering;domain engineering	DB	-60.651139914763625	21.045667344308914	18232
85aa4619d452998a4f4333ca5d80187b077af3d9	simulation based performance analysis of an intelligent robotic system control architecture	system design;intelligent systems;simulation model;intelligent control;discrete event simulation;robot control;system testing	This paper presents a discrete event simulation approach to the analysis of intelligent robotic systems. These systems require the integration and control of many diverse functions. The simulation model is constructed in SIMAN, and the performance measure is the average time required to complete a task. The model is intended to help balance system design decisions. Future work will focus on methods to use the simulation model to improve operation of the robotic system.	profiling (computer programming);robot;simulation	Pieter A. Voss;Jorge Haddock	1993		10.1109/WSC.1993.718404	control engineering;simulation;computer science;engineering;artificial intelligence;technical report;discrete event simulation;simulation modeling;control theory;robot control;system testing;intelligent control;systems design	Robotics	-37.139238502368656	22.59857699920695	18243
6d939c749b56121e879140f00ad0d0cbe98fe3ab	continuous architectural knowledge integration: making heterogeneous architectural knowledge available in large-scale organizations	software;semantics;software architecture;cognition;tools;organizations;adaptation models	The timely discovery, sharing and integration of architectural knowledge (AK) have become critical aspects in enabling the software architects to make meaningful conceptual and technical design decisions and trade-offs. In large-scale organizations particular obstacles in making AK available to architects are a heterogeneous pool of internal and external knowledge sources, poor interoperability between AK management tools and limited support of computational AK reasoning. Therefore we introduce the Continuous Architectural Knowledge Integration (CAKI) approach that combines the continuous integration of internal and external AK sources together with enhanced semantic reasoning and personalization capabilities dedicated to large organizations. Preliminary evaluation results show that CAKI potentially reduces AK search effort by concurrently yielding more diverse and relevant results.	application domain;continuous integration;interoperability;knowledge integration;personalization;software architect	Jürgen Musil;Fajar J. Ekaputra;Marta Sabou;Tudor B. Ionescu;Daniel Schall;Angelika Musil;Stefan Biffl	2017	2017 IEEE International Conference on Software Architecture (ICSA)	10.1109/ICSA.2017.28	computer science;systems engineering;knowledge management;management science	DB	-60.66437701602708	19.53611924903325	18265
ccef07a4b725478d900d63c2959c0b8a5f157cfb	formal verification of composite service recovery mechanisms consistency	formal verification web services calculus web and internet services context aware services collaboration cascading style sheets service oriented architecture protocols context modeling;reliability;event calculus;formal model;event calculus formal verification service recovery mechanisms consistency web services transactional flow;web service;program verification;service recovery mechanisms consistency;service recovery;formal verification;calculus;business;web services;control flow;abortion;process control;ontologies;web services program verification;transactional flow	Due to the inherent autonomy and heterogeneity of Web services, ensuring composite services reliability remains a challenging problem. Extending the classical control flow with a transactional flow (encapsulating a set of recovery mechanisms) is widely accepted for ensuring composite services reliability. However, current approaches define recovery mechanisms in and ad-hoc way while they have to respect consistency rules regarding the control flow. In this paper, we propose a formal model based on event calculus for capturing both control and transactional flow of composite services. Following a pattern based modelling approach, we depict a set of rules characterising consistent transactional flow that can be defined w.r.t a given control flow. In addition, we propose two complementary approaches for enhancing composite services reliability.	cascading style sheets;control flow;event calculus;formal verification;hoc (programming language);mathematical model;service composability principle;service-oriented modeling;transaction processing;web service	Walid Gaaloul;Sami Bhiri;Manfred Hauswirth;Mohsen Rouached;Claude Godart	2007	2007 International Conference on Collaborative Computing: Networking, Applications and Worksharing (CollaborateCom 2007)	10.1109/COLCOM.2007.4553842	web service;computer science;process control;database;distributed computing;programming language;law	DB	-45.90661753119294	18.42702116485691	18278
8393ded06888e9386afea675e7aa38f82ccbeb63	incremental load in a data warehousing environment	etl metadata;metadata model;incremental load;data warehousing;observation timestamp;data warehouse;delta load	Incremental load is an important factor for successful data warehousing. Lack of standardized incremental refresh methodologies can lead to poor analytical results, which can be unacceptable to an organization's analytical community. Successful data warehouse implementation depends on consistent metadata as well as incremental data load techniques. If consistent load timestamps are maintained and efficient transformation algorithms are used, it is possible to refresh databases with complete accuracy and with little or no manual checking. This paper proposes an Extract-Transform-Load ETL metadata model that archives load observation timestamps and other useful load parameters. The author also recommends algorithms and techniques for incremental refreshes that enable table loading while ensuring data consistency, integrity, and improving load performance. In addition to significantly improving quality in incremental load techniques, these methods will save a substantial amount of data warehouse systems resources.		Nayem Rahman	2010	IJIIT	10.4018/jiit.2010070101	metadata modeling;computer science;data warehouse;data mining;database;world wide web	DB	-34.098190545901694	16.094841643106538	18282
e78deebda09c4c836eb2f8ad2a8476a975195ede	an object model for product and workflow data management	production lifecycle;control systems;groupware;workflow management;object oriented programming cad cam product development groupware;collaborative work;design engineering;design engineers;electrical equipment industry control systems collaborative work industrial control data engineering design engineering engineering management product design workflow management software production systems;data management;object oriented programming;data engineering;product data management;electrical equipment industry;data model;cad cam collaborative design;large scale;product designs;large scale high energy physics detectors object model workflow data management product data management design engineers product data management systems product designs collaborative design level cad cam collaborative design data model production lifecycle;high energy physics;large scale high energy physics detectors;engineering management;cad cam;industrial control;particle physics;workflow management software;production systems;workflow management system;product design;collaborative design;collaborative design level;workflow data management;industrial design;product data management systems;object model;product development	In industry design engineers have traditionally employed Product Data Management Systems to coordinate and control access to documented versions of product designs. However, these systems provide control only at the collaborative design level and are seldom used beyond design. Workflow management systems, on the other hand, are employed in industry to coordinate and support the more complex and repeatable work processes of the production environment. The integration of Product Data Management with Workflow Management can provide support for product development from initial CAD/CAM collaborative design through to the support and optimisation of production workflow activities. This paper investigates this integration and proposes a data model for the support of product data throughout the full development and production lifecycle and demonstrates its usefulness in the construction of large scale high energy physics detectors at the European Particle Physics laboratory at CERN.	access control;computer-aided design;data model;deployment environment;management system;mathematical optimization;new product development;sensor	Nigel Baker;Alain Bazan;G. Chevenier;Florida Estrella;Zsolt Kovacs;T. Le Flour;Jean-Marie Le Goff;S. Lieunard;Richard McClatchey;Steve Murray;Jean-Pierre Vialle	1998		10.1109/DEXA.1998.707489	workflow;industrial design;object model;data model;data management;computer science;knowledge management;product lifecycle;product design specification;design review;applied engineering;database;production system;product design;object-oriented programming;workflow management system;new product development;workflow engine;computer-aided technologies;product engineering;workflow technology	DB	-50.80656957324675	18.939011320475245	18289
0d3f14a0bf03778ddbc565373b50f886ee45421f	top-level ideas about importing, translating and exporting knowledge via an ontology of representation languages	ontology of krls;knowledge representation languages krls;language technologies;knowledge integration	This article introduces KRLO, an ontology of knowledge representation languages (KRLs), the first to represent KRL abstract models in a uniform way and the first to represent KRL notations, i.e., concrete models. Thus, KRLO can help design tools handling many KRLs and letting their end-users design or adapt KRLs. KRLO also represent KRL import, translation and export methods in a declarative way, both via Datalog like rules and pure functions.	datalog;krl;knowledge representation and reasoning;ontology (information science);unified framework;xml	Philippe Martin;Jérémy Bénard	2016		10.1145/2993318.2993344	natural language processing;computer science;knowledge management;data mining	AI	-37.160320318039396	7.648252330694657	18292
98d249508333c4fb08fc10e2564410109152e29d	comparison of ontology reasoning systems using custom rules	custom rules;inference rule;support system;ontology reasoning system;question answering system;semantic web;ontology;knowledge base	"""In the semantic web, content is tagged with """"meaning"""" or """"semantics"""" that allows for machine processing when implementing systems that search the web. General question/answer systems that are built on top of reasoning and inference face a number of difficult issues. In this paper we analyze scalability issues in the context of a question/answer system (called ScienceWeb) in the domain of a knowledge base of science information that has been harvested from the web. In ScienceWeb we will be able to answer questions that contain qualitative descriptors such as """"groundbreaking"""", """"top researcher"""", and """"tenurable at university x"""". ScienceWeb is being built using ontologies, reasoning systems and custom based rules for the reasoning system. In this paper we address the scalability issue for a variety of supporting systems for ontologies and reasoning. In particular, we study the impact of using custom inference rules that are needed when processing queries in ScienceWeb."""	computation;customer relationship management;knowledge base;ontology (information science);reasoning system;scalability;semantic web;web search engine	Hui Shi;Kurt Maly;Steven J. Zeil;Mohammad Zubair	2011		10.1145/1988688.1988708	knowledge representation and reasoning;computer science;knowledge management;model-based reasoning;data mining;database;reasoning system	AI	-40.258715584249344	6.775070717144296	18401
fa601ac743d331fa052174112650178d7651df71	the axiomatisation of socio-economic principles for self-organising systems	norms self organisation socio economics;self organisation;action language;reasoning about action;executable specification;sociologically inspired computing socio economic principles axiomatisation self organising systems resource constrained systems open systems embedded systems ad hoc networks sensor networks opportunistic networks decentralised control decision making pool resource management problem ostrom socio economic principles event calculus;resource allocation;temporal logic;self adjusting systems;satisfiability;artificial intelligent;resource management calculus monitoring ad hoc networks water resources security decision making;embedded systems;decentralised control;necessary and sufficient condition;temporal logic decentralised control decision making embedded systems resource allocation self adjusting systems socio economic effects;norms;collective decision making;socio economics;socio economic effects;common pool resource	We are interested in engineering for open, embedded and resource-constrained systems, which have applications in ad hoc, sensor and opportunistic networks. In such systems, there is decentralised control, competition for resources and an expectation of both intentional and unintentional errors. The 'optimal' distribution of resources is then less important than the 'robustness' or 'survivability' of the distribution mechanism, based on collective decision-making and tolerance of unintentional errors. We therefore seek to model resource allocation in the network as a common pool resource management problem, and apply a formal characterisation of Ostrom's socio-economic principles for building enduring institutions. This paper presents a complete axiomatisation in the Event Calculus of six of Ostrom's eight principles, describes a preliminary testbed for experimenting with the axiomatisation, and considers the work from a methodological perspective of sociologically-inspired computing for self-organising systems.	action language;axiomatic system;cloud computing;embedded system;event calculus;experiment;formal system;hoc (programming language);robustness (computer science);self-awareness;self-organization;sociotechnical system;testbed	Jeremy V. Pitt;Julia Schaumeier;Alexander Artikis	2011	2011 IEEE Fifth International Conference on Self-Adaptive and Self-Organizing Systems	10.1109/SASO.2011.25	group decision-making;common-pool resource;temporal logic;resource allocation;action language;computer science;knowledge management;artificial intelligence;management science;norm;satisfiability	Embedded	-40.098059956716014	19.625219899791873	18472
a2704b83c4f42bc42a94f30786701ff7730746b3	a layered architecture for flexible web service invocation	process execution;web service;single web service;web service compatibility;compatible web service;complex web service;individual web service;substitutable web service;business process;intra-organizational business process;flexible web service invocation;layered architecture	service publication can be done by saving into the vispo Registry a tModel which refers to the WSDL abstract description of the service. The tModel is characterized by a categoryBag with a keyedReference in which the keyValue element contains the name of the compatibility class defined by the published abstract service. Once the abstract service is published, the descriptor is automatically created while the vispo Registry is in charge of checking out that every new abstract service defines a new compatibility class. It is not allowed having more than one abstract service for a compatibility class. The registry analyzes the published contents and, if inconsistencies are detected, notifies the abstract service publisher. Concrete service publication requires to register a tModel, which refers to the complete WSDL description including the binding information and specifies the compatibility classes in which the concrete service is inserted. The tModel is characterized by a categoryBag with a series of keyedReference, each of them defining a compatibility class to which the concrete service belongs. The value of the compatibility class is inserted into the keyValue element and the vispo Registry is in charge of checking that every defined keyValue refers to an existing compatibility class. If that don’t happen, the registry notifies the concrete service publisher. When a concrete services is published, descriptor and mapping information are generated. While the descriptor generation is performed by the registry itself, the generation of mapping information is performed by the Compatible Service Provider. Given a published concrete service, the vispo Registry passes it to the Compatible Service Provider, which is in charge of evaluating its compatibility with respect to the abstract services of the compatibility classes in which it was inserted and generating the mapping information. The Compatible Service Provider is deeply described in the next section. However, in order to avoid wrong publications and create homogeneous compatibility classes, the domain expert must check the submitted keyValue values and the generated information for verifying that the concrete service is really suitable to be included in the specified compatibility classes. 3.2.2. Compatible Service Provider Given a set of services, the Compatible Service Provider (CSP) is able to evaluate their compatibility with respect to a reference service and generate the correspondent mapping information. Once the mapping information has been generated, it is saved into a dedicated registry and can be accessed by the CSP for retrieving useful information about service compatibility. In the vispo system, the CSP is used during the publication and invocation phases. In the first phase, it is used by the vispo Registry for evaluating the affinity of the published concrete service with respect to the abstract services that define the compatibility classes in which the service is published. In the latter, the Invocator uses the CSP for retrieving the compatibility Copyright c © 0 John Wiley & Sons, Ltd. Softw. Pract. Exper. 0; 0:1–0 Prepared using speauth.cls A LAYERED ARCHITECTURE FOR FLEXIBLE WEB SERVICE INVOCATION 17 Compatibility Module VISPO Registry Service Research Module Compatibility Evaluation Module	affinity analysis;data descriptor;john d. wiley;subject-matter expert;verification and validation;web services description language;web service	Valeria De Antonellis;Michele Melchiori;Luca De Santis;Massimo Mecella;Enrico Mussi;Barbara Pernici;Pierluigi Plebani	2006	Softw., Pract. Exper.	10.1002/spe.696	web service;web application security;web development;web modeling;business process execution language;data web;web-based simulation;web design;web standards;computer science;operating system;ws-policy;service-oriented architecture;web navigation;ws-addressing;database;multimedia;services computing;ws-i basic profile;web 2.0;world wide web;mashup	Logic	-42.66538264329303	12.935812731636187	18499
1a194f0a000215425abf24520ba6198d2db513f5	a visual language should be easy to use: a step forward for xml-gl	query language;computacion informatica;graphical query language;graphs;query languages;expressive power;ciencias basicas y experimentales;recursion;visual language;xml;semantic web;xml document;transitive closure;grupo a;www	XML is spreading out as a standard for semistructured documents on the Web, so the possibility of querying XML documents which are linked by XML links is becoming a goal to achieve. In this paper we present XML-GLrec, an extended version of the graphical query language for XML documents XML-GL. XML-GL allows to extract and restructure information from XML specified WWW documents. We extend XML-GL in the following directions: (i) XML-GLrec allows to represent XML simple finks, so that it is possible to query whole XML specified WWW sites in a simple and intuitive way; (ii) XML-GLrec improves the expressive power of XML-GL, where only transitive closure can be expressed, by allowing generic recursion; (iii) finally, we permit the user to specify queries in an easier fashion, by allowing sequences of nested query, in the same way as in SQL.	visual language;xml schema	Barbara Oliboni;Letizia Tanca	2002	Inf. Syst.	10.1016/S0306-4379(02)00007-8	xml catalog;xml validation;xml encryption;regular language description for xml;simple api for xml;xml;relax ng;streaming xml;computer science;document type definition;document structure description;xml framework;data mining;xml database;xml schema;database;xml signature;programming language;world wide web;xml schema editor;cxml;query language;efficient xml interchange;sgml	DB	-34.63522972914308	7.402014908847502	18567
5decfa98820703e3f6db6808bd8c37d2dd321574	a unified framework for application integration - an ontology-driven service-oriented approach	service orientation;application integration	The crucial problem of Enterprise Application Integration (EAI) is the semantic integration problem. This latter is not correctly addressed by today's EAI solutions that focus mainly on the technical and syntactical integration. Addressing the semantic aspect will promote EAI by providing it more consistency and robustness. Some efforts are suggested to solve the semantic problem, but they are still not mature. This article will propose an approach that combines both ontologies and web services in order to overcome some issues related to the semantic integration problem.	enterprise application integration;enterprise software;ontology (information science);prototype;semantic integration;service-oriented device architecture;web service;web services protocol stack	Saïd Izza;Lucien Vincent;Patrick Burlat	2005			semantic integration;computer science;knowledge management;artificial intelligence;data science;data mining;database;ontology-based data integration	Web+IR	-43.7992244940863	8.506014598900313	18593
f6d9ad50cf5ea637dcad7315a6b9106b5822aae8	etude comparative des systèmes de bases de données à base ontologiques		Nowadays, domain ontologies are largely advocated by industrial and academic communities. This adoption gives raise to new needs for managing large amounts of ontological instances. Several ontological formalisms were proposed. Persistency solutions were developed for storing these instances in DBMS. Note that each DBMS has its own architecture and storage model for instances and ontologies. In this paper, we first present a state of art on ontologies, their formalisms, storage models and architectures of their target DBMS. Secondly, a formalisation of ontologies and ontology-based databases is given. An experimental study using Lehigh University BenchMark is conducted to prove three DBMS: two from industrial community (Oracle and IBM SOR) and one from academic research laboratory (LIAS-ENSMA). MOTS-CLÉS : Ontologies, BDBO, Web sémantique, évaluation des performances	database;experiment;flexos;ontology (information science);performance;storage model;triple des;world wide web	Bery Leouro Mbaiossoum;Selma Khouri;Ladjel Bellatreche;Stéphane Jean;Mickaël Baron	2012				DB	-38.862612496407735	7.726464220405579	18604
b1a3f4ebe793f75ccfda4ba4412dd602e44188c2	a technique for integrating simulation and system design	abstract design;system modeling language;elaborated system;simulation model;incomplete system;integrated simulation;valid simulation model;integrated simulation method;ppml system;system design;contention;input output;cpu;process model;design process;design method;system modeling;top down	A technique for simulating incomplete systems is given which allows performance prediction during system design. This technique, called integrated simulation, allows the system design to itself be a simulation model, thus avoiding the overhead of maintaining a separate, valid simulation model for the system. The paper presents integrated simulation in the framework of a system modeling language called the Program Process Modeling Language, PPML. This language provides a means for describing systems of concurrent processes in both abstract and explicit terms, thus lending itself well to a top-down design method. In the design process, any PPML representation of the system can be simulated directly, from the most abstract design to the completely elaborated system. Simulation of the completely elaborated system is, in fact, simply the system in execution. The paper defines PPML and describes the techniques required to simulate PPML systems given various underlying machines. It concludes with a discussion of the limitations of the integrated simulation method.	simulation;systems design	John Sanguinetti	1979	SIGMETRICS Performance Evaluation Review	10.1145/1009373.805457	input/output;real-time computing;simulation;systems modeling;design process;design methods;computer science;theoretical computer science;operating system;central processing unit;simulation modeling;top-down and bottom-up design;process modeling;systems design	EDA	-36.06785351056487	30.054026614235525	18690
12e140ef42b4ecca683db45e7c71e280707427c1	composition and inversion of schema mappings	data exchange;schema mapping	A schema mapping is a specification that describes how data from a source schema is to be mapped to a target schema. Schema mappings have proved to be essential for data-interoperability tasks such as data exchange and data integration. The research on this area has mainly focused on performing these tasks. However, as Bernstein pointed out [7], many information-system problems involve not only the design and integration of complex application artifacts, but also their subsequent manipulati on. Driven by this consideration, Bernstein proposed in [7] a general framework for managing schema mappings. In this framework, mappings are usually specified in a logical language, and high-level algebraic operators are used to manipulate them [7, 17, 34, 13, 8]. Two of the most fundamental operators in this framework are thecompositionand inversionof schema mappings. Intuitively, the composition can be described as follows. Given a mappingM1 from a schemaA to a schemaB, and a mappingM2 fromB to a schemaE, the compositionof M1 andM2 is a new mapping that describes the relationship between schemas A andE. This new mapping must be semantically consistent with the relationships previously established by M1 andM2. On the other hand, an inverseof M1 is a new mapping that describes thereverserelationship fromB toA, and is semantically consistent withM1. In practical scenarios, the composition and inversion of schema mappings can have several applications. In a data exchange context [14], if a mapping M is used to exchange data from a source to a target schema, an inverse ofM can be used to exchange the data back to the source, thusreversingthe application ofM. As a second application, consider a peer-data management system (PDMS) [10, 25]. In a PDMS, a peer can act as a data source, a mediator, or both, and the system relates peers	database schema;high- and low-level;interoperability;matchware mediator;pdms;phil bernstein;schema (genetic algorithms);xml schema	Marcelo Arenas;Jorge Pérez;Juan L. Reutter;Cristian Riveros	2009	SIGMOD Record	10.1145/1815933.1815938	data exchange;computer science;theoretical computer science;star schema;database;algorithm	DB	-33.779296156329245	11.538857619980202	18704
2f179b8da70e1fb13afdc9d66338e0f672147839	characteristics of document similarity measures for compliance analysis	text mining;performance comparison;type of service;latent semantic indexing;contract template retrieval;reusable component;compliance analysis;document similarity;cosine similarity;service delivery	Due to increased competition in the IT Services business, improving quality, reducing costs and shortening schedules has become extremely important. A key strategy being adopted for achieving these goals is the use of an asset-based approach to service delivery, where standard reusable components developed by domain experts are minimally modified for each customer instead of creating custom solutions. One example of this approach is the use of contract templates, one for each type of service offered. A compliance checking system that measures how well actual contracts adhere to standard templates is critical for ensuring the success of such an approach. This paper describes the use of document similarity measures - Cosine similarity and Latent Semantic Indexing - to identify the top candidate templates on which a more detailed (and expensive) compliance analysis can be performed. Comparison of results of using the different methods are presented.	cosine similarity;design by contract;itil;type of service	Asad B. Sayeed;Soumitra Sarkar;Yu Deng;Rafah Hosn;Ruchi Mahindru;Nithya Rajamani	2009		10.1145/1645953.1646106	natural language processing;text mining;latent semantic indexing;computer science;service delivery framework;type of service;data mining;database;world wide web;vector space model;information retrieval	Web+IR	-47.77447496306495	15.488608654722098	18807
5d9acd8cae49ea9d26ac0370b0cbab8083877f7b	using datalog data model and data mining to solve bill of materials personalization problems	ecommerce;databases;electronic commerce;ebusiness;data models data mining bills of materials portals internet search engines information retrieval turning uniform resource locators transaction databases;data mining;complex transaction management datalog data model data mining bill of materials personalization problems portals;relational databases data mining internet datalog electronic commerce invoicing;data model;datalog;internet;invoicing;relational databases;synthetic data;work in progress;bill of material	This Work In Progress (WIP) refers to personalization issues in the design of portals that manage complex transactions that comes with the Bill Of Material (BOM) problem. Three tools are briejl) described. The work is in the very beginning, and we have few experiments with synthetic data.	browser object model;data mining;data model;datalog;experiment;personalization;portals;synthetic data	Alberto Sulaiman	1999		10.1109/WECWIS.1999.788196	computer science;data mining;database;world wide web	DB	-38.54031821879914	9.923603036520449	18867
56fd5505bb4316e95c28a8895ad9fac3984e6f2d	automatic synthesis of sdl models in use case methodology	executable specification;formal model;software development process;specification and description language;requirement analysis;message sequence chart;system design;system analysis;use case	Formal description techniques (FDT’s) supported by computer-aided software engineering (CASE) tools are rapidly evolving as a response to the new challenges of the telecommunications industry, especially the need to improve “ time-to-market ” of software products. In this paper we summarize our experience in using automatic synthesis of formal models in ITU-T standard Specification and Description Language (SDL) to speed-up the software development process. Suggested accelerated methodology requires formalization of functional scenarios (use cases) using another ITU-T standard Message Sequence Charts (MSC) extended with data operations . Our Moscow Synthesizer Tool (MOST-SDL) provides a bridge from MSC models to SDL executable specifications which can be simulated using SDL tools to provide an early feedback for the phases of requirements analysis, system analysis or system design. We present our synthesis algorithm, provide comparison with related work and discuss the results of a few case studies where the Moscow Synthesizer Tool was used together with Telelogic SDL tools for an accelerated MSC-based prototyping which involved incremental synthesis, validation and simulation of the formal model.	algorithm;automatic control;computer-aided software engineering;executable;formal methods;mathematical model;message sequence chart;powerflasher fdt;requirement;requirements analysis;simulation;software development process;specification and description language;system analysis;systems design	Nikolai Mansurov;D. Zhukov	1999		10.1016/B978-044450228-5/50016-3	reliability engineering;computer science;systems engineering;software engineering	SE	-47.472725881555334	30.499574028885363	18870
4983c98b35160c9edc8be91193c615c8bbcf1b32	advancing generic metamodels	specialised languages;dsls;virtual classes;generic types;class nesting;software development;metamodelling;domain specific language	Domain-Specific Languages (DSLs) allow modelling concerns at a high abstraction level. This simplifies the modelling process and ensures that non-technical stakeholders can be more closely involved in software development. However, increasing the abstraction level causes details of the problem domain to be excluded from the problem space. In some situations, this may render a DSL useless since required details can not be captured by the language. In this paper we explore how generic metamodels can be parameterised to model additional details and thereby increase the reuse value of DSLs.	abstraction layer;digital subscriber line;domain-specific language;metamodeling;personalization;problem domain;programming language;software development;type class	Henning Berg;Birger Møller-Pedersen;Stein Krogdahl	2011		10.1145/2095050.2095055	simulation;computer science;domain-specific language;software development;software engineering;programming language	SE	-48.448818465165765	25.40675606225614	18894
2e10418ba858cb1f4827fb51e6e582d3cdf5072f	specifying services using the service oriented architecture modeling language (soaml) - a baseline for specification of cloud-based services		The Service oriented architecture Modeling Language (SoaML) is a new specification from the Object Management Group (OMG) that provides support for modelling services. The SoaML specification defines three different approaches to specifying services; simple interfaces, service interfaces and service contracts. In this paper we provide an overview of the SoaML language constructs and discuss the three different ways to specify services. Furthermore, we provide practical modelling guidelines for how the different SoaML service specification approaches can be aligned and used as a baseline for specifying cloud-based services.	align (company);baseline (configuration management);business process model and notation;cloud computing;legacy system;model-driven architecture;modeling language;sms language;service-oriented device architecture;service-oriented modeling;soaml;software engineering	Brian Elvesæter;Arne-Jørgen Berre;Andrey Sadovykh	2011			database;world wide web	SE	-48.41700186075622	17.225022443305374	18934
107822953ba138d6376ec46e2376a8a4f2bd8b86	the dfx shell: a generic framework for applying 'design for x' (dfx) tools	article	The 'Design for X' (DFX) shell is a generic platform which can be easily extended or tailored to develop a variety of DFX tools quickly and consistently. Resulting DFX tools share a high degree of commonality and consistence essential for rapid implementation, integration and trade-off analysis. The aim of this paper is to demonstrate how DFX tools basically work through a general procedure. Seven steps are involved, each corresponding to a major DFX function and addressing associated important issues. This DFX procedure is then placed in a wider context of Business Process Reengineering (BPR) to maximize its effectiveness in transforming product development from a problem-prone sequential engineering environment to a problem-free concurrent engineering environment.	visual effects	George Q. Huang;Kai-Ling Mak	1998	Int. J. Computer Integrated Manufacturing	10.1080/095119298130516	computer science;systems engineering;engineering;operations management;engineering drawing	EDA	-59.749201613083144	11.597195798550684	18965
fc6d543b3053cb331e0dc48e6dc406707d460ed6	ontology-driven association rules extraction: a case of study	association rule	This paper proposes an integrated framework for extracting Constraint-based Multi-level Association Rules with an ontology support. The system permits the definition of a set of domain-specific constraints on a specific domain ontology, and to query the ontology for filtering the instances used in the association rule mining process. This method can improve the quality of the extracted associations rules in terms of relevance and understandability.	algorithm;association rule learning;extensibility;ontology (information science);relevance	Andrea Bellandi;Barbara Furletti;Valerio Grossi;Andrea Romei	2007			artificial intelligence;natural language processing;geometry;stacking;lagging;computer science	DB	-39.52193732883503	5.471605365659941	18968
8be0786852712c5f5de49332bdae921a4c7fc77f	designing real-time and distributed applications with the uml (tutorial session)	distributed application;object oriented model;application software;uml;real time;collaboration;software engineering;permission;object oriented;unified modeling language;performance analysis;object oriented analysis and design;software design;unified modeling language object oriented modeling application software design methodology software design real time systems permission performance analysis collaboration software engineering;object oriented modeling;real time systems;design methodology	Object-oriented concepts are crucial in software design because they address fundamental issues of adaptation and evolution. With the proliferation of object-oriented notations and methods, the Unified Modeling Language (UML) has emerged to provide a standardized notation for describing object-oriented models. However, for the UML notation to be effectively applied, it needs to be used with an object-oriented analysis and design method. This tutorial describes the COMET method for designing real-time and distributed applications, which integrates OO and concurrency concepts and uses the UML notation.	concurrency (computer science);distributed computing;real-time clock;real-time transcription;software design;unified modeling language	Hassan Gomaa	2000		10.1145/337180.337855	unified modeling language;uml tool;computer science;systems engineering;software engineering;applications of uml;programming language;node;object constraint language	PL	-49.31988291343262	30.580534483295402	18990
e1634b68d574b3e6f54cc1ef780d62e214b1a89f	bpel'n'aspects&compensation: adapted service orchestration logic and its compensation using aspects	web service;control flow;workflow management system;business process	One of the main weaknesses of workflow management systems is their inflexibility regarding process changes. To address this drawback in our work on the BPEL’n’Aspects approach we developed a standards-based mechanism to adapt the control flow of BPEL processes [1]. It uses AOP techniques to non-intrusively weave Web service invocations in terms of aspects into BPEL processes. Aspects can be inserted before, instead or after BPEL elements and that way adaptation of running processes is enabled. In this work we want to present a novel extension of the BPEL’n’Aspects prototype that deals with the compensation of weaved-in aspects in a straightforward manner. The extension enormously improves the applicability of the approach in real-world scenarios: processes in production need the means to compensate behavior that was inserted into the process in the course of adaptation steps. The ability to compensate weaved-in aspects distinguishes our approach from other existing concepts that introduce AOP techniques to business processes.	business process execution language;control flow;orchestration (computing);process (computing);prototype;web service	Mirko Sonntag;Dimka Karastoyanova	2010		10.1007/978-3-642-17358-5_73	web service;computer science;knowledge management;database;business process;control flow;management;law;workflow management system;workflow engine;workflow technology	SE	-54.665651407915334	18.5860454272838	19007
32bc2f93b82e746eb8c04dae71f6bce1497dfbd5	testing communication protocols	verification;generation;lotos specifications;protocols;formal specification;communication protocols testing;parametrization communication protocols testing common intermediate model lotos specifications ttcn test finite state machines conformance testing cim generation verification selection;selection;cim;parametrization;protocols open systems reliability engineering design engineering automatic testing software testing specification languages writing formal languages tree data structures;finite state machines;conformance testing;extended finite state machine;protocols conformance testing formal specification;communication protocol;ttcn test;common intermediate model	The authors describe a unifying, common intermediate model that lets Lotos specifications and TTCN test suites be translated into extended finite-state machines, providing a single medium for conformance testing. The paper covers specifying a protocol in Lotos, specifying test suites in TTCN, translating specifications to CIM, and the generation, verification, selection, parametrization, and execution of tests.<<ETX>>	computer-integrated manufacturing;conformance testing;finite-state machine;language of temporal ordering specification	Sagar Naik;Behçet Sarikaya	1992	IEEE Software	10.1109/52.108777	reliability engineering;communications protocol;computer science;software engineering;finite-state machine;programming language	SE	-46.58044612609818	30.612063858678834	19042
436a247c2dcd584bea1597a60fa587e09784d377	deriving business process data architecturesfrom process model collections		The focus in BPM shifts from single processes to process interactions. Business process architectures were established as convenient way to model and analyze such interactions on an abstract level focusing on message and trigger relations. Shared data objects are often a means of interrelating processes. In this paper, we extract hidden data dependencies between processes from process models with data annotations and their object life cycles. This information is used to construct a business process architecture, thus enabling analysis with existing methods. We describe and validate our approach on an extract from a case study that demonstrates its applicability to real world use cases.	business process;conformance testing;control flow;data architect;data architecture;data dependency;design structure matrix;directed acyclic graph;interaction;interdependence;lambda lifting;oracle bpa suite;process architecture;process modeling;tracing (software)	Rami-Habib Eid-Sabbagh;Marcin Hewelt;Andreas Meyer;Mathias Weske	2013		10.1007/978-3-642-45005-1_43	computer science;artifact-centric business process model;process modeling;data mining;database;business process model and notation;process mining;business process discovery;business process modeling	SE	-53.45337976626139	17.960740000164446	19049
190d6503d960d66572b08643829b28222ef67c18	from custom applications to domain-specific frameworks	tecnologia electronica telecomunicaciones;computacion informatica;grupo de excelencia;ciencias basicas y experimentales;tecnologias;domain specificity		domain-specific language	Wim Codenie;Koen De Hondt;Patrick Steyaert;Arlette Vercammen	1997	Commun. ACM	10.1145/262793.262807	programming language;domain specificity;computer science	Graphics	-48.0445537912019	22.421536613397727	19050
6fc0b8ea1ea936d3c5f6026a6f79dc93955c0a34	formal software engineering	software engineering	This project concerned refinement techniques for formal software engineering. Our focus was on extending and developing a more formal approach to work of Jackson and Zave on the relationship between requirements and specifications [JZ92, JZ95, ZJ97]. Our primary contribution on this project was to derive a 'reference model' for software engineering based on five artifacts: domain knowledge, (user) requirements, (software) specifications, program, and programming platform. These artifacts are related to each other based on phenomena classified according to visibility and control. Domain knowledge and requirements are viewed as descriptions of the environment; program and programming platform are descriptions of the system. These four artifacts are related by the software specification, which is expressed in terms of the shared phenomena of the environment and system. The basic conditions are described in [GGJZ98]. This work represents the theory in higher order logic and introduces a new condition for refinement relating the five artifacts. Our condition addresses shortcomings of the Functional Documentation model [vSPM92, PM95] (sometimes called the 'four variables' model). We exercised the model and associated refinement methodology in a study [BGG+98] with Karthikeyan Bhargavan and Davor Obradovic of a benchmark problem called the Village Telephone System (VTS). VTS is a multiparty communication problem similar to a chat room, in which a request for communication by a user requires a best effort from the system to find a suitable partner. The problem is somewhat more interesting than Plain Old Telephone Service (POTS) because there is a wider range of approaches to a solution (for example, broadcast, anycast, hunting, and hotlines). We investigated a refinement based on anycast using I-IOL and SML and a refinement based on broadcast using HOL and Mocha.	anycast;artifact (software development);benchmark (computing);best-effort delivery;chat room;documentation;formal specification;hol (proof assistant);jackson;mocha;pots codec;reference model;refinement (computing);requirement;software engineering;vehicle tracking system	Carl A. Gunter;Elsa L. Gunter;Pamela Zave	2000	ACM SIGSOFT Software Engineering Notes	10.1145/340855.340951	personal software process;verification and validation;software engineering process group;software verification;computer science;social software engineering;component-based software engineering;software development;civil engineering software;software engineering;software construction;software walkthrough;resource-oriented architecture;software measurement;software deployment;software requirements;software system;computer engineering	SE	-52.51230133921633	24.39549982964891	19059
ae3d0ce1e6d570a3b5d619429f861c622613aa0b	a new perspective on formal testing method for real-time software	time dependent;temporal logic;real time;program verification program testing real time systems temporal logic petri nets;program verification;software testing petri nets logic testing application software computer science mathematical model software design mathematics real time systems concurrent computing;software requirements;test suites formal testing method real time software real time applications testing activities formal testing strategy dual language approach software requirements temporal properties descriptive formalism abstract semantics temporal logic formulae timed petri nets operational formalism test case generation test oracle generation timed test cases;time petri net;program testing;test methods;temporal properties;petri nets;real time application;test oracle;real time systems	The time dependent and asynchronous nature of many real time applications adds a new and potentially difficult element to the testing activities, which needs to be solved. To address this need, we present a formal testing strategy for real time software by using a dual language approach. In our approach, we start out with the derivation of real time software requirements in temporal logic form as our basis of descriptive formalism. Then we present an abstract semantics to correlate the temporal logic formulae with the timed Petri nets of the software, which is the operational formalism, and is used to generate the test cases. Based on the temporal properties of the software requirements, the descriptive formalism provides rich information for test oracle generation. By combining the timed test cases with oracles, the firm and definite test suites are formed.	real-time transcription	Jin-Cherng Lin;Ian Ho	2000		10.1109/EURMIC.2000.874428	test data generation;real-time computing;computer science;software construction;software testing;programming language;test case;test management approach;algorithm	SE	-43.18268260750267	31.05673901681396	19109
c2e3f92ba7d5e54d7f5f225cfd62d401373fbb65	a framework to develop web applications based on rfid panels.		The pervasiveness of the Web, and the emergence of new technologies such as the RFID, allow users to interact with the physical environment. This fact has caused the conception of new types of applications, for instance, the Web applications based on RFID panels that allow users to retrieve and store resources from and to the Web through RFID panels. The development of these applications is defined by three main concepts: the Tool that performs domain model functionality, the Command that represents an action to be performed by the tool, and finally, the Resource representing the result of the command on the tool. Thus, this work presents a framework that enables developers to model Web applications based on RFID panels in terms of these concepts.	application domain;artifact (software development);bluetooth;client–server model;compactflash;design pattern;domain model;emergence;extensibility;mobile device;radio-frequency identification;scalability;server (computing);service-oriented architecture;software deployment;web application;world wide web	Pedro González Villanueva;Ricardo Tesoriero;José A. Gallud;Abdulrahman H. Altalhi	2013	J. UCS	10.3217/jucs-019-12-1792	web modeling	Web+IR	-47.59985400404944	21.9064073719856	19133
750f99f78ce639566eb5fc8d34b732fa728c5a31	an integrated approach for developing e-commerce applications	integrated approach;multiagent system;electronic commerce;e commerce;information technology;intelligent agents;intelligent agent;ontologies;business intelligence;natural language processing	This paper presents a framework that merges various advanced information technologies for developing electronic commerce (e-commerce) applications. The use of e-commerce utilities provides several advantages to businesses. Intelligent agents can be used to facilitate some tasks from those that take place in a commercial transaction moving to a second generation of e-commerce applications. We present a prototype which integrates a multiagent system (composed by buyer and seller agents) with a Web application. q 2004 Elsevier Ltd. All rights reserved.	agent-based model;e-commerce;multi-agent system;prototype;web application	Francisco García-Sánchez;Rafael Valencia-García;Rodrigo Martínez-Béjar	2005	Expert Syst. Appl.	10.1016/j.eswa.2004.10.004	computer science;knowledge management;ontology;artificial intelligence;intelligent agent	AI	-50.732069225224436	12.606592598150286	19173
e4c6998565e4010bc54adc596209438d83a39585	support for life cycle decision-making in sustainable manufacturing - results of an industrial case study				Teuvo Uusitalo;Jyri Hanski;Markku Reunanen;Susanna Kunttu	2014		10.1007/978-3-662-44736-9_20	systems engineering;engineering;operations management;manufacturing engineering	Robotics	-61.38944911374987	8.116212192825222	19259
de3de6277ca455d4b795784bcc740ca43e9361b5	contributions to component-based software engineering - composition, reuse and evolution -				Christelle Urtado	2016				SE	-51.39243316772825	26.652846829114683	19296
6332243f8e81d62eb33d4c86d6021b1b01d910cb	research on construction of the virtual dynamic knowledge discovery tree based on ontology reusability	databases;ontology reusability;pediatrics;construction industry;knowledge discovery accuracy rate;software reusability data mining ontologies artificial intelligence;set theory;data mining;ontologies artificial intelligence;knowledge discovery accuracy rate virtual dynamic knowledge discovery tree ontology reusability;knowledge discovery tree;virtual dynamic knowledge discovery tree;accuracy;software reusability;ontologies pediatrics set theory accuracy construction industry databases;attribute weight;ontologies;field ontology knowledge discovery tree ontology reusability attribute weight;field ontology;knowledge discovery	The scope of ontology application is widespread, but even if in the same application field the emphasis points of different applications are different, the ontology which is suitable for some applications, but is not suitable for the other applications, this paper proposes a method of constructing knowledge discovery ontology tree for different applications based on the same ontology, it enhances the knowledge discovery accuracy rate, and enhances the reusability rate of ontology.		Yajie Fei	2010	2010 Seventh International Conference on Fuzzy Systems and Knowledge Discovery	10.1109/FSKD.2010.5569267	upper ontology;ontology alignment;computer science;knowledge management;ontology;data science;data mining;accuracy and precision;knowledge extraction;ontology-based data integration;process ontology;set theory;suggested upper merged ontology	ML	-43.488766131356776	6.3990221286348055	19367
e9b50c5b3d7312b6f0a18b7bbc05a1faefcceafa	semantic web technologies for the adaptive web	semantic web technology;data model;semantic web;web technology;domain ontology;user model	Ontologies and reasoning are the key terms brought into focus by the semantic web community. Formal representation of ontologies in a common data model on the web can be taken as a foundation for adaptive web technologies as well. This chapter describes how ontologies shared on the semantic web provide conceptualization for the links which are a main vehicle to access information on the web. The subject domain ontologies serve as constraints for generating only those links which are relevant for the domain a user is currently interested in. Furthermore, user model ontologies provide additional means for deciding which links to show, annotate, hide, generate, and reorder. The semantic web technologies provide means to formalize the domain ontologies and metadata created from them. The formalization enables reasoning for personalization decisions. This chapter describes which components are crucial to be formalized by the semantic web ontologies for adaptive web. We use examples from an eLearning domain to illustrate the principles which are broadly applicable to any information domain on the web.	conceptualization (information science);data model;global variable;ontology (information science);personalization;semantic web;user modeling	Peter Dolog;Wolfgang Nejdl	2007		10.1007/978-3-540-72079-9_23	web service;web application security;web development;web modeling;user modeling;data web;web mapping;web design;semantic search;semantic grid;data model;web standards;computer science;semantic web;web navigation;social semantic web;data mining;semantic web stack;web intelligence;web 2.0;world wide web;information retrieval;semantic analytics	Web+IR	-42.44570487911877	9.172959773064619	19423
47ff420ba2908b9ae4810d6ea188cac1d0dac4e7	completeness and realizability: conditions for automatic generation of workflows	indexing terms;automatic generation;concurrency;workflow;completeness;semantic correctness	In recent years, workflow technology has greatly facilitated business process modeling and reengineering in information systems. On one hand, the separation of an application’s control structure from the implementation of its task programs simplifies and speeds up application development. On the other hand, the run-time system assists users in coordinating and scheduling tasks of a business process. As a result, the cost of doing business is reduced, and business enterprises become more responsive to new business requirements and opportunities, hence, become more competitive in the market. Several formal methods have been proposed for specifying and modeling workflows. However, most workflows are designed manually, which becomes a time-consuming and error-prone procedure when a workflow involves hundreds or thousands of task programs. A recent approach is to generate workflow automatically from a task library and a specification of the desired outcome. In this paper, we define the notions of positive and negative dependency graphs for a task library to represent the dependencies among tasks in the library. Based on these dependencies, we identified sufficient conditions for a task library to be complete, and the conditions for a workflow postcondition to be realizable from a task library. We also identified a sufficient and necessary condition for the completeness of a class of task libraries, called S-task libraries. Index terms – completeness, workflow, semantic correctness, concurrency.	algorithm;business process;business requirements;code refactoring;cognitive dimensions of notations;concurrency (computer science);control flow;correctness (computer science);formal methods;information system;library (computing);postcondition;process modeling;requirement;runtime system;scheduling (computing)	Shiyong Lu;Arthur J. Bernstein;Philip M. Lewis	2006	Int. J. Found. Comput. Sci.	10.1142/S0129054106003784	workflow;index term;concurrency;completeness;computer science;artifact-centric business process model;theoretical computer science;data mining;database;programming language;workflow management system;workflow engine;workflow technology	DB	-52.06347093406181	19.272717780887767	19453
e9ba9e47f51cdd1de100f2f1e1a142153970603f	workflow management system based on web technology	workflow;workflow management system;workflow engine	Through the analysis of workflow management system based on Web, the work, following WFMC workflow model, proposed a universal workflow management system with the combination of specific application requirements of enterprises. Workflow management system based on Web was described from system function, software structure, system structure, workflow engine and security. The actual case of the design of aeronautical structure showed that workflow system performance can be greatly improved by using Web technology.	requirement;workflow engine;world wide web	Lixia Qi	2017	Cluster Computing	10.1007/s10586-017-0786-7	workflow;xpdl;computer science;knowledge management;workflow management coalition;database;windows workflow foundation;workflow management system;workflow engine;workflow technology	DB	-50.81076338882379	16.353269017688234	19464
2a2cf8580013c5dea9d847e70b6977a10c8f2598	safe simulation testing of systems with refusals and destructions	formal model;model based testing;complete testing;simulation;system with refusals and destructions	This paper deals with conformance testing based on formal specifications. The concept of safe testing was earlier proposed by the authors for trace based conformance. This concept is propagated for the case of (weak) simulation based on a relation between the specification and implementation states. The theory of the safe simulation of systems with refusals and destructions is proposed. The problems of complete testing and sufficient conditions for the existence of a complete test suite are discussed. A practical algorithm of complete testing for restricted classes of specifications and implementations is described.	algorithm;conformance testing;simulation;test suite	Igor B. Bourdonov;Alexander S. Kosachev	2011	Automatic Control and Computer Sciences	10.3103/S0146411611070042	reliability engineering;computer science;systems engineering;conformance testing;algorithm	SE	-33.704077472419456	30.511055827851067	19484
107e92db1ec95cd2bb4971c73b60656345029800	an automatic approach to transform bpmn models to pi-calculus	pi calculus workflow patterns bpmn graph transformation atom3 meta modeling;logic gates;synchronization;atom 3 business process modeling notation bpmn pi calculus workflow pattern transformation model driven engineering mde metamodeling model transformation graph transformation tool;calculus;unified modeling language;software engineering business data processing calculus graph theory;logic gates integrated circuits synchronization unified modeling language calculus;integrated circuits	In order to automate Business Processes Modeling, the last research works in workflow technology have resulted in the identification of a number of models (workflow patterns) that describe the behavior of Business Processes. Like any new trend, the Business Process approach raises many expectations and many positions. BPMN (Business Process Modeling Notation) has been used to describe graphically such patterns. However, BPMN notation lacks verification tools which allow anomalies and errors detection such as deadlock and multiple repetition situations. On the other hand, formal methods, such as Pi-Calculus, have powerful tools for verifying such situations. In this paper, we propose an automatic approach to transform the basic workflow patterns into their equivalent Pi-Calculus code for the analysis purposes. To achieve this goal, we use the Model-Driven Engineering (MDE) approach which is mainly based on Meta-modeling and Model Transformations. The graph transformation tool AToM3 is used. Our approach is illustrated through an example.	business process model and notation;control flow;deadlock;formal methods;formal verification;graph rewriting;lambda calculus;metamodeling;model-driven engineering;model-driven integration;process modeling;structural pattern;verification and validation;workflow pattern;π-calculus	Riad Boussetoua;Hammadi Bennoui;Allaoua Chaoui;Khaled Khalfaoui;Elhillali Kerkouche	2015	2015 IEEE/ACS 12th International Conference of Computer Systems and Applications (AICCSA)	10.1109/AICCSA.2015.7507176	unified modeling language;synchronization;xpdl;logic gate;telecommunications;computer science;theoretical computer science;database;business process model and notation;business process modeling;algorithm	SE	-44.24817633484627	30.009233541079716	19546
34e258489ff54f7979feb311fd6df2d00dafd9c4	specifying privacy requirements with goal-oriented modeling languages		Context: Privacy of personal data is a growing concern regarding users of software systems. In this sense, the literature reports that in order to avoid privacy breaches, there must be systematic approaches to specify privacy requirements from the early activities of software development. Objective: Motivated by this situation, this paper presents a framework of privacy modeling capabilities that must be addressed by requirements modeling languages to better support privacy specification. The capabilities will be used to compare three goal-oriented modeling languages (i*, NFR-Framework and Secure-Tropos). Method: The framework was created with basis on a conceptual foundation and a conceptual model of privacy built from an analysis of a standard, a regulation, guidelines and other bibliographical sources related to privacy. A health care example is used to illustrate how the framework can be used to compare the chosen modeling languages. Results: Fourteen privacy modeling capabilities were defined in the framework and it was observed that the analyzed modeling languages do not fully support them. Conclusions: The proposed framework contributes towards the consolidation of a privacy conceptual foundation that can be used to evaluate modeling languages for privacy in Requirements Engineering. The comparison performed by using this framework indicates Secure-Tropos as the most complete language to model privacy among the analyzed goal-oriented modeling languages.	goal modeling;modeling language;non-functional requirement;personally identifiable information;privacy;requirements analysis;requirements engineering;semiconductor consolidation;software development;software system	Mariana Maia Peixoto;Carla Silva	2018		10.1145/3266237.3266270	modeling language;conceptual model;software system;systems engineering;requirements engineering;goal orientation;software development;computer science	SE	-57.5219700956993	20.182756793412256	19556
90c501685c57b7827708b0d5a5c37cba8dc35c52	acp2p: agent-community-based peer-to-peer information retrieval - an evaluation	busqueda informacion;distributed system;multiagent system;systeme reparti;information re trieval;information retrieval;par a par;interrogation base donnee;multidestinatario;distributed computing;interrogacion base datos;intelligence artificielle;agent communication;sistema repartido;poste a poste;recherche information;comportement utilisateur;calculo repartido;artificial intelligence;inteligencia artificial;user behavior;peer to peer computing;sistema multiagente;peer to peer;information storage and retrieval;calcul reparti;database query;multidestinataire;comportamiento usuario;multicast;systeme multiagent	The Agent-Community-based Peer-to-Peer Information Retrieval (ACP2P) method [1],[2] uses agent communities to manage and look up information of interest to users. An agent works as a delegate of its user and searches for information that the user wants by communicating with other agents. The communication between agents is carried out in a peer-to-peer computing architecture. Retrieving information relevant to a user query is performed with content files which consist of original and retrieved documents, and two histories: a query/retrieved document history and a query/sender agent history. The ACP2P is implemented using the Multi-Agent Kodama framework.#R##N##R##N#In this paper, we present some mathematical aspects of the ACP2P method with respect to the relationships between communication loads and the number of records that are stored both in the two histories and retrieved document content files, and discuss the experimental results, for which illustrate the validity of this approach. The results confirm the mathematical conjectures we presented and show that the two histories are more useful for reducing the communication load than a naive method employing 'multicast' techniques, and lead to a higher retrieval accuracy than the naive method.	information retrieval;peer-to-peer	Tsunenori Mine;Akihiro Kogo;Makoto Amamiya	2005		10.1007/11925941_12	query expansion;computer science;artificial intelligence;database;world wide web	Web+IR	-38.902954410419404	13.671294715801197	19562
d5ecb4b52258532d94a6f542afc80b4ad268aa31	managing the development of manufacturing systems software using a unified framework	supervisory control;flexible manufacturing systems;fms;agile manufacturing;software project management;software development methodology;object oriented method;fmc;manufacturing system;article;quality management	Software has become a principal component in today's agile manufacturing systems. The ability to deliver software that satisfies the original requirements and expectations within budgeted time and cost is one of the major factors in determining the success of the project. While existing software engineering techniques are available for the effective design of complex software systems, much of the effort relies on a designer's experience and intuition. The paper presents a unified framework that aims to quantify software development and to assist engineers to manage the development process in order that not only the quality of the software produced is assured, but also the development process. The application of the framework to the development of supervisory software for a conveyor-based flexible manufacturing cell (FMC) is illustrated.	unified framework	Henry Y. K. Lau;Kai-Ling Mak	2004	IJMTM	10.1504/IJMTM.2004.004505	personal software process;quality management;verification and validation;team software process;software sizing;software project management;systems engineering;engineering;package development process;social software engineering;operations management;software framework;software development;software design description;software construction;supervisory control;systems development life cycle;software walkthrough;empirical process;lean software development;software deployment;goal-driven software development process;software development process;manufacturing engineering;software system;software peer review	Robotics	-62.05177384610515	27.12676882580783	19593
27a0755ee0ee74b322a0481a1bc2616d83f0eca7	a semantic framework for business process modeling based on architecture styles	complexity theory;software architecture business data processing computational complexity;semantic business process;architecture style business process modeling semantic business process;semantics;business process modeling;style based semantic framework business process modeling architecture styles combinational methods business process semantic software architectural concepts;business process model;computer architecture;software architecture;semantics unified modeling language ontologies computer architecture complexity theory organizations;computational complexity;business data processing;unified modeling language;ontologies;organizations;architecture style;business process;architectural style	Business processes perform a significant role in increasing the success of organizational processes and functionalities. Due to the ever increasing growth in the scale and complexity of processes in line with taking advantage of combinational methods and ideas to optimize workflows and gain higher efficiency, lack of a framework considering both business process semantic and structure for business process modeling is completely sensible. Adding semantic to business process models will result in more comprehensible and automatically-executable processes. Moreover, preparing a suitable structure by making use of software architectural concepts will lead to a major decrease in misunderstanding of complexities. In this paper, a style-based semantic framework is represented which improves business processes and their models, and enhances management of them in a semantically and structured way, by this approach business processes will become measurable with respect to different criteria.	business process;combinational logic;executable;ibm basic programming support;interaction;list of system quality attributes;process modeling	Mohammad Ebrahim Khalaj;Shahrouz Moaven;Jafar Habibi;Hamed Ahmadi	2012	2012 IEEE/ACIS 11th International Conference on Computer and Information Science	10.1109/ICIS.2012.16	business domain;business requirements;computer science;systems engineering;knowledge management;artifact-centric business process model;business process management;function model;process modeling;management science;business process model and notation;process management;business system planning;business process;process mining;business process discovery;business rule;new business development;business process modeling;business architecture	Vision	-56.5183505510918	18.224862556433433	19662
6dce00afed27f67b3cfa50c113a9a63114a4bdce	towards the quality evaluation of functional aspects of operative web applications	quality assurance;function point;conceptual model;quality evaluation	The development and maintenance approaches for web applications (WebApps) have often been ad hoc, lacking systematic strategies not only for development but also for quality assurance. One of our current concerns is as- sessing the quality of operative WebApps considering both functional and non- functional (F&NF) requirements. We claim that an operative web application should be assessed not only from the quality perspective of the nonfunctional requirements, but also from a functional viewpoint like informational and navi- gational architecture. In this paper, we specifically discuss how to deal with the functional side, i.e., the re-engineering and evaluation of conceptual models of a WebApp in the maintenance phase using the Web Function Points and Quality Evaluation Methodology (WebFP_QEM).	web application	Silvia Mara Abrahão;Luis Olsina;Oscar Pastor	2002		10.1007/978-3-540-45275-1_29	quality assurance;conceptual model;function point	Web+IR	-60.53431075083028	25.929144995506377	19681
d7c402da2e86f119607c7d43fec0119fc58a43ee	reliability improvement in component-based software development environment	reliability;quality function deployment;qfd;cbsd;component based software development;software reliability;software quality;software qfd	Software quality is becoming increasingly important since software is now used in many demanding applications and also in safety critical systems. Reliable functioning of software systems is paramount concern to millions of users who depend on it every day. Unfortunately most of the systems still fall short of user expectation of reliability. Component-based software development is a new approach based on the idea that software systems can be developed by selecting appropriate off-the-shelf components and then assembling them with well-defined software architecture. In this paper, it is proposed to apply the software quality function deployment technique in a systematic manner to manage the software development process to improve the quality of the component based software by improving its reliability. This approach is applied in ERP software and the results show that software quality function deployment is best suitable for improving the quality of component based software development.	affinity diagram;component-based software engineering;display resolution;erp;enterprise resource planning;integrated development environment;processor affinity;quality function deployment;requirement;software architecture;software deployment;software development process;software quality;software system;usability	K. Vijayalakshmi	2011	IJISCM	10.1504/IJISCM.2011.041510	quality function deployment;personal software process;long-term support;verification and validation;software quality management;software sizing;economics;package development process;backporting;social software engineering;software reliability testing;software development;software construction;software deployment;software quality control;software quality;software metric;software quality analyst;software system;avionics software;software peer review	SE	-61.84022931833687	27.468754198898274	19754
ce2a756deaf676474c2a1b83ec965ea1626d37f1	prototyping a visual formalism for system modelling	formal specification;software systems;system modelling;configuration management	Formal, visual approaches to system modelling are a promising research sub-area of con guration management. A visual notation for con guring software systems, called ConForm [God93], has been designed, formally speci ed in the Z language, and a prototype is currently being implemented. This paper outlines the design of ConForm, and details experience gained in transforming the formal speci cation into a prototype.	formal system;naruto shippuden: clash of ninja revolution 3;prototype;software system	Michael W. Godfrey;Richard C. Holt;Spiros Mancoridis	1994		10.1007/BFb0035817	reliability engineering;computer science;systems engineering;theoretical computer science;software engineering;formal specification;configuration management;software system	Robotics	-51.0012609494856	26.50884429621957	19767
027dda6ce4f16b21bad393dcbbb9e3633891a182	feature oriented refactoring of legacy applications	product lines;refactoring;product line;program synthesis;feature interaction;features;program algebra;feature interactions	Feature oriented refactoring (FOR) is the process of decomposinga program into features, where a feature is an increment in programfunctionality. We develop a theory of FOR that relates code refac-toring to algebraic factoring. Our theory explains relationshipsbetween features and their implementing modules, and why fea-tures in different programs of a product-line can have differentimplementations. We describe a tool and refactoring methodologybased on our theory, and present a validating case study.	apel (emacs);code refactoring;extensibility;fea-m;hans moravec;ibm notes;integer factorization;linear algebra;prevayler;sven jaschan;theory	Jia Liu;Don S. Batory;Christian Lengauer	2006		10.1145/1134285.1134303	reliability engineering;feature;computer science;systems engineering;programming language;code refactoring	SE	-52.81070110409151	30.89294036208612	19790
a5150285e803bb254b256cb9ae10f511097d1720	rationalizing approaches to multi-objective optimization in systems architecture design	complexity theory;architecture frameworks design decision making multiobjective optimization complexity;systems engineering decision making defence industry design optimisation;optimization complexity theory decision making computer architecture algorithm design and analysis modeling;computer architecture;complexity measures multiobjective optimization systems architecture design decision process systems engineering methodologies decision making support naval systems context cost constraints architecture space;optimization;modeling;algorithm design and analysis	The decision process is considered very important in many systems engineering methodologies, and multi-objective optimization is known to be an important tool for decision-making support. However, there is still a lack of a theoretical ground to guide its smart use. In a context of conception of naval systems, we present the outline of a process designed to output a set of alternatives for its architecture, optimizing several objectives and subject to constraints. The key point here is to outline the importance of the development of methods to choose smartly our approach to multi-objective optimization, in order to get the desired quality of results along several criteria, under several cost constraints. These choices include the choice of the algorithm and its parameters, but also the choice of the width of the architecture space. We show how complexity measures may be used to this end. We also show how we can take advantage of design with architecture frameworks in our approach.	algorithm;constraint (mathematics);mathematical optimization;multi-objective optimization;quality of results;systems architecture;systems engineering	Omar Hammami;Marc Houllier	2014	2014 IEEE International Systems Conference Proceedings	10.1109/SysCon.2014.6819289	enterprise architecture framework;probabilistic-based design optimization;reference architecture;space-based architecture;engineering optimization;database-centric architecture;decision engineering;computer science;systems engineering;operations management;service-oriented modeling;management science;data architecture;systems design	EDA	-62.17654798838473	9.208301748257508	19809
bc55ee0685e882ae9360d418915f0753b642f7e2	high-performance xml parsing and validation with permutation phrase grammar parsers	xml schema;xml web services automata engines runtime simple object access protocol doped fiber amplifiers computer science personal digital assistants data processing;web service;high performance xml parsing;permutation phrase grammar parsers;automata;parsing;grammars;engines;permutation phrase grammar;schema specific parsing high performance xml parsing permutation phrase grammar parsers interoperability web services push down automaton;web services;permutation phrase grammar xml parsing validation;xml;production;validation;interoperability;push down automaton;schema specific parsing;open systems;xml grammars open systems web services;high performance;doped fiber amplifiers;flexible printed circuits	The extensibility, flexibility, expressiveness, and platform-neutrality of XML delivers key advantages for interoperability. The interoperability of XML Web services often comes at the price of reduced efficiency of message composition, transfer, and parsing compared to simple binary protocols. This paper presents a high-performance XML parsing and validation technique that is time and space optimal. A schema-specific parsing method is developed that uses a two-stack push-down automaton (PDA) for single-pass parsing and validation without backtracking. The schema validity constraints are packed in a compact parsing table derived from a permutation phrase grammar. This approach reduces both the space and time requirements of XML parsing and validation. By contrast, other XML schema-specific parsing methods trade efficiency for space (larger code and/or data size) or trade space for efficiency (backtracking). Performance results show that the method is significantly faster than traditional validating and non-validating XML parsers.	backtracking;decision table;extensibility;interoperability;message passing;parsing;personal digital assistant;pushdown automaton;recursive descent parser;requirement;stack (abstract data type);web service;xml schema	Wei Zhang;Robert A. van Engelen	2008	2008 IEEE International Conference on Web Services	10.1109/ICWS.2008.101	natural language processing;web service;xml validation;parser combinator;simple api for xml;relax ng;streaming xml;top-down parsing language;computer science;bottom-up parsing;document structure description;parsing;xml framework;s-attributed grammar;xml schema;database;xml signature;programming language;law;top-down parsing;efficient xml interchange	SE	-34.4922598439994	8.473651322669236	19831
c893592ec97305b1a091da2629aa541acafb85da	re-pref: support for reassessment of preferences of non-functional requirements for better decision-making in self-adaptive systems	non functional requirements trade off;uncertainty;self adaptation	Modelling and reasoning with prioritization of non-functional requirements (NFRs) is a research field that needs more attention. We demonstrate RE-PREF, an approach that supports the modelling of NFRs and their preferences, and discovery of possible scenarios where badly chosen preferences can either make the runtime system miss or suggest unnecessary adaptations that may degrade the behavior of a self-adaptive system (SAS). Specifically, we showcase how RE-PREF is used in a remote data mirroring (RDM) system. The model of NFRs and the analysis of their preferences are enabled by using dynamic decision network (DDNs) and Bayesian Surprise.	adaptive system;bayesian network;disk mirroring;functional requirement;influence diagram;non-functional requirement;runtime system;sas	Luis Hernán García Paucar;Nelly Bencomo	2016	2016 IEEE 24th International Requirements Engineering Conference (RE)	10.1109/RE.2016.29	simulation;uncertainty;computer science;data mining	SE	-45.594922479807956	20.31042819979066	19836
d1fb643f88e642a9b2ad2ff1ee70aab7fbb1c56f	architecture refinements by code refactoring of behavioral vhdl-ams models	model code refining;architecture synthesis;code transformations;integrated circuit modelling electronic design automation high level synthesis;code refactoring;and mixed signal;behavior modeling;catalogs;analog behavioral model;software engineering;structural representations;context modeling circuit synthesis software engineering electronic design automation and methodology mathematical model integrated circuit modeling catalogs radio frequency high level synthesis computer architecture;computer architecture;high level synthesis;electronic design automation and methodology;radio frequency;integrated circuit modelling;automatic structure synthesis;architecture synthesis architecture refinements code refactoring behavioral vhdl ams models automatic structure synthesis system representation analog behavioral model mixed signal behavioral models model code refining code transformations software engineering analog circuit synthesis structural representations;integrated circuit modeling;system representation;mathematical model;behavioral vhdl ams models;analog circuit synthesis;mixed signal behavioral models;context modeling;architecture refinements;circuit synthesis;electronic design automation	This paper presents an automatic structure synthesis technique by partitioning the system representation, which consists of interconnected analog and mixed-signal behavioral models coded in VHDL-AMS. The proposed model code refining methodology restructures, refines, and simplifies behavioral models by means of code transformations of given abstract models. The fundamental approach for these transforms is code refactoring - an approach taken from software engineering and adjusted to the requirements of analog circuit synthesis. Through code refactoring one improves the comprehensibility, expandability, and reusability of a behavioral block model and restructures the model such that subsequent circuit synthesis steps may produce adequate structural representations of the intended behavior. Application examples demonstrate the feasibility of this approach to architecture synthesis	analog signal;analogue electronics;code refactoring;mixed-signal integrated circuit;prototype;requirement;software engineering;user error;vhdl;vhdl-ams	Kaiping Zeng;Sorin A. Huss	2006	2006 IEEE International Symposium on Circuits and Systems	10.1109/ISCAS.2006.1692875	behavioral modeling;computer architecture;electronic design automation;computer science;systems engineering;theoretical computer science;mathematical model;context model;high-level synthesis;radio frequency;code refactoring	SE	-48.02081935473144	30.17337184575662	19894
924d25a1cc890cfeb574b1885c793e259e35190b	using metamodels to promote data integration in an e-government application scenario	modeling technique;data integrity;metadata management;meta object facility;open standard	The increasing popularization of Internet has created unprecedented expectations and promises when dealing with a more intelligent  use of the available data. This use is based on metadata and on a new dimension of metadata modeling techniques. An initiative  supported by OMG culminated in the current MOF — Meta-Object Facility specification, which is an open standard with facilities  to definition and manipulation of metadata and metamodel. This paper describes a metadata management system that is based  on the MOF specification and presents one usage of this system in an egovernment scenario.  	e-government;metamodeling	Adriana Maria C. M. Figueiredo;Aqueo Kamada;Luciano Lançia Damasceno;Manuel de Jesus Mendes;Marcos Antônio Rodrigues	2003		10.1007/1-4020-7907-9_23	computer science;systems engineering;data mining;database;data element;meta data services	Robotics	-43.72379671394688	9.031847368241483	20018
c6fd8f79dead4cc1a10a0fcf9e87ff20a3782a91	minimum steiner tree for automatic sql query generation applied on a medical record database	databases;automatic sql query generation;automatic sql steiner tree databases electronic heath records;medical record database;medical records;minimum steiner tree;query processing;steiner trees;sql;web services medical information systems query processing sql;steiner trees html indexes dictionaries web services relational databases;web service architecture;relational database;web service;automatic sql;html;indexes;medical information systems;indexation;dictionaries;web services;relational databases;epic clarity reporting database;electronic health records minimum steiner tree automatic sql query generation medical record database epic clarity reporting database web service architecture;electronic heath records;steiner tree;electronic health records	The size and complexity of medical record databases makes extracting information challenging. With the tables numbering in thousands, even database analysts have trouble finding important fields and discovering various associations between tables. This paper presents a case study of our initial method of finding minimum Steiner trees in the Epic Clarity Reporting database to solve this problem. In addition, we present a web service architecture that can be used to extend our approach to multiple databases.	database;diagram;directed graph;graph (abstract data type);graph (discrete mathematics);minimum spanning tree;sql;select (sql);steiner tree problem;web service	Christopher E. Gillies;Nilesh V. Patel;Gautam B. Singh;Serge G. Kruk;Eddie Cheng;George D. Wilson	2011	2011 IEEE World Congress on Services	10.1109/SERVICES.2011.24	computer science;data mining;database;world wide web	DB	-33.7076365591087	6.570900841380498	20026
6995965e8ccbbfc4bf8c4102286f7b5a38758f7b	making the transition from oo analysis to oo design with the unified process	unified process	The current momentum for object oriented (OO) development in industry makes OO techniques worthy of attention. Information systems researchers and practitioners are increasingly using constructs such as use cases and class diagrams to define system requirements. A glaring weakness in the literature is the lack of useful guidelines and strategies for taking a relatively high level OO requirements model and translating it into an implementable architecture and detailed OO design. This tutorial paper demonstrates techniques for bridging the gap between OO requirements models and detailed OO design drawing on the framework provided by the Unified Process (UP) and based on concepts and techniques developed by researchers working on OO design patterns. The examples provided illustrate the transition from requirements, to architecture, to detailed design, and on to program code for one UP iteration. Communications of the Association for Information Systems (Volume12, 2003)659-683 659 Making the Transition from OO Analysis to OO Design With the Unified Process by J.W. Satzinger and R.B. Jackson MAKING THE TRANSITION FROM OO ANALYSIS TO OO DESIGN WITH THE UNIFIED PROCESS John W. Satzinger Southwest Missouri State University jws086f@smsu.edu Robert B. Jackson Brigham Young University ABSTRACT The current momentum for object oriented (OO) development in industry makes OO techniques worthy of attention. Information systems researchers and practitioners are increasingly using constructs such as use cases and class diagrams to define system requirements. A glaring weakness in the literature is the lack of useful guidelines and strategies for taking a relatively high level OO requirements model and translating it into an implementable architecture and detailed OO design. This tutorial paper demonstrates techniques for bridging the gap between OO requirements models and detailed OO design drawing on the framework provided by the Unified Process (UP) and based on concepts and techniques developed by researchers working on OO design patterns. The examples provided illustrate the transition from requirements, to architecture, to detailed design, and on to program code for one UP iteration.		John W. Satzinger;Robert B. Jackson	2003	CAIS		computer science;systems engineering;unified process;software engineering;management	SE	-53.50978857031782	23.800912941138808	20082
5f5cadea01c9373e601ba7ebcfe33ee6de492819	soa for services or uml for objects: reconciliation of the battle of giants with object-process methodology	object process methodology;service level;heart;system modeling;service oriented architecture unified modeling language software systems object oriented modeling computer architecture logic programming heart application software animation functional programming;application software;service orientation;emergency service;software systems;spectrum;functional programming;computer architecture;logic programming;animation;software development;unified modeling language;object oriented approach;extended enterprise;enterprise system;service oriented architecture;object oriented modeling	Two software system lifecycle development paradigms have been competing on the minds and hearts of software developers and executives: The traditional Object-Oriented approach and the emerging Service-Oriented Architecture (SOA) or SO Development of Application (SODA). While OO puts objects and their encapsulated behavior at the center stage, emphasizing primarily rigid structure, SODA hails services as the prime players to cater primarily to behavior. We discuss the new SOA technologies from the extended enterprise and the service network all the way to the atomic service level and show that Object- Process Methodology (OPM), which strikes a unique balance between structure and behavior, is most suitable as the underlying SOA-based lifecycle engineering approach. Using OPCAT, the OPMsupporting systems modeling software environment, we construct the top level diagram of a model of SODA and simulate it using animation in order to show how OPM conveniently serves as an ideal overarching comprehensive methodology that encompasses the entire spectrum of service-oriented enterprise systems development.	.net framework;access control;blueprint;business process execution language;database;diagram;end-to-end principle;enterprise system;extended enterprise;graphics;holism;hooking;java platform, enterprise edition;legacy system;modal logic;object process methodology;on the fly;programming paradigm;service-oriented architecture;service-oriented device architecture;service-oriented modeling;simulation;software deployment;software developer;software development process;software system;system lifecycle;system of systems;systems engineering;systems modeling;unified modeling language	Dov Dori	2007	IEEE International Conference on Software-Science, Technology & Engineering (SwSTE'07)	10.1109/SwSTE.2007.10	anime;unified modeling language;spectrum;application software;enterprise system;real-time computing;systems modeling;service level;computer science;systems engineering;software development;operating system;software engineering;service-oriented architecture;programming language;functional programming;logic programming;heart;software system	SE	-49.81390116114452	25.879695828749245	20156
67fb633dff3e69106b29affa15d012229e27270d	a data-centric approach for networking applications	declarative networking;programming abstraction;case based distributed query optimization	"""The paper introduces our vision for rapid prototyping of heterogeneous and distributed applications. It abstracts a network as a large distributed database providing a unified view of """"objects"""" handled in networkss a network as a large distributed database providing a unified view of """"objects"""" handled in networks and applications. The applications interact through declarative queries including declarative networking programs (e.g. routing) and/or specific data-oriented distributed algorithms (e.g. distributed join). CaseBased Reasoning is used for optimization of distributed queries by learning when there is no prior knowledge on queried data sources and no related metadata such as data statistics."""	distributed algorithm;distributed computing;distributed database;mathematical optimization;rapid prototyping;routing	Ahmad Ahmad-Kassem;Christophe Bobineau;Christine Collet;Etienne Dublé;Stéphane Grumbach;Fuda Ma;Lourdes Martínez;Stéphane Ubéda	2012			computer science;theoretical computer science;database;distributed computing;distributed design patterns	DB	-36.93825165944901	9.46792109191176	20229
1dd8419dae3d1dec15bfc7110586d13ef88f741c	understanding the dynamics of process models: a unified approach	proceso de software;simulacion;modelado de procesos	IN THIS WORK, A TECHNIQUE TO INTEGRATE THE RELEVANT ASPECTS OF PROCESS MODELING AND A SIMULATION METHODOLOGY IS INTRODUCED PROVIDING WITH THIS A MORE COMPLETE GUIDE FOR THE STUDY OF ORGANIZATIONAL PROCESSES. OUR APPROACH IS REINFORCED WITH THE DESCRIPTION OF ITS STEPS AND THE DEVELOPMENT OF A SUPPORT TOOL. THIS TOOL ALLOWS THE AUTOMATIC MAPPING OF PROCESS MODELS, CAPTURED USING ROLE ACTIVITY DIAGRAMS (RADS), TO THE INPUT TO A DISCRETE EVENTS SIMULATOR MODELS FROM SCRATCH, AND ALLOWING THE EVALUATION OF PROPOSED PROCESS MODEL CHANGES TO BE INFLUENCED BY THE RESULTS OF A SIMULATION STUDY. THE APPROACH IS ILLUSTRATED WITH THE SOFTWARE PROCESS EZAMPLE ISPW-6.		Ana I. Martínez-Garcia;Brian Warboys	2001	Computación y Sistemas		simulation;computer science;systems engineering;artificial intelligence;goal-driven software development process	Vision	-55.79101429546042	21.666970336570557	20251
44d9afd73783f18e4e96dd35598fb988f2412aeb	a system of systems architecture for supporting decision-making		Good Decision Support Systems require three main features: (i) a good handling of the domain data and information; (ii) an efficient user interface; and (iii) a good knowledge of past decisions. Usually such features are handled by different specialized systems difficult to integrate. In this research we keep specialized systems independent, focusing on interoperability. We propose a system of systems architecture (SoS) integrating a domain system in which users interact, a multi-agent system implementing an efficient user interface and taking into account results from the domain system, and a platform to capitalize and manage knowledge. Our approach extracts indicators from the interaction or behavior of users within the domain system, and provides them analyses, statistics and recommendations to help them reach good decisions. We built a prototype and applied it to two different domains: collaborative software development and healthcare. In this paper, we will focus on the multi-agent system which is a key component of the SoS architecture.	apple sos;collaborative software;decision support system;interoperability;multi-agent system;prototype;software development;system of systems;systems architecture;user interface	Gregory Moro Puppi Wanderley;Marie-Hélène Abel;Jean-Paul A. Barthès;Emerson Cabrera Paraiso	2017	2017 IEEE 21st International Conference on Computer Supported Cooperative Work in Design (CSCWD)	10.1109/CSCWD.2017.8066692	system of systems;knowledge management;decision support system;architecture;interoperability;systems design;computer science;systems architecture;multi-agent system;user interface	DB	-51.244190173999435	13.976626385802938	20289
7b1b3f18e2fea4e08f700d306c754bc4b3aaf876	meta-packages: painless domain specific languages	research outputs;research publications	Domain Speci c Languages are used to provide a tailored modelling notation for a speci c application domain. There are currently two main approaches to DSLs: standard notations that are tailored by adding simple properties; new notations that are designed from scratch. There are problems with both of these approaches which can be addressed by providing access to a small meta-language based on packages and classes. A meta-modelling approach based on metapackages allows a wide range of DSLs to be dened in a standard way. The DSLs can be processed using standard object-based extension at the meta-level and existing tooling can easily be de ned to adapt to the new languages. This paper introduces the concept of meta-packages and provides a simple example.	application domain;domain-specific language;object-based language;tree-meta	Tony Clark	2008	CoRR		computer science;programming language;engineering drawing;algorithm	PL	-47.27454667293539	25.754394798328853	20302
fd2cef30c0fe96816f6534ae4dc38bbdee16cab5	modelling of visualised data-flow diagrams using petri net model	entity relationship model;software tools formal specification petri nets programming theory;data flow diagrams;data flow diagram;direct manipulation;automation level;entity relationship model data flow diagrams petri nets high level semantics direct manipulation validation automation level visualised dfds data flow vectors correctness consistency visual level graphical forms;data flow vectors;graphical forms;correctness;software requirements and specifications petri nets programming theory software tools;visual level;validation;visualised dfds;petri nets;petri net;consistency;high level semantics	In this paper, an approach to the modelling and implementation of data-flow diagrams (DFDs) using Petri nets is introduced. A direction is identified where visualisation and high-level semantics can be incorporated into data-flow diagrams to facilitate direct manipulation, interpretation and validation. At the automation level, visualised DFDs generate layouts for data-flow vectors and use Petri nets to safeguard the correctness of a specification. The Petri net model uses a set of constraints to enforce consistency, both within and across diagrams. At the visual level, visualised DFDs replace the traditional textual specifications of the process and data-flow components with graphical forms. The entity-relationship model is adopted as the hierarchical and logical view of data.	dataflow;diagram;petri net	Poh-Tin Lee;K.-P. Tan	1992	Software Engineering Journal	10.1049/sej.1992.0001	data flow diagram;computer science;theoretical computer science;software engineering;database;programming language;petri net	SE	-46.9400036517573	27.896501505462087	20305
157c6413b1d81f25852364c9036adac1ffdef6e7	an ontology-based analysis of the industry foundation class schema for building information model exchanges	model view definitions mvd;semantic exchange modules sem;industry foundation class ifc;product or process modeling;building information modeling bim;ontology	Robust knowledge sharing frameworks between different stakeholders in a building project is of high priority. Industry Foundation Classes (IFC) provides a rich schema for interoperability through object-based transactions. However, IFC lacks semantic clarity in mapping entities and relationships, resulting in multiple definitions to map the same information between different federated models. The objective of this research is to examine IFC from a perspective of an ontological framework, which can make the IFC definitions more formal, consistent and unambiguous. Different methods of ontological approaches to engineering knowledge are reviewed. Various issues such as the need for a logical framework, the current semantic approaches in the AEC/FM industry, and advantages of building an ontology structure are addressed. A comparative study of the ontology and segments of the existing IFC schema definition are performed. This exercise reveals the ambiguous nature of current IFC definitions and proposes reforms such that data exchanges would be more semantically robust. An ontology would structure the overall interoperability of BIM tools by providing a formal and consistent taxonomy and classification structure for extending IFC and for defining subsets as model view definitions (MVD).	bim;building information modeling;diagram;entity;entity–relationship model;hoc (programming language);imperative programming;industry foundation classes;information model;library (computing);microsoft outlook for mac;ontology (information science);overhead (computing);software developer	Manu Venugopal;Charles M. Eastman;Jochen Teizer	2015	Advanced Engineering Informatics	10.1016/j.aei.2015.09.006	computer science;knowledge management;ontology;data mining;database	DB	-57.03177994654792	14.042842333790412	20318
06e8040e0cc3d5672a6616802e59b5b0a0c48084	an architecture for the evolution of web applications (poster session)	blackboard architecture;software architecture;gis;java server pages;software development;web based system;object orientation;design patterns;flexibility	This work presents a software architecture that is especially useful for managing the evolution of web applications. Web-based systems are a range of applications for which there are no technological standards and new concepts and tools are currently under evolution. Examples of this lack of standards include the transition from CGI scripts to Java Servlets and to Java Server Pages (JSP). Therefore, the maintenance and evolution of web applications is an important topic for software developers and the software research community. The proposed architecture combines the n-tier, broker, and blackboard architectural patterns.	architectural pattern;blackboard system;common gateway interface;evolution;java servlet;javaserver pages;multitier architecture;software architecture;software developer;web application	Paulo Caroli;Carlos José Pereira de Lucena;Marcus Fontoura	2000		10.1145/367845.367958	multilayered architecture;blackboard system;reference architecture;software architecture;software design pattern;web development;web modeling;geomatics;architectural pattern;computer science;applications architecture;multitier architecture;component-based software engineering;software development;cross-platform;web page;database;software architecture description;programming language;resource-oriented architecture;object-orientation;world wide web;web server;application server	SE	-48.939131391009674	21.369427973747083	20344
49e61a095bdcf3a83fd6bb9aefe8fc6cd9e46ca1	process-based e-service-logistics for healthcare networks		Coordination in healthcare networks becomes increasingly important to enable integrated care scenarios, to enhance patient satisfaction and to reduce costs of the treatment processes. A process-oriented approach for coordination in healthcare networks is introduced. It shows how interorganizational treatment processes can be supported by the concept of process-based e-service-logistics. The allocation of e-services is based on a model describing services and coordination tasks between roles in a healthcare network. The underlying systems architecture is presented. A solution for the (semi-) automated individualization of process-based e-service-logistics based on Case Based Reasoning (CBR) technology is discussed.	case-based reasoning;e-services;logistics;run time (program lifecycle phase);service-oriented architecture;systems architecture;usability	Günter Schicker;Freimut Bodendorf	2006			automotive engineering;flow (psychology);electrical conduit;fuel tank;environmental science;coolant;internal combustion engine;fuel injection;vapor pressure	AI	-53.27564039399886	9.614052906241204	20395
663b0134c77c1b7f581c7b0ee4cb8e61301d1149	distributed and collaborative design activities at the national institute of standards and technology	groupware;engineering graphics;collaboration design engineering product development computer aided manufacturing standards development manufacturing systems collaborative tools product design process design knowledge engineering;cad;virtual reality;multimedia computing;data visualisation;collaborative environment;data visualisation groupware virtual reality digital simulation multimedia computing engineering graphics cad research initiatives product development;information exchange;tools and techniques;heterogeneous application interoperation collaborative design activities distributed design activities national institute of standards and technology engineering artifacts product development globalisation manufacturing environment engineering application network multimedia tools geographically distributed applications geographically distributed design agents virtual reality tools simulation visualization information exchange standards;research initiatives;collaborative design;geographic distribution;digital simulation;national institute of standards and technology;product development	The increasing complexity of engineering artifacts and the globalization of product development necessitates a distributed and collaborative environment for design and manufacture. The future manufacturing environment will consist of a network of engineering applications, where state of the art multimedia tools and techniques will enhance closer collaboration between geographically distributed applications or design agents, virtual reality tools will allow visualization and simulation in a synthetic environment, and information exchange standards will facilitate seamless interoperation of heterogeneous applications. I provide an overview of our research activities in collaborative design.		Ram D. Sriram	1999		10.1109/ENABL.1999.805167	information exchange;human–computer interaction;computer science;software engineering;cad;database;virtual reality;new product development	HCI	-50.299445389334814	18.738091186967498	20403
e9b2c6cce46427c4ffb7cdef02490a8f97631549	software engineering for smart cyber-physical systems: models, system-environment boundary, and social aspects		Smart Cyber-Physical Systems (sCPS) are a novel kind of Cyber- Physical Systems engineered to take advantage of large-scale cooperation between devices, users and environment to achieve added value in face of uncertainty and various situations in their environment. Examples of sCPS include modern traffic systems, Industry 4.0 systems, systems for smart-buildings, smart energy grids, etc. The uniting aspect of all these systems is that to achieve their high-level of intelligence, adaptivity and ability to optimize and learn, they heavily rely on software. This makes them software-intensive systems, where software becomes their most complex part. Engineering sCPS thus becomes a recognized software engineering discipline, which however, due to specifics of sCPS, can only partially rely on the existing body of knowledge in software engineering. In fact, it turns out that many of the traditional approaches to architecture modeling and software development fail to cope with the high dynamicity and uncertainty of sCPS. This calls for innovative approaches that jointly reflect and address the specifics of such systems. This paper maps the discussions and results of the Third International Workshop on Software Engineering for Smart Cyber-Physical Systems (SEsCPS 2017), which specifically focuses on challenges and promising solutions in the area of software engineering for sCPS.		Tomás Bures;Danny Weyns;Bradley R. Schmerl;John Fitzgerald	2018	ACM SIGSOFT Software Engineering Notes	10.1145/3282517.3282542		SE	-61.31174151550738	20.04476303789918	20467
82d45d30c6871e81a15ec20c6891264af3bb14ba	a metamodel for modeling cost behavior in service composition	cost management service oriented computing service cost cost metamodel;service cost;electronic mail;web service cost behavior modeling service position lifecycle service costs resource utilization service composition lifecycle;cost metamodel;web services resource allocation service oriented architecture;engines;service oriented computing;business;xml;cost management;xml electronic mail engines business	During the service composition lifecycle, service costs should be predicted, controlled and reported in order to optimize resource utilization and increase profit. Several approaches have been proposed to address cost issues in some phases of the service composition lifecycle. However, each approach expresses costs in its own way, which makes it hard to integrate them into a comprehensive and automated approach that tackles cost issues throughout the service composition lifecycle. This paper addresses this problem by proposing a metamodel for expressing costs in service compositions. The proposed metamodel allows designers to express different cost behaviors and to enforce them throughout the service composition lifecycle. In addition to the metamodel, the paper also discusses the tools have been specially designed and implemented to support this metamodel. In order to evaluate the metamodel, we performed a case study in which cost results calculated with the proposed tools are compared with results obtained in a conventional way. Moreover, we describe some cost behaviors of real web service to evaluate the applicability of our metamodel.	algorithm;experiment;metamodeling;service composability principle;web service	Robson W. A. Medeiros;Nelson Souto Rosa;Luís Ferreira Pires	2014	2014 IEEE/ACS 11th International Conference on Computer Systems and Applications (AICCSA)	10.1109/AICCSA.2014.7073183	service level requirement;xml;differentiated service;computer science;service delivery framework;service-oriented architecture;service design;database;world wide web;cost accounting	SE	-46.97010492309358	16.21736496893018	20526
70f373431654dc53d344e9e025b297e06b8f781a	graphed: a graph description diagram for graph databases		Within recent years, graph database systems have become very popular and deployed mainly in situations where the relationship between data is significant, such as in social networks. Although they do not require a particular schema design, a data model contributes to their consistency. Designing diagrams is one approach to satisfying this demand for a conceptual data model. While researchers and companies have been developing concepts and notations for graph database modeling, their notations focus on their specific implementations. In this paper, we propose a diagram to address this lack of a generic and comprehensive notation for graph database modeling, called GRAPHED (Graph Description Diagram for Graph Databases). We verified the effectiveness and compatibility of GRAPHED in a case study in fraud identification in the Brazilian government.	diagram;graph database	Gustavo C. G. van Erven;Waldeyr Mendes Cordeiro da Silva;Rommel N. Carvalho;Maristela Holanda	2018		10.1007/978-3-319-77703-0_111	diagram;implementation;data mining;data model;notation;graph database;social network;conceptual schema;government;computer science	AI	-50.25173328054593	16.696100174643085	20544
7f9d7212ec561b2e0de0da9fb682b2c8a3af7866	transforming a flat metadata schema to a semantic web ontology: the polish digital libraries federation and cidoc crm case study		This paper describes the transformation of the metadata schema used by the Polish Digital Libraries Federation to the CIDOC CRM model implemented in OWL as Erlangen CRM. The need to transform the data from a flat schema to a full-fledged ontology arose during preliminary works in the Polish research project SYNAT. The Digital Libraries Federation site offers aggregated metadata of more than 600,000 publications that constitute the first portion of data introduced into the Integrated Knowledge System - one of the services developed in the SYNAT project. To be able to perform the desired functions, IKS needs heavily linked data that can be searched semantically. The issue is not only one of mapping one schema element to another, as the conceptualization of CIDOC is significantly different from that of the DLF schema. In the paper we identify a number of problems that are common to all such transformations and propose solutions. Finally, we present statistics concerning the mapping process and the resulting knowledge base.		Cezary Mazurek;Krzysztof Sielski;Maciej Stroinski;Justyna Walkowska;Marcin Werla;Jan Weglarz	2012		10.1007/978-3-642-24809-2_10	computer science;database;world wide web;information retrieval	Web+IR	-42.305785262085195	4.2106939208459835	20548
0e1c01fdb7c372633ad77a2b42a811e8fc376a9d	development of virtual foundry fab based on distributed multi-agents	subsystems;manufacturing systems;real time shop floor operations virtual foundry fab distributed multi agents semiconductor foundry order fulfilment customer satisfaction on time product delivery real time information event driven platform order management system production planning lot priority setting tool capacity allocation shop floor operation event monitoring process subsystems due date setting order planning order scheduling;shop floor operation;capacity allocation;management system;capacity planning;distributed agents;job shop scheduling;real time;distributed multi agents;order scheduling;event driven platform;lot priority setting;real time information;planning and scheduling;order management system;customer satisfaction;mechanical engineering;multi agent systems;production control;real time shop floor operations;semiconductor foundry;due date setting;message passing semiconductor device manufacture integrated circuit manufacture multi agent systems production control scheduling computer aided production planning;scheduling;robots;event monitoring process;priority setting;semiconductor device manufacture;message passing;computer aided production planning;production planning;foundries process planning manufacturing systems robots laboratories mechanical engineering job shop scheduling environmental management production planning capacity planning;process planning;order fulfilment;order planning;foundries;environmental management;virtual foundry fab;integrated circuit manufacture;on time product delivery;tool capacity allocation	The keys to the success of a semiconductor foundry fab are based on order fulfilment and customer satisfaction. The main objective of order fulfilment is to deliver the products on time. However, many processes, including due-date setting, planning and scheduling of the order and real-time shop-floor operations, are involved in accomplishing this goal. In order to enhance the customer satisfaction, the foundry company should not only promise on-time delivery but also provide real-time information about orders. A virtual foundry fab can realise these two important issues, and is constructed based on distributed agents and a proposed event-driven platform. The core of the virtual foundry fab is the order fulfilment process. The process is triggered by the customers' orders in the foundry fab environment and handled by the order management system. This paper focuses on the entire order fulfilment process. It includes the order management process, production planning, lot priority setting, tool capacity allocation, shop-floor operation and event monitoring processes. Each subsystem is established as an agent and performs its task on a distributed framework. The results show that the overall virtual foundry fab can be easily constructed using distributed multiple agents.	semiconductor fabrication plant	Chih-Yuan Yu;Han-Pang Huang	2001		10.1109/ICSMC.2001.973054	robot;job shop scheduling;real-time data;message passing;computer science;artificial intelligence;management system;customer satisfaction;scheduling	HPC	-54.03965495348308	12.019579303564507	20601
aefdc2cf85eb3399575d07e0024e251b9a9b49a9	software dependability metrics and analysis based on aadl error model	aadl error model;markov analysis method;dependability metrics;probabilistic reasoning	To analyze the software products dependability early in the software life cycle is an important means to assure the final product quality. This paper firstly defines the rules of transforming the AADL error model into expanded Markov chain, and then builds a dependability measurement model based on AADL error model. After discussing how to use the property of Markov chain to measure the software, a method is presented to measure the software dependability as a whole combined with AADL core model. Finally an example is given to explain the use of the measurement method and to analyze the measurement results.	architecture analysis & design language;dependability;markov chain;software release life cycle	Xin-ning Liu;Hong-Bing Qian	2011		10.1007/978-3-642-23896-3_28	real-time computing;computer science;probabilistic logic	Metrics	-62.47545258104968	31.52903493126247	20620
633b0e1895ed5d53970bd74b6560b4dc7e725dd6	utml: unified transaction modeling language	design process;bottom up;top down;unified modeling language process design logic devices navigation logic design laboratories distributed information systems transaction databases design methodology data visualization;state machine;modeling language;transaction processing specification languages internet;uml class diagram;internet;specification languages;transaction processing;uml utml unified transaction modeling language high level transaction modeling language complex web transaction design sub transactions legacy systems databases interfaces complex semantics transaction meta model transaction models behavioral patterns;legacy system;meta model;design methodology;dynamic behavior	We propose UTML as a high level transaction modeling language to facilitate the complex web transaction design process. Web transactions may be complex, composed of several sub-transactions and they may access resources with diverse behavior and interfaces like legacy systems and databases. They may also have complex semantics. Thus, transaction design methodologies and tools need to be very flexible allowing for designing web applications from scratch (top-down design), as well as using existing systems or services to compose new applications which offer added-value services (bottom-up design) to the user. UTML is based on a transaction meta-model, which can describe, in a flexible and extensible manner, most of the known transaction models as well as new ones according to the application’s requirements. It provides modeling for transactions that incorporate different behavioral patterns, and it is capable to describe activities with weaker transactional semantics that they do not have all the ACID properties. Unlike other models, it can be used to synthesize new transactions from pre-existing transaction systems (like legacy systems), with diverse transactional semantics. UTML provides a rich notation to visualize the transaction design process. This notation has been built on top of UML using its extension mechanisms.	acid;behavioral pattern;bottom-up parsing;database;high-level programming language;legacy system;metamodeling;requirement;top-down and bottom-up design;unified modeling language;web application	Nektarios Gioldasis;Stavros Christodoulakis	2002		10.1109/WISE.2002.1181649	extreme transaction processing;database transaction;transaction processing;distributed transaction;computer science;theoretical computer science;top-down and bottom-up design;database;online transaction processing;finite-state machine;programming language;serializability;transaction processing system	DB	-46.92388193132903	19.370755343243395	20623
81a5b7fb943d3acc36a55de36ec9a6d2053c5e80	injecting quality attributes into software architectures with the common variability language	quality attributes;cvl;weaving;variability;spl	Quality attributes that add new behavior to the functional software architecture are known as functional quality attributes (FQAs). These FQAs are applied to pieces of software from small components to entire systems, usually crosscutting some of them. Due to this crosscutting nature, modeling them separately from the base application has many advantages (e.g. reusability, less coupled architectures). However, different applications may require different configurations of an FQA (e.g. different levels of security), so we need a language that: (i) easily expresses the variability of the FQAs at the architectural level; and that (ii) also facilitates the automatic generation of architectural configurations with custom-made FQAs. In this sense, the Common Variability Language (CVL) is extremely suited for use at the architectural level, not requiring the use of a particular architectural language to model base functional requirements. In this paper we propose a method based on CVL to: (i) model separately and generate FQAs customized to the application requirements; (ii) automatically inject customized FQA components into the architecture of the applications. We quantitatively evaluate our approach and discuss its benefits with a case study.	applications architecture;functional programming;functional requirement;functional software architecture;heart rate variability;list of system quality attributes;meta-object facility;non-functional requirement;spatial variability	Jose Miguel Horcas;Mónica Pinto;Lidia Fuentes	2014		10.1145/2602458.2602460	real-time computing;systems engineering;engineering;software engineering;programming language;engineering drawing;weaving	SE	-54.4092935847459	27.465403321546404	20637
964207f8ad800e8edee38f0d35a4bc02a8a247c5	it support for release management processes in the automotive industry	dynamique processus;distributed system;duracion;gestion entreprise;concepcion ingenieria;industrie automobile;engineering design;new product;ciclo desarrollo;systeme reparti;calculateur embarque;life cycle;automovil;automotive industry;securite;conception ingenierie;processus metier;firm management;developpement produit;producto nuevo;development process;dinamica proceso;duration;process management;embedded system;synchronisation;sistema repartido;structural dynamics;automobile;synchronization;industria automovil;motor car;safety;boarded computer;traitement exception;cycle developpement;produit nouveau;proceso oficio;exception handling;estructura producto;coordinacion;administracion empresa;sincronizacion;systeme gestion base donnee;information system;process dynamics;seguridad;sistema gestion base datos;database management system;structure produit;calculador embarque;systeme information;desarrollo producto;automobile industry;business process;product structure;embedded software;duree;coordination;sistema informacion;product development	Car development is based on long running, concurrently executed and highly dependent processes. The coordination and synchronization of these processes has become a complex and error-prone task due to the increasing number of functions and embedded systems in modern cars. These systems realize advanced features by embedded software and enable the distribution of functionality as required, for example, by safety equipment. Different life cycle times of mechanical, software and hardware components as well as different duration of their development processes require efficient coordination. Furthermore, productdriven process structures, dynamic adaptation of these structures, and handling real-world exceptions result in challenging demands for any IT system. In this paper we elaborate fundamental requirements for the IT support of car development processes, taking release management as characteristic example. We show to which extent current product data and process management technology meets these requirements, and discuss which essential limitations still exist. This results in a number of fundamental challenges requiring new paradigms for the product-driven design, enactment and adaptation of processes.	cognitive dimensions of notations;embedded software;embedded system;graph (discrete mathematics);information system;p (complexity);process management (computing);programming paradigm;release management;requirement;simnet;schmitt trigger	Dominic Müller;Joachim Herbst;Markus Hammori;Manfred Reichert	2006		10.1007/11841760_26	synchronization;simulation;computer science;automotive industry;management;engineering design process	Embedded	-40.54100155529466	24.980509250748852	20700
c2a2d2a13bc68ef438fea819875cf2355956c652	a framework for development and management of e-lessons in e-learning		The use and or re-use of the existing e-lessons for the creation of new ones make the e-learning both time and cost effective. To accomplish this, however, requires the removal of some obstacles first. This paper presents a framework for that purpose. The progression of the concepts leading to the framework includes the introduction of a multi-dimensional e-lesson model that leads to the construction of an e-lesson cube. This cube is the backbone of an e-lesson warehouse, which in turn is the main component of the proposed	color gradient;internet backbone	Azita A. Bahrami	2005			knowledge management;data mining;computer science;information framework;management process	SE	-58.393834375573086	14.118904778385339	20724
02fec67063f2e33c84c435743870b01fbaba3267	a causally precedent relation among messages in topic-based publish/subscribe systems		Event-driven publish/subscribe (PS) systems are widely used in various types of applications. In this paper, we consider a peer-to-peer (P2P) model of a topic-based PS system which is composed of peer processes (peers) with no centralized coordinator. Here, each peer publishes a message with publication topics while receiving messages whose publication topics are in the subscription topics of the peer. Each peer has to deliver every pair of messages related with respect to topics in the causal order of publication events. In this paper, a message is considered to carry objects whose meanings are denoted by topics. Based on the meanings of objects, we define an object-based-causally (OBC) precedent relation among messages. Based on the OBC precedent relation, we newly propose a protocol to topic-based-causally (TBC) deliver messages to peers. Here, each peer causally delivers event messages which are related with respect to topics. If a message (m_{1}) OBC-precedes a message (m_{2}), the message (m_{1}) TBC-precedes (m_{2}).		Takumi Saito;Shigenari Nakamura;Tomoya Enokido;Makoto Takizawa	2018		10.1007/978-3-319-98530-5_47	precedent;distributed computing;computer science;publication	Logic	-40.43685023010742	13.30716176101364	20730
d224e2dd07c93c0348ddd8830bea8eccad4bd44b	a survey on 3d cad model quality assurance and testing tools	quality assurance;cad model quality testing	Abstract A new taxonomy of issues related to CAD model quality is presented, which distinguishes between explicit and procedural models. For each type of model, morphologic, syntactic, and semantic errors are characterized. The taxonomy was validated successfully when used to classify quality testing tools, which are aimed at detecting and repairing data errors that may affect the simplification, interoperability, and reusability of CAD models. The study shows that low semantic level errors that hamper simplification are reasonably covered in explicit representations, although many CAD quality testers are still unaffordable for Small and Medium Enterprises, both in terms of cost and training time. Interoperability has been reasonably solved by standards like STEP AP 203 and AP214, but model reusability is not feasible in explicit representations. Procedural representations are promising, as interactive modeling editors automatically prevent most morphologic errors derived from unsuitable modeling strategies. Interoperability problems between procedural representations are expected to decrease dramatically with STEP AP242. Higher semantic aspects of quality such as assurance of design intent, however, are hardly supported by current CAD quality testers.	computer-aided design;correctness (computer science);decision problem;downstream (software development);embedded system;hoc (programming language);interoperability;level of detail;requirement;software metric;software quality;taxonomy (general);text simplification	Carmen González-Lluch;Pedro Company;Manuel Contero;Jorge Camba;Raquel Plumed	2017	Computer-Aided Design	10.1016/j.cad.2016.10.003	simulation;computer science;systems engineering;mathematics;engineering drawing	EDA	-58.923411970250484	29.82412478831632	20733
1701f88f466c6fce8aff57d433621a89ed36bc44	pergo: an ontology towards model driven pervasive game development	systemvetenskap informationssystem och informatik;mdsd;information systems;pervasive game;dsm;datavetenskap;domain analysis;computer science;ontology	Model Driven Software Development MDSD & Domain Specific Modeling DSM are means to overcome software development challenges like increased software complexity and shortened development cycle in many domains. However, in the computer game domain it is not widely and successfully applied yet since it is not easy to understand the complex domain knowledge and use the knowledge to develop qualified DSM solutions. These difficulties can be alleviated by a deep and thorough domain analysis. In our research, we proposed an ontology to structure and accelerate the domain analysis process. To make our work more concrete, we focus on the emerging pervasive computer game genre.		Hong Guo;Hallvard Trætteberg;Alf Inge Wang;Shang Gao	2014		10.1007/978-3-662-45550-0_67	domain analysis;simulation;domain;computer science;knowledge management;domain engineering;world wide web	AI	-60.13315076341453	24.806311176001945	20753
36a0f069c770a7a97b0ac621afcffb14381dbd92	the fmics view on the verified software repository	industrial critical systems;formal verification;model checking;service oriented platforms	An important step in meeting the Verifying Compiler Grand Challenge is the Verified Software Repository. In the FMICS view, the repository should include proven correct software and tools to help establishing the correctness of the software in question. We propose to set up a collaborative demonstrator, based on the jETI technology, to provide tools to the repository and to orchestrate different tools.	compiler;correctness (computer science);formal methods;grand challenges;hoare logic;misra c;software repository;verification and validation	Álvaro Enrique Arenas;Juan Bicarregui;Tiziana Margaria	2006	Transactions of the SDPS		model checking;formal verification;computer science;software engineering;database;programming language	SE	-44.652960549565265	30.508132042950905	20772
76fa2b32e5047ca72568651f78ab0c167fccd068	getting started in performance tuning and capacity planning.	capacity planning;performance tuning			Neil Ervin	1994			performance tuning;operations management;capacity planning;computer science	Robotics	-61.63563454639251	5.152282135343838	20776
033aaa368654acc180d62f9dbee9eb152f5f15f7	compliance in service-oriented architectures: a model-driven and view-based approach	service oriented architectures;software engineering;process driven soas;model driven;compliance;view based;domain specific languages	Context: Ensuring software systems conforming to multiple sources of relevant policies, laws, and regulations is significant because the consequences of infringement can be serious. Unfortunately, this goal is hardly achievable due to the divergence and frequent changes of compliance sources and the differences in perception and expertise of the involved stakeholders. In the long run, these issues lead to problems regarding complexity, understandability, maintainability, and reusability of compliance concerns. Objective: In this article, we present a model-driven and view-based approach for addressing problems related to compliance concerns. Method: Compliance concerns are represented using separate view models. This is achieved using domain-specific languages (DSLs) that enable non-technical and technical experts to formulate only the excerpts of the system according to their expertise and domain knowledge. The compliance implementations, reports, and documentation can be automatically generated from the models. The applicability of our approach has been validated using an industrial case study. Results: Our approach supports stakeholders in dealing with the divergence of multiple compliance sources. The compliance controls and relevant reports and documentation are generated from the models and hence become traceable, understandable, and reusable. Because the generated artifacts are associated with the models, the compliance information won’t be lost as the system evolves. DSLs and view models convey compliance concerns to each stakeholder in a view that is most appropriate for his/her current work task. Conclusions: Our approach lays a solid foundation for ensuring conformance to relevant laws and regulations. This approach, on the one hand, aims at addressing the variety of expertise and domain knowledge of stakeholders. On the other hand, it also aims at ensuring the explicit links between compliance sources and the corresponding implementations, reports, and documents for conducting many important tasks such as root cause analysis, auditing, and governance.	business process;complexity;conformance testing;control flow;documentation generator;domain-specific language;integrated development environment;model-driven architecture;model-driven integration;norm (social);quality of service;requirement;service-oriented architecture;software system;specification language;traceability	Huy Tran;Uwe Zdun;Ta'id Holmes;Ernst Oberortner;Emmanuel Mulo;Schahram Dustdar	2012	Information & Software Technology	10.1016/j.infsof.2012.01.001	computer science;systems engineering;domain-specific language;engineering;knowledge management;software engineering;service-oriented architecture;data mining;database;programming language;management	SE	-57.159181189377044	20.8702993442512	20777
bece0e2a8e89e15ed7355348bd9f64d4b5cbf48d	decision support system for servitization of industrial smes: a modelling and simulation approach	simulation of production systems;business processes re engineering;product service systems;servitisation;modelling of production systems	Decision support system for servitization of industrial SMEs: a modelling and simulation approach M. Chalal, X. Boucher & G. Marques To cite this article: M. Chalal, X. Boucher & G. Marques (2015) Decision support system for servitization of industrial SMEs: a modelling and simulation approach, Journal of Decision Systems, 24:4, 355-382, DOI: 10.1080/12460125.2015.1074836 To link to this article: http://dx.doi.org/10.1080/12460125.2015.1074836	ambiguous name resolution;ct scan;decision support system;endeavour (supercomputer);feedback;in re boucher;nl (complexity);physical symbol system;production system (computer science);quality of service;service-oriented device architecture;simulation;socket.io;switch statement;washing machine	Malik Chalal;Xavier Boucher;Guillaume Marquès	2015	Journal of Decision Systems	10.1080/12460125.2015.1074836	artifact-centric business process model;operations management;business process model and notation;process management;new business development;business process modeling	Robotics	-57.09215086542467	15.818146734427687	20780
35120e9f15a39a7cd06fb18a91c5d2501cd19db7	the usability canary in the security coal mine: a cognitive framework for evaluation and design of usable authentication solutions		Over the past 15 years, researchers have identified an increasing number of security mechanisms that are so unusable that the intended users either circumvent them or give up on a service rather than suffer the security. With hindsight, the reasons can be identified easily enough: either the security task itself is too cumbersome and/or time-consuming, or it creates high friction with the users’ primary task. The aim of the research presented here is to equip designers who select and implement security mechanisms with a method for identifying the “best fit” security mechanism at the design stage. Since many usability problems have been identified with authentication, we focus on “best fit” authentication, and present a framework that allows security designers not only to model the workload associated with a particular authentication method, but more importantly to model it in the context of the user’s primary task. We draw on results from cognitive psychology to create a method that allows a designer to understand the impact of a particular authentication method on user productivity and satisfaction. In a validation study using a physical mockup of an airline check-in kiosk, we demonstrate that the model can predict user performance and satisfaction. Furthermore, design experts suggested personalized order recommendations which were similar to our model’s predictions. Our model is the first that supports identification of a holistic fit between the task of user authentication and the context in which it is performed. When applied to new systems, we believe it will help designers understand the usability impact of their security choices and thus develop solutions that maximize both.	authentication;curve fitting;holism;personalization;usability	Brian Glass;Graeme Jenkinson;Yuqi Liu;M. Angela Sasse;Frank Stajano	2016	CoRR	10.14722/eurousec.2016.23007	computer security model;simulation;human–computer interaction;computer science;operating system;human-computer interaction in information security;world wide web;computer security	Security	-51.61506651041331	6.169587449163086	20783
4ac2d34df49824800d884a7a63eb46a5e763daf2	before you invest: an illustrated framework to compare conceptual designs for an enterprise information system	software metrics;uml;systems design;erp;built and human environment	Post-implementation analysis on Enterprise Resource Planning (ERP) systems has drawn attention to many structural shortcomings. Yet, no framework exists to compare the different structural features of the ERP system. This paper develops a framework to compare different enterprise-wide systems at the conceptual design level using size, coupling and architectural complexity as criteria. Since, metrics used to measure these criteria are subjected to individual interpretation, a statistical technique using repeated measures design is used to validate the results of multiple evaluators. The framework was applied to the comparison of two enterprise-wide system implementations at the conceptual design level. One was a typical ERP, and the other was a documentbased system. A conceptual model was developed for the two methodologies using Unified Modeling Language (UML). Ten evaluators, all graduate students with the knowledge of UML were given the conceptual models of both systems and were instructed to apply the metrics. The evaluators performed the evaluations separately and were under no time restriction. Their results were used in the repeated measures design. Based on the results, TDM was smaller in size, more loosely coupled and less complex as compared to the ERP model. The framework successfully demonstrated that it can differentiate between two different implementations on the basis of their size, module coupling and architectural complexity. This framework presents a quantifiable technique that helps in informed decision making prior to a major financial commitment.	erp;enterprise information system;enterprise resource planning;loose coupling;toad data modeler;unified modeling language	Mohammed Arif;Dennis J. Kulonda;Michael D. Proctor;Kent Williams	2004	Information, Knowledge, Systems Management		reliability engineering;simulation;computer science;systems engineering;applications of uml	SE	-58.81729541826349	24.969493069831607	20805
73163f09634a3c5f20bd5e5f543519d2a7b001ec	declarative interaction through interactive planners	executable specifications;formal specifications;intelligent user interfaces;declarative interaction;planning;goal description languages.;petri nets;user interface management sys- tems;geo- graphic information systems;task analysis;model-based systems;management system;process algebra;formal specification;paradigm shift;human computer interaction;petri net	Recent progress in planning has enabled this technique to be applied to some significant real-world problems, including the construction of intelligent user interfaces. Previous research in interactive planners has emphasised their dynamism and maintenance advantages. This paper adopts a user-interaction perspective, and explores the theme that a paradigm shift in human-computer interaction is now a prospect: away from the requirement to instruct machines towards a more declarative, goal-based form of interaction. This initiative necessarily involves consideration of the design of goal description languages, and some alternatives are analysed. Some implementation issues involved with embedding planners within a user interface management system are examined. The general planning strategy of constructing executable models of causality within some domain is discussed in the context of human-computer interaction specification methods. Some advantages of planners in contrast to process algebras are described, and it is also shown how Petri nets could usefully incorporate some initiatives from planning research.	algorithm;causality;constraint satisfaction problem;data model;declarative programming;executable;geographic information system;human–computer interaction;imperative programming;intelligent user interface;petri net;process calculus;programming paradigm;system dynamics;user interface management systems;verification and validation	Conn V. Copas;Ernest A. Edmonds	1996			management science;task analysis;formal specification;intelligent user interface;theoretical computer science;petri net;management system;executable;interactive systems engineering;computer science;user interface	AI	-45.93791991998258	24.242774059259816	20818
295d26aeed8f71a0163a05ab649fa9214383ed84	can bpmn be used for making simulation models		We investigate the question if BPMN can be used for simulation modeling by evaluating it against ABDESO, a foundational ontology for agentbased discrete event simulation. Since a simulation model is intended to capture a real-world system, BPMN, if used as the modeling language for making the simulation model, should have a “real-world semantics” based on a foundational ontology for agent-based discrete event simulation.	agent-based model;angular defect;business process model and notation;lucidity;modeling language;simulation language;world-system	Giancarlo Guizzardi;Gerd Wagner	2011		10.1007/978-3-642-24175-8_8	systems engineering;process management	AI	-54.362419995221906	19.554547866245745	20857
4562d63f3abef345140c8fa7f4bbb761e4c9e232	feature interaction in a federated communications-enabled collaboration platform	enterprise communication;collaboration tools;journal article;feature interaction	Existing online collaboration tools and platforms provide basic communications integration and the ability to include some real-time information sources. Moreover, users prefer to be able to choose which collaboration tool they use for a given interaction, and over the course of long-term collaboration, will typically use a variety of tools, including email, instant messages, wikis, blogs, web conferences, and shared documents. For enterprise use there is a need to integrate the various tools as well as link with existing intelligent communication systems to support long-term collaborations in a variety of ways. Due to the number and different nature of collaboration services used in enterprises today, building such a federated collaboration platform is challenging. Collaboration tools differ in terms of storage model, APIs, content organization, addressing, formats, user authentication, and user interface. By the very nature of such systems they include a large number of independently developed features and services and thus provide a strong potential for feature interactions. This paper presents novel work on feature interaction analysis in collaboration environments and presents an approach to detect and resolve such interactions where the collaboration space is used as a communication endpoint. In this paper ConnectedSpaces is used as a basis to carry out a detailed analysis of feature interaction problems in collaboration environments. ConnectedSpaces is a new model for federated collaboration environments. Like a number of existing systems, ConnectedSpaces uses a collaboration space as the basic construct. ConnectedSpaces enables the user to work directly in the client application of their choice; this is illustrated with plug-ins for MS Outlook, Internet Explorer and Skype. This paper presents distinctive characteristics of ConnectedSpaces, including views, spaces as communication endpoints, space persistence and structuring, and embedded objects. Using these features, new types of feature interactions for collaboration platforms are categorized and analyzed. The work presented in this paper focuses on handling feature interactions which are caused by using ConnectedSpaces as a communication endpoint with enterprise communication platforms. This work is novel as it is the first investigation into feature interactions with collaboration platforms. Our approach uses a runtime feature interaction technique which can cope with features being provided by different organizations.	authentication;blog;categorization;client (computing);collaborative software;communication endpoint;email;embedded system;feature interaction problem;instant messaging;interaction technique;internet explorer;microsoft outlook for mac;open collaboration;persistence (computer science);real-time data;storage model;user interface;wiki	Mario Kolberg;John F. Buford;Krishna Kishore Dhara;Xiaotao Wu;Venky Krishnaswamy	2013	Computer Networks	10.1016/j.comnet.2013.02.023	knowledge management;operating system;data mining;world wide web;computer security	HCI	-49.112389545108535	12.359775561788993	20888
2c61a585d6f5c37143c166df5d4856ed96b43dc9	global nested transaction management for odmg-compliant multi-database systems	database system;object oriented data model;nested transaction;distributed computing;data model;common object request broker architecture	Object technology has received considerable attention in t he recent years for the integration of various local data sources in a multi-database sy tem (MDBS). An objectoriented data model like ODMG-93 can serve as the canonical d at model for the global layer in the MDBS. The ODMG-93 standard defines a close d n sted ACID transaction model without intra-transaction parallelism . Although the nested transaction model provides special support for distributed comput ing environments, the implications of its usage as a global transaction model for MDB S have so far not been examined. In this paper, we present a simple and practical method to imp le ent global nested transaction management for ODMG-compliant multi-databas e sy tems. The main contribution of our work is the adaption of the ticket method to a chieve global serializability for global nested transactions that conform to ODMG . Our approach is also applicable to OMG's common object request broker architect ur . We have succesfully implemented our global nested transaction model within the IRO-DB multi-database system .	acid;data model;database;enterprise javabeans;global serializability;nested transaction;object data management group;object request broker;parallel computing	Thomas Tesch;Jürgen Wäsch	1997		10.1145/266714.266861	common data representation;real-time computing;nested set model;database transaction;transaction processing;data model;distributed transaction;computer science;microsoft transaction server;object request broker;transaction data;common object request broker architecture;database;distributed computing;online transaction processing;transaction processing system;nested transaction	DB	-34.18401834523989	12.557934599596061	20913
8b81e53ede57b8b5be9a34883c8bfbf706ede25b	towards practical modeling of web applications and generating tests	hypermedia space;model design;program testing hypermedia internet online front ends;new technology;web navigation;navigation browsers adaptation model web pages presses load modeling history;web pages;history;navigation models;presses;satisfiability;web browser interactions;browsers;web applications;hypermedia;online front ends;navigation;adaptive navigation;adaptation model;internet;program testing;web application;test generation;web browser interactions adaptive navigation web application test generation;load modeling;hypermedia space web applications test generation navigation models web browser interactions adaptive navigation	As Web applications evolve, their structures become more and more complex. Web browsers may influence on the correctness of the Web applications, and Web browser’s interactions can cause further complications of Web application. Existing navigation models are static ones on the whole. Users’ navigation paths are all determined on stage of model design. Web browser interactions have not been taken into account make them different from practical navigation in Web applications. Moreover, as Web applications evolve and new technologies emerge, adaptive navigation was wildly incorporated in current Web applications. It aggravates the complexity of Web navigations. In this paper, a practical approach to modeling of Web applications and generating tests was pro-posed. And special care is taken on Web browser’s interactions and adaptive navigation during the user’s traversal within hypermedia space. At last, test generation is given out which satisfy the corresponding coverage.	adaptive grammar;algorithm;correctness (computer science);hypermedia;interaction;web application;world wide web	Shengbo Chen;Huaikou Miao;Bo Song;Yihai Chen	2010	2010 4th IEEE International Symposium on Theoretical Aspects of Software Engineering	10.1109/TASE.2010.25	web service;ajax;web application security;web development;web application;web modeling;web analytics;web mapping;web-based simulation;web design;human–computer interaction;web accessibility initiative;web standards;computer science;web navigation;web page;multimedia;client-side scripting;web engineering;programming language;world wide web;mashup	SE	-46.774962250883085	20.94225782523853	20944
1272ad4d5d0bad6ad11e5ab4dd680cba3e719689	synthesis of component and connector models from crosscutting structural views	synthesis;component and connector models	We present component and connector (C&C) views, which specify structural properties of component and connector models in an expressive and intuitive way. C&C views provide means to abstract away direct hierarchy, direct connectivity, port names and types, and thus can crosscut the traditional boundaries of the implementation-oriented hierarchical decomposition of systems and sub-systems, and reflect the partial knowledge available to different stakeholders involved in a system's design. As a primary application for C&C views we investigate the synthesis problem: given a C&C views specification, consisting of mandatory, alternative, and negative views, construct a concrete satisfying C&C model, if one exists. We show that the problem is NP-hard and solve it, in a bounded scope, using a reduction to SAT, via Alloy. We further extend the basic problem with support for library components, specification patterns, and architectural styles. The result of synthesis can be used for further exploration, simulation, and refinement of the C&C model or, as the complete, final model itself, for direct code generation. A prototype tool and an evaluation over four example systems with multiple specifications show promising results and suggest interesting future research directions towards a comprehensive development environment for the structure of component and connector designs.	code generation (compiler);np-hardness;prototype;refinement (computing);simulation;specification language	Shahar Maoz;Jan Oliver Ringert;Bernhard Rumpe	2013		10.1145/2491411.2491414	computer science;systems engineering;engineering drawing;algorithm	SE	-45.52541419718109	25.614267059962756	20967
07506df8007c01edb0a810c1728cdae911ac22d5	the role of hci models in service front-end development	front end;hci models;service front ends;human computer interaction;tool support;web service;development environment;interactive application;web services	description, it is then possible to derive more concrete ones in the specific concrete languages for each target platform. Since the concrete languages share a common core abstract vocabulary, this work is easier than working on a number of implementationmodalitydependent languages. 5. Exploiting Web services and annotations in UI generation In this section, we discuss how in our method it is possible to exploit the information contained in Web Services and related annotations for the generation of UIs, with particular reference to the supporting developed tool, MARIAE. The exploitation can be carried out at the different abstraction levels that may be involved in a multi-device UI specification, as is detailed in the following sub-sections. 5.1. Task level As previously stated, the meeting point between the classical top-down approach of the user interface modelling and the bottom-up approach for composing services within the MARIAE tool is the binding between the system tasks and the service operations. Such correspondence allows the definition of the composition structure and the flow of information passing through the service operation chain. Indeed, before creating any description of the user interface itself, the information contained in the service definition and the annotations enable improving the task model, describing more in detail the information exchanged between them. For instance, when a binding is created, the designer has to specify which interaction task provides the information related to all the input parameters. In addition, the designer has to specify which task exploits the information produced by the operation invocation, selecting from all the tasks that can be enabled by the bound system task. Moreover, the annotations can be exploited for obtaining additional information with respect to that in the data types of the service definition.	exploit (computer security);human–computer interaction;top-down and bottom-up design;user interface;vocabulary;web service;world wide web	Fabio Paternò;Carmen Santoro;Lucio Davide Spano	2012	Behaviour & IT	10.1080/0144929X.2011.563795	web service;simulation;human–computer interaction;computer science;multimedia;law	SE	-47.404408420452306	21.46898523279419	21012
cb847fdf7d25a315ffee224f49f8d3e57ad14e95	a büchi automata based model checking framework for reo connectors	linear time temporal logic;component based systems;operational semantics;reo;coordination language;buchi automata of records;model checking;linear temporal logic;context dependent;symbolic representation;binary decision diagram	Reo is an exogenous coordination language for synchronizing components participating in a component-based system. In this paper we provide a verification framework for model checking of Reo connectors. The proposed framework applies an extension of Büchi automata as the operational semantic model for Reo connectors and a record-based extension of linear time temporal logic (LTL) for expressing properties. Several aspects of Reo connectors, specially synchronization, context dependencies and fairness constraints, are addressed by this model checker due to its supported underlying model. The main ideas behind this implementation are to introduce a symbolic representation for the main elements of our model checking framework, adapt some existing theories to our verification context and develop a new BDD-based model checker with efficient performance. Moreover, all above mentioned features of Reo connectors are addressed by this toolkit. This implementation is evaluated by means of some case studies and the results are reported.	automata theory;büchi automaton;component-based software engineering;fairness measure;linear temporal logic;model checking;time complexity	Sarmen Keshishzadeh;Mohammad Izadi;Ali Movaghar-Rahimabadi	2012		10.1145/2245276.2232021	model checking;linear temporal logic;computer science;theoretical computer science;context-dependent memory;reo coordination language;programming language;operational semantics;binary decision diagram;algorithm	SE	-38.0394691080856	30.53723755641886	21034
11a1c512881ff44a5e8f8c8dc016d5e8339b2a00	seamlessly integrated, but loosely coupled: building user interfaces from heterogeneous components	user interface development;user interface;component based software;integration;semantic web;ontologies;user interfaces;rdf	User interface development is a time and resource consuming task. Thus, reusing existing UI components is a desirable approach for rapid UI development. To keep UIs maintainable, those components should be loosely coupled. Composing UIs of heterogeneous components developed with different technologies, on the other hand, is a non-trivial task not supported well by currently existing integration frameworks, and there is only little progress in automatizing the integration step.  In this paper, we introduce a framework for UI integration which is capable of handling heterogeneous UI components. It facilitates events annotated with RDF and ontologies for assembling user interfaces from loosely coupled components. With that framework, UIs can be composed semi-automatically, based on logic event processing rules.	complex event processing;loose coupling;ontology (information science);rapid application development;resource description framework;semiconductor industry;user interface	Heiko Paulheim	2010		10.1145/1858996.1859017	human–computer interaction;computer science;artificial intelligence;composite ui application block;database;user interface;world wide web	SE	-42.37505983115673	10.877949796875116	21050
40ff23e0404820154c7879b5e6e01b21ee11f9d4	supervisor simplification in fmss: comparative studies and new results using petri nets	manufacturing systems;petri nets discrete event systems flexible manufacturing systems;tin monitoring complexity theory petri nets manufacturing systems reliability;reliability;complexity theory;supervisor simplification automated manufacturing systems deadlock resolution inequality analysis petri nets;monitoring;discrete event controllers supervisor simplification petri nets structural simplification techniques flexible manufacturing systems fms control;petri nets;tin	Modern complex systems require intensive application of sophisticated supervisors. Structural simplification techniques are one of the fundamental researches in the context of flexible manufacturing systems (FMSs). They can reduce implementation cost, mitigate fabrication complexity, and improve reliability. Several typical methods have been developed along this direction. In order to thoroughly explore their effectiveness and performance, we not only conduct a comparison investigation but also develop some new theoretical results. Several analytical results and performance measures are proposed for their qualitative and quantitative comparison. Our approach can assist researchers and practitioners to better comprehend the inherent mechanisms and relative merits of these simplification methodologies as well as their applicability in FMSs. This paper is motivated by FMSs' control; however, it is also applicable to other systems with discrete event controllers.	complex systems;level of detail;maximal set;petri net;social inequality;symbolic computation;text simplification	Hesuan Hu;Yang Liu;Ling Yuan	2016	IEEE Transactions on Control Systems Technology	10.1109/TCST.2015.2420619	reliability engineering;real-time computing;tin;computer science;reliability;mathematics;process architecture;petri net	Visualization	-34.63861795058224	21.6287709763823	21078
4387eb4e7819f4d868a9dbdf35eac9601caf3f54	towards searching domain assets based on semantic similarity	databases;semantic similarity;ontologies semantics databases transportation data models algorithm design and analysis educational institutions;information retrieval;search algorithm;semantics;semantic networks;satisfiability;data model;domain knowledge;keyword search;transportation;ontologies;search problems;algorithm design;transportation domain semantic similarity domain knowledge domain assets search algorithm keyword search;algorithm design and analysis;semantic networks information retrieval search problems;data models	Domain Assets are the domain knowledge constructed according to the common requirements in the domain. In order to reuse the domain assets effectively, a domain assets search algorithm is proposed in this paper. Compared with the keyword search, this algorithm is based on semantic similarity, and the domain assets that closely satisfy the users can be selected so as to alleviate the burden of users when users search the domain assets. In addition, an example in transportation domain is illustrated to validate the effect of this algorithm.	requirement;search algorithm;semantic similarity	Wei Guo;Jian Wang;Keqing He;Dunhui Yu;Pengfei Du	2011	2011 Seventh International Conference on Semantics, Knowledge and Grids	10.1109/SKG.2011.14	domain analysis;algorithm design;business domain;computer science;artificial intelligence;domain engineering;data mining;database;semantics;linguistics;information retrieval	Robotics	-44.729233464795975	14.160131001451981	21110
5651155bc54ea1344f60d654203f101309bdd2b6	metamorphic malware detection using base malware identification approach	histogram intersection kernel;metamorphic malware;support vector machine;obfuscation	Malware is a malicious program that is intentionally developed to harm computer systems. Because the metamorphic malwares are advanced in nature, they mutate their code in each generation by employing code obfuscation techniques to thwart detection. Conventional scanners even fail to detect all variants of such malware. In the view of metamorphic malware detection, we have proposed the concept of machine learning approach like support vector machine with histogram intersection kernel. It has been successfully implemented in the area of image classification, bioinformatics protein classification and cancer classification. This method provides more accuracy in terms of detection rate to build the effective detection system for metamorphic malwares. In the proposed method, we first extract feature histograms from each portable executable file and map them into the feature space using a histogram intersection kernel. The histogram intersection kernel helps us to find the optimal hyperplane for separating the metamorphic variants from benign programs in a feature space of very high dimension. The results show that our proposed method is capable of detecting metamorphic variants with few false alarms or misses. Copyright © 2013 John Wiley & Sons, Ltd.		Devendra Kumar Mahawer;A. Nagaraju	2014	Security and Communication Networks	10.1002/sec.869	support vector machine;obfuscation;computer science;theoretical computer science;machine learning;computer security	Security	-35.49283424924118	23.109549495104616	21147
4f6c9f035dbef18747678a2ee6c4103b168f0c1d	input data management methodology for discrete event simulation	data handling;discrete event simulation;project management;des projects;des software;idm software;aerospace industry;core manufacturing simulation data format;data collection;discrete event simulation;input data management methodology	Input Data Management (IDM) is a time consuming and costly process for Discrete Event Simulation (DES) projects. In this paper, a methodology for IDM in DES projects is described. The approach is to use a methodology to identify and collect data, then use an IDM software to extract and process the data. The IDM software will structure and present the data in Core Manufacturing Simulation Data (CMSD) format, which is aimed to be a standard data format for any DES software. The IDM methodology was previously developed and tested by Chalmers University of Technology in a case study in the automotive industry. This paper presents a second test implementation in a project at the National Institute of Standards and Technology (NIST) in collaboration with an aerospace industry partner.	simulation	Nils Bengtsson;Guodong Shao;Björn Johansson;Y. Tina Lee;Swee Leong;Anders Skoogh;Charles R. McLean	2009	Proceedings of the 2009 Winter Simulation Conference (WSC)		project management;unified modeling language;data modeling;simulation;nist;data management;computer science;systems engineering;engineering;discrete event simulation;software engineering;group method of data handling;database;aerospace;manufacturing;world wide web;statistics;data collection	SE	-56.66726954962251	13.32856616544415	21182
e669149f61e5aa1e47e75d9da3d6ce154586034c	a conversation model of collaborative pair programming based on language/action theory	programming profession collaborative work collaborative software computer science navigation problem solving switches education international collaboration information security;collaborative work;information security;collaboration;conversation model;language action perspective;modeling language;pair programming;cscw pair programming collaborative pair programming language action perspective conversation model;navigation;development environment;programming profession;driver circuits;cscw;computer science;switches;collaborative pair programming;problem solving;collaborative software	Pair programming is a programming practice in which two programmers use one computer to work together on the same analysis, design, and programming of the same software. Collaborative Pair Programming (CPP) supports two programmers to work on the same task from different locations. This paper first reviews the existing CPP tools. Then a conversation model during CPP process is presented based on language/action perspective. Some basic requirements of CPP tool are given in terms of the conversation model. Finally, a framework of CPP tool is presented. The framework allows not only to use the same editor between the pairs, but also to support different editors or developing environments between them.	action potential;action theory (philosophy);admissible numbering;collaborative software;file sharing;interoperation;jbuilder;java;language/action perspective;one-to-many (data model);pair programming;programmer;programming tool;requirement;route inspection problem;software design pattern;visual café;visual j++	Wanfeng Dou;Kui Hong;Wei He	2010	The 2010 14th International Conference on Computer Supported Cooperative Work in Design	10.1109/CSCWD.2010.5472012	first-generation programming language;navigation;simulation;pair programming;human–computer interaction;programming domain;network switch;computer science;knowledge management;artificial intelligence;information security;software engineering;computer-supported cooperative work;database;development environment;modeling language;programming language;management;collaborative software;collaboration	EDA	-49.66651557069092	19.013434072130718	21243
06456eba1133f9d3c0a8bd57c5352bef49b31ddb	application of semantic search in idea management systems	resource description framework xml lead semantics;idea managament semantic search rdf ontology;semantic web business data processing innovation management;semantic web idea management system semantic search model open innovation support system business analysis distributed public brainstorming system	The following paper describes the design, architecture and use of a semantic search model in open innovation support systems. We explore the relationships between the user submitted content to improve interaction and simplify the current schemes of analysis of Idea Management System data. In order to accomplish this, we propose a model where users can build their own scenarios for business analysis. In particular, we present a methodology for collecting, organization and search of ideas submitted in a number of distributed public brainstorming systems. The description of our model is accompanied with a set of use cases.	approximation;business analysis;cluster analysis;coherence (physics);management system;ontology (information science);open innovation;plasma cleaning;search algorithm;semantic web;semantic search;web search engine	Geovanny Poveda;Adam Westerski;Carlos Angel Iglesias	2012	2012 International Conference for Internet Technology and Secured Transactions		semantic data model;semantic interoperability;cwm;semantic computing;semantic integration;semantic web rule language;data web;semantic search;semantic grid;computer science;knowledge management;semantic web;social semantic web;linked data;semantic web stack;semantic compression;database;semantic technology;information retrieval;semantic analytics	DB	-41.789402967311304	7.350981636976643	21301
33085342ac4a89c4d7710aee799332d537785e77	large scale web service discovery and composition using high performance in-memory indexing	web services data mining indexing semantic web;web service discovery;service orientation;semantic technologies;web service;service matching;data mining;emergent semantics;large scale;vitalab;indexing;vitalab large scale web service discovery high performance in memory indexing service oriented community semantic technologies service matching;indexation;web services;semantic web;service oriented community;semantic relations;high performance;high performance in memory indexing;large scale web service discovery;large scale systems web services indexing ontologies information retrieval query processing web and internet services	With the growing number and ubiquitous usage of Web services throughout the service-oriented community, the need to find service descriptions in a given repository, as well as composing them to a desired output, becomes a major issue in both research and corporate environments. Considering emerging semantic technologies and methods for service matching that is not limited to a mere syntactic level, the need for fast discovery and composition algorithms arises. In this paper we present a system created at the VitaLab in Vienna with the purpose to overcome the obstacles which are implications of both, large service repositories and large ontologies to describe semantic relations.	algorithm;apache axis2;ontology (information science);requirement;service discovery;service-oriented software engineering;software design pattern;web service	Lukasz Juszczyk;Anton Michlmayr;Christian Platzer;Florian Rosenberg;Alexander Urbanec;Schahram Dustdar	2007	The 9th IEEE International Conference on E-Commerce Technology and The 4th IEEE International Conference on Enterprise Computing, E-Commerce and E-Services (CEC-EEE 2007)	10.1109/CEC-EEE.2007.60	web service;computer science;database;world wide web;information retrieval	Robotics	-40.517349828889145	8.119506988923721	21303
3585fbc4d257712bf6353e3bd348af3030d7d422	specifying usability features with patterns and templates	human computer interaction;software engineering;case-based software requirements specification;functional usability;interactive software systems;pragmatic approach;software development;usability patterns catalog;software requirements specification;usability;usability features;usability patterns;use cases	"""Functional usability features like Undo or Auto-Save can greatly add to the usability of interactive software systems. This paper presents a pragmatic approach to considering usability features as """"first-class citizens"""" during early phases of software development, in particular during requirements analysis and definition. A catalog of usability patterns is used to describe proven and reusable solutions and to support software engineers in selecting appropriate usability features for a system. To allow for a systematic consideration, usability features are specified in a use case-based software requirements specification using semiformal specification templates. The resulting extended specification defines where and how usability features shall be integrated in the system, thus facilitating subsequent development activities (e. g. software architecture design, implementation, and test)."""	activity diagram;graphical user interface;interaction;level of detail;microsoft outlook for mac;requirement;requirements analysis;software architecture;software development;software development process;software engineer;software requirements specification;software system;undo;unified modeling language;usability	Holger Röder	2012			usability goals;pluralistic walkthrough;web usability;reliability engineering;component-based usability testing;software requirements specification;cognitive walkthrough;usability;agile usability engineering;computer science;systems engineering;software engineering;usability engineering;heuristic evaluation;usability inspection	SE	-52.40331184664668	25.48845108501096	21361
0f782e93d1e560c1022d21df56811304fd09198e	principles for modeling language design	design principle;computacion informatica;programming language;uml;modeling languages;grupo de excelencia;modeling language;unification;object oriented;ciencias basicas y experimentales;mathematical model;article;design principles	Modeling languages, like programming languages, need to be designedif they are to be practical, usable, accepted, and of lasting value. We present principles for the design of modeling languages. To arrive at these principles, we consider the intended use of modeling languages. We conject that the principles are applicable to the development of new modeling languages, and for improving the design of existing modeling languages that have evolved, perhaps through a process of unification. The principles are illustrated and explained by several examples, drawing on object-oriented and mathematical modeling languages.	computer-aided software engineering;diagram;executable;experiment;foremost;mathematical model;metacase tool;modeling language;problem domain;programming language;reversible cellular automaton;software development process;unification (computer science)	Richard F. Paige;Jonathan S. Ostroff;Phillip J. Brooke	2000	Information & Software Technology	10.1016/S0950-5849(00)00109-9	natural language processing;fourth-generation programming language;idef4;algebraic modeling language;computer science;domain-specific language;third-generation programming language;ontology language;modeling language;fifth-generation programming language;programming language;second-generation programming language;comparison of multi-paradigm programming languages	PL	-47.52461273588466	24.855025201281908	21366
a87e5cc5139d755592734e017b0844a2c3fca06f	taming the uncertainty: variability as a means for predictable system evolution	behavioral analysis;uncertainty;variability;sofware evolution	Software systems are increasingly request to evolve during their life time. Evolutions cannot always be anticipated or it might not be convenient to anticipate all possible system changes. This introduces levels of uncertainty in the predictable behavior of the system. Variability explicitly introduced in the software life cycle can help reducing the uncertainty constraining the behavioral analysis into well defined boundaries. In the talk I will provide a brief overview of approaches we recently developed in which variability plays the role described earlier and acts at different phases of the software life cycle. I will end discussing future research directions.	heart rate variability;software release life cycle;software system;spatial variability	Paola Inverardi	2013		10.1145/2430502.2430505	simulation;uncertainty;engineering;operations management	SE	-61.90419130665117	20.39832171824842	21367
46cc951401de40e823feef07aff070dbbf186808	preopt-w: a simulation program for off-line optimization of binary gradient separations in hplc-ii. data management and miscellaneous aspects of use	data management;simulation model	Abstract   This second part on the PREOPT-W program description deals with data management and other miscellaneous topics which allow PREOPT-W to build up the simulation model to be used later on for isocratic or gradient separations' optimization. Operational, priming, information and control data once properly given will be used to fit a specific problem-instrument retention profile model which is at the heart of PREOPT-W. The organization and facilities to do this task inside PREOPT-W are described in detail.	gradient;simulation	Rafael Cela;Marta Lores	1996	Computers & Chemistry	10.1016/0097-8485(95)00063-1	biology;simulation;computer science;simulation modeling;management science;operations research	ML	-60.114667482538955	10.030411158701298	21373
57d408c20bf9632beccffe8ebfa1c67a7c7b42a0	developing an architecture for the software subsystem of a learning technology system-an engineering approach	component based nature;software engineering process;reusability;architecting process;object oriented programming educational technology teaching software engineering open systems;information technology;software systems;ltsa working standard;component based nature software subsystem learning technology system engineering approach high level frameworks portability interoperability reusability architecting process lts ltsa working standard ieee ltsc business model software engineering process;object oriented programming;engineering approach;software engineering;portability;systems engineering and theory;business model;computer architecture;learning technology system;computer science education;high level frameworks;intelligent systems;humans;learning technology systems;interoperability;computer science;educational technology;computer architecture systems engineering and theory software engineering humans educational technology computer science education software systems computer science information technology intelligent systems;open systems;ieee ltsc;teaching;lts;software subsystem	There exists an urgent demand on defining architectures for Learning Technology Systems (LTS), so that high-level frameworks for understanding these systems can be discovered, portability, interoperability and reusability can be achieved and adaptability over time can be accomplished. In this paper we propose an architecting process for only the software subsystem of an LTS. We base our work upon the LTSA working standard of IEEE LTSC, which serves as a business model and on the practices of a well-established software engineering process. Special emphasis is granted on imposing a component-based nature on the produced architecture.	component-based software engineering;high- and low-level;interoperability;local tangent space alignment;software development process;software portability	Paris Avgeriou;Symeon Retalis;Andreas Papasalouros;Emmanuel Skordalakis	2001		10.1109/ICALT.2001.943843	business model;interoperability;reusability;educational technology;computer science;operating system;database;open system;object-oriented programming;information technology;software development process;software system	SE	-57.469604663672996	26.110648505930744	21389
c414e2b1e8304281874bed665f231bfa0cf85982	enhance matching web service security policies with semantic		Web service security policy is a way to add some security restrictions to a web service. Matching web service security policies is hard and important to inte- grate web services effectively. However, the lack of semantics in WS-SecurityPolicy (WS-SP) hampers the effectiveness of matching the compatibility between secu- rity policies of different web services. To enhance matching web service security policies, we propose a semantic approach for specifying and matching the security policies. The approach uses the transformation of WS-SP into an OWL-DL ontol- ogy, the definition of a set of semantic relations that can exist between the provider and requestor security concepts, and the algorithm to determine the match level of the provider and requestor security policies. We show how these relations and the matching algorithm lead to more correct and more flexible matching of security policies.		Tuan-Dung Cao;Nguyen-Ban Tran	2013		10.1007/978-3-319-02741-8_19	computer security model;cloud computing security;web application security;security through obscurity;security information and event management;security convergence;ws-policy;information security standards;social semantic web;data mining;database;security service;security testing;network security policy;world wide web	Web+IR	-42.96583726234391	13.6338528088604	21390
913eb5080351f6e2c846273ceff3ad3bdd59ab70	advanced requirements engineering workstation	formal specification;workstations prototypes design engineering laboratories software testing system testing software systems software tools user interfaces object oriented databases;software prototyping;user interface;dynamic model;expert system requirements engineering workstation requirements engineering testbed c3i system software requirements tools user interface object oriented database requirements engineering environment requirements analysis prototyping tools rl knowledge based requirements assistant frame based representation language intelligent notepad advanced requirements engineering workstation rapid prototyping dynamic modeling;requirements elicitation;intelligent design assistants;requirement analysis;software requirements;rapid prototyping;requirement engineering;robust performance;tools and techniques;software tools command and control systems formal specification intelligent design assistants object oriented databases software prototyping;software tools;object oriented databases;object oriented database;command and control systems;knowledge base;expert system	Since 1985, Rome Laboratory (RL.) has been evolving a Requirements Engineering Testbed (RET) to host and evaluate C31 system and sofware requirements tools and techniques. The RET concept will house various tools and environments which provides a common user interface and object-oriented database for the easy manipulation of information. RET currently consists of the Requirements Engineering Environment (REE) which is an integrated toolset of requirements analysis and prototyping tools. The analysis and prototyping capabilities provided by the environment will be enhanced by incorporating the existing RL. Knowledge Based Requirements Assistant (KBRA) tool functionality, which includes a frame-based representation language, multiple presentations, nonfunctional requirements capture and an intelligent notepad editor, into the REE. The resulting Advanced Requirements Engineering Workstation (AREW) will also be atended by incorporating metric capabilities and enhancing the existing REE methodology to provide guidelines for users performing requirements analysis activities using knowledge based techniques. Our approach is influenced by the need to make progress in integrating the KBRA technology, while preserving robustness, performance, and REE functionality such as rapid prototyping and dynamic modeling. AREW is concerned with evolving long term requirements elicitation and analysis capabilities to more fully utilize knowledge based, expert system technology.		James L. Sidoran	1993		10.1109/IWRSP.1993.263181	embedded system;requirements analysis;knowledge base;requirements management;business requirements;computer science;systems engineering;requirement;operating system;software engineering;requirements elicitation;formal specification;requirements engineering;programming language;user interface;expert system;software requirements;computer engineering	SE	-49.6411199748953	29.261704962684814	21402
632e7aec5a4aa1901cb76bb092ca2c00dad29e35	designing a cross-organizational case management system using dynamic condition response graphs	activity diagram;model driven design;semantics;process aware information systems;indexing terms;declarative workflow;business process model;business data processing;unified modeling language;industrial relations;workflow management system;humans;imperative models cross organizational case management system dynamic condition response graphs declarative business process model exformatics a s knowledge management systems workflow management systems behavioral constraints petri net uml sequence diagram activity diagrams bpmn ad hoc sub process activity bpmn 2 0 standard cross organizational process aware information systems;case management;organizations;graph model;organisational aspects business data processing digital simulation;model driven design case study declarative workflow;adaptation models;petri net;simulation tool;conditioned response;unified modeling language industrial relations adaptation models semantics humans organizations;digital simulation;graphic design;organisational aspects	We present a case study of the use of Dynamic Condition Response (DCR) Graphs, a recently introduced declarative business process model, in the design of a cross-organizational case management system being developed by Exformatics A/S, a Danish provider of knowledge and workflow management systems. We show how DCR Graphs allow to capture directly both the behavioral constraints identified during meetings with the customer and the operational execution as markings of the graph. In comparison, imperative models such as BPMN, Petri Net, UML Sequence or Activity diagrams are only good at describing the operational way to fulfill the constraints, leaving the constraints implicit. In particular, we point out that the BPMN ad-hoc sub process activity, intended to support more loosely structured goal driven ad-hoc processes, is inconsistently described in the final version of the BPMN 2.0 standard. The case study motivated an extension of the DCR Graphs model to nested graphs and the development of graphical design and simulation tools to increase the understanding of the models. The study also revealed a number of challenges for future research in techniques for model-driven design of cross-organizational process-aware information systems combining declarative and imperative models.	business process model and notation;diagram;graphical user interface;hoc (programming language);imperative programming;information system;management system;model-driven engineering;model-driven integration;organizational behavior;petri net;process modeling;simulation;unified modeling language	Thomas T. Hildebrandt;Raghava Rao Mukkamala;Tijs Slaats	2011	2011 IEEE 15th International Enterprise Distributed Object Computing Conference	10.1109/EDOC.2011.35	graphic design;classical conditioning;unified modeling language;index term;activity diagram;computer science;systems engineering;organization;knowledge management;data mining;database;semantics;industrial relations;management;business process modeling;petri net;workflow management system	SE	-54.17059923047417	19.070633230989664	21407
c1cdf907c2af70a4591556ce37be8f99f3153815	genmadem: a methodology for generative multi-agent domain engineering	domain model;developpement logiciel;modelizacion;ontologie;multiagent system;generators;domain engineering;multi agent system;componente logicial;reutilizacion;composant logiciel;intelligence artificielle;reuse;langage dedie;modelisation;desarrollo logicial;software development;software component;domain specific language;artificial intelligence;ontologia;estructura producto;development methodology;inteligencia artificial;multi agent systems development methodologies;sistema multiagente;software product line;modeling;generative software reuse;structure produit;software reuse;ontology;product structure;reutilisation;domain specific languages;systeme multiagent;lenguaje dedicado	Abstract】The crosscutting concerns are not considered in current agent-oriented methods and the agent is a too high level concept which can not e mapped to detail design and implementation directly. Metamodel Based Generative Domain Engineering(MBGDE) utilizes aspect oriented oftware development technology to capture the crosscutting concerns, and generative technology to promote reuse in software product families. his approach improves the quality and productivity of development for multi-agent system. Key words】metamodel; Agent-oriented software engineering; domain engineering	agent-oriented software engineering;aspect-oriented programming;cross-cutting concern;domain engineering;high-level programming language;metamodeling;multi-agent system	Mauro Jansen;Rosario Girardi	2006		10.1007/11763864_32	domain analysis;domain;computer science;domain-specific language;artificial intelligence;feature-oriented domain analysis;domain engineering;domain model;ontology;programming language;algorithm;generative design	SE	-40.787970726384415	24.528523914122545	21455
c1ba4910d03de1e2e27c531a2e79927787f9fd2e	pounamu: a meta-tool for exploratory domain-specific visual language tool development	end user development;visual design;swinburne;multi user;software engineering;journal article;multiple views;open architecture;meta case;visual language;domain specific language;visual design environments;tool integration;meta tools;domain specificity;meta model;domain specific languages	Domain-specific visual language tools have become important in many domains of software engineering and end user development. However building such tools is very challenging with a need for multiple views of information and multi-user support, the ability for users to change tool diagram and meta-model specifications while in use, and a need for an open architecture for tool integration. We describe Pounamu, a meta-tool for realising such visual design environments. We describe the motivation for Pounamu, its architecture and implementation and illustrate examples of domain-specific visual language tools that we have developed with Pounamu.	code generation (compiler);data structure;definition;diagram;eclipse;end-user development;entity;event-driven programming;feedback;graphical user interface;list of concept- and mind-mapping software;many-to-many;metamodeling;multi-user;one-way function;open architecture;open-source software;simple set;software deployment;software engineering;usability;vrml;view model;visual language	Nianping Zhu;John C. Grundy;John G. Hosking;Na Liu;Shuping Cao;Akhil Mehra	2007	Journal of Systems and Software	10.1016/j.jss.2006.10.028	natural language processing;computer science;systems engineering;domain-specific language;software engineering;programming language	SE	-49.070858763813554	24.89027347837886	21494
7cdf48cb0a1d930b52afc08c501f66b1895fdf0b	an object-oriented database architecture for providing securty in cyberspace			cyberspace	Reind P. van de Riet;Ehud Gudes	1996				DB	-50.44815283434878	8.592163200852774	21510
d0f8791c67a2402480dbc62edf525571580a830b	active, real-time, and heterogenous database systems			real-time transcription;relational database management system	Shamkant B. Navathe;Sharma Chakravarthy	1991			database;computer science	Embedded	-33.80987074085677	9.53525099251604	21526
4279f8bf982f6222a4862c049de3cfe5bd2ae8b0	applying megamodelling to model driven performance engineering	analytical models;model driven engineering concrete weaving conferences programming unified modeling language erbium;megamodelling;tool support;software development management meta data;mdpe modelling mde megamodelling model management performance engineering;biological system modeling;data mining;software development model driven performance engineering metadata modelling;performance engineering;mdpe;mde;computational modeling;adaptation model;software development;unified modeling language;model driven engineering;model driven performance engineering;meta data;model management;metadata modelling;context modeling;use case;software development management	Model Driven Engineering (MDE) has to deal with an increasing number of interrelated modelling artifacts. The Model Driven Performance Engineering (MDPE) process is one concrete illustration of such a situation. This process applies MDE within the context of performance engineering in order to support domain experts, who generally lack the necessary performance expertise. In this paper, we demonstrate the use of megamodelling to manage the numerous artifacts involved in MDPE. Megamodelling enables the explicit modelling of the metadata on MDE artifacts, including possible relationships between those artifacts. Appropriate tool support enables different stakeholders to exploit this additional information. Applying the megamodelling to MDPE pointed out the need for an extension of the existing approach. Thus, the result of the paper is twofold: first, an extension of megamodelling is proposed, second the benefits of the approach are shown on the MDPE use case. We claim that the extension is not solely useful for the latter case, but has a more generic applicability.	eclipse;error-tolerant design;experiment;metamodeling;model-driven engineering;no silver bullet;performance engineering;real life;socket am3;user interface	Mathias Fritzsche;Hugo Brunelière;Bert Vanhooff;Yolande Berbers;Frédéric Jouault;Wasif Gilani	2009	2009 16th Annual IEEE International Conference and Workshop on the Engineering of Computer Based Systems	10.1109/ECBS.2009.33	use case;unified modeling language;model-driven architecture;performance engineering;computer science;systems engineering;engineering;knowledge management;software development;software engineering;data mining;context model;computational model;metadata	DB	-53.89376075172469	24.29076017478848	21564
2e042483c0b08d78a1e2a446d524895b84cbbc57	conjunctive constraint mapping for data translation	hierarchical structure;digital library;digital libraries;satisfiability	In this paper we present a mechanism for translating information in heterogeneous digital library environments. We model information as a set of conjunctive constraints that are satisfied by real-world objects ( e.g., documents, their metadata). Through application of semantic rules and value transformation functions, constraints are mapped into ones understood and supported in another context. Our machinery can also deal with hierarchically structured information.	browsing;cad data exchange;declarative programming;digital library;formal system;graphical user interface;hierarchical database model;librarian;library (computing);machine translation;modular programming;norm (social);semantic interoperability;standard generalized markup language;tree (data structure);xml	Kevin Chen-Chuan Chang;Hector Garcia-Molina	1998		10.1145/276675.276681	computer science;theoretical computer science;data mining;database	DB	-36.96046892713491	7.633527671543461	21576
4eacd4c52d164cd7a54e8c10b0bf57e96b53c769	a multi-agent system for dynamic ontologies	multi agent system	In the article, we present Dynamo (an acronym of DYNAMic Ontologies), a tool based on an adaptive multi-agent system to construct and maintain an ontology from a domain specific set of texts. The originality of our proposal is that the adaptative multi-agent system is used both to represent the ontology itself and to produce the ontology. This enables us to propose a system building and maintaining dynamically an ontology according to interactions with the user (also called the ontologist). We present our system and the mechanisms used to build and maintain the ontology from the texts and for the interactions with the ontologist. We also give results of the evaluation of our system.	high-level programming language;information retrieval;information system;interaction;multi-agent system;ontology (information science);organizing (structure);relation (database);taxonomy (general)	Kévin Ottens;Nathalie Hernandez;Marie Pierre Gleizes;Nathalie Aussenac-Gilles	2009	J. Log. Comput.	10.1093/logcom/exn050	upper ontology;ontology inference layer;computer science;knowledge management;ontology;artificial intelligence;multi-agent system;data mining;ontology-based data integration;world wide web;process ontology;suggested upper merged ontology	AI	-42.841543310942946	8.090055942219454	21607
283c3908ad11b59d4b4880bf5b7975bc9f8d71ae	strider: configuration modelling and analysis of complex systems	testing human factors software maintenance hardware couplings;software prototyping;stakeholder involvement;qa75 electronic computers computer science;complex system;software reconfiguration strider tool configuration modeling complex system analysis automated analysis system development system evolution;software tools software prototyping configuration management;system development;software tools;configuration management	This paper describes an approach and support tool for the modeling and analysis of proposed reconfigurations to complex systems. The configuration models used are quick to construct and can help to promote understanding by the various stakeholders involved in system development and evolution. These models also form the basis of automated analysis, the results of which can help us to understand the full social and technical implications of the proposed changes to a system.	complex systems;strider	Simon Lock	2005	21st IEEE International Conference on Software Maintenance (ICSM'05)	10.1109/ICSM.2005.86	reliability engineering;complex systems;verification and validation;software configuration management;systems engineering;engineering;package development process;backporting;social software engineering;software development;software engineering;software construction;software testing;configuration management;systems development life cycle;software analytics;software deployment;computer-aided software engineering;software development process;software system	SE	-61.506755919877556	21.15786870304627	21654
16658016fd156e79bf3b320e255e6defee32963e	a template for the evaluation of tools for the simulation of continuous system			simulation	Yskandar Hamam;François Rocaries;A. Carrière	1995				EDA	-54.61221522565659	7.464587332501335	21707
5260e9afd5afc4937db5b52cbef1f52cd7a9e8ae	a tool to automate the sizing of application process for soa based platform		SOA (Service Oriented Architecture) is a loosely-coupled architecture designed to tackle the problem of Business/Infrastructure alignment to meet the needs of an organization. A SOA based platform enables the enterprises to develop applications in the form of independent services. To provide scalable service interactions, there is a need to maintain service’s performance and have a good sizing guideline of the underlying software platform. Sizing aids in finding the optimum resources required to configure and implement a system that would satisfy the requirements of BPI(Business Process Integration) being planned. A web based Sizing Tool prototype is developed using Java APIs(Application Programming Interface) to automate the process of sizing the applications deployed on SOA platform that not only scales the performance of the system but also predicts its business growth in the future. Keywords— SOA(Service Oriented Architecture), SOA Platforms, SOA Sizing, Sizing Tool prototype, Java Sizing API.	application programming interface;interaction;java;prototype;requirement;scalability;service-oriented architecture	Debajyoti Mukhopadhyay;Juhi Jariwala;Payal Innani;Sheetal Bablani;Sushama Kothawale	2014	CoRR		real-time computing;systems engineering;engineering;software engineering	SE	-49.5529808306281	18.276310785515236	21716
2fbf8320b0cc2014b7173548e84c7e17f601ff2c	a novel architecture for utility driven management	objeto de conferencia;policy based management;ciencias informaticas;service level agreement;utility driven management	In this paper, we specify and implement a framework for utility driven generation and scheduling of management actions based on Business context and Service Level Agreements (SLAs). SLAs are compiled into low level management policies; as well as sets of performance metrics and utility functions. These are subsequently used to drive the scheduling of the low level policy actions. Each action is associated with a utility participation value based on parameters relevant to the contract(s) it is related to; as well as the run-time context of its triggering and execution times. A Web hosting company case study is used to illustrate the benefit of taking into account business level implications when scheduling the execution of management tasks. We measure the overall business profitability as a pondered linear function of other business metrics such as overall raw financial profit and overall customer satisfaction. Finally, we discuss the difficulties and challenges related to the correct estimation of utility costs associated with the low level management/control actions.	compiler;high-level programming language;linear function;run time (program lifecycle phase);scheduling (computing);service-level agreement;simulation;web hosting service	Issam Aib;Raouf Boutaba;Guy Pujolle	2006		10.1007/978-0-387-34827-8_8	knowledge management;operations management;management science;business	Metrics	-59.623718767695124	18.64651114131815	21719
f7e7d27853e5c3465d3e631710c5495031a882c9	a controlled experiment for validating class diagram structural complexity metrics	developpement logiciel;quality assurance;class diagram;evaluation performance;fuzzy rule system;performance evaluation;lenguaje uml;fuzzy rules;evaluacion prestacion;data collection;clase complejidad;langage modelisation unifie;metric;controlled experiment;uml class diagram structural complexity;structural complexity;uml class diagram;aseguracion calidad;classe complexite;complexity class;object oriented;desarrollo logicial;unified modelling language;empirical validation;software development;unified modeling language;structural complexity metrics;oriente objet;metrico;uml class diagram modifiability;prediction model;assurance qualite;orientado objeto;qualite logiciel;software quality;metrique	Measuring quality is the key to developing high-quality software, and it is widely recognised that quality assurance of software products must be assessed focusing on early artifacts, such as class diagrams. After having thoroughly reviewed existing OO measures applicable to class diagrams at a high-level design stage, a set of metrics for the structural complexity of class diagrams obtained using Unified Modeling Language (UML) was defined. This paper describes a controlled experiment carried out in order to corroborate whether the metrics are closely related to UML class diagram modifiability. Based on data collected in the experiment, a prediction model for class diagram modifiability using a method for induction of fuzzy rules was built. The results of this experiment indicate that the metrics related to aggregation and generalization relationships are the determinant of class diagram modifiability. These findings are in the line with the conclusions drawn from two other similar controlled experiments.	class diagram	Marcela Genero;Luis Jiménez;Mario Piattini	2002		10.1007/3-540-46102-7_40	unified modeling language;quality assurance;computer science;class diagram;programming language;story-driven modeling;algorithm	Robotics	-60.37446833529722	29.51197436909819	21721
9255258466ead4e8f101be95449ca908f6b5b0e7	towards ontology guided translation of activity-centric processes to gsm		There exist two major modeling paradigms for business process modeling: The predominant activity centric one and the artifact centric paradigm. Both are suitable for modeling and for executing business processes. However, process models are typically designed from different perspectives. Current translation methods operate on the syntactic level, preserving the point of view of the source process. The results of such translations are not particularly useful, understandable and insightful for stakeholders. In this paper we motivate the need for ontology-guided translations by comparing the results of a purely syntactic translation with a manual translation. We discuss shortcomings of the generated solutions and propose an ontology-based framework and sketch corresponding translation method for the generation of semantic translations, which allow to incorporate the point of view of the target modeling paradigm.	application domain;business process;interoperation;ontology (information science);process modeling;programming paradigm;semantic translation;subject-matter expert	Julius Köpke;Jianwen Su	2015		10.1007/978-3-319-42887-1_30	natural language processing;database;world wide web	Vision	-53.49258247026979	19.402542586947014	21724
f6dccb7c52dad88cb6e714086b805fff2e5ad0a7	a framework for bpml assessment and improvement: a case study using idef0 and eepc	integrated information system;programming language;reliability modeling;aerospace industry;process management;simulation software;information flow;performance improvement;user requirements;event driven process chain;programming languages;business process modelling;evaluation framework;design methodology	Purpose – The purpose of this paper is to evaluate and improve two popular business process modelling languages (BPMLs) the Integration definition for function modelling (IDEF0) and event‐driven process chain (eEPC).Design/methodology/approach – The paper aims to select, compare and evaluate against a proposed criteria framework two popular BPMLs. In order to meet end‐user requirements, it suggests concrete improvements for either language. Evaluation findings and improvement attempts are documented over a case study within the context of a large European aerospace industry. The languages are applied through the use of appropriate software such as BPWin and Arena Simulation Software for IDEF0 and Architecture of Integrated Information Systems (ARIS) Toolset for eEPC.Findings – Improved languages seem to overcome several deficiencies and increase their modelling performance. Improvements in IDEF0 include: classification of component information and insertion of logical operators. In this approach the langu...	business process modeling language;idef0	Loukas Tsironis;Kiriakos Anastasiou;Vassilis Moustakis	2009	Business Proc. Manag. Journal	10.1108/14637150910960657	reliability engineering;information flow;economics;design methods;simulation software;computer science;systems engineering;engineering;user requirements document;software engineering;aerospace;event-driven process chain;business process modeling	NLP	-57.479962548351	23.28385830734901	21743
b1618c300e7c03f7212743e6f740df404c515472	multiagent systems and darpa	multiagent system;tecnologia electronica telecomunicaciones;computacion informatica;grupo de excelencia;ciencias basicas y experimentales;tecnologias	When the U.S. military faces a crisis, manpower and time are our most precious resources. Unfortunately, the software we employ during a crisis doesn’t always make the best use of our people or support a timely response. The commercial office automation products we use support editing and presentation of information, but their direct-manipulation interfaces require specification of all the details. Internet sources provide access to a huge amount of unfiltered data in different formats; and getting information from these sources still requires a lot of manual work. Our current focus on client/server information systems is an attempt to buy time by providing quick access to information we use for decision making. However, our experience in software procurement suggests that building large distributed information systems is both risky and expensive, even when using OO technology and standard interface protocols. One problem not addressed by these best practices is that developers still depend on the closed-world assumption that the builder of each software component knows all the relevant interfaces. As the complexity of applications increases, the number of interfaces also rises. At some point, the assumption fails. Another related problem is that developers hardcode interfaces as if they will never change. In reality, components, middleware, operating systems, and hardware are all periodically upgraded, so services change and new functions are required. These two problems combine to make frequent maintenance necessary for all current applications. Furthermore, dependence on the closed-world assumption has serious consequences on the complexity of problems that current software practice can address. Software agent technology is poised to solve these problems. Agents will soon revolutionize UI by interpreting user requests and automating manual processes. Agents will allow users to delegate simple tasks. Users will have time to solve complex, abstract problems, while agents use their knowledge of user preferences, standard domain defaults, and networked information sources to make simple decisions and even take action on behalf of the user. As agent technology matures and agent applications become more common, developers will want to integrate multiple applications so that different systems collaborate synergistically. Integrating many complex applications is a very challenging problem that many developers hope will be assisted by software. One way agents might do this is to use their knowledge to dynamically negotiate software interfaces, enabling agents to self-organize, forming super-applications at run time. These new super-applications will have simpler UIs, better problem-solving abilities, and more flexible composability than anything we have today. Super-applications will embody a new generation of scalable, cost-effective software technology. It is clear to me our current GUIs are beginning to limit the complexity of applications as well as our level of interactions with these applications. There are just too many new functions we would like to have and the screen real estate isn’t growing at the same pace. It also seems clear that users desire automation for many tasks. Moreover, software developers are still seeking methods to reduce the cost of building large applications, despite the advantages of OO technologies. However, the autonomy and partial knowledge that makes agents useful for addressing these problems can also cause problems. Agents can misinterpret user requests, make poor decisions, or interact with other agents in destructive ways. In the extreme, agents might run out of control, consuming resources such as CPU cycles, memory, and network bandwidth. If any of these problems occur with regularity, users happy with the control over their current computing environment will reject agents out of hand. By the same token, these problems will invalidate any advantage for system developments. Without effective control strategies, agent systems will not be adopted and progress is unlikely. Many people are interested in or actively developing agent applications. At DARPA, we are leveraging these investments by funding a project that will supply control strategies for multiagent systems. Not only will these strategies ensure the availability of system resources and system integrity, they will enable heterogeneous agent systems to collaborate, even when not hard-coded to do so. If we are successful, we will enable a drastic paradigm shift in software technology toward automation and costeffective, powerful applications.	agent-based model;autonomy;best practice;central processing unit;client–server model;closed-world assumption;component-based software engineering;composability;direct manipulation interface;freedom of information laws by country;hard coding;information system;instruction cycle;interaction;middleware;multi-agent system;operating system;problem solving;procurement;programming paradigm;regular expression;run time (program lifecycle phase);scalability;self-organization;server (computing);software agent;software developer;synergy;system integrity;user (computing);user interface	Douglas E. Dyer	1999	Commun. ACM	10.1145/295685.298128	artificial intelligence	SE	-54.138912324779334	10.890471448435884	21765
0d0f59634482af3d46882be055111fc2b0194a34	a service bus architecture for application integration in the planning and production phases of a product lifecycle	product lifecycle management;adaptive manufacturing;production planning;enterprise service bus;service oriented architecture;event driven architecture	Constantly changing business conditions require a high level of flexibility in business processes as well as an adaptive and fully interoperable IT infrastructure in today’s manufacturing environments. The lack of flexibility prevents manufacturing companies from improving their responsiveness and adapting their workflows to turbulent scenarios. In order to achieve highly flexible and adaptive workflows, information systems in digital factories and shop floors need to be integrated. The most challenging problem in such manufacturing environments is the high heterogeneity of the IT landscape, where the integration of legacy systems and information silos has led to chaotic architectures over the last two decades. In order to overcome this issue, the authors present a flexible integration platform that allows a loose coupling of distributed services in event-driven manufacturing environments. The proposed approach enables a flexible communication between digital factory and shop floor components by introducing a service bus architecture. This solution integrates an application-independent canonical message format for manufacturing events, content-based routing and transformation services as well as event processing workflows. DOI: 10.4018/978-1-4666-2470-2.ch010	business process;complex event processing;event-driven programming;high-level programming language;information silo;information system;integration platform;interoperability;legacy system;loose coupling;model-driven architecture;responsiveness;routing;turbulence	Jorge Mínguez;Stefan Silcher;Philipp Riffelmacher;Bernhard Mitschang	2011	IJSSOE	10.4018/jssoe.2011040102	real-time computing;integrated computer-aided manufacturing;computer science;operating system;software engineering;service-oriented architecture;database;computer-integrated manufacturing;law	Robotics	-56.71755956945442	15.304750210068782	21799
c7651441fbd731a4923a04f61cde9a46d06cd671	quality assurance of mobile applications: a systematic mapping study	quality assurance;software testing;mobile applications;state of the art;mapping study	Mobile applications have become highly pervasive in recent years. The quality of mobile applications for business use, in particular, is relevant for all stakeholders since application failures can lead to serious consequences, such as damage of corporate reputation or financial loss. For other applications, a reasonable level of quality is also required to convince users to use them. The goal of this work is to identify approaches that address the issue of quality assurance for mobile applications. We present an overview of the identified approaches based on certain viewpoints, such as the focused test level and the addressed quality, and show current research challenges. In order to drive the systematic mapping study, we derived seven research questions based on the stated goal. Then two researchers identified 3,192 records from four digital libraries based on a search string related to terms regarding quality assurance for mobile applications and predefined selection criteria. Ultimately, 230 articles were selected. We created clustered views to answer our seven research questions. In addition, we used surveys found to complement our overview of current challenges. The results show an overall upward trend of publications since 2003. Important topics include automation of GUI tests and assurance of non-functional qualities. Aspects of future research could be the establishment of test environments and the focus on defects addressing stronger the specific characteristics of mobile applications.	capability maturity model;digital library;functional requirement;graphical user interface;high-level programming language;library (computing);mobile app;pervasive informatics;software bug;string searching algorithm;system testing	Konstantin Holl;Frank Elberzhager	2016		10.1145/3012709.3012718	quality assurance;human–computer interaction;computer science;data mining;management science;software testing	SE	-60.37778136590307	26.02453398691292	21824
8c882102dcb3a1b187991c7dd6df783426f0ecfc	generating rewrite rules by browsing rdf data	rewrite rule;atomic query expressions;complex queries;resource description framework semantic web database languages engines navigation debugging usability knowledge representation web sites data visualization;rewrite rule generation;wilbur query engine;null;query rewriting rewrite rule generation rdf data path queries wilbur query engine atomic query expressions complex queries;query languages;rewriting systems;rewriting systems query languages;rdf data;query rewriting;path queries	"""In this paper we show how path queries in the Wilbur query engine can be augmented via the use of a simple rule system. This system can substitute atomic query expressions with complex queries, effectively rewriting queries. We demonstrate that this approach can be used for simple reasoning in the context of RDF(S). We further present a tool that allows the user to create complex queries merely by browsing an RDF graph, and by virtue of naming the automatically generated queries can create rules for the rule system. These rules appear in the system as """"virtual"""" RDF properties, and enable the user to interactively customize how RDF data is presented"""	browsing;interactivity;resource description framework;rewriting	Ora Lassila	2006	2006 Second International Conference on Rules and Rule Markup Languages for the Semantic Web (RuleML'06)	10.1109/RULEML.2006.13	rdf/xml;query optimization;query expansion;web query classification;computer science;sparql;linked data;database;rdf query language;programming language;web search query;information retrieval;query language;rdf schema;spatial query	DB	-35.34640419781657	5.976889824674777	21836
c47137d286947dfc5bc50ebe3320238aa13d8400	challenges in deployment of model driven development	source coding software engineering;software;development artifacts;model transformation;development process;development process support;software engineering;model driven development;model transformations;development process support model driven development;process support;unified modeling language;source code;model transformations model driven development development artifacts source code;product development process;organizations;programming model driven engineering product development software engineering visualization scattering concrete testing productivity scalability;programming;object oriented modeling;source coding;product development	Model-driven development (MDD) is an approach that focuses on creating models as first class development artifacts to produce source code by utilizing model transformations. Process support is needed for effective MDD as it guides the development of the model and helps to manage the relationships between models. Our paper highlights the results of the survey on real life experiences of using MDD in companies. The results confirm the validity of the previously published MDD-related challenges. Regardless of the advantages identified by the respondents there are still many challenges to tackle before MDD will become more generally used in organizations. However, respondents found the approach useful and state that in the next five years the product development processes, methods and tools will be developed towards MDD adoption in their organizations.	first-class function;model transformation;model-driven integration;new product development;real life;software deployment	Susanna Teppola;Päivi Parviainen;Juha Takalo	2009	2009 Fourth International Conference on Software Engineering Advances	10.1109/ICSEA.2009.11	simulation;computer science;systems engineering;software engineering;management;engineering drawing;new product development;source code	SE	-58.339936587368655	26.995803373509638	21842
b53ccc69cf586e5062a18b0e2a6449c47192a657	model checking human-human communication protocols using task models and miscommunication generation		Human–human communication is critical to safe operations in air transportation systems. For example, airlines develop and train pilots to use communication protocols designed to ensure that verbally communicated air traffic clearances are correctly executed by the pilots. Given the safety criticality of such interactions, these protocols should be designed to be robust to miscommunication. However, designers may not anticipate all of the different ways that miscommunication can occur. Thus, communication protocols can fail. This paper presents a method for evaluating human–human communication protocols using the enhanced operator function model with communications, which is a task analytic modeling formalism that can be used in model-checking formal verification analyses. In particular, a novel means of generating miscommunications from normative human–human communication protocols, instantiated as enhanced operator function models with communications, is introduced. An air transportation example is used to illustrate the power of the approach, where a protocol is iteratively evaluated and improved tomake it robust formultiplemiscommunications.Different versions of the application protocol are used to assess the scalability of the method. Results are discussed, and avenues of future research are explored.	communications protocol;formal system;formal verification;function model;human–computer interaction;model checking;scalability;self-organized criticality	Matthew L. Bolton	2015	J. Aerospace Inf. Sys.	10.2514/1.I010276	simulation;engineering;artificial intelligence;computer security	SE	-40.90774368180842	29.491656124846056	21855
10f52347a823c00ac55fb1fa60e7e85f9f3fadd3	strategy planning for collaborative humanoid soccer robots based on principle solution	humanoid robotics;intelligent technical systems;articulo;principle solution;mechatronics;design methodology	Collaborative humanoid soccer robots are currently under the lime light in the rapidly advancing research area of multi-robot systems. With new functionalities of software and hardware, they are becoming more versatile, robust and agile in response to the changes in the environment under dynamic conditions. This work focuses on a new approach for strategy planning of humanoid soccer robot teams as in the RoboCup Standard Platform League. The key element of the approach is a holistic system model of the principle solution encompassing various strategies of a soccer robot team. The benefits of the modelbased approach are twofold —it enables intuitive behavioral specification of the humanoid soccer robots in line with the team strategies envisaged by the system developers, and it systematicizes the realization of their collaborative behaviors based on the principle solution. The principle solution is modeled with the newly developed specification technique CONSENS ® for the conceptual design of mechatronic and selfoptimizing systems.		Cheng Yee Low;Norheliena Aziz;Mustafa Aldemir;Roman Dumitrescu;Harald Anacker;Martin Mellado	2013	Production Engineering	10.1007/s11740-012-0416-4	control engineering;simulation;mechatronics;design methods;computer science;engineering;humanoid robot;artificial intelligence	Robotics	-43.933044520901895	22.053714892430534	21916
be97d9a4118b3a81aa94aef9c4a65fadd437c9b4	agent-based distributed manufacturing control: a state-of-the-art survey	dynamic change;flexible manufacturing systems;holonic manufacturing systems;multi agent system;life cycle;agent based;intelligent manufacturing systems;intelligent manufacturing control;multi agent systems;control system;control architecture;distributed artificial intelligence;dynamic response;distributed manufacturing control;article	Manufacturing has faced significant changes during the last years, namely the move from a local economy towards a global and competitive economy, with markets demanding for highly customized products of high quality at lower costs, and with short life cycles. In this environment, manufacturing enterprises, to remain competitive, must respond closely to customer demands by improving their flexibility and agility, while maintaining their productivity and quality. Dynamic response to emergence is becoming a key issue in manufacturing field because traditional manufacturing control systems are built upon rigid control architectures, which cannot respond efficiently and effectively to dynamic change. In these circumstances, the current challenge is to develop manufacturing control systems that exhibit intelligence, robustness and adaptation to the environment changes and disturbances. The introduction of multi-agent systems and holonic manufacturing systems paradigms addresses these requirements, bringing the advantages of modularity, decentralization, autonomy, scalability and reusability. This paper surveys the literature in manufacturing control systems using distributed artificial intelligence techniques, namely multi-agent systems and holonic manufacturing systems principles. The paper also discusses the reasons for the weak adoption of these approaches by industry and points out the challenges and research opportunities for the future. & 2008 Elsevier Ltd. All rights reserved.	agile software development;autonomy;benchmark (computing);display resolution;distributed artificial intelligence;distributed control system;distributed manufacturing;emergence;holon (philosophy);multi-agent system;qp state machine frameworks;reconfigurability;reconfigurable computing;requirement;robustness (computer science);scalability	Paulo Leitão	2009	Eng. Appl. of AI	10.1016/j.engappai.2008.09.005	manufacturing execution system;biological life cycle;process development execution system;computer science;artificial intelligence;multi-agent system;computer-integrated manufacturing	AI	-53.93831726044292	11.936253283413174	21949
122e9ed835aa50d456b04ead55ce194de894fd95	contributions à l'analyse formelle et au diagnostic à partir de réseaux de petri colorés avec l'accessibilité arrière. (contributions to formal analysis and to diagnosis using colored petri nets with backward reachability)		Embedded system development creates a need of new design, verification and validation technics. Formal methods appear as a very interesting approach for embedded systems analysis, especially for dependability studies. The chosen formalism for this study is based on Colored Petri Net (CPN). Among the CPN models interests : expressivity, formal nature. Also, they express easily the double nature of the studied systems : static and dynamic. The main challenge of this thesis is to use existing models, which describe the system structure and/or behavior, to extract dependability information in a most general use and failure diagnosis information in a special use. The proposed approach is a CPN structural backward reachability analysis. It can be split in two parts. The first is the tool to perform the proposed analysis. This tool is the inverse CPN. It is obtained thanks to structural transformation applied on an original CPN. The second part is the analysis implementation. This part needs some complementary concepts whose the most important is the marking enhancement. The proposed approach is studied under two complementary aspects : algorithmic aspect and theoretic aspect. The first one proposes transformations for the CPN inversion and the analysis implementation. The second aspect (the theoretical one) aims to offer a formal proof for the approach by applying different methods : linear algebra and linear logic.		Mohamed Bouali	2009				Embedded	-42.04675061971278	27.65563750303262	21978
16e73c78479588789ba3bfce66c529cd3e3be38e	an investigation into applying uml to the zachman framework	class diagram;uml;unified model ing language;uml business profile;the zachman framework;enterprise architecture;modeling tool	The Zachman framework is considered to be the most referenced framework for the purpose of enterprise architecture. It is commonplace to compare other frameworks with this basic one in order to show correctness and usability of those frameworks. However, this is more than a fashion, the Zachman framework is actually the best one. Despite of its popularity, the Zachman framework could be a challengeable one in practical situations because there are not enough well-known methods and tools covering all of its aspects. Three major challenges in using this framework, are discussed in this article. These challenges are lack of a methodology, a well-defined repository and a popular modeling notation. Focus of this article is on solving the last problem with the help of notations in UML (Unified Modeling Language) and UML Business Profile. At the first glance the topic seems to be already researched by others, but there are some major distinctions between this work and the others’, which make it a unique one. Most of the other work tried to cover the framework using multiple class diagrams stereotyped in different ways. This work tries to cover the Zachman framework using all of the UML features, especially those, which are convenient in common modeling tools as well as ignoring unfamiliar symobls as it is used by some authors. A case study is used upon which we show how to apply the selected notation on a sample enterprise to develop cells in second and third rows of the framework. Models are tested to consider if they are supporting Zachman rules governing the framework. Furthermore, in order to see if they could be convincing enough, a statistical study is employed. Although A. Fatolahi ( ) · F. Shams Electrical and Computer Engineering Faculty, Shahid Beheshti University, Post Box 15875/1761, Velenjak, Tehran, Iran e-mail: Ali Fatolahi@yahoo.com results of these tests are relatively acceptable, the problem of inventing new modeling notations is mentioned as an open problem.	computer engineering;correctness (computer science);diagram;email;enterprise architecture;software repository;unified modeling language;usability;zachman framework	Ali Fatolahi;Fereidoon Shams Aliee	2006	Information Systems Frontiers	10.1007/s10796-006-7977-8	unified modeling language;rm-odp;uml tool;computer science;knowledge management;artificial intelligence;applications of uml;class diagram;data mining;database;enterprise architecture;view model;world wide web	Web+IR	-51.96749083299479	22.759353681389587	21981
1b6182122443261832d2699330ad6acb04973955	the application-specific task area	application software;software systems;integrated circuit technology;software reusability;software standards;very high speed integrated circuits;software reusability hardware software systems application software software standards integrated circuit technology knowledge based systems very high speed integrated circuits;knowledge based systems;hardware	The key goal in this area is to make software reusable. Short-term tasks involve building reusable software, while long-term solutions focus on very high level languages (VHLLs), and knowledge-based systems.	high-level programming language;knowledge-based systems;make	Joseph C. Batz;Paul M. Cohen;Samuel T. Redwine;John R. Rice	1983	Computer	10.1109/MC.1983.1654244	personal software process;computer architecture;verification and validation;computing;application software;software sizing;software verification;computer science;artificial intelligence;package development process;backporting;social software engineering;software framework;component-based software engineering;software development;software design description;operating system;software engineering;knowledge-based systems;software construction;resource-oriented architecture;software measurement;software deployment;software requirements;software system	ML	-52.86964637451762	28.398531361462712	21995
93f66a352b4bea047d552e991813c00b18ba2387	the well-tempered architecture	design pattern pattern software pattern architectural pattern;musical rhythms well tempered architecture well structured music song structure musical patterns software intensive systems architectural patterns design patterns musical motifs abstraction programmatic idioms;pattern;software pattern;software architecture;computer architecture software design pattern matching rhythm software architecture embedded system databases collaborative work software systems computer languages;levels of abstraction;design pattern;architectural pattern;music;structural design;software architecture music	Virtually all well-structured music, music that pleases the ear and moves the spirit, is full of patterns. Music is a primal medium of expression, and while some musicians in every age push the envelope of contemporary practice, there have emerged over the centuries common patterns of song structure, motifs, and even scales to which our ears have become accustomed. As it turns out, these musical patterns aren't so much constraining as they are liberating. Each level of structure imposes a discipline that limits a musical work from being something else and thus distinguishes one music piece from another. Similarly, all well-structured software-intensive systems are full of patterns. Architectural patterns serve the same role as song structure; design patterns and musical motifs are at the same level of abstraction; programmatic idioms and musical rhythms and scales are isomorphic.	architectural pattern;design pattern;whole earth 'lectronic link	Grady Booch	2007	IEEE Software	10.1109/MS.2007.122	new interfaces for musical expression;software architecture;software design pattern;speech recognition;behavioral pattern;architectural pattern;computer science;engineering;software analysis pattern;software engineering;interaction design pattern;music;pattern language;multimedia;design pattern;pattern		-50.85297157587387	32.10675829270058	22010
077430c59f8230bf289a42151629a24fa2d59180	reusing ocl in the definition of imperative languages			imperative programming;object constraint language	Fabian Büttner	2011				NLP	-48.14064582033463	27.188331143031984	22099
8f1758b2e1a43e603eead91d496e96836af4266e	programming without a net	software platform;embedded system;process model	Embedded systems programming presents special challenges to engineers unfamiliar with that environment.	embedded system;system programming	George Neville-Neil	2003	ACM Queue	10.1145/644254.644264	embedded system;real-time computing;reactive programming;computer science;software development;process modeling;inductive programming;system programming	EDA	-49.12015874799133	30.17737544893641	22100
9b9f67a80aaa63366c7fe3bb80c458b03c11e334	developing process mediator for web service interactions	space process mediation business process;web services business data processing data flow computing;web service interaction;web services mediation switches automatic control service oriented architecture runtime simple object access protocol customer profiles privacy collaborative work;collaboration;soa;web service;development process;evolution biology;process mediation;engines;mismatch pattern web service interaction soa business process space based architecture process mediator control flow data flow computing;mismatch pattern;mediation;business data processing;space based architecture;business;web services;control flow;process control;data flow computing;space;data flow;process mediator;business process	Web service interactions lie in the core of SOA. Due to the autonomy, heterogeneity and continuous evolution of Web services, mediators are usually needed to support service interactions to overcome possible mismatches that may exist among business processes. In this paper, we introduce a space-based architecture for process mediator which considers both control-flow and data-flow, present possible mismatch patterns, and suggest how they can be automatically mediated. Our work can be used to perform runtime mediation and thus to facilitate service interactions.	autonomy;business process;control flow;dataflow;interaction;service-oriented architecture;space-based architecture;web service	Zhangbing Zhou;Sami Bhiri;Walid Gaaloul;Lei Shu;Laurentiu Vasiliu;Manfred Hauswirth	2008	2008 IEEE International Conference on Web Services	10.1109/ICWS.2008.126	web service;computer science;process control;database;distributed computing;law;world wide web	SE	-47.28158671484465	18.213122928437222	22152
b84655041974198f9610d56013b7cfa24864c387	(an example for) formally modeling robot behavior with uml and ocl		One of the problems that the design and development of robotic applications currently have is the lack of unified formal modeling notations and tools that can address the many different aspects of these kinds of applications. This paper presents a small example of a chain of robotized arms that move parts in a production line, modeled using a combination of UML and OCL. We show the possibilities that these high-level notations provide to describe the structure and behaviour of the system, to model some novel aspects such as measurement uncertainty and tolerance of physical elements, and to perform several kinds of analyses.	coat of arms;high- and low-level;object constraint language;randomness;robot;simulation;systems design;unified modeling language	Martin Gogolla;Antonio Vallecillo	2017		10.1007/978-3-319-74730-9_22	systems engineering;measurement uncertainty;notation;behavior-based robotics;unified modeling language;computer science	Robotics	-45.18041308340134	24.29548565420061	22293
7e0c8a632bdda05a08912552ee16e39a988c958e	formalism-independent specification of ontology mappings - a metamodeling approach	modelizacion;graphic method;distributed system;reseau social;ontologie;systeme reparti;correspondance ontologie;red www;ontology mapping;lenguaje uml;web semantique;reseau web;004 informatik;service web;langage modelisation unifie;unifled modeling language;meta object facility;web service;metalangage;modelisation;social network;sistema repartido;metamodel;methode graphique;internet;metamodele;metalanguage;object oriented;metamodelo;web ontology language;web semantica;unified modelling language;semantic web;graphical model;metodo grafico;oriente objet;world wide web;ontologia;modeling;orientado objeto;ontology;correspondencia ontologia;red social;servicio web;metalenguaje	Recently, the advantages of metamodeling as a foundation for the graphical specification of ontologies have been recognized by the semantic web community. This has lead to a number of activities concerned with the development of graphical modeling approaches for the Web Ontology Language based on the Meta Object Facility (MOF) and the Unified Modeling Language (UML). An aspect that has not been addressed by these approaches so far is the need to specify mappings between heterogenous ontologies. With an increasing number of ontologies being available, the problem of specifying mappings is becoming more important and the rationales for providing model based graphical modeling support for mappings is the same as for the ontologies themselves. In this paper, we propose a MOF-based metamodel for mappings between OWL DL ontologies as well as a UML based graphical language for modeling mappings independent of a specific mapping formalism.	graphical user interface;meta-object facility;metamodeling;ontology (information science);semantic web;semantics (computer science);unified modeling language;visual programming language;web ontology language;world wide web	Saartje Brockmans;Peter Haase;Heiner Stuckenschmidt	2006		10.1007/11914853_56	metamodeling;web service;unified modeling language;the internet;semantic integration;systems modeling;metalanguage;computer science;artificial intelligence;semantic web;ontology;data mining;database;graphical model;programming language;web ontology language;object-oriented programming;world wide web;social network	Web+IR	-37.15851040621963	12.953449728817766	22327
7522e5aedc1a170a934e11ddd36514166ac04af0	an xml representation of dae systems obtained from continuous-time modelica models	dae representation;reglerteknik;technology and engineering;xml design	This contribution outlines an XML format for representation of differential-algebraic equations (DAE) models obtained from continuous time Modelica models and possibly also from other equation-based modeling languages. The purpose is to offer a standardized model exchange format which is based on the DAE formalism and which is neutral with respect to model usage. Many usages of models go beyond what can be obtained from an execution interface offering evaluation of the model equations for simulation pur poses. Several such usages arise in the area of control engineering, where dynamic optimization, Linear Fractional Transformations (LFTs), derivation of robotic controller s, model order reduction, and real time code generation are some examples. The choice of XML is motivated by its de facto standard status and the availability of free and efficient tools. Also, the XSLT language enables a convenient specification of the transformation of the XML model representation into other formats.	aggregate data;code generation (compiler);control engineering;differential algebraic equation;dynamic programming;formal system;jmodelica.org;mathematical optimization;model order reduction;modeling language;robot;simulation;xml;xslt;xbox controller	Roberto Parrotto;Johan Åkesson;Francesco Casella	2010			xml validation;computer science;theoretical computer science;xml framework;database;programming language	DB	-36.51108961387545	28.875443390084893	22330
bf43ac0f42ffdd7c062ce16620cb0f7707b4ef1b	new paradigm for developing software for e-business	enterprise resource planning organizational aspects business application software packaging companies hardware computer networks productivity communications technology;electronic commerce;software engineering;software requirements;user requirements;information based processes software development e business user requirements formal specification software requirement;electronic commerce software engineering	Many large organisations are spending considerable amounts of money to IT enable their business processes, in order to be competitive in the emerging global economy. Either they develop in-house solutions or purchase Enterprise Resource Planning (ERP) applications developed by a third party [1]. The aim of these packages is to integrate information-based processes within and across functional areas in an organisation. The high cost of developing an in-house solution or buying a third party solution has limited this approach to very large enterprises. Further in mid 1999 we saw articles such as “ERP R.I.P.” [2], “E.R.P. Staying Out of Trouble” [3] appearing indicating the ERP market is reaching a saturation point.	business process;erp;enterprise resource planning;money	Athula Ginige	2001		10.1109/HCC.2001.995269	personal software process;software requirements specification;verification and validation;enterprise software;software engineering process group;business requirements;systems engineering;package development process;software design;social software engineering;software development;requirement;software engineering;software construction;software as a service;business;software walkthrough;resource-oriented architecture;software deployment;software requirements;software quality;software system;computer engineering;software peer review	ML	-61.766685386757246	23.36657720696819	22365
917402f36001fd5d7ab16e7ff2a8a486a106cc2b	efficiently synchronizing multidimensional schema data	personal computer;data warehousing and the web;data warehouse design;special needs;data warehousing;xml;materialized views;data warehouse;system architecture	Most existing concepts in data warehousing provide a central data¿base system storing gathered raw data and redundantly computed materialized views. While in current system architectures client tools are sending queries to a central data warehouse system and are only used to graphically present the result, the steady rise in power of personal computers and the expansion of network bandwidth makes it possible to store replicated parts of the data warehouse at the client thus saving network bandwidth and utilizing local com¿puting power. Within such a scenario a - potentially mobile - client does not need to be connected to a central server while performing local analyses. Although this scenario seems attractive, several pro¿blems arise by introducing such an architecture: For example schema data could be changed or new fact data could be available. This paper is focusing on the first problem and presents ideas on how changed schema data can be detected and efficiently synchro¿nized between client and server exploiting the special needs and requirements of data warehousing.	database schema;materialized view;personal computer;requirement;server (computing)	Lutz Schlesinger;Andreas Bauer;Wolfgang Lehner;G. Ediberidze;Michael M. Gutzmann	2001		10.1145/512236.512246	materialized view;xml;data transformation;dimensional modeling;computer science;data warehouse;data mining;database;world wide web	DB	-35.69398649995752	9.845612856259844	22377
c9b8e2a80fee8cf6ea535018c3af753becd69eff	research on the organizational decision support system for small & medium-size enterprise based on agent	databases;organizational decision support system;multi agent system;small medium size enterprise;design and development;software maintenance;coordination mechanisms;organizational decision support systems odss;small to medium enterprises;multi agent system mas intelligent agents organizational decision support systems odss;mas;companies;software maintenance decision support systems multi agent systems organisational aspects small to medium enterprises software architecture;computer architecture;support system;software architecture;multi agent systems;information integration;decision support system;adaptation model;intelligent agents;legacy systems;legacy systems organizational decision support system odss small medium size enterprise mas multiagent systems aodss application agency decision agency chinese tv company;decision support systems;knowledge sharing;intelligent agent;application agency;aodss;decision process;multi agent system mas;decision agency;legacy system;decision support systems decision making multiagent systems software systems information processing chaos power generation economics environmental economics power system management tv;multiagent systems;data models;organisational aspects;odss;chinese tv company	To develop more powerful and flexible Organizational Decision Support Systems (ODSS), after the introduction of abstract architecture of a federated MAS system with two types of agent, the architecture of AODSS with three layers has been presented. The core layer includes two kinds of agencies: Application Agency for the common applications of this system, and Decision Agency for performing the actual decision activity and providing the results. To illustrate the architecture, a simulation work has been done in one Chinese TV company and the results imply that the architecture provides a very efficient method to design and develop ODSS for small & medium-size enterprise, in coordination mechanisms to ensure that organizational decision processes are optimized, information integrating of legacy systems for knowledge sharing, the interaction of multiple groups, flexibility and ability to extend and reengineer, the reusable ability of legacy systems, has played a very important role.	decision support system;information management;legacy system;mii;scalability;simulation	Ruixue Fu;Chaofeng Xu;Ming Song;Zhanhong Xin	2008	2008 International Symposiums on Information Processing	10.1109/ISIP.2008.89	enterprise architecture framework;decision support system;systems engineering;engineering;knowledge management;applications architecture;management science	AI	-53.28193463788372	14.414453652005179	22431
281730acefd9079c752b61d1c18b25c9bdb0cca5	ontology-based information visualization	information visualization;semantics network;ontology	The Semantic Web is an extension of the current World Wide Web, based on the idea of exchanging information with explicit, formal and machine-accessible descriptions of meaning. Providing information with such semantics will enable the construction of applications that have an increased awareness of what is contained in the information they process and that can therefore operate more accurately. This has the potential of improving the way we deal with information in the broadest sense possible, e.g. better search engines, mobile agents for various tasks, or even applications yet unheard of. Rather than being merely a vision, the Semantic Web has significant backing from various institutes such as DARPA, the European Union and the W3C, which all have formed current and future Semantic Web activities. In order to be able to exchange the semantics of information, one first needs to agree on how to explicitly model it. Ontologies are a mechanism for representing such formal and shared domain descriptions. They can be used to annotate data with labels (metadata) indicating their meaning, thereby making their semantics explicit and machine-accessible. Many Semantic Web initiatives emphasize the capability of machines to exchange the meaning of information. Although their efforts will lead to increased quality of the application’s results, their user interfaces often take little or no advantage of the increased semantics. For example, an ontology-based search engine could use its ontology when evaluating the user’s query (e.g. for query formulation, disambiguation or evaluation), but it could also use it to enrich the presentation of the resulting list to the end user, e.g. by replacing the endless list of hits with a navigation structure based on the semantics of the hits. Aidministrator is a software provider in the market of information and content management. One of Aidministrator’s core products is Spectacle. It facilitates the creation of information presentations that meet the needs of end users, e.g. a personalized navigation that reduces the need for searching and enables people to find information in a few clicks. Spectacle establishes this using the semantics of the information that can be provided by the Semantic Web. Therefore, Spectacle can be used to construct user interfaces that take advantage of the Semantic Web.	computer cluster;content management system;information seeking;information visualization;mobile agent;ontology (information science);personalization;real life;semantic web;software publisher;usability;user interface;web search engine;word-sense disambiguation;world wide web	Christiaan Fluit;Marta Sabou;Frank van Harmelen	2002			upper ontology;visual analytics;information visualization;visualization;computer science;ontology;data mining;ontology-based data integration;world wide web;information retrieval;process ontology;data visualization;suggested upper merged ontology	Web+IR	-41.00222071193225	8.275944469125676	22472
92a2608ef7f6f0e670f84e56b9351092869ac54a	adaptive swe and snmp-based sensor management for environmental monitoring	environment monitoring;simple network management protocol;sensor web enablement;sensor management;snmp;swe	Environmental monitoring technologies and applications have developed rapidly because of growing interest in environmental issues. Previous research on environment monitoring can be divided into two major categories: sensing data collection and heterogeneous system integration. With the improvement of sensing devices, the operational condition of a device is also regarded as environmental information. This study proposes a sensor web enablement (SWE) and simple network management protocol (SNMP)-based management framework. The proposed framework defines the entity management information base (MIB) of debris-flow sensors to integrate the management of various debris-flow sensors. An administrator can describe an object and its attributes to construct the tree-based SWE management architecture. This framework provides dynamically managed objects and standardises the message management between the management system and sensors. Data access and collection are based on the SWE standard message format, which enhances the exchangeability of sensing data. The proposed system integrates the SWE and SNMP services into a web service-based interface that provides real-time, seamless, and remote management services. The proposed system also provides dynamic monitoring functions for different rainfall events.	simple network management protocol	Chyi-Ren Dow;Yu-Hong Lee;Ruei-Yu Hu	2014	IJCNDS	10.1504/IJCNDS.2014.064637	computer science;data mining;network management application;simple network management protocol;structure of management information;computer security;computer network	Robotics	-35.941388206976505	15.041655580852588	22483
108689bfbec75ed17f299dacc6eea2d16f55f640	information models and methods of the university's scientific knowledge life cycle support		The main aim of this work is to develop methods and technologies of the university’s scientific knowledge management. The paper examines the concept of knowledge management and life-cycle processes of the university’s scientific knowledge. Text Mining and Semantic Web technologies are used to develop the ontological information model and for information resources processing. The paper describes the developed information model of the university’s scientific knowledge, the methods of forming scientific profiles, and the concept of the university’s scientific knowledge semantic portal.	enterprise life cycle;information model;knowledge base;knowledge management;personalization;personalized search;semantic web;text mining;web search engine	Gulnaz Zhomartkyzy;Tatiana Balova;Marek Milosz	2014		10.15439/2014F462	knowledge integration;computer science;knowledge management;data science;management science	AI	-42.41273933381416	6.324705738890615	22528
6694e25e16c19133f566f35e82e131c6c9c25a4f	a toolchain on model checking spin via kalman decomposition for control system software	software;control systems;model checking;aerospace electronics;mathematical model;petri nets;security	This paper proposes a new model checking method to detect falsification on control system software. In the previous study, we have examined a method which detects illegal rewriting for control system software via Petri Net and Kalman Decomposition (KD). In this paper, in order to divert this method to model checking, we consider a new toolchain with the existing model checker SPIN. Specifically, we develop a tool that translates Petri Net into Promela (modeling language of SPIN) and clarify that KD allows us to generate Linear Temporal Logic (LTL) formulas for SPIN automatically. In addition, we give a simple example of applying SPIN to Petri Net models before and after falsification.	control system;kalman filter;linear temporal logic;model checking;modeling language;petri net;processor affinity;promela;rewriting;spin;sensor;toolchain	Kento Tsukada;Kenji Sawada;Seiichi Shin	2016	2016 IEEE International Conference on Automation Science and Engineering (CASE)	10.1109/COASE.2016.7743421	real-time computing;simulation;computer science;theoretical computer science;petri net	SE	-40.29017976232477	30.837007855947018	22549
1956202aeafb783ee77ea3fa1634ce286341d523	on the role of simulation in the engineering of self-organising systems: detecting abnormal behaviour in mas	human immune system;design process;multi agent system;system modeling;stochastic calculus;formal method;large scale simulation;system evolution;agent coordination	The intrinsic complexity of self-organising multiagent systems calls for the use of formal methods to predict global system evolutions at early stages of the design process. In particular, we evaluate the use of simulations of high-level system models to analyse properties of a design, which can anticipate the detection of wrong design choices and the tuning of system parameters, so as to rapidly converge to given overall requirements and performance factors. We take abnormal behaviour detection as a case, and devise an architecture inspired by principles from human immune systems. This is based on theTuCSoN infrastructure, which provides agents with an environment of artefacts—most notably coordination artefacts and agent coordination contexts. We then use stochasticπ-calculus for specifying and running quantitative, large-scale simulations, which allow us to verify the basic applicability of our ID and obtain a preliminary set of its main working parameters.	agent-based model;converge;formal methods;high- and low-level;multi-agent system;requirement;self-organization;sensor;simulation	Luca Gardelli;Mirko Viroli;Andrea Omicini	2005			simulation;systems engineering;engineering;artificial intelligence	AI	-43.07204055128623	22.08799091169265	22622
b7e951a11612be5f61e610012c372de0e15978b0	structured prototyping: integrating prototyping into structured system development	system development	Abstract   Software development methodologies present two major schools of thought: one is that of  structured system development  and the other is that of  prototyping . Between these extremes, there are many mixed approaches. But any form of prototyping, though attractive, is difficult to implement for large systems because of its implied lack of structure. This paper proposes a framework for the integration of prototyping into structured system development. We first carry out structured analysis and design; these products are then used to support systematic prototyping. The resulting prototype serves to provide the user with an iterative process of understanding and improving the requirements until they are satisfactory. This methodology for structured prototyping has four elements: interface, data, process, and system prototypes. The methodology is based on a new unified approach to the analysis and design phases.	prototype	Peretz Shoval;Nava Pliskin	1988	Information & Management	10.1016/0378-7206(88)90064-X	iterative design;requirements analysis;simulation;computer science;systems engineering;engineering;engineering drawing;software development process	HCI	-59.897685534123596	11.480522196701004	22634
6fb6a9c8485be67d7b2ecbfd54f11c4a053a4016	towards automated inconsistency handling in design models	design model;model system;search space;model driven engineering	The increasing adoption of MDE (Model Driven Engineering) favored the use of large models of different types. It turns out that when the modeled system gets larger, simply computing a list of inconsistencies (as provided by existing techniques for inconsistency handling) gets less and less effective when it comes to actually fixing them. In fact, the inconsistency handling task (i.e. deciding what needs to be done in order to restore consistency) remains largely manual. This work is a step towards its automatization. We propose a method for the generation of repair plans for an inconsistent model. In our approach, the depth of the explored search space is configurable in order to cope with the underlying combinatorial characteristic of this problem and to avoid overwhelming the designer with large plans that can not be fully checked before being applied.	altran praxis;eclipse modeling framework;eventual consistency;exception handling;loose coupling;model-driven engineering;papyrus;search algorithm;unified modeling language	Marcos Aurélio Almeida da Silva;Alix Mougenot;Xavier Blanc;Reda Bendraou	2010		10.1007/978-3-642-13094-6_28	model-driven architecture;simulation;computer science;systems engineering;artificial intelligence;software engineering;data mining;database;algorithm	SE	-54.9208906628039	28.674414501872064	22672
69227be6dc5fad6a3b84b3a8b5a33241813a173f	constraint agents for the information age	digital library;information age;internet access	We propose constraints as the appropriate computational constructs for the design of agents with the task of selecting, merging and managing electronic information coming from such services as Internet access, digital libraries, E-mail, or on-line information repositories. Speci cally, we introduce the framework of Constraint-Based Knowledge Brokers, which are concurrent agents that use so-called signed feature constraints to represent partially speci ed information and can exibly cooperate in the management of distributed knowledge. We illustrate our approach by several examples, and we de ne application scenarios based on related technology such as Telescript and work ow management systems.	digital library;internet access;library (computing);online and offline;telescript (programming language)	Jean-Marc Andreoli;Uwe M. Borghoff;Remo Pareschi;Johann H. Schlichter	1995	J. UCS	10.3217/jucs-001-12-0762	information age;digital library;internet access;computer science;multimedia;world wide web;information retrieval	AI	-42.89822351398542	8.228186999684707	22673
e6eb1143527e12681ba185e1693f56e66e360e2d	object-oriented design of the control software for a flexible manufacturing system	object oriented design;flexible manufacturing system	A flexible , automated and integrated system must be able to reply to the market demand, which is, on the short term, very variable and characterized by low production volumes. Such a capability mostly depends on the adaptive and dynam ic fe atures of the control software . In fact contemporary software package s for controlling manufacturing system s are proprie tary and require an e xpensive implementation and maintenance e ffort to fit the changing needs of a specific enterprise in a particular time period. A greater system flexibility is needed, supported by an adaptive and dynamic control software which guarantees a good utilization of the system resources. Th is pape r gives guidelines to design operational control software for a flexible manufacturing system, with generic, flexible and obje ct-oriented features. The obje ct-oriented paradigm allows us to decompose the control software in to appropriate ly in teracting standard module s. The decomposition scheme naturally arises from a discre te event dynamic system mode l of the Flexible Manufacturing System behaviour. Modularity of our formalism is the key factor for achieving reusable and general software.	content-control software;dynamical system;field electron emission;programming paradigm;semantics (computer science);wilhelm pape	Guido Maione;Giacomo Piscitelli	1999	Int. J. Computer Integrated Manufacturing	10.1080/095119299130434	manufacturing execution system;integrated computer-aided manufacturing;process development execution system;computer science;object-oriented design;computer-integrated manufacturing;manufacturing engineering	Robotics	-53.541718606770864	13.37772169342685	22685
67ee81195a4dca250bbde9350ba0091a55e7338a	a collaborative approach to construction of large scale distributed reasoning systems	collaborative reasoning;artificial intelligence;service oriented architecture;ontology	This paper introduces a new collaborative approach to construction of large scale service oriented systems supporting distributed reasoning. In particular, we assume systems in which complex situation assessment is carried out through composition of heterogeneous services, each specialized for a particular type of analysis. Different services are composed automatically by using service discovery and negotiation. One of the major challenges in such settings is efficient definition of a large number of different types of services. The presented solution supports efficient definition of services by using a combination of light weight service ontologies, efficient construction procedures and tools. In particular, machine-understandable descriptions of heterogeneous services with well defined syntax and semantics can be created by multiple designers, without complex coordination of collaborative design processes and without any knowledge of formal ontologies.	ontology (information science);service discovery	Ate Penders;Gregor Pavlin;Michiel Kamermans	2011	International Journal on Artificial Intelligence Tools	10.1142/S021821301100053X	computer science;knowledge management;artificial intelligence;service-oriented architecture;ontology;data mining	SE	-44.208171394173974	9.670670856265266	22707
2170cd6fee8db3d6bd7ca0b071a30d0c87f5fafd	business environment scanner for senior managers: towards active executive support with intelligent agents	strategic management;industry news business environment scanner senior managers active executive support intelligent software agent strategic management prototype system business information resources world wide web information retrieval pulp industry paper industry market information;business environment;pulp and paper industry;business data processing;environmental management information management knowledge management intelligent agent software agents software prototyping prototypes information resources web sites data mining;intelligent agent;world wide web;environmental scanning;intelligent software agent	A good knowledge and understanding of the busin environment is a basic premise for strateg management. A system that is able to help mana actively scan the environment will contribute to active executive support. This paper examines the relevanc the intelligent software agent approach in environmen scanning activities and exploits ways that an agent can help in accomplishing scanning tasks. It then describe prototype system that is currently under developm The system is designed to make use of potential bus environment information resource on the World Wide Web to extract useful information for managers. Us pulp and paper industry as a case context, it is showe this paper how the agent is constructed and how it provides up-to-date industry news and market information to managers.	intelligent agent;prototype;software agent;world wide web	Shuhua Liu	1998		10.1109/HICSS.1998.648292	executive information system;information technology management;environmental scanning;computer science;knowledge management;marketing;operations management;software engineering;database;information management;management;world wide web;intelligent agent;strategic management	AI	-51.66473232956863	11.265690364926238	22713
c6bf8c9a5e38c07a3feb894a3a6359da7dba006e	compositional structured component model: handling selective functional composition	software component;handling selective functional composition;software reuse;software development complexity;component functional composition;compositional structured component model;required functionalities;unwanted functionalities;software component technology;component model;unwanted component functionalities;software quality;object oriented programming;functional requirement;software metrics;software development	Software component technology has been promoted as an innovative means to tackle the issues of software reuse, software quality and, software development complexity. Several component models (CORBA, .Net, JavaBeans) have been introduced, yet certain issues and limitations inherent to components still need to be addressed. As software components with hosts of functionalities tend to be coarse to large-grained in size and since the set of functionalities required by an application varies according to the particular application context, an excessive number of unwanted functionalities might be generated by such components within the application. We present the compositional structured component model (CSCM) designed to handle the issue of unwanted component functionalities and to provide a flexible approach for easier customization, adaptation, and reuse. The CSCM model is designed to handle this issue via component functional composition using metadata composition instances, which allow selective composition of a component's required functionalities.	.net framework;code reuse;common object request broker architecture;component-based software engineering;context (computing);software development;software quality	Hamdan Msheik;Alain Abran;Eric Lefebvre	2004	Proceedings. 30th Euromicro Conference, 2004.	10.1109/EURMIC.2004.1333358	long-term support;verification and validation;software sizing;computer science;systems engineering;package development process;backporting;software design;social software engineering;software framework;component-based software engineering;software development;software design description;software construction;database;software walkthrough;programming language;resource-oriented architecture;software measurement;software deployment;software quality;software system	SE	-52.815150116433756	29.88202464498105	22809
50412dea7b94067bf604674da3d9b54cebeb6d25	slmc: a tool for model checking concurrent systems against dynamical spatial logic specifications	qa75 electronic computers computer science	The Spatial Logic Model Checker is a tool for verifying π-calculus systems against safety, liveness, and structural properties expressed in the spatial logic for concurrency of Caires and Cardelli. Model-checking is one of the most widely used techniques to check temporal properties of software systems. However, when the analysis focuses on properties related to resource usage, localities, interference, mobility, or topology, it is crucial to reason about spatial properties and structural dynamics. The SLMC is the only currently available tool that supports the combined analysis of behavioral and spatial properties of systems. The implementation, written in OCAML, is mature and robust, available in open source, and outperforms other tools for verifying systems modeled in π-calculus.	concurrency (computer science);interference (communication);liveness;model checking;ocaml;open-source software;software system;structural dynamics;verification and validation	Luís Caires;Hugo Torres Vieira	2012		10.1007/978-3-642-28756-5_35	real-time computing;computer science;theoretical computer science;distributed computing;programming language;algorithm	SE	-36.98431354486952	31.571299731092427	22864
aeee5e36ebd961813742d32b51f188e4768f619a	a knowledge retrieval model using ontology mining and user profiling	knowledge retrieval ontology user profiles personalization information retrieval;080107 natural language processing;080708 records and information management excl business records and information management	Over the last decade, the rapid growth and adoption of the World Wide Web has further exacerbated the user need for efficient mechanisms for information and knowledge location, selection and retrieval. Much research in the area of semantic web is already underway, adopting information retrieval tools and techniques. However, much work is required to address knowledge retrieval; for instance, users’ information needs could be better interpreted, leading to accurate information retrieval. In this paper, a novel computational model is proposed for solving retrieval problems by constructing and mining a personalized ontology based on world knowledge and a user’s Local Instance Repository. The proposed model is evaluated by applying to a Web information gathering system, and the result is promising. ∗X. Tao, Y. Li, and R. Nayak are with the Faculty of Information Technology, Queensland University of Technology, Australia. Emails: {x.tao, y2.li, r.nayak}@qut.edu.au	commonsense knowledge (artificial intelligence);computation;computational model;document;email;information needs;information retrieval;knowledge base;knowledge level;library of congress subject headings;personalization;semantic web;sensitivity and specificity;test set;user profile;world wide web	Xiaohui Tao;Yuefeng Li;Richi Nayak	2008	Integrated Computer-Aided Engineering		document retrieval;question answering;relevance;cognitive models of information retrieval;image retrieval;computer science;data mining;adversarial information retrieval;world wide web;data retrieval;information retrieval;human–computer information retrieval	AI	-41.45495705336398	6.7245075317223915	22967
1065928e5e4a9791032bfd394a60a1ea21967a95	automated recommendations for reducing unnecessary variability of technology architectures		A technology architecture (TA) represents the technical infrastructure of a company and consists of hardware and software components. As the evolution of such TAs is typically uncoordinated, their complexity often grows with a company’s requirements. As a consequence, a variety of redundancies and architectural variants exist, which are not necessary for the architecture’s purpose. This leads to increased costs and higher effort for evolving and maintaining the entire IT landscape. To alleviate these problems, unnecessary variability has to be identified and reduced. As a manual approach requires high effort and is not feasible for largescale analysis, experts face a major challenge. For this purpose, we propose an automated approach, which provides experts with recommendations for restructurings of related TAs in order to reduce unnecessary variability. We show suitability of our approach by expert interviews and an industrial case study with real-world TAs.	component-based software engineering;computer hardware;requirement;spatial variability	Kenny Wehling;David Wille;Christoph Seidl;Ina Schaefer	2017		10.1145/3141848.3141849	computer science;software engineering;systems engineering;component-based software engineering;real-time computing;architecture;architectural technology	SE	-60.18718855894115	21.811517850681366	23005
0b442bc02e32b4637b5d013b123a64d6d2646e90	software is a directed multigraph (and so is software process)	project manager;software systems;software engineering;development methodology;system management;software process	For a software system, its architecture is typically defined as the fundamental organization of the system incorporated by its components, their relationships to one another and their environment, and the principles governing their design. If contributed to by the artifacts coresponding to engineering processes that govern the system’s evolution, the definition gets natually extended into the architecture of software and software process. Obviously, as long as there were no software systems, managing their architecture was no problem at all; when there were only small systems, managing their architecture became a mild problem; and now we have gigantic software systems, and managing their architecture has become an equally gigantic problem (to paraphrase Edsger Dijkstra). In this paper we propose a simple, yet we believe effective, model for organizing architecture of software systems. First of all we postulate that only a hollistic approach that supports continuous integration and verification for all software and software process architectural artifacts is the one worth taking. Next we indicate a graph-based model that not only allows collecting and maintaining the architectural knowledge in respect to both software and software process, but allows to conveniently create various quantitive metric to asses their respective quality or maturity. Such model is actually independent of the development methodologies that are currently in-use, that is it could well be applied for projects managed in an adaptive, as well as in a formal approach. Eventually we argue that the model could actually be implemented by already existing tools, in particular graph databases are a convenient implementation of architectural repository.	capability maturity model;continuous integration;graph database;multigraph;organizing (structure);software development process;software system	Robert Dabrowski;Krzysztof Stencel;Grzegorz Timoszuk	2011	CoRR		reference architecture;personal software process;verification and validation;systems management;software engineering process group;software sizing;architectural pattern;computer science;systems engineering;engineering;package development process;software design;social software engineering;component-based software engineering;software development;software design description;software engineering;software construction;software walkthrough;resource-oriented architecture;software deployment;goal-driven software development process;software development process;software metric;software system;computer engineering	SE	-54.85749002233615	24.75136806436503	23025
166f6970b6fa18ee1dc58b481cbe779b16e17be5	electric grid disaster response management — a systems of systems engineering approach		As customer outage counts escalate and demand for service restoration becomes daunting and dynamic, electric utility restoration resources utilization becomes more and more challenging during natural disasters. System status information exchange between operators, intelligent electronic devices (IEDs), restoration analysts, and field crews is handled mainly by the Outage Management System (OMS) and the Supervisory Control and Data Acquisition (SCADA) processes. The intrinsic use of OMS and SCADA processes in managing field resources presents strain in restoration efforts. This research employs the concept of a Location Set Covering Problem (LSCP) to solve the problem of a centralized SCADA managing distributed field resource activities. A decentralized SCADA solution with the use of substation nodes in the electric grid network is presented to demonstrate a reduction in travel distance by first responders. This is implemented through a Multi Agent Systems (MAS) approach that combines the use of Specific Points of Contact (SPOCs) with the aid of Unmanned Aerial Vehicles (UAVs) and the confluence of Regional Mutual Assistance Groups (RMAGs). The proposed multi-agent architecture will be implemented using the Electric Power Research Institute (EPRI) IntelliGrid layered model. A modified architectural perspective using the International Electrotechnical Commission (IEC) 61850 standard is developed to identify the physical and functional architectures and linkages between the constituent systems for improved restoration practices. A System of Systems (SoS) perspective to analyze the subsystems from a logistical, technical, and operational viewpoint is presented using SysML. A unique framework that integrates qualitative and quantitative analysis of response and recovery practices for improved restoration practice by electric utility entities is developed.	aerial photography;agent architecture;apple sos;centralized computing;circuit restoration;confluence;content management system;data acquisition;downtime;entity;grid network;information exchange;logistics;multi-agent system;order management system;set cover problem;system of systems;systems modeling language;systems engineering;traction substation;unmanned aerial vehicle	Abdulai H. Kargbo;Timothy Eveleigh;Bereket Tanju	2018	2018 Annual IEEE International Systems Conference (SysCon)	10.1109/SYSCON.2018.8369557	architecture;system of systems;systems engineering;outage management system;electric utility;electric power;multi-agent system;systems modeling language;computer science;scada	Robotics	-58.915575079237755	4.227399424651197	23121
56f259bfdc0490fe5975db1c2d2113c6657fe6d4	roost: reference ontology on software testing		Software testing is a complex and critical process for achieving product quality. Its importance has been increasing and well recognized, and there is a growing concern in improving the accomplishment of this process. In this context, Knowledge Management (KM) emerged as an important supporting approach to improve the software testing process. However, managing relevant testing knowledge requires effective means to represent and to associate semantics to a large volume of testing information. To address this concern, we have developed a Reference Ontology on Software Testing (ROoST). ROoST establishes a common conceptualization about the software testing domain, which can serve several KM-related purposes, such as defining a common vocabulary for knowledge workers with respect to the testing domain, structuring testing knowledge repositories, annotating testing knowledge items, and for making search for relevant information easier. In this paper, we present ROoST, and we discuss how it was developed using two ontology pattern languages. Moreover, we discuss how we evaluated ROoST following four complementary approaches: assessment by humans, data-driven evaluation, ontology testing, and application-based evaluation.	axiomatic system;conceptualization (information science);configuration management;core ontology;documentation;independent computing architecture;information repository;knowledge management;mmh-badger mac;on-board data handling;ontology (information science);open programming language (opl);pattern language;pattern language (formal languages);reference model;requirement;sequence alignment;software engineering;software requirements;software testing;vocabulary;web ontology language	Érica Ferreira de Souza;Ricardo de Almeida Falbo;Nandamudi Lankalapalli Vijaykumar	2017	Applied Ontology	10.3233/AO-170177	computer science;data mining;database;world wide web	SE	-44.32337070883478	5.731787615218471	23133
dcd9604f716e9235236d3aa956cce6bef6c893cc	managing complexity and variability of a model-based embedded software product line	variability modelling;model transformation;complexity;info eu repo semantics article;traceability;software product lines	This paper presents a framework for model-based product lines of embedded systems. We show how to integrate model-based product line techniques into a consistent framework that can deal with large product lines as they are common in industry. The framework demonstrates the strengths of model-based techniques like abstraction, support for customised representations, and a high degree of automation. In particular, we provide the following contributions: (1) to shift existing product lines towards a model-based approach, we support the (semi-) automated extraction of models from existing requirement, test, and implementation artefacts; (2) to cope with the complexity of artefacts and their interrelations in industrial product lines, we support the generation of context-specific views. These views support developers, e.g., in analysing complex dependencies between different artefacts; (3) finally, we support automated product derivation based on an integrated hardware abstraction layer. Most of the presented concepts have been inspired by challenges arising in the industrial application of product line techniques in the model-based engineering of embedded systems. We report on experiences gathered during the application of the techniques to a prototypical product line (on a rapid prototyping platform in the university lab) and to industrial sample cases (at the industry partner).	abstraction layer;cognitive complexity;domain-specific language;embedded software;embedded system;fits;fault tolerance;feature model;hardware abstraction;heart rate variability;matlab;model transformation;rapid prototyping;simulink;software engineering;software product line;toolchain;visual editor	Andreas Polzer;Daniel Merschen;Goetz Botterweck;Andreas Pleuß;Jacques Thomas;Bernd Hedenetz;Stefan Kowalewski	2011	Innovations in Systems and Software Engineering	10.1007/s11334-011-0174-z	traceability;complexity;simulation;computer science;systems engineering;engineering;operating system;product engineering	SE	-56.494651740537556	26.085310677143898	23177
aae144a99e714a1e6d61fc296a704af7f26cc636	features and algorithms for tooling cost evaluation for stamping	tooling cost evaluation		algorithm	Prashant V. Mahajan;Corrado Poli;David W. Rosen;Michael J. Wozny	1993			operations management;engineering drawing;manufacturing engineering	HCI	-59.28328492716263	8.399537141871388	23186
2f4ba46a319503f90b58349d6eb9fde9ee3a459b	materializing architecture recovered from object-oriented source code in component-based languages		In the literature of software engineering, many approaches have been proposed for the recovery of software architectures. These approaches propose to group classes into highly-cohesive and loosely-coupled clusters considered as architectural components. The recovered architecture plays mainly a documentation role, as high-level design views that enhance software understandability. In addition, architecture recovery can be considered as an intermediate step for migration to component-based platforms. This migration allows to fully benefit from all advantages brought by software component concept. For that, the recovered clusters should not be considered as simple packaging and deployment units. They should be treated as real components: true structural and behavior units that are instantiable from component descriptors and connected together to materialize the architecture of the software. In this paper, we propose an approach for revealing component descriptors, component instances and component-based architecture to materialize the recovered architecture of an object-oriented software in component-based languages. We applied our solution onto two well known component-based languages, OSGi and SOFA.	component-based software engineering	Zakarea Alshara;Abdelhak-Djamel Seriai;Chouki Tibermacine;Hinde-Lilia Bouziane;Christophe Dony;Anas Shatnawi	2016		10.1007/978-3-319-48992-6_23	natural language processing;computer science;programming language	PL	-52.66163326112734	29.756472472496448	23295
8736f5d07dfae83e9e71070ea6a7919b0a8f09c8	activities: abstractions for collective behavior	object oriented model;collective behavior;information system	"""code component. A pattern represents the core of a solution to similar recurring problems, comprising a general arrangement of classes/objects (Gamma et al. 94). Design patterns are more abstract design elements than frameworks (they may be applied in the construction and design of a framework) and their architectural granularity is ner. The activity is a modelling and programming mechanism that may be used to describe a wide variety of programs and program fragments, abstract or concrete. It is an abstraction mechanism, able to be used to create abstractions of varying de nition { from the more abstract/general (design patterns) to the more concrete (frameworks). This abstraction mechanism enables us to have another basic component in the design vocabulary we use when creating such abstractions. Frameworks, design patterns and abstraction mechanisms are also used differently in the program development process. The universe of frameworks and design patterns is not, by nature, nite. Therefore, it will be necessary to search for and identify appropriate frameworks/design patterns that may be applicable to the problem. In the case of a framework, you will need to understand its functionality and how to customize it. With design patterns, it is necessary to recognize the context in which a pattern could be applied and how it should be realized in a concrete design. An abstraction mechanism forms part of the language. It is therefore fundamental in its in uence on how we conceive the world around us, how we initially form our understanding, and then later in expressing it. Such mechanisms give us a basic lexicon with which we can describe higher-level, structured abstractions { like frameworks and design patterns. Card Games and C++. The activity abstraction was investigated in a project described in (May 94). The objective of the project was to explore issues related to the design and construction of object-oriented frameworks { the C++ language was used to build software artifacts through the course of the project. The problem domain on which the study concentrated was that of card games, namely, designing a framework for writing card game applications. Several pieces of software were produced: a Blackjack game (to gain experience in the problem area), a card game framework, and a Five Hundred game. We explored the activity abstraction to address the issue of representing more complicated sequences of interplay yet simplifying their complexity. A framework for activities was created, which later became the basis for a card game framework. This was eventually used to create the Five Hundred game. Limitations were encountered using C++. In its `standard' form, the language lacks multi-sequential and concurrent mechanisms { it is not possible to properly represent multiple executing active objects or reactive activities. Further, there is no support for locality. Overall, the project indicated that most mainstream object-oriented languages had little support for the facilities required to accurately simulate activities. While activities could be implemented in such languages, the absence of such support will result in an implementation solution that does not properly match the design solution { and is less intuitive. Languages should provide more exible constructs (e.g. sub-method inheritance, locality, roles) to enable the design model to be implemented and communicated in a far more natural way. Conference Organizing and the Mediator. The activity abstraction was compared to design patterns, especially the Mediator (Gamma et al. 94), in an implementation project. Descriptions of a subset of a conference organizing system was developed and compared. The intent of the Mediator pattern is to \De ne an object that encapsulates how a set of objects interact. Mediator promotes loose coupling by keeping objects from referring to each other explicitly, and it lets you vary their interaction independently"""". Mediator ConcreteMediator ConcreteColleague1 Colleague ConcreteColleague2 Mediator Fig. 23. Structure of the Mediator Pattern In Fig. 23 the structure of the Mediator pattern is reproduced. The Mediator class corresponds to an activity and the Colleague classes to participants. The ConcreteMediator class implements cooperative behaviour by coordinating Colleague objects, and knows and maintains its colleagues. Each Colleague class knows its Mediator object, and each Colleague class communicates with its mediator whenever it would have otherwise communicated with another colleague. From our description in the experiment, the Mediator pattern appears to be similar to how we characterise the collective behavior of activities. Indeed, there is centralisation of control into an object { which manages the interaction between other objects. But while the overall architectural techniques are similar, motivation and focus for collective behavior is di erent. At its heart, the design pattern aims to provide an abstract, general design solution to a set of problems. It is structured to be less well-de ned and more informal. In short, it is an abstraction that is not supposed to be set in concrete: its malleability and generality is its strength. On the other hand, our approach has been at a more elemental and atomic level. The purpose of our research was to inquire into the nature of interaction { rst, our intuitive understanding, then mapping into an object-oriented domain. We have therefore characterised and de ned how we picture activities: the ways in which object-oriented concepts may be applied to them, and how they relate to each other and their participants. The activity is an abstraction mechanism { a type of brick that can be used to build abstractions. In the same way that a class is used to create abstractions (like design patterns), the activity is used as well-de ned component in constructing abstractions. In short, the activity is a mechanism that is supposed to be capable of extension, but well-de ned and less vague. Similar to the class, it is used `as is' rather than requiring a mapping into speci c domains (like design patterns). Therefore, it is possible to envisage building libraries of components that have been constructed using activities (and other mechanisms). The nature of this abstraction mechanism covers the ambit of modelling and programming languages. Thus, we can use activities as building mechanisms in creating modelling abstractions then isomorphically map into a concrete language. Furthermore, the emphasis of the Mediator pattern is to promote loose coupling and encapsulate object interaction. The activity abstraction mechanism also seeks to give force to these goals; of themselves, they are useful and worthwhile objectives. But the emphasis of our inquiry was to represent and give force to the properties of interaction { collective and otherwise. We also investigated beyond the generalised object arrangement scheme embodied by the Mediator. The present paper looks at a dichotomy of how activities can be classi ed into initiating and reactive forms, how they may exploit the power of object-oriented properties in a natural fashion, and supporting the characteristics of activities using concepts such as relations and roles. This clearly exceeds the scope and de nition of the Mediator pattern. In essence, activities are used to build abstractions { solutions. 5 Summary The underlying assumption in this paper is that in existing object-oriented methodologies and languages, objects appear as isolated elements with an implicit and poor description of the interplay structure between them. However, as human beings we identify such interplay structures as another kind of phenomena { usually known as activities { and inspired of this kind of phenomena we introduce an abstraction mechanism, which may be used to model the interplay structures. This language mechanism { the activity { is expressive and powerful for the modeling of organization and interplay of usual objects, { the collective behavior of objects. Related Work. While not discussed explicitly, collective activities are within the ambit of Booch's description of an object (Booch 94): \tangible and/or visible thing; something capable of intellectual apprehension; and something toward which thought or action is directed"""". Most pointedly, \an object models some part of reality and is therefore something that exists in time and space"""". In OMT (Rumbaugh et al. 91) the dynamic model is a collection of state diagrams that interact via shared events. A state diagram describes the life cycle of a class of objects { but only from a local perspective. State diagrams are also related to the object structure: the aggregation of objects implies the aggregation of the state diagrams of these objects, resulting in composite states; the specialization of classes implies that a subclass inherits the state diagram of its superclass and together with the state diagram added it works as a composite of concurrent state diagrams. Responsibilities, collaborations, and contracts from (Wirfs-Brock et al. 90) de ne the dependencies between objects and subsystems. However, these are only concerned with the static dependencies, and there is no support for the description of the dynamic interplay between them. Use cases from (Jacobson et al. 92) models system functionality. Use cases { with actors of various kinds { are abstractions of the user's interaction with a system. The actor and system in dialogue is a sequence of transactions each initiated by some stimulus from the actor. An actor may be involved in a number of use cases. A user is seen as an instantiation of an actor, and an actual execution of an interaction session with a user is seen as an instantiation of a use case. This instantiation yields an object. A use case is described by a state transition graph, and user stimuli imply state changes. The description of a use case is organized as a basic course and seve"""	ambit;blackjack;brick (electronics);c++;centralisation;complexity;design pattern;elemental;gamma correction;james rumbaugh;lexicon;library (computing);locality of reference;loose coupling;mathematical model;mediator pattern;organizing (structure);partial template specialization;problem domain;programming language;simulation;state diagram;state transition table;universal instantiation;vagueness;vocabulary	Bent Bruun Kristensen;Daniel C. M. May	1996		10.1007/BFb0053074	simulation;human–computer interaction;computer science;collective behavior;information system	SE	-36.99411584704138	19.52242990758885	23303
7513c3fc018fff03e0a766a1f6b0a3807b845297	valid: custom asic verification and fpga education platform	fpga development platform;microprocessors;student designed system;field programmable gate array;fpga instruction platform valid custom asic verification application specific integrated circuits fpga education platform field programmable gate array student designed system teaching fpga design fpga development platform;custom asic verification;testing;fpga;sockets;application specific integrated circuits field programmable gate arrays hardware microprocessors testing linux throughput education sdram sockets;ease of use;application specific integrated circuits;fpga design;electronic engineering education;field programmable gate arrays teaching testing electronic engineering education application specific integrated circuits;linux;asic;field programmable gate arrays;valid;fpga instruction platform;fpga education platform;sdram;teaching;throughput;hardware	This paper describes VALID, a platform for testing student designed ASICs and for teaching the basics of FPGA design. VALID is designed to maximize ease of use from a student’s perspective while maintaining enough flexibility for its use as an FPGA development and instruction platform. This system was designed entirely by students, has been successfully manufactured and is currently being used in a number of courses at Rice.	application-specific integrated circuit;field-programmable gate array;usability	Patrick Murphy;J. Patrick Frantz;Erik Welsh;Ricky Hardy;Tinoosh Mohsenin;Joseph R. Cavallaro	2003		10.1109/MSE.2003.1205257	education;embedded system;computer architecture;computer science;engineering;fpga prototype;field-programmable gate array;computer engineering	Mobile	-53.84984436369155	4.516889891305499	23362
84048a6ab59fdab3162b40cd2bfca6806d0a4312	a multi-agent framework for dependable adaptation of evolving system architectures	runtime environment;computational modeling;engines;mathematical model;context;component architectures	We present a multi-agent framework for the formal verification of component-based systems after changes such as addition, removal and modification of components. The core of our approach is an Agent Verification Engine (AVE) that constructs evolvable Belief-Desire-Intention (BDI) agents to coordinate and plan the re-verification of component models after system changes. The engine provides BDI-agents with existing techniques for the compositional verification of component-based systems. We illustrate this integration for Satisfiability Modulo Theories (SMT) constraint analysis and demonstrate our framework on requirements arising from industrial control systems.	belief–desire–intention software model;component-based software engineering;control system;formal verification;modulo operation;multi-agent system;requirement;satisfiability modulo theories	Kenneth Johnson;Roopak Sinha;Radu Calinescu;Ji Ruan	2015	2015 41st Euromicro Conference on Software Engineering and Advanced Applications	10.1109/SEAA.2015.49	real-time computing;computer science;systems engineering;theoretical computer science;mathematical model;runtime verification;computational model;statistics	SE	-42.26754517598072	32.18135097676822	23385
e431efc5f4eaa51817afcf31c28623e83f425954	standardised model data exchange for dispersed systems engineering design teams	system engineering;standardisation;data exchange	The engineering of systems has always been a multi-disciplinary activity carried out by teams of engineers operating within different domains of expertise. The paper discusses work in developing standardised approaches to systems engineering tool data exchange and developments which will support globally dispersed teams. The paper begins with a brief overview of the domain of systems engineering and the issues involved in exchanging Systems Engineering (SE) models. It discusses the SEDRES Project, a European project which developed an appropriate SE data model and transitioned it into the ISO, where it has become Application Protocol AP-233, within the ISO 10303 STEP environment. Other issues were raised within the SEDRES Project, and the results of experiments into the effectiveness of the system are discussed.	engineering design process;systems engineering	David Harris	2000			system of systems engineering;systems engineering;engineering;mechanical engineering	DB	-62.313738753127666	15.362325608906762	23392
7229389c5edbc10346ca680b4cabe6fa74a07eec	a wsan solution for irrigation control from a model driven perspective	domain specific languages;precision agriculture.;model driven approach	Wireless Sensor and Actor Networks (WSAN) constitute a growing research field in several engineering areas. One very interesting domain of WSAN application is precision agriculture, and in particular, the automatic control of tree irrigation depending on sap flow levels. Nowadays, the software development process followed in these kinds of applications is largely dependent on the platform where the final implementation is done. Consequently, commonly desired attributes such as flexibility, reuse and evolution are relegated to a second level of priority. Nevertheless, the growing interest in WSAN has been led to advances from different points of view: new application domains, new middleware, new simulation environments, and so on. In spite of all these advances, WSAN development is today needed of concrete mechanisms that make easy the software generation process. This paper summarizes our contribution in this field from two points of view: as an agronomic solution and as new opportunities for affording the construction of these systems taking into consideration the most recent advances in software engineering.1.	application domain;automatic control;code generation (compiler);compiler;digital subscriber line;domain engineering;domain-specific language;middleware;mike lesser;model-driven architecture;model-driven engineering;simulation;software development process;software engineering;virtual artifact	Fernando Losilla;Pedro Sánchez;Cristina Vicente-Chicote;Bárbara Álvarez;Andrés Iborra	2007			water resource management	SE	-60.225317332588624	20.695981896949856	23398
a639a7853576b9bbec3bcad003fd32a5b554d378	orthogonal relations for reasoning about posets	distributed system;orthogonality;representacion conocimientos;systeme reparti;relation ordre partiel;abstraction;sistema complejo;abstraccion;sistema repartido;systeme complexe;complex system;causalite;partial ordering;relacion orden parcial;knowledge representation;representation connaissances;orthogonalite;causality;causalidad;ortogonalidad	In large distributed systems, event abstraction becomes an important issue in order to represent interactions and reason at the right level of abstraction. Abstract events are collections of more elementary events, which provide a view of the system execution at an appropriate level of granularity. Understanding how two abstract events relate to each other is a fundamental problem for knowledge representation and reasoning in a complex system. In this paper, we study how two abstract events in a distributed system are related to each other in terms of the more elementary causality relation. Specifically, we analyze the ways in which two abstract events can be related to each other orthogonally, that is, identify all the possible mutually independent relations by which two such events could be related to each other. © 2002 Wiley Periodicals, Inc.	agent-based model;causality;colocation centre;complex system;distributed computing;elementary;interaction;john d. wiley;knowledge representation and reasoning	Ajay D. Kshemkalyani;Roshan Kamath	2002	Int. J. Intell. Syst.	10.1002/int.10062	partially ordered set;knowledge representation and reasoning;complex systems;causality;orthogonality;computer science;artificial intelligence;mathematics;abstraction;algorithm	AI	-38.206825720240644	24.860147764879304	23421
d0d0a00fbe6bc3bda27e422676c990368ed0ac87	sisi in the alps: a simple simulation and verification approach for pass		Originally developed as a simple static computation tool (Simple Sim - SiSi), in this paper we describe the principle behind a pragmatic approach that is not only practical for simple calculation of lead times for process models in Abstract Layered PASS (ALPS), but also can serve as tool of structural soundness verification for the distributed and somewhat fractured descriptions of this subject-oriented process modeling language. It is the foundation for the first deployed tool that can handle soundness verification all of PASS including the multi-subject construct.	application-level profile semantics (alps);computation;modeling language;process modeling;simulation	Matthes Elstermann;Jivka Ovtcharova	2018		10.1145/3178248.3178262	systems engineering;theoretical computer science;computation;soundness;computer science;process modeling	Logic	-44.259856533053295	28.399880531226795	23424
b9cad2af1ce2a235b92335757bcb5af4a2f0d12c	a multiple product line development method based on variability structure analysis		This article proposes a multiple product line development method based on variability structure analysis. In product line development, the problem area is divided into the domain engineering and application engineering for delivering diverse products. Now, the development of automotive software requires to meet both agility and extreme diversity, which is a big challenge. We developed a structural analysis method of variability for multiple product lines using an extended model of OVM (Orthogonal Variability Model). Together with the variability analysis method, we propose an agile application development method to refine development items according to variability dependency based on the analysis, and develop them incrementally. We applied the proposed method to the development of the multiple product lines of automotive software systems, and demonstrated to reduce the volatility of the test efforts and usage of the test environment, and higher velocity and better manageability of the value stream.	agile application;agile software development;automotive software;deployment environment;domain engineering;heart rate variability;open verification methodology;software system;spatial variability;structural analysis;velocity (software development);volatility	Kengo Hayashi;Mikio Aoyama	2018		10.1145/3233027.3233048	control engineering;computer science;domain engineering;systems engineering;automotive software;software product line;agile software development;value stream mapping;agile application	SE	-56.409088146984196	25.875402654620984	23427
e290d1d42c463b952bd158cef33850ca79d26351	moov++: a methodology for formally developing object-oriented specifications	object oriented			Quentin Charatan	1999			software engineering;computer science;theoretical computer science;distributed computing;object-oriented programming	PL	-39.25329029773392	28.23046394859167	23463
448607ba3c39ba194111b42f1062cd69b9b3ec12	animated transitions between user interface views	institutional repositories;user interface development;fedora;web pages;life cycle;user interface;user interface view;user interface development method;vital;multiple views;integrated development environment;model evolution animation;levels of abstraction;animation;model driven engineering;abstract user interface;vtls;animated transition;animal model;ils	User interface development life cycle often involve several different views of the user interface over time either at the same level of abstraction or at different levels of abstraction. The relationship between these different views is often supported by tiling coordinated windows containing these related views simultaneously, thus leaving the developer with the responsibility to effectively and efficiently link the corresponding elements of these different views. This paper attempts to overcome the shortcomings posed by the coordinated visualization of multiple views by providing UsiView, a user interface rendering engine in which one single window ensures an animated transition between these different user interface views dynamically an internal view, an external view, and a conceptual view. Examples include the following cases: an authoring environment ensures an animated transition between an internal view (e.g., HTML5) and its external view (e. g., a web page), an Integrated Development Environment ensures an animated transition between its conceptual view and its external view; a model-driven engineering environment ensures an animated transition between the conceptual view at different levels of abstraction, e.g., from task to abstract user interface to concrete user interface until final user interface. The paper discusses the potential advantages of using animated transitions between user interface views during the development life cycle.	html5;integrated development environment;layout engine;microsoft windows;model-driven engineering;principle of abstraction;software development process;tiling window manager;user interface;web page	Charles-Eric Dessart;Vivian Genaro Motti;Jean Vanderdonckt	2012		10.1145/2254556.2254623	anime;biological life cycle;model-driven architecture;simulation;human–computer interaction;computer science;operating system;software engineering;web page;multimedia;natural user interface;user interface;world wide web	HCI	-48.16244077153039	22.72265715593005	23474
c5b81adf3c6fd2f06b0c2f6c31b4a7ff60f1d433	a study on renovative plan for engineering educational curricula and courses for soc(system on chip) design architects in korea's it industry	integrated circuit design;system on chip;educational courses;engineering education;design engineering system on a chip educational programs educational institutions educational technology systems engineering education electrical engineering computing computer science education government engineering management;electronic engineering education;technical needs engineering educational curricula engineering courses system on chip soc design practical skills industrial needs;integrated circuit design electronic engineering education educational courses system on chip	This study aims to develop a new SoC design engineering curricula for graduate schools. The new curricula focuses on fostering practical skills in order to meet technical and industrial needs.		Eunok Kim;Janghyun Park	2005	2005 IEEE International Conference on Microelectronic Systems Education (MSE'05)	10.1109/MSE.2005.14	system on a chip;engineering management;embedded system;electrical engineering technology;health systems engineering;engineering education;computer science;systems engineering;engineering;electrical engineering;computer engineering;integrated circuit design	Robotics	-54.856138012989035	4.940407649820938	23526
0f867397ef60a8da2ac367c0cfec10ed81a2dc63	a study on modeling of multi-agent collaboration in virtual enterprise based on extended uml	protocols;multi agent system;virtual enterprises;collaboration uml virtual enterprise multi agent system;uml;task allocation multi agent collaboration virtual enterprises unified modeling language contract net protocol;contract net protocol;linear array;collaboration;virtual enterprises unified modeling language object oriented modeling collaborative tools multiagent systems software engineering collaborative software international collaboration collaborative work computer science;contracts;joints;production management;multi agent systems;unified modeling language;virtual enterprise;multi agent collaboration;object oriented modeling;virtual enterprises multi agent systems production management unified modeling language;multiagent systems;task allocation;binary tree	Through extending the graphical and semantic elements of UML message, and using UML to construct the mechanism of multi-agent cooperation based on contract-net protocol, an extended UML based multi-agent collaboration model for task allocation in virtual enterprise (VE) is proposed. As UML is a kind of standard unified modeling language, the model is endowed with some good properties, such as visualization, easy to understand and so on.	contract net protocol;graphical user interface;knowledge query and manipulation language;multi-agent system;unified modeling language;virtual enterprise	Jiang Zi-bin	2008	2008 International Conference on Computer Science and Software Engineering	10.1109/CSSE.2008.1498	unified modeling language;uml state machine;uml tool;computer science;knowledge management;artificial intelligence;element;applications of uml;class diagram;multi-agent system;database;shlaer–mellor method;node;object constraint language	SE	-41.55313614844489	18.479618541860734	23533
69878f14e56c88f01481195250d682d58ab7c993	degree of freedom &#8213; experience of applying software framework	virtual system development team software framework software factories;software;system design management;software maintenance;degree of freedom;software systems;design implementation gap control;programming implementation staff;systems analysis software development management;software framework application;object oriented programming;global virtual system development;virtual system development team;side effect;design and implementation;systems analysis;system design;programming profession;production facilities;user requirements;software framework;system development;design implementation team;software tools;development standardization;computer science;programming profession computational intelligence society computer science software maintenance productivity software systems production facilities software tools documentation object oriented programming;productivity;factories;software factories;software development management;development standardization software framework application programming implementation staff global virtual system development design implementation team system design management design implementation gap control;documentation;computational intelligence society	Programming in the large (PITL) is a major challenge for global virtual system development team. One of the issues is the control and management between the design and implementation teams. Ideally, a design team do a system design based on user requirements and an implementation team, supposedly, implement the design. It is hard to enforce the implementation team to follow the design closely especially when the teams are in different geographical locations and in different time zones. We observe that one major cause of this design implementation gap lies in the degree of freedom given to the implementation developers. Given a design, the implementation staff has too many ways to implement it. We adopted software framework in our practice to standardize developments, to reuse major components and eventually to improve the productivity and maintainability of code. However, the side effect of adopting framework comes out as a surprise. It actually enables us to manage and control the design implementation gap more effectively and efficiently	entity name part qualifier - adopted;requirement;reuse (action);software framework;systems design;user requirements document;teams	Wang-chan Wong;Mohammad Eyadat;Shane Ng	2006	Third International Conference on Information Technology: New Generations (ITNG'06)	10.1109/ITNG.2006.48	systems analysis;productivity;documentation;computer science;knowledge management;software framework;software engineering;programming language;software maintenance;side effect	SE	-53.530328189091335	27.70049623066291	23535
b0cd3e5b2f40f9d51b4969a787091b903fc199cf	wise3: the third international workshop on intelligent software engineering (workshop session)	decomposition;composition;software engineering;separation of concerns	There is a growing realization that the design of effective software engineering tools must be smarter. Real world software specs can be very intricate. Manual browsing by a software engineer cannot reveal its subtleties. Automatic tools are required to reflect over business knowledge to identify what is missing or could be effectively changed. At the same time, many AI researchers now realize that software engineering provides the best testbed for AI tools and techniques. While these AI tools are all potentially useful, the core question remains: <italic>Which of these tools, if any, are truly cost-effective????</italic> A sample of these AI tools is listed below. For a further list of techniques, see the proceedings of WISE1 and WISE2. During analysis<list><item>Knowledge acquisition methods for requirements elicitation. </item><item>Knowledge representation methods for the business knowledge. </item><item>Non-classical logics for requirements engineering </item></list> During<list><item>Knowledge-based program synthesis. </item><item>Knowledge based techniques. </item><item>Knowledge-based validation techniques to detect bad semantics. </item><item>Theorem proving and formal reasoning for managing changing specs. </item></list> During<list><item>AI tools to maintain declarative and procedural knowledge. </item> <item>AI tools for program comprehension and reverse engineering. </item></list> The purpose of the WISE series is to assess the utility of the above technique WISE<list><item>Collect<italic>chaems</italic> in software engineering i.e.<list><item>A description of some task. </item> <item>A web site where researchers can download further materials on that task. </item><item>Any an initial solution including baselinures for effort and effectiveness of that solution. </item>  <item>Collectwar-stories of the application of novel technologies to the challenge problems </item><item>A careful and critical evaluation of the relative merits of different technologies for the challenge problems. </item></list> WISE4 and beyond would then encourage different solutions to these challenge problems. Our long-term goal (e.g. WISE6) is to foster the develop of some yet-to-be-funded rigorous evaluation experiment. To succeed in attracting that adequate funding, we must first build a strong community, clearly define the open issues, and develop good evaluation methods. To encourage all the above, the materials and challenge problems for WISE<supscrpt>3</supscrpt> are all collected together at http: //www.tim.menzies.com/wise3/. So, even if you miss WISE<supscrpt>3</supscrpt>, you can still download challenge problems and explore them for WISE4 and beyond.	declarative programming;download;hypertext transfer protocol;knowledge acquisition;knowledge representation and reasoning;knowledge-based systems;program comprehension;program synthesis;programming tool;requirement;requirements elicitation;requirements engineering;reverse engineering;software engineer;software engineering;testbed;utility	Tim Menzies	2000		10.1145/337180.337831	composition;separation of concerns;computer science;systems engineering;engineering;operating system;software engineering;data mining;decomposition;programming language;management	SE	-60.15339659930186	24.80391431294461	23544
c07ef27a7b28c00eaffeb38a3debcf742482961a	laser simulation - methods of pulse detection in laser simulation	data processing;centre of mass	This paper deals with the problem of laser simulation. At the beginning it gives a broader overview of the project of laser simulation which is processed at the University of West Bohemia. The simulation is described in several fundamental steps, a technique of data obtaining, processing and usage for the simulation is highlighted to understand the whole approach well. Three methods for automatic pulse detection are described in detail. Pulse detection is the main part of the pulse extraction, which is one of the most important data processing steps. The main idea of each described method is explained and their problems and possible ways of their elimination are discussed. At the end of the paper future plans for the project with the focus on the alternatives of system automation are introduced.	data pre-processing;experiment;preprocessor;simulation;spec#	Jana Hajková	2008			center of mass;computer science	AI	-60.57750886093256	4.334595022918862	23637
ac802df65dd0e5ee53352e4fa3619143da74eeef	reengineering legacy systems using web	hardware costs application software wrapping investments documentation software architecture iron libraries programming profession;software maintenance;software architecture systems re engineering software maintenance distributed programming software tools;maintenance cost;reengineering legacy systems web software development maintenance costs documentation software architecture web based development;software architecture;distributed programming;software development;software tools;legacy system;systems re engineering	There has been an increasing need to migrate legacy systems to new hardware and software development paradigms because legacy systems present problems such as high maintenance costs and lack of documentation. All organizations must overcome serious challenges if they are to remain competitive in today's fast changing business and technological environment. Legacy systems cannot evolve to provide new functionality, they run on obsolete hardware and maintenance is expensive. We have analyzed the different ways in which a Web based solution can be provided for the technological requirement of legacy systems and focus on Web-based development solutions. This research is implemented using a sound software architecture.	code refactoring;legacy system;world wide web	Rakesh Agarwal;Suresh Nayak;Sambit Mishra	2000		10.1109/CMPSAC.2000.884713	software architecture;software modernization;long-term support;verification and validation;computer science;systems engineering;engineering;package development process;backporting;software design;social software engineering;software framework;component-based software engineering;software development;software engineering;software construction;systems development life cycle;software analytics;resource-oriented architecture;software maintenance;software deployment;legacy system;software development process;software archaeology;software system;computer engineering;software peer review	NLP	-61.86269809874315	23.174930805975045	23643
b5b5d8916bb81ba4dca30557463583b5e2a0edc2	towards evolving constraints in data transformation for xml data warehousing	data integrity;satisfiability;data representation;functional dependency;data semantics;data transformation;data warehousing	Transformation of data is considered as one of the important tasks in data warehousing and data integration. With the massive use of XML as data representation and exchange format over the web in recent years, transformation of data in XML for integration purposes becomes necessary. In XML data transformation, a source schema and its conforming data is transformed to a target schema. Often, source schema is designed with constraints and the target schema also has constraints for data semantics and consistency. Thus, there is a need to see whether the target constraints are implied from the source constraints in data transformation. Towards this problem, we define two important XML constraints namely XML key and XML functional dependency(XFD). We then use important transformation operations to see if the source constraints are satisfied by the source document, then the target constraints are also satisfied by the target document. Our study is towards the utilization of constraints data integration and data warehousing in XML.	xml	Md. Sumon Shahriar;Jixue Liu	2009		10.1007/978-3-642-12082-4_11	data exchange;xml validation;xml encryption;simple api for xml;data quality;xml schema;data transformation;computer science;document structure description;data warehouse;xml framework;data integrity;data mining;xml database;xml schema;database;external data representation;functional dependency;xml signature;data transformation;xml schema editor;information retrieval;efficient xml interchange;satisfiability	DB	-34.940063019386464	6.820966914272841	23653
16df3de661602b7a6f70e1cdc4eddddc2bc43de4	a choice relation framework for supporting category-partition test case generation	resource constraint;program testing computer aided software engineering;choice relation table;specification based testing;swinburne;computer aided software engineering;software testing choice relation framework category partition test case generation category partition test case generation environment conditions test frames consistency checks resource constraints;test case generation;program testing;test case construction;consistency checking;test frame;computer aided software engineering software testing software maintenance spine software algorithms costs humans information technology australia computer science;article;choice relation framework;category partition testing	We describe in this paper a choice relation framework for supporting category-partition test case generation. We capture the constraints among various values (or ranges of values) of the parameters and environment conditions identified from the specification, known formally as choices. We express these constraints in terms of relations among choices and combinations of choices, known formally as test frames. We propose a theoretical backbone and techniques for consistency checks and automatic deductions of relations. Based on the theory, algorithms have been developed for generating test frames from the relations. These test frames can then be used as the basis for generating test cases. Our algorithms take into consideration the resource constraints specified by software testers, thus maintaining the effectiveness of the test frames (and hence test cases) generated.	algorithm;append;boolean algebra;delay line interferometer;digital light processing;emoticon;eventual consistency;http 404;iso 10303;internet backbone;lr parser;linked list;natural deduction;pointer (computer programming);real life;relational operator;software testing;test case	Tsong Yueh Chen;Pak-Lok Poon;T. H. Tse	2003	IEEE Trans. Software Eng.	10.1109/TSE.2003.1214323	reliability engineering;computer science;systems engineering;software engineering;programming language;computer-aided software engineering;test case;algorithm	SE	-47.677343349506444	19.51905892451723	23667
fe5e5445089c3896087c3c63d967a96139d979b0	pon-s: a systematic approach for applying the physics of notation (pon)	physics of notation;design process;ontology pattern languages;concrete syntax;business and economics;visual modeling language	Visual Modeling Languages (VMLs) are important instruments of communication between modelers and stakeholders. Thus, it is important to provide guidelines for designing VMLs. The most widespread approach for analyzing and designing concrete syntaxes for VMLs is the so-called Physics of Notation (PoN). PoN has been successfully applied in the analysis of several VMLs. However, despite its popularity, the application of PoN principles for designing VMLs has been limited. This paper presents a systematic approach for applying PoN in the design of the concrete syntax of VMLs. We propose here a design process establishing activities to be performed, their connection to PoN principles, as well as criteria for grouping PoN principles that guide this process. Moreover, we present a case study in which a visual notation for representing Ontology Pattern Languages is designed.	parse tree;pattern language (formal languages);visual modeling	Maria das Graças da Silva Teixeira;Glaice Kelly da Silva Quirino;Frederik Gailly;Ricardo de Almeida Falbo;Giancarlo Guizzardi;Monalessa Perini Barcellos	2016		10.1007/978-3-319-39429-9_27	computer science;systems engineering;theoretical computer science	SE	-53.26919027708585	23.706207596864466	23708
1707c3d6d637c79aefc9d06c8dd1d91bc8431718	special track on enterprise information systems: editorial message	customer relationship management;data stream;eca rules;information access;data mining;software engineering;enterprise content management;computer security;global economy;decision support system;enterprise integration;requirement engineering;event processing;enterprise information system;enterprise resource planning;business intelligence;document engineering;incomplete and failed events;knowledge base	Enterprise Information Systems are those intended to support business in the contemporary knowledge-based global economy. Therefore, developing and deploying these systems means to deal with complex and cross-disciplinary enterprise integration issues. EIS area embraces a plethora of subjects that range from Enterprise Resources Planning (ERP), Enterprise Content Management (ECM) and Customer Relationship Management (CRM) to Decision Support Systems and Business Intelligence. This track complements other SAC'2008 tracks such as Database Theory, Technology, and Applications, Data Mining, Data Streams, Document Engineering, e-Business Applications, Information Access and Retrieval, Organizational Engineering, Requirement Engineering, Software Engineering, and Computer Security, by stressing technology and business integration issues.	computer security;customer relationship management;data mining;database theory;document engineering;erp;electronic business;enterprise application integration;enterprise content management;enterprise information system;enterprise integration;enterprise resource planning;information systems;information access;requirements engineering;software engineering	Rogério Atem de Carvalho;Asterio Kiyoshi Tanaka	2008		10.1145/1363686.1363929	functional software architecture;document engineering;knowledge base;enterprise system;enterprise application integration;enterprise systems engineering;enterprise software;decision support system;nist enterprise architecture model;information engineering;computer science;knowledge management;three schema approach;complex event processing;integrated enterprise modeling;software engineering;digital firm;data mining;database;enterprise data management;enterprise architecture;business intelligence;enterprise integration;management;world wide web;computer security;enterprise planning system;enterprise information security architecture;enterprise information system;enterprise information integration;system integration;business architecture;enterprise life cycle	DB	-58.8396592757994	14.683929862481813	23727
33c51d7139be501e847177acd04589760fd002e4	uml to b: formal verification of object-oriented models	developpement logiciel;object oriented model;formal specification;systeme b;lenguaje uml;systeme critique;logiciel a securite critique;metodo formal;methode formelle;langage modelisation unifie;integrite;integridad;program verification;software engineering;b system;sistema reactivo;formal method;specification formelle;uml class diagram;especificacion formal;verificacion programa;formal verification;integrity;critical system;object oriented;desarrollo logicial;unified modelling language;safety critical software;software development;reactive system;systeme reactif;oriente objet;verification formelle;verification programme;orientado objeto;sistema b	The integration of UML and formal methods such as B and SMV provides a bridge between graphical specification techniques usable by mainstream software engineers, and precise analysis and verification techniques, essential for the development of high integrity and critical systems. In this paper we define a translation from UML class diagrams into B, which is used to verify the consistency of UML models and to verify that expected properties of these models hold.	formal verification;unified modeling language	Kevin Lano;David J Clark;Kelly Androutsopoulos	2004		10.1007/978-3-540-24756-2_11	unified modeling language;formal methods;formal verification;uml tool;reactive system;computer science;software development;applications of uml;class diagram;formal specification;programming language;object-oriented programming;algorithm	Logic	-42.1654110613237	26.59628489234761	23728
ee7c16fd8933a96c432b2af492d96c86f9f45bf2	model-driven navigation design for semantic web applications with the uml-guide	state diagram;state machine;semantic web	In this paper, we describe an extension to the UML-Guide for model driven navigation design of Semantic Web applications. The UML-Guide is used to specify platform independent navigation guides in web applications. We describe an OWL model for state machines which serves as a metamodel for semantic web descriptions of the navigation guides on the Semantic Web. Following the MDA approach, a state machine model of such navigation guide is generated from the UML state diagrams. The possible applications of such generated state machines are also discussed.	component-based software engineering;experiment;finite-state machine;metamodeling;model-driven integration;semantic web;side effect (computer science);state diagram;unified modeling language;web ontology language;web application;web service;world wide web	Peter Dolog	2004			computer science;data web;world wide web;web modeling;social semantic web;semantic analytics;semantic web;database;semantic web stack;web design;web navigation	Web+IR	-47.21216093393166	21.812684056611594	23731
d73bd3b76aa4b471993747d7f15c2f52f94ba4b7	chaintracker, a model-transformation trace analysis tool for code-generation environments		Model-driven engineering is advocated as an effective method for developing families of software systems that systematically differ across well defined dimensions. Yet, this software construction paradigm is rather brittle at the face of evolution. Particularly, when building code-generation environments, platform evolution scenarios force developers to modify the generated code of individual generation instances in an ad-hoc manner. Thus violating the systematicity of the original construction process. In order to maintain the code-generation environment synchronized, code refinements have to be traced and backwardly propagated to generation infrastructure, so as to make these changes systematically possible for all systems that can be generated. This paper presents ChainTracker, a general conceptual framework, and model-transformation composition analysis tool, that supports developers when maintaining and synchronizing evolving code-generation environments. ChainTracker gathers and visualizes model-to-model, and model-to-text traceability information for ATL and Acceleo model-transformation compositions.	model transformation	Victor Guana;Eleni Stroulia	2014		10.1007/978-3-319-08789-4_11	synchronizing;software construction;computer science;traceability;software system;code generation;model transformation;conceptual framework;effective method;systems engineering	Logic	-54.87123084211107	29.274271977013484	23774
2a68ab5ad46945ba5a1b925317a365126b3a6fbb	language-based software engineering	software engineering;domain specific languages	We present a language-centric view of the software development process. We argue that success of the domain-specific language (DSL) methodology depends on being able to rapidly craft a DSL's implementation infrastructure. We present logic programming as a rapid way of developing this implementation infrastructure. We also present a language-centric view of a software system as a processor of its input language. A language-centric view of software engineering is presented.A software system is a processor of its input language.Success of DSLs depends on rapidly building their implementation infrastructure.Implementation infrastructure can be developed rapidly via logic programming.	software engineering	Gopal Gupta	2015	Sci. Comput. Program.	10.1016/j.scico.2014.02.010	domain analysis;personal software process;verification and validation;computing;software engineering process group;software sizing;computer science;domain-specific language;package development process;software design;social software engineering;software framework;component-based software engineering;software development;software design description;domain engineering;software construction;programming language;resource-oriented architecture;software deployment;software development process;software requirements;software system	SE	-52.11903380158565	29.246208343037623	23899
eb1d22df4e00efe5a2fa69d9f25ecf1604fc8d2c	restructuring and optimizing knowledge representations	optimisation;systems;knowledge based system;decision tree;optimisation knowledge based systems decision tables knowledge acquisition knowledge representation;knowledge;knowledge acquisition;knowledge acquisition knowledge based systems knowledge representation design optimization decision trees automation logic design specification languages skeleton filling;model;prologa workbench knowledge based systems decision trees decision tables knowledge acquisition knowledge representation knowledge implementation representation formalisms;knowledge representation;decision tables;decision table;knowledge based systems	This paper focuses on three diflerent formalisms which play a major role in the development of knowledge based systems, decision trees, decision tables and rules, and how the formalisms appear in the main areas of knowledge acquisition, knowledge representation and knowledge implementation. It will be demonstrated that the decision tables, trees or rules in the distinct stages serve different purposes in the development of knowledge based systems and therefore will not necessarily remain unchanged. Restructuring and even optimizing representation formalisms will therefore be necessary. Transitions and optimizations of the different formalisms are described here in the context of their automation in the Prologa workbench. Three major parts of the knowledge development process will be considered: 0 During the knowledge acquisition phase, knowledge is acquired and verified in the form of tables or rules. This is elaborated further in section 2. 0 In the next phase the decision tables are transformed into a suitable representation (trees or rules) depending on the problem characteristics. This will be described in section 3. In the third phase, the knowledge representation formalisms have to be implemented. Implementation has to deal with several criteria such as order and relevancy of the questions, execution time efficiency, ... . Depending on the priority of the criteria different implementation strategies can be chosen as will be explained in section 4.	decision table;decision tree;knowledge acquisition;knowledge representation and reasoning;optimizing compiler;relevance;run time (program lifecycle phase);workbench	Jan Vanthienen;Geert Wets	1994		10.1109/TAI.1994.346405	natural language processing;decision table;knowledge representation and reasoning;knowledge interchange format;knowledge base;computer science;knowledge management;artificial intelligence;body of knowledge;knowledge-based systems;knowledge engineering;open knowledge base connectivity;data mining;procedural knowledge;knowledge extraction;commonsense knowledge;domain knowledge	AI	-53.23186766749668	19.55827547162663	23907
27649ef881426af1533eb139b05c8daa237313b6	query planning in mediator based information systems	doctoral thesis;information system	Information integration has gained new importance since the widespread success of the World Wide Web. The simplicity of data publishing on the web and the promises of the emerging eCommerce markets pose a strong incentive for data providers to offer their services on the Internet. Due to the exponential growth rate of the number of web sites, users are already faced with an overwhelming amount of accessible information. Finding the desired piece of information is difficult and time-consuming due to the inherently chaotic organisation of the Web. For this reason, information integration services are becoming increasingly important. The idea of such a service is to offer to a user a single point of access that provides him or her exactly with the information he or she is interested in. To achieve this goal, the service dynamically integrates and customises data from various data providers. For instance, a business information service would integrate news tickers, specialised business databases, and stock information. However, integration services face serious technical problems. Two of them are particularly hard to overcome: The heterogeneity between data sources and the high volatility that interfaces to data providers on the web typically exhibit. Mediator based information systems (MBIS) offer remedies for those problems. A MBIS tackles heterogeneity on two levels: Mediators carry out structural and semantic integration of information stemming from different origins, whereas wrappers solve technical and syntactical problems. Users only communicate with mediators, which use wrappers to access data sources. To this end, mediators and wrappers are connected by declarative rules that semantically describe the content of data sources. This decoupling supports the stability of interfaces and thus increases the maintainability of the overall system. This thesis discusses query-centred MBIS, i.e., MBIS in which mediators represent their domain through a schema. The core functionality of a mediator is to receive and answer user queries against its schema. Two ingredients are essential to accomplish this task: First, it requires a powerful language for specifying the rules that connect mediators and wrappers. The higher the expressiveness of this these rules, the more types of heterogeneity can be overcome declaratively. Second, the mediator must be equipped with algorithms that are – guided by the semantic rules – capable of efficiently rewriting user queries into queries against wrappers. We contribute to both issues. We introduce query correspondence assertions (QCA) as a flexible and expressive language to describe the content of heterogeneous data sources with respect to a given schema. QCAs are able to bridge more types of conflicts between schemas than previous languages. We describe algorithms that rewrite queries against a mediator into sequences of queries against wrappers, based on the knowledge encoded in QCAs. Our algorithms are considerably more efficient than previously published algorithms for query rewriting in MBIS. Furthermore, we define a formal semantics for queries in MBIS, which allows us to derive statements about properties of rewriting algorithms. Based on this semantics, we prove that our algorithm is sound and complete. Finally, we show how to reduce the main cost factor of query answering in MBIS, i.e., the number of accesses to remote data sources. To this end, we device algorithms that are capable of detecting and removing redundant remote accesses.	algorithm;chaos theory;coupling (computer programming);database;declarative programming;e-commerce;information system;internet;matchware mediator;qualitative comparative analysis;rewrite (programming);rewriting;semantic integration;semantics (computer science);sensor;stemming;time complexity;volatility;world wide web	Ulf Leser	2000		10.14279/depositonce-194	computer science;knowledge management;data science;data mining	DB	-36.83879483222774	6.178108892606927	23919
e81f32589b84dc7259e91499a6317c266eae10e4	on the conceptualization of etl patterns: a reo approach	patterns and meta models;reo coordination language;etl systems;conceptual modelling;data warehousing;data warehousing systems;verification and validation	Due to their complexity and importance on data warehousing systems development, ETL systems are being a strong research subject approaching several issues especially related to reduce implementation costs, and enhance decision-making processes abilities. Since ETL systems are intrinsically connected to business processes, they are strongly influenced by requirements changing, which impact ranges from changes in data source structures to the integration of new business rules and requirements. In this paper, we propose the use of ETL patterns not only to specify ETL systems internal behaviour but also to describe how patterns communicate and interchange data among them. In order to test and demonstrate the feasibility of our approach, we used the Reo coordination language for conceptual modelling, which provided an understandable notation and methodology with the ability to reduce implementation errors and development costs.	business process;conceptualization (information science);reo coordination language;requirement;software development process	Bruno Oliveira;Orlando Belo	2014		10.1145/2628194.2628247	verification and validation;computer science;data warehouse;data mining;database;reo coordination language	SE	-55.58963121241137	18.31660200709848	23933
0f6a717571e28c509e0040fbf8046b948b55c48b	towards quicker discovery and selection of web services considering required degree of match through indexing and decomposition of non-functional constraints	non functional selection;optimisation;service composition;service selection;functional discovery;constraint decomposition;web services;performance optimisation;service indexing;service discovery	An approach is proposed for identifying best services for composition based on functional and non-functional characteristics of services with a special focus on computational optimisation of functional discovery and non-functional selection. Discovery is optimised using a unique indexing consists of two indices, one for outputs of services and the other for inputs of services. In either index, each key is mapped to its semantically related service categories. The fine split of semantic relations into eight categories assists in handling disparate similarity demands of service clients efficiently. Also, indexing eliminates semantic reasoning entirely during querying. Non-functional selection is optimised using local selection method in multithreaded fashion with a new method of decomposing non-functional constraints. Further, indexing is used to expedite the searching of finding best services during selection. Experimentation results are presented. The minimum time consumption of the method makes it more applicable to dynamic composition needs.	computation;experiment;hash table;input/output;mathematical optimization;multithreading (computer architecture);precomputation;quality of service;software repository;thread (computing);time complexity;web service	Chellammal Surianarayanan;Gopinath Ganapathy;Manikandan Sethunarayanan Ramasamy	2015	IJCSE	10.1504/IJCSE.2015.067057	web service;computer science;operating system;data mining;database;service discovery;world wide web	DB	-45.20974642660734	13.091892845559252	23948
cb717598d4bab9a8dd684dc21a9fe5d8d394894d	software reliability models for practical applications	software reliability models;practical applications;software reliability	Reliability is one of the most important aspects of product quality. Software reliability research has been going on worldwide and many software reliability models are proposed and studied. In this paper, we first review some of the important software reliability models and then discuss them with respect to their validity and usefulness. The final part of this paper is aimed to present some simple models for the analysis of software failure data. Unlike the conventional approach, we present our model based on the graphical interpretation and this approach allows us to easily test a few models before detailed study based on a selected model is carried out.	list of software reliability models;software reliability testing	M. Xic	1994			reliability engineering;verification and validation;software sizing;intra-rater reliability;software verification;software reliability testing;software construction;software testing;software deployment;software metric;avionics software	Crypto	-62.722353090582615	30.91313277898819	23996
f02a17605bb7be6f64e814fe8385678390705505	digital twin approach for solving reconfiguration planning problems in rms		Reconfigurable Manufacturing System (RMS) appeared as a solution to high variation in customer demands allowing manufacturers to satisfy different amount of demands in different period. RMS satisfies demands by rapidly reconfiguring its hardware and software components, in order to quickly adjust its production capacity and functionality within a part family in response to sudden market changes or intrinsic system change depends on the demand of every single period. This reconfiguration process brings a critical issue within the RMS that is called as reconfiguration planning problems (RPP) introduced in this paper. With the rise of digital twin that has been a global issue, many companies or manufacturers are trying to integrate it into their production systems. There is a need of RMS to apply digital twin in order to hopefully improve the effectiveness and efficiency so that RPP can be automatically solved and controlled. The goal of this paper is to address the importance and requirement of the integration of digital twin simulation into RMS by providing comparison study between normal simulation program and digital twin simulation program. A case study is presented for comparison of two simulation models. Plant Simulation 11 is used for a normal simulation model, while Visual Components is used to build a digital twin simulation model.		Kezia Amanda Kurniadi;Sangil Lee;Kwangyeol Ryu	2018		10.1007/978-3-319-99707-0_41	component-based software engineering;simulation modeling;real-time computing;control reconfiguration;reconfigurable manufacturing system;computer science	AI	-54.65325548562021	11.915576444684806	24075
0a8b181b45927230f7568b7e96306db74ee4dc89	impact of execution modes on finding android failures		The iMPAcT tool combines the benefits of existing user recurring behaviour (User Interface Patterns) on mobile applications to facilitate the test automation of Android mobile applications. It uses an automatic exploration process combined with reverse engineering to identify the existing user interface patterns on a mobile application and then tests those patterns with generic test strategies (designated Test Patterns). The Test Patterns are defined in a catalogue that can be reused for testing other applications. However the results obtained by the iMPAcT tool depend on the exploration mode and on the order in which the test strategies are applied. This paper describes an experiment conducted to evaluate the impact of using different exploration modes and of changing the order by which UI patterns are searched and subsequently tested on the failures found and on the number of events fired. c © 2016 The Authors. Published by Elsevier B.V. Peer-review under responsibility of the Conference Program Chairs.	android;international symposium on fundamentals of computation theory;internationalization and localization;mobile app;order by;reverse engineering;test automation;test card;user interface	Ines Coimbra Morgado;Ana C. R. Paiva	2016		10.1016/j.procs.2016.04.127	real-time computing;simulation;operating system;data mining;world wide web	SE	-59.43998517966816	31.716774458837957	24092
069fff2e105792ed503c83a09f0fea067ebbe83f	development and evolution of web-applications using the webcomposition process model	developpement logiciel;red www;reutilizacion;component based development;composant logiciel;software engineering;reuse;internet;desarrollo logicial;software development;software component;world wide web;reseau www;component based software development;process model;web application development;markup language;reutilisation	From a software engineering perspective the World Wide Web is a new application platform. The implementation model that the Web is based on makes it difficult to apply classic process models to the development and even more the evolution of Web-applications. Component-based software development seems to be a promising approach for addressing key requirements of the very dynamic field of Webapplication development and evolution. But such an approach requires dedicated support. The WebComposition Process Model addresses this requirement by describing the component-based development of Web-applications. It uses an XML-based markup language to seamlessly integrate with existing Webstandards. For the coordination of components the concept of an open process model with an explicit support for reuse is introduced. By describing application domains using domain-components the process model addresses the need for a controlled evolution of Web applications.	component-based software engineering;evolution;markup language;process modeling;requirement;software development;web application;world wide web;xml	Martin Gaedke;Guntram Gräf	2001		10.1007/3-540-45144-7_8	computer science;component-based software engineering;operating system;database;programming language;world wide web	SE	-46.87504497424063	22.576188238974517	24105
6bfde1ff8a99df4980df7940807bfc873716cc8c	variable structure in devs component-based modeling and simulation	modelizacion;model specification;structure interface;systeme evenement discret;variable structure;componente logicial;component based modeling and simulation;composant logiciel;sistema complejo;systeme adaptatif;sistema acontecimiento discreto;modelisation;discrete event system;estructura interfaz;systeme complexe;specification modele;complex system;especificacion modelo;interface structure;adaptive system;software component;sistema adaptativo;adaptive complex systems;devs;modeling	Variable structure refers to the ability of a system to dynamically change its structure according to different situations. It provides component-based modeling and simulation environments with powerful modeling capability and the flexibility to design and analyze complex systems. In this paper, we discuss variable structure, specifically the structure and interface change capability, in DEVS-based modeling and simulation environments. The operations of structure and interface changes are discussed and their respective operation boundaries are defined. Three examples are given to illustrate the role of variable structure and how it can be used to model and design adaptive complex systems. Principles for the implementation of variable structure are also presented and illustrated in the DEVSJAVA modeling and simulation environment.	complex systems;component-based software engineering;devs;simulation	Xiaolin Hu;Bernard P. Zeigler;Saurabh Mittal	2005	Simulation	10.1177/0037549705052227	simulation;systems modeling;computer science;systems engineering;artificial intelligence;component-based software engineering;adaptive system;devs;specification;algorithm	Robotics	-39.28837395816276	25.131989425982304	24124
47bf135b98a952acde9ecac0da26ca7c45bff9d9	using pi-calculus to formalize grid workflow parallel computing patterns	parallel computing;grid workflow;parallel processing calculus petri nets pattern analysis algebra information technology mesh generation information analysis message passing centralized control;parallel computing patterns;grid workflow pattern verification;mature pi tool pi calculus parallel computing grid workflow pattern verification formalizing method;pi calculus;buffer storage;pi calculus formal verification grid computing parallel processing;data mining;mature pi tool;formal method;computational modeling;formal verification;workflow system;algebra;calculus;parallel computer;formalizing description grid workflow parallel computing patterns pi calculus;formalizing method;petri nets;grid computing;workflow patterns;parallel processing;formalizing description	The article analyzed the significance of formalizing grid workflow patterns and the advantage of using the Pi calculus to formalize. After that, it used the Pi calculus to formalize the grid workflow patterns. On the foundation of lucubrating basic framework characteristics of grid workflow patterns and Pi calculus theory, the paper proposed a rule of formalizing method. This method compared practicably with former ways in describing grid workflow, we can directly make use of the fruit of this paper with mature pi-tools to verify grid workflow system.	parallel computing;workflow pattern;π-calculus	Zhan-jun Li;Yong-zhong Huang;Shao-zhong Guo	2009	2009 Sixth International Conference on Information Technology: New Generations	10.1109/ITNG.2009.63	workflow patterns;parallel processing;π-calculus;formal verification;computer science;theoretical computer science;database;distributed computing;programming language;computational model;petri net;workflow management system;grid computing;workflow technology	HPC	-34.79700374977812	29.88492642858409	24144
26a2778ece1bda764d628d3ed473efdb68f0d691	stakeholder discovery and classification based on systems science principles	product safety;stakeholder centric conditions;quality attributes;quality properties stakeholder discovery stakeholder classification systems science principles software development methods quality attributes systemic properties availability security reusability maintainability stakeholder centric conditions systems theory specialized stakeholders generic concepts;reusability;availability;information technology;software systems;stakeholder;stakeholder classification;system theory;software engineering;software systems information technology software engineering web services computer science usability product safety software safety computer security software quality;computer security;systems science principles;generic concepts;systems theory;software safety;systems analysis;software development;web services;system theory software quality software reliability systems analysis;software development methods;computer science;systems science;quality properties;usability;security;modeling;software reliability;software quality;stakeholder discovery;maintainability;systemic properties;specialized stakeholders	It is the goal of our research work to elaborate on improvements to the sofrware development methods so that quality attributes can be handled more systematically. By quality attributes we mean the large group of typically systemic properties of a sofrware system, such as availability, security, etc., but also reusability, maintainability and many more. We define quality attributes as stakeholder-centric conditions on the behavior or structure of a system. The importance of the notion of a stakeholder cannot surprise, but the lack of a general theory on how to define and identify the relevant set of stakeholders does. Drawing from systems theory we claim that four basic, generic types of stakeholders are sufJicient to be able to derive a specialized set of stakeholders for any considered system and domain of inquiry. It is only when we understand the generic concepts and principles behind quality properties of systems, that we can properly derive methods and build tools to cope with them.	list of system quality attributes;systems science;systems theory	Otto Preiss;Alain Wegmann	2001		10.1109/APAQS.2001.990019	reliability engineering;computer science;systems engineering;knowledge management;stakeholder analysis	DB	-58.699554892063574	24.312111931181484	24159
4fa1af51dc82c115ca6a3c885780f1e63e0ae34e	mml, a modelling language with dynamic selection of methods			modeling language	Vicente Guerrero Rojo	1996				NLP	-51.27378162549839	26.503423301090134	24161
5aeec5c86be60a6bdaa3b61e772817019ccd8d06	knowledge grid based knowledge discovery in distributed environment	computer aided instruction;information technology;meta data knowledge grid ontology distributing;data mining;ontologies artificial intelligence;knowledge grid;heterogeneous information;research and development;distributed environment;semantic web computer aided instruction data mining educational institutions grid computing ontologies artificial intelligence;semantic web;meta data;grid computing;university knowledge grid knowledge discovery distributed environment information technology software technology publishing knowledge base resources semantic web heterogeneous information sources knowledge sharing process ontology server educational institution;ontology;ontologies servers data mining knowledge based systems distributed databases clustering algorithms algorithm design and analysis;distributing;knowledge base;knowledge discovery	The development of real life problem is not the key issue. Various information technologies available now a days. But the major issue is that to get more advantages of these technologies for academic purpose in distributed environment where faculty and students communicate with software technology rather then with individual. Knowledge Based Grid was introduced for publishing, managing, sharing and utilizing different amount of knowledge base resources on Semantic Web in distributed environment. Knowledge discovery from heterogeneous information sources available on knowledge Grid environment is a major challenging research and development issue. This paper mainly concerns all aspects of the knowledge discovery, sharing process and integrates grid data resource by ontology server for educational institutes and university in distributed environment.	algorithm;computer science;data mining;database;function composition (computer science);knowledge base;knowledge management;knowledge-based systems;real life;semantic web;server (computing)	Muqeem Ahmed;S. Zeeshan Hussain;Syed Muhammad Asim Ali Rizvi	2010	2010 International Conference on Computer Information Systems and Industrial Management Applications (CISIM)	10.1109/CISIM.2010.5643496	knowledge base;knowledge integration;computer science;knowledge management;artificial intelligence;data science;knowledge-based systems;semantic web;knowledge engineering;ontology;open knowledge base connectivity;data mining;knowledge extraction;metadata;information technology;domain knowledge;grid computing;distributed computing environment	DB	-45.28868663200537	7.73687325245112	24172
c39e60923f8c315862ade4945870fad9b2b200b8	enterprise system introduction with controlling enabled configurative models	reference model;best practice;customer needs enterprise system preconfigured processes reference information models customization process;continuous improvement;business data processing;enterprise resource planning;enterprise system;reference information model;control system synthesis costs companies context modeling adaptation model sections information systems business process re engineering artificial intelligence acceleration;enterprise resource planning business data processing	Customization of enterprise systems (ES) is often a time and cost consuming task. Therefore many of these ES, such as SAP R/3, are provided with preconfigured processes and data objects that can be regarded as best-practice and which are documented by reference information models. Customizing can be accelerated if these models are used for the customization process. This requires profound configuration and adaptation mechanisms that encompass variants due to specific customer needs. To ensure continuous improvement towards a shorter customization time and reduced cost, controlling of the adaptation process becomes a crucial task. This controlling aims at improving the reference model basis and their configuration mechanisms. Therefore we introduce configuration mechanisms that can be used to adapt reference information models due to company characteristics. Afterwards the configuration mechanisms are interpreted by the ES to perform the necessary customization steps	enterprise system;field research;information model;modeling language;plug-in (computing);precondition;reduced cost;reference model	Christian Seel;Patrick Delfmann;Tobias Rieke	2006	15th IEEE International Workshops on Enabling Technologies: Infrastructure for Collaborative Enterprises (WETICE'06)	10.1109/WETICE.2006.38	enterprise system;reference model;enterprise systems engineering;enterprise software;mass customization;computer science;knowledge management;software engineering;database;enterprise integration;management;enterprise information system;best practice;enterprise life cycle	Embedded	-57.0245058872908	17.940367635418646	24176
f22bd17fd5c6535d67e5bbeb2a59f62ad6d84b4d	the fastest algorithm for the pert problem with and-and or-nodes (the new-product-new-technology problem)	new technology;new products		algorithm;fastest;program evaluation and review technique	E. A. Dinic	1990			mathematical optimization;mathematics	Theory	-60.93427812025954	6.530222865485685	24208
f17bb89d2598e50d5f10ed5ebf8bc0b099bde423	applying petri net reduction to support ada-tasking deadlock detection	program verification ada concurrency control distributed processing petri nets;reduction rules analysis by transformation model reduction petri net reduction ada tasking deadlock detection reachability analysis petri net theory ada tasking semantics;ada;distributed processing;deadlock detection;program verification;concurrency control;system recovery algorithm design and analysis petri nets information analysis software systems laboratories reachability analysis face detection fets displays;petri nets;petri net;reachability analysis	As part of our continuing research on using Petri nets to support automated analysis of Ada tasking behavior, we have investigated the applicaLion of Pctri net reduction for Ada-tasking deadlock detection. Net reduction can ease reachability analysis by reducing the size of the net while preserving relcvant properties. By combining Petri net theory and knowledge of Ada tasking semantics, we derive some specific efficient reduction rules for Petri net models of Ada-tasking. In addition, we suggest a method by which a useful description of a detected deadlock state can be easily obtained from the reduced net's information.	ada;deadlock;petri net;reachability	Shengru Tu;Sol M. Shatz;Tadao Murata	1990		10.1109/ICDCS.1990.89289	real-time computing;stochastic petri net;computer science;distributed computing;process architecture;programming language;petri net	Robotics	-42.68177227453945	31.25175352143522	24216
de499bac94989d5500bb47605d3f488752e75d6a	towards a component-based design of adaptive, context-sensitive services for ubiquitous systems				Tomás Ruiz-López;Carlos Rodríguez-Domínguez;Manuel Noguera;María José Rodríguez-Fórtiz;José Luis Garrido	2013		10.3233/978-1-61499-286-8-57	systems engineering;component-based software engineering;computer science	EDA	-51.15828629511117	26.71082664602457	24265
1a6777e6b0aa43193f534866e8a3b34cefaa01a5	linking wikidata to the rest of the semantic web			semantic web;wikidata	Andra Waagmeester;Egon L. Willighagen;Núria Queralt-Rosinach;Elvira Mitraka;Sebastian Burgstaller-Muehlbacher;Tim E. Putman;Julia Turner;Lynn M. Schriml;Paul Pavlidis;Andrew I. Su;Benjamin M. Good	2016			world wide web;semantic web;semantic web stack;computer science	Web+IR	-39.544254127928966	6.4506935617504535	24295
b06095e727afd91e0e9eb0470af9ed466999afa9	semantic models for concurrency	semantic model		concurrency (computer science)	Michael W. Mislove	2000	ACM SIGSOFT Software Engineering Notes	10.1145/340855.340980	semantic data model;semantic interoperability;semantic similarity;semantic computing;semantic web rule language;semantic search;computer science;social semantic web;semantic compression;database;semantic equivalence;programming language;semantic gap	SE	-38.63766354463433	6.917584116213518	24298
5a79593eee96b8454f53c2e26d23c0a3ce74ecd3	artificial intelligence techniques in the dynamic negotiation of qos: a user interface for the internet new generation	offre service;distributed system;interfase usuario;analyse amas;systeme reparti;service provider;negociation;user interface;autonomous system;real time;qos guarantee;intelligence artificielle;diferenciacion servicio;classification;sistema autonomo;qualite service;user assistance;artificial intelligent;sistema repartido;cluster analysis;assistance utilisateur;internet;negociacion;policy based network management;temps reel;comportement utilisateur;asistencia usuario;systeme autonome;bargaining;agent technology;autoorganizacion;service differentiation;tiempo real;artificial intelligence;self organization;interface utilisateur;analisis cluster;inteligencia artificial;user behavior;quality of service;proposals;clasificacion;autoorganisation;differenciation service;service quality;comportamiento usuario;calidad servicio	The Internet New Generation provides a service adapted to the needs of the applications (particularly real time) including a Quality of Service (QoS) guaranteed. It is based on the DiffServ architecture and the policy-based networking management. It also uses the agent technology to solve problems and control infrastructures and flows. Access to the Internet New Generation is more difficult. The user has to choose the best service provider and indicate the technical parameters that he needs. In this paper, we investigate the use of some techniques of the AI (Artificial Intelligence) domain to implement a user interface in order to help the user access to the Internet New Generation. We use the connectionist clustering in the management of the negotiation profiles. Then we use the agent technology to help the user to choose the best service provider, dynamically negotiate the SLS on the user’s behalf, follow the users behavior to be able to anticipate the negotiations and manage the re-negotiations.	algorithm;artificial intelligence;cluster analysis;computer terminal;connectionism;differentiated services;internet;multi-agent system;neural impulse actuator;quality of service;standard sea level;user (computing);user interface	Zeina Jrad;Francine Krief;Lahcène Dehni;Younès Bennani	2006		10.1007/11880905_13	service provider;the internet;self-organization;simulation;quality of service;biological classification;computer science;autonomous system;artificial intelligence;cluster analysis;user interface;world wide web;computer security;service quality;negotiation	AI	-38.20362390461155	16.223962455741837	24327
0b8f9a8181dee8eb54159f15037afea65879467b	application of 3d virtual presentation technology in product customer system	software;virtual reality consumer products customer relationship management electronic commerce manufacturing data processing;virtual presentation;electronic commerce;cult3d technology;customer relationship management;3d digital products;e commerce;web3d technology;internet java space technology mechanical engineering application software computer industry two dimensional displays instruments three dimensional displays data visualization;biological system modeling;virtual reality;network customization system;customer virtual presentation cult3d technology e commerce;html;product customer system;3d model;internet;manufacturing data processing;three dimensional displays;system integration;industrial equipments;solid modeling;3d virtual presentation technology;e commerce module;customer;consumer products;cult3d;cult3d 3d virtual presentation technology product customer system 3d digital products household electrical appliances industrial equipments medical instruments network customization system e commerce module web3d technology;system architecture;medical instruments;interaction design;household electrical appliances;java;new products	Due to the increasing demand of customer in variation and personalization of products, static, textual and 2D display of products are no longer satisfactory for presenting products on the Internet, especially for 3D digital products such as household electrical appliances, industrial equipments and medical instruments. This paper aimed at the problems of network customization system based mainly on the traditional static display form of e-commerce module, and put forward to a new Web3D technology-Cult3D, which advantages in contrast to VRML, a new e-commerce based appliance 3D digital customize system is developed, it can be used to realize the dynamic display and interactive custom conveniently. The research focused on some important problems such as system architecture, the creation of 3D models and system integration. The application was proved that could help improve the effect of info transfer and customer satisfactory degree, provide a new interactive design mode for the development of new product.	3d modeling;application programming interface;autodesk 3ds max;browsing;e-commerce;home automation;interactive design;internet;java class library;list of java apis;mainframe computer;microwave;mobile phone;personalization;server (computing);server-side;system integration;systems architecture;vrml;web3d	Xiaoling Li;Wei Wang;Haibo Xv	2008	2008 International Conference on Computer Science and Software Engineering	10.1109/CSSE.2008.680	e-commerce;customer;the internet;simulation;html;computer science;final good;operating system;interaction design;multimedia;solid modeling;java;system integration	Robotics	-53.61791181899799	8.812777650394876	24328
5bc5da949c5d1f4e7464ce00af675318e814066f	toward a trust model for knowledge-based communities	trust;specification;knowledge	The ultimate goal of trust is to reach and make decisions based upon the available knowledge. We think that it is not enough to build trust on beliefs or on recommendation-based models. Our approach aims to implement it within a programming methodology inspired from the theorem proving domain. We propose a conceptual framework which transposes this to the context of virtual organizations. In this paper we describe our approach and partially illustrate it with a prototype system dedicated to information searching in the context of academic exchanges.	automated theorem proving;conceptual schema;prototype;software development process;virtual organization (grid computing)	Jacques Calmet;Pierre Maret	2013		10.1145/2479787.2479814	computer science;knowledge management;data mining;management science	AI	-42.27127395017439	18.674206728750782	24332
b2ea07e9520566352f5fa442184d4229bd9f61a6	on the de-facto standard of event-driven process chains: how epc is defined in literature		The Business Process Modelling Notation (BPMN) and the Event-driven Process Chain (EPC) are both frequently used modelling languages to create business process models. While there is a well-defined standard for BPMN, such a standard is missing for EPC. As a standard would be beneficial to improve interoperability among different vendors, this paper aims at providing the means for future EPC standardization. Therefore, we have conducted a structured literature review of the most common EPC variants in IS research. We provide a structured overview of the evolution of different EPC variants, describe means and capabilities and elaborate different criteria for decision-making in regard to including EPC variants in a standardization process.	business process model and notation;event-driven process chain;interoperability;modeling language;process modeling;systematic review	Dennis M. Riehle;Sven Jannaber;Arne Karhof;Oliver Thomas;Patrick Delfmann;Jörg Becker	2016			systems engineering;interoperability;business process modeling;standardization;de facto standard;systematic review;business process model and notation;computer science	Web+IR	-60.0605754119267	17.42439231326235	24344
cbfb29a70d82867d8cf753eab64488d649512216	instant management infrastructure - through network management support systems and software agents coordination	software agent;support system;network management	Enterprises need to automate manual and routine aspects of IT infrastructure management. In this paper a new concept that integrates different autonomous and management level applications through Instant Messaging protocol (XMPP) is introduced. This is achieved by means of a common management information model implemented in LDAP. A content language implemented in XML is also described, allowing autonomous application integration to carry out management tasks dynamically.	autonomous robot;information model;instant messaging;lightweight directory access protocol;management information system;software agent;xml	José A. Folha;Bruno F. Marques;José A. Oliveira;Paulo M. Coelho;Raul F. Oliveira	2006			operations support system;network management;fcaps;element management system;long-term support;change management;real-time computing;systems management;information technology management;network management station;computer science;knowledge management;software development;software agent;release management;software as a service;network management application;structure of management information;application lifecycle management;software deployment;software system	DB	-51.41974267305685	15.363096824425506	24405
e294b88a75a52fc357eaea8034b7f056849d543b	a calculus of program modifications	program modification;software component;software development methodologies;user requirements;reusability	It is common to distinguish between two paradigms of software reuse: black box reuse, which consists in reusing components verbatim, without modifying them; and whit e boz reuse, which provides for making modifications to retrieved components before using them. Because software components are very information-rich (i.e. it takes a great deal of information to characterize a component), the chances of an exact match between an available component and a query are in general very slim; hence it is necessary to make provisions for adapting retrieved components to user requirements. This paper discusses a mathematical foundation for carrying out this modification process in a correctnear+preaerving manner.	black box;code reuse;component-based software engineering;requirement;user requirements document	Rym Mili;Marc Frappier;Jules Desharnais;Ali Mili	1997		10.1145/258366.258415	reusability;software requirements specification;verification and validation;software sizing;software verification;computer science;systems engineering;engineering;package development process;backporting;software design;social software engineering;software framework;user requirements document;component-based software engineering;software development;software engineering;software construction;programming language;resource-oriented architecture;software measurement;software deployment;goal-driven software development process;software development process;software requirements;software system	SE	-54.28047153848963	27.314401204348304	24447
08ecacca94c51a2e6c9f651e29fe899b875fb586	integrating user-perceived quality into web server design	perceived quality;e commerce;user perception;conceptual model;system design;user requirements;internet services;quality of service;server design;experience design	Quality of Service, user perception, eCommerce, server design, internet, web server design As the number of Web users and the diversity of Web applications continues to explode, Web Quality of Service (QoS) is an increasingly critical issue in the domain of e-Commerce. This paper presents experiments designed to estimate users' tolerance of QoS in the context of e-commerce. In addition to objective measures we discuss contextual factors that influence these thresholds and show how users' conceptual models of Web tasks affect their expectations. We then show how user thresholds of tolerance can be taken into account when designing web servers. This integration of user requirements for QoS into systems design is ultimately of benefit to all stakeholders in the design of Internet services.	design of experiments;e-commerce;experiment;future internet;interaction;online and offline;quality of service;requirement;server (computing);system configuration;systems design;user requirements document;utility;web application;web server;web service	Nina T. Bhatti;Anna Bouch;Allan Kuchinsky	2000	Computer Networks	10.1016/S1389-1286(00)00087-6	e-commerce;web service;web application security;user experience design;web development;web modeling;quality of service;web design;experience design;web standards;computer science;knowledge management;conceptual model;user requirements document;ws-policy;web navigation;multimedia;web engineering;world wide web;web server;computer network;systems design	Web+IR	-49.56928619323506	17.031114867840003	24561
cce6d5b9ec257f776faf66f6defc1bf2793dc84e	s3: a service-oriented reference architecture	semiconductor optical amplifiers;capacity planning service oriented reference architecture quality of service interconnected architectures reusability architecture validation;capacity planning;reusability;service orientation;service oriented reference architecture;soa solution stack s3;soa solution stack s3 service oriented architecture soa web services reference architecture;interconnected architectures;web service;software architecture;software reusability;web services;software reusability quality of service software architecture;service oriented architecture soa;architecture validation;service oriented architecture data models context aware services semiconductor optical amplifiers;quality of service;service oriented architecture;reference architecture;data models;context aware services	For most businesses, a service-oriented architecture offers considerable flexibility in aligning IT functions and business processes and goals. An SOA decouples reusable functions, for example, and lets an organization externalize quality-of-service (QoS) variations in declarative specifications such as WS-Policy and related standards. As a flexible, extensible architectural framework, SOA reduces cost, increases revenue, and enables rapid application delivery and integration across organizations and siloed applications. There's a challenging downside to SOA, however, in that it's significantly difficult to create an SOA solution. The architect must figure out how to produce a solution using a well-defined notation or how to organize the solution as an architectural framework with interconnected architectures and transformation capabilities. There is also the question of how to design for reusability and which tools will take the guesswork out of architecture validation and capacity planning	application streaming;business process;enterprise architecture framework;quality of service;reference architecture;service-oriented architecture;service-oriented device architecture;ws-policy	Ali Arsanjani;Liang-Jie Zhang;Michael Ellis;Abdul Allam;Kishore Channabasavaiah	2007	IT Professional	10.1109/MITP.2007.53	web service;real-time computing;computer science;service-oriented architecture;law;oasis soa reference model	SE	-48.26161618782771	17.07603654287684	24570
1ae859e7a7443d9aa2585bd00c72ac8e22701320	asynchronous sequential machine design and analysis: a comprehensive development of the design and analysis of clock-independent state machines and systems	sequential;arbiters;logic;state machine;machine design;digital;machines;self timed;sequencers;asynchronous	This textbook provides practicing scientists and engineers an advanced treatment of the Atmel AVR microcontroller. This book is intended as a follow on to a previously published book, titled “Atmel AVR Microcontroller Primer: Programming and Interfacing.’’ Some of the content from this earlier text is retained for completeness. This book will emphasize advanced programming and interfacing skills. We focus on system level design consisting of several interacting microcontroller subsystems. The first chapter discusses the system design process. Our approach is to provide the skills to quickly get up to speed to operate the internationally popular Atmel AVR microcontroller line by developing systems level design skills. We use the Atmel ATmega164 as a representative sample of the AVR line. The knowledge you gain on this microcontroller can be easily translated to every other microcontroller in the AVR line. In succeeding chapters, we cover the main subsystems aboard the microcontroller, providing a short theory section followed by a description of the related microcontroller subsystem with accompanying software for the subsystem.We then provide advanced examples exercising some of the features discussed. In all examples, we use the C programming language. The code provided can be readily adapted to the wide variety of compilers available for the Atmel AVR microcontroller line. We also include a chapter describing how to interface the microcontroller to a wide variety of input and output devices. The book concludes with several detailed system level design examples employing the Atmel AVR microcontroller.	atmel avr;compiler;input/output;interaction;level design;microcontroller;output device;primer;systems design;the c programming language	Richard F. Tinder	2009		10.2200/S00160ED1V01Y200811DCS018	asynchronous system;embedded system;electronic engineering;real-time computing;computer science;electrical engineering;theoretical computer science;finite-state machine;logic;algorithm	HCI	-53.696307762507324	4.489829603784024	24572
47a9c18adaa6a36c6567b2e1c0d92701ac87af3f	design and development of an event-driven in-memory business process engine		Although organizations have widely adopted Business Process Management Systems (BPMS) as an automation and integration middleware, these systems remain limited in their orchestration capabilities. BPMS can only react to event information that enterprise applications emit and only integrate against the service interfaces these applications provide. At the same time, organizations increasingly leverage large-scale in-memory database platforms as a shared database layer to house all their enterprise applications. These databases challenge traditional three-tier architectures by relocating data-intense application code into the data-tier. Consequently, the database contains both application data and low-level service procedures, which make up the required inputs for an orchestration capability.This paper presents the design and development of an event-oriented Business Process Engine (BPE) that runs within an in-memory platform. The approach comprises a compiler which transforms processes modeled in BPMN 2.0 into artifacts of the in-memory database, and the actual BPE that is implemented in the database platform's procedural programming language. The approach provides unconstrained reach to external events, which are expressed as arbitrary database state changes. Using BPMN as input, this paper addresses the notation's poorly specified message semantics to declare events by clarifying the notion of messages w.r.t the BPE and the message properties of BPMN. Special consideration is on message correlation and messaging patterns toward messaging scenarios far beyond the narrow BPMN specification.	business process model and notation;compiler;enterprise software;high- and low-level;in-memory database;management system;messaging pattern;middleware;multitier architecture;procedural programming;programming language	Jan Hendrik Betzing	2017	2017 IEEE 19th Conference on Business Informatics (CBI)	10.1109/CBI.2017.31	orchestration (computing);messaging pattern;compiler;business process;procedural programming;database;real-time computing;business process management;business process model and notation;computer science;middleware	DB	-55.914662527991716	19.146737405899596	24598
668dd0484ac9d7049ac31a9d4c313fad10b627fc	towards a norm-driven design of context-aware e-health applications		In this paper, we explore the usefulness of elaborating process models with norms, especially focusing on the Norm Analysis Method (NAM) as an elaboration tool that can be combined with a process modeling tool, such as Petri Net (PN). The PN-NAM combination has been particularly considered in the paper in relation to a challenge that concerns the design of context-aware applications, namely the challenge of specifying and elaborating complex behaviors that may include alternative (context-driven) processes (we assume that a user context space can be defined and that each context state within this space corresponds to an alternative application service behavior). Hence, the main contribution of our paper comprises an adaptability-driven methodological and modeling support to the design of context-aware applications; modeling guidelines are proposed, considered together with corresponding modeling tools (in particular PN and NAM), and partially illustrated by means of an e-Healthrelated example. Given the multi-disciplinary nature of the e-Health domain, it is expected that the current research will be useful for it. In particular, e-Health system developers might benefit from the relevant methodological and modeling support, proposed in the paper.	nam;petri net;process modeling;software testing controversies;utility	Boris Shishkov;Hailiang Mei;Marten van Sinderen;Thijs Tonis	2008			systems engineering;engineering;operations management;management science	SE	-57.95036323170121	20.30431041198244	24608
48b866782a972a159daaf9fa13450ff50e47829d	specifying complex systems in object-z: a case study of petrol supply systems	system specification;formal methods	As modern complex systems become increasingly large, sophisticated, feature-rich and data-intensive, people have recognized the importance of precisely and unambiguously specifying them with formal methods for a number of years. This paper advocates the use of Object-Z, a formal specification language, in the description of complex systems. Object-Z is an extension to the Z language to facilitate specification in an object-oriented style. The notation ObjectZ builds on Z’s strengths in modeling complex data and algorithms, and on its new class structuring’s strengths in succinctly specifying the various relationships and communication between objects in a large system. In detail, first we describe informally the syntax and semantics of ObjectZ, highlighting those features that facilitate decomposing a large system into a collection of interacting objects and thus separating concerns. Then, we demonstrate the use of Object-Z by presenting a case study of a petrol supply system, illustrating how the system runs by communicating the constituent objects. Finally, we discuss several issues we encountered in this exercise, which may serve as feedback to the development of Object-Z.	algorithm;complex systems;data-intensive computing;formal methods;formal specification;interaction;object-z;software feature;specification language	Yangping Li;Xiaoheng Pan;Tianming Hu;Sam Yuan Sung;Huaqiang Yuan	2014	JSW		simulation;formal methods;specification language;computer science;artificial intelligence;system requirements specification;formal specification;database;programming language;computer security;algorithm	Web+IR	-39.68175759646352	30.219124230763576	24616
8b80785cba6b29635980370cb043973b423066ee	prodproc - product and production process modeling and configuration		Software product configurators are an emerging technology that supports companies in deploying mass customization strategies. Such strategies need to cover the management of the whole customizable product cycle. Adding process modeling and configuration features to a product configurator may improve its ability to assist mass customization development. In this paper, we describe a modeling framework that allows one to model both a product and its production process. We first introduce our framework focusing on its process modeling capabilities. Then, we outline a possible implementation based on Constraint Logic Programming of such product/process configuration system. A comparison with some of the existing systems for product configuration and process modeling concludes the paper.	constraint logic programming;knowledge-based configuration;process modeling	Dario Campagna;Andrea Formisano	2011				Robotics	-58.5334572845017	13.151912608615588	24617
def381e243180c0b09e59cd0977cf3647850a082	an information visualization feature model for supporting the selection of software visualizations	feature model;awareness;software visualization	Software development comprises the execution of a variety of tasks, such as bug discovery, finding reusable assets, dependency analysis etc. A better understanding of the task at hand and its surroundings can improve the development performance in general. Software visualizations can support such understanding by addressing different issues according to the necessity of stakeholders. However, knowing which visualizations better fit a given task in progress is not a trivial skill. In this sense, a feature model, intended for organizing the knowledge of a given domain and allowing the reuse of components, can support the identification, categorization and selection of information visualization elements. This work presents an ongoing domain analysis performed for building an information visualization feature model, whose goal is to support the process of choosing and building proper, suitable software visualizations.	categorization;dependence analysis;domain analysis;feature model;information visualization;organizing (structure);software development	Renan Vasconcelos;Marcelo Schots;Cláudia Maria Lima Werner	2014		10.1145/2597008.2597796	software visualization;awareness;computer science;knowledge management;data science;feature-oriented domain analysis;software engineering;data mining;programming language;feature model	SE	-59.759525798653684	23.323273779999337	24625
083c0f0f0c4b2ec8b55c727fc06e7cfafc30fc0d	establishing a software architecting environment	architectural design;life cycle;software maintenance;model analysis;software development process;telecommunication computing;product line;modeling language;model validation;software architecture;uml profile;specification languages;computer architecture unified modeling language programming software architecture subspace constraints software systems documentation software tools software maintenance control systems;telecommunication computing software architecture reverse engineering specification languages software maintenance;product implementation architecture software architecture environment architecture design architecture reconstruction architecture maintenance software product line platform architecture modeling platform architecture analysis reverse engineered product nokia mobile terminals architecture model validation architecture model analysis reverse architecting software development design tools documentation tools nokia software architects uml architecture modeling language;software product line;mobile terminal;reverse engineering;modeling and analysis	We present the work of establishing an integrated environment that facilitates architecture design, reconstruction, and maintenance in the entire life cycle of a software product line. This architecting environment (ART environment) has been used in modeling and analysis of both the designed platform architecture model and the reverse-engineered product implementation architecture models of different releases in a big product line of Nokia mobile terminals. ART environment comprises tools for architecture model validation, architecture model analysis and processing, and reverse architecting. The ART environment fits the current software development process inside Nokia, and is integrated with the design and documentation tools that have already been used by Nokia software architects. UML, after being customized with UML profiles for architecture design, is used as the architecture modeling language in ART environment.	comparison of command shells;documentation;fits;profile (uml);reverse engineering;software architect;software development process;software product line;unified modeling language	Claudio Riva;Petri Selonen;Tarja Systä;Antti-Pekka Tuovinen;Jianli Xu;Yaojin Yang	2004	Proceedings. Fourth Working IEEE/IFIP Conference on Software Architecture (WICSA 2004)	10.1109/WICSA.2004.1310702	multilayered architecture;enterprise architecture framework;functional software architecture;reference architecture;biological life cycle;software architecture;space-based architecture;architecture tradeoff analysis method;database-centric architecture;systems engineering;engineering;applications architecture;service-oriented modeling;software engineering;solution architecture;software architecture description;regression model validation;modeling language;resource-oriented architecture;software maintenance;software development process;reverse engineering;data architecture;computer engineering	SE	-50.01773107208219	28.880221609851173	24641
007b5668b43942e6fb2ecf8cdcb4dc903f6ad3df	on2broker: semantic-based access to information sources at the www	html	On2broker provides brokering services to improve access to heterogeneous, distributed, and semistructured information sources as they are presented in the World Wide Web. It relies on the use of ontologies to make explicit the semantics of Web pages. This paper discusses the general architecture and main components (i.e., query engine, information agent, inference engine, and database manager) of On2broker and provides some application scenarios. The paper shows how semantic based access is provided to Web sources described with HTML (HyperText Markup Language), XML (eXtensible Markup Language), or RDF (Resource Description Framework). (Contains 15 references.) (Author/MES) Reproductions supplied by EDRS are the best that can be made from the original document. On2broker: Semantic-based access to information sources at the WWW Dieter Fensel, Jurgen Angele, Stefan Decker, Michael Erdmann, Hans-Peter Schnurr, Steffen Staab, Rudi Studer, and Andreas Witt PERMISSION TO REPRODUCE AND DISSEMINATE THIS MATERIAL HAS BEEN GRANTED BY	database;freedom of information laws by country;html;hypertext;inference engine;manufacturing execution system;markup language;ontology (information science);resource description framework;www;world wide web;xml	Dieter Fensel;Jürgen Angele;Stefan Decker;Michael Erdmann;Hans-Peter Schnurr;Steffen Staab;Rudi Studer;Andreas Witt	1999			database;world wide web;information retrieval	DB	-40.89302481099808	6.133195651779357	24681
7fadc3c60f5d7a3a1e28a413cef82a7a0ebcd004	partition-based block matching of large class hierarchies	distributed system;ontologie;partition method;systeme reparti;image processing;red www;web semantique;reseau web;procesamiento imagen;traitement image;similitude;large scale;sistema repartido;methode partition;internet;linguistique structurale;web semantica;similarity;linguistica estructural;tâche appariement;tarea apareamiento;semantic web;correspondencia bloque;block matching;world wide web;ontologia;metodo particion;similitud;correspondance bloc;structural linguistics;ontology;matching task;large classes;virtual document;ontology matching	Ontology matching is a crucial task of enabling interoperation between Web applications using different but related ontologies. Due to the size and the monolithic nature, large-scale ontologies regarding real world domains cause a new challenge to current ontology matching techniques. In this paper, we propose a method for partition-based block matching that is practically applicable to large class hierarchies, which are one of the most common kinds of large-scale ontologies. Based on both structural affinities and linguistic similarities, two large class hierarchies are partitioned into small blocks respectively, and then blocks from different hierarchies are matched by combining the two kinds of relatedness found via predefined anchors as well as virtual documents between them. Preliminary experiments demonstrate that the partitionbased block matching method performs well on our test cases derived from Web directory structures.	algorithm;biclustering;class hierarchy;cluster analysis;directory (computing);dynamic web page;experiment;interoperation;ontology (information science);ontology alignment;test case;time complexity	Wei Hu;Yuanyuan Zhao;Yuzhong Qu	2006		10.1007/11836025_8	the internet;similarity;image processing;computer science;artificial intelligence;theoretical computer science;similitude;semantic web;ontology;structural linguistics;database;world wide web;algorithm	AI	-38.10302951409869	12.769060307125974	24706
0217b1337b790aedbce39deed8c7f2671e9bb86b	case-based reasoning integrating with direct-case-linkage for tacit knowledge management	performance test;case base reasoning;tacit knowledge;knowledge creation;conference proceeding	Tacit knowledge is the source of knowledge creation, but the organization and retrieval of tacit knowledge using IT has not been discussed much. In this paper, we defined Internal Knowledge Evolution Network (IKEN) to describe the knowledge evolution process from tacit to explicit, and applied the Case-Based Reasoning (CBR) integrating with Direct-Case-Linkage technique to support the IKEN management. To argue that the technique can better support the retrieval of tacit knowledge, we first implemented a prototype system, and then evaluated the system by carrying out a performance test.		Limin Lin;Hong Ling;Chang Zhang;L. Song;H. Xue	2003			case-based reasoning;computer science;knowledge management;body of knowledge;knowledge engineering;management science;procedural knowledge;knowledge extraction;personal knowledge management;knowledge value chain;domain knowledge	AI	-62.166859318239354	13.525866733678088	24750
3decd92db9aa422744b9071ffc6897cb002400e6	systematic and structured methods for digital board testing				Frans P. M. Beenker	1985			computer engineering;computer science;electronic engineering;structured analysis and design technique	HCI	-56.71190790216233	6.592889760245892	24833
f86ef53873023bd4a710ddbfae40bafdba757fc3	compatibility analysis of local process views in interorganizationalworkflow	groupware;workflow autonomy;workflow process modeling;local process views;interorganizational workflow;privacy preservation;interorganizational collaboration environment;compatibility analysis;collaborative environment;data privacy;cultural backgrounds;workflow management software;collaborative work cultural differences companies privacy informatics subcontracting global communication documentation telephony contracts;workflow inter visibility;workflow inter visibility compatibility analysis local process views interorganizational workflow interorganizational collaboration environment cultural backgrounds workflow process modeling privacy preservation workflow autonomy;workflow management software data privacy groupware organisational aspects;organisational aspects	In an interorganizational collaboration environment, due to different cultural backgrounds, participants from different organizations always have different views of modeling workflow process. Moreover, organizations require preserving privacy and autonomy of its own workflow. Therefore, workflow inter-visibility is expected to be as little as collaborations need. This paper proposes an approach of modeling loosely coupled interorganizational workflow considering different views of organizations. In this approach, organizations have their own local process views of modeling workflow process instead of sharing a predefined global workflow. Furthermore, we design compatibility analysis mechanism for different local process views to detect incompatibilities among organizations. Finally, we provide a demo tool for the proposed mechanism.	algorithm;analysis of algorithms;interaction protocol;loose coupling;privacy;social informatics	Donghui Lin	2007	The 9th IEEE International Conference on E-Commerce Technology and The 4th IEEE International Conference on Enterprise Computing, E-Commerce and E-Services (CEC-EEE 2007)	10.1109/CEC-EEE.2007.34	workflow;information privacy;computer science;knowledge management;management science;collaborative software;workflow technology	Robotics	-54.45555234465018	17.897941994079623	24844
7f2c4ccf9096c1e32d38017f7136f117628352c9	a goal driven framework for software project data analytics	conditional contributions;software analytics;software engineering;multi view goal models;probabilistic reasoning	The life cycle activities of industrial software systems are often complex, and encompass a variety of tasks. Such tasks are supported by integrated environments (IDEs) that allow for project data to be collected and analyzed. To date, most such analytics techniques are based on quantitative models to assess project features such as effort, cost and quality. In this paper, we propose a project data analytics framework where first, analytics objectives are represented as goal models with conditional contributions; second, goal models are transformed to rules that yield a Markov Logic Network (MLN) and third, goal models are assessed by an MLN probabilistic reasoner. This approach has been applied with promising results to a sizeable collection of software project data obtained by ISBSG repository, and can yield results even with incomplete or partial data.	capability maturity model integration;compiler;first-order logic;function point;integrated development environment;markov chain;markov logic network;probabilistic turing machine;smart;scrum (software development);semantic reasoner;software analytics;software development;software project management;software system	George Chatzikonstantinou;Kostas Kontogiannis;Ioanna-Maria Attarian	2013		10.1007/978-3-642-38709-8_35	analytics;computer science;systems engineering;data science;software engineering;data mining;database;probabilistic logic;software analytics	SE	-60.79779426744388	30.839867077576347	25014
643f3df7b7d4afb62c8df6e708ef0123c268c89b	modelling web user synergism for the similarity measurement on the ontology matching: reasoning on web user felling for uncertain evolving systems	dynamical system;usage mining;similarity;user behavior;ontology;bifurcation theory;ontology matching	"""Though many ontology matching are characterized by various similarity measures this work introduces a method based on significant changes of """"a web user feelings"""" on web content, represented by web object. The development of a web user synergism on the similarity measurements for the ontology alignment has been modeled in terms of the systems dynamic. The analysis of the model proposed was done according to the Bifurcation Analysis, while its validation was performed with the comparison between the model results and the users observations."""	bifurcation theory;emergence;ontology alignment;web content	Massimiliano Dal Mas	2013		10.1145/2479787.2479799	upper ontology;ontology alignment;web modeling;computer science;ontology;data mining;ontology-based data integration;world wide web;owl-s;information retrieval;process ontology	Web+IR	-43.69164077123451	11.807721777383575	25110
48fd6a1c3b5b661622fd8adc2e853902aeea7374	argument evaluation in the context of assurance case confidence modeling	assurance case;evaluation assurance case confidence argument;decision making artificial intelligence;confidence;software reliability conferences;evaluation;formal argument evaluation assurance case confidence modeling decision making process assurance case argument;argument	In recent years, assurance cases have been gaining popularity across various domains, such as the railway, aeronautics, automotive and medical domains, as an important tool in the establishment of system safety. The assurance case is essentially an argument for the existence of a certain system property. The confidence that we may place in the validity of any such argument plays an important role in the decision-making process, both for the developer and the regulator. However, even though there is increasing interest in this research topic, it seems that there is no consensus on what the precise definition of assurance case confidence is, and therefore the approaches for its modeling and measurement vary. The concept of an assurance case argument is based on the ideas presented by Toulmin in his groundbreaking work [1]. He outlined a scheme for the layout of arguments, but did not provide guidelines for formal argument evaluation. Here we look into some works extending his ideas to incorporate a theory of argument evaluation, and offer our insights on what the implications are for the definition of confidence, as well as an approach that would prove suitable for its modeling. In essence, when we reason about the confidence one might place in an argument, we are trying to establish how well the argument corresponds to the notions of a 'good argument', as well as taking into account any and all sources of uncertainty that are inherent when we are faced with imperfect information. Even so, what we ultimately measure is not how true the conclusions of the argument are, but instead, how justifiable they are given our current knowledge.	system safety;theory	Silviya Grigorova;T. S. E. Maibaum	2014	2014 IEEE International Symposium on Software Reliability Engineering Workshops	10.1109/ISSREW.2014.87	argument;reliability engineering;toulmin method;computer science;knowledge management;evaluation;management science;confidence	Embedded	-57.49833062819086	22.080726486584613	25162
adc7c08b31d0c4302a00f8418f568e90730c1e99	reusability and composability analysis for an agent-based hierarchical modelling and simulation framework		Abstract Agent-based modeling and simulation has been proved useful in a variety of different complex adaptive systems comprised of autonomous, interacting components. To resolve the shortcoming of current agent-based modeling frameworks with respect to decomposition and modularity, this paper presents a formal hierarchical modeling and simulation framework with three–level architecture to reduce ambiguity as well as improve clarity in the model definition. The bottom level is Component Model (CM), which implements some domain-specific support functionality, such as curve motion in the physical domain, intelligent decision-making in the cognitive domain, etc. The middle level is Agent Model (AM), which describes an agent which can react to the current situation by executing a sequence of CMs. The top level is System Model (SM), which defines that a CAS model consists of several AMs and also the interactions between these AMs. In the hierarchical architecture, one SM can be built up from lower-level models, which were linked in a loosely coupled fashion via an event-driven interface. We then analyze the reusability and composability of lower-level models of this hierarchical framework in a formalized way. To demonstrate the effectiveness of the proposed solution, we develop a graphical composite modelling tool named GraphSim , and the case study concerning two social dynamics system scenarios is also presented.		Feng Zhu;Yiping Yao;Jin Li;Wenjie Tang	2019	Simulation Modelling Practice and Theory	10.1016/j.simpat.2018.10.009	architecture;computer science;real-time computing;system model;modularity;composability;social dynamics;reusability;modeling and simulation;distributed computing;complex adaptive system	Logic	-42.30128947757344	21.645884968815793	25176
3b2ec3d3d2bfe44d481a97545728f29ff7235c3e	privacytag: a community-based method for protecting privacy of photographed subjects in online social networks		Online social networks, such as Facebook, have become popular with people of all ages, and online communication with friends and acquaintances via messages that include photos has become very common. With the increasing ease with which users can take and post photos, the unintentional disclosure of sensitive information of various kinds through mistakes made while posting has become a problem. In this work, we focused on the privacy of people appearing in photos and developed a method called “PrivacyTag” for adaptively blurring their facial area in accordance with the communities to which they belong by using tags embedded with community-based privacy policies. We also evaluated a newly designed privacy tag and developed a prototype application for Facebook that uses this tag.		Shimon Machida;Adrian Dabrowski;Edgar R. Weippl;Isao Echizen	2017		10.1007/978-3-319-68557-1_24	business;privacy policy;internet privacy;information sensitivity;computer security;social network	ML	-50.22393227306435	5.23409720241557	25228
1e9fb0be7a154ff9f8e4c612aa9251af233fdc41	a formal treatment of agents, goals and operations using alternating-time temporal logic	formal treatment;online shopping marketplace;core modelling language;alternating-time temporal logic;behavioural goal;atlkhi formula;requirements engineering modelling language;multi-agent temporal logic;formal framework;toy example;main concept;formal semantics	The aim of this paper is to provide a formal framework for Requirements Engineering modelling languages featuring agents, behavioural goals and operations as main concepts. To do so, we define Khi, a core modelling language, as well as its formal semantics in terms of a fragment of the multi-agent temporal logic ATL*, called ATLKhi. Agents in the sense of concrete and provided entities, called actors, are defined by their capabilities. They also pursue behavioural goals that are realised by operations, which are themselves gathered into abstract, required, agents, that we call roles. Then a notion of assignment, between (coalitions of) actors and roles is defined. Verifying the correctness of a given assignment then reduces to the validity of an ATLKhi formula that confronts the capabilities of (coalitions of) actors with the operations in roles played by the said actors. The approach is illustrated through a toy example featuring an online shopping marketplace.	actor model;alternating-time temporal logic;assignment (computer science);correctness (computer science);entity;modeling language;multi-agent system;online shopping;requirements engineering;semantics (computer science)	Christophe Chareton;Julien Brunel;David Chemouil	2011		10.1007/978-3-642-25032-3_13	simulation;computer science;knowledge management;artificial intelligence	AI	-42.986518717754464	19.007377773650774	25279
54ec0c901847e5bf689f5d324682712c69c0b1ff	an integrated framework for developing discrete-time modelling in software reliability engineering	imperfect fault debugging;software testing and debugging;fault debugging complexity;nonhomogenous poisson process;software reliability engineering	Quality and Reliability Engineering International#R##N#Early View (Online Version of Record published before inclusion in an issue)	reliability engineering;software reliability testing	Omar Shatnawi	2016	Quality and Reliability Eng. Int.	10.1002/qre.1978	reliability engineering;real-time computing;search-based software engineering;computer science;social software engineering;software reliability testing;software engineering;software construction;algorithmic program debugging;software quality;software fault tolerance	SE	-62.47831925017805	31.506683171396993	25280
b7be9483cb41d16c975ca2b6a45c3b67e0240711	on qos web service composition using satisfiability	quality of service software as a service cloud computing planning artificial intelligence;web service composition;sat;weighted maxsat problem qos web service composition satisfiability cloud computing software as a service service oriented architectures data stream saas web service composition;artificial intelligence;planning;software as a service;quality of service;web service composition cloud computing software as a service sat quality of service;web services cloud computing computability quality of service service oriented architecture;cloud computing	Cloud Computing based Software as a Service (SaaS) combines multiple Web Services in order to satisfy a SaaS request. SaaS is based on Service Oriented Architectures and Web Service technology which are popular paradigm to design new generation of applications. These functionalities are published on the Internet, but exploiting rigorously a large data stream in order to use Web Services is a complicated and laborious task which may involve error prone. In this paper we investigate the problem of SaaS Web Service Composition. We present a new technique that translates the problem of minimum SaaS Web Services composition into MaxSAT problem. We extend this encoding to take int account the QoS by proposing a weighted MaxSAT version.	algorithm;cloud computing;cognitive dimensions of notations;computation;computational problem;internet;maximum satisfiability problem;programming paradigm;quality of service;real life;service composability principle;service-oriented architecture;software as a service;web service	Abderrahim Ait Wakrime;Saïd Jabbour	2015	2015 5th International Conference on Information & Communication Technology and Accessibility (ICTA)	10.1109/ICTA.2015.7426929	planning;web service;service level requirement;web modeling;mobile qos;service catalog;quality of service;cloud computing;differentiated service;computer science;artificial intelligence;service delivery framework;operating system;ws-policy;service-oriented architecture;service design;cloud testing;software as a service;database;distributed computing;utility computing;data as a service;world wide web	DB	-45.70042073707323	14.775864357524872	25306
dae27fea9a1d34b148a7396a1a55a82adbb32080	virtual constructor used for research of hydrotransport system operation conditions	database management systems;pipelines mathematical model high temperature superconductors valves training personnel software;virtual reality;virtual reality computer based training database management systems graphical user interfaces personnel;graphical user interfaces;personnel;computer based training;virtual constructor educational training problems reference databases virtual element libraries graphical interface personnel training hydrotransport system;personnel training computer simulator virtual constructor virtual model hydrotransport system technological schemes	A hydrotransport system virtual constructor structure is offered. It including a set of apparatus and modeling aids for rapid and efficient creation of technological schemes, their analysis and personnel training. A graphical interface enabling flexible creation of new virtual element libraries, reference databases, extension of the scope of educational-training problems is developed.	complexity;database;global variable;graphical user interface;library (computing);prototype pattern	Mikhaylo V. Zagirnyak;E. Korenkov;Anatolii Kravets;T. Korenkova	2013	Eurocon 2013	10.1109/EUROCON.2013.6625132	simulation;human–computer interaction;computer science;knowledge management;operating system;graphical user interface;virtual reality	Visualization	-55.65579464956093	9.755666608314876	25331
f8d830e9663e864c957890f27778aeeabed33446	on the reduction of sequences of xml document and schema update operations	reduction rules xml document schema update operations data throughout sequence reduction;document handling;xml schema;complexity theory;protein complex;schema update operations;xml document handling;vegetation;data throughout;indexes;reduction rules;schema versioning;proteins;indexation;xml;xml document;xml labeling context vegetation proteins complexity theory indexes;temporal semistructured data;context;labeling;sequence reduction	Automating the management of data throughout its lifecycle requires solutions to effectively and efficiently handle updates, both on data and on the corresponding schema. Such solutions are expecially needed for XML documents and schemata, due to the high dynamicity of the contexts in which they are employed. XML documents need to be kept up-to-date, schemata as well are often subjected to updates and progressively refined to adapt to changing requirements. In this paper, we address the problem of reducing a sequence of updates on a tree representing either an XML document or an XML schema. Reducing means deriving a shorter sequence with the same effect on the tree of the original one. Specifically, we propose a set of reduction rules and an efficient reduction algorithm.	algorithm;benchmark (computing);database schema;experiment;overhead (computing);requirement;synthetic data;xml schema	Federico Cavalieri;Giovanna Guerrini;Marco Mesiti;Barbara Oliboni	2011	2011 IEEE 27th International Conference on Data Engineering Workshops	10.1109/ICDEW.2011.5767649	well-formed document;xml validation;xml encryption;simple api for xml;xml;relax ng;xml schema;streaming xml;computer science;document definition markup language;document structure description;xml framework;data mining;xml database;xml schema;database;document schema definition languages;xml signature;xml schema editor;information retrieval;efficient xml interchange	DB	-35.968808816861916	4.697976558622158	25380
d604f64fd390e9474979eec1c84d95c5682aa6ae	a web-based virtual machine for developing computational societies	virtual machine;multiagent system;programming language;agent based;separation of concern;social network;electronic institution;business process	Different theoretical and practical insights into the field of computational organisations and electronic institutions has led to a clear separation of concerns between societal and agent-based features in the implementation of multiagent systems. From a theoretical perspective, this separation of concerns is also at the core of recent proposals towards a  societal programming language. Building on the operational model of one of these proposals, this paper addresses the practical issue of implementing a web-based virtual machine for that language. The resulting framework is intended to be used in a wide range of applications, all of them related to the implementation of social processes (business processes, social networks, etc.).	computation;virtual machine	Sergio Saugar;Juan Manuel Serrano	2008		10.1007/978-3-540-85834-8_14	simulation;separation of concerns;computer science;knowledge management;virtual machine;artificial intelligence;management science;business process;world wide web;social network	HPC	-44.67139984980264	20.358750904955528	25409
550ad9c6722381b29d0a6a26e2c12a33e23b7f42	a quality model for spreadsheets	quality assessment spreadsheet quality model iso iec 9126 standard software quality model software characteristics spreadsheet characteristic spreadsheet specific metrics normal distribution euses spreadsheet corpus quality score;quality model;spreadsheet programs iec standards iso standards normal distribution software quality	In this paper we present a quality model for spreadsheets based on the ISO/IEC 9126 standard that defines a generic quality model for software. To each of the software characteristics defined in the ISO/IEC 9126, we associate an equivalent spreadsheet characteristic. Then, we propose a set of spreadsheet specific metrics to assess the quality of a spreadsheet in each of the defined characteristics. To obtain the normal distribution of expected values for a spreadsheet in each of the proposed metrics, we have executed them in the widely used EUSES spreadsheet corpus. Then, we quantify each characteristic of our quality model after computing the values of our metrics, and we define quality scores for the different ranges of values. Finally, to automate the quality assessment of a given spreadsheet, according to our quality model, we have integrated the computation of the metrics it includes in both a batch and a web-based tool.	computation;iso/iec 9126;programming tool;spreadsheet;web application	Jácome Cunha;João Paulo Fernandes;Christophe Peixoto;João Saraiva	2012	2012 Eighth International Conference on the Quality of Information and Communications Technology	10.1109/QUATIC.2012.16	reliability engineering;computer science;systems engineering;software engineering	SE	-59.09666524655806	28.228804672989924	25438
b7fec1781c63dea4ef3a1cea19bd2cb967db5d67	online monitoring system of the enrichment factory input ore flows quality on the base of temporal model		This article describes the solution of the problem of determining the ore belonging to a particular quarry in the multi-flow technological process of ore crushing at the ore enrichment fabric of a mining and processing plant. The paper proposes a new temporal model for solving this problem and describes its implementation in the form of an online monitoring system of ore quality and it belonging to a concrete quarry.	gene ontology term enrichment	Viktor Toporov;Valery Axelrod;Ualsher Tukeyev	2018		10.1007/978-3-319-75420-8_64	data mining;factory;computer science	DB	-55.56679248545973	12.428923598290194	25442
95392f3b98bf85e176f1f9dd02e2aa938c7900a1	goal-driven software product line engineering	model analysis;feature modeling;goal oriented requirements engineering;large scale;product family;software product line	Feature Models encapsulate functionalities and quality properties of a product family. The employment of feature models for managing variability and commonality of large-scale product families raises an important question: on what basis should the features of a product family be selected for a target software application, which is going to be derived from the product family. Thus, the selection of the most suitable features for a specific application requires the understanding of its stakeholders' intentions and also the relationship between their intentions and the available software features. To address this important issue, we adopt a standard goal-oriented requirements engineering framework, i.e., the i* framework, for identifying stakeholders' intentions and propose an approach for explicitly mapping and bridging between the features of a product family and the goals and objectives of the stakeholders. We propose a novel approach to automatically preconfigure a given feature model based on the objectives of the target product stakeholders. Also, our approach is able to elucidate the rationale behind the selection of the most important features of a family for a target application.	best practice;bridging (networking);design rationale;feature model;feature selection;requirement;requirements engineering;software product line;spatial variability	Mohsen Asadi;Ebrahim Bagheri;Dragan Gasevic;Marek Hatala;Bardia Mohabbati	2011		10.1145/1982185.1982336	knowledge management;product design specification;management science;product design;new product development;product engineering	SE	-56.62724585987752	25.19580860051821	25449
56e4cea249cd8d99528c7c8052721893d4d46617	distributed goal-oriented reasoning engine for multi-agent systems: initial implementation	goal orientation;multi agent system;agent systems	This paper describes the sample implementation of a distributed goaloriented reasoning engine formulti-agent systems. The  paper summarizes part of the design and programming issues that we addressed for providing the initial prototype with customization  and self-configuration facilities.  	multi-agent system;semantic reasoner	Mihnea Scafes;Costin Badica	2009		10.1007/978-3-642-03214-1_35	real-time computing;simulation;computer science;knowledge management	AI	-41.88312411521503	21.07555148985212	25494
d0d3d8d57a025f747defea2cb1e1f47a0b7f1ca7	an extensible graphical programming environment for semantic modelling	graphical programming	Extensible semantic models which allow the definition and subsequent use of user-defined, application specific modelling concepts are one approach to enhance database functionality for technical and engineering applications via a database design process that is trimmed for the specific application. In this paper we present an approach to how graphical programming techniques can be used to support the database design process. In particular will we discuss the definition of graphical representations for user-defined modelling concepts and their use for the acquisition, representation and modification of knowledge. Furthermore we present different abstraction techniques which are absolutely necessary when applications of a certain complexity are to be modelled. All principles and techniques described in this paper have already been implemented in the DEED project, a prototype design environment for engineering database applications currently under development.		Klaus Radermacher	1992			natural language processing;first-generation programming language;declarative programming;human–computer interaction;programming domain;reactive programming;functional reactive programming;extensible programming;functional logic programming;programming paradigm;event-driven programming;procedural programming;symbolic programming;inductive programming	HCI	-47.51583535207436	25.29950954605725	25549
a77cce35bf04a2eabea107f61296030336398933	supply chain systems - recent trend in research and applications	special issues and sections;decision making supply chain system autonomous company;supply chains;production planning;supply chains decision making production planning supply chain management;supply chain;special issues and sections supply chains supply chain management;supply chain management	Supply chains consist of a number of autonomous companies that make decision independently. In this paper applications of various system approaches from theoretical to implementation issues of supply chain systems are discussed. This special section is a collection of original re search that addresses various aspects of supply chain systems design, implementation, and applications.		Hing Kai Chan	2011	IEEE Systems Journal	10.1109/JSYST.2010.2100191	supply chain risk management;demand chain;supply chain management;service management;systems engineering;supply chain	Embedded	-61.78461990492559	8.26434204234803	25635
7ad20e488b3812431ca73bd9dd2a54ab12e8709d	an on-line assistance system for the simulation model development environment	outil logiciel;software tool;base donnee;programming environment;on line;en linea;relacion hombre maquina;database;base dato;man machine relation;systeme conversationnel;user assistance;medio ambiente programacion;development environment;assistance utilisateur;interactive system;herramienta controlada por logicial;asistencia usuario;sun 3 160c;sistema conversacional;en ligne;relation homme machine;simulation model;environnement programmation	Abstract   The Assistance Manager, one of the tools of the Simulation Model Development Environment (SMDE), is required to provide effective and efficient transfer of assistance information to an SMDE user. This paper describes a prototype of the SMDE Assistance Manager. Objectives are set forth and a design is established and implemented on a SUN   3  160C   workstation. The prototype is evaluated with respect to the design objectives and is shown to provide a highly flexible interface between the user and the database of assistance information. Results indicate that the prototype Assistance Manager incorporates the characteristics considered desirable in on-line assistance systems and serves as a basis for future enhancement and development.	simulation	Valerie L. Frankel;Osman Balci	1989	International Journal of Man-Machine Studies	10.1016/0020-7373(89)90022-9	embedded system;simulation;computer science;simulation modeling;development environment	Robotics	-35.26519572869105	24.83539513153879	25796
9e740f024eae49c24fb3cf2462a5abff4c1ef00d	trajectory description conception for industrial robots	industrial robots;trajectory service robots planning libraries multiprotocol label switching software algorithms	In this paper we observe the difficulties one can face, while wiling to obtain a complicated robot movement, like using multiple standalone or implemented in different MPLs (Motion Planning Library) algorithms. We propose a new conception and a language whose goal is to solve these problems. The idea is to present an interface between robot programming instruments and existing algorithms. In contrast to the existing related methods, we propose approach based on the declarative language (without control flow) for a trajectory specification. Our goal is to provide a powerful tool for developers of software approaches for industrial robots programming. It should allow them to obtain difficult motions by easy combination of different MPLs in one application using unified specification of the movement. In addition, the proposed conception hides the inner structure of libraries and eliminates the need to investigate algorithms before applying. That would increase the speed and the quality of the newly developed software systems.	algorithm;control flow;declarative programming;industrial robot;library (computing);motion planning;multiphoton lithography;multiprotocol label switching;online and offline;software design pattern;software system	Sergey Alatartsev;Matthias Güdemann;Frank Ortmeier	2012			simulation;computer science;artificial intelligence;operations management	Robotics	-50.71194460287769	30.404440091220344	25830
569aa494f89959331984133b82145cfe8178e6fd	extending iso/iec 29110 basic profile with privacy-by-design approach: a case study in the health care sector		Privacy related elements have become an essential part of any information system. Previous studies reveal a scarcity of research on privacy in software processes, few engineering practices and a lack of methodological support to address privacy requirements in software systems. Introducing Privacy-by-Design (PbD) into software developments is an advantageous solution to tackle privacy related concerns. This paper presents an integration of PbD goals into the ISO/IEC 29110 Basic profile for small software development organizations. The most frequently encountered privacy goals as well as privacy addressing practices from previous methodological proposals were taken into account and included in the form of tasks, work products and roles. As a practical example, we describe a real life project development of a health care system that motivated the creation of the ISO/IEC 29110 PbD extension.		Miguel Morales Trujillo;Gabriel Alberto García-Mireles	2018	2018 11th International Conference on the Quality of Information and Communications Technology (QUATIC)	10.1109/QUATIC.2018.00018	software system;privacy by design;systems engineering;scarcity;project management;information system;health care;software;computer science;software development	SE	-61.4142471108084	17.21291509691577	25833
6901eb54cbd148c9db710778614fcb9b9f16c775	study  on the intelligent cad technology of body welding jig based on the knowledge	reused knowledge database intelligent cad technology body welding jig automobile body production;automobile manufacture;field knowledge knowledge engineering body welding jig intelligent cad case knowledge;cad;welding;intelligent cad;indexing method;field knowledge;welding design automation artificial intelligence automotive engineering fixtures automobiles intelligent vehicles production deductive databases technology planning;describing function;body welding jig;case knowledge;welding automobile manufacture cad;knowledge base;knowledge engineering	In order to assure the quality of welding-assembly, A great deal body welding jigs are used during the all process of automobile body production. The structure of body welding jig have resemblance. It provides the technological support and achieved probability to develop the standardized design. The intelligent CAD technology based on knowledge, based on summing up design experience and field knowledge, can build a reused knowledge database and design planning model by abstracting, describing and maintaining, to offer some index method. By analyzing and describing function and structure character of the body welding jig, This paper builds knowledge base of typical body welding jig and introduces knowledge project into conventional CAD system, which will effectively support fast realization of intelligent CAD of body welding jig.	caddie;computer-aided design;knowledge base	Xiaoping Xiong;Quandong Jin;Pingping Jiang	2009	2009 Second International Workshop on Knowledge Discovery and Data Mining	10.1109/WKDD.2009.155	knowledge base;computer science;artificial intelligence;describing function;knowledge engineering;cad;welding	Robotics	-57.60763157492743	10.684209963126664	25857
341838c9804c385afe52dfa33e41df7abf0b5bc4	an evaluation of the adaptation capabilities in programming languages	context aware;programming language;programming paradigm;non functional requirement;context oriented programming;object oriented;aspect oriented programming;adaptive system;self adaptive software;context	In recent years the need for software applications to adapt to the environment in which they are situated has become common. Beside architectural approaches, language-level support for the development of adaptable and context-aware software have been investigated. Many existing solutions adopt ad hoc programming paradigms such as aspect oriented programming (AOP) or context oriented programming (COP). In this paper we investigate the use of the abstractions offered by traditional object-oriented and functional paradigms for the development of context-adaptable systems. We carry out our analysis along a set of conceptual directions which consider the requirement of functional adaptation beside non functional requirements such as safety and effective modularization. Our analysis were validated though the development of several prototypes of an adaptable cache server which is chosen as the running example through the paper. We provide an estimation of the performance advantages of the techniques based traditional programming languages compared with context-oriented programming.	aspect-oriented programming;functional requirement;hoc (programming language);programming language;programming paradigm;server (computing);situated;web cache	Carlo Ghezzi;Matteo Pradella;Guido Salvaneschi	2011		10.1145/1988008.1988016	constraint programming;protocol;real-time computing;declarative programming;programming domain;reactive programming;functional reactive programming;computer science;systems engineering;software development;extensible programming;functional logic programming;programming paradigm;procedural programming;symbolic programming;inductive programming;fifth-generation programming language;programming language theory;programming language;comparison of multi-paradigm programming languages;concurrent object-oriented programming;programming in the large and programming in the small	SE	-52.32932212092275	29.514498147634896	25949
2567e1a534c5453428ce441b11906063f7448b7a	e-government services composition using multi-faceted metadata classification structures	value added services;service composition;public sector;process model;service delivery	The connectivity generated by the Internet is opening new opportunities in service delivery. As a consequence, administrations are forming online alliances in order to deliver integrated value-adding services. However, due to lack of a step-by-step method for identification, classification and further processing of services, the development of such composite eGovernment services across organizations is usually ad-hoc. In this paper, we demonstrate how such a systematic service composition can be accomplished: with the help of the proposed Service Description Worksheet, acting as a multifaceted taxonomy tool, the e-Government Services can now be classified, grouped, searched for and composed into larger groups. This goal driven approach can be used to understand the needs of different organizations and to depict the various functional characteristics of the cooperative processes in a declarative manner, suitable for rapid prototyping projects in the public sector. The paper illustrates the proposed methodology and analyzes the facets of this Service Description Worksheet that drives a database implementation. Applying this method in the context of the Greek e-Government Services Framework, various services have been analysed, populating the worksheet database and leading to corresponding process models applicable to services for citizens and businesses.	business process model and notation;code refactoring;e-government;e-services;faceted classification;hoc (programming language);itil;information system;internet;interoperability;list comprehension;mechatronics;prism (surveillance program);population;rapid prototyping;relational database;requirement;service composability principle;service-oriented architecture;xml schema	Fenareti Lampathaki;Yannis Charalabidis;Demetrios Sarantis;Sotirios Koussouris;Dimitris Askounis	2007		10.1007/978-3-540-74444-3_11	differentiated service;knowledge management;service delivery framework;process modeling;database;public sector;services computing;world wide web;computer security;service system	Web+IR	-49.059273907715784	14.046216614997675	25956
0989b93d7feee18d4eb18c591cc56c80d88d7496	applying agent oriented software engineering to cooperative robotics	search and rescue;multiagent system;bottom up;cooperative robotics;top down;analysis and design;agent oriented software engineering;multirobot systems;system design;autonomous robot	This paper reports our progress in applying multiagent systems analysis and design techniques to autonomous robotics applications. In this paper, we apply the Multiagent Systems Engineering (MaSE) methodology to design a team of autonomous, heterogeneous search and rescue robots. MaSE provides a top-down approach to building multirobotic systems instead of the bottom up approach employed in most robotic implementations. We follow the MaSE steps and discuss various approaches and their impact on the final system design.	agent-based model;autonomous robot;multi-agent system;robotics;software engineering;structured systems analysis and design method;systems design;systems engineering;top-down and bottom-up design	Scott A. DeLoach;Eric T. Matson;Yonghua Li	2002			simulation;artificial intelligence;top-down and bottom-up design	AI	-43.35573716164999	22.13896317074137	26003
b10298221848396f5d47431863d3c976d07ad7a6	using map for recovering the architecture of web systems of a spanish insurance company	web system;web based applications;insurance data processing;software maintenance;spanish insurance company;software systems;maintenance cost;product line;object oriented programming;software reusability insurance data processing internet object oriented programming software architecture software maintenance;web applications;architecture mining web system architecture spanish insurance company software maintenance software system evolution web applications software architecture reusable components;software architecture;internet;software reusability;web system architecture;software system evolution;reusable component;reusable components;architecture mining;insurance companies;service oriented architecture insurance computer architecture software systems application software software architecture software maintenance costs informatics telematics	Software maintenance is a key activity for supporting the evolution of existing software systems but in many cases they are considered time consuming tasks. In certain systems (e.g., Web applications), changes must be performed very often and the time to carry out the maintenance activities is very short. In such cases, the need to count with suitable software architectures able to support the dynamicity of changes or new requirements becomes a need for every software project. In this work we describe how we applied the MAP method for building the architecture of a Web-based application of a Spanish insurance company. One of the goals of the company was to reduce the maintenance costs of the existing systems, which motivated to move to a product line approach and fostering the usage of reusable components. We describe a case study carried out in a Spanish insurance company to obtain a single architecture valid for several applications belonging to the same domain	map;requirement;software architecture;software maintenance;software project management;software system;web application	Rafael Capilla	2005	13th IEEE International Workshop on Software Technology and Engineering Practice (STEP'05)	10.1109/STEP.2005.33	reliability engineering;reference architecture;systems engineering;engineering;software engineering	SE	-58.0148755859178	22.65597926912368	26018
62bf686cd82726fc156949f2092140d5afe8eeed	a hybrid approach to process mining: finding immediate successors of a process by using from-to chart	graph theory;graph theory business data processing data mining;process model discovery;training;dependency graph;materials;data mining;process mining;event logs;from to chart;hybrid approach;evaluation metric;monitoring;business data processing;materials handling;activity transition monitoring;business;event logs from to chart process discovery immediate successor process mining;process discovery;evaluation metrics;process model;frequency graph process mining from to chart data mining process model discovery event logs activity transition monitoring evaluation metrics dependency graph;immediate successor;frequency graph;monitoring machine learning production software engineering neural networks noise measurement concurrent computing connectors petri nets machine learning algorithms;data models	"""Process mining is a branch of data mining that aims to discover process model from the event logs. In this study, we propose a hybrid approach to process mining in such a way that, """"from-to chart"""" is used as the frontend to monitor the transitions among activities of a realistic event log. Another novelty of this study is developed evaluation metrics, which are used for finding immediate successors in order to convert these raw relations into dependency/frequency graph."""	data mining;process modeling	Eren Esgin;Pinar Senkul	2009	2009 International Conference on Machine Learning and Applications	10.1109/ICMLA.2009.107	data modeling;dependency graph;computer science;graph theory;data science;machine learning;process modeling;data mining;database;process mining;business process discovery	ML	-53.14813537952535	17.48090066502041	26060
3723eb8f09eb2f23fd694d0a1933fd3776f14e2e	a modeling method to develop goal-oriented adaptive agents in modeling and simulation for smart grids	adaptability;smart grid;role based organization model and goal oriented requirement engineering;agent based modeling and simulation;maintainability	Agent-based modeling and simulation is a useful method to analyze and predict the complex and dynamic behavior of a smart grid which consists of diverse stakeholders and components such as devices, services and policies. A smart grid adaptively behaves in its dynamically changed environment and evolves over time as introducing new components and modifying (or removing) the existing components. Therefore, the model of the grid also has to be adaptive and evolutionary for users to obtain meaningful analysis. In this work, we propose a goal-oriented modeling and simulation framework to systematically model and simulate an adaptive and evolutionary smart grid. In this framework, we concentrate on the activity to design agents for the grid. This activity is based on a goal-oriented organizational agent model which goal-oriented requirement language, belief-desire-intention architecture and agent-group-role model are integrated into. This model helps modelers to design adaptive agents from their simulation requirements and to revise their models with the already developed agents like as a smart grid evolves. Further, we demonstrate the benefits of our modeling method in designing agents for a simulation scenario where a virtual power plant shares profit with its distributed energy resources in a smart grid.	goal modeling;goal-oriented requirements language;requirement;simulation	Hyo-Cheol Lee;Hee-Soo Kim;Seok-Won Lee	2014		10.1145/2593845.2593846	real-time computing;simulation;systems engineering;engineering	AI	-42.68022063437326	21.266076941553	26075
08e2531d2608e4a447d2bfb958fb3dfb493dbb78	evaluation of deviating alerts coming from behavioral intrusion detection system	system approach;support vector machines;risk analysis;bayes methods;anomaly detection;bayesian modeling behavioral intrusion detection system decision block function risk analysis support vector machines behavioral anomaly detection;intrusion detection;bayesian modeling;support vector machines bayes methods risk analysis security of data;behavioral anomaly detection;decision block function;support vector machine;behavioral intrusion detection system;security of data;intrusion detection monitoring engines bayesian methods information systems information security risk analysis support vector machines machine vision event detection;intrusion detection system;bayesian model	The growth of behavioral intrusion detection solutions raises a new issue. The update of normal references is necessary and determines the flexibility and accuracy of the detection. This paper describes a decision block function used to update a behavioral intrusion detection method. Based on a risk analysis and support vector machines, our approach completes the behavioral anomaly detection using Bayesian modeling based on a global vision of the system approach.	anomaly detection;automaton;it risk management;information system;intrusion detection system;semiconductor industry;support vector machine;test set	Jacques Saraydaryan;Véronique Legrand;Stéphane Ubéda	2007	The International Conference on Emerging Security Information, Systems, and Technologies (SECUREWARE 2007)	10.1109/SECUREWARE.2007.4385320	anomaly-based intrusion detection system;intrusion detection system;support vector machine;anomaly detection;computer science;machine learning;pattern recognition;data mining;bayesian inference;computer security	EDA	-35.56044786270116	21.15045718778208	26172
d3af9ffe7ea7fac878f0afe61d97dfce88cf589e	a systematic approach to mission and scenario planning for uavs	systematics;trajectory;safety;planning;collision avoidance;collision avoidance modeling planning trajectory systematics safety;modeling	As unmanned autonomous vehicles (UAVs) are being widely utilized in military and civil applications, concerns about mission safety and how to integrate different phases of mission design are growing significantly. One important barrier to a cost-effective and timely safety certification process for UAVs is the lack of a systematic approach for bridging the gap between understanding high-level commander/pilot intent and implementation of intent through low-level UAV behaviors. In this paper we demonstrate an entire systems design process for a representative UAV mission, beginning from an operational concept and requirements and ending with a simulation framework for segments of the mission design, such as path planning and decision making in collision avoidance.	autonomous robot;bridging (networking);high- and low-level;motion planning;requirement;scenario planning;simulation;systems design;unmanned aerial vehicle	Niloofar Shadab;Huan Xu	2016	2016 Annual IEEE Systems Conference (SysCon)	10.1109/SYSCON.2016.7490664	simulation;engineering;operations management;computer security	EDA	-34.165912201392146	20.84247810793715	26185
ecd8bf09b09fa9306ad978731e80879c006b8803	ontology management for large-scale e-commerce applications	search and retrieval;query language;owl;service composition;electronic commerce;management system;relational database table;virtual enterprises;api;application software;information retrieval;e commerce;relational database;resource description framework;ontologies artificial intelligence;query languages;enterprise computing;large scale;information integration;web ontology language;ontologies large scale systems application software resource description framework owl scalability markup languages information retrieval middleware database languages;markup languages;semantic web;middleware;meta data;ontologies;relational databases;scalability;enterprise scale ontology management system;large scale e commerce application;semantic markup language;markup language;relational database table large scale e commerce application semantic markup language rdf resource description framework owl web ontology language meta data middleware enterprise computing enterprise scale ontology management system api query language;database languages;rdf;large scale systems;semantic web electronic commerce ontologies artificial intelligence query languages relational databases virtual enterprises middleware	Semantic markup languages such as RDF (Resource Description Framework) and OWL (Web Ontology Language) are increasingly being used to externalize meta-data or ontologies about data, software and services in a declarative form. Such externalized descriptions in ontological format are used for purposes ranging from search and retrieval to information integration and to service composition. The barrier to more wide-spread use of ontologies for such applications is the lack of support in the currently available middleware stacks used in enterprise computing. This paper presents our work on developing an enterprise-scale ontology management system that provide APIs and query languages, and scalability and performance that enterprise applications demand. We present a novel approach to representing ontologies in relational database tables to address the scalability and performance issues.	application programming interface;e-commerce;enterprise software;markup language;middleware;ontology (information science);query language;relational database;resource description framework;scalability;semantic web;service composability principle;table (database);web ontology language	Juhnyoung Lee;Richard Goodwin	2005	International Workshop on Data Engineering Issues in E-Commerce	10.1109/DEEC.2005.14	upper ontology;idef5;open biomedical ontologies;ontology components;bibliographic ontology;computer science;ontology;data mining;database;ontology language;ontology-based data integration;web ontology language;information retrieval;process ontology	DB	-38.09830436148587	7.766920853248991	26207
f2296fb5b8c54553aeb2a718eb7db9f0d7364f90	an analyzable model of automated service negotiation	formal specification;insurance data processing;engineering and technology;teknik och teknologier;timed automata services service compositions service negotiation formal analysis;service negotiation;web services;web services automata theory formal specification insurance data processing service oriented architecture;automata theory;services;timed automata;formal analysis;service oriented architecture;web service automated service negotiation service oriented system formal model formal tools timing constraint cost constraint resource constraint information exchange mathematically driven technique analyzable negotiation model service clients service providers remes language textual service composition language hdcl negotiation interface negotiation strategy negotiation protocol timed automata formal framework insurance scenario contract net protocol;service compositions;analytical models clocks contracts automata protocols synchronization	Negotiation is a key aspect of Service-Oriented Systems, which is rarely supported by formal models and tools for analysis. Often, service negotiation proceeds with timing, cost and resource constraints, under which the users and providers exchange information on their respective goals, until reaching a consensus. Consequently, a mathematically driven technique to analyze various ways to achieve such goals is beneficial. In this paper, we propose an analyzable negotiation model between service clients and providers, in our recently introduced language REMES and its corresponding textual service composition language HDCL. The model can be viewed as a negotiation interface for different negotiation strategies and protocols, which iterates until an agreement is reached. We show how to analyze the negotiation model against timing, cost and utility constraints, by transforming it into the Timed Automata formal framework. We illustrate our approach through an insurance scenario assuming a form of the Contract Net Protocol for web services.	application-layer protocol negotiation;automata theory;business process execution language;contract net protocol;high- and low-level;image scaling;iterative method;model checking;operational semantics;service composability principle;service-oriented architecture;service-oriented device architecture;simulation;timed automaton;uppaal;vii;web service	Aida Causevic;Cristina Cerschi Seceleanu;Paul Pettersson	2013	2013 IEEE Seventh International Symposium on Service-Oriented System Engineering	10.1109/SOSE.2013.51	web service;service;computer science;knowledge management;service-oriented architecture;automata theory;formal specification;database;law;computer security	SE	-44.9063327174315	18.456434458032025	26212
050f4af05851990991430a44316b81db4b982033	methods of checking general safety criteria in uml statechart specifications	systeme commande;sistema control;reachability;sistema critica;consistencia semantica;securite;soundness;lenguaje uml;systeme critique;logiciel a securite critique;uml statecharts;safety systems;safety criteria;langage modelisation unifie;graph transformation;analisis programa;meta analisis;metaanalysis;control system;metamodel;critical system;safety analysis;metamodele;object oriented;metamodelo;asequibilidad;unified modelling language;ocl;safety critical software;safety;metaanalyse;consistance semantique;systeme securite;atteignabilite;oriente objet;program analysis;analyse programme;software specification;seguridad;orientado objeto;reachability analysis;system safety;intermediate representation	This paper describes methods and tools for safety analysis of UML statechart specifications. A comprehensive set of general safety criteria including completeness and consistency is applied in automated analysis. Analysis techniques are based on OCL expressions, graph transformations and reachability analysis. Two canonical intermediate representations of the statechart specification are introduced. They are suitable for straightforward implementation of checker methods and for the support of the proof of the correctness and soundness of the applied analysis. One of them also serves as a basis of the metamodel of a variant of UML statecharts proposed for the specification of safetycritical control systems. The analysis is extended to object-oriented specifications. Examples illustrate the application of the checker methods implemented by an automated tool-set. q 2004 Elsevier Ltd. All rights reserved.	control system;correctness (computer science);graph rewriting;metamodeling;object constraint language;reachability;state diagram;uml state machine;unified modeling language	Zsigmond Pap;István Majzik;András Pataricza;András Szegi	2005	Rel. Eng. & Sys. Safety	10.1016/j.ress.2004.04.011	reliability engineering;meta-analysis;computer science;systems engineering;engineering;control system;applications of uml;mathematics;system safety;algorithm	SE	-41.939992617606194	27.22368691331939	26223
80427a133e7252767a736383edad8a4f2ec11d53	a fuzzy-based multi-agent model to control the micro-grid operation based on energy market dynamics		The concept of distributed generation and renewable energy has increased the need for using Smartgrids which are electric micro-grids having intelligent characteristics that provide autonomy to the system not only to improve their operation but also to make it easier for users their management. The aim of this paper is to propose a fuzzy-based Multi-Agent Model to control a micro-grid by determining optimal operation states based on real-time process conditions and energy market dynamics. The Prometheus methodology is used for the MAS architecture design and development. The implementation of the system is carried out using Java, the JADE framework and the JFuzzyLogic library. Based on the proposed fuzzy MAS model, a prototype was implemented and validated through a case study. Results obtained demonstrate the effectiveness of this approach to automatically manage the states of a micro-grid when connected to external grid in a dynamic energy market environment. It is also possible to extend this application for different micro-grid applications involving other power generation, storage, and consumption capabilities.		Santiago Gil;Oscar M. Salazar;Demetrio Arturo Ovalle Carranza	2018		10.1007/978-3-319-94779-2_26	grid;renewable energy;electricity generation;architecture;fuzzy logic;distributed generation;real-time computing;energy market;java;computer science	Robotics	-37.62137574109888	22.037286207328346	26232
3e17dccd78c6198413a574e88301123695474c3b	reverse engineering web sales configurators	sales management;software maintenance;web;semi structured web pages reverse engineering web sales configurators reliability efficiency maintainability unstructured web pages;internet;data mining feature extraction web pages data models reverse engineering pattern matching crawlers;software reusability;web sites;web sites internet reverse engineering sales management software maintenance software reliability software reusability;reverse engineering web variability;variability;software reliability;reverse engineering	Sales configurators are widespread Web applications. Although such applications have specific common characteristics (e.g., they manage options governed by constraints, they enforce a configuration process.), they are usually developed in an unspecific way, that is, like any other Web application. Proceeding this way leads to configurators that are sub optimal in reliability, efficiency and maintainability. This PhD thesis is concerned with the reverse-engineering of Web sales configurators. It aims to develop a consistent set of methods, languages and tools to semi-automatically extract configuration-specific data from a Web configurator. Such data is stored in formal models (e.g., variability models, process models). These models can later be used for verification purposes (e.g., checking the completeness and correctness of the configuration constraints) as well as input for generative techniques (e.g., to re-engineer legacy configurators). More precisely, our two main research questions are: (1) How to extract variability data from the unstructured or semi-structured Web pages of a sales configurator? (2) How to extract such data from the dynamic content created when the configurator is executing? The accuracy of the extracted data and the scalability of the delivered tools are major concerns. The PhD thesis is meant to be completed within the coming year.	algorithm;correctness (computer science);dynamic web page;html;pattern matching;reverse engineering;scalability;semiconductor industry;spatial variability;web application	Ebrahim Khalil Abbasi	2013	2013 IEEE International Conference on Software Maintenance	10.1109/ICSM.2013.101	web service;web application security;web development;web modeling;the internet;data web;web analytics;web mapping;web design;web standards;computer science;engineering;software engineering;social semantic web;sales management;data mining;database;programming language;software maintenance;web 2.0;world wide web;software quality;reverse engineering	SE	-46.38878182288978	17.834856024784294	26285
fd310741a6048619242c386c03c153c29feb90a5	integration of safety analysis in model-driven software development	informatica;developpement logiciel;modelizacion;language analysis;safety requirement;arbol defecto;fault tree;ajustamiento modelo;program diagnostics;formal specification;langage modelisation;language refinement safety analysis model driven software development safety critical software software verification software architecture safety requirement software modelling language engineering platform independent language failure mode effects criticality analysis fault tree analysis unified modelling language language abstract syntax metamodel language mapping model transformation;telecomunicaciones;securite;lenguaje uml;platform independent language;software verification;logiciel a securite critique;exigence usager;exigencia usuario;criticite;safety systems;automatisation;model transformation;langage modelisation unifie;failure mode;program verification;automatizacion;desarrollo verbal;criticality analysis;model driven development;ajustement modele;modelisation;software architecture;verificacion programa;metamodel;safety analysis;diagnostic panne;metamodele;arbre defaut;modelling language;analyse langage;lenguaje modelizacion;metamodelo;unified modeling language fault trees formal specification program diagnostics program verification safety critical software software architecture;desarrollo logicial;user requirement;abstract syntax;unified modelling language;fault diagnostic;model matching;safety critical software;software development;safety;unified modeling language;language development;diagnostico pana;analisis lenguaje;model driven software development;developpement verbal;systeme securite;architecture basee modele;language abstract syntax;software modelling;exigence securite;verification programme;seguridad;modeling;criticidad;language mapping;language engineering;exigencia seguridad;model driven architecture;architecture logiciel;failure mode effects;fault tree analysis;language refinement;arquitectura basada modelo;fault trees;criticality;automation	Safety critical software requires integrating verification techniques in software development methods. Software architectures must guarantee that developed systems will meet safety requirements and safety analyses are frequently used in the assessment. Safety engineers and software architects must reach a common understanding on an optimal architecture from both perspectives. Currently both groups of engineers apply different modelling techniques and languages: safety analysis models and software modelling languages. The solutions proposed seek to integrate both domains coupling the languages of each domain. It constitutes a sound example of the use of language engineering to improve efficiency in a software-related domain. A model-driven development approach and the use of a platform-independent language are used to bridge the gap between safety analyses (failure mode effects and criticality analysis and fault tree analysis) and software development languages (e.g. unified modelling language). Language abstract syntaxes (metamodels), profiles, language mappings (model transformations) and language refinements, support the direct application of safety analysis to software architectures for the verification of safety requirements. Model consistency and the possibility of automation are found among the benefits.	criticality matrix;failure cause;fault tree analysis;metamodeling;model-driven architecture;model-driven engineering;requirement;safety engineering;software architect;software architecture;software development process;unified modeling language	Miguel A. de Miguel;Javier Fernández Briones;Juan Pedro Silva;Alejandro Alonso	2008	IET Software	10.1049/iet-sen:20070050	domain analysis;personal software process;software requirements specification;verification and validation;fault tree analysis;software sizing;software verification;computer science;systems engineering;package development process;software design;social software engineering;component-based software engineering;software development;software design description;domain engineering;software construction;programming language;resource-oriented architecture;goal-driven software development process;software development process;software requirements;algorithm;avionics software	SE	-42.43911593760945	26.737240388029782	26305
a9690fee3fc2b1b4a4d2873956b123fd9b5b3676	an extensible framework to sort out nodes in graph-based structures powered by the spreading activation technique: the ontospread approach	web of data;resource description framework rdf;spreading activation technique;ontospread framework;information and document retrieval	The aim of this paper is to present an extensible framework for the Spreading Activation technique. This technique is supported by the ONTOSPREAD framework enabling the development, con guration, customization and execution of the Spreading Activation method on graph-based structures. It has been used for a long time to the e cient exploration of knowledge bases built on semantic networks in Information and Document Retrieval domains. Now the emerging Web of Data and the sheer mass of information now available make it possible the deployment of new services and applications based on the reuse of existing vocabularies and datasets. A huge amount of this information is published using semantic web languages and formats such as RDF, implicit graph structures developed using W3C standard languages: RDF-Schema or OWL, but new exible and scalable methods to create added-value services and exploit the data are required. That is why ONTOSPREAD is considered to be relevant in order to provide a new way to implement the double process of activation and spreading of concepts. in graph-based structures, more speci cally to browse and rank resources in the Web of Data realm. The original constraints like weight degradation according to the distance are provided in combination with others coming from the extension of this technique like the converging paths reward. Finally an evaluation methodology and two examples using the well-known ontologies GALEN and SNOMED CT are presented to validate the goodness, the improvement and the capabilities of this technique applied to an speci c domain like clinical decission support systems.	algorithm;browsing;clinical decision support system;data web;document retrieval;elegant degradation;implicit graph;naruto shippuden: clash of ninja revolution 3;ontology (information science);procurement;programming model;rdf schema;randomness extractor;resource description framework;scalability;semantic web;semantic network;software deployment;spreading activation;systematized nomenclature of medicine;vocabulary;web ontology language;whole earth 'lectronic link;world wide web	Jose María Álvarez Rodríguez;José Emilio Labra Gayo;Patricia Ordóñez de Pablos	2012	IJKSR	10.4018/jksr.2012100106	computer science;knowledge management;artificial intelligence;semantic web;data mining;database;world wide web	Web+IR	-40.310890523466924	7.34605036123149	26313
161ae582e956d89bb119a4dda0a1055290bf84e0	a systematic approach to creating and maintaining software documentation	database system;information retrieval;software engineering;documentation	Current software documentation is difficult to write and seldom meets the varying needs of its users. We propose that by considering different users and applying information retrieval techniques to the information included in software documentation, we can provide effective access to that information. We submit a set of features for inclusion in documentation database systems and describe a prototype designed to determine the usefulness of these features.	database;documentation generator;hypertext;information retrieval;prototype;software documentation	Allison L. Powell;James C. French;John C. Knight	1996		10.1145/331119.331176	long-term support;verification and validation;software engineering process group;information engineering;crowdsourcing software development;software project management;documentation;computer science;package development process;software design;software development;technical documentation;software construction;database;software walkthrough;software documentation;software deployment;world wide web;software system;software peer review	SE	-55.21912864839639	31.89001133278969	26316
c9054d78dbaf2dbfccc4f55c1cce616143f24fd5	a domain-specific query language for information services mash-up	computers;dsql;query language;portals;web services graphical user interfaces query languages;information systems;information science;information services mash up;graphical user interface;web service;domain knowledge domain specific query language information service mash up;ease of use;query languages;nsis;domain knowledge;national scientific information system;nsis domain specific query language dsql information services mash up web services yahoo pipes popfly graphical user interface national scientific information system;graphical user interfaces;yahoo pipes;web services;graphic user interface;popfly;information service;information system;service oriented architecture;grid computing;domain specific query language;database languages;information service mash up;domain specificity;business process	With the prevalence of Web Services technology, more and more information in the web are provided through Web Services. In certain domains, information can be queried by web services, but building a complete and exact query from these services is always time-consuming and less convenient for end users, especially domain users. Meanwhile, mash-up brings a new way for end-users to build personal view of data and many mash-up tools like Yahoo Pipes, Popfly etc are provided to construct mash-up application. Many of these tools rely on a graphical user interface for ease of use. However, for domain users, they can not help to get the desired outcome quickly. Domain users are familiar with the domain knowledge, and yearn for a dialect using this available domain knowledge to express their query requirements precisely and concisely.In this paper, a domain-specific query language (DSQL) for services mash-up is proposed. We first abstract the domain knowledge model as components of the DSQL, and propose the definition of DSQL to express advanced query requirements. Meanwhile, correlated services could be recommended via business process in domain after the execution of the DSQL. We build a portal site as a case study, featuring the central idea of domain-specific query language (DSQL), according to the application of National Scientific Information System (NSIS) in scientific information domain. The portal site is an interactive platform to receive and respond to userspsila requests by the DSQL.	business process;compiler;domain-specific language;graphical user interface;information system;knowledge representation and reasoning;mash-1;microsoft popfly;next steps in signaling;persistence (computer science);personalization;query language;requirement;usability;user (computing);web service	Weilong Ding;Jing Cheng;Kaiyuan Qi;Yan Li;Zhuofeng Zhao;Jun Fang	2008	2008 IEEE Congress on Services - Part I	10.1109/SERVICES-1.2008.59	web query classification;computer science;database;world wide web;information retrieval	DB	-37.203102723956725	8.697389185573973	26320
5c338bf37704bb8d15e4fd82e31fb9f058d537c2	interactions model and code generation for j2me applications	interfase usuario;calculateur embarque;user interface;generation code;cellular radio;generacion codigo;code generation;langage java;device independence;automatic generation;boarded computer;visual language;lenguaje java;interface utilisateur;interaction model;radiotelephonie cellulaire;calculador embarque;embedded software;java language	The Java2 Micro Edition platform can really be considered an emerging standard for new generation embedded software. This article introduces a practical methodology aimed to automatically generate a software prototype starting from an abstract description which defines the dialogue between the user and the application by means of a device independent and abstract description. We will show how an agenda application for cellular phones can be described by means of a visual language called PLANES and present how the personal agenda prototype is implemented by an appropriate generation tool.	device independence;embedded software;embedded system;java platform, micro edition;mobile phone;prototype;software prototyping;visual language	Davide Carboni;Stefano Sanna;Sylvain Giroux;Gavino Paddeu	2002		10.1007/3-540-45756-9_24	embedded software;human–computer interaction;computer science;operating system;database;distributed computing;programming language;user interface;algorithm;code generation	Embedded	-39.51399578008642	27.216652098270423	26330
02abc34f7a94d0d3467f8ab5a25d77c2c455eabb	design activities for supporting the evolution of service-oriented architecture	service oriented architecture	The advent of deregulation combined with new opportunities opened by advances in telecommunications technologies has significantly changed the paradigm of telecommunications services, leading to a dramatic increase in the number and type of services that telecommunication companies can offer. Building new advanced multimedia telecommunications services in a distributed and heterogeneous environment is very difficult, unless there is a methodology to support the entire service development process in a structured and systematic manner, and assist and constrain service designers and developers by setting out goals and providing specific means to achieve these goals. Therefore, in this paper, after a brief presentation of a proposed service creation methodology, its service design phase is examined in detail focusing on the essential activities and artifacts. In this process, the exploitation of important service engineering techniques and UML modelling principles is especially considered. Finally, alternative and complementary approaches for service design are highlighted and a validation attempt is briefly outlined.	programming paradigm;service-oriented architecture;unified modeling language	Dionisis X. Adamopoulos	2008			multilayered architecture;enterprise architecture framework;reference architecture;software architecture;the open group architecture framework;space-based architecture;database-centric architecture;computer science;architecture domain;applications architecture;service-oriented modeling;service-oriented architecture;enterprise architecture management;service;solution architecture;software architecture description;architecture framework;enterprise architecture;view model;data architecture;business architecture	HCI	-58.84693906705344	18.696683274711933	26423
ba3da440249f5a613d0058b219c30eb9694d4d84	action-level real-time devs modeling and simulation	real time devs;real time statecharts;real time simulation;action level modeling	For some classes of systems, it is advantageous to develop real-time models instead of step-wise or logical-time models. Toward this goal, the action-level real-time ALRT discrete-event system specification DEVS modeling and simulation approach is proposed. Modeling of actions is introduced into the parallel DEVS formalism using time invariants defined for real-time statecharts. Actions are specified in terms of time-windows that are to be executed in real-time. An abstract simulator protocol is devised for executing the ALRT-DEVS models under constrained computational resources. The approach is implemented in the parallel DEVS-Suite simulator. These models can be simulated on unitary computing platforms. A simple example switch model is detailed and tested to show the kinds of real-time modeling and simulation studies that can be supported.	devs;real-time locating system;simulation	Hessam S. Sarjoughian;Soroosh Gholami	2015	Simulation	10.1177/0037549715604720	embedded system;real-time computing;simulation;computer science;devs	Embedded	-37.43882721470086	29.72583980090657	26437
0ef27146b6516b6bd8380ff23510d1473e33e703	enhancing semantic consistency in anti-fraud rule-based expert systems		Abstract In this study, an ontology-driven approach is proposed for semantic conflict detection and classification in rule-based expert systems. It focuses on the critical case of anti-fraud rule repositories for the inspection of Card Not Present (CNP) transactions in e-commerce environments. The main motivation is to examine and curate anti-fraud rule datasets to avoid semantic conflicts that could lead the underpinning expert system to incorrectly perform, e. g., by accepting fraudulent transactions and/or by discarding harmless ones. The proposed approach is based on Web Ontology Language (OWL) and Semantic Web Rule Language (SWRL) technologies to develop an anti-fraud rule ontology and reasoning tasks, respectively. The three main contributions of this work are: first, the creation of a conceptual knowledge model for describing anti-fraud rules and their relationships; second, the development of semantic rules as conflict-resolution methods for anti-fraud expert systems; third, experimental facts are gathered to evaluate and validate the proposed model. A real-world use case in the e-commerce (e-Tourism) industry is used to explain the ontological knowledge design and its use. The experiments show that ontological approaches can effectively discover and classify conflicts in rule-based expert systems in the field of anti-fraud applications. The proposal is also applicable to other domains where knowledge rule bases are involved.	expert system;logic programming	María del Mar Roldán García;José García-Nieto;José Francisco Aldana Montes	2017	Expert Syst. Appl.	10.1016/j.eswa.2017.08.036	web ontology language;subject-matter expert;rule-based system;semantic data model;data mining;semantic web rule language;computer science;conflict resolution strategy;expert system;legal expert system	AI	-44.355593202935715	5.215050800467453	26498
538ec6a56a9238adcd31a05345b4dd9bc123dc8b	a context-aware intentional service prediction mechanism in pis	context aware;information systems;history;service orientation;prediction algorithms;pervasive information system;classification;classification pervasive information system service orientation intention context aware prediction clustering;clustering;context history context modeling ontologies information systems predictive models prediction algorithms;predictive models;ontologies;context modeling;prediction;context;intention;ubiquitous computing information systems recommender systems;context aware intentional service prediction mechanism recommendation process user needs pis efficiency enhancement pis transparency enhancement is generation information system generation pervasive information system pis	Pervasive Information System (PIS) represents a new generation of Information Systems (IS) available anytime, anywhere in a pervasive environment. In this paper, we propose to enhance PIS transparency and efficiency through a context-aware intentional service prediction approach. This approach allows anticipating user's future needs, offering and recommending him the most suitable service in a transparent and discrete way. We detail in this paper our service prediction mechanism and present encouraging experimental results demonstrating our proposition.	anytime algorithm;behavior model;cluster analysis;expect;experiment;information system;ontology (information science);pervasive informatics;point of view (computer hardware company);precision and recall;requirement;scalability;systems design;user-centered design	Salma Najar;Manuele Kirsch-Pinheiro;Carine Souveyet	2014	2014 IEEE International Conference on Web Services	10.1109/ICWS.2014.97	prediction;computer science;knowledge management;data mining;world wide web	Robotics	-49.76232522510181	16.03400725951408	26657
b9baec278ecba920924d803336e6820650fdc44b	goal-directed interactions in artifact-based mas: jadex agents playing in cartago environments	goal directed agents agents and artifacts cognitive agents interactions reasoning environments;environments;protocols;cognitive systems;sensors;cognitive agents;books;protocols intelligent agent context modeling information systems computer science distributed computing humans software engineering middleware buildings;goal directed agents;multi agent systems;first class mediating tools goal directed interactions artifact based mas jadex agents cartago environments cognitive agent programming frameworks goal orientation speech acts mediated interactions artifact based environments;mathematical programming;cognition;agents and artifacts;interactions;multi agent systems cognitive systems mathematical programming;artificial intelligence;reasoning;proposals;programming	In the context of cognitive agent programming frameworks, a main research effort accounts for exploiting goal-orientation for specifying and enacting agent interaction. Existing research work focuses almost totally on direct communication models, typically based on speech-acts and FIPA ACL. In this paper we focus instead on mediated interactions, and in particular on interaction taking place in artifact-based environments, where artifacts are first-class mediating tools that are used by cognitive agents in goal-directed way. The investigation is concretely supported by integrating the Jadex platform (enrolling the Belief-Desire-Intention model of agency) with the CARTAGO technology (enabling the design of artifact based environments).	interaction	Michele Piunti;Alessandro Ricci;Lars Braubach;Alexander Pokahr	2008	2008 IEEE/WIC/ACM International Conference on Web Intelligence and Intelligent Agent Technology	10.1109/WIIAT.2008.349	communications protocol;programming;interaction;cognition;computer science;knowledge management;sensor;artificial intelligence;multi-agent system;reason	Robotics	-41.57400673318282	19.087868533347702	26689
6200cada6812af374039889b9692b97d7565b080	protocols for web service invocation		The automatic invocation of a web service by an agent is a complex task which is currently being addressed by semantic markup techniques. However, it is difficult to define the computational aspects of a web service in this approach. In this paper we propose a protocol-based formalism which appears better suited to a representation of these issues. We define the syntax and semantics of a protocol language which express precisely how the interaction with a service should be performed, and how the service should be invoked. We also sketch an architecture for the execution of our protocols.	automated planning and scheduling;communications protocol;hl7publishingsubsection <operations>;interaction;interface device component;knowledge bases;knowledge base;level of detail;machine learning;markup language;ontology (information science);protocols documentation;semantic html;semantics (computer science);verification of theories;web service definition language;web services description language;web service	Christopher D. Walton	2005				Web+IR	-41.38626999195993	13.809829939490479	26724
5b8715bffed31e1ebdf6a93fdc60b7da4f831862	mapping generation for xml data sources: a general framework	xml mediation humans conferences information retrieval;information retrieval;mediation;xml;humans;conferences	The inter-operability of multiple autonomous and heterogeneous data sources is an important issue in many applications such as mediation systems, datawarehouses, or web-based systems. These systems provide a view, called a target schema, on the top of the data sources. Mappings are defined for describing the way instances of the target schema are derived from instances of the data sources. The generation of such mappings is a difficult problem, especially when the target schema and the source schemas are in XML format. In this paper, we propose a framework to automatically find the mappings for a target schema given the source schemas and a set of semantic correspondences. In our framework, the target schema is decomposed into subtrees. Mappings are first determined for each subtree, and then combined to generate the mapping for the whole target schema. The generated mappings are expressed in a standard language, such as XQuery or XSLT.	autonomous robot;database schema;interoperability;operability;plasma cleaning;tree (data structure);web application;xml database;xquery;xslt	Zoubida Kedad;Xiaohui Xue	2005	International Workshop on Challenges in Web Information Retrieval and Integration	10.1109/WIRI.2005.26	data exchange;xml validation;relax ng;logical schema;xml schema;computer science;document structure description;star schema;data mining;xml schema;database;document schema definition languages;xml schema editor;information retrieval	DB	-35.699252466358864	6.927939874779928	26755
2787263b0a2d151d09d8609ff7925d54a1dfea65	modeling system requirements in modelica: definition and comparison of candidate approaches	verification;modelica;requirements;assertions;safety;validation;properties;modeling	The modeling of system requirements deals with formally expressing constraints and requirements that have an impact on the behavior of the system to enable their verification through real or simulated experiments. The need for models representing system requirements as well as for methods and techniques centered on model-based approaches able to support the modeling, evaluation, and validation of requirements and constraints along with their traceability is today greater than ever. In this context, this paper proposes a meta-model for modeling the requirements of physical systems. Furthermore, different approaches for integrating the modeling of system requirements in the Modelica language and their verification during the simulation are proposed and, then, evaluated and compared through a case study.	application programming interface;dimes;experiment;fault tree analysis;metamodeling;metaobject;openmodelica;requirement;simulation;software engineering institute;system requirements;traceability;verification and validation	Lena Rogovchenko-Buffoni;Andrea Tundis;Peter Fritzson;Alfredo Garro	2013			reliability engineering;requirements analysis;simulation;computer science;systems engineering;system requirements specification;non-functional testing;non-functional requirement;requirements traceability	SE	-44.04152533237579	32.11839456934865	26757
f06af840d4ef3fc572fe9b74ab7409236b569a58	a model driven engineering approach applied to master data management	mda;xml schema;uml;data management;software engineering;mde;complex data;metamodel;model driven engineering;master data management	The federation of data sources and the definition of pivot models are strongly interrelated topics. This paper explores a mediation solution based on XML architecture and the concept of Master Data Management. In this solution, pivot models use the standard XML Schema allowing the definition of complex data structures. The introduction of a MDE approach is a mean to make modeling easier. We use UML as an abstract modeling layer. UML is a modeling object language, which is more and more used and recognized as a standard in the software engineering field, which makes it an ideal candidate for the modeling of XML Schema models. In this purpose we introduce features of the UML formalism, through profiles, to facilitate the definition and the exchange of models.	cross-validation (statistics);data model;data quality;data structure;information model;master data management;metamodeling;model-driven engineering;object language;pivot table;profile (uml);research data archiving;semantics (computer science);software engineering;unified modeling language;xml schema	Ludovic Menet;Myriam Lamolle	2009		10.1007/978-3-642-05290-3_10	data exchange;metamodeling;xml validation;model-driven architecture;semi-structured model;xml schema;uml tool;computer science;systems engineering;document structure description;applications of uml;data mining;xml schema;database;document schema definition languages;xml schema editor	SE	-33.79497457045585	11.615724148554092	26776
938e65ce58b539d317f208e3842d5e4cf6858b4d	rule-based modeling and verification of business processes using ecape net	business process;rule based	In this paper we discuss the need to ensure that thernbusiness processes are at the same time robust andrnagile. The aim of our work is to improve the businessrnprocess management by offering a flexible modeling tornimplement changes quickly and verification of arnbusiness process by identifying errors in the processrnspecification. To achieve these objectives, we proposerna new model grounded on a new formalism issued fromrnECA model. In this model, a business rule has anrnEvent/Condition/Action/Post condition/Event triggeredrn(ECAPE) formalism. To represent this formalism asrnwell as the functioning in a business process, a newrncolored Petri net, called ECAPE net, is used in orderrnto define formally a business process and to detectrnerrors by taking account of the identified properties ofrnthis ECAPE net.	business process;rule-based modeling	Mohamed Boukhebouze;Youssef Amghar;Aïcha-Nabila Benharkat;Zakaria Maamar	2009			business process discovery;business process;systems engineering;data mining;computer science;business process modeling;artifact-centric business process model;business process management;business process model and notation;business rule;process modeling	Logic	-54.67872721383732	19.463191230691002	26801
cdeb679940a9a452588ed83da45f371e8ac2d8ab	metallic materials ontology population from lod based on conditional random field		Abstract In recent years, with the rapid development of ontology technology, many relatively perfect domain ontologies have emerged gradually and achieved favorable applications. However, for the existing metallic materials ontologies, such as the metallic materials ontology created by Ashino , MatonTO and ONTORULE, the knowledge of their instances is comparatively insufficient. Additionally, for the users, they hope that not only a large number of the materials instances are included in the ontology, but also the properties of the instances are desired. Linked Open Data (LOD) provides huge open knowledge bases which contain ample materials knowledge. Thus, we expect the knowledge of LOD can be inserted into a specific ontology. Obviously, it is not an easy work, since the LOD is very large, and its structure is inconsistent with ontology’s. Therefore, a method is proposed to populate a specific metallic materials ontology with the metallic materials information in the LOD. Firstly, in the LOD, we determine the information that can be filled into the existing metallic materials ontology. Then, we convert the LOD to Chain Triples (CHTs) according to the filling information. We use conditional random field (CRF) to achieve CHTsu0027 filling positions in the specified metallic materials ontology. Finally, we insert the information into the ontology. The approach is evaluated in light of F-measure, and the experiment results demonstrate that the proposed approach can be effective to populate a specific ontology with the metallic materials data in LOD. This approach not only enriches the existing metallic materials ontology, but also greatly saves the manual efforts on the process of ontology population.	conditional random field	Xiaoming Zhang;Zhishen Zhang;Huiyong Wang;Mingming Meng;Dongyu Pan	2018	Computers in Industry	10.1016/j.compind.2018.03.032	linked data;information retrieval;systems engineering;engineering;ontology (information science);ontology;open knowledge;population;conditional random field	AI	-45.42476986389975	5.717098421001853	26829
8ca4ca864bfe1f7eb047f467232eaa63a2f32989	a formal specification of interaction widgets hierarchy framework	design by;page description languages;user interaction widget hierarchy framework;formal specification;user interfaces formal specification object oriented languages;object constraint language ocl;formal specifications;formal specifications concrete user interfaces rendering computer graphics contracts guidelines page description languages mobile handsets unified modeling language australia;application interface;contracts;device independence;widget;device independent interface;contract;guidelines;widget conformance;levels of abstraction;design by contract principle;unified modeling language;widget constraint specification;abstract widget;widget device independent interface abstract interactor object constraint language ocl design by contract;mobile handsets;design by contract principle formal specification user interaction widget hierarchy framework behavioral classification object constraint language widget constraint specification application interface widget conformance abstract widget;design by contract;abstract interactor;contract design;rendering computer graphics;behavioral classification;user interaction;abstract;interactor;user interfaces;object oriented languages;object constraint language;australia;concrete	In this paper we provide a behavioral classification of user interaction widgets. We use object constraint language (OCL) to specify widget constraints in a formal manner. The benefits of such a behavioral classification are that application interface can be described in a device and technology independent way, and that design by contract principle can be applied to reason about the conformance of widgets at various level of abstraction. In addition, such classification can be considered as a guideline for mapping between abstract widgets and concrete widgets	conformance testing;design by contract;device independence;formal methods;formal specification;object constraint language;usability	L. J. Wang;A. S. M. Sajeev;Lachana Inchaiwong	2006	Third International Conference on Information Technology: New Generations (ITNG'06)	10.1109/ITNG.2006.8	computer science;operating system;formal specification;database;programming language;world wide web;container	SE	-47.91606882376087	27.877251278148837	26847
5b7aa47015a58d30612a24d82720fbc418e68b5d	the future of enterprise groupware applications.	tool support;heterogeneous information;information integration;system integration;virtual enterprise;enterprise system	Strathprints is designed to allow users to access the research output of the University of Strathclyde. Unless otherwise explicitly stated on the manuscript, Copyright © and Moral Rights for the papers on this site are retained by the individual authors and/or other copyright owners. Please check the manuscript for details of any other licences that may have been applied. You may not engage in further distribution of the material for any profitmaking activities or any commercial gain. You may freely distribute both the url (https://strathprints.strath.ac.uk/) and the content of this paper for research or private study, educational, or not-for-profit purposes without prior permission or charge.	collaborative software	Sotirios Terzis;Paddy Nixon;Vincent P. Wade;Simon A. Dobson;John Fuller	1999			functional software architecture;enterprise system;enterprise application integration;enterprise systems engineering;enterprise software;enterprise modelling;computer science;knowledge management;architecture domain;information integration;integrated enterprise modeling;cimosa;enterprise architecture management;database;enterprise architecture;enterprise integration;enterprise planning system;enterprise information security architecture;enterprise information system;enterprise information integration;system integration;enterprise life cycle	HCI	-54.539705777099336	14.694098455288334	26897
c5fb41c10edea8201cb42132d9242d569d3fd48b	a better approach for conceptual readability of wsdl	wsdl;readability;wsdl web services readability;indexes;dacw conceptual readability interoperability heterogeneous environment flexible platform service oriented architecture soa web service description language xml form structural description nonstructural description functionality scope business competitor wsdl file components domain ontology synonyms wordnet simplified dale chall readability index;indexes ontologies mathematical model service oriented architecture web sites xml;web services;web sites;xml;mathematical model;ontologies;xml ontologies artificial intelligence service oriented architecture web services;service oriented architecture	Issues that concerns with the inter-operability on a heterogeneous environment can easily be address using the flexible platform of Service Oriented Architecture (SOA). Web service is an implementation and modeling of Service Oriented Architecture (SOA). Web service description language (WSDL)is a standard describing a web service in XML form. This Description can be categorized in two parts i.e. Structural and non-structural. The readability of a web service helps the consumer to understand it easily, it is suggested to provide sufficient details about functionality scope and limitation of scope in WSDL, so that it can easily be understandable. Readability depends upon interaction of two variables i.e. Text and reader. The maximum details about a web service could lead to it's reproduction by business competitor, and it may helps in maximizing vulnerabilities in it. This paper focuses on a technique for computing readability index by a detail analysis of WSDL document. This readability index obtain using this approach helps the producer of a web service to adjust readability, so that it can easily be understandable by consumer. The better readability index can also leads the provider to a better service discovery. To calculate Readability Index, extraction of WSDL file components was performed. After extraction of key concepts, they were mapped with the Domain Ontology. The words that were not mapped in the ontology, synonyms are employed by consulting the Word Net. Final readability was obtained using Simplified Dale Chall readability index (DaCw). The Web Service Readability can be measure more precisely by considering words that were not found in the mapping process.	categorization;http 404;interoperability;microsoft word for mac;ontology (information science);operability;service discovery;service-oriented architecture;web ontology language;web services description language;web service;world wide web;xml	Kashif Sohail Abid;Asif Sohail Abid;M. Mohsen Ansari	2015	2015 IEEE International Conference on Multimedia Big Data	10.1109/BigMM.2015.52	web service;computer science;data mining;database;world wide web	Web+IR	-36.10096626148692	7.40138008206652	26913
f50e95374de50a73a6e30cd177d2cad5494065e9	a bayesian network approach to rational architectural design	kwic;automated design;architectural design;bayesian network;software engineering;artificial intelligence;software architecture design;knowledge capture;software quality	In software architecture design, we explore design alternatives and make decisions about adoption or rejection of a design from a web of complex and often uncertain information. Different architectural design decisions may lead to systems that satisfy the same set of functional requirements but differ in certain quality attributes. In this paper, we propose a Bayesian Network based approach to rational architectural design. Our Bayesian Network helps software architects record and make design decisions. We can perform both qualitative and quantitative analysis over the Bayesian Network to understand how the design decisions influence system quality attributes, and to reason about rational design decisions. We use the KWIC (Key Word In Context) example to illustrate the principles of our approach.	bayesian network	Hongyu Zhang;Stan Jarzabek	2005	International Journal of Software Engineering and Knowledge Engineering	10.1142/S0218194005002488	reliability engineering;software architecture;probabilistic design;architectural pattern;computer science;systems engineering;engineering;software design;object-oriented design;software engineering;bayesian network;data mining;design education;software quality	SE	-59.25544519674901	25.49973467020068	27098
d55bd3262106b711ff7e4409bcdab2a8bbd4d13d	health: related information structuring for the semantic web	information structure;web pages;national library of medicine;information extraction;unified medical language system;semantic net;knowledge acquisition;semantic web;world wide web;web search;ontology	The World Wide Web has become an important medium for the dissemination of information related to a wide range of topics. The majority of human information is becoming available on the web very rapidly. In the medical domain, the number of documents related to healthcare is already large and continues to grow at an exponential rate. Most information on the web is buried inside HTML documents which are designed for human consumption. Restructuring information automatically into machine understandable form and making it available to web search agents would bring the web to its full potential. In this work we have downloaded a set of 100 diabetes-related websites, over 12000 HTML files, which have been carefully analyzed. Our intention is first to learn the general structure of these websites which would increase the efficiency of information extraction and structuring. Every website has a purpose mainly providing services or products (or both). Our study resulted in the construction of an ontology covering a set of general services and products that these websites offer. The main goal of such ontology is to provide guidance in the process of extracting and structuring information. We incorporated the Unified Medical Language System (UMLS) Semantic Net which serves as an upper level ontology for medicine. We used the MetaMap Transfer (MMTx) API developed by the US National Library of Medicine (NLM) for mapping text into concepts from the UMLS Semantic Net. Pinpointing concepts in web pages provides an efficient way to determine the attributes and therefore facilitates more efficient extraction and restructuring of information. This paper describes the first part of our work and findings.	html;information extraction;netware loadable module;ontology (information science);semantic web;semantic network;time complexity;upper ontology;web page;web search engine;world wide web	Mohammad Ali H. Eljinini	2011		10.1145/1980822.1980828	web service;web application security;web development;web modeling;data web;web mapping;html;web design;web standards;computer science;semantic web;web navigation;social semantic web;web page;data mining;semantic web stack;web intelligence;web 2.0;world wide web;owl-s;website parse template;information retrieval;web server	Web+IR	-41.29479827902339	7.955581161150085	27122
9208ada42ea74ebeebee9831c22c6fb9367896bf	famoosr 2009 - workshop on famix and moose in software reengineering	half-day workshop;moose accommodates;extensive infrastructure;reverse engineering;analysis technique;reverse engineering research;software reengineering;famix family;previous research;engineering effort;shared infrastructure;systems analysis;system monitoring;software systems;meta model;data mining;data model	The increasing amount of data available about software systems poses new challenges for re- and reverse engineering research, as the proposed approaches need to scale. In this context, concerns about meta-modeling and analysis techniques need to be augmented by technical concerns about how to reuse and how to build upon the efforts of previous research. MOOSE is an extensive infrastructure for reverse engineering evolved for over 10 years that promotes the reuse of engineering efforts in research. MOOSE accommodates various types of data modeled in the FAMIX family of meta-models. The goal of this half-day workshop is to strengthen the community of researchers and practitioners who are working in re- and reverse engineering, by providing a forum for building future research starting from MOOSE and FAMIX as shared infrastructure.	code refactoring;moose;metamodeling;reverse engineering;software system	Simon Denier;Tudor Gîrba	2009	2009 16th Working Conference on Reverse Engineering	10.1109/WCRE.2009.56		SE	-61.072033625540335	21.95119939849746	27254
6900417880738d348f3430c8aae941c2a0320e09	modelling a sharable medical concept system: ontological foundation in galen	sharable medical concept system;ontological foundation	Without Abstract	ontology (information science)	Geri Steve;Aldo Gangemi;Angelo Rossi Mori	1995		10.1007/3-540-60025-6_163	computer science;knowledge management;artificial intelligence	AI	-41.709594301576345	6.416522747571572	27281
47fb05ad26766498700ad7105e41a60502b63af8	model-driven multi-view conceptual architecture design in a phm system environment		Today's systems or devices in the Internet of Things (IoT) applications are more and more complex. Analytic facilities are typically deployed in these systems for Prognostics and Health Management (PHM) purposes. One of the main challenges for architecting such control and diagnostics systems is their restrictive performance requirements, which directly impact the architecture and subsequent detailed designs. This paper presents a case study on the conceptual architecture design in such an environment, and co-develops the architecture and the domain solution to improve prototyping rapidness. First, on applying systems thinking and technologies, during architecting, we include the tasks of meeting both functional and performance requirements especially with respect to analytics, in a single architecture description framework. Second, we study a domain-specific issue, where un-attempted methods must be researched, and provide a solution that re-uses existing system elements, through which the mutual impacts between the information from both architecture and domain solutions are shown. Practical and important issues including benefits, standards, and implementations are also explored as part of the required tasks for architecting. Results including architecture designs and empirical performance research are illustrated, to indicate a systematic design process for systems in a PHM environment.	environment variable;free viewpoint television;internet of things;model-driven integration;requirement	Haifeng Zhu;Dan Hestand	2017	2017 IEEE International Conference on Prognostics and Health Management (ICPHM)	10.1109/ICPHM.2017.7998325	enterprise architecture framework;systems design;data architecture;reference architecture;systems architecture;applications architecture;systems engineering;space-based architecture;solution architecture;computer science	EDA	-60.616213694214956	19.24593314817194	27337
dadf0f9153f1f8567a8befb5597526cca2be9700	software reuse: issues and an example	intelligent reuse support system;reuse;prototyping	Abstract   Reusability is a general principle that is instrumental in avoiding duplication and capturing commonality in inherently similar tasks. It simplifies and unifies classes of phenomena and is the basis for economic justification for developing reusable software products that make computers and programmers more productive. This paper provides an overview of some of the major issues in reuse combined with practical experience based on a case study of reuse in the telecommunications industry: a project of moderate complexity on signaling link provisioning that was carried out at AT&T Bell Labs. The project incorporates reuse into the prototyping paradigm. The benefits of reuse are quantified, and their effect on productivity is shown. In addition, a simple and effective intelligent reuse support system, based on concepts of rule based expert systems and relational databases, is detailed for use as a meta-language interface for automatic code (skeleton) generation. The case illustrates many significant aspects associated with the integration of reuse in information systems development.		M. Ramesh;H. Raghav Rao	1994	Decision Support Systems	10.1016/0167-9236(94)90074-4	simulation;computer science;operations management;data mining;reuse;database;prototype	ECom	-59.48055308855116	19.44898827158962	27341
4a31a753b96c2e32c148446d170fa9b8e1a80de9	an improvement on data interoperability with large-scale conceptual model and its application in industry		In the world of the Internet of Things, heterogeneous systems and devices need to be connected. A key issue for systems and devices is data interoperability such as automatic data exchange and interpretation. A wellknown approach to solve the interoperability problem is building a conceptual model (CM). Regarding CM in industrial domains, there are often a large number of entities defined in one CM. How data interoperability with such a largescale CM can be supported is a critical issue when applying CM into industrial domains. In this paper, evolved from our previous work, a meta-model equipped with new concepts of “PropertyRelationship” and “Category” is proposed, and a tool called FSCM supporting the automatic generation of property relationships and categories is developed. A case study in an industrial domain shows that the proposed approach effectively improves the data interoperability of large-scale CMs.	entity;internet of things;interoperability;interpretation (logic);metamodeling	Lan Wang;Shinpei Hayashi;Motoshi Saeki	2017			conceptual model;systems engineering;interoperability;computer science	SE	-44.376623892132834	6.903362224855782	27345
99c8547440b27ad939b9f2f5b770a6d823b4c388	integration of heterogeneous web service components	web service	Integrated value-added Web services can be developed by combining existing Web service components that are often heterogeneous in many aspects, such as having different interfaces and data encoding schemes. Web service integration also has to face the challenge that Web service components evolve frequently in response to business needs. This paper describes a three-layer-structured model for building reliable Web service compositions. The proposed layered structure can significantly reduce the complexity of integrating heterogeneous service partners. Furthermore, the evolution of a Web service component can be supported by making a rather minor amendment to the mapping file corresponding to this particular component.	business requirements;code;hoc (programming language);multitier architecture;service-oriented modeling;web service	Xin-Jian Xu;Peter Bertók	2004			web service;web modeling;universal description discovery and integration	Web+IR	-48.42175773623388	16.882765645922625	27360
47985f2caf4f008b8b6766ce49e8b662502711f3	combination of rss newsfeeds and forms for driving web-based workflow	human facing steps rss newsfeed web based workflow content syndication format electronic business processes automatic facing steps;really simple syndication;human interaction;electronic commerce;automatic facing steps;human computer interaction;electronic business processes;workflow management software electronic commerce human computer interaction internet;content syndication format;general solution;human facing steps;humans user interfaces portals xml internet protocols computerized monitoring rendering computer graphics html java;internet;user experience;workflow management software;web based workflow;electronic business;rss newsfeed	This paper proposes a novel application of the popular content syndication format RSS (really simple syndication) to improve the user experience of humans interacting with electronic workflows. We will discuss this in relation to a more general solution, formidable, for developing and deploying electronic business processes that consist of a mixture of automatic and human-facing steps	business process;electronic business;interaction;rss;user experience;web syndication	Daniela Bourges-Waldegg;Christian Hörtnagl	2005	IEEE International Conference on e-Business Engineering (ICEBE'05)	10.1109/ICEBE.2005.37	e-commerce;interpersonal relationship;the internet;computer science;operating system;rss;electronic business;database;web syndication;multimedia;world wide web	DB	-47.478623319424514	13.709726209421897	27429
3c3d53a3b8f78bdc56242dab8e1e991be4a67d98	a cross-curriculum open design platform approach to electronic and computing systems education	signal processing cross curriculum open design platform electronic system education computing system education global faculty project based active learning ict engineering education undergraduate program postgraduate program digital systems embedded systems vlsi soc design digital communication;second year;postgraduate program;cross curriculum open design platform;logic design;systematics;vlsi soc design;very large scale integration;active learning;computing system education;project based active learning;system on a chip;embedded system;ict engineering education;vlsi computer science education digital signal processing chips electronic engineering education embedded systems logic design signal processing system on chip;computer architecture;embedded systems;computer science education;digital communication;system on chip;signal processing;digital systems;engineering education;undergraduate program;electronic engineering education;vlsi;electronic system education;digital signal processing chips;field programmable gate arrays;global faculty;europe asia engineering education signal design design engineering digital systems embedded system very large scale integration digital communication digital signal processing;hardware	This paper summarizes the experiences of global faculty (N. America, Europe, Asia) in using an open design platform approach for project-based active learning in electronics, computing and ICT engineering education. A common design platform was used to support courses spanning a range of university engineering levels from 2nd year undergraduate to 2nd second year postgraduate programs, and across a range of disciplines from Digital Systems, Embedded Systems, VLSI/SoC-Design, Digital Communications and Signal Processing.	embedded system;file spanning;open design;signal processing;very-large-scale integration	Mihir Ravel;Mark Chang;Mark McDermott;Michael Morrow;Nikola Teslic;Mihajlo Katona;Jyotsna Bapat	2009	2009 IEEE International Conference on Microelectronic Systems Education	10.1109/MSE.2009.5270828	system on a chip;embedded system;engineering education;computer science;engineering;electrical engineering;software engineering;signal processing;very-large-scale integration;computer engineering	Robotics	-54.76382038797295	4.780184486581434	27500
47b4ebb997f62aedc7b1ac7b4d9f78dc5c79872c	towards an ontology-based approach for information interoperability between bim and facility management		Building information modeling (BIM) brings interoperability to the architecture, engineering, construction and facility management (AEC/FM) industry by providing an information backbone throughout a building’s lifecycle. Information interoperability or data mapping is critical for seamless information sharing between BIM and FM, because the approaches to information representation in BIM and in FM systems are different. The geometric and semantic information in BIM can be represented by IFC schema, while the FM data is commonly represented in a corresponding relational database. Even though COBie is a neutral data format to deliver information from BIM to FM, the data structure of COBie does not incomplete to represent all information from BIM to FM. Therefore, there is a lack of an appropriate solution to smoothly integrate BIM with FM. This paper aims to address the information interoperability issue and propose an ontology-based methodology framework for data mapping between BIM and FM. Based on the proposed framework, an ontology approach is developed as a tool to facilitate the facility knowledge management and to improve the data mapping process. Finally, a case application about facility maintenance activity is implemented to demonstrate the feasibility of the ontology approach.	artificial intelligence;bim;interoperability	Weiwei Chen;Keyu Chen;Jack C. P. Cheng	2018		10.1007/978-3-319-91638-5_25	building information modeling;data mapping;systems engineering;interoperability;information sharing;architecture;data structure;relational database;computer science;facility management	AI	-47.29104678060159	7.968042087515089	27512
e43a643fb52886478bcd7ca521fae66d004fa91f	a model-driven visualization system based on dvdl		Though model-driven engineering (MDE) methodology has made significant improvements in terms of efficiency and effectiveness in many areas of software development, the same cannot be said in the development of data visualization systems. With this challenge in mind, this paper introduces DVDL, a modular and hierarchical visualization description language that take advantage of the model-based design of MDE to describe visualization development at an abstract level. This paper also presents DVIZ, a visualization system based on DVDL. With a growing popularity and demand for data visualization technology, a number of visualization tools have emerged in recent years, though few would be considered as adaptable and scalable as DVIZ. Some of its key features include the ability for users to select data source, configure properties of visual elements, publish and share result. The system also supports real-time result generation and multi-visuals interaction. Lastly, since DVIZ is web-based, it supports distribution of result across various social media.	data visualization;model-driven engineering;model-driven integration;real-time computing;real-time transcription;scalability;social media;software development;web application	Yi Du;Lei Ren;Yuanchun Zhou;Jianhui Li	2016		10.1007/978-3-319-61994-1_2	software development;scalability;data visualization;data mining;modular design;visualization;social media;information visualization;popularity;computer science	Visualization	-48.596821525445066	22.00107945141461	27524
0c12d6f21a8a482e8d9814b7cbaabc22f4f0bf75	a preliminary study of models for manufacturing (mfm) applied to incremental sheet forming		Models for Manufacturing is a new approach proposed by the authors to apply Model-based Systems Engineering concepts to Manufacturing. The methodology under development is supported by a 3-layer framework (referred to as Data Base and Interfaces, Ontology and Software Tools layers) and simple and easy-to-use software tools. This work presents a preliminary implementation of Models for Manufacturing to SPIF, an innovative incremental sheet forming that makes use of CNC technology and usually requires a numerical study to validate the manufacturing process. The work introduces the proposed methodology and presents the model in development with special emphasis on the Ontology layer.		Domingo Morales-Palma;Fernando Mas;Jesús Racero;Carpóforo Vallellano	2018		10.1007/978-3-030-01614-2_26	software engineering;ontology (information science);ontology;incremental sheet forming;software;computer science	Robotics	-58.077411652183564	11.561280488807224	27537
95befef203f53b507ed031e9f9d0dae90536aa0d	towards general representability in knowledge exchange		In data exchange, one is typically given a source database instance and a mapping between a source schema and a target schema. The goal then is to materialize a target database instance that corresponds to the source instance and the mapping. In this setting source data is explicitly given, that is, every fact that is true in it is explicitly mentioned in the source database instance. Knowledge bases typically consist of some explicit knowledge – like in database instances – and some implicit knowledge, usually given in the form of rules that specify how to derive knowledge not explicitly stored. In [5], Arenas et al. introduced the setting of knowledge exchange, where one is given a source knowledge base and a mapping between a source schema and a target schema, and the goal is to materialize a target knowledge base, that is, both explicit and implicit knowledge. While the question of what constitutes a “good” solution to a data exchange problem has been the topic of research in recent years [11], the question of what constitutes a “good” solution to a knowledge exchange problem is rather new. In particular, there are now two components, explicit and implicit knowledge, which play rather different roles in what we expect from them. In [5], two especially desirable properties of the target knowledge base were identified. First, one generally wants to minimize explicit knowledge, thus generating as much knowledge by rules as possible. Second, in typical knowledge-based systems (such as those based on RDFS, OWL, or general description logics), the explicit knowledge changes frequently, but the implicit knowledge remains constant over a longer time. Hence, it is desirable to let the target implicit knowledge only depend on the implicit knowledge at the source and the mapping between source and target. Thus, knowledge exchange effectively becomes a two-stage process:	database;description logic;knowledge base;knowledge-based systems;rdf schema;source data;web ontology language;zero-knowledge proof	Marcelo Arenas;Jorge Pérez;Emanuel Sallinger	2013			explicit knowledge;source data;description logic;machine learning;schema (psychology);knowledge base;algorithm;rdf schema;data exchange;artificial intelligence;mathematics	AI	-36.72854344144661	6.195159963877012	27539
0ce5097b3ee5cc99896a518b2a5d0cfdd8dcbf32	goliath: an extensible model-based environment to develop user interfaces	model-based interface design;multi-agent system.;user interface;multi agent system;interface design	Despite the success of visual interface builders, user interfaces are still too difficult to develop. Model-based approaches are promising but have a high threshold of use. In this paper, we describe Goliath  , an easy-to-use Model Based User Interface Development Environment (MB-UIDE) with an extensible architecture. The models of Goliath  are simple enough to be used by developers who currently use visual interface builders. However, these models are rich enough to better support the links between the interface and the functional core of the application than current MB-UIDEs.	user interface	David Julien;Mikal Ziane;Zahia Guessoum	2004			user interface design;user;shell;human–computer interaction;natural language user interface;magic pushbutton;computer science;network interface;interface control document;multimedia;natural user interface;user interface;world wide web;graphical user interface testing;multiple document interface	DB	-48.280968709238536	21.49361547901904	27541
5bea73efcc845081591f2c07bb62ed492d32cd54	decision support for off-the-shelf software selection in web development projects	decision support;web based systems development;web engineering;off the shelf components;experience management;open source software	Reusing off-the-shelf (OTS) components (including commercial and open source software) has become a key success factor in software development projects leading to reduced costs, faster time-to-market and better software quality. This especially holds true in the field of web engineering, where software engineers are faced with a steady proliferation of new technologies and standards. But there are upfront and ongoing efforts and risks attached to the adoption of OTS components which makes decision-making very difficult. Such difficulties are for example a large and intransparent market, incompatibilities between components and architectural mismatches. In this paper, a plan towards a novel platform concept is proposed that can improve the situation for software engineers coping with the adoption of OTS components during web-based systems development.#R##N##R##N#One key contribution is an empirically derived ontology to describe software artifacts on a feature level allowing a better description and identification of OTS components in the domain of web development. Another key contribution is a concept for a lean experience sharing mechanism. The goal of both contributions is to improve OTS component decision-making.#R##N##R##N#The concept will be implemented as a platform prepopulated with OTS components from the domain of Java web development. A cross-case study is planned to evaluate the concept.	web development	Widura Schwittek;Stefan Eicker	2012		10.1007/978-3-642-35623-0_26	personal software process;computer science;software framework;component-based software engineering;software development;software engineering;software construction;web engineering;resource-oriented architecture;world wide web	SE	-59.65073924658099	22.3041437425861	27597
1d2f1d9e47178dc9a6affacc54523069b8069564	a concern-based approach to generating formal requirements specifications	requirements management;separation of concern;requirement analysis;formal verification;document driven requirements analysis method separation of concerns concern relationship graph 4 variable model formal requirements documentation requirements management;natural language;software design;requirement specification	Document driven requirements analysis, as proposed by Prof. David Parnas, which has had some success in practice, focuses on creating concise and complete formal requirements documents to serve as references for formal verification, software design, implementation, testing, inspection, and so on. However, at present large number of requirements documents are still written in natural languages. Therefore, generating formal requirements specification from informal textual requirements description has become a big challenge. In this paper, a concern-based approach to generating formal requirements specification from textual requirements document is proposed, which applies separation of concerns during requirements analysis and utilizes concerns and their relationships to bridge the gap between textual requirements statements and formal requirements documentation. A tool suite has been developed for supporting our approach, and a case study has been performed to illustrate the process of our approach. Results indicate that our approach facilitates guiding the process of formal requirements documentation with concerns and their relationships.	central processing unit;complex systems;cross-cutting concern;documentation;formal verification;natural language processing;prototype;requirement;requirements analysis;requirements engineering;separation of concerns;software design;software requirements specification	Ying Jin;Jing Zhang;Weiping Hao;Pengfei Ma;Yan Zhang;Haiyan Zhao;Hong Mei	2010	Frontiers of Computer Science in China	10.1007/s11704-010-0151-y	requirements analysis;software requirements specification;requirements management;market requirements document;requirement prioritization;formal methods;specification language;business requirements;formal verification;separation of concerns;computer science;software design;requirement;needs analysis;system requirements specification;requirements elicitation;formal specification;functional specification;requirements engineering;non-functional testing;natural language;programming language;non-functional requirement;requirements traceability;vision document	SE	-56.76593932508241	24.531759843124743	27613
bcf5a090a6da908acfd9ff4d69e6ec2cceeb9471	software reliability in weapon systems	probability weapons computerised control software reliability engineering graphics;goodness of fit;integration testing;probability;software libraries;engineering graphics;computerised control;maximum likelihood estimation;maximum likelihood estimation software reliability weapons military computing program testing software tools software libraries;program testing;operational profiles weapon systems goodness of fit criterion afotec operational testing application software integration testing unit testing prequential likelihood graphical tool software library software reliability growth models predictive strength;software tools;predictive strength software reliability weapon systems air force operational test and evaluation center afotec application software graphical tool software reliability growth models goodness of fit criterion prequential likelihood;software reliability weapons equations system testing software testing software tools predictive models parameter estimation frequency propulsion;software reliability growth model;software reliability;software reliability weapons software testing system testing predictive models application software software libraries software measurement;weapons;military computing	INTRODUCTION AFOTEC is responsible for the operational testing of AFOTEC and the Jet Propulsion Laboratory have application sojiware used in weapon systems. In order to recently developed the Computer Aided Software determine if a system is ready for operational testing, raw Reliability Estimation (CASRE) tool to provide information data from unit and integration testing are analyzed to determine if the software is exhibiting maturity and reliability growth. A graphical tool con raining a libran of widely accepted sofiwu re reliability growth models then selects the optimum model by first subjecting the data to goodness-of-fit criterion and then prequential likelihood (PL) as a measure of predictive strength. The intent is to use these data with operational profiles to determine the expected software reliabilirl\, for a given system operutional mission. key words: sojhvare, reliabilin: operational testing, maturity on software reliability. The tool has been implemented in the Windows environment and consists of over 30 K source lines of code. The principal benefit of CASRE as compared to other available software reliability tools such as the and estimation of reliability functions for software (SMERFS) and the software reliability modeling programs (SRMP) is that i t is of command-line menu driven instead driven and it displays all results in graphical form as	capability maturity model;command-line interface;graphical user interface;integration testing;microsoft windows;naruto shippuden: clash of ninja revolution 3;reliability engineering;software quality;software reliability testing;source lines of code	P. Carnes	1997		10.1109/CSSRE.1997.637851	non-regression testing;reliability engineering;verification and validation;regression testing;software performance testing;system integration testing;integration testing;systems engineering;engineering;acceptance testing;software reliability testing;probability;operational acceptance testing;software testing;maximum likelihood;goodness of fit;software quality;statistics;computer engineering	SE	-61.25141239596438	32.122827307498966	27614
2f4e0641ccd1a96915912382bcd6866347dec9fc	a standard for business architecture description	outil logiciel;software tool;architecture systeme;organisation entreprise;information technology;technologie information;metalangage;enterprise organization;organizacion empresa;metalanguage;herramienta controlada por logicial;mappage;structure solution entreprise;firm structure;arquitectura sistema;mapping;information system;system architecture;tecnologia informacion;structure entreprise;estructura empresa;systeme information;sistema informacion;metalenguaje	"""A complete architectural specification of an information technology (IT) system includes information about how it is partitioned and how the parts are interrelated. It also contains information about what it should do and the purpose it must serve in the business. This paper provides a set of business concepts that partition the world of business meaning. It discusses the purpose of such an architectural view of business and ways in which it can be used. A set of generic concepts and their interrelationships organize business information content in terms of requirements on the business, the boundary of the business, and the business as a system for delivery of value. Methods are introduced to explore variations on the basic business concept patterns. These concepts are positioned to describe IT systems that support the business, and they are used to manage the work of IT system development and deployment. B today is inextricably intertwined with information system technology. From the smallest home office business supported by a """"shrink-wrap"""" business suite, to the multinational corporation with multiple monolithic legacy applications, it is impossible to be in business today without confronting the issues of supporting the business with software. The papers in this issue of the IBM Systems Journal are based on the premise that a set of interlocking semantic frameworks are necessary in order to understand and create the software solutions for the enterprise of today and the future. This paper focuses on the business concepts that underlie information technology (IT) systems."""	business architecture;information system;requirement;self-information;software deployment;software framework	Douglas W. McDavid	1999	IBM Systems Journal	10.1147/sj.381.0012	business model;business analysis;business transformation;simulation;business domain;business requirements;metalanguage;engineering;artifact-centric business process model;business case;business process model and notation;business system planning;business process;business process discovery;business rule;new business development;information technology;business process modeling;information system;line of business;business activity monitoring;systems architecture;business architecture	DB	-59.166825565218126	14.365665496431284	27664
2f89d395446e1c328bc455b2df8c514e6ecbb7da	generative and component-based software engineering		Despite advances in software engineering and process methodologies over the past decades, not many IT projects seem particularly well adapted to today's fast-paced world. Software developers must start to acknowledge change and even uncertainty as a given, rather than the exception that should be studiously avoided, and they must adapt their techniques accordingly. Some business domains have seen attempts to address this situation. Several workflow vendors, for instance, have been marketing change and end-user programmability as major assets of their products. But, in general, they have been strangely ignorant of (good) modern software engineering practices, and the results have not really lived up to the claims. But we may expect a revival on a grander scale: the ability to (re) define the business logic on the fly is becoming a crucial asset when businesses re-align their core processes around the Internet. The Internet is transforming the way we envision and design applications. While we could build yesterday's simple Web applications with, let's face it, primitive techniques, this is simply no longer true. High-volume databases, long-term transactions, interoperability, distributed objects, re-use, these are some of the technical issues that must be dealt with. But the real challenge will be to leverage all this technology: we must empower the user to set up, maintain and change his applications more easily. We need dynamic systems, where applications can be changed at run-time in a high-level way, preferably by end-users. Above all, we need appropriate architectural techniques. In this paper we explore the use of dynamic object models. It turns out that the basic concepts are fairly simple. As for the difficulties, we can borrow solutions from many disciplines in computer science. If we do it right, we can even make the system work for itself.	align (company);business logic;component-based software engineering;computer science;database;distributed object;dynamical system;high- and low-level;internet;interoperability;on the fly;software developer;web application	G. Butler;Stan Jarzabek;Paul Bassett;Michel Tilman;Awais Rashid;James Coplien;Liping Zhao;Herbert Klaeren;Elke Pulvermüller;Andreas Speck;Thorsten Teschke;Jörg Ritter;Merijn de Jonge;Joost Visser;Martin Becker;Michael Goedicke;Gustaf Neumann;Uwe Zdun;Hans de Bruin;Jan Bosch;Mattias Högström	2001		10.1007/3-540-44815-2	social software engineering;software development;feature-oriented domain analysis;software construction;generative design	SE	-58.87320835655964	20.30056676560134	27676
b231b109a47e57129f7833d7993c80d6682db974	mobile device user level interface for dynamic access to spatial data	wireless networks;empirical study;mobile device;spatial data;pervasive computing;data engineering;personal digital assistants;expressive power;mobile environment;spatial databases;handheld device;computer science;query by example;mobile computing;computer interfaces;database query;personal digital assistants computer interfaces mobile computing handheld computers cellular phones computer science data engineering spatial databases wireless networks pervasive computing;handheld computers;cellular phones	The use of handheld devices, such as cell phones, PDAs or pocket computers as tools for querying spatial data in mobile environments, is becoming increasingly popular. Thus, there is a need for simple and user-friendly interfaces to allow users to pose adhoc queries. At present, Query-By-Example (QBE) is available as a user-friendly interface, developed for accessing a RDBMS on a desktop computer. In this paper, we propose extensions for QBE to support spatial queries on mobile devices. It is accordingly named as Spatial mQBE (m stands for mobile). An empirical study shows that Spatial mQBE is a simple and an intuitive interface which facilitates the dynamic expression of both spatial and common database queries. The main strengths of this interface are its simplicity to express a query and its expressive power	database;desktop computer;expressive power (computer science);microsoft query;mobile device;mobile phone;personal digital assistant;pocket computer;query by example;usability	Shapiee Abd Rahman;Subhash Bhalla	2006	The Sixth IEEE International Conference on Computer and Information Technology (CIT'06)	10.1109/CIT.2006.121	human–computer interaction;computer science;operating system;mobile device;database;mobile computing;world wide web;spatial database;spatial query	DB	-35.31294443150928	13.951854958404992	27684
fe139d6a875a4a4ed274905ee38bca70e645acb7	a case tool for robot behavior development		The development of high-level behavior for autonomous robots is a time-consuming task even for experts. This paper presents a ComputerAided Software Engineering (CASE) tool, named Kouretes Statechart Editor (KSE), which enables the developer to easily specify a desired robot behavior as a statechart model utilizing a variety of base robot functionalities (vision, localization, locomotion, motion skills, communication). A statechart is a compact platform-independent formal model used widely in software engineering for designing software systems. KSE adopts the Agent Systems Engineering Methodology (ASEME) modeldriven approach. Thus, KSE guides the developer through a series of design steps within a graphical environment that leads to automatic source code generation. We use KSE for developing the behavior of Aldebaran Nao humanoid robots competing in the Standard Platform League of the RoboCup competition.	automatic programming;autonomous robot;code generation (compiler);computer-aided software engineering;graphical user interface;high- and low-level;humanoid robot;mathematical model;nao (robot);software system;state diagram;systems engineering	Angeliki Topalidou-Kyniazopoulou;Nikolaos I. Spanoudakis;Michail G. Lagoudakis	2012		10.1007/978-3-642-39250-4_21	mobile robot;robot learning;social robot;robot control	Robotics	-43.723832516483505	22.327506265422993	27689
3822bbe9e085ec13930affdf36b50d7a3380b0fb	evaluation of bpmn models quality - a family of experiments		The design phase is of special importance in the development of a business process. This phase refers to the modeling, handling and redesigning of processes, but when maintenance tasks have to be performed, this stage may be rather complicated. It implies a heavy investment of time and resources, since it involves both technical developers and business analysts. Moreover, process modeling should permit not only the production of models which are understandable to the users, but also the early detection and correction of errors. All of this adds to the overall quality of the model. We therefore propose a set of measures with which to assess the structural complexity of conceptual business process models. Our aim is to obtain useful indicators to be used when carrying out maintenance tasks on these models, thus obtaining higher quality models by means of an early evaluation of the model’s given quality properties. With the development of a family of experiments, it has been possible to discover a set of measures which may be useful in assessing the usability and maintainability of conceptual business process models.	business process model and notation;experiment;linear algebra;process modeling;usability	Elvira Rolón Aguilar;Félix García;Francisco Ruiz;Mario Piattini;Corrado Aaron Visaggio;Gerardo Canfora	2008			reliability engineering;systems engineering;data mining	SE	-56.243622355499525	23.487428253021257	27732
43277ca0f32088589b34de6c29d486827ce91b4a	design and implementation of information management tools for the edison open platform		We have developed an information management tool for the EDISON (EDucation-research Integration through Simulation On the Net) open platform. EDISON is, at present, a web-based simulation service for education and research in five computational areas, namely, nanophysics, fluid dynamics, chemistry, structural dynamics, and computer aided optimal design. The EDISON open platform consists of three tiers: EDISON application framework, EDISON middleware, and EDISON infra-resources. The platform provides web portals for education and research in areas such as computational fluid dynamics, computational chemistry, computational nanophysics, computational structural dynamics, and computer aided optimal design along with user service. The main purpose of this research is to test the behavior of the release version of the EDISON Open-Platform under normal operating conditions. This management tool has been implemented using the RESTful API designed in EDISON middleware. The intention is to check co-operation between the middleware and the infrastructure. Suggested tools include User management, Simulation and Job management, and Simulation software (i.e., solver) testing. Finally, it is considered meaningful to develop a management tool that is not supported in other web-based online simulation services.	information management;open platform	Jin Ma;Jong-Suk Ruth Lee;Kumwon Cho;Minjae Park	2017	TIIS	10.3837/tiis.2017.02.026	simulation software;the internet;distributed computing;information management;computer-aided;systems engineering;computer science;simulation;open platform;solver;web-based simulation;middleware	DB	-52.539662156273344	10.313588870329346	27771
ea6e751cbe804c3ef2b7aee807e23a7c10183b04	towards a model for specifying and composing concerns in software product line engineering.	aspect oriented programming;user requirements;software product line	In order to fulfil sets of similar user requirements within a specific application domain, one typically uses software product line engineering. In this paper, we investigate the nature of implementations of concerns, specific to software product line engineering. Based on these investigations, we present an approach that allows a modular specification and composition of concerns, with the purpose of constructing concrete variants of a software product line. The approach uses concepts from generic and aspect-oriented programming, and adapts them to the requirements imposed by software product line engineering.	application domain;aspect-oriented programming;interaction;modular programming;requirement;software product line;type system;user requirements document	Volker Kuttruff	2008			reliability engineering;requirements analysis;software requirements specification;verification and validation;aspect-oriented programming;software sizing;computer science;systems engineering;engineering;software design;social software engineering;software framework;user requirements document;component-based software engineering;software development;requirement;software engineering;software construction;software walkthrough;software measurement;software requirements;product engineering	SE	-54.23258825634502	27.107839612597527	27786
052a7f87e5bb6e932d1dcc07a5f490d6d13057f4	rudolf: an http api for exposing semantically represented fiscal olap cubes	databases;resource description framework;data structures;aggregates;data visualization;organizations;data models	OpenSpending is the world's largest repository of open fiscal datasets. As of now it only supported loading datasets from CSV files, leaving out more heavily-structured formats like RDF. Rudolf, an RDF backend has been developed to expose Data Cube RDF triples and OLAP operations in JSON format through an OpenSpending-compatible HTTP API. This API can be directly utilized by the OpenSpending Viewer application to transparently offer aggregate visualizations for RDF fiscal datasets out of the box.	aggregate data;application programming interface;data cube;hypertext transfer protocol;json;olap cube;online analytical processing;out of the box (feature);resource description framework;thinking outside the box	Lazaros Ioannidis;Charalampos Bratsas;Sotiris Karabatakis;Panagiotis Filippidis;Panagiotis D. Bamidis	2016	2016 11th International Workshop on Semantic and Social Media Adaptation and Personalization (SMAP)	10.1109/SMAP.2016.7753406	rdf/xml;computer science;data mining;database;world wide web;rdf schema	DB	-36.568265964414934	5.159614973928223	27795
ef1fdc3b4d79a35e69e3130999b83be30dab9cf5	pre-galois connection on coalgebras for generic component refinement	forward backward;galois connection;behavior modeling;component;refinement;satisfiability;pre galois connection;software component;coalgebra;state transition;reverse engineering	The technique of Galois connections has been applied successfully in many areas of computer science. By employing coalgebras as models for software components, we claim that different forms of behavior model and types of state transitions for components are instances of a single form of coalgebra in a Kleisli category. Based on the Kleisli category, the results on forward/backward morphisms and refinement of components in Set are still satisfied in this more generic framework. We propose a notion of pre-Galois connection in the context of coalgebras for refinement of state-based software components which takes into consideration not only the refinement ordering but also the dynamics of the components, and we study its properties in the Kleisli category. This notion is a powerful tool for relating a component to its refinement and for relating a component to its abstraction. Thus it provides a basis for reasoning about state-based software designs and reverse engineering.		Meng Sun	2008	Electr. Notes Theor. Comput. Sci.	10.1016/j.entcs.2008.03.094	behavioral modeling;combinatorics;discrete mathematics;computer science;component-based software engineering;pure mathematics;component;mathematics;refinement;programming language;reverse engineering;satisfiability	Logic	-43.67627788433254	27.61726983629069	27852
8cd10b5b6f6ee221e57bbc829f4602f82084204b	a unifying reference framework for multi-target user interfaces	institutional repositories;context aware computing;multi platform user interface;fedora;user interface;model based approach;context of use;plasticity of user interfaces;vital;model based approach multi platform user interfaces;vtls;context sensitive user interfaces;ils;multi target user interfaces	This paper describes a framework that serves as a reference for classifying user interfaces supporting multiple targets, or multiple contexts of use in the field of context-aware computing. In this framework, a context of use is decomposed in three facets: the end users of the interactive system, the hardware and software computing platform with which the user have to carry out their interactive tasks and the physical environment where they are working. Therefore, a context-sensitive user interface is a user interface that exhibits some capability to be aware of the context (context awareness) and to react to changes of this context. This paper attempts to provide a unified understanding of context-sensitive user interfaces rather than a prescription of various ways or methods of tackling different steps of development. Rather, the framework structures the development life cycle into four levels of abstraction: task and concepts, abstract user interface, concrete user interface and final user interface. These levels are structured with a relationship of reification going from an abstract level to a concrete one and a relationship of abstraction going from a concrete level to an abstract one. Most methods and tools can be more clearly understood and compared relative to each other against the levels of this framework. In addition, the framework expresses when, where and how a change of context is considered and supported in the context-sensitive user interface thanks to a relationship of translation. In the field of multi-target user interfaces is also introduced, defined, and exemplified the notion of plastic user interfaces. These user interfaces support some adaptation to changes of the context of use while preserving a predefined set of usability properties. © 2003 Elsevier Science B.V. All rights reserved.	context awareness;context-sensitive user interface;interactivity;principle of abstraction;reification (knowledge representation);software development process;usability	Gaëlle Calvary;Joëlle Coutaz;David Thevenin;Quentin Limbourg;Laurent Bouillon;Jean Vanderdonckt	2003	Interacting with Computers	10.1016/S0953-5438(03)00010-9	user interface design;look and feel;user;user experience design;human action cycle;user modeling;computer user satisfaction;interface metaphor;human–computer interaction;user journey;magic pushbutton;computer science;user requirements document;operating system;multimedia;event-driven programming;post-wimp;natural user interface;user interface;world wide web;multiple document interface	HCI	-48.14698834664794	22.541566372741713	27866
39b07eb5c36215695742e7aab173fe7e1350514c	using web services to create the collaborative model for enterprise digital content portal	economie;utilisation information;economia;commerce electronique;uso informacion;base donnee;modele entreprise;enterprise digital content portal;comercio electronico;protocole transmission;red www;sistema temporizado;organisation entreprise;empresa numerica;construction structure;informacion electronica;information use;transparence;real time;information technology;collaboration;timed system;reseau web;database;service web;software systems;base dato;langage java;technologie information;web service;modelo empresa;lenguaje marcacion;transparencia;feasibility;information electronique;enterprise organization;business model;business environment;software architecture;protocolo transmision;organizacion empresa;digital enterprise;internet;structure construction;digital content;value chain;estructura construccion;temps reel;web services;systeme temporise;tiempo real;electronic information;communication protocol;world wide web;transparency;lenguaje java;knowledge economy;economy;information system;entreprise numerique;electronic business;tecnologia informacion;markup language;systeme information;practicabilidad;faisabilite;architecture logiciel;electronic trade;servicio web;java language;langage marquage;competitive advantage;sistema informacion;transmission protocol	meet consumer demand for access to high-quality content through multiple devices. Traditional media companies can make use of existing assets and technologies to deliver and capitalize on the services that consumers want, such as interactive media or Web video. Companies can adopt cost-effective, file-based workflows and connect business and production processes to successfully compete with the growing number of new media providers in this market. can use these tools to collaborate during the creation of rich media content, to support manual workflows, and to automate machine-based processes. Your team can consistently fulfill customer demands for innovative services and content delivered through a variety of mediums with digital content management solutions based on Microsoft products and technologies. Meet new market demands. Go beyond basic metadata and media file management capabilities to better take advantage of the many business opportunities associated with the Web and mobile devices, for instance. To efficiently deliver new services, add components for encoding, streaming, and presenting digital media content and for managing digital rights. Gain first-mover advantage in the marketplace. Use speedier processes to help get new services to market before the competition and maintain the flexibility to react to new priorities and opportunities. Innovative technologies for the entire content value chain help your company to stay ahead. Build new competencies. Provide new offerings and launch strategic initiatives more easily with adaptable workflows, automated processes, and other efficiencies that make content preparation processes less labor intensive. For example, more easily support region-specific launches that require language translation. Production teams can finish projects faster and with lower overhead costs using powerful collaboration tools that are part of the digital content management solutions from Microsoft.	content management system;digital media;digital recording;digital rights management;interactive media;mobile device;new media;overhead (computing);video clip;web service;world wide web	Ruey-Ming Chao;Chin-Wen Yang	2005		10.1007/11539506_132	web service;simulation;computer science;operating system;electronic business;database;information technology;world wide web;computer security;enterprise information system	HCI	-59.42835993956703	11.143201287702825	27894
950620d7c34f3e48a544b576d4dab522388d79b7	hodfa: an architectural framework for homogenizing heterogeneous legacy database	federated database system;heterogeneous databases;sgml;heterogeneous information;text database;object oriented databases;information system	One of the main difficulties in supporting global applications over a number of localized databases and migrating legacy information systems to modern computing environment is to cope with the heterogeneities of these systems. In this paper, we present a novel flexible architecture (called HODFA) to dynamically connect such localized heterogeneous databases in forming a homogenized federated database system and to support the process of transforming a collection of heterogeneous information systems onto a homogeneous environment. We further develop an incremental methodology of homogenization in the context of our HODFA framework, which can facilitate different degrees of homogenization in a stepwise manner, so that existing applications will not be affected during the process of homogenization.	federated database system;information system;stepwise regression	Kamalakar Karlapalem;Qing Li;Chung-Dak Shum	1995	SIGMOD Record	10.1145/202660.202663	computer science;data mining;database;world wide web;information system;database testing;sgml	DB	-34.357702624753955	12.075537705394048	28011
3f9bc5df7fe482cc1431f25e94854778266fbdfd	bpm supported privacy by design for cross-organization business processes		Satisfying privacy related obligations within IT systems that involve multiple organizations is one of the most important, yet challenging tasks in security engineering. When systems involve multiple actors, resources and computing devices, identifying data flows, actors’ liabilities and accesses on data become fundamental requisites for taking appropriate design choices to preserve privacy. To facilitate these tasks, principles such as Privacy by Design have been proposed. However, applying such principles implies rethinking the whole project development lifecycle in order to fulfil at the same time privacy, technical and administrative requirements from early stages of systems design.	beam propagation method;business process;privacy by design	Jovan Stevovic;Paolo Sottovia;Maurizio Marchese;Giampaolo Armellin	2014		10.1007/978-3-319-22885-3_7	business process management;business administration;process management;business	DB	-57.500874066689754	19.8003998882628	28013
60d61754632bd776a39e86f502b57363ae65f923	negotiating and delegating obligations	security model;conflict of interest;the orbac model;delegation;security policy;context;everyday life;obligations	In this paper, we describe a security model where users are allowed to control their obligations partially or totally, depending on the security policy. The main motivation of our work is to design more flexible systems that take into account users' requirements in order to avoid obligation violations and therefore sanctions. In our model, users are able to negotiate or delegate their obligations in the case of incapacity to fulfill them. This is an important aspect to be considered, since it is common that, at work or in everyday life, a user may need to negotiate the fulfillment of a given obligation, or also need the help of others to perform a task on his/her behalf. This may be due to several reasons such as absence, vacation, conflict of interest, lack of time, of resource, of competence or simply for the sake of efficiency. In our model, we propose an approach to deal with the negotiation and the delegation of obligations based on the concept of contexts.	computer security model;requirement	Meriam Ben-Ghorbel-Talbi;Frédéric Cuppens;Nora Cuppens-Boulahia	2010		10.1145/1936254.1936310	computer security model;delegation;computer science;security policy;computer security	SE	-39.19275238357369	19.818918477167717	28029
893626993e22a1e80d73f40d2f6c158069b8a348	fors: a software tool for flexible design	software tool;dynamic reconfiguration;simultaneous engineering;object oriented programming;concurrent design;object oriented;design environment;power system;distributed problem solving;mechanism design;flexible organizations	This paper is a description of FORS (Flexible Organizations), a design environment based on a network representation of the design effort. Each design network consists of: (a) Tools (software programs distributed over the whole network of computers) and (b) Aspects (models to which the tools are applied). The system's communication and exchange of data are based on distributed problem-solving techniques. FORS provides an icon based interface, allows for the dynamic reconfiguration of the design network, maintains libraries of records, tools and aspects, and attempts to develop mechanisms for collaboration between the different tools. The addition and the deletion of tools are relatively easy and the user has the ability to access information and data from previous design efforts. FORS is a new approach to design environments because it gives equal emphasis on the tools and the data used in the design effort. FORS embodies some old ideas, like object-oriented representation of the tools, but simultaneously extends these and creates a modular and flexible environment. One important aspect of FORS is the introduction of the issue of remote effects (the impacts that one design task can have on other tasks). FORS is currently being used in the mechanical design of an automobile window regulator; an implementation in the area of power systems is in progress.	computer;emoticon;ibm power systems;library (computing);problem solving;programming tool;window function	Nikolaos Papanikolopoulos	1991	J. Intelligent Manufacturing	10.1007/BF01471332	real-time computing;simulation;computer science;systems engineering;engineering;artificial intelligence;object-oriented programming;concurrent engineering	EDA	-49.50148586451117	20.004988900126403	28114
a02b75c3f16a07c5ebb7c7481a6fed5ccfffc919	computer-aided systems technology: its role in advanced computerization	computer aided design;time varying;software systems;object oriented;design environment;next generation;process model;problem solving environment	Next generation intelligent machines which will work autonomously or semi-autonomously as well as computer-aided problem solving environments including computer-aided design and computer-aided software system design environments will have sophisticated computerization requirements. It appears that Computer-Aided Systems Technology (CAST) may provide the necessary powerful scientific framework to handle the inherent complexity associated with such requirements. A system theoretic concept, coupling, has been shown to provide a reach paradigm for this purpose. The following types of couplings are discussed: Data coupling, stamp coupling, control coupling, external coupling, common coupling, and content coupling; 1-system coupling, n-system coupling; external and internal couplings; nested, feedback, cascade, and conjunctive couplings; time-varying coupling and multimodels; coupling applied to events, processes, and multimodel process models; time-varying coupling and multifacetted models; hard and soft couplings; and coupling and object-oriented formalism.		Tuncer Ören	1993		10.1007/3-540-57601-0_37	human–computer interaction;computer science;object-oriented design;computer aided design;software engineering;process modeling;object-oriented programming;software system	Logic	-49.11492590319681	20.204808470852285	28141
774bd098f67309226430e64faabd3116aeb21874	communicating requirements using end-user gui constructions with argumentation	formal specification;graphical interface;software engineering;software requirements;graphical user interfaces;systems analysis;requirements elicitation communicating requirements end user gui constructions graphical user inteface textual argumentation requirements specification software engineering process requirements gathering multiple end user constructions software requirements requirements analysts automated assistance;requirement specification;graphical user interfaces software engineering documentation information analysis computer science engineering management information resources solids terminology natural languages;systems analysis graphical user interfaces formal specification	Unsuccessful communication is often at the root of inadequate requirements specification [14]. This can lead to requirements that do not capture complete stakeholder expectations. Stakeholders can include managers, software engineers, end-users, clients, etc. End-users provide a rich source of information about a system as they will directly interact with the final system. They also tend to have a solid knowledge of the domain including the tasks being automated. Thus, a major goal early in the software engineering process is gathering meaningful requirements from end-users. Potts, et al. [14] propose inquiry-based requirements analysis. They break the process into three major phases: Requirements Documentation, Requirements Discussion, and Requirements Evaluation. Finkelstein [5] talks about seven difficult areas in requirements engineering. One of those areas is requirements acquisition. Requirements documentation or requirements acquisition is the process of getting an initial set of requirements from stakeholders. Getting this starting base of requirements is a challenge. My topic is to explore using mock end-user graphical interface construction supplemented with textual argumentation as a means of communicating software requirements information to software requirements analysts and providing automated assistance for requirements analysts examining this information.	documentation;graphical user interface;information source;mock object;potts model;requirement;requirements analysis;requirements engineering;software development process;software engineer;software engineering;software requirements specification;word lists by frequency	J. Michael Moore	2003		10.1109/ASE.2003.1240338	requirements analysis;software requirements specification;requirements management;system requirements;business requirements;computer science;systems engineering;software design;social software engineering;user requirements document;software development;requirement;software engineering;system requirements specification;requirements elicitation;software construction;functional specification;graphical user interface;database;requirements engineering;non-functional testing;programming language;software documentation;software requirements;requirements traceability	SE	-60.381303284368336	24.09209622297587	28171
c14361e192fc72ad9b0748a06d1dc3e2381f83e0	axiomatic specification of large information systems: experiences and consequences	hybrid approach;requirement engineering;medical information system;information system	This paper reports on a case study where formal (axiomatic) techniques were applied to the functional specification of a large medical information system. In order to cope with the size of the specification and with the process of requirements engineering, a combination of semi-formal (mainly diagrammatic) and purely formal notations were used. For the semi-formal notations, a translation into axiomatic specifications was defined such that the whole specification is still on the formal level. In this paper, a short overview of the case study is given together with a critical evaluation. Two problematic issues are pointed out regarding the results of the case study, and proposals for a further improvement are made. The systematic usage of a hybrid approach mixing semi-formal and formal notation is strongly recommended for the precise specification of large application systems.	information system	Heinrich Hußmann	1994		10.1007/BFb0014437	reliability engineering;information engineering;computer science;systems engineering;knowledge management;management information systems;information quality;information system	EDA	-57.0752908696988	23.144563269766905	28172
ddb3fd962ba0eaddb14d74a1a64bd6ef34257bf7	the approach to provide and support the aviation transportation system safety based on automation models		We offered an approach to provide and support the safety of the complex system functioning based on the coordination of the interaction between its elements. The automation model of functioning process was created on the basis of the cause-effect approach. This model allows to present synchronous communication between elements of these systems. The model can be used in aviation training centers, which provide such programs as a periodic ground training and a professional development of aviation staff.	automation;system safety	Alexander F. Rezchikov;Vadim A. Kushnikov;Vladimir Ivaschenko;Aleksey Bogomolov;Leonid Filimonyuk;Olga N. Dolinina;Ekaterina Kulakova;Konstantin Kachur	2017		10.1007/978-3-319-57141-6_26	system safety;professional development;automation;complex system;synchronization;aviation;transport engineering;asynchronous communication;engineering	Robotics	-54.40843472772704	6.674329711110482	28189
70a5d4a72f3b9264995a4e5ebd963ed3ec22053a	an approach to integrate data and knowledge management in next generation information systems.	knowledge management;next generation;information system		information system;knowledge management;next-generation network	Qing Li;Frederick H. Lochovsky	1993			knowledge base;data management;computer science;knowledge management;data mining;knowledge extraction;structure of management information;information management;information system	AI	-48.50170038093123	8.43651099167621	28243
1f9cb5c765007522ab2f3f6d6c462c1aac9e47e3	workflow management in electronic commerce	business to business;workflow management;electronic commerce;electronic markets;process support;virtual enterprise;business process	In electronic commerce scenarios, effectiveness and efficiency of business process execution are of paramount importance for business success. Even more than in traditional commerce scenarios, they determine the chances of survival of organizations in fast moving, highly competitive electronic markets. To obtain the required levels of effectiveness and efficiency, well-structured automated business process support is required. For typical business-to-consumer (B2C) electronic commerce, process support is usually of an intra-organizational nature. For businessto-business (B2B) electronic commerce, however, process support across organizational boundaries is often required as the basis for virtual enterprises. This tutorial addresses the application of workflow management (WFM) for process support in both these cases. The tutorial is organized into three parts. In the first part, we pay attention to classical workflow management in the context of a single organization. In the second part, we extend this to workflow management across the boundaries of organizations. In the third part, we further extend this model by making service processes  implemented as workflows  the objects traded in ecommerce scenarios. We outline each part in the sections below.	business process;e-commerce;electronic markets;wired for management	Paul W. P. J. Grefen	2002		10.1007/3-540-45816-6_7	e-commerce;workflow;xpdl;computer science;knowledge management;business process management;workflow management coalition;database;process management;business process;event-driven process chain;management;business process modeling;workflow management system;workflow engine;workflow technology	DB	-58.327039278345296	15.175942112529059	28244
2231b95d5ca371ef67509411df4133ca5803ba16	task decomposition and grouping for customer collaboration in product development	customer collaboration;adaptive genetic algorithm;task grouping;task decomposition;90b50;design structure matrix;product development			Xuefeng Zhang;Yu Kyung Yang;Beifang Bao	2016	J. Intelligent Systems	10.1515/jisys-2014-0171	computer science;knowledge management;operations management;engineering drawing	Robotics	-59.132411796012896	10.776913620648479	28248
6407aee4deaf95f290a9e98f05fecf600fec697a	best practices for automated traceability	busqueda informacion;manuals;document handling;automated traceability;formal specification;standards organizations;software maintenance;information retrieval;information retrieval techniques;best practice;information retrieval document handling formal specification;maintenance engineering;code standards;standards development;recherche information;best practices;capability maturity model;unified modeling language;requirements trace matrix;system testing;rastreabilidad;tracabilite;traceability;best practices software maintenance capability maturity model code standards standards development standards organizations unified modeling language manuals maintenance engineering system testing;legacy documents automated traceability information retrieval techniques requirements trace matrix;legacy documents	Automated traceability applies information-retrieval techniques to generate candidate links, sharply reducing the effort of manual approaches to build and maintain a requirements trace matrix as well as providing after-the-fact traceability in legacy documents.The authors describe nine best practices for implementing effective automated traceability.	best practice;information retrieval;requirement;traceability matrix	Jane Cleland-Huang;Brian Berenbach;Stephen Clark;Raffaella Settimi;Eli Romanova	2007	Computer	10.1109/MC.2007.195	maintenance engineering;computer science;software engineering;reverse semantic traceability;database;management;traceability matrix;requirements traceability;best practice	SE	-58.0577320132442	32.1200029099118	28265
15e0d3fc7f53e436d24f5085dd94f71af303d24e	knowledge-driven finite-state machines. study case in monitoring industrial equipment	owl;manufacturing line knowledge driven finite state machines monitoring industrial equipment state machines ontological models sparql queries industrial robots;industrial monitoring finite state machine ontology knowledge driven manufacturing owl sparql;service robots;computational modeling;monitoring computational modeling owl ontologies service robots manufacturing;monitoring;manufacturing;ontologies;production equipment condition monitoring finite state machines ontologies artificial intelligence production engineering computing	Traditionally state machines are implemented by coding the desired behavior of a given system. This work proposes the use of ontological models to describe and perform computations on state machines by using SPARQL queries. This approach represents a paradigm shift relating to the customary manner in which state machines are stored and computed. The main contribution of the work is an ontological model to represent state machines and a set of generic queries that can be used in any knowledge-driven state machine to compute valuable information. The approach was tested in a study case were the state machines of industrial robots in a manufacturing line were modeled as ontological models and used for monitoring the behavior of these devices on real time.	computation;finite-state machine;high-level programming language;industrial robot;language-independent specification;ontology (information science);programming paradigm;sparql;state transition table	Luis E. Gonzalez Moctezuma;Borja Ramis;Xiangbin Xu;Andrei Lobov;José L. Martínez Lastra	2015	2015 IEEE 13th International Conference on Industrial Informatics (INDIN)	10.1109/INDIN.2015.7281881	engineering;data science;data mining;database	Robotics	-47.582054921339015	15.056138464105441	28278
3b9ce0423519a5eceb24ac797271845e20b91f56	a probabilistic trust model for semantic peer to peer systems	probabilistic trust model;probabilistic model;local computation;p2p network;p2p setting;semantic annotation;obsolete annotation;external authority;semantic peer-to-peer system;decentralized electronic social network;different viewpoint;decentralized overlay network;overlay network;p2p;social network	Semantic peer to peer (P2P) systems are fully decentralized overlay networks of people or machines (called peers) sharing and searching varied resources (documents, videos, photos, data, services) based on their semantic annotations using ontologies. They provide a support for the emergence of open and decentralized electronic social networks, in which no central or external authority can control the reliability of the peers participating to the network. This lack of control may however cause some of the results provided by some peers to be unsatisfactory, because of inadequate or obsolete annotations.  In this paper, we propose a probabilistic model to handle trust in a P2P setting. It supports a local computation and a simple form of propagation of the trust of peers into classes of other peers. We claim that it is well appropriate to the dynamics of P2P networks and to the freedom of each peer within the network to have different viewpoints towards the peers with which it interacts.	computation;emergence;java annotation;ontology (information science);peer-to-peer;social network;software propagation;statistical model	Gia Hien Nguyen;Philippe Chatalic;Marie-Christine Rousset	2008		10.1145/1379350.1379359	computer science;database;internet privacy;world wide web	Web+IR	-41.58867150325362	9.571216790159983	28333
a31dc0a6df9e5a56a15d5dd737d571c05340d599	a service composition approach for inter-domain provisioning	integrated approach;business parameter service composition interdomain qos aware service provisioning internet heterogeneity customer service requirement service class specification qos performance parameter service specific parameter;customer service requirement;internet heterogeneity;service composition;interdomain qos aware service provisioning;service specific parameter;qos performance parameter;satisfiability;customer service;additives;quality of service internet;internet;business;inter domain provisioning;bandwidth;business parameter;peer to peer computing;jitter;quality of service;qos model;service provision;service composition inter domain provisioning qos model service class specification;service class specification;quality of service business additives delay peer to peer computing jitter bandwidth	Inter-domain QoS-aware service provisioning is still a complex task due to the Internet heterogeneity. It is necessary to overcome several obstacles in order to achieve a scenario where providers fully interact to satisfy all customer service requirements. Some of these obstacles are service class specification and service composition. This paper presents an integrated approach for service class specification and service composition that supports the provisioning of QoS-aware services in inter-domain environments. This approach makes use of QoS performance parameters, service-specific parameters and business parameters to compose services that fulfill customer requirements and comply with providers' business expectations.	business process;inter-domain;provisioning;quality of service;requirement;service composability principle	Fernando Matos;Alexandre Matos;Paulo Simões;Edmundo Monteiro	2010	2010 International Conference on Network and Service Management	10.1109/CNSM.2010.5691273	service provider;service level requirement;service level objective;real-time computing;mobile qos;the internet;jitter;quality of service;telecommunications;differentiated service;food additive;computer science;service delivery framework;service design;service guarantee;service desk;customer service assurance;world wide web;bandwidth;computer network;satisfiability	HPC	-47.17492440246425	16.605294719447013	28370
235bbaa0be72950b7d3abd5808bc9153a2accc6d	a simulation environment for the coordinated operation of multiple autonomous underwater vehicles	automatic control;autonomous underwater vehicle;object interaction;underwater vehicles;remotely operated vehicles;specification language;expressive power;automata;dynamic environment;computational modeling;marine vehicles;underwater vehicles remotely operated vehicles sea measurements vehicle dynamics computational modeling marine vehicles power system modeling automata automatic control graphics;hybrid system;shift language;hybrid automata;technical report;power system modeling;vehicle dynamics;graphics;general applications;simulation environment;control strategy;dynamic networks;hybrid systems;sea measurements	A simulation environment of the coordinated operation of multiple Autonomous Underwater Vehicles (AUVs) is presented. The primary application of this simulation environment is the specification and analysis of an innovative approach to coastal oceanography based on the Generalized Vehicle [GV] concept. A Generalized Vehicle is a group of vehicles whose spatial and logic organization is coordinated in such a way that the group behaves as a single entity. The simulation environment was developed in SHIFT, a new specification language for describing dynamic networks of hybrid automata. These constitute the most adequate modeling formalism for this problem domain. The expressive power of SHIFT provides a compact notation for modeling spatial and logical relationships in a dynamic environment and for modeling and analyzing control strategies governing object interactions.	automata theory;autonomous robot;hybrid automaton;interaction;problem domain;semantics (computer science);simulation;specification language	João Borges de Sousa;Aleks Göllü	1997		10.1145/268437.268755	intervention auv;control engineering;simulation;computer science;engineering;automatic control;marine engineering;hybrid system	Robotics	-39.960441941340854	22.05973013527317	28382
0e2545bee9bc2a5b5fc06f0bc9d29b9028fbaa56	ontology-based translation of natural language queries to sparql		We present an implemented approach to transform natural language sentences into SPARQL, using background knowledge from ontologies and lexicons. Therefore, eligible technologies and data storage possibilities are analyzed and evaluated. The contributions of this paper are twofold. Firstly, we describe the motivation and current needs for a natural language access to industry data. We describe several scenarios where the proposed solution is required. Resulting in an architectural approach based on automatic SPARQL query construction for effective natural language queries. Secondly, we analyze the performance of RDBMS, RDF and Triple Stores for the knowledge representation. The proposed approach will be evaluated on the basis of a query catalog by means of query efficiency, accuracy, and data storage performance. The results show, that natural language access to industry data using ontologies and lexicons, is a simple but effective approach to improve the diagnosis process and the data search for a broad range of users. Furthermore, virtual RDF graphs do support the DB-driven knowledge graph representation process, but do not perform efficient under industry conditions in terms of performance and scalability.	algorithm;computer data storage;graph (abstract data type);knowledge graph;knowledge representation and reasoning;lexicon;nl (complexity);natural language;ontology (information science);prototype;relational database management system;requirement;resource description framework;sparql;spin;scalability;semantic search;simple knowledge organization system;software prototyping;table (information);triplestore;uptime;usability	Malte Sander;Ulli Waltinger;Mikhail Roshchin;Thomas A. Runkler	2014				Web+IR	-35.04948356746069	4.198939618701369	28392
cd941cf65b14b02e7279d14bfc025431357c4e6e	conceptual model for a software maintenance environment	object representation;document structure;object representation model conceptual model software maintenance comform configuration management formalization for maintenance incremental documentation software documentation form filling data model;software maintenance;software systems;system documentation;conceptual model;data model;system documentation software maintenance configuration management software development management;software maintenance documentation filling data models software systems standardization software engineering guidelines computer science cities and towns;configuration management;software development management	A conceptual model for a software maintenance method named COMFORM (Configuration Management Formalization for Maintenance) is presented. COMFORM provides guidelines and procedures for carrying out the maintenance process, while establishing a systematic approach for the support of existing software systems. Incremental documentation, the process of building up the software documentation while the system is maintained, has a key role in this maintenance method. The documentation required by the method consists of keeping the maintenance history and information related to the software modules being maintained. Forms have been created in order to guide the maintainers during the maintenance process. Thus, their task will be of filling in forms for generating the required documentation instead of defining their own document structures. The system information obtained by filling in forms has been formalized according to a data model which provides a common basis for the representation of the method. This paper presents the conceptual model for COMFORM which was obtained using the data model termed Object Representation Model (ORM). ORM has been used because of its enhanced semantic capabilities and it provides the necessary generality and standardization for software representation.	configuration management;data model;diagram;international standard book number;object type (object-oriented programming);requirement;software documentation;software maintenance;software system;system information (windows);traceability	Miriam A. M. Capretz	1997		10.1109/HICSS.1997.663160	reusability;personal software process;long-term support;verification and validation;software sizing;data model;software project management;computer science;conceptual model;package development process;backporting;software design;social software engineering;component-based software engineering;software development;document structure description;software engineering;software construction;database;configuration management;software documentation;software analytics;software maintenance;software deployment;software development process;software system;software peer review	SE	-51.83323042892042	21.841333045938516	28394
90b9c499ef69b97b3b7c053715db27d9eba68dd0	business process modeling using petri nets		Business process modeling has become a standard activity in many organizations. We start with going back into the history and explain why this activity appeared and became of such importance for organizations to achieve their business targets. We discuss the context in which business process modeling takes place and give a comprehensive overview of the techniques used in modeling. We consider bottom up and top down approaches to modeling, also in the context of develop- ing correct-by-construction models of business processes. The correctness property we focus on is soundness, or weak termination, basically mean- ing that at every moment of its execution, a process has an option to continue along an execution path leading to termination, which is an im- portant sanity check for business processes. Finally, we discuss analogies between business processes and software services and their orchestrations and argue the applicability of the described modeling techniques to the world of services.	business process;petri net;process modeling	Kees M. van Hee;Natalia Sidorova;Jan Martijn E. M. van der Werf	2013	Trans. Petri Nets and Other Models of Concurrency	10.1007/978-3-642-38143-0_4	business domain;computer science;systems engineering;knowledge management;artifact-centric business process model;business process management;operations management;process modeling;business process model and notation;business process;business process discovery;business rule;new business development;business process modeling;business architecture	SE	-56.61520939940681	19.055939480761463	28395
8b8e613f83009eb8f7d83b3386a8bddee300cbca	beyond mere application structure thoughts on the future of cloud orchestration tools	cloud computing;life cycle management	Managing cloud applications running on IaaS is complicated and error prone. This is why DevOps tools and application description languages have been emerging. While these tools and languages enable the user to define the application and communication structure based on application components, they lack the possibility to define sophisticated communication patterns including the wiring on instance level. This paper details these shortcomings and presents approaches to overcome them. In particular, they we propose (i) adding boundaries to wiring specifications and (ii) introducing a higher-level abstraction—called facet—on top of the application. The combination of both concepts allows specifying wiring on basis of logical units and their relations. Hence, the concepts overcome general wiring problems that currently exist in cloud orchestration tools. In addition to that, the introduction of facets improves the re-use of components across different applications. c © 2014 The Authors. Published by Elsevier B.V. Peer-review under responsibility of Institute of Communication and Computer Systems.	cloud computing;cognitive dimensions of notations;component-based software engineering;devops;hardware description language;inter-process communication;wiring	Jörg Domaschka;Frank Griesinger;Daniel Baur;Alessandro Rossini	2015		10.1016/j.procs.2015.09.231	simulation;computer science;artificial intelligence;theoretical computer science;operating system;data mining;algorithm	HPC	-54.23808987496603	23.697795829116608	28431
f1903f1d79eb14235fbeb3396aa94a4458da5147	formal software development in the verification support environment (vse)	formal methods software engineering deduction security verification	The paper presents a survey of the VSE system, a kind of CASE-tool for formal software development. It is a summary of a tutorial presentation describing methodology, formalisms, architecture, and proof support of the system. For illustration a commercial application from the IT-security domain is used.	business models for open-source software;care-of address;computer-aided software engineering;concurrent computing;earthbound;formal methods;graphical user interface;programming paradigm;software development	Dieter Hutter;Georg Rock;Jörg H. Siekmann;Werner Stephan;Roland Vogt	2000	J. Exp. Theor. Artif. Intell.	10.1080/095281300454784	verification and validation;formal methods;formal verification;software verification;computer science;package development process;software construction;programming language	SE	-45.61206402211629	30.333418726129384	28449
b5ef01c956e5bbb895bf673650ee2cb1591986bb	holonic and multi-agent technologies for service and computing oriented manufacturing		Industrials are seeking for models and solutions th at are not only able to provide efficient overall production performance, but also to face re actively a growing set of unpredicted events. The demand for large scale industrial syste ms running in complex and even chaotic environments requires the consideration of new para digms and technologies that provide flexibility, robustness, agility and responsiveness . Holonic systems are, actually by definition, targeting challenges that include coping with the h eterogeneous nature of manufacturing systems and their on-line interactive nature in com bination with competitive pressures. Multiagent systems is a suitable implementing approach t o address these challenge by offering an alternative way to design control systems, based on the decentralization of control functions over distributed autonomous and cooperative entitie s.	autonomous robot;control function (econometrics);control system;holon (philosophy);multi-agent system;online and offline;responsiveness;software agent	André Thomas;Theodor Borangiu;Damien Trentesaux	2017	J. Intelligent Manufacturing	10.1007/s10845-015-1188-4	systems engineering;process management;manufacturing engineering	Robotics	-53.48351010059457	11.961778673030127	28492
86dfb008d411dfa611114a51a153129d06c924be	ontological approach to the assessment of information sufficiency for software quality determination		"""The aim of this study is the development of approach to the assessment of information sufficiency for software quality determination (according to ISO 25010: 2011). The proposed approach to assessment of information sufficiency is based on the comparative analysis of fragments of ontology of the subject domain """"Software Engineering"""" and ontologies, that are developed on the basis of software requirements and system specification of the developed software. The approach provides the improvement the specifications for the presence of measures, that are necessary to the determination of software quality sub characteristics and characteristics. The work of developed approach is illustrated by the assessment of information sufficiency for software quality determination of automated system for large-format photo print."""	cross-correlation;formal specification;interference (communication);ontology (information science);qualitative comparative analysis;requirement;software engineering;software quality;software requirements;veracity	Tetyana Hovorushchenko;Oksana Pomorova	2016			software quality;ontology;computer science;systems engineering	SE	-58.021752866079666	24.62705175883809	28537
f29d7d4fa0284e008a961ed4176ad5dee81f954e	abstract interaction tools: a language for user interface management systems	lenguaje programacion;interfase usuario;input device;knowledge based system;user interface management system;programming language;gestion;user interface;implementation;production system;resource manager;software engineering;input output;ejecucion;interactive system;error correction;process control;langage programmation;interface utilisateur;context dependent;user interaction;management;language model;physical interaction;production rule;real time systems	A language model is presented for the specification of User Interface Management Systems. The model, called the Abstract Interaction Tool (AIT) model, offers a tree-like hierarchy of interaction objects. Each object represents a subtree and can be considered as an abstract input device containing a syntax-like specification of the required input pattern. The hierarchy of specifications amounts to a system of syntactical productions with multiple control. Terminal nodes of the AIT tree represent the interface to the physical interaction devices. The AIT model features hierarchical output resource management. At the higher, more abstract, level the input-output is loosely coupled. At lower levels the coupling becomes increasingly tight. At the upper levels, AITs model the functions (what) required by the user, whereas at the lower levels the way to accomplish them (how) is stressed. The AIT model has modes for multithread and multiple-device user interaction. There are facilities for context-dependent prompting, echoing, feedback, error correction, and expertise levels. A special section in the AIT provides for links to application modules. As a model for general interactive systems, AITs can be applied to graphics, process control, dialogue, and real-time systems. AITs can also be used to define controlled production rules in knowledge-based systems. In addition the model can provide tools for the software engineering phases specification and prototyping.	advanced intelligent tape;context-sensitive language;echo (computing);error detection and correction;feedback;graphics;human–computer interaction;input device;knowledge-based systems;language model;loose coupling;real-time computing;real-time locating system;software engineering;thread (computing);tree (data structure);user interface management systems	Jan van den Bos	1988	ACM Trans. Program. Lang. Syst.	10.1145/42190.42191	input/output;real-time computing;simulation;error detection and correction;human–computer interaction;computer science;context-dependent memory;process control;production system;programming language;user interface;implementation;input device;language model	SE	-38.567130802847366	26.060687397667085	28574
7e5453e38a92c789d5c6b3d057ddb3e6b18f686b	emerging consensus in-situ	ontology mapping;p2p;feature vector;distributed environment;information exchange;on the fly;context dependent	Traditional ontology mapping techniques are not strictly applicable in a dynamic and distributed environment (e.g. P2P and pervasive computing) in which on-the-fly alignments are sought after. We propose an approach that collaborates the logic formalisms with collaboratively created web repositories. A logic conceptualisation based “signaturing” algorithm is to discover, from concept definitions, the “feature” vectors that uniquely identify concepts; web repositories are used to understand the implications of these features. Such a combination solidifies an on-demand and approximate mechanism that emerges a contextdependent and task-specific consensus among heterogeneous participants of an information exchange task.	approximation algorithm;information exchange;semantic integration;ubiquitous computing;world wide web	Bo Hu;Srinandan Dasmahapatra;Paul H. Lewis	2007			computer science;bioinformatics;data mining;information retrieval	Web+IR	-43.24222723763244	9.034402475556918	28583
143852399dafcd40a3ca9f54082589d93904b068	integrating distributed heterogenous databases and distributed grid computing	grid computing;xml;distributed databases;distributed transactions;relational database;storage system;database system;middleware;data access;distributed database;e commerce	The aim of this paper is to present a middleware that combines the flexibility of distributed heterogeneous databases with the performance of local data access. The middleware will support both XML and relational database paradigms and applies Grid security techniques. The computing and database access facilities are implemented using Grid and Java technologies. In our system, data can be accessed in the same way independently of its location, storage system, and even storage format. The system will also support distributed queries and transaction management over heterogeneous databases. Our system can be utilised in many applications related to storing, retrieval, and analysis of information. Because of advanced security components, e-commerce is a potentical application area, too. The implementation is based on the principle that each node on the computing grid containing a database contains also a Java agent. The database requests are first sent to the agent which takes care of security tasks, possibly does some preprocessing or translation to the query, and finally transmits the request to the database system. The agents also take care of distributed transaction management. The system does not have a special master but each agent has a capability to handle distributed transactions by sending requests to other agents.	care-of address;computer data storage;data access;distributed computing;distributed database;distributed transaction;e-commerce;grid security infrastructure;grid computing;java;middleware;preprocessor;relational database;transaction processing;xml	Tapio Niemi;Marko Niinimäki;Vesa Sivunen	2003			distributed concurrency control;data mining;grid computing;drmaa;distributed algorithm;database;distributed database;semantic grid;computer science;database testing;distributed design patterns;distributed computing	DB	-36.48107327789608	14.223435701668217	28632
0563f1ab9109ab7ed4fbd466ef783a4f6d918ba1	conceptual framework for the use of the service-oriented architecture-approach in the digital preservation	business process execution language;service component architecture;digital preservation;service oriented architectures	This paper presents a conceptual framework for the use of the SOA-approach in the digital preservation. The focus of this work reflects the service composition part within the SOA service concept. Previously released approaches have been separately using process-oriented models to describe the behaviour of services, and structure composition models to represent service interactions. In this paper, the authors attempt to combine the even mentioned disjunctive models to obtain a comprehensive model, which represents both, the structure and the behaviour of the services. For this purpose, the novel SCA-BPEL serves as basis for the implementation in a future-oriented SOA-compliant digital preservation software system. The SCA-model specifies the architecture of the intended system, while the BPEL-model indicates the behavior of each service, which is defined in the SCA-model. We can conclude that the SCA-BPEL approach is well-suited for building a scalable, adaptable and service-oriented software system. The knowledge gained from the conceptual framework will serve as a basis for future digital preservation developments.	business process execution language;business logic;conceptual schema;disjunctive normal form;interaction;iterative method;open archival information system;requirement;scalability;service composability principle;service-oriented architecture;service-oriented device architecture;software system;systems design	Christian Saul;Fanny Klett	2008			systems engineering;software system;digital preservation;architecture;scalability;conceptual framework;service-oriented architecture;the conceptual framework;computer science	SE	-54.15267713326621	18.973421404707747	28666
bacf221503c2b018a809f6108477b1bfc03d9cf8	focusing real-time systems analysis on user operations	systems analysis finite automata real time systems;bottle filling system;bottle filling system real time systems analysis user operations system development requirements model operations concept model implementation model system analysis structured analysis finite state machines threads multiview paradigm;real time systems power system modeling software systems sensor phenomena and characterization process design delay humans system testing aircraft;real time;multiview paradigm;real time systems analysis;operations concept model;finite state machines;requirements model;systems analysis;finite automata;system analysis;system development;structured analysis;threads;point of view;implementation model;finite state machine;structure analysis;user operations;real time systems	A way is presented to model and validate complex, real-time systems by describing these systems from the viewpoints of the major parties in system development: the customer, the user, and the implementer. The models representing these points of view are called, respectively, the requirements model, the operations-concept model, and the implementation model. The focus is on how the concept of operations can be formally factored into established real-time system-analysis methods in terms a nontechnical user can understand. The approach integrates and refines several real-time-oriented modeling methods, including structured analysis, finite-state machines, and threads. Modeling needs are discussed, the multiview paradigm is presented, and an extensive example of a bottle-filling system is given to illustrate the use of the method.<<ETX>>	finite-state machine;programming paradigm;real-time clock;real-time computing;real-time operating system;requirement;structured analysis	Michael S. Deutsch	1988	IEEE Software	10.1109/52.7942	systems analysis;thread;real-time computing;simulation;user modeling;computer science;theoretical computer science;software engineering;structural analysis;system analysis;finite-state machine;structured analysis	Embedded	-39.59857275321268	30.719592814452458	28674
5a073c90fb96022ec328aa3222d1fb132e4a4386	synthesis revisited: generating statechart models from scenario-based requirements	object-oriented variant;major improvement;statechart model;good synthesis algorithm;play-engine tool;long-known general;complex system;live sequence chart;fundamental problem;existing uml case tool;scenario-based requirement	Constructing a program from a specification is a long-known general and fundamental problem. Besides its theoretical interest, this question also has practical implications, since finding good synthesis algorithms could bring about a major improvement in the reliable development of complex systems. In this paper we describe a methodology for synthesizing statechart models from scenario-based requirements. The requirements are given in the language of live sequence charts (LSCs), and may be played in directly from the GUI, and the resulting statecharts are of the object-oriented variant, as adopted in the UML. We have implemented our algorithms as part of the Play-Engine tool and the generated statechart model can then be executed using existing UML case tools.	algorithm;chart;complex systems;computer-aided software engineering;graphical user interface;requirement;state diagram;unified modeling language	David Harel;Hillel Kugler;Amir Pnueli	2005		10.1007/978-3-540-31847-7_18	state diagram;simulation;computer science	SE	-44.84336864871529	28.781911853024507	28765
f0b0e7e2ec9934176d3c89d8b78f47dd15048389	modernization of teaching in embedded systems design-an international collaborative project	embedded systems teaching;imperial college;international collaborative project;london university;personal digital assistant;learning experience;design engineering;manchester university;development costs reduction;digital camera;learning environment;embedded system;international collaboration in teaching;mobile phone;pedagogical issues;university of new south wales;embedded systems;programmable hardware development board embedded systems teaching international collaboration in teaching microprocessor design teaching;computer science education;teaching modernization;embedded system design;learning tool teaching modernization embedded systems international collaborative project university of new south wales australia manchester university imperial college london university united kingdom development costs reduction programmable hardware software development;learning tool;assessment methods;united kingdom;programmable hardware development board;educational courses;microprocessor design teaching;new south wales;software development;computer science education electrical engineering education design methodology;electrical engineering education;laboratory experiment;teaching computer science education design engineering educational courses electrical engineering education embedded systems;electrical engineering;programmable hardware;australia;teaching;design methodology	This paper describes the process of review, design, and delivery of a course in modern embedded systems, an international collaborative teaching project involving the University of New South Wales (Australia), Manchester University, and Imperial College, London University (United Kingdom). This project, being the first of its kind anywhere in the world, provides a learning environment that replicates the current industrial practice in embedded systems design in an easy and comprehensible setting, an environment where the processor, dedicated coprocessors, and software are all integrated to create a functional system such as used in sophisticated electronic devices, including mobile phones, Web phones, televisions, digital cameras, and personal digital assistants. Such collaborations are important in both reducing development costs in developing up-to-date, and increasingly sophisticated, courses and in addressing pedagogical issues that are common between computer and electrical engineering programs in all academic institutions. To assist students' learning experience, the course is supported with purpose built state-of-the-art programmable hardware and software development platforms, carefully planned laboratory experiments, lecture notes, weekly online quizzes, tutorials, and a companion CD-ROM as a learning tool. Since the introduction of this complete package, students' satisfaction, assessment results, and skills obtained through evaluation and assessment methods have improved markedly	cd-rom;coprocessor;digital camera;electrical engineering;embedded system;experiment;mobile phone;personal digital assistant;software development;systems design;television	Saeid Nooshabadi;Jim D. Garside	2006	IEEE Transactions on Education	10.1109/TE.2006.872402	engineering management;education;simulation;design methods;computer science;engineering;electrical engineering;software development;software engineering	Embedded	-54.15878274956912	4.486455283109877	28777
2c029c2c296c729a80d06b4972a7e7f972027f55	the impact of interactive application development with codestar	cycle time;life cycle;texas instruments;lines of code;interactive application;pilot project;information system	Many companies are currently plagued with the problem of not being able to deliver information systems quickly enough to meet business opportunities. Management is generally dissatisfied with the development cycle time, and backlogs are often two years or more. Texas Instruments has a strategic program to solve this problem by developing an integrated set of tools to automate the systems life cycle of analysis, design, construction and maintenance, and to reduce associated costs.CODESTAR, the first major tool to be completed (currently for use only at TI), addresses both construction and maintenance. It supports applications ranging from simple to complex and can be used for the development of IMS, batch and TSO applications. For example, the current CODESTAR was developed using the previous CODESTAR.A pilot project assessed the impact of CODESTAR. The project's scope included the construction, checkout and installation of a 20-screen IMS transaction system involving 6,000 lines of code. The project had originally been designed, scheduled and budgeted for a non-CODESTAR methodology.Results were impressive. Both elapsed time and manpower were reduced by 50 percent, while computer costs decreased slightly.	batch processing;information management system (ims);information system;list of code lyoko episodes;point of sale;source lines of code;system lifecycle;time sharing option	Robert Fisher	1987	SIGMETRICS Performance Evaluation Review	10.1145/32100.32101	biological life cycle;simulation;cycle time variation;computer science;operating system;programming language;source lines of code;operations research;information system	SE	-60.570294714697596	5.80554197088947	28795
927fdf88b8b864f3205d41f34c11fa47ced595d2	development and application of composite complexity models and a relative complexity metric in a software maintenance environment	developpement logiciel;complexity metrics;ciclo desarrollo;life cycle;software maintenance;software complexity;software management;maintenance cost;metric;minimizacion costo;minimisation cout;complexity measure;cost minimization;desarrollo logicial;mesure complexite;software development;costo manutencion;cycle developpement;metrico;fiabilite logiciel;fiabilidad logicial;software design;software reliability;medida complexidad;metrique;gestion logiciel;software process;cout entretien	A great deal of effort is now being devoted to the study, analysis, prediction, and minimization of software maintenance expected cost, long before software is delivered to users or customers. It has been estimated that, on the average, the effort spent on software maintenance is as costly as the effort spent on all other software costs. Software design methods should be the starting point to aid in alleviating the problems of software maintenance complexity and high costs. Two aspects of maintenance deserve attention: (1) protocols for locating and rectifying defects, and for ensuring that no new defects are introduced in the development phase of the software process, and (2) protocols for modification, enhancement, and upgrading. This article focuses primarily on the second aspect, the development of protocols to help increase the quality and reduce the costs associated with modifications, enhancements, and upgrades of existing software. This study developed parsimonious models and a relative complexity metric for complexity measurement of software that were used to rank the modules in the system relative to one another. Some success was achieved in using the models and the relative metric to identify maintenance-prone modules.	communications protocol;occam's razor;rectifier;software design;software development process;software maintenance	Jonathan M. Hops;Joseph S. Sherif	1995	Journal of Systems and Software	10.1016/0164-1212(94)00095-5	reliability engineering;biological life cycle;software quality management;software sizing;metric;systems engineering;engineering;software design;software development;software engineering;software maintenance;software deployment;goal-driven software development process;software development process;software quality;programming complexity;software metric;software quality analyst;avionics software	SE	-61.84654625263941	28.796941356475507	28805
582acb97e0946a0e304a67765ff991c4550398ec	structured programming in a production programming environment	computer facilities;programming;production programming environment;structured programming;top down programming;chief programmer teams (cpt's);development support libraries (dsl's);structured coding;top-down development;top-down programming;encoding;organizations;dsl	Discusses how structured programming methodology has been introduced into a large production programming organization using an integrated but flexible approach. It next analyzes the advantages and disadvantages of each component of the methodology and presents some quantitative results on its use. It concludes with recommendations based on this generally successful experience, which could be useful to other organizations interested in improving reliability and productivity.	structured programming	F. Terry Baker	1975	IEEE Trans. Software Eng.	10.1109/TSE.1975.6312844	computer science;top-down and bottom-up design;inductive programming;programming language	SE	-50.90152015874931	30.965440186952883	28819
5e31ef410d9413216604749ed0f768234ed21714	segregating feature interfaces to support software product line maintenance	feature dependencies;feature interface;software product lines	Although software product lines are widely used in practice, their maintenance is challenging. Features as units of behaviour can be heavily scattered across the source code of a product line, hindering modular reasoning. To alleviate this problem, feature interfaces aim at enhancing modular reasoning about features. However, considering all members of a feature interface is often cumbersome, especially due to the large number of members arising in practice. To address this problem, we present an approach to group members of a feature interface based on their mutual dependencies. We argue that often only a subset of all interface members is relevant to a maintenance task. Therefore, we propose a graph representation that is able to capture the collaboration between members and apply a clustering algorithm to it to group highly-related members and segregate non-related members. On a set of ten versions of a real-world product line, we evaluate the effectiveness of our approach, by comparing the two types of feature interfaces (segregated vs. original interfaces) with co-change information from the version-control system. We found a potential reduction of 62% of the interface members to be considered during maintenance. This way, the effort to reason about features can be reduced.	algorithm;aspect-oriented programming;busybox;cluster analysis;complexity;control system;emoticon;feature-oriented programming;graph (abstract data type);modular programming;mutual exclusion;personal and ubiquitous computing;preprocessor;reduction (complexity);software bug;software maintenance;software product line;winsock	Bruno Barbieri Pontes Cafeo;Claus Hunsen;Alessandro F. Garcia;Sven Apel;Jaejoon Lee	2016		10.1145/2889443.2889451	computer science;machine learning;data mining;engineering drawing;feature model	SE	-54.19668277183212	31.41064661858738	28827
f9999cc8647aa3a8468722e0bc423f96d4a26fe9	synchronizing cardinality-based feature models and their specializations	developpement logiciel;modelizacion;cardinal number;synchronisation;modelisation;nombre cardinal;numero cardinal;synchronization;desarrollo logicial;software development;software package;architecture basee modele;estructura producto;sincronizacion;progiciel;modeling;structure produit;paquete programa;model driven architecture;product structure;arquitectura basada modelo	A software product line comprises a set of products implementing different configurations of features. The set of valid feature configurations within a product line can be described by a feature model. In some practical situations, a feature configuration needs to be derived in stages by creating a series of successive specializations of the initial feature model. In this paper, we consider the scenario where changes to the feature model due to, for example, the evolution of the product line, need to be propagated to its existing specializations and configurations. After discussing general dimensions of model synchronization, a solution to synchronizing cardinality-based feature models and their specializations and configurations is presented.	feature model;software product line	Chang Hwan Peter Kim;Krzysztof Czarnecki	2005		10.1007/11581741_24	synchronization;computer science;artificial intelligence;mathematics;algorithm;feature model	DB	-40.95699680170956	25.47110491312519	28832
248a2ff6549232b5ac457e11148171eb87a659a9	a controlled experiment for corroborating the usefulness of class diagram metrics at the early phases of oo developments	information system quality;prediction models;empirical validation;class diagram maintainability;. object oriented metrics;fuzzy prototypical knowledge discovery;class diagram structural complexity;knowledge discovery;prediction model;structural complexity;class diagram;life cycle;unified modeling language;information system	The quality of class diagrams is critical because it has a great influence on the quality of the object oriented information system (OOIS) which are finally delivered. This fact motivated us to define a set of measures for evaluating the structural complexity (an internal quality attribute) of class diagrams made using the Unified Modeling Language (UML), which nowadays is the standard language for object oriented modelling. These measures could be used to predict class diagram external quality characteristics, such as maintainability, early in the OOIS life-cycle. In order to corroborate the practical utility of those metrics, we have put them under empirical validation by means of a controlled experiment. The description of each of the steps carried out to perform the experiment and the construction of the prediction model for class diagram maintainability are the main goals of this paper.	class diagram;information system;unified modeling language	Marcela Genero;José Angel Olivas;Mario Piattini;Francisco P. Romero	2001			maintainability;knowledge extraction;information system;communication diagram;unified modeling language;class diagram;object-oriented programming;structural complexity;computer science;systems engineering	DB	-60.33805839176752	29.466833435427922	28847
bcf01316ad3e39c8d931002d8cf0bb37f305ad9b	generating executable multi-agent system prototypes from sonar specifications	organisations;multi agent systems;renew;mulan4sonar;middleware;petri nets;sonar	This contribution presents the Mulan4Sonar middleware and its prototypical implementation for a comprehensive support of organisational teamwork, including aspects like team formation, negotiation, team planning, coordination, and transformation. Organisations are modelled in Sonar, a Petri net-based specification formalism for multiagent organisations. Sonar models are rich and elaborated enough to automatically generate all necessary configuration information for the Mulan4Sonar middleware.	executable;multi-agent system;sonar	Michael Köhler-Bußmeier;Matthias Wester-Ebbinghaus;Daniel Moldt	2010		10.1007/978-3-642-21268-0_2	real-time computing;simulation;systems engineering;engineering	AI	-42.47947288067124	21.294978803918244	28868
68a11e871e2d531f56446c49583d1b1848c066f3	a supportability framework	high availability;quality attributes;electronic mail;software quality software architecture;stakeholder concerns;stakeholder concerns supportability framework quality attributes qa technique productivity goal;computer architecture;software architecture;focal point;software architecture quality attributes stakeholder concerns;organizations;productivity;high throughput;productivity computer architecture usability organizations electronic mail;usability;use case;configuration management;software quality;architectural style	Stakeholder concerns extend beyond end-user functionality and often go beyond error free operation, fast response times, high throughput, high availability and security. A large set of stakeholder concerns relate to the cost of building, owning and managing an IT-system in terms of quality attributes such as the ease of modifiability, configurability, manageability, usability and maximizing the system's ROI. Consequently, the realization of these quality attributes can be verified by how the system is built rather than what goes into the system. Because of this these quality attributes tend to be ambiguously specified and are hard to verify using conventional QA techniques. This paper presents a Supportability Framework that uncovers and links together concerns of 3 major types of stakeholders and transforms these concerns into a set of features and functionality to be realized in the system to be used by these stakeholders. This is accomplished using supportability scenarios, which use quality attributes as focal points with a specific productivity goal such as optimizing resources, time or money. The degree of realization of each of the quality attributes is described in terms of the conceptual tools of architecture such as use-cases, architecture styles and patterns, platform services and allocation views. The resultant architecture description and features produced by the supportability framework makes it simpler to establish the inherent relationship of the productivity concerns of the organization with respect to the system and their eventual architectural realization as a set of quality attributes.	.net framework;4+1 architectural view model;architectural pattern;domain model;entity;extensibility;focal (programming language);formal verification;high availability;hoc (programming language);information model;like button;list of system quality attributes;mda framework;non-functional requirement;region of interest;resultant;software quality assurance;throughput;traceability;usability	Nagaraju Pappu;Satish Sukumar;Feroz Sheikh	2011	2011 Ninth Working IEEE/IFIP Conference on Software Architecture	10.1109/WICSA.2011.26	use case;high-throughput screening;reliability engineering;software architecture;productivity;usability;computer science;systems engineering;organization;engineering;knowledge management;software engineering;configuration management;high availability;software quality	SE	-55.51984342776215	27.12569936583579	28913
4d753a8a576e0c1c1c2707cfec7265b542d6142d	the last byte			byte		2001	IEEE Design & Test of Computers		computer engineering;byte;computer science	Embedded	-56.43035385406413	5.152029656654792	28918
4fc1f0d81cd8046df0e2dd72319b566ea47dcdbd	design decision support for evolvability and variability		Introduction Business critical software systems have to be maintained for a long time in order to conserve their business value and for the constant provision of business services. However, frequent changes due to enhancements, business process optimization, or technological improvements have to be performed. As a consequence, evolvability and variability of software systems constitute important quality goals for business success. Architectural design or redesign and the proper consideration of quality goals is a complex task. Therefore, there is a need for design decision support for these goals. Recent architectural design methods and approaches, for example QASAR, Siemens’ 4 Views, or Attribute Driven Design (ADD), consider quality goals such as flexibility, or changeability. However, regarding evolvability and variability a general methodical support for architectural design decisions is rare. In our approach we provide guidance and a procedure for architectural decision-making regarding evolvability and variability. We explain how we integrate this in the architectural analysis and synthesis phases. With a goal-oriented procedure we decompose the quality goals related to change and reduce the damage to the architecture, the so-called architectural decay, due to a reduced change impact.	architectural decision;business process;decision support system;heart rate variability;mathematical optimization;process optimization;software rot;software system	Matthias Riebisch;Stephan Bode	2010	Softwaretechnik-Trends		software system;architecture;systems engineering;computer science;service (economics);decision support system;business process management;design methods;evolvability;business value	SE	-58.39823292985641	20.918794901280247	28919
9979c0f79e994f40212acbd56b75f22dcbc7fcb8	ontology-based content management in a virtual organization	content management	 this paper we describe an ontology-based content management and retrievalsystem, a kind of Document-based Corporate Memory (see [DCGR99]).This system has been realized in the setting of a virtual organization, a newkind of business partnership at the forefront of ontology-based KnowledgeManagement due to the special needs for organizing corporate knowledge usingflexible, but well-understood and machine processable structures 	data model;design of experiments;experiment;fits;knowledge management;knowledge-based systems;lightweight ontology;ontology (information science);ontology learning;prospective search;scalability;semantic web;semiconductor industry;server (computing);virtual organization	Peter Mika;Victor Iosif;York Sure-Vetter;Hans Akkermans	2004			content management;computer science;knowledge management;multimedia;world wide web	DB	-48.00067685554715	8.536192811096356	28982
797e5a267a5e5e36280b81dbc8fef1ca361887da	measuring reuse in hazard analysis	argument structure;seguridad funcionamiento;surete fonctionnement;analisis sistema;sistema critica;tool support;time measurement;analisis estructural;reutilizacion;chronometrie;systeme critique;edit distance;riesgo accidente;reuse;risque accidentel;systeme a securite critique;critical system;cronometria;dependability;safety critical system;system analysis;analyse systeme;analyse structurale;structural analysis;safety arguments;hazard;hazard analysis;reutilisation	Hazard analysis for safety-critical systems require sufficient coverage and rigour to instill confidence that the majority of hazardous consequences have been identified. These requirements are commonly met through the use of exhaustive hazard analysis techniques. However such techniques are time consuming and error-prone. As an attempt at exhaustive coverage, hazard analysts typically employ reuse mechanisms such as copy-and-paste. Unfortunately if reuse is applied inappropriately there is a risk that the reuse is at the cost of rigour in the analysis. This potential risk to the validity of the analysis is dependent on the nature and amount of reuse applied. This paper investigates hazard analysis reuse over two case studies. Initially reuse in an existing safety argument is described. Argument structures within the hazard analysis are identified and the amount of verbatim reuse examined. A second study is concerned with how reuse changes as a result of tool support. In contrast to the first case, the defined arguments are more diverse reuse has occurred but is less verbatim in nature. Although tool support has aided the customisation of the reused arguments, many are only trivially customised. An edit distance algorithm is utilised to identify and enumerate verbatim and trivial reuse in the arguments.	algorithm;code reuse;cognitive dimensions of notations;cut, copy, and paste;dependability;display resolution;edit distance;enumerated type;hazard analysis;overhead (computing);personalization;prototype;requirement	Shamus P. Smith;Michael D. Harrison	2005	Rel. Eng. & Sys. Safety	10.1016/j.ress.2004.08.010	reliability engineering;edit distance;hazard;engineering;hazard analysis;dependability;reuse;structural analysis;system analysis;operations research;algorithm;time	SE	-59.731082445890934	31.091861908177968	29067
2cbcab0e87c18ac82ecb44d4c47ef36f22b43218	shared computer-aided structural design model for construction industry (infrastructure)	construction process;international alliance for interoperability;building block;model infrastructure;construction industry;product model;technology transfer;standard model;product model standard;industry foundation classes;interoperability;data handling;structural design	The current interaction between participants in a construction project requires much time and is often a cause of mistakes and misunderstandings. Improvement of this interaction may therefore contribute to an improvement of the construction process as a whole. The lack of interoperability is the main problem behind such interaction drawbacks. In this paper, an infrastructure for a technology transfer model, namely Shared Computer-Aided Structural Design (sCAsD) model, is developed. It is built upon three basic building blocks: the Standard for the Exchange of Product Model Data (STEP, ISO-10303) Parts 104 and 107, the CIMsteel Integration Standard (CIS/2.0) resources, and the Industry Foundation Classes (IFC) standard that is being developed by the International Alliance for Interoperability (IAI). The sCAsD model is an extension for the structural domain/view of the IFC model, providing professional standardization within the synergy effect of the IFC. The model infrastructure is explained and discussed in terms of model schemata. In addition, model feasibility is studied within two assessments for model schemata and model realization in the construction industry. The former assessment has verified the robustness and effectiveness of the model through using a model interface in data handling within an application of an integrated earthquake simulation. Meanwhile, the assessment of model realization has validated the roadmap of model implementation in the construction industry through IAI. The model has been accepted as a formal IAI project, namely ST-7, and is being supported by IAI Japan chapter.		M. Hassanien Serror;Junya Inoue;Yoshinobu Adachi;Yozo Fujino	2008	Computer-Aided Design	10.1016/j.cad.2007.07.003	standard model;interoperability;computer science;systems engineering;engineering;knowledge management;group method of data handling;mechanical engineering	EDA	-62.213170850253626	16.012175533532925	29085
8ec7bb70ff62543058dc07079a9f746ad143dd5b	perspective oriented business process visualization	business process model;business process;meta model	Visualizing business process models in various ways supports modelers in creation and users in understanding. Therefore we present a flexible and extensible meta model based approach to enhance business process models by multiple visualizations. These visualizations are geared to the so called perspectives of a business process model and emphasize different aspects of a business process model.	business process;diagram;extensibility;graphical user interface;meta element;metamodeling;microsoft outlook for mac;process modeling;requirement	Stefan Jablonski;Manuel Götz	2007		10.1007/978-3-540-78238-4_16	metamodeling;business domain;computer science;systems engineering;knowledge management;artifact-centric business process model;business process management;function model;process modeling;management science;business process model and notation;process management;business process;event-driven process chain;process mining;business process discovery;management;business rule;business process modeling;business activity monitoring;business architecture	HCI	-56.15262892361698	17.297317862906365	29090
08ed31f28e6c381ce5023d007ccd9963ab87f4d0	advancing candidate link generation for requirements tracing: the study of methods	independent validation analysis dynamic candidate link generation retro tool requirements tracing on target tool independent verification analysis;lsi;formal specification;independent validation and verification iv v;selected works;requirements tracing;information retrieval;verification and validation v v;indexing terms;satisfiability;dynamic linking;tf idf;precision requirements tracing dynamic link generation verification and validation v v independent validation and verification iv v information retrieval tf idf lsi recall;formal verification;precision;dynamic link generation;recall;bepress;software tools;risk analysis system testing spine computer society feedback prototypes information retrieval large scale integration computer aided software engineering;verification and validation;software tools formal verification formal specification;validation and verification	This paper addresses the issues related to improving the overall quality of the dynamic candidate link generation for the requirements tracing process for verification and validation and independent verification and validation analysts. The contribution of the paper is four-fold: we define goals for a tracing tool based on analyst responsibilities in the tracing process, we introduce several new measures for validating that the goals have been satisfied, we implement analyst feedback in the tracing process, and we present a prototype tool that we built, RETRO (REquirements TRacing On-target), to address these goals. We also present the results of a study used to assess RETRO's support of goals and goal elements that can be measured objectively.	chi;endurability;information retrieval;integrated circuit;prototype;requirement;scalability;verification and validation;vii	Jane Huffman Hayes;Alex Dekhtyar;Senthil Karthikeyan Sundaram	2006	IEEE Transactions on Software Engineering	10.1109/TSE.2006.3	requirements management;verification and validation;computer science;data mining;database;programming language;engineering drawing	SE	-58.12401670959628	31.95770948161607	29114
1951fc05caf6c2f51dfccb7316745ea374c5db0a	controller patterns for component-based reactive control software systems	coordination patterns;composite connectors;software systems;computation and coordination separation;reactive control;good practice;reactive control software;component model;component based software development;software design	It is considered good practice in control software design to distinguish computation and coordination on the architectural level. Current component models largely fail to provide distinct abstractions for that purpose. In this paper, we introduce such distinct abstractions. In particular, we introduce controller patterns, an abstraction for defining coordination in the context of component-based software development. We present their definition and demonstrate their usage in a case study, conducted in our prototype tool.	component-based software engineering;computation;content-control software;prototype;software design;software development;software system	Petr Stepan;Kung-Kiu Lau	2012		10.1145/2304736.2304749	reliability engineering;software visualization;real-time computing;software sizing;architectural pattern;computer science;systems engineering;software design;software framework;component-based software engineering;software development;software design description;software engineering;software construction;component object model;programming language;resource-oriented architecture;presentation–abstraction–control;goal-driven software development process;software development process;software system	SE	-53.99980217747453	28.419290784030974	29131
f9dd9a92e1eaf3b98170f50910cae8b7d7a3c25b	coordination and collective mind in software requirements development	systeme temps reel;metodo coordinacion;outil logiciel;sistema operativo;software tool;productivite;methode coordination;analisis datos;concepcion sistema;implementation;specification;productividad;systeme conversationnel;ejecucion;software requirements;data analysis;operating system;especificacion;interactive system;herramienta controlada por logicial;system design;sistema conversacional;analyse donnee;systeme exploitation;coordination method;real time system;sistema tiempo real;productivity;conception systeme;ibm	The purpose of this study was to understand how the group processes of teams of software requirements analysts led to problems and to suggest possible solutions. Requirements definition is important to establish the framework for a development project. Researchers have proposed numerous requirements development techniques, but less has been done on managing teams of requirements analysts. To learn more about group processes within such teams, we studied two teams of analysts developing requirements for large, complex real-time systems. These teams had problems ensuring that requirements documents were complete, consistent, and correct; fixing those problems required additional time and effort. To identify sources of problems, we applied two theories of collective action, coordination theory and collective mind theory. Coordination theory suggests that a key problem in requirement analysis is identifying and managing dependencies between requirements and among tasks. Most requirements methods and tools reflect this perspective, focusing on better representation and communication of requirements. The collective mind perspective complements these suggestions by explaining how individuals come to understand how their work contributes to the work of the group. This perspective suggests that deficiencies in actors' representations of the process and subordination to collective goals limit the value of their contributions.	requirement;software requirements	Kevin Crowston;Ericka Eve Kammerer	1998	IBM Systems Journal	10.1147/sj.372.0227	requirements analysis;requirements management;productivity;simulation;real-time operating system;business requirements;computer science;systems engineering;engineering;requirement;operating system;data analysis;implementation;specification;software requirements;ibm;systems design	SE	-38.30537322347231	23.116123865634908	29183
4ffffbafeab6a207da96c2c69f9c605a5088e887	development of agent-driven systems: from i* architectural models to intentional agents code		The intentionality concept can improve the cognitive capacity of software agents, especially if the proposed intentional reasoning engine deals with softgoals at runtime. In this scenario, the use of an intentionality-based technological set to develop agent-driven systems from i* models to code is adequate. In this paper, we propose heuristics to improve the development of agent-driven systems from i* models to Belief-Desire-Intention-based code. Moreover, we apply a fuzzy-logic-based mechanism to deal with softgoals “on the fly”, improving the reasoning engine of intentional agents. We compare our efforts with related work and illustrate our contributions with a case study.	fuzzy logic;heuristic (computer science);intentionality;on the fly;run time (program lifecycle phase);semantic reasoner;software agent	Maurício Serrano;Julio Cesar Sampaio do Prado Leite	2011				AI	-40.90887792172048	21.50862930097894	29234
8dd5d1c8f8323633143174bb77559295ec2ca322	driver duty: a pattern for public transport systems	real time control;public transport;scheduling	In this paper, the authors present a type of pattern language that is known as Transport Object Patterns (TOPS) and which is applicable to scheduling processes in a public transit setting. They describe the TOP-Driver Duty, a pattern that provides a framework within which driver duty components can be assembled. The Driver Duty pattern supports a tree structure for ordering and layering driver duty components, provides an interface to all components, and copes with variations in defining driver duties.		Liping Zhao;Ted Foster	1998	JOOP		real-time computing;simulation;real-time control system;computer science;public transport;scheduling	ML	-38.604532989942726	31.718031904806598	29244
f96e9c5f32159196bf8cc04ca5d1f0f25d17de01	goal-oriented data warehouse quality measurement	goal orientation;goal oriented requirements engineering;cs se;requirement analysis;modelling framework;uml profile;requirement engineering;data warehousing;quality measures;data warehouse	Requirements engineering is known to be a key factor for the success of software projects. Inside this discipline, goal-oriented requirements engineering approaches have shown specially suitable to deal with projects where it is necessary to capture the alignment between system requirements and stakeholders’ needs, as is the case of datawarehousing projects. However, the mere alignment of data-warehouse system requirements with business goals is not enough to assure better data-warehousing products; measures and techniques are also needed to assure the data-warehouse quality. In this paper, we provide a modelling framework for data-warehouse quality measurement (i∗DWQM). This framework, conceived as an i∗ extension, provides support for the definition of data-warehouse requirements analysis models that include quantifiable quality scenarios, defined in terms of well-formed measures. This extension has been defined by means of a UML profiling architecture. The resulting framework has been implemented in the Eclipse development platform.	eclipse;requirement;requirements analysis;requirements engineering;system requirements;unified modeling language;well-formed formula	Cristina Cachero;Jesús Pardillo	2009	CoRR		reliability engineering;requirements analysis;goal modeling;computer science;systems engineering;engineering;requirement;software engineering;data warehouse;requirements elicitation;goal orientation;data mining;requirements engineering;management;functional requirement;non-functional requirement	SE	-57.04239025897266	20.671598612565045	29290
7343f5ff43c6916a676761cf9474815f3da6ead9	analysis of iso 6983 nc data based on iso 14649 cnc data model	cam software iso 6983 nc data model iso 14649 cnc data model technical information cnc control language;sice iccas 2006;machining;analysis of iso 6983 nc data based on iso 14649 cnc data model;iso standards;robotics and systems;data model;production engineering computing;institute of control;iso 14649 data analysis technical information machining feature nc data workingstep;data analysis;hiroshi yamada;computerised numerical control;production engineering computing computer aided manufacturing computerised numerical control data models iso standards machining process planning;computer aided manufacturing;제어로봇시스템학회;next generation;masahiko onosato;iso standards computer numerical control data models machining data analysis information analysis computer aided manufacturing cadcam software testing system testing;process planning;fumiki tanaka;data models	Retaining technical information is an important element for performing high quality machining. However, actual NC data (ISO 6983) contain implicit technical information which reflects the skilled worker's knowledge. In this research, to obtain technical information, NC data are analyzed based on a next-generation CNC control language (ISO 14649) which contains technical information explicitly. In this paper, we demonstrate how ISO 6983 NC data generated by CAM software are applied to the test implemented system, and how valid technical information is obtained	data model;display resolution	Hiroshi Y Yamada;Fumiki Tanaka;Masahiko Onosato	2006	2006 SICE-ICASE International Joint Conference	10.1007/0-387-34403-9_13	computer science;operations management;engineering drawing;manufacturing engineering	HPC	-58.12074671038078	9.730761121488957	29419
4b28950e6a1f0185a97e5a576bf226e06c5c5c30	design management using dynamically defined flows	databases;design automation;design management;history;design engineering;design flow;process design;tree graphs;organizing;engineering management;computer science;design automation history process design databases computer science design engineering engineering management organizing tree graphs content addressable storage;content addressable storage	"""Many CAD frameworks now use the notion of a design flow to help provide methodology management services. Most flow-based approaches are limited, however, in that they involve a fixed sequence of operations specified in advance, restrict designers to using only those flows, and """"hardwire"""" specific tools to flows. To overcome this, we introduce the concept of """"dynamically defined flows"""" as tool-independent flows that are built up, on demand, by designers. Dynamically defined flows can be used to provide a semantically rich means for browsing the design history database as well as to provide support for multiple design approaches, such as goal-based, tool-based, data-based and plan-based design."""	computer-aided design;control unit;design flow (eda)	Peter R. Sutton;Jay B. Brockman;Stephen W. Director	1993	30th ACM/IEEE Design Automation Conference	10.1145/157485.165080	process design;electronic design automation;computer science;systems engineering;design flow;computer-automated design;theoretical computer science;environmental graphic design;database;design education;design management;design technology;tree	EDA	-45.96291898290885	21.852131167684515	29475
6e731878bf9549ddde9ac4a98aac3eb2de62ecea	dealing with traceability in the mddof model transformations	software;proposals object oriented modeling software dsl complexity theory data models software engineering;complexity theory;dsl;software engineering;source code software research and development software engineering;model transformations;model driven engineering;systematic research methodology mdd traceability software engineering model driven engineering project model transformation languages metagem trace trace generation lower level transformation models dsl source code emf based toolkit atl model transformations etl model transformations;traceability;proposals;object oriented modeling;data models	Traceability has always been acknowledged as a relevant topic in Software Engineering. However, keeping track of the relationships between the different assets involved in a development process is a complex and tedious task. The fact that the main assets handled in any model-driven engineering project are models and model transformations eases the task. In order to take advantage of this scenario, which has not been appropriately capitalized on by the most widely adopted model transformation languages before, this work presents MeTAGeM-Trace, a methodological and technical proposal with which to support the model-driven development of model transformations that include trace generation. The underlying idea is to start from a high-level specification of the transformation which is subsequently refined into lower-level transformation models in terms of a set of DSLs until the source code that implements the transformation can be generated. Running this transformation produces not only the corresponding target models, but also a trace model between the elements of the source and target models. As part of the proposal, an EMF-based toolkit has been developed to support the development of ATL and ETL model transformations. This toolkit has been empirically validated by conducting a set of case studies following a systematic research methodology.	eclipse modeling framework;high- and low-level;model transformation;model-driven architecture;model-driven engineering;norm (social);software engineering;trace (psycholinguistics);traceability;transformation language	Juan M. Vara;Verónica Andrea Bollati;Álvaro Jiménez;Esperanza Marcos	2014	IEEE Transactions on Software Engineering	10.1109/TSE.2014.2316132	data modeling;model-driven architecture;traceability;verification and validation;digital subscriber line;computer science;systems engineering;social software engineering;software development;software engineering;programming language	SE	-53.663238482211824	24.923379898565763	29476
4d2d783f48c49f7a5d054bf9d22e250dd3b710d8	validation of ultrahigh dependability for software-based systems	fiabilidad;reliability;tecnologia electronica telecomunicaciones;computacion informatica;failure;good engineering practice;validacion;approche bayesienne;specification;methode formelle;grupo de excelencia;dependence;dependance;ingenieria logiciel;satisfiability;software engineering;fracaso;preuve;especificacion;ciencias basicas y experimentales;fiabilite;ultrahigh dependability;safety critical system;genie logiciel;risk assessment;validation;tecnologias;safety critical systems;growth model;dependencia;echec;qa76 computer software	Modern society depends on computers for a number of critical tasks in which failure can have very high costs. As a consequence, high levels of dependability (reliability, safety, etc.) are required from such computers, including their software. Whenever a quantitative approach to risk is adopted, these requirements must be stated in quantitative terms, and a rigorous demonstration of their being attained is necessary. For software used in the most critical roles, such demonstrations are not usually supplied. The fact is that the dependability requirements often lie near the limit of the current state of the art, or beyond, in terms not only of the ability to satisfy them, but also, and more often, of the ability to demonstrate that they are satisfied in the individual operational products (validation). We discuss reasons why such demonstrations cannot usually be provided with the means available: reliability growth models, testing with stable reliability, structural dependability modelling, as well as more informal arguments based on good engineering practice. We state some rigorous arguments about the limits of what can be validated with each of such means. Combining evidence from these different sources would seem to raise the levels that can be validated; yet this improvement is not such as to solve the problem. It appears that engineering practice must take into account the fact that no solution exists, at present, for the validation of ultra-high dependability in systems relying on complex software. ACM Copyright Notice Copyright © 1993 by the Association for Computing Machinery, Inc. Permission to make digital or hard copies of part or all of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, to republish, to post on servers, or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from Publications Dept, ACM Inc., fax +1 (212) 869-0481, or permissions@acm.org. Littlewood-Strigini: Validation of Ultra-High Dependability for Software-based Systems	computer;dependability;fax;like button;requirement	Bev Littlewood;Lorenzo Strigini	1993	Commun. ACM	10.1145/163359.163373	risk assessment;simulation;operating system;reliability;life-critical system;computer security;specification;statistics;satisfiability	SE	-61.73957818581696	31.22961775568101	29507
afc16c85f3114c9b5896924ee1a735d66fabea68	a simulation-based software system for evaluating hub-and-spoke transportation networks	information management system;transportation networks;software systems;transport system;user support;technology transfer;simulation modelling;knowledge base	Abstract   We present a simulation-based software system for evaluating Hub-and-Spoke transportation networks. A complete description of the software system, known as HUBNET, is presented. Major topics of discussion include the motivating problem environment of truckload trucking, the overall simulation solution architecture, and the primary components of the HUBNET system. The simulation driver, written in the SIMNET II language, is described in detail. Also discussed are the information management systems designed to create appropriate supporting information to drive the simulator and to integrate the software system with befitting data, and the user support facilities designed to enhance usability and to isolate the user of the system from detailed simulation coding tasks. Concluding remarks include a discussion of technology transfer and field use, and a discussion of ongoing and future research with the HUBNET simulator.	simulation;software system	Tarek Taha;G. Don Taylor;Hamdy A. Taha	1996	Simul. Pr. Theory	10.1016/0928-4869(95)00016-X	knowledge base;simulation;human–computer interaction;computer science;systems engineering;engineering;artificial intelligence;operating system;software system	Logic	-55.551146829354	8.783167595512394	29518
a6818b6ce83d40fba5099ac0f3f1fa73a7165e7f	converting legacy code into ada: a cognitive approach	software tools costs programming profession intelligent systems pressing decision making software engineering fasteners information analysis scattering;ada;software tools ada visual programming software engineering;software engineering;visual programming;visual representation;system design;software tools;integrated reengineering workbench legacy code ada code conversion system design software reengineering cognitive approach visual representation	Describes a code conversion tool that helps programmers visualize and understand system design. The author first reviews current software reengineering tools and then describe a new cognitive approach to system (re)engineering based on code comprehension tools that provide a visual representation of code containing less cognitive noise. This better enables programmers to understand system design. The approach integrates code comprehension tools with current reengineering methodologies to create an integrated reengineering workbench for converting legacy code into newer languages such as Ada or C/C++.<<ETX>>	ada;code refactoring;fax;fortran;interoperability;legacy code;mission critical;programmer;systems design;workbench	Joseph M. Scandura	1994	Computer	10.1109/2.275004	kpi-driven code analysis;ada;code review;computer science;software framework;software development;software engineering;software construction;computer programming;real-time control system software;visual programming language;programming language;computer-aided software engineering;software archaeology;static program analysis;source code;systems design	SE	-50.857717404680024	30.594460186259425	29526
bc0340ab52eb6141eb0b961f9c9b8f990d9e51ae	architecture and algorithms for a distributed reputation system	distributed system;agent interaction;multiagent system;confiance;systeme reparti;psychologie sociale;image processing;social interaction;interaction sociale;speech processing;tratamiento palabra;procesamiento imagen;traitement parole;traitement image;reputation system;confidence;sistema repartido;interaccion social;confianza;algorithme reparti;psicologia social;pattern recognition;algoritmo repartido;social psychology;reconnaissance forme;reconocimiento patron;sistema multiagente;distributed algorithm;systeme multiagent;business relationship	Trust is an essential component of successful interactions in social life as well as in business relationships. In this paper we propose a system that closely reflects real-world trust building in an online environment. We describe the models used to represent trust in entities in various categories, algorithms to calculate and update trust based on experiences of entities with each other and the agent interactions necessary for finding and exchanging trust information.	algorithm;automatic control;chain of trust;entity;identity management;interaction;prototype;reputation system;soundness (interactive proof)	Michael Kinateder;Kurt Rothermel	2003		10.1007/3-540-44875-6_1	web of trust;distributed algorithm;image processing;trust anchor;computer science;artificial intelligence;speech processing;confidence;business relationship management;computational trust	AI	-37.86786968128951	16.796389369758195	29601
e0caad9026c37e018e86df4f27e402248311df58	cad to support cim applications (invited paper)			computer-aided design;computer-integrated manufacturing	Chengi Kuo	1986			software engineering;cad;computer science	EDA	-56.984367589504465	5.943227160569564	29617
b54b830936809f93224574ee07559be04ea8b1a9	graph-based specification and verification for aspect-oriented languages	labelled transition system;component based systems;aspect oriented software development;rule based system;separation of concern;operational semantics;software systems;individual object;graph transformation;featherweight java;specification and verification;object oriented;aspect oriented programming;state space;software development life cycle;aspect oriented	Aspect-oriented software development aims at improving separation of concerns at all levels in the software development life-cycle, from architecture to code implementation. In particular, aspect-oriented programming addresses separation of concerns at the implementation level, by allowing the modular expression of crosscutting concerns. In this thesis we strive to develop verification methods specifically for aspectoriented languages. For this purpose, we model the behaviour of these languages through an operational semantics. We use graph transformations to specify these semantics. Graph transformation has mathematical foundation, and provides an intuitive way to describe component-based systems, such as software systems. In addition, graph transformations have an executable nature, and can be used to generate the execution state space of programs. We use these state spaces for the verification of programs with aspects. We start by defining an improvement of specification by rule-based systems. Pure rule-based systems typically consist of a single, unstructured set of rules. The behaviour of such systems is that all rules are applicable in every state. Rules can then only be forced into a certain order of application by adding special elements to the states, which are tested for within the rules. In other words, control over rule applicability is not explicit but has to be encoded in the state, which reduces understandability and maintainability of the rule-based system as a whole. We propose so-called control automata, which can be added on top of pure rule-based systems. The resulting behaviour is defined as the product of the original state space and the control automaton. Our control automata include so-called failure transitions, representing the observation of the non-applicability of one or more rules. The result is a reactive semantics for control expressions, which is distinct from the usual input-output semantics. Control automata may introduce artificial non-determinism into the behaviour, which is an undesirable effect. We introduce guarded control automata to get rid of this effect, and we define a semantics-	aspect-oriented programming;aspect-oriented software development;automaton;component-based software engineering;conditional (computer programming);control theory;cross-cutting concern;denotational semantics;executable;graph rewriting;logic programming;operational semantics;rule-based system;separation of concerns;software development process;software system;state space	Tom Staijen	2010			rule-based system;aspect-oriented programming;computer science;theoretical computer science;runtime verification;programming language;well-founded semantics;operational semantics;denotational semantics;algorithm	SE	-41.89362939815955	29.200172959096186	29621
a2794c86cd9e3407d7f1ee18e85b7e743d7ec5d6	compatibility test for coordination aspects of software components	formal specification;service provider;object oriented programming;temporal operators third party software components customer individual application systems business related aspects automated compatibility tests component service specification multilayered specification framework object constraint language ocl;object oriented programming program testing formal specification object oriented languages;program testing;information management;software component;software testing automatic testing application software australia system testing software standards information technology business communication informatics systems engineering and theory;object oriented languages;object constraint language	Combining third party software components to customer-individual application systems requires first, standardized specification techniques for describing the technical as well as the business-related aspects of the services provided and required by the corresponding software components and second, automated compatibility tests in order to identify components fulfilling demands specified by component requestors. Adequate techniques for the specification of component services are consolidated in a multilayered specification framework, where formal notations are preferred in order to enable the execution of automated compatibility tests. These tests are a prerequisite for the existence of component markets where third party software components are traded and components that fulfil the specified demands are identified. This paper presents an algorithm for the layer of the specification framework where coordination aspects of a software component are described. On this layer an extension of the object constraint language (OCL) by temporal operators is used to specify the succession relationships between the services of related software components. Thereby the connections to other layers are tagged and existing tests are integrated.	algorithm;component-based software engineering;experience;license compatibility;microsoft outlook for mac;object constraint language;succession;third-party software component;turing completeness	Johannes Maria Zaha;Antonia Albani	2006	Australian Software Engineering Conference (ASWEC'06)	10.1109/ASWEC.2006.22	connascence;software requirements specification;verification and validation;formal methods;software sizing;computer science;systems engineering;software design;software framework;component-based software engineering;software development;software engineering;software construction;formal specification;database;software testing;information management;programming language;object-oriented programming;resource-oriented architecture;artificial intelligence systems integration;language of temporal ordering specification;software system	SE	-52.99199762965808	27.65591061357018	29651
e7510b155811e422f485864285a8112e3ba0aee6	extending an abstract reference model for transdisciplinary work in cultural heritage	cultural heritage;comunicacion de congreso;transdisciplinarity;charm;conceptual modelling;conml;abstract reference model	Obtaining models of cultural heritage that guarantee information interoperability and, at the same time, maintain a high degree of fitness to the problem at hand is not a trivial quest. This paper proposes a two-step approach to attain this, where particular models for each problem at hand are derived from a common, standardised Cultural Heritage Abstract Reference Model (CHARM) by using specific rules that guarantee abstract interoperability while allowing for as much specificity as necessary. This is illustrated through a case study involving three different communities, each with a different conceptual model of cultural heritage, which still generate a seamless object model.	reference model	Cesar Gonzalez-Perez;Patricia Martin-Rodilla;César Parcero-Oubiña;Pastor Fábrega-Álvarez;Alejandro Güimil-Fariña	2012		10.1007/978-3-642-35233-1_20	cultural heritage	Crypto	-45.167451644180865	6.9204482919468715	29699
b91124819c4bb23cce63a979dc598ad512521f56	information brokers: sharing knowledge in a heterogeneous distributed system	database system;distributed information system;shared knowledge;heterogeneous distributed system;indexation;property a;information service	A large percentage of valuable electronic information is not stored in conventional database systems. Very often, applications have to deal with heterogeneous services such as electronic libraries, airline reservation systems or weather information services. Many times, finding these services and information can be an overwhelming task. In this paper, we describe a tool to facilitate the finding of such information. The cornerstone of the service is the idea of a broker. A broker indexes services and objects by their describing properties. A query to a broker returns enough information to contact the service and get the object or information needed. The type and amount of information indexed by the broker depends on the information that is known and available about the service or object. We present a simple but powerful design for the broker that is flexible enough to accommodate a wide variety of information providers. We also present a complete architecture for our distributed information system.	distributed computing	Daniel Barbará;Chris Clifton	1993		10.1007/3-540-57234-1_7	distributed algorithm;global information system;computer science;knowledge management;data mining;database;replication	ML	-36.71725966942403	14.700634413328736	29707
4c4874ab531d2018de220eb3914dee879a09b70e	data warehouse design from xml sources	data mart;e commerce;data warehousing and the web;data warehouse design;data format;expressive power;conceptual schema;semi structured data;decision making process;information exchange;data warehousing;xml	A large amount of data needed in decision-making processes is stored in the XML data format, which is widely used for e-commerce and Internet-based information exchange. Thus, as more organizations view the web as an integral part of their communication and business, the importance of integrating XML data in data warehousing environments is becoming increasingly high. In this paper we show how the design of a data mart can be carried out starting directly from an XML source. Two main issues arise: on the one hand, since XML models semi-structured data, not all the information needed for design can be safely derived; on the other, different approaches for representing relationships in XML DTDs and Schemas are possible, each with different expressive power. After discussing these issues, we propose a semi-automatic approach for building the conceptual schema for a data mart starting from the XML sources.	conceptual schema;data mart;database schema;e-commerce;floor and ceiling functions;information exchange;requirement;semi-structured data;semiconductor industry;user requirements document;xml namespace	Matteo Golfarelli;Stefano Rizzi;Boris Vrdoljak	2001		10.1145/512236.512242	e-commerce;data exchange;xml validation;decision-making;semi-structured data;xml;information exchange;xml schema;data transformation;streaming xml;computer science;conceptual schema;document structure description;data warehouse;xml framework;soap;data mining;xml database;xml schema;database;xml signature;world wide web;xml schema editor;cxml;expressive power;efficient xml interchange	DB	-34.82783808303166	10.35410288895216	29729
5679734d174c1ec7bd89fa66db03462c84c60186	modeling and simulation with insight	modeling and simulation;technical report;simulation model;problem solving	The INSIGHT simulation language describes systems in a quick, simple, and compact fashion using a network representation. This description can be entered and simulated using novel interactive facilities that relieve the user of needing to know specific syntax, while promoting a greater understanding of model behavior. Statistics summarizing the simulation are produced automatically, but can be greatly enhanced by various input models and output analysis mechanisms. Use of the language does not require programming and complex models use the descriptive features of simple ones, incorporating more elaborate specifications and more sophisticated concepts. INSIGHT is available for most computers and is portable across machines. The language has been extensively applied and its scope of applications has ranged from manufacturing to service environments. Using INSIGHT the process of simulation modeling and the results from the simulations combine to provide “insight” into problem solving.	canonical account;chao (sonic);emulator;fortran;industrial engineering;interactivity;internet explorer;mainframe computer;operating system;problem solving;requirement;simulation language;world sudoku championship	Stephen D. Roberts	1986		10.1145/318242.318272	simulation;computer science;engineering;artificial intelligence;technical report;simulation modeling;modeling and simulation;world wide web	HPC	-35.22042803261501	26.343910982344312	29735
84fd2dcddf57270cb9756ee95164bcb147cc92bc	workflow description of digital rights management systems	modelizacion;distributed system;controle acces;groupware;ontologie;architecture systeme;systeme reparti;langage modelisation;traitement flux donnee;intellectual property;data description;musica;piratage;flot donnee;service web;flujo datos;web service;piracy;modelisation;software architecture;musique;sistema repartido;internet;senal video;signal video;modelling language;lenguaje modelizacion;data privacy;data flow processing;propiedad intelectual;video signal;workflow;ontologia;arquitectura sistema;access control;ontology web language;data flow;system architecture;pirateria;collecticiel;modeling;propriete intellectuelle;music;confidentialite donnee;ontology;digital right management;architecture logiciel;description donnee;servicio web	Digital Rights Management (DRM) is becoming a key issue in our highly networked world. Piracy of digital goods of any kind (music, software, video) is growing day by day. In this scenario, many companies, organisations and administration-funded projects provide solutions for the implementation of digital rights management (DRM) systems. Nevertheless, although these solutions have several points in common, they are incompatible in terms of architecture and system components. This paper analyses some of these solutions, focusing on the description of their data flow, one area where common points can be found. We propose the use of workflow modelling in order to find commonalities among data flow of DRM systems, that would allow easier implementation of new ones. The selected language for performing this modelling is OWL-S (Ontology Web Language for Services). The use of an ontology language will allow us to combine workflow modelling with ontologies defining DRM concepts.	dataflow;digital rights management;mpeg-21;management system;owl-s;ontology (information science);process modeling;web language;web ontology language;world wide web	Silvia Llorente;Eva Rodríguez;Jaime Delgado	2004		10.1007/978-3-540-30470-8_71	web service;workflow;software architecture;simulation;computer science;artificial intelligence;access control;operating system;ontology;music;database;distributed computing;world wide web;computer security;intellectual property	AI	-41.26233905452303	24.28532958905854	29778
15d03e49d0b4e1249781f4d211acdc3f2a45a2d4	cognitive perception in rafale-sp methodology	ploom unity specification;multiagent system;formal specification;mobile perception description;multi agent system;computational modeling multiagent systems software tools cities and towns analytical models software design unified modeling language context modeling application software design methodology;uml;mobile agents;virtual representation;multi agent systems;conceptual representation;unified modeling language;cognitive perception;unified modeling language formal specification mobile agents mobile computing multi agent systems;mobile computing;rafale sp methodology;mobility oriented methodology;mobile perception description cognitive perception rafale sp methodology multiagent system mobility oriented methodology virtual representation conceptual representation mobility simulator uml ploom unity specification;mobility simulator	Several methodologies based on multi-agent systems (MAS) already exist. They help designers to describe software or to create MAS which aim at solving complex problems by simulations. Due to used formalisms, a methodology may be more or less generic. In this context, we have created a mobility oriented methodology called RAFALE-SP based on multi-agent systems. It helps us to describe mobiles which move on a space. This environment can be a virtual representation of a real space like a town where unpredictable events arise. We apply our methodology to solve problems which come from different research areas. We use it to find answers to geographical problems. The presented methodology begins by a conceptual representation of each mobile type and finishes by a mobility simulator. It uses several formalisms: UML and Ploom-unity. They allow us to define mobiles, their interactions and their environment. According to their knowledge, their behaviour rules, mobiles moves on a space by following few motion types. They get an individual perception of the world. In this paper we focus on mobile perception description	interaction;multi-agent system;simulation;unity	Nicolas Marilleau;Christophe Lang;Pascal Chatonnay;Laurent Philippe	2005	International Conference on Computational Intelligence for Modelling, Control and Automation and International Conference on Intelligent Agents, Web Technologies and Internet Commerce (CIMCA-IAWTIC'06)	10.1109/CIMCA.2005.1631533	unified modeling language;simulation;computer science;artificial intelligence;theoretical computer science;multi-agent system	Robotics	-43.40426838985146	27.311526575121086	29804
162cc871fc4e891a80824a855dd8fbeaeef79d49	scpm: facilitating process-centric deployment in enterprise system implementation	analytical models;software;business modeling;scpm;system configuration;it execution;soa;service oriented architecture supply chain management process design acceleration application software companies business communication laboratories semiconductor optical amplifiers software tools;supply chains;supply chain process molder;business process transformation;business model;software architecture;process centric deployment;business data processing;business;business process management;cross platform integration technology;optimization;enterprise system;service oriented architecture supply chain process molder process centric deployment business process transformation process centric methodology cross platform integration technology business modeling business process management enterprise system configuration tool it execution;organizations;process deployment;service oriented architecture;supply chain management business data processing organisational aspects software architecture;supply chain management;business process;enterprise system configuration tool;process centric methodology;organisational aspects;soa process deployment enterprise system scpm	Nowadays lots of organizations rely on enterprise systems to gain efficient and effective business operation. However, enterprise system implementation is a complex endeavor of business process transformation. In the journey, multifarious procedures are carried out while raising a lot of fatal problems. In this paper, based on process-centric methodology and cross-platform integration technology, we developed an integrated platform SCPM to facilitate the whole life of business process transformation. SCPM possesses rich functionalities in business modeling and analysis. Besides, it facilitates to deploy business processes for enterprise system implementation through integrating BPM tool with enterprise system configuration tool. SCPM closes the gap between business process, system configuration and IT execution. And the cross-platform structure makes SCPM to be a milestone on the way of SOA.	business process;cornelis h. a. koster;emerald;enterprise system;framing (social sciences);harris affine region detector;informatics;logistics;service-oriented architecture;simulation;software deployment;springer (tank);susan landau;system configuration	Qinhua Wang;Changrui Ren;Bing Shao;Jin Dong;Hongwei Ding;Wei Wang	2008	2008 IEEE International Conference on e-Business Engineering	10.1109/ICEBE.2008.42	business model;supply chain management;computer science;marketing;service-oriented architecture;enterprise integration;enterprise information system;business architecture;enterprise life cycle	DB	-57.60358233768068	16.835499911627654	29862
b42dc1e947ebd7bb74773d5cb3d6cc7711be0599	layered autonomic systems	organisms;air traffic control;formal specification;two dimensions;distributed processing;system behavior evaluation;robust control;local neighbour interactions layered autonomic systems formal specification system behavior evaluation airspace management;autonomic system;qa75 electronic computers computer science;aerospace control;layered autonomic systems;formal specification air traffic control distributed processing;nominations and elections;airspace management;clustering algorithms;robustness;nominations and elections air traffic control robustness robust control aircraft aerospace control rendering computer graphics insects organisms clustering algorithms;insects;rendering computer graphics;local neighbour interactions;aircraft	We adopt a layered approach to autonomic systems to simplify the specification, implementation and evaluation of self-* behaviours. Autonomy is rendered in two dimensions and interfaces suitable for tool based development are incorporated. To exemplify our approach we present an emergent solution for airspace management. This is representative of many problems in which local neighbour interactions can be utilised to give stable and robust global behaviour	autonomic computing;autonomy;defense in depth (computing);emergence;exemplification;interaction	Richard Anthony;Alun Butler;Mohammad T. Ibrahim	2005	Second International Conference on Autonomic Computing (ICAC'05)	10.1109/ICAC.2005.36	robust control;embedded system;organism;two-dimensional space;real-time computing;simulation;computer science;artificial intelligence;operating system;air traffic control;machine learning;formal specification;database;distributed computing;cluster analysis;computer security;robustness;computer network	SE	-40.36788239430465	19.475664252648027	29908
59de553054069d045cda66a9e73dd06ae26382fd	csrml: a goal-oriented approach to model requirements for collaborative systems	i;csrml;requirements engineering;awareness;collaborative systems;goal oriented	A collaborative system is software which allows several users to work together and carry out collaboration, communication and coordination tasks. To perform these tasks, the users have to be aware of other user's actions, usually by means of a set of awareness techniques. In previous works, we found by means of empirical studies that the most suitable Requirements Engineering approach to specify the requirements of this kind of systems is the Goal-Oriented one, and more precisely i* approach. In this paper, CSRML (Collaborative Systems Requirements Modelling Language) is presented, an extension of i* to deal with the specification of the requirements of these systems in which the collaboration and the awareness of other users presence / actions are crucial. In order to validate this proposal, a case study has been carried out by modelling a jigsaw activity: a cooperative-learning technique in which students individually do some research in a proposed problem and then they teach each other what they have learned by sharing each individual view of the problem.	collaborative software	Miguel A. Teruel;Elena M Navarro;Víctor López-Jaquero;Francisco Montero Simarro;Pascual González	2011		10.1007/978-3-642-24606-7_4	requirements analysis;software requirements specification;simulation;awareness;computer science;knowledge management;requirement;software engineering;requirements elicitation;goal orientation;data mining;database;requirements engineering;management;collaboration	SE	-52.32359015213206	22.363441420707655	29979
8395e36362b00d4d3c7e1a3d7bb00e85f109386a	modeling workflows with recursive ecatnets	software prototyping;operational semantics;rapid prototyping;workflow management software algebra petri nets recursive functions rewriting systems software prototyping;algebra;rewriting systems;rewriting logic;logic petri nets concurrent computing power system planning process planning workflow management software prototypes control systems mission critical systems process design;recursive functions;workflow management software;workflow management system;petri nets;petri net;workflow patterns;system maude workflow management system advanced workflow pattern recursive extended concurrent algebraic term nets recursive petri net conditional rewriting logic operational semantic rapid prototyping	A major limitation of current workflow management systems appears in (1) their lack of support for flexible workflows whose structures can be modified dynamically during the execution and (2) in their failure in dealing, efficiently, with the most advanced workflow patterns. In this paper, we propose a new model which we call recursive ECATNets (RECATNets) to model workflow processes with dynamic structure and, particularly, to handle the most complex workflow patterns, in a concise way. The RECATNets extend classical ECATNets (extended concurrent algebraic term nets) with the recursion concept firstly introduced in the recursive Petri nets. We define the semantics of RECATNets in the conditional rewriting logic framework. Rewriting logic is a true concurrency and operational semantics which allows rapid prototyping using rewriting techniques and the system Maude in particular	category theory;concurrency (computer science);executable;interrupt;linear algebra;maude system;model checking;operational semantics;petri net;rapid prototyping;recursion (computer science);rewrite (programming);rewriting;run time (program lifecycle phase);workflow pattern	Awatef Hicheur;Kamel Barkaoui;Noura Boudiaf	2006	2006 Eighth International Symposium on Symbolic and Numeric Algorithms for Scientific Computing	10.1109/SYNASC.2006.52	computer science;database;distributed computing;windows workflow foundation;programming language;petri net;workflow management system;workflow engine;workflow technology	Logic	-42.49845505996817	29.928233533441052	30107
faf29f318fb2fd20a2f1b49f7df1822b6eb7ece6	verifying ocl specifications of uml models: tool support and compositionakity	formal verification;software engineering;specification language;object constraint language;type system;formal method;state machine;theorem prover;real time systems;class diagram		object constraint language;unified modeling language	Marcel Kyas	2006				SE	-44.49848736471333	30.180635207950296	30126
19c141caf948bc0014af1258677c839e805a8fa0	a framework for service-oriented testing of web services	service providing;service request;performance test;service provider;service orientation;web service;service providing service oriented testing web services service request;internet;program testing;web services;test methods;program testing internet;web services application software software testing insurance system testing collaboration ontologies quality assurance distributed computing standards development;service oriented testing	Testing Web services (WS) application systems is difficult and expensive. It imposes great challenges to existing testing methods, techniques and tools. This paper analyses the problems in testing WS applications and proposes a service oriented framework to solve the problems. It enables collaborations between various parties involved in the development of WS applications via service request and service providing. It also enables special testing services to be provided as WS to perform testing tasks on behalf of their customers. The key technical issues of the approach are discussed	owl-s;service-oriented device architecture;software testing;test automation;web service	Hong Zhu	2006	30th Annual International Computer Software and Applications Conference (COMPSAC'06)	10.1109/COMPSAC.2006.95	service provider;test strategy;web service;service level requirement;service level objective;software performance testing;application service provider;system integration testing;differentiated service;service delivery framework;ws-policy;service design;cloud testing;database;operational acceptance testing;software testing;service virtualization;law;world wide web;computer security;web testing	SE	-47.752831720304584	17.569292820782756	30128
55e17ca1ee1e93230b2c984df6c08d5fba3929f1	matchmaking among minimal agents without a facilitator	multi agent system;middle agents;matchmaking;multi agent simulation;local community;agent architectures;open system;agent architecture;multi agent collaboration;peer to peer;random search;directory service	Multi-Agent Systems are a promising way of dealing with large complex problems. However, it is not yet clear just how much complexity or pre-existing structure individual agents must have to allow them to work together effectively. In this paper, we ask to what extent agents with minimal resources, local communication and without a directory service can solve a consumer-provider matchmaking problem. We are interested in finding a solution that is massively scalable and can be used with resource poor agents in an open system. We create a model involving random search and a grouping procedure. Through simulation of this model, we show that peer-to-peer communication in a environment with multiple copies of randomly distributed like clients and providers is sufficient for most agents to discover the service consumers or providers they need to complete tasks. We simulate systems with between 500 and 32,000 agents, between 10 and 2000 categories of services, and with three to six services required by each agent. We show that, for instance, in a system with 80 service categories and 2000 agents, each requiring three random services between 93\% and 97\% of possible matches are discovered. Such a system can work with at least 90 different service categories and tens of thousands of agents.	directory service;multi-agent system;open system (computing);peer-to-peer;random search;randomness;scalability;simulation	Elth Ogston;Stamatis Vassiliadis	2001		10.1145/375735.376467	agent architecture;directory service;random search;computer science;knowledge management;artificial intelligence;multi-agent system;distributed computing;open system;world wide web	ECom	-42.13974051247928	16.78457644850775	30148
62b1386c2f045d9402005afe94aef6b6afa15f72	towards a standard protocol for community-driven organizations of knowledge	hypertopic;knowledge management;web service;rest web services;web 2 0;open directory project;collective intelligence;communities	This paper deals with the “Web 2.0”, where every user can contribute to the content, “harnessing collective intelligence”. After studying what makes the success of services like Google Base, Del.icio.us and the Open Directory Project, we propose a unifying “REST” protocol for this kind of community-driven organizations of knowledge. The aim is to make the collaboration possible beyond the boundaries of the software and of the resulting communities.	apple open directory;collective intelligence;google base;web 2.0	Chao Zhou;Christophe Lejeune;Aurélien Bénel	2006			web service;web development;web modeling;computer science;knowledge management;social semantic web;database;web intelligence;project management 2.0;web 2.0;world wide web	Web+IR	-45.71488580688884	9.397146846394538	30234
7068248895abeb46a6185b48f09c21301a0561fc	a three-dimensional abstraction framework to compare multi-agent system models	multiagent system;multi agent system;three dimensions;three dimensional;levels of abstraction	Models of agents or multiagent systems in a certain application area can be made at different levels of abstraction. The aim of this paper is to clarify different types of abstraction levels for agent systems by expliciting different dimensions of abstraction. The three dimensions of considered are: the process abstraction dimension, the temporal dimension, and the agent cluster dimension. Thus a three-dimensional framework is obtained in which different types of multi-agent system models can be classified. For a number of multiagent system models in different application areas from the literature it is discussed how they fit in the framework.ion. The aim of this paper is to clarify different types of abstraction levels for agent systems by expliciting different dimensions of abstraction. The three dimensions of considered are: the process abstraction dimension, the temporal dimension, and the agent cluster dimension. Thus a three-dimensional framework is obtained in which different types of multi-agent system models can be classified. For a number of multiagent system models in different application areas from the literature it is discussed how they fit in the framework.	agent-based model;multi-agent system;principle of abstraction	Tibor Bosse;Mark Hoogendoorn;Michel C. A. Klein;Jan Treur	2010		10.1007/978-3-642-16693-8_33	three-dimensional space;simulation;computer science;artificial intelligence;theoretical computer science;multi-agent system	AI	-41.86035608508176	22.576695718802846	30265
9b534a6425df82bd4ff3d3787d796c2667f0a610	guide for pragmatical modelling of ontologies in corporate settings		The application of semantic technologies in a corporation sometimes requires modelling specialized ontologies under the requirements imposed by the corporate setting. Often a proof of concept needs to show the usefulness of a semantic application first, before additional investments will be made into the technology. Therefore, an initial ontology needs to be developed quickly with limited resources to demonstrate the usefulness of a semantic application. This chapter describes a practical and pragmatical approach for resource-limited modelling of ontologies. Guided by rules, this modelling approach starts with the modelling of a thesaurus which later can be extended to a full-fledged ontology. The initial step of modelling a thesaurus, allows for the development of a proof of concept first and to put the semantic application into productive use early, in order to acquire additional insights and information about its usage.	ontology (information science)	Thomas Hoppe;Robert Tolksdorf	2018		10.1007/978-3-662-55433-3_2	proof of concept;semantic technology;knowledge management;ontology;ontology (information science);computer science	AI	-45.993030880337955	7.554493662772552	30291
4510c92c34264e06b1d4f2a3a780c96add5632fc	service-oriented and autonomous distribution and provision of multimedia contents	incremental development;value added services;multimedia;service orientation;mobile agents;web service;agreement;agent framework;service oriented computing;mobile agent;multimedia services	This work considers encapsulation of multimedia contents as services, and their autonomous provision and distribution by agents. This approach enables content providers to have their contents provided and distributed together with their own business logics regarding interaction with other services and contents, control logic for various options upon provision, and value-added services. This paper proposes a framework for development of agents that provide and distribute such content services. In the framework, the interaction logic of agents is first developed in the same way as in development of ordinary Web services. Control descriptions are then given for each aspect, such as selection of partner agents, negotiation on service options, and migration. The separated descriptions for each aspect facilitate incremental development and test, as well as later modification, of agents with complex behaviors.	autonomous robot;business process;encapsulation (networking);intelligent agent;iterative and incremental development;logic programming;service-oriented architecture;service-oriented device architecture;system migration;web service	Fuyuki Ishikawa;Nobukazu Yoshioka;Shinichi Honiden	2006		10.1145/1160633.1160802	multi-frequency network;web service;computer science;knowledge management;service-oriented architecture;iterative and incremental development;mobile agent;multimedia;services computing;world wide web	AI	-46.0485225021304	15.351977039634017	30320
e2ab5ec75ce5cc6e275cdd1f3ea178672d90c92f	extending the reach and power of deductive program verification	verification;concurrency;verifikation;deductive;java	Soware is vital for modern society. e ecient development of correct and reliable soware is of ever-growing importance. An important technique to achieve this goal is deductive program verication: the construction of logical proofs that programs are correct. In this thesis, we address three important challenges for deductive verication on its way to a wider deployment in the industry: 1. verication of thread-based concurrent programs 2. correctness management of verication systems 3. change management in the verication process. ese are consistently brought up by practitioners when applying otherwise mature verication systems. e three challenges correspond to the three parts of this thesis (not counting the introductory rst part, providing technical background on the KeY verication approach). In the rst part, we dene a novel program logic for specifying correctness properties of object-oriented programs with unbounded thread-based concurrency. We also present a calculus for the above logic, which allows verifying actual JAVA programs. e calculus is based on symbolic execution resulting in its good understandability for the user. We describe the implementation of the calculus in the KeY verication system and present a case study. In the second part, we provide a rst systematic survey and appraisal of factors involved in reliability of formal reasoning. We elucidate the potential and limitations of self-application of formal methods in this area and give recommendations based on our experience in design and operation of verication systems. In the third part, we show how the technique of similarity-based proof reuse can be applied to the problems of industrial verication life cycle. We address issues (e.g., coping with changes in the proof system) that are important in verication practice, but have been neglected by research so far.	concurrency (computer science);correctness (computer science);deductive database;formal methods;formal proof;formal verification;java;key;proof calculus;software deployment;symbolic execution;verification and validation	Vladimir Klebanov	2009			verification and validation of computer simulation models;software verification;computer science;theoretical computer science;high-level verification;runtime verification;programming language;intelligent verification;algorithm;functional verification	PL	-42.831627364096384	27.27175870715859	30330
016d7c157a7aafe81dcdb543e14144bf44b0cf49	a retrieval technique for software components using directed replaceability similarity	developpement logiciel;similarity metric;composant logiciel;metric;similitude;desarrollo logicial;software development;similarity;software component;metrico;source code;component based software development;similitud;metrique	"""A mechanism of retrieving software components is indispensable for component-based software development. However, conventional retrieval techniques require an additional description, and cannot evaluate the total characteristics of a component. In this paper, we propose a new similarity metric, """"directed replaceability similarity' (DRS), which represents how two components differ in terms of structure, behavior, and granularity.We developed a retrieval system that automatically measures DRS between a user's prototype component and components stored in a repository, without any source codes or additional information. As a result of evaluation experiments, it is found that the retrieval performance of our system is higher than those of conventional techniques."""		Hironori Washizaki;Yoshiaki Fukazawa	2002		10.1007/3-540-46102-7_34	computer science;theoretical computer science;component-based software engineering;data mining;database;mathematics;programming language	SE	-58.17846664017349	32.240365901440605	30336
260eedcf8c490fd1d409862abac92e2a3571e222	towards an ontology for process monitoring and mining	process mining;semantic information;process monitoring;levels of abstraction;business process analysis;process model;coarse grained	Business Process Analysis (BPA) aims at monitoring, diagnosing, simulating and mining enacted processes in order to support the analysis and enhancement of process models. An effective BPA solution must provide the means for analyzing existing e-businesses at three levels of abstraction: the business level, the process level and the IT level. BPA requires semantic information that spans these layers of abstraction and which should be easily retrieved from audit trails. To cater for this, we describe the Process Mining Ontology and the Events Ontology which aim to support the analysis of enacted processes at different levels of abstraction spanning from fine grain technical details to coarse grain aspects at the business level.	abstraction layer;beam propagation method;business process;compaq evo;experiment;file spanning;ontology (information science);oracle bpa suite;principle of abstraction;simulation;stemming	Carlos Pedrinaci;John Domingue	2007			computer science;artifact-centric business process model;business process management;data science;data mining;database;business process model and notation;process mining;business process discovery;business process modeling	ML	-52.76307462055157	18.303940768243756	30338
76e74884a1442d83c8f24136eaa4b67eabdf3455	a constructive approach to compositional architecture design	constructive;architectural building blocks;software architecture;architecture composition;design;compositional;architectural patterns;approach;architecture	Most of today’s software systems are large-scaled and have to manage manifold demands. To ease their development, reusable and proven architectural building blocks, for example architectural patterns, are often composed to the desired architecture. Building blocks are specified by their structure and behaviour. Additionally, each architectural building block has specific properties which are interpreted as assurances. Keeping assurances also valid during composition of different architectural building blocks is essential for software quality. This paper introduces an approach which constructs software architectures by composing architectural building blocks and which also assures architectural properties of these compositions. Aiming at a sound approach, a proper description of the different architectural building blocks and their properties is required. Furthermore, this paper presents how to compose architectural building blocks and how to check their assurances.	architectural pattern;software architecture;software quality;software system	Constanze Deiters;Andreas Rausch	2011		10.1007/978-3-642-23798-0_8	software architecture;design;computer architecture;architectural engineering;architectural geometry;architectural pattern;systems engineering;engineering;architecture;software engineering;architectural technology;representational state transfer	SE	-54.25398874844666	27.240001625227436	30350
425c18be5373b90cd0669333061ea687db9d21ac	characterizing relations between architectural views	integration of views;architectural views;viewpoint;architectural descriptions;iso iec 42010;software engineering;multiple views;consistency model;view relations;ieee 1471;models;consistency	It is commonly agreed that an architectural description (AD) consists of multiple views. Each view describes the architecture from the perspective of particular stakeholder concerns. Although views are constructed separately, they are related as they describe the same system. A thorough study of the literature reveals that research on relations between views is fragmented and that a comprehensive study is hampered by an absence of common terminology. This has become apparent in the discussion on inter-view relational concepts in the revision of IEEE 1471 as ISO/IEC 42010 (Systems and Software Engineering — Architectural Description). This paper puts forward a framework that employs a consistent terminology to characterize relations between views. The framework sheds light on the usage, scope and mechanisms for relations, and is illustrated using several representative approaches from the literature. We conclude with a reflection on whether the revision of ISO 42010 aligns with our findings.	aim alliance;ambient occlusion;architectural pattern;architecture description language;closing (morphology);documentation;embedded system;fractal;heuristic (computer science);ieee 1471;iso/iec 42010;imperative programming;interactivity;list of system quality attributes;national fund for scientific research;on the fly;software architecture;software engineering;visual editor	Nelis Boucké;Danny Weyns;Rich Hilliard;Tom Holvoet;Alexander Helleboogh	2008		10.1007/978-3-540-88030-1_7	software architecture;iso/iec 42010;system model;computer science;engineering;knowledge management;consistency model;software engineering;consistency;view model	SE	-55.32492107854152	22.946064753597234	30357
c9d51c0f07647ecfb8e2199ef27cba15f4343e49	a formal methodology for accomplishing iec 61850 real-time communication requirements		Reliability is extremely important for control systems of energy distribution and generation. The IEC 61850 standard specifies an open architecture and communication protocols for such applications. The standard defines an open control architecture for networked control systems composed by intelligent electronic devices, stating some requirements that must be accomplished when developing reliable controllers for such systems. In this paper, we present a systematic and formal methodology to be adopted to achieve the correct implementation of the communication requirements of this standard. The methodology consists in five steps: modeling of real-time communication requirements defined by the standard; simulation of the obtained model; formal verification of the model, improved in the previous step; translation of the global model (simulated and verified) into the input language of the real controller; and finally, application of conformance testing technique to the computational routine implemented in the real controller. Presented research deals with the proposition of a strategy to synthesize and validate models of systems developed under IEC61850 real-time requirements (GOOSE and SMV) through simple operational conditions cases that, once validated, can be used in performance and conformance testing of more complex systems. The proposed methodology allows designers to synthesize reliable systems under IEC61850 real-time communication requirements.	automata theory;complex systems;conformance testing;control system;formal methods;formal verification;open control architecture;open architecture;real-time clock;real-time transcription;requirement;semantics (computer science);simulation;timed automaton	Guilherme Kunz;José Machado;Eduardo Perondi;Valeriy Vyatkin	2017	IEEE Transactions on Industrial Electronics	10.1109/TIE.2017.2682042	open architecture;control engineering;conformance testing;communications protocol;control theory;real-time computing;open control architecture;iec 61850;formal verification;control system;computer science	Embedded	-38.11953996044616	31.4588576744629	30371
a0002f04016ac49c9e9656560993b25b02ecb5fc	towards safe and productive development of secure software: fades and model-based software engineering	pufs;delegation;roks;read once keys;cryptography;soc;physically unclonable functions;asic;hardware	Cost effective development of secure software is a key goal for many software organizations as they seek to manage the risks of misbehaving software. Employing Formal Methods (FMs) in the Model-Based Software Engineering (MBSE) paradigm that systematically produces software systems through modeling, simulation, reuse and automation provides a reasonable approach for developing highly secure software in a productive manner. MBSE approaches introduce some complexities at the beginning of the lifecycle, but save substantial time in production and delivery by identifying and resolving defects/errors early and reducing rework. On the other hand, the expertise needed for FMs and the concomitant costs often inhibit their wide employment in securing large and complex software systems. In this paper, we report our experience with Formal Analysis and Design for Engineering Security (FADES) an approach we introduced two years ago at this venue. Through systematic and automated transformation from semiformal requirements specifications to formal design, FADES facilitates embedding FMs into the development lifecycle of secure software systems. We outline the case studies and validation of FADES feasibility for the design and implementation of secure software systems. Promising experience with FADES was a necessary precursor to our work on generalizing FADES and our proposal to direct FADES toward being an MBSE approach. We discuss how the formality, transformation, reuse and automation in FADES may further enhance the MBSE-based production and delivery of secure software.	formal methods;programming paradigm;requirement;rework (electronics);simulation;software engineering;software system;venue (sound system)	Riham Mansour;Shawn A. Bohner;Mohamed Eltoweissy	2010		10.1145/1852666.1852689	embedded system;verification and validation;real-time computing;engineering;package development process;software development;software construction;software walkthrough;computer security	SE	-58.12030258126216	25.458250504420377	30386
0f116aa0fbe2eae3f9d9108b7c2cbef8f419246e	design of a model-generated repository as a service for usdl	080501 distributed and grid systems;programming language;user interface;model generation;code generation;web service;080505 web technologies excl web search;usdl;repository;object oriented;080302 computer system architecture;service description;web services;model driven engineering;portfolio management;services;distributed systems;open source	"""SAP and its research partners have been developing a language for describing details of Services from various viewpoints called the Unified Service Description Language (USDL [12]. At the time of writing, version 3.0 describes technical implementation aspects of services, as well as stakeholders, pricing, lifecycle, and availability. Work is also underway to address other business and legal aspects of services. This language is designed to be used in service portfolio management, with a repository of service descriptions being available to various stakeholders in an organisation to allow for service prioritisation, development, deployment and lifecycle management.  The structure of the USDL metadata is specified using an object-oriented metamodel that conforms to UML, MOF and EMF Ecore. As such it is amenable to code generation for implementations of repositories that store service description instances. Although Web services toolkits can be used to make these programming language objects available as a set of Web services, the practicalities of writing distributed clients against over one hundred class definitions, containing several hundred attributes, will make for very large WSDL interfaces and highly inefficient """"chatty"""" implementations.  This paper gives the high-level design for a completely model-generated repository for any version of USDL (or any other data-only metamodel), which uses the Eclipse Modelling Framework's Java code generation, along with several open source plugins to create a robust, transactional repository running in a Java application with a relational datastore. However, the repository exposes a generated WSDL interface at a coarse granularity, suitable for distributed client code and user-interface creation. It uses heuristics to drive code generation to bridge between the Web service and EMF granularities."""	code generation (compiler);data store;eclipse modeling framework;heuristic (computer science);high- and low-level;internet protocol suite;java;level design;list of toolkits;meta-object facility;metamodeling;model transformation;open-source software;plug-in (computing);programming language;software deployment;unified modeling language;user interface;web services description language;web service;world wide web	Keith Duddy;Michael Henderson;Alejandro Metke-Jimenez;Jim Steel	2010		10.1145/1967486.1967600	computer science;systems engineering;database;world wide web	PL	-40.695505884368814	11.367380553469774	30422
bd91ff89b53896825d876c6b5bf1d75046c0f25a	a preliminary model-based approach for gender analysis of airbus research organization		The objective of this paper is to approach gender analysis in a novel way, applying MBSE (Model-Based Systems Engineering) techniques. MBSE is a methodology to enhance multidisciplinary design and simulation of complex systems and can be used to specify functions and behaviors of a system. The work described on this paper, was made in the frame of an Airbus CTO (Central Technical Office) project launched late 2017, with the target to increase up to 30% the women representation in Airbus R&T population in 2021. The novel way presented has been made by creating ontology as an analytical framework to approach the complex gender diversity social problem. The authors have applied the same methods used in Airbus to approach other complex engineering problems. The ontology presented is composed by a scope, a data model and behaviors models and has been modelled using several FOSS (Free and Open-Source Software) tools. Finally, an Airbus R&T use case has been presented, instantiating with real data, simulated and discussed.	complex systems;data model;instance (computer science);model-based systems engineering;open-source software;simulation	Rebeca Arista;Fernando Mas	2018	2018 IEEE International Conference on Engineering, Technology and Innovation (ICE/ITMC)	10.1109/ICE.2018.8436319	software engineering;data model;multidisciplinary approach;ontology;ontology (information science);data modeling;gender diversity;gender analysis;population	SE	-54.35163522205692	24.057656236075815	30442
9a3c04d585494f158c27188c425272e5e4ee33a9	ontograte: towards automatic integration for relational databases and the semantic web through an ontology-based framework	relational data;ontology mapping;heterogeneous databases;relational database;data mining;information integration;semantic web;query translation;multi relational data mining;ontology based information integration	Integrating existing relational databases with ontology-based systems is among the important research problems for the Semantic Web. We have designed a comprehensive framework called OntoGrate which combines a highly automatic mapping system, a logic inference engine, and several syntax wrappers that inter-operate with consistent semantics to answer ontology-based queries using the data from heterogeneous databases. There are several major contributions of our OntoGrate research: (i) we designed an ontology-based framework that provides a unified semantics for mapping discovery and query translation by transforming database schemas to Semantic Web ontologies; (ii) we developed a highly automatic ontology mapping system which leverages object reconciliation and multi-relational data mining techniques; (iii) we developed an inference-based query translation algorithm and several syntax wrappers which can translate queries and answers between relational databases and the Semantic Web. The testing results of our implemented OntoGrate system in different domains show that the large amount of data in relational databases can be directly utilized for answering Semantic Web queries rather than first converting all relational data into RDF or OWL.	algorithm;conjunctive query;decibel;experiment;inference engine;ontology (information science);relational data mining;relational database;resource description framework;semantic web;semantic integration;synthetic data;unified framework;web ontology language	Dejing Dou;Han Qin;Paea LePendu	2010	Int. J. Semantic Computing	10.1142/S1793351X10000961	semantic data model;upper ontology;idef1x;relational model;data web;bibliographic ontology;relational calculus;ontology inference layer;relational database;computer science;ontology;social semantic web;data mining;semantic web stack;database;conjunctive query;ontology-based data integration;owl-s;information retrieval	Web+IR	-37.716976044984264	6.567027699849139	30446
f82797aa5b119afbfc057e4d63ea323c7f07afa8	developing complex information systems from standard software components: a case study within manufacturing resource planning (mrp ii)	sme;information systems;performance test;information systems software standards standards development software systems materials requirements planning application software packaging process planning organizing manufacturing processes;complex manufacturing processes;manufacturing resource planning;application software;building block;complex information systems design;manufacturing resources planning;software systems;complex applications;enterprise type specific building blocks complex information systems design standard software components case study manufacturing resource planning mrp ii system complex applications microsoft office packages small to medium sized enterprises planning systems complex manufacturing processes sme engineering concept standard functions performance tests business processes component configurator;packaging;enterprise type specific building blocks;mrp ii system;component configurator;performance tests;engineering concept;standards development;manufacturing processes;production control;standard software components;manufacturing data processing;organizing;microsoft office packages;software reusability;integrated software;software component;materials requirements planning;planning systems;standard functions;small to medium sized enterprises;software standards;process planning;information system;office automation;business process;software packages;business processes	At our research institute, we explored to what extent it is possible to build complex applications with standard software. Using Microsoft Office packages we established an MRP II-system which contains all important modules. For small to medium-sized enterprises (SME) it might be an alternative to today’s planning systems, most of which cusing on organizing and supervising complex manuf turing processes with many options for tuning and ada tation. In this aspect our system is lean and particula well suited for SME. We describe our engineering conc and present the architecture of our prototype. A balance standard functions which were used, on the one hand, functions which had to programmed individually, on th other hand, is discussed. Furthermore, we summa strengths and weaknesses of our approach, including sults of performance tests and adaptations to spec business processes. Finally, we specify the concept component configurator which composes an MRP system from enterprise-type-specific building blocks.	ada;business process;component-based software engineering;enterprise resource planning;information system;media redundancy protocol;organizing (structure);prototype;spec#	Marc Braun;Sybille Möhle	1998		10.1109/HICSS.1998.654768	computer science;operations management;operating system;software engineering;database;business process;management;information system	SE	-56.1576545165679	21.773909638516358	30465
0a0922ed2b15508ab952d87a50a035c0a4230870	rmi-like communication for migrable software components in harness			component-based software engineering	Mauro Migliardi;Roberto Podestá	2003				SE	-51.20338335867676	26.718179398987257	30600
f05e0c7a68af110b1c6c048930c77035831f26d0	concurrent engineering aspects of software development	requirements definition;design decisions;reliability;measurement;software measurement;software maintenance;concurrent engineering programming software maintenance costs hardware product design guidelines product development software measurement software reliability;metrics;measurement concurrent engineering operational aspects software development design decisions product development support considerations planning requirements definition reliability maintainability metrics;software development process;operational aspects;support considerations;software engineering;guidelines;software development;planning;dp management;product design;software reliability;software engineering concurrent engineering dp management;programming;concurrent engineering;maintainability;hardware;product development	Often the earliest design decisions in product development have significant impact on the operational and support (O&S) aspects of the software product. These support considerations can best be handled concurrently to the planning, requirements definition, and high level dpsign activities. A number of techniques and guidelines are developed in this paper to ensure a focus on reliability and maintainability during the software development process. Some discussion is made of the metrics and measurement of software reliability and maintainability,	automated planning and scheduling;high-level programming language;new product development;requirement;software development process;software quality	K. C. Keene;S. J. Keene	1992		10.1109/ISSRE.1992.285858	planning;reliability engineering;programming;requirements analysis;personal software process;long-term support;verification and validation;software engineering process group;computer science;systems engineering;engineering;package development process;software design;social software engineering;software reliability testing;software development;software design description;software engineering;software construction;reliability;software walkthrough;product design;software maintenance;software measurement;metrics;goal-driven software development process;software development process;software requirements;software quality;new product development;maintainability;software metric;measurement;concurrent engineering;software peer review	SE	-60.29700598258604	27.921113578682345	30623
e1cfd518ef98a95055caf5f24e086188efddab34	dynamic explicitly specified behaviors in distributed agent-based industrial solutions	industry automation;agents;events;manufacturing;knowledge transfer;architectures;behavior;knowledge representation	Currently, the manufacturing domain is primarily characterized by the flexibility, adaptability and robustness of the production system. The manufacturing flow processes lead to shorter cycle times to efficiently meet customer needs. Mentioned features can be more easily achieved in a distributed system, such as holonic or multi-agent system, which becomes strongly influenced by the advancement of semantic technologies. In the majority of existing multi-agent based control systems, which are responsible for acting, sensing, computing and production planning, the ontology (necessary for knowledge bases and communication) is usually hard-coded directly in the agent code. In this case, the hardcoded system behavior can be hardly maintained—usually system reprogramming is needed from time to time to satisfy customer requirements. In this paper we discuss the necessity of explicit definition of both declarative and procedural knowledge and propose explicit procedural knowledge handling. Sharing and distribution of such knowledge is discussed and illustrated on an implemented transportation system example. We also introduce the utilization of discussed architecture for explicit specification of agent behavior in failures patterns handling and smart grid configuration scenario. Such a solution greatly increases the possibility of system integration, openness, flexibility, and extensibility, all without having to restart the running distributed system. The topic discussed in this paper shows the ability of the M. Radakovič (B) · M. Obitko · V. Mařík Department of Cybernetics, Czech Technical University in Prague, Karlovo náměstí 13, 121 35 Prague 2, Czech Republic e-mail: radakmil@fel.cvut.cz M. Obitko e-mail: marek.obitko@fel.cvut.cz V. Mařík e-mail: marik@fel.cvut.cz dynamic reconfigurable multi-agent system to participate in development of industrial control systems and solutions.	agent-based model;behavioral modeling;complex system;control system;cybernetics;declarative programming;distributed computing;email;expert system;extensibility;hard coding;high- and low-level;holon (philosophy);information explosion;intelligent agent;knowledge base;knowledge management;multi-agent system;openness;procedural programming;production system (computer science);requirement;robustness (computer science);service-oriented architecture;simulation;software agent;system integration;systems design;usability	Miloslav Radakovic;Marek Obitko;Vladimír Marík	2012	J. Intelligent Manufacturing	10.1007/s10845-011-0593-6	knowledge representation and reasoning;simulation;computer science;engineering;knowledge management;artificial intelligence;marketing;machine learning;manufacturing;behavior	AI	-42.87770856787801	21.020826791293533	30629
272749dce12f4f7ea3ed17d579f9210f50c7f18c	application of design patterns for hardware design	wrapping;systems on chip design;object oriented methods;ssytem level design processes;hardware software codesign;intellectual property;application software;uml;circuit cad system on chip integrated circuit design wrapping hardware software codesign object oriented methods industrial property;software engineering;system on a chip;wrapper design pattern;integrated circuit design;system level design processes;permission;system on chip;design pattern;unified modeling language;system level design;hardware design;design patterns;pattern analysis;circuit cad;industrial property;productivity;software design;ssytem level design processes design patterns hardware design systems on chip design metaprogramming wrapper design pattern;metaprogramming;hardware software design application software unified modeling language software engineering productivity intellectual property system on a chip permission pattern analysis;hardware	Design patterns, which encapsulate common solutions to the recurring design problems, have contributed to the increased reuse, quality and productivity in software design. We argue that hardware design patterns could be used for customizing and integrating the Intellectual Property (IP) components into System-on-Chip designs. We formulate the role of design patterns in HW design, and describe their implementation using metaprogramming. We propose a Wrapper design pattern for adapting the behavior of the soft IPs, and demonstrate its application to the communication interface synthesis.	metaprogramming;software design pattern;system on a chip;wrapper function	Robertas Damaševičius;Giedrius Majauskas;Vytautas Stuikys	2003		10.1145/775832.775847	system on a chip;unified modeling language;embedded system;computer architecture;software design pattern;behavioral pattern;computer science;systems engineering;design flow;operating system;distributed design patterns;programming language;design technology;structural pattern;generative design;computer engineering	EDA	-48.73566216736915	31.226820453684766	30637
69433c1ee418646068117992081ae663e29cbaa5	database requirements of cim applications	application development;database system;object oriented database systems;relational database system;computer integrated manufacturing	Changes in market and production profiles require a more flexible concept of manufacturing. Computer Integrated Manufacturing (CIM) describes an integrative concept for joining business and manufacturing islands. In this context database technology is the key technology for implementing the CIM philosophy. However, CIM applications are more complex and thus, more demanding than traditional database applications like business and administrative applications. In this chapter we systematically analyze the database requirements for CIM applications including business and manufacturing tasks. Special emphasis is given on integration requirements due to the distributed, partly isolated nature of CIM applications developed over the years. An illustrative sampling of current efforts in the database community to meet the challenge of nonstandard applications like CIM concludes this chapter.	cognitive dimensions of notations;computer-integrated manufacturing;data modeling;process modeling;relational database management system;requirement;reverse engineering;sampling (signal processing);schema evolution;transaction processing	Gerti Kappel;Stefan Vieweg	1995		10.1007/3-540-60286-0_99	database theory;relational database management system;database server;database tuning;relational database;systems engineering;database model;data mining;database;database schema;object-relational impedance mismatch;database testing;database design;component-oriented database	DB	-59.13959085144447	13.549665476458815	30686
bd042838ff4b8bf3926614fc183b6f6023a76257	integrating ontological domain knowledge into a robotic dsl	artificial intelligent;domain knowledge;knowledge modelling;model driven engineering;domain specific language;semantic web	Coming from the Artificial Intelligence (AI) and Semantic Web (SW) circles, ontologies are used mainly to represent domains. The Model Driven Engineering (MDE) field gave birth to Domain Specific Languages to represent a particular technical domain. Abstracting from their uses, we consider as many others researchers that ontologies and models are closer than their original fields could get to think. Furthermore, their building or development are facing the same problems. They are costly and need experts' interviews in order to grasp specific knowledge and structure it. Likewise, ontologies and DSL can benefit from each other domains in reusing construction methodologies and even reusing knowledge modelled in another format. In this paper we first present the ontologies and DSL definition we use and some methodologies of development enabling the reuse of knowledge (as alignment, fusion). We then present how we propose to reuse the knowledge of a robotic ontology to develop robotic DSLs within the PROTEUS project in order to inject readymade domain information to the DSL.	digital subscriber line	Gaëlle Lortal;Saadia Dhouib;Sébastien Gérard	2010		10.1007/978-3-642-21210-9_39	natural language processing;idef5;model-driven architecture;computer science;systems engineering;domain-specific language;knowledge management;domain engineering;semantic web;data mining;programming language;domain knowledge	Robotics	-53.09590400145851	21.79003060025551	30713
396633d53ea69c194cd260ae92a394cf209ac47d	pattern-based collaboration in ad-hoc teams through message annotation	proof of concept;interaction pattern;message logging	In this paper we present a specification for annotating messages to enable computer-supported message processing, addressing, and analysis. The benefits of annotating messages according to our XML based specification are two-fold: Firstly, it allows computer support during collaboration by enabling automated message addressing (i.e., determining who should get a message) and message management (e.g., managing your messages according to activities, projects, and tasks). Secondly, it enables post-collaboration analysis of messages and mining of message logs for patterns and for workflow models. We provide a proof of concept by presenting how annotated messages may support and facilitate collaboration that happens according to certain collaboration patterns. In addition to the patterns we have already introduced in our previous work, we present more patterns such as Monitors that emphasize the applicability of computer supported message handling.	design pattern;email;embedded system;high-level programming language;hoc (programming language);java annotation;server (computing);technical support;xml	Daniel Schall;Robert Gombotz;Schahram Dustdar	2007			computer science;database;distributed computing;publish–subscribe pattern;message broker;proof of concept;world wide web	Visualization	-49.81153453888999	13.582522981834499	30726
da54edf605914565e15a81653e1c5945e9bf94ae	a semantic approach to policy-based management - linking policies to ontologies	policy based management	The possibility of dynamically managing Quality of Service (QoS) in heterogeneous networks represents a key element for telecom operators which aim at making their communication infrastructures able to support new emerging multimedia services. The large success of triple play services together with the ongoing migration of voice carriers towards the NGN (Next Generation Network) architecture imposes a new way of controlling and utilizing network resources in order to fulfill user’s requirements. The use of network level policies to configure and manage QoS-based communication networks allows network operators to automatically adapt the managed systems to changing requirements of the new operational and business scenarios. In this paper we present an innovative approach to policy-based network management which ensures flexibility and effectiveness to all processes composing the service life cycle, from negotiation to delivery. In order to allow users and applications to modify their QoS requirements, thus triggering the SLA re-negotiation, at the same time optimizing the configuration of network elements we implemented a novel framework capable to automatically translate user’s requirements into network policies. Such framework relies on the adoption of ontologies as means to describe heterogeneous realms such as those associated with the fruition and delivery of innovative services. Ontologies are used to represent user’s needs and preferences, which feed the policy creation and enforcement process. Different real world scenarios are depicted to validate the effectiveness of the proposed approach.	next-generation network;ontology (information science);quality of service;realms;requirement;service-level agreement;swing (java);telecommunications network	Stefano Avallone;Salvatore D'Antonio;Simon Pietro Romano	2007			computer science;knowledge management;management science	Networks	-48.0510769152222	14.921088828570017	30765
abf19f43072c72c7c446fc16b3f6c8139f4503e0	research on service discovery and matching based on ontology and service capabilities in manufacturing grid	databases;manufacturing systems;owl;owl s;grid technology;grid technology mg manufacturing grid service capability ontology service discovery service matching manufacturing resource sharing powerful semantic model web service owl s web ontology language for service;web services grid computing knowledge representation languages manufacturing systems ontologies artificial intelligence resource allocation;resource allocation;powerful semantic model;web service;service matching;manufacturing resource sharing;ontologies artificial intelligence;knowledge representation languages;service capability;semantic model;service capabilities manufacturing grid service discovery service matching ontology;engines;web ontology language;resource sharing;web services;manufacturing;mg;ontologies;manufacturing grid;ontologies web services manufacturing automation computer aided manufacturing robotics and automation resource management computer science helium computer integrated manufacturing virtual manufacturing;service discovery;quality of service;web ontology language for service;grid computing;ontology;service capabilities;matching method	In manufacturing grid (MG), manufacturing service discovery and matching are related to the realization of the goal of manufacturing resource sharing. Because of lacking the support of a powerful semantic model, the methods and effects of service discovery and matching are still non-ideal, and affect the implementation of rapid, effective discovery and matching of the manufacturing service. On the basis of analyzing the deficiencies of service discovery mechanisms of the current Web service, and the problems of service discovery and matching in MG, the paper propose that the matching of service capabilities are the basic requirements of service discovery and matching in MG. The model of the service discovery and matching is set up. The matching method based on OWL-S (Web Ontology Language for Services), the matching degrees, matching rules and algorithms based on ontology and service capabilities are put forward.	algorithm;mg (editor);owl-s;ontology (information science);requirement;service discovery;web ontology language;web service	Yuan He;Dongqi Wu;Tao Yu	2009	2009 WRI World Congress on Computer Science and Information Engineering	10.1109/CSIE.2009.837	web service;computer science;knowledge management;artificial intelligence;ontology;database;service discovery;web ontology language;world wide web;grid computing	DB	-44.28471357865844	13.817459215754756	30785
52b50deeb7d94f4c985bb1382da26dec6a240ac4	metadata extraction using text mining	text mining;. metadata	Grid technologies have proven to be very successful in the area of eScience, and healthcare in particular, because they allow to easily combine proven solutions for data querying, integration, and analysis into a secure, scalable framework. In order to integrate the services that implement these solutions into a given Grid architecture, some metadata is required, for example information about the low-level access to these services, security information, and some documentation for the user. In this paper, we investigate how relevant metadata can be extracted from a semi-structured textual documentation of the algorithm that is underlying the service, by the use of text mining methods. In particular, we investigate the semi-automatic conversion of functions of the statistical environment R into Grid services as implemented by the GridR tool by the generation of appropriate metadata.	algorithm;correctness (computer science);documentation;e-science;extraction;generic drugs;high- and low-level;overhead (computing);population parameter;programming languages;programming language;r language;scalability;scripting language;semiconductor industry;solutions;text mining;tracing (software);web service	Shivani Seth;Stefan Rüping;Stefan Wrobel	2009	Studies in health technology and informatics	10.3233/978-1-60750-027-8-95	information retrieval;grid;knowledge extraction;architecture;documentation;scalability;data mining;metadata;medicine;text mining	HPC	-41.25941030672526	5.7264341103162275	30850
9269b647b1270aeebe33f2781704f32d0063fd20	user assistance for complex systems	task based design;information architecture;user technologies;software documentation;personas;development process;task modeling;user assistance;best practices;software development;usability;computer documentation;information development	"""There is much opportunity for innovation in the areas of design, development, and delivery of technical communication for """"systems of systems."""" Systems can be extremely complex, and contain many subsystems and components. The presentation of technical communication for a system of systems adds layers of complexity both to explaining the basic concepts of the system and all the details required for each area of the system that may be applicable to each type of user or role, function, and operation. It becomes more critical and yet more difficult to provide clear and comprehensive overviews and details of a system and its subsystems and components, as the complexity increases."""	complex systems;complexity;system of systems	Robert Pierce	2012		10.1145/2379057.2379060	persona;user experience design;usability;human–computer interaction;system of systems;computer science;software development;user guide;software engineering;technical documentation;systems development life cycle;software documentation;user analysis;management;world wide web;software development process;information architecture;best practice;software system;systems design	EDA	-61.84261644131501	19.27019030103801	30859
96040d644017a77b259a29f9ddfd09d9532b7c45	how object-oriented design principles enhance the development of complex automation programs - a best practice paper on how to develop service-interlaces for process modules as defined in vdi/vde/namur 2658		The complexity and difficulty for designing and developing automation programs based on the IEC 61131–3 [1] is continuously increasing. With the VDI/VDE/NAMUR 2658 [2] a new level of complexity will be reached - control modules with more complex interfaces, services as functional capsulation in process operations and interdependencies to other unknown up- or downstream modules. In these applications, the proven procedural approach reaches its limits. The object-oriented paradigm could be the solution. However the object-oriented extension of [1] is not supported in many available plc development tools. This results in a low acceptance and low experience in object-oriented thinking by plc developers. This paper will be focused on an object-oriented motivated transformation of design principles and patterns into Structured Text. The results are demonstrated in form of a best practice implementation for programs compliant to [2]. The presented approach does not use any kind of supportive or generating tools, it's based completely on the possibilities of IEC 61131–3.		Andreas Stutz;Mathias Maurmaier	2018	2018 IEEE 14th International Conference on Automation Science and Engineering (CASE)	10.1109/COASE.2018.8560397	automation;procedural approach;object-oriented design;software engineering;work in process;structured text;best practice;design elements and principles;interdependence;computer science	DB	-51.84456224837592	31.01158626241081	30911
3cb21d8788759e7fe2c87e4230227c1462b9d229	enhancing tool availability in the forging industry by adjusting ppc and tool maintenance	production planning and control ppc;tool allocation tool availability enhancement forging industry ppc adjustment tool maintenance day to day business collaborative research centre process chain precision forged high performance component manufacturing operative tool management;reliability;maintenance engineering;resource management companies availability logistics delay effects inspection;reliability forging machine tools maintenance engineering production planning;industrial production;forging;production planning;planning and control;collaborative research;forging industry production planning and control ppc tool maintenance;machine tools;tool maintenance;high performance;forging industry	The day-to-day business of the forging industry is characterized by fluctuating order quantities and production of numerous variants. Within the framework of the Collaborative Research Centre (CRC) 489 “Process chain for the manufacturing of precision forged high performance components” a simulation based approach was developed for the implementation of operative tool management to reduce delays caused by the allocation of tools.	cyclic redundancy check;interaction;interdependence;logistics;mathematical model;requirement;simulation	Anis Selaouti;Sven Baumgarten;Jens-Michael Potthast;Rouven Nickel	2011	2011 IEEE International Conference on Industrial Engineering and Engineering Management	10.1109/IEEM.2011.6117886	maintenance engineering;industrial production;engineering;operations management;machine tool;forging;reliability;engineering drawing;manufacturing engineering	DB	-59.83206039110901	8.193937143545039	30919
d5b747d6c1fe4a0ff43a3435e4b5d4d9ed4358e9	pópulo: a tool for debugging uml models	action language;executable uml;software development process;tool interoperability;model driven development;model execution;model simulation	Model-Driven Development (MDD) has made models first-class citizens of the software development process. Thus, a key factor for the successful adoption of MDD techniques is the ability to verify models, which can be achieved by model simulation and testing. This is already a reality for UML models, due mainly to the UML action language. However, at the current time, there are currently no tools available which are fully compliant with the UML action language. This leads to tool-interoperability and extensibility problems. In order to overcome this limitation, this paper presents Pópulo, a UML model debugger that interprets the UML action language. It is fully compliant with the UML 2.0 standard, and can be customised for executing models that need to extend (i.e. profile) the UML action language.	action (uml);action language;debugger;debugging;extensibility;interoperability;model-driven engineering;model-driven integration;simulation;software development process;unified modeling language	Lidia Fuentes;Jorge Manrique;Pablo Sánchez	2008		10.1145/1370175.1370205	real-time computing;uml state machine;uml tool;action language;computer science;systems engineering;software engineering;applications of uml;shlaer–mellor method;programming language;node;software development process;object constraint language	SE	-48.798579194410486	25.47571777661921	30927
10fc5c5e21dc65538c1195c389994e9756fd6324	a feature based content analysis of blockchain platforms		This paper presents a result of feature analysis for building blockchain platforms based on software product line engineering. The result includes a feature model describing major features and constraints among them, and discuss which blockchain platform enables each feature. The result contributes to a developer or an organization who wants to build their own blockchain platform by suggesting commonality and variability of features of the blockchain platform domain, and diverse alternatives to implement the platform.	bitcoin;feature model;heart rate variability;software product line	Suntae Kim;Sooyong Park;YoungBeom Park;JeongAh Kim;Young-Hwa Cho;Jae-Young Choi;Chin-Chol Kim	2018	2018 Tenth International Conference on Ubiquitous and Future Networks (ICUFN)	10.1109/ICUFN.2018.8436843	feature model;software;blockchain;content analysis;distributed computing;software product line;computer science	DB	-57.00692980407274	25.08455195868766	30961
ca07e779f9863cc016aecb81581912e17ad7e5e7	open hypermedia as user controlled meta data for the web	web pages;data integrity;xlink;data format;data semantics;webdav;open hypermedia;xml;interchange format;semantic web;meta data;open hypermedia systems;guided tour;data structure	This paper introduces an approach to utilise open hypermedia structures such as links, annotations, collections and guided tours as meta data for Web resources. The paper introduces an XML based data format, called Open Hypermedia Interchange Format OHIF, for such hypermedia structures. OHIF resembles XLink with respect to its representation of out-of-line links, but it goes beyond XLink with a more rich set of structuring mechanisms, including e.g. composites. Moreover OHIF includes an addressing mechanisms (LocSpecs) that goes beyond XPointer and URL in its ability to locate non-XML data segments. By means of the Webvise system, OHIF structures can be authored, imposed on Web pages, and finally linked on the Web as any ordinary Web resource. Following a link to an OHIF file automatically invokes a Webvise download of the meta data structures and the annotated Web content will be displayed in the browser. Moreover, the Webvise system provides support for users to create, manipulate, and share the OHIF structures together with custom made web pages and MS Office 2000 documents on WebDAV servers. These Webvise facilities goes beyond ealier open hypermedia systems in that it now allows fully distributed open hypermedia linking between Web pages and WebDAV aware desktop applications. The paper describes the OHIF format and demonstrates how the Webvise system handles OHIF. Finally, it argues for better support for handling user controlled meta data, e.g. support for linking in non-XML data, integration of external linking in the Web infrastructure, and collaboration support for external structures and meta-data.	data structure;desktop computer;download;hypermedia;web content;web page;web resource;webdav;world wide web;xlink;xml	Kaj Grønbæk;Lennert Sloth;Niels Olof Bouvin	2000	Computer Networks	10.1016/S1389-1286(00)00070-0	web service;static web page;web modeling;xml;data web;data structure;computer science;operating system;semantic web;web navigation;web page;data integrity;database;metadata;world wide web;information retrieval	Web+IR	-39.62260282038242	8.772467923974833	30965
931f4560cea64a3cbaf558b033b328cf33cd62fe	rigorous mapping of orthologous bidirectional promoters invertebrates defines their evolutionary history	grid computing ontologies data engineering semantic web vocabulary internet service oriented architecture contracts application software deductive databases;semantic web grid computing ontologies artificial intelligence pattern matching;satisfiability;semantic web technology;ontologies artificial intelligence;pattern matching;background knowledge;data access;semantic web;semantic web technologies semantic based data source discovery dai system grid environment data access integration system task requirements ontology based data source selector semantic matching data source matching;semantic matching;grid computing	Orthologous genes with deep phylogenetic histories are likely to retain similar regulatory features. In this report we utilize orthology assignments for pairs of genes co-regulated by bidirectional promoters to map the ancestral history of the promoter regions. Our mapping of bidirectional promoters from humans to fish shows that many such promoters emerged after the divergence of chickens and fish. Furthermore, annotations of promoters in deep phytogenies enable detection of missing data or assembly problems present in higher vertebrates. The functional importance of bidirectional promoters is indicated by selective pressure to maintain the arrangement of genes regulated by the promoter over long evolutionary time spans. Characteristics unique to bidirectional promoters are further elucidated using a technique for unsupervised classification, known as ESPERR. Results of these analyses will aid in our understanding of the evolution of bidirectional promoters, including whether the regulation of two genes evolved as a consequence of their proximity or if function dictated their co-regulation.	homology (biology);missing data;phylogenetics;sequence homology;supervised learning;unsupervised learning	Mary Yang;James Taylor;Laura Elnitski	2007	Second International Multi-Symposiums on Computer and Computational Sciences (IMSCCS 2007)	10.1109/IMSCCS.2007.85	semantic data model;semantic interoperability;semantic computing;semantic integration;data web;semantic search;semantic grid;computer science;semantic web;social semantic web;linked data;data mining;semantic web stack;database;ontology-based data integration;semantic technology;information retrieval;semantic analytics;data mapping	Comp.	-38.18842037539729	5.182040532029635	31076
163a2d22b1a8932c915a12e862b8a6e427ac014b	qualitative analysis of semantically enabled knowledge management systems in agile software engineering	semantically enabled knowledge management systems;qualitative analysis;wiki;software engineering;experience management;human centered design;knowledge management system;riki;software reuse;semantic wiki;agile software engineering	In many agile software engineering organizations there is not enough time to follow knowledge management processes, to retrieve knowledge in complex processes, or to systematically elicit knowledge. This chapter gives an overview about the human-centered design of semantically-enabled knowledge management systems based on Wikis used in agile software engineering environments. The methodology – developed in the RISE (Reuse in Software Engineering) project – enables and supports the design of human-centered knowledge sharing platforms, such as Wikis. Furthermore, the paper specifies requirements one should keep in mind when building human-centered systems to support knowledge management. A two-phase qualitative analysis showed that the knowledge management system acts as a flexible and customizable view on the information needed during working-time which strongly relieves software engineers from time-consuming retrieval activities. Furthermore, the observations gave some hints about how the software system supports the collection of vital working experiences and how it could be subsequently formed and refined. DOI: 10.4018/978-1-4666-0035-5.ch008	agile software development;knowledge management;management system;requirement;software engineer;software engineering;software system;two-phase commit protocol;user-centered design;wiki	Jörg Rech;Christian Bogner	2010	IJKM	10.4018/jkm.2010040104	requirements analysis;personal software process;verification and validation;user-centered design;software engineering process group;software mining;agile usability engineering;software configuration management;computer science;knowledge management;qualitative research;social software engineering;software development;requirement;domain engineering;knowledge engineering;software construction;knowledge extraction;personal knowledge management;empirical process;software development process;domain knowledge;software system	SE	-58.73616186439329	22.858424667358534	31114
8b4233189b32c0c83cda77f6c11dbfb70ca4a563	a survey on web service discovery approaches		With the growth and emergence of the Internet of Things (IoT) and API economy, the number of APIs and web services increased rapidly over the web. Web services play a significant role in today's business computing environment for the development of distributed applications across different networks. The process of finding the right web services that meet users' functional and nonfunctional requirements is crucial. Several web service discovery approaches have been proposed to facilitate the discovery process. These approaches are different, operate in multiple layers, and use various techniques to meet users' requirements. In this paper, we present a survey of different web service discovery approaches. The survey includes context-ware, user-side, clustering and recommender-based web service discovery approaches.	application programming interface;cluster analysis;distributed computing;emergence;information system;internet of things;non-functional requirement;recommender system;service discovery;warez;web service	Waeal J. Obidallah;Bijan Raahemi	2017		10.1145/3018896.3056773	web service;web application security;web development;web modeling;data web;web analytics;web mapping;web design;web standards;computer science;ws-policy;social semantic web;data mining;database;service discovery;web intelligence;web engineering;web 2.0;world wide web;universal description discovery and integration;mashup	Web+IR	-45.9660535871296	12.945217939885117	31135
f031170a54bd67624c5e3b79b85d5aacfb4e65d1	merging g-grid p2p systems while preserving their autonomy.	p2p system;data management;p2p;multi dimensional;peer to peer	Peer-to-Peer (P2P) systems share and manage huge amounts of data and resources distributed across a large number of machines. In pure P2P environments the control is totally decentralized in peers, which are autonomous, perform the same roles and do not have a global view of the entire system. Several P2P solutions have been deployed and proposed in literature managing data within a single P2P system with a variety of different features and performances. But in all cases a single P2P system conceptually corresponds to a single database containing a unique relational table and all functions, such as querying, routing and content location, are defined to properly work just within such a single system. Existing solutions cannot support several databases, which originate and grow separately, or simply just one database with several tables, because it would be necessary many distinct P2P systems. In this paper we present a solution to merge G-Grid P2P systems, which are multi-dimensional distributed structures for P2P data management, preserving their own autonomy and identity. Thanks to this users and applications can view the merged systems both as a single environment and also as a set of distinct systems. As P2P systems merge, all their functions, such as complete and partial range querying, content routing and so on, adapt naturally to efficiently work in the multi-grid P2P system.	application-oriented networking;autonomous robot;autonomy;data structure;database;interaction;network packet;peer-to-peer;performance;range query (data structures);routing;scalability;self-organization	Gianluca Moro;Gabriele Monti;Aris M. Ouksel	2004			environmental resource management	DB	-37.20090940271046	15.427667089873584	31149
5b22fda24a9482d1bed786e412ffe3fbef8532df	guidelines on the use of fit tables in software maintenance tasks: lessons learned from 8 experiments	libraries;software maintenance program testing program verification project management software development management;web based applications;integration testing;project management;test driven development;fixtures;software maintenance;availability;project manager;maintenance engineering;testing;program verification;fit table;empirical evidence;code correctness;program testing;guidelines;executable acceptance test;lessons learned;controlled experiments;software development;integrated test framework;maintenance engineering testing fixtures availability java guidelines libraries;software development software maintenance fit table integrated test framework change requirement comprehension code correctness project manager executable acceptance test open source framework;open source framework;fit acceptance test;test driven development controlled experiments fit acceptance test change requirements;change requirements;software development management;change requirement comprehension;java	Executable acceptance test case-in particular Fit (Framework for Integrated Test) tables-originally intended for the development phase proved useful in maintenance activities too. Empirical evidence suggests that Fit tables are useful in improving the comprehension of change requirements and the correctness of the maintained code. Stemming from eight experiments formerly performed by the authors, this paper presents a set of lessons learned and guidelines useful for project managers on the use of Fit tables in maintenance tasks. Specifically, the paper discusses the use of Fit tables in maintenance tasks considering a set of dimensions, ranging from maintainerspsila experience to the nature of application being maintained and to the kind of benefits introduced by Fit tables. Benefits of Fit tables, such as improving the code correctness and comprehension, increase with developers experience and complex requirements but decrease with Web-based applications and when programmers work in pairs.	acceptance testing;authorization;correctness (computer science);decision table;exptime;executable;experiment;framework for integrated test;glue code;ieee xplore;pair programming;programmer;requirement;software bug;software maintenance;software quality;stemming;table (database);test case;web application	Filippo Ricca;Massimiliano Di Penta;Marco Torchiano	2008	2008 IEEE International Conference on Software Maintenance	10.1109/ICSM.2008.4658080	maintenance engineering;project management;reliability engineering;test-driven development;availability;web application;empirical evidence;integration testing;computer science;systems engineering;engineering;software development;software engineering;software testing;programming language;software maintenance;java	SE	-56.43471437709192	31.430817207965884	31153
524c6a666db4078a29e15866a6878c598b507b1b	software language engineering in the large: towards composing and deriving languages		Abstract Suitable software languages are crucial to tackling the ever-increasing complexity of software engineering processes and software products. They model, specify, and test products, describe processes and interactions with services and serve many other purposes. Meanwhile, engineering suitable modeling languages with useful tooling also has become a challenging endeavor - and far too often, new languages are developed from scratch. We shed light on the advances of modeling language engineering that facilitate reuse, modularity, compositionality, and derivation of new languages based on language components. To this end, we discuss ways to design, combine, and derive modeling languages in all their relevant aspects. We illustrate the application of advanced language engineering throughout the paper, which culminates in the example of deriving complete domain-specific transformations language from existing language components.		Katrin Hölldobler;Bernhard Rumpe;Andreas Wortmann	2018	Computer Languages, Systems & Structures	10.1016/j.cl.2018.08.002	computer science;principle of compositionality;theoretical computer science;scratch;modeling language;software;reuse;systems engineering;modularity;on language	DB	-54.307531085684964	25.494447327914408	31206
ad66705f703d01999d39271dc42434b0e77ec3bf	exploring dataflow in legacy systems.	legacy system	Maintenance and transformation of large program systems require means for comprehension of their data dependences. We consider facilities for dataflow visualization implemented in the RescueWare® system – a workbench for modernizing legacy systems. These features allow for source code navigation and are primarily intended for identification of program points to which the transformation of Business Rules Extraction is to be applied.	cobol;dataflow;high- and low-level;legacy system;quantum entanglement;type system;workbench	Mikhail A. Bulyonkov;N. N. Filatkina	2001			software modernization;computer architecture;parallel computing;computer science;programming language;legacy system	SE	-50.786969392370096	31.24377322483015	31280
38432a701996b2a36bc101d7d32ab45b7211a6a4	sidra: a flexible distributed indexing and ranking architecture for web search	ciencias basicas y experimentales;web search;computer science;article		web search engine	Miguel Costa;Mário J. Silva	2003			web modeling;data web;web search engine;computer science;data science;web search query;world wide web;information retrieval	Web+IR	-33.73139636951798	6.070182224034362	31282
ab0f03b32bc51aee179db1e497b271114acc70b4	integrating discovery and automated composition: from semantic requirements to executable code	protocols;formal specification;executable code;service engines;web services service oriented architecture testing engines telecommunications concrete humans books protocols filters;discovery integration;filters;service engines discovery integration automated composition semantic requirements executable code web services stateless functional descriptions automated end to end composition executable orchestrations;testing;web service;data mining;semantic requirements;stateless functional descriptions;books;software architecture;automated composition;engines;automated end to end composition;web services;humans;service oriented architecture;service engineering;executable orchestrations;telecommunications;concrete;web services data mining formal specification software architecture	Web services are conveniently advertised and published based on (stateless) functional descriptions, while they are usually realized as (stateful) processes. Therefore, the automated enactment of complex Web services on the basis of pre-existing ones requires the ability to handle services described at very different abstraction levels. This is the main reason behind the current lack of approaches capable to perform automated end-to-end composition, starting from semantic requirements to obtain executable orchestrations of stateful processes. In this paper we achieve such a challenging goal, by modularly integrating a range of incrementally more complex techniques that cover the necessary discovery and composition phases. By gradually bridging the gap between the high-level requirements and the concrete realization of services, our architecture manages sensibly the complexity of the problem: incrementally more complex techniques are provided with incrementally more focused input. The tests of our architecture on a deployed scenario witness the functionality of the platform and its integrability with standard service engines.	bridging (networking);end-to-end principle;executable;high- and low-level;modular programming;requirement;state (computer science);stateless protocol;web service	Piergiorgio Bertoli;Jörg Hoffmann;Freddy Lécué;Marco Pistore	2007	IEEE International Conference on Web Services (ICWS 2007)	10.1109/ICWS.2007.111	web service;real-time computing;computer science;operating system;database;programming language;law;world wide web	SE	-46.99658488048081	18.182211699581792	31291
31d4ff95152dc8e5a0cbd321dfae92b19bdf2af8	using dependency models to manage complex software architecture	busqueda informacion;lenguaje programacion;virtual memory;shared memory;analyse statique;programming language;information retrieval;memoria compartida;matrice structure dependance;program verification;software engineering;analisis estatica;dependency;software architecture;verificacion programa;recherche information;memoire virtuelle;genie logiciel;dsm;model;langage programmation;matrix;information system;static analysis;verification programme;architecture;ingenieria informatica;systeme information;memoria virtual;architecture logiciel;memoire partagee;sistema informacion	An approach to managing the architecture of large software systems is presented. Dependencies are extracted from the code by a conventional static analysis, and shown in a tabular form known as the 'Dependency Structure Matrix' (DSM). A variety of algorithms are available to help organize the matrix in a form that reflects the architecture and highlights patterns and problematic dependencies. A hierarchical structure obtained in part by such algorithms, and in part by input from the user, then becomes the basis for 'design rules' that capture the architect's intent about which dependencies are acceptable. The design rules are applied repeatedly as the system evolves, to identify violations, and keep the code and its architecture in conformance with one another. The analysis has been implemented in a tool called LDM which has been applied in several commercial projects; in this paper, a case study application to Haystack, an information retrieval system, is described.	algorithm;conformance testing;design structure matrix;information retrieval;software architecture;software system;static program analysis;table (information);the matrix	Neeraj Sangal;Ev Jordan;Vineet Sinha;Daniel O Jackson	2005		10.1145/1094811.1094824	dependency;shared memory;reference architecture;software architecture;simulation;dependency theory;computer science;virtual memory;artificial intelligence;architecture;static analysis;information system;algorithm;matrix	PL	-42.365486154884714	24.988727399470015	31304
d1b25e501ca5f302cc4b35c43bb64f8168e62863	keyline: software productivity tools for program design, implementation, documentation	program design		documentation	Maurizio Barioglio;G. Capella;I. Lupo;Luigi Petrone	1986			documentation;software engineering;software;engineering;program design language	SE	-51.02094984151906	30.71590278739042	31329
de70839a63f49e96748eb97e8e2efa3ea86df292	using a standards-based approach for a multimedia knowledge-base		In recent years, we witnessed the diffusion and rise in popularity of software platforms for User Generated Content management, especially multimedia objects. These platforms handle a big quantity of unclassified information. UGC sites (i.e. YouTube and Flickr) do not force the users to perform classification operations and metadata definitions, leaving space to a logic of free-tags (Folksonomies). In the context of an industrial project financed by the Autonomous Region of Sardinia, the idea of producing a Geolocalized Guide based on a Knowledge-base came forth. Such Guide would be able to share georeferenced content with their users, originated from UGC sources as well as from users themselves. For this purpose, we defined an ontology that can represent the semantics of multimedia content, especially its metadata, which in turn can be given an unambiguous meaning. The innovation in this work is represented by the use of the Adobe XMP, DUBLIN CORE, EXIF, IPTC standards as a starting point. In order to unify metadata coming from different sources we defined all laws of mapping toward a structure defined by sources like YouTube and	dublin core;exif;extensible metadata platform;flickr;folksonomy;geocoding;geolocation;interoperability;mobile device;portals;user-generated content;web content management system	Maria Ilaria Lunesu;Filippo Eros Pani;Giulio Concas	2011			knowledge management;data mining;knowledge base;computer science	DB	-41.608626867729626	6.261805166643523	31351
b74e35f1403ba2b8b4cbdbe454dd67b773893fd8	integrating interactive tv services and the web through semantics	business models;personalization;interactive tv;semantic web;mpeg 7	Interactive TV has started to penetrate broadcasting markets, providing a new user experience through novel services to subscribers and new revenue opportunities for companies. Personalization and intelligent behavior, such as proactive content delivery are considered key features for the services of the future TV. However, most of the work in this area is limited to personalization of electronic program guides and advanced program recommendation. In this article, the authors adopt a more horizontal approach and describe the application of concepts, practices and modern Web trends to the TV domain in the context of the POLYSEMA platform. A key characteristic of this approach is the formal modeling of multimedia and user semantics that enables novel TV services. Specifically, Semantic Web methodologies are employed e.g., ontologies and rules while compatibility with the MPEG-7 standard is also pursued. The paper describes the overall architecture of the platform, provides implementation details and investigates business issues.	world wide web	Vassileios Tsetsos;Antonis Papadimitriou;Christos Anagnostopoulos;Stathes Hadjiefthymiades	2010	Int. J. Semantic Web Inf. Syst.	10.4018/jswis.2010010101	business model;computer science;semantic web;personalization;database;multimedia;interactive television;world wide web	Web+IR	-46.72110516445636	12.387459309969397	31353
afd111f7ed28fef8400f3c53722788b0dfcd5c61	semantic path ranking scheme for relational keyword queries	information retrieval;database management;global information systems;keyword search;result ranking	Existing works on keyword search over relational databases typically do not consider users’ search intention for a query and return many answers which often overwhelm users. We observe that a database is in fact a repository of real world objects that interact with each other via relationships. In this work, we identify four types of semantic paths between objects and design an algorithm called pathRank to compute and rank the results of keyword queries. The answers are grouped by the types of semantic paths which reflect different query interpretations, and are annotated to facilitate user understanding.	information;relational database;search algorithm	Zhong Zeng;Zhifeng Bao;Gillian Dobbie;Mong-Li Lee;Tok Wang Ling	2014		10.1007/978-3-319-10085-2_8	global information system;computer science;concept search;data mining;database;keyword density;information retrieval	DB	-34.39494807230078	4.649731350294666	31367
fa7255c3293f5360c70589b2559603c1bf17bdb2	semantics in space systems architectures	uml;synchronous;dodaf;fuml;updm;modeling;modaf	Costs, life cycles, technologies and agreements between stakeholders and organizations make space systems unique with respect to the complexity. A commonly accepted technique to address part of this complexity is to model and to maintain space systems architectures through the life cycle of their space programs. The benefits may range from supporting consistent model definitions and maintenance up to supporting analysis and verification. Space systems architectures have been modeled using UPDM (unified profile for DoDAF And MODAF; a UML profile). In fact, UPDM argues that it provides a clearer understanding of the semantics behind specific views and viewpoints. Nonetheless, while UML defines its semantics imprecisely using plain text and variation points, UPDM does not define any semantics. In this paper, we evaluate an extension of fUML (semantics of a foundational subset for executable UML models) as a semantics for space systems architectures. The extension of fUML as a synchronous language (synchronous fUML) provides a limited, but formally precise and deterministic, form to describe structure and behavior in UML. Through the combination of this semantics with UPDM, a precise language supporting a standardized meta-model emerges for the definition of space systems architectures. At the end, a simplified case study covering the operational view (OV-*) is presented. Our initial results show that synchronous fUML is able to offer a precise and deterministic semantics for UPDM.	computation;department of defense architecture framework;diagram;differential algebraic equation;emergence;executable uml;metamodeling;model checking;operational view;profile (uml);programming language;rm-odp;requirement;space segment;systems architecture;systems engineering;transition system;updm;unified modeling language;whole earth 'lectronic link	Alessandro Gerlinger Romero;Klaus Schneider;Maurício Gonçalves Vieira Ferreira	2015	Innovations in Systems and Software Engineering	10.1007/s11334-015-0267-1	unified modeling language;systems modeling;computer science;systems engineering;engineering;theoretical computer science;synchronous learning;algorithm	SE	-52.856729792286956	26.436767464383603	31477
a469857a56cc22d6dd48897deb34eb4377fc3b74	towards a formal methodology for designing multi-agent applications	multiagent system;multi agent system;intelligence artificielle;refinement method;planificacion;artificial intelligence;coordinacion;planning;inteligencia artificial;planification;methode raffinement;multilinguisme;sistema multiagente;metodo afinamiento;lenguaje formal;multilingualism;formal language;systeme multiagent;multilinguismo;coordination;design methodology;langage formel	This paper has two purposes. First, it defines a formal language for specifying multi-agent systems. This language is expressive enough to cover individual agent aspects (knowledge, goals, roles, ...) as well as collective aspects of in terms of coordination protocols, organization structure and planning activities. Second, it provides a formal design methodology based on stepwise refinements allowing to develop a design specification starting from an abstract requirements one.		Amira Regayeg;Ahmed Hadj Kacem;Mohamed Jmaiel	2005		10.1007/11550648_14	planning;formal language;formal methods;design methods;specification language;computer science;artificial intelligence;multi-agent system;formal specification;algorithm	EDA	-39.617155933342715	24.26281087484251	31487
175954ac1d60652a51b8268fab9f86b55b12f4d2	customers, vendors, and universities: determining the future of eda together (panel)				Thomas Pennino	1998		10.1145/277044.277045	engineering	DB	-61.172064138351175	5.773102203244746	31518
6a554c90a0625f063457659857b6291f2296ed44	slam ii, including a material handling extension	modeling language;technical report	SLAM II was the first simulation language which allowed a modeler to formulate a system description using process, event, or continuous world views or any combination of the three. Since its initial release in 1981, SLAM II has undergone continual development and application. This paper will provide an introduction to the modeling language and describe the most recent developments in SLAM II itself and support software.		Jean J. O'Reilly	1986		10.1145/318242.318269	simulation;computer science;artificial intelligence;technical report;modeling language;engineering drawing	Robotics	-58.99106572384757	9.657966309986369	31520
a19bc2acfbe2d1f717b5576eb903dedc6fe97f9b	the design of large knowledge-based systems: the example of digital equipment's xsel project	knowledge based system;xsel;environment;design;management;participation;artificial intelligence a i	Abstract. This paper discusses the management problems associated with building and implementing large systems. The example described is XSEL, a configuring expert system designed by the Digital Equipment Corporation for worldwide application.#R##N##R##N##R##N##R##N#Digital, like many other larger computer manufacturers, had experienced problems in achieving a high level of configuring accuracy when assembling its computer. These problems showed up in the manufacturing plants but originated in the sales offices. They caused difficulties with customers and increased manufacturing and selling costs. The company decided that an expert system could solve the problem.#R##N##R##N##R##N##R##N#The processes associated with the design of this successful system created as many human as technical challenges. The paper describes these, discusses how and why they originated, and evaluates Digital's strategies for solving them. It makes some general recommendations for the successful management of major change.	knowledge-based systems	Enid Mumford	1991	Inf. Syst. J.	10.1111/j.1365-2575.1991.tb00029.x	design;economics;computer science;systems engineering;engineering;knowledge management;operations management;software engineering;knowledge-based systems;management;world wide web	DB	-62.11296071192515	7.021171171471522	31578
285a03f6df7168adfe40fdc04c1cdba917e28374	a pattern-based usability inspection method: first empirical performance measures and future issues	performance measure;usability patterns;usability inspection;heuristic evaluation;evaluation;experiment	The Usability Pattern Inspection (UPI) is a new usability inspection method designed for the added downstream utility of producing concrete design recommendations. This paper provides first empirical evidence that UPI measures up to the established inspection method Heuristic Evaluation (HE) regarding defect identification. It is shown that there is also some potential for synergy between UPI and HE. The further research plan of measuring UPI is presented.	downstream (software development);heuristic evaluation;interaction design pattern;software bug;synergy;usability inspection	Martin Schmettow;Sabine Niebuhr	2007		10.1145/1531407.1531433	usability goals;pluralistic walkthrough;reliability engineering;cognitive walkthrough;simulation;usability;systems engineering;engineering;heuristic evaluation;usability inspection	SE	-61.252731612265336	26.310260736682196	31606
f33dded85913b370cda4afde67f59cdfb061f221	information retrieval from distributed semistructured documents using metadata interface	busqueda informacion;query language;metadata;information retrieval;xml language;interrogation base donnee;interrogacion base datos;langage java;lenguaje interrogacion;semistructured data;recherche documentaire;dato semi estructurado;heterogeneidad;recherche information;busqueda documental;decouverte connaissance;metadonnee;descubrimiento conocimiento;lenguaje java;langage interrogation;document retrieval;metadatos;database query;langage xml;lenguaje xml;heterogeneity;heterogeneite;java language;knowledge discovery;donnee semistructuree	We describe a method for retrieving information from distributed heterogeneous semistructured documents, and its implementation in the metadata interface DDXMI (Distributed Document XML Metadata Interface). The system generates local queries appropriate for local schemas from a user query over the global schema and shows the result of the generated queries. The three components are designed to generate the local queries: mappings between global schema and local schemas (extracted from local documents if not given), path substitution, and node identification for resolving the heterogeneity among nodes with the same label that often exist in semistructured data. The system uses Quilt as its XML query language. An experiment is reported over three local semistructured documents: ‘thesis', ‘reports', and ‘journal' documents with ‘article' global schema. The prototype was developed under Windows system with Java and JavaCC.	information retrieval	Guija Choe;Young-Kwang Nam;Joseph A. Goguen;Guilian Wang	2006		10.1007/11730262_8	document retrieval;xml;computer science;heterogeneity;database;metadata;world wide web;information retrieval;query language	Web+IR	-36.63265516046313	11.541530184188488	31630
3e4c637076d05bdb6765796ba651e0b51e390221	simplifying web service discovery & validating service composition	discomp algorithm;web service discovery simplification;service composition;web service discovery;web service standardization;composition;wsdl;efficient algorithm;signature based approach web service discovery simplification service composition validation software components machine to machine interaction web service standardization service oriented architecture soa wsdl uddi discovery agents finite state machine discomp algorithm;semantics;soa;web service;satisfiability;design decision;software components;web service composition;semantics ontologies service oriented architecture servers unified modeling language semantic web;signature based approach;finite state machines;servers;unified modeling language;web services;software component;semantic web;design decision web service machine to machine interaction web service discovery composition parameter matching;service composition validation;uddi;ontologies;is success;discovery agents;service discovery;machine to machine interaction;web services finite state machines service oriented architecture user interfaces;service oriented architecture;user interfaces;interactive web service;finite state machine;parameter matching	Web services are software components developed to simplify machine-to-machine interaction over the Web. Many researches are targeted towards Web service standardization, and these efforts have significantly contributed towards improving functionality of Service Oriented Architecture (SOA). However, there are number of issues yet to be resolved. Among them, one of the major challenges is the standardization of Web service composition. When a single web service cannot satisfy the given request, composition of web services need to be incorporated. In this paper, we address Web service composition problem with the signature-based service discovery and composition approach[30]. In the proposed approach, each web service is described by WSDL. Our design eliminates the need of complicated discovery agents like UDDI and also facilitates validation of the service before actually accessing it for integration. The composition problem has been modelled as a finite state machine, which means if the all the intermediate states are rightly composed then the final composition is successful. We propose a simple yet efficient algorithm DISCOMP for the discovery and composition. This paper analyses build time and runtime issues related to signature-based approach. We support our design decision with implementation and performance results obtained on a decentralized setup.	algorithm;component-based software engineering;finite-state machine;machine to machine;service composability principle;service discovery;service-oriented architecture;web services description language;web services discovery;web service;world wide web	Shrabani Mallick;Rajender Pandey;Sanjeev Neupane;Shakti Mishra;Dharmender Singh Kushwaha	2011	2011 IEEE World Congress on Services	10.1109/SERVICES.2011.60	web service;web modeling;web standards;computer science;service delivery framework;ws-policy;data mining;database;service discovery;web engineering;world wide web;devices profile for web services;universal description discovery and integration;mashup	Web+IR	-44.60340002949889	14.25142210931947	31669
63509fdbe5314da77488954777a007b09afd6a73	a standard model for multimedia synchronization: premo synchronization objects	premo;norme iso;multimedia;standards;inter media synchronization;normalisation;norma iso;computer systems;iso standard;multimedia systems;synchronisation;standard model;object oriented;synchronization;active objects;multimedia synchronization;oriente objet;systeme informatique;multimedia presentation;media synchronization;orientado objeto;standardization	This paper describes an event-based synchronization mechanism, which is at the core of the inter-media synchronization in the upcoming standard for multimedia presentation, PREMO. The synchronization mechanism of PREMO is a powerful tool, based on a small number of concepts, and on cooperation among active objects, and represents a synthesis of various synchronization models described in the literature. This model can serve as a basis for the implementation of complex synchronization patterns in multimedia presentations, both purely event-based, as well as time-based.	algorithm;computer graphics;constraint satisfaction;elegant degradation;encapsulation (networking);entity;high- and low-level;maximal set;mozilla application framework;parsing;programming paradigm;quality of service;requirement;sampling (signal processing);software propagation;synchronization (computer science);synchronization model	Ivan Herman;Nuno Correia;David A. Duce;David J. Duke;Graham J. Reynolds;James van Loo	1998	Multimedia Systems	10.1007/s005300050078	embedded system;synchronization;real-time computing;telecommunications;computer science;multimedia;data synchronization;synchronization	Robotics	-34.27784529295231	30.502577027295818	31740
054ce8bb65fde90fac22efad4ef369f8e990e36b	generation of role-specific information for an enterprise integration framework using xml descriptions	hypermedia markup languages;controller area networks;automation and control enterprise integration semantics syntax role specific descriptions xml;control system;enterprise integration;computer integrated manufacturing;use case;xml automatic control control systems manufacturing automation internet control system synthesis java enterprise resource planning html automatic generation control;electronic data interchange;computer integrated manufacturing hypermedia markup languages electronic data interchange controller area networks	Enterprise integration is one of the most important tasks in modern automation and control solutions. For effective applications at enterprise level, specific interfaces and description models have to be defined. Considering these enterprise applications playing each a specific use case, a role, to the underlying automation and control system, role-specific descriptions with special semantics and syntax have to be generated. These descriptions represent specific views of a general system's information set. To keep them consistent and easy to create, new methods for their handling have to be introduced. This paper shows a concept for generating role-specific descriptions based on XML.	control system;description logic;enterprise integration;enterprise software;xml	Martin Wollschlaeger;Christian Diedrich;Mario Thron	2001	ETFA 2001. 8th International Conference on Emerging Technologies and Factory Automation. Proceedings (Cat. No.01TH8597)	10.1109/ETFA.2001.997691	manufacturing execution system;use case;enterprise application integration;enterprise systems engineering;enterprise software;computer science;knowledge management;control system;software engineering;electronic data interchange;database;computer-integrated manufacturing;enterprise appliance transaction module;enterprise integration;programming language;efficient xml interchange;enterprise information system;enterprise information integration	Robotics	-50.69645596663247	17.585345022211335	31755
b3ec9cc2c1243acd95893c1709dca9f11d01b801	ontological view based semantic transformation for distributed systems	distributed system;information systems;ontologies vocabulary cybernetics usa councils finance environmental economics distributed information systems prototypes globalization artificial intelligence;semantic integration;distributed processing;vocabulary;ontological view based semantic transformation;open environment ontology semantic integration distributed systems;open distributed information systems;resource description framework;open environment;data mining;ontologies artificial intelligence;semantic heterogeneity;distributed information system;business;semantic integration ontological view based semantic transformation open distributed information systems;ontologies;humans;tv;ontologies artificial intelligence distributed processing information systems;distributed systems;ontology	This paper presents a novel ontological view-based semantic transformation method to address the semantic heterogeneity design issue of open distributed information systems. After carefully reviewing the traditional ontology definitions, this work extends the ontological view concept to represent the partial knowledge about the same business domain in an open environment where common ontology does not exist or is not explicitly represented. Solutions in mathematical formulation and corresponding application algorithms, based on the definition of an ontological view, are proposed. By dealing with structural constant and predicate heterogeneity, respectively, the solution enables the ontological views to be transformed, one to another, automatically.	algorithm;backup;business domain;concept image and concept definition;data mining;distributed computing;glossary of computer graphics;information retrieval;information system;interrupt;ontology (information science);semantic heterogeneity;web 2.0	Ying Daisy Wang;Hamada H. Ghenniwa;Weiming Shen	2009	2009 IEEE International Conference on Systems, Man and Cybernetics	10.1109/ICSMC.2009.5346661	semantic integration;computer science;knowledge management;ontology;rdf;ontology;data mining;database;information system	Robotics	-38.52399862467731	6.149873360747636	31816
ee74e3cf648d3eee70b814bfdf47f8470ccdc786	towards a reliable air traffic control	system reliability;air traffic control;software tool;agent based simulation;decision aid;agent based;socio technical system;agent based decision aided system;simulation environment	Since critical socio-technical systems include people interacting with equipments in workplaces, their intrinsic reliability problems have been concerned with both these two “actors”. Air Traffic Control (ATC) is going to be such a system in which controllers use a large number of distributed software tools to provide safety ATC services. The reliability of these services relies on the availability of the various tools. Indeed, a partial failure of a tool in use can have tragic consequences. This paper presents a multi-agent approach to this problem. We propose an agent-based decision-aided system that helps controllers in using their multiple software tools in situations where some tools are not available due to technical incidents. We build and test our system in an ATC simulation environment, thus develop an Agent-Based Simulation (ABS). Experimental work has demonstrated the significance of our system to air traffic controllers.	advanced tactical center;advanced transportation controller;agent-based model;applicative programming language;complex adaptive system;computation;conformity;critical system;distributed computing;exception handling;experiment;fault tolerance;interaction;multi-agent system;simulation;sociotechnical system;unavailability	Minh Nguyen-Duc;Zahia Guessoum;Olivier Marin;Jean-François Perrot;Jean-Pierre Briot;Vu Duong	2008		10.1145/1402795.1402814	simulation;air traffic control	Robotics	-44.45432553350479	21.817476475275136	31830
408d4b11e04760dc981c760a950debfb8d5cf1f3	application development over software-as-a-service platforms	application development;software;salesforce com;software methodologies software as a service saas application development;apex;web services software engineering;software engineering;software delivery platforms;google application engine sdk;computer architecture;internet;guidelines;business;software development;web services;software as a service platforms;application software programming enterprise resource planning companies software engineering search engines facebook buildings software design guidelines;software delivery platforms software as a service platforms web development salesforce com google application engine sdk apex facebook api;facebook api;software as a service;programming;software methodologies;web development;documentation;saas	New web development and deployment platforms are arising; some examples of these are Apex of Salesforce.com, Google Application Engine SDK, Facebook API, and so on. These software delivery platforms (SDP) are meant to serve as the basis for the delivery of an important percentage of the software offer. In the other hand, application development over these new platforms is not a defined process. Building applications over an SDP change the way software is designed, developed and delivered. Common methods of software development should be analyzed and redefined in order to fulfill the requirements of these new ways of constructing and delivering software. This paper presents the analysis of the impact of these requirements and proposes guidelines to be applied for application development in software-as-a-service (SaaS) environments.	application programming interface;definition;google app engine;requirement;software as a service;software deployment;software development kit;web development	Javier Espadas;David Concha;Arturo Molina	2008	2008 The Third International Conference on Software Engineering Advances	10.1109/ICSEA.2008.48	computer science;engineering;package development process;software development;operating system;software engineering;software as a service;management;software deployment;world wide web;goal-driven software development process;software development process	SE	-48.84648538080123	17.017417854817158	31844
fcacc98a806b43b0a1b6e3abf0d3dacbbf44838d	testing web services	web service description language;software testing;protocols;mutation analysis web service testing application to application interaction communication protocols service descriptions service discovery web protocols open xml standards web services description language wsdl;mathematics;standards;specification languages internet protocols standards xml program testing;wsdl;web and internet services;mutation analysis;application to application interaction;software systems;open xml standards;testing;web service testing;web service;universal description discovery and integration;internet;program testing;specification languages;web services;communication standards;xml;communication protocol;testing web services genetic mutations protocols xml software systems web and internet services computer science mathematics communication standards;genetic mutations;computer science;service discovery;web protocols;web services description language;communication protocols;service descriptions	Summary form only given. Web services present a promising software technology, which provides application-to-application interaction. They are based on communication protocols, service descriptions, and service discovery and are built on top of existing Web protocols and based on open XML standards. Web services are described using Web Services Description Language (WSDL), and the universal description, discovery, and integration directory provide a registry of Web services descriptions. Testing Web services is important for both the Web service provider and the Web service user. This paper proposes a technique for testing Web services using mutation analysis. The technique is based on applying mutation operators to the WSDL document in order to generate mutated Web service interfaces that are used to test the Web service. For this purpose, we define mutant operators that are specific to WSDL documents. Our empirical results have shown the usefulness of this technique.	directory (computing);mutation testing;service discovery;web services description language;web services discovery;web service;world wide web;xml	Reda Siblini;Nashat Mansour	2005	The 3rd ACS/IEEE International Conference onComputer Systems and Applications, 2005.	10.1109/AICCSA.2005.1387124	web service;web application security;communications protocol;web development;web modeling;data web;web mapping;web design;web standards;computer science;operating system;software engineering;ws-policy;web navigation;social semantic web;web page;data mining;ws-addressing;database;ws-i basic profile;web 2.0;world wide web;devices profile for web services;universal description discovery and integration;web testing;web coverage service	Web+IR	-46.266703783803926	17.764996044218933	31926
69cf246f34e9dbcb3d289d073e833fea03b60b4e	ontology in information security: a useful theoretical foundation and methodological tool	formal specification;information security;first order;human factors;natural language;theory;efficiency measurement;theoretical foundation;security;languages;natural language processing;standardization;documentation	The paper introduces and advocates an ontological semantic approach to information security. Both the approach and its resources, the ontology and lexicons, are borrowed from the field of natural language processing and adjusted to the needs of the new domain. The approach pursues the ultimate dual goals of inclusion of natural language data sources as an integral part of the overall data sources in information security applications, and formal specification of the information security community know-how for the support of routine and time-efficient measures to prevent and counteract computer attacks. As the first order of the day, the approach is seen by the information security community as a powerful means to organize and unify the terminology and nomenclature of the field.	floor and ceiling functions;formal specification;information security;lexicon;natural language processing	Victor Raskin;Christian Hempelmann;Katrina E. Triezenberg;Sergei Nirenburg	2001		10.1145/508171.508180	computer security model;natural language processing;documentation;computer science;information security;information security standards;data mining;formal specification;database;natural language;computer security;theory;standardization	Security	-57.4220065322823	20.942072947745995	31947
12e87b485c3b52a85432f535a1a22b233bf1fe20	towards robust service compositions in the context of functionally diverse services	service composition;service selection;multi objective optimization;qos aware service composition;adaptive workflow;decision maker;non functional requirement;web service composition;risk preference;functional diversity;robustness;quality of service;optimal algorithm;service computing	Web service composition provides a means of customized and flexible integration of service functionalities. Quality-of-Service (QoS) optimization algorithms select services in order to adapt workflows to the non-functional requirements of the user. With increasing number of services in a workflow, previous approaches fail to achieve a sufficient reliability. Moreover, expensive ad-hoc replanning is required to deal with service failures. The major problem with such sequential application of planning and replanning is that it ignores the potential costs during the initial planning and they consequently are hidden from the decision maker. Our basic idea to overcome this substantial problem is to compute a QoS optimized selection of service clusters that includes a sufficient number of backup services for each service employed. To support the human decision maker in the service selection task, our approach considers the possible repair costs directly in the initial composition. On the basis of a multi-objective approach and using a suitable service selection interface, the decision maker can select compositions in line with his/her personal risk preferences.	algorithm;automated planning and scheduling;backup;functional requirement;hoc (programming language);mathematical optimization;non-functional requirement;quality of service;service composability principle;web service	Florian Wagner;Benjamin Klöpper;Fuyuki Ishikawa;Shinichi Honiden	2012		10.1145/2187836.2187966	service level requirement;service level objective;decision-making;mobile qos;quality of service;service product management;differentiated service;computer science;knowledge management;service delivery framework;multi-objective optimization;data mining;database;services computing;programming language;data as a service;non-functional requirement;robustness	Web+IR	-46.14222888868028	15.838786922536944	31964
1d9c08e0c3bbb4f655d979768b96e21a20bfd2b5	an automated software design assistant	coupling;concepcion asistida;computer aided design;structured software design;metodologia;classification hierarchisee;quantitative measures;hierarchic classification;ingenieria logiciel;automatic programming;indexing terms;satisfiability;couplage;software engineering;methodologie;modulo programa;software engineering environment;groupement;cohesion;structured programming automatic programming software tools;acoplamiento;clustering;automated software design assistant;system design;software design process design software tools software measurement design methodology software engineering particle measurements application software information management;structured programming;computer aid;genie logiciel;conception assistee;asistencia ordenador;software tools;structured software design software tools automated software design assistant software engineering environment quantitative measures;agrupamiento;methodology;software design;module programme;clasificacion jerarquizada;structural design;assistance ordinateur;decision rule;program module	An automated software design assistant was implemented as a part of a long-term project with the objectives of applying the computer-aided technique to the tools in a software engineering environment. A set of quantitative measures are derived based on the degree to which a particular design satisfied the attributes associated with a structured software design. The measure are then used as decision rules for a computer-aided methodology for structured design. The feasibility of the approach is also demonstrated by a case study using a small application system design problem. >		Jahangir Karimi;Benn R. Konsynski	1988	IEEE Trans. Software Eng.	10.1109/32.4638	connascence;iterative design;verification and validation;index term;software sizing;computer science;systems engineering;software design;software reliability testing;component-based software engineering;software development;software design description;cohesion;operating system;object-oriented design;computer aided design;software engineering;software construction;methodology;decision rule;cluster analysis;coupling;programming language;structured programming;computer-aided software engineering;structured analysis;software development process;software requirements;software metric;software system;computer engineering;satisfiability;systems design	SE	-61.04219654143514	28.64125761612304	31965
462802086efea755161f8cb7acfec1f3ac17359a	holonic management system for hierarchical robot groups	hierarchical robot groups;holonic management system;management system	This paper introduces a management system for robot groups with “holonic architecture” which is one of distributed and hierarchical system architectures. In order to manage collaboration of many robots, we put sub-management system on each work sub-space. A management system on a subspace divides a task given by upper space into some sub-tasks and gives lower sub-spaces those sub-tasks. With this architecture we obtain distributed and hierarchical management system for the whole work space. We made a demonstration system and showed an example of task division and execution.	holon (philosophy);management system;robot	Yasumichi Aiyama	2002			systems engineering;knowledge management;operations management	Robotics	-52.54775470516621	13.665651480956141	31979
0674e476a2903d3629c062704b7df4627f5c62a1	requirements uncertainty in a software product line	software;control systems;software engineering formal verification large scale systems risk management;uncertainty;risk mitigation complex system requirement uncertainty analysis software development gas turbine engine control systems rolls royce critical design review software product line;articulo;risk management;requirements uncertainty in a software product line;uncertainty engines software risk management control systems context turbines;software engineering;requirements;formal verification;engines;software product lines requirements uncertainty;context;software product lines;turbines;large scale systems	A complex system's requirements almost always remain uncertain late into its software development. In gas turbine engine control systems at Rolls-Royce, for a traditional project (non-product line) typically 50% of requirements will change between Critical Design Review and Entry into Service. Requirements uncertainty is particularly relevant when defining the scope of a Software Product Line. If the core asset team fails to recognise or accommodate requirements uncertainty, changes will manifest later in the product line. If the core asset team over-compensates by adding too much functionality or variability to account for a wide range of uncertainty, they will invest effort that may never be required. The optimal balance can be found through an application of requirements uncertainty analysis and understanding the balance between the impact of risk and mitigation effort. This paper first describes the use of the requirements uncertainty analysis technique at Rolls-Royce for traditional (non-product line) software development and then explains how this technique works in the context of a software product line.	complex system;control system;customer relationship management;design review (u.s. government);requirement;rework (electronics);risk management;software development;software product line;spatial variability;systems engineering;while;winston w. royce	Andy J. Nolan;Silvia Mara Abrahão;Paul C. Clements;Andy Pickard	2011	2011 15th International Software Product Line Conference	10.1109/SPLC.2011.13	reliability engineering;requirements analysis;software requirements specification;requirements management;requirement prioritization;uncertainty;risk management;business requirements;formal verification;computer science;systems engineering;engineering;operations management;requirement;software engineering;non-functional testing;management	SE	-61.812412062000945	20.813202953060166	32027
242fff344fe7a6eca597f00232bc990821d4d466	the sparql query graph model for query optimization	query language;query processing;query optimization;semantic web;world wide web;graph model	The Semantic Web community has proposed several query languages for RDF before the World Wide Web Consortium started to standardize SPARQL. Due to the declarative nature of the query language, a query engine should be responsible to choose an efficient evaluation strategy. Although all RDF repositories provide query capabilities, some of them require manual interaction to reduce query execution time by several orders of magnitude. In this paper, we propose the SPARQL query graph model (SQGM) supporting all phases of query processing. On top of the SQGM we defined transformations rules to simplify and to rewrite a query. Based on these rules we developed heuristics to achieve an efficient query execution plan. Experiments illustrate the potential of our approach.	consortium;heuristic (computer science);query language;query optimization;query plan;rewrite (programming);run time (program lifecycle phase);sparql;semantic web;world wide web	Olaf Hartig;Ralf Heese	2007		10.1007/978-3-540-72667-8_40	online aggregation;sargable;query optimization;query expansion;web query classification;ranking;boolean conjunctive query;computer science;sparql;query by example;semantic web;database;rdf query language;web search query;view;world wide web;information retrieval;query language;object query language;spatial query	DB	-35.313903750941044	4.775319094422077	32049
f181d345cfe82d9853ad027ab0568f617b3bb3f9	multiagent systems: an emerging subdiscipline of ai	multiagent system;intelligence artificielle;ingenieria logiciel;software engineering;genie logiciel;artificial intelligence;inteligencia artificial;sistema multiagente;communication;comunicacion;systeme multiagent	As more AI applications are being formulated in terms of spatially, functionally, or temporally distributed processing, multiagent systems (or what was previously called distributed AI) are emerging as an important subdiscipline of AI. This is especially true as the outlines of a potential model for computing in the next century are beginning to coalesce: a model in which networks of interacting, real-time, intelligent agents could seamlessly integrate man and machine. Agents in these networks need to be highly adaptive due to their “open” operating environments, where the configuration and capabilities of other agents and network resources would change dynamically. Agents in such environments would aim to produce the best possible result given their available processing, communication, and information resources. As part of this model, we see agents eventually using high-level content languages for rich and succinct communication with other agents. Consequently, problem solving for effectively interacting with other agents would be as, or more, complex than the agent’s domain problem solving. The current set of multiagent applications can be classified into three broad areas. Distributed situation assessment applications, such as distributed network diagnosis, emphasize how (diagnostic) agents with different spheres of awareness and control (network segments) should share their local interpretations to arrive at consistent and comprehensive explanations and responses. Distributed resource planning and allocation applications, such as distributed factory scheduling, emphasize how (scheduling) agents (associated with each workcell) should coordinate their schedules to avoid and resolve conflicts over resources and to maximize system output. Distributed expert systems applications, such as concurrent engineering, emphasize how agents negotiate over collective solutions (designs) given their different expertise and criteria. The next generation of applications alluded to will probably involve all the emphases of these generic applications and more. In general, multiagent systems are computational systems in which several semi-autonomous agents interact or work together to perform some set of tasks or satisfy some set of goals. These systems may involve computational agents that are homogeneous or heterogeneous and they may involve activity on the part of agents having common goals or goals that are distinct. Research and practice on these systems generally focus on problem solving, communication, and coordination aspects, as distinct from low-level parallelization or synchronization issues that are more the focus of distributed computing. The design, implementation, and assessment of multiagent systems raise many specific issues. These include coordination strategies that enable groups of agents to solve problems effectively; negotiation mechanisms that serve to bring a collection of agents to an acceptable state; techniques for conflict detection	agent-based model;applications of artificial intelligence;autonomous robot;computation;distributed artificial intelligence;distributed computing;enterprise resource planning;expert system;file synchronization;high- and low-level;intelligent agent;interaction;multi-agent system;next-generation network;null (sql);operating environment;parallel computing;problem solving;real-time clock;scheduling (computing);semiconductor industry	Victor R. Lesser	1995	ACM Comput. Surv.	10.1145/212094.212121	simulation;computer science;artificial intelligence;operations research	AI	-38.87424278663608	19.313558950045852	32050
ccac594114260a3e1987edf1f7ed05dce9d65a6b	knowledge recommendation method for concept development of manufacturing technology using morphological similarity		Concept development is the first and most knowledge-intensive step in the development process of manufacturing technology. Its core is to find a solid scientific foundation for the manufacturing requirements in order to propose a feasible manufacturing technology concept. However, the lack of formal methods and finiteness of personal knowledge result in high randomness and low efficiency of this step. This paper presents a formal design knowledge recommendation method for manufacturing technology concept development by calculating the morphological similarity between manufacturing requirements and multi-domain effect knowledge. In this method, the morphological matrix of general manufacturing technology is constructed first as a template. Then, manufacturing requirements and multi-domain effect knowledge are both expressed as matrices based on this template. Finally, through quantitatively calculating the normalized weighted Euclidean distance between manufacturing requirements and multi-domain effect kno...		Junhao Geng;Sumei Zhang;Wei Hui	2018	International Journal of Software Engineering and Knowledge Engineering	10.1142/S0218194018500328	data mining;design knowledge;randomness;computer science;personal knowledge base;formal methods;euclidean distance;matrix (mathematics)	SE	-44.245347868462325	6.62387899453836	32087
fa840a29bf181e60c9b6c30000a821e3c5997b72	simple life-events ontology in su(m)o-kif	distributed system;administracion electronica;ontologie;systeme reparti;ingenierie connaissances;administration publique;proof of concept;sistema repartido;administration electronique;electronic government;ontologia;civil service;administracion publica;domain ontology;ontology;life event;public administration;knowledge engineering	This paper presents a proof-of-concept research into building an ontology of life-events in public administration and integration of this domain ontology with standard upper ontology. SUMO was chosen to be the upper ontology and SUO-KIF the language of both upper and domain ontology.	knowledge interchange format;ontology (information science);upper ontology	Bostjan Bercic;Mirko Vintar	2004		10.1007/978-3-540-24683-1_14	upper ontology;ontology inference layer;computer science;artificial intelligence;knowledge engineering;ontology;public administration;proof of concept;suggested upper merged ontology	AI	-38.16452209371686	12.641982974631198	32175
406d0a33a7016e0f18453c63c8e2ea1c050bcbfe	facilitating cloud process family co-evolution by reusable process plug-in: an open-source prototype	期刊论文;cloud computing companies prototypes logistics open source software;article;evolution process family business process model pattern semantic annotation bpm prototype aspect oriented programming process graph	In a business cloud environment, a reference business process model needs to be customized in order to meet the individualized requirements of each organization. Consequently, a reference process model is generally evolved to a couple of process variants, known as a process family. Currently, there exist some approaches and tools that can efficiently configure a reference process model. However, a key issue is how to manage co-evolution appropriately within a family of process models if the base process model of a process family is changed. Contemporary process management tools do not adequately support the management of such co-evolution. Each process variant in the process family has to be changed as a separate process model which often leads to redundancies and inefficiencies. In this article, we propose a novel approach for managing co-evolution of process families based on an aspect-oriented approach. Change options on base process model are abstracted and extracted as a pluggable component, which can be selectively reused for all members, and consequently, guides the co-evolution for the whole process family. In particular, the control-flow and data-flow relations between process extension and a member of process families can be built by leveraging process extensibility patterns. The correctness of our extension approach is proved based on graph theory. The whole approach in this article have been implemented as a working open-source prototype and tested against a real case study from the city logistic distribution domain as well as real data set from SAP reference models.	aspect-oriented software development;business process;control flow;correctness (computer science);dataflow;evolution;existential quantification;extensibility;graph theory;norm (social);open-source software;process modeling;prototype;requirement	Zaiwen Feng;Dickson K. W. Chiu;Rong Peng;Ping Gong;Keqing He;Yiwang Huang	2017	IEEE Transactions on Services Computing	10.1109/TSC.2015.2504973	data mining;systems engineering;business process management;reference model;database;cloud computing;business process modeling;correctness;plug-in;computer science;process modeling;extensibility	Visualization	-53.63093738578362	18.311052410261397	32190
8637fc033e1aedc9e5476ed27dd334380e32924f	trends in manufacturing execution systems		Today’s manufacturing plants are equipped with heterogeneous software systems for different types of tasks, both manufacturing operations and factory planning. On the operating level software systems are neither yet integrated and thus support separate tasks such as production monitoring, sequence planning, work piece identification, maintenance order management, worker information and others. Nor are MES-systems parts of the integrated industrial engineering chain from mechanical engineering, electrical engineering, PLC-programming to operations. Today information technology becomes the main enabler for new processes and structures in manufacturing and logistics. In this paper the author presents six relevant trends for MES-systems, derived from actual R&Dprojects with industrial partners. The mentioned trends are illustrated by examples from projects.	electrical engineering;industrial engineering;logistics;manufacturing execution system;order management system;power-line communication;software system	Olaf Sauer	2009		10.1007/978-3-642-10430-5_53	integrated computer-aided manufacturing;process development execution system;manufacturing operations;engineering;operations management;industrial engineering;computer-integrated manufacturing;production engineering;manufacturing engineering	Robotics	-61.24697372734977	8.58065823315106	32203
aab66e4f643a47af2e0026c0539fe9c625ec00a7	model-based requirements engineering for data warehouses: from multidimensional modelling to kpi monitoring		A Data Warehouse (DW) is one of the main components of every BI system. It has been convincingly argued that the success of BI projects can be strongly affected by the Requirements Engineering (RE) phase, when the requirements of a DW are captured. Multiple RE methods for DWs have been proposed which have goal models in the core of their approach. Existing methods cover RE up to the static part of a DW, where the Multidimensional (MD) model is obtained. However, the RE for the dynamic part of the DW, where the requirements of operations on the DW are captured, has been neglected in the literature. In this paper, we propose a RE method, covering both the static and the dynamic part of a DW in an integrated manner. Our approach is to use the concept of a Key Performance Indicator (KPI). We initially use KPIs as the main driver to obtain the MD model and then discuss how decision-makers analyse them in order to measure the success of an organisation. In our method, the goal model from the i* framework was extended with UML use case diagrams.	diagram;dreamwidth;interaction design;molecular dynamics;requirement;requirements engineering;unified modeling language;use case diagram	Azadeh Nasiri;Robert Wrembel;Esteban Zimányi	2015		10.1007/978-3-319-25747-1_20	data mining;database	SE	-57.85486120143563	19.717346145666514	32219
4fb01d4b2f80ede62c747dec9e7b32459b6b5a21	a process algebra software engineering environment	software development process;software engineering;universiteitsbibliotheek;software engineering environment;process algebra	In previous work we described how the process algebra based language PSF can be used in software engineering, using the ToolBus, a coordination architecture also based on process algebra, as implementation model. In this article we summarize that work and describe the software development process more formally by presenting the tools we use in this process in a CASE setting, leading to the PSF-ToolBus software engineering environment. We generalize the refine step in this environment towards a process algebra based software engineering workbench of which several instances can be combined to form an environment. Ke ywords: process algebra, software engineering, software architecture, workbench, environment	code refactoring;complex systems;computer-aided software engineering;documentation;process calculus;simulation;software architecture;software development process;software engineering;software system;workbench	Bob Diertens	2008	CoRR		personal software process;verification and validation;process calculus;software engineering process group;software sizing;search-based software engineering;computer science;systems engineering;engineering;package development process;software design;social software engineering;component-based software engineering;software development;software engineering;software construction;software walkthrough;empirical process;resource-oriented architecture;computer-aided software engineering;goal-driven software development process;software development process;software requirements;software system;computer engineering	SE	-51.735127968635645	27.188562893520196	32224
579b7e3707d93464d48adc5d41d486a52cb84aa5	formal modelling of environment restrictions from natural-language requirements		When creating system models, further to system behaviour one should take into account properties of the environment in order to achieve more meaningful models. Here, we extend a strategy that formalises data-flow reactive systems as CSP processes to take into account environment restrictions. Initially, these restrictions are written in natural language. Afterwards, with the aid of case-grammar theory, they are formalised by deriving LTL formulae automatically. Finally, these formulae are used to prune infeasible scenarios from the CSP-based system specification, in the light of the environment restrictions. Considering examples from the literature, and from the aerospace (Embraer) and the automotive (Mercedes) industry, we show the efficacy of our proposal in terms of state space reduction, up to 61% in some cases.	natural language;requirement	T. Santos;Gustavo Carvalho;Augusto Sampaio	2018		10.1007/978-3-030-03044-5_16	programming language;natural language;linear temporal logic;state space;automotive industry;communicating sequential processes;computer science;system requirements specification;reactive system;aerospace	AI	-41.48766445508207	29.077546416715126	32228
e1a53df0da5364f2a56e77cbbd5a87dfe07c412f	model-driven development of real-time software based on omg standards	real time software modeling;software testing;software verification;real time;program verification;software testing model driven development method real time software modeling omg standards software verification computer numerical controller;software standards standards development real time systems unified modeling language system software costs system testing automatic testing educational institutions application software;model driven development;software architecture;model driven development method;unified modeling language computerised numerical control distributed object management program testing program verification real time systems software architecture software standards;computerised numerical control;program testing;distributed object management;unified modeling language;computer numerically controlled;software standards;computer numerical controller;omg standards;real time systems	Model-driven development method centers on software modeling and primary artifacts designing instead of traditional method, which centers on codes. This can promote the abstract layer from code level to model level and implement the testing and verification of real-time system function in model level. It can help to solve the disaccord between models and codes, the disjointed problem of real-time in the traditional methods. The application of model-driven development method in computer numerical controller is verified	code;model-driven architecture;model-driven engineering;model-driven integration;modeling language;numerical analysis;real-time clock;real-time computing;real-time transcription;sms language;software development;unified modeling language	Junli Gao;Di Li;Shixiong Zheng	2006	First International Conference on Innovative Computing, Information and Control - Volume I (ICICIC'06)	10.1109/ICICIC.2006.471	unified modeling language;software architecture;real-time computing;software verification;computer science;software testing;programming language	SE	-48.74403729330901	31.25524128192635	32286
0d8089d1d3415f76f807e33cd9222927cc238164	bridge construction schedule generation with pattern-based construction methods and constraint-based simulation	constraint based simulation;process pattern;product model;3d model;level of detail;monte carlo method;construction method;manufacturing industry;process model;schedule generation;discrete event simulation	This paper presents a novel methodology which assists in automating the generation of time schedules for bridge construction projects. The method is based on a simulation of construction works, taking into account the available resources and the interdependencies between individual tasks. The simulation is realized by means of a discrete-event simulation software originally created for plant layout in the manufacturing industry. Due to the fact that the fixed process chains provided are too rigid to model the spontaneous construction task sequences, a constraint module that dynamically selects the following task has	3d modeling;constraint (mathematics);executable;interdependence;level of detail;process modeling;process patterns;refinement (computing);requirement;schedule (computer science);scheduling (computing);simulation software;spontaneous order	I-Chen Wu;André Borrmann;Ulrike Beißert;Markus König;Ernst Rank	2010	Advanced Engineering Informatics	10.1016/j.aei.2010.07.002	simulation;computer science;engineering;artificial intelligence;discrete event simulation;level of detail;process modeling;manufacturing;engineering drawing;statistics;monte carlo method	Logic	-56.54407893198724	13.445247445214834	32289
bb0257a3e61dd9f72c122e9356b674a8b4ee6260	workflow management for enterprise transformation	workflow support;enterprise transformation;business process management;selected workflow concept;workflow pattern;workflow adaptation;modern enterprise information technology;workflow data mining;modern workflow management system;workflow management	Workflow management is a core component of modern enterprise information technology infrastructure that automates the execution of critical business processes. Since enterprise transformation typically introduces changes to the corresponding business processes, it is important for modern workflow management systems to provide effective support for seamless incorporation of these changes. In this paper, we examine a collection of selected workflow concepts and techniques that are significant for dealing with transformational changes. Especially, we will focus on notions and techniques that are directly relevant to enterprise transformation, such as workflow patterns, workflow adaptation, and workflow data mining and merging. We also include a short summary of business process management, the fundamental concepts of workflow management, and a discussion of workflow support for enterprise transformation to keep the paper self-contained.	business process;data mining;legacy system;modeling language;process modeling;seamless3d;side effect (computer science);software deployment;workflow pattern	James Caverlee;Joonsoo Bae;Qinyi Wu;Ling Liu;Calton Pu;Willian Bill Rouse	2007	Information, Knowledge, Systems Management		workflow;xpdl;enterprise software;computer science;systems engineering;knowledge management;business process management;workflow management coalition;document management system;database;enterprise data management;event-driven process chain;enterprise integration;workflow management system;workflow engine;enterprise information system;enterprise life cycle;workflow technology	DB	-56.313864461446634	18.203178429396647	32302
619d7b62ebb9866d8f6d46304b47cd42cfaccaf8	agents and their cities	internet access;test bed;large scale;agent technology;agent systems	The interactive Web seems a natural place for the use of agent technology, to bring access to e-services with solutions to dynamic, open and changing environments. However, agent technology is still quite low key in this expanding area of Internet access and e-business space. Part of the reason for this has been the lack of a large-scale test-bed. Some fundamental changes in the development of agent systems have helped to move the research into the area of directly addressing high-level interoperability: emergence of a standard, availability of many agent systems for interoperability testing, better understanding of agent infrastructure, etc. In this paper we look at the developments of agent technology and the challenges, which will enable agent technology to play a key role in the Internet space. This paper describes the design of high-level interoperable agent services through the concept of Agentcities, its motivations, drivers and its implementation. Finally, the key challenges to be addressed to make this initiative a success are evaluated.	e-services;electronic business;emergence;high- and low-level;internet access;interoperability;testbed	Patricia Charlton;David Bonnefoy;Nicolas Lhuillier	2002			simulation;internet access;computer science;knowledge management;computer security;intelligent agent;testbed	HCI	-44.42538787304494	19.585819307565032	32325
a84c55302792cf48a00e0f8dddfb50a6207b7776	recovering three-level architectures from the code of open-source java spring projects (s)		Despite the well-admitted benefits of keeping design decisions as a documentation all along the lifecycle of software, many software projects have lost this information. In order to use design information to guide software maintenance and evolution, this paper proposes to retro-engineer architecture descriptions from source code. The originality of this work is to target a three-leveled architecture description language which represents software specification , configuration and deployment. Retro-engineering these three levels will provide a more precise source of guidance for the maintenance of software. Targeted projects are open-source Java projects that use Spring to describe the implemented architecture.	java;spring framework	Alexandre Le Borgne;David Delahaye;Marianne Huchard;Christelle Urtado;Sylvain Vauttier	2018		10.18293/SEKE2018-140	software deployment;systems engineering;component-based software engineering;computer science;architecture description language;software requirements specification;source code;software;model-driven architecture;software maintenance	SE	-54.676484073729426	28.207745162062213	32350
c1baaace0ba1dac79c015ab6c03947314521e6b9	ontology enhanced concept hierarchies for text identification	sw;hierarchy of concepts;text identification;semantic web;concept hierarchy;ontology	The Internet holds huge amount of documents available for users. Effective utilization of this enormous repository means a need for systems supporting users in a process of finding related documents. An ontology defined in the framework of the Semantic Web (Berners, 2001) allows for specification of concepts, their instances, and relationships existing between concepts. A hierarchy of concepts (Yager, 2000) is a graph-like structure providing a means for representing human-like dependencies. The article proposes an approach for utilization of a hierarchy of concepts to perform categorization of web pages in the Semantic Web. A user provides a hierarchy that can only partially “cover” their domain of interest. The hierarchy is treated as a “seed” representing user’s initial knowledge about the domain. Ontologies are treated as supplementary knowledge bases. They are used to instantiate the hierarchy with concrete information, as well as to enhance it with new concepts initially unknown to a user.	categorization;internet;knowledge base;ontology (information science);random seed;semantic web;web page	Marek Reformat;Ronald R. Yager;Zhan Li	2008	Int. J. Semantic Web Inf. Syst.	10.4018/jswis.2008070102	upper ontology;epistemology;computer science;knowledge management;semantic web;ontology;data mining;database;world wide web;information retrieval	Web+IR	-42.18356273339929	8.191794322890459	32363
5f8a1bb335707e924f5dae7969d3a3f0fe1077b4	onto-pdm: product-driven ontology for product data management interoperability within manufacturing process environment	iso 10303;product data management;enterprise integration and networking;interoperability;ontology;iec 62264	This paper proposes an approach for facilitating systems interoperability in a manufacturing environment. It is based on the postulate that an ontological model of a product may be considered as a facilitator for interoperating all application software that share information during the physical product lifecycle. The number of applications involved in manufacturing enterprises may in fact refer to the knowledge that must be embedded in it, appropriately storing all its technical data based on a common model. Standardisation initiatives (ISO and IEC) try to answer the problem of managing heterogeneous information scattered within organizations, by formalising the knowledge related to product technical data. The matter of this approach is to formalise all those technical data and concepts contributing to the definition of a Product Ontology, embedded into the product itself and making it interoperable with applications, thus minimising loss of semantics.	embedded system;enterprise software;information exchange;interoperability;microelectromechanical systems;norm (social);ontology (information science);relevance;traceability;universal instantiation;web ontology language	Hervé Panetto;Michele Dassisti;Angela Tursi	2012	Advanced Engineering Informatics	10.1016/j.aei.2011.12.002	interoperability;computer science;systems engineering;engineering;knowledge management;product lifecycle;product design specification;ontology;database;product management;product engineering	DB	-49.558631205913024	10.731492521296921	32368
7e059fe3c90bd473b88c2da6ce36f36e2f42ec41	using industry-grade test equipment in a digital test and product engineering lab course	industry grade automatic test equipment;microcontrollers;embedded systems testing;random access memory;critical thinking skills;circuit faults;labs;embedded systems testing digital systems test engineering labs hands on learning critical thinking skills;automatic test equipment;industries;testing;engineering education automatic test equipment educational courses;product engineering lab course;test engineering industry grade automatic test equipment digital testing product engineering lab course digital core courses;digital systems;educational courses;engineering education;testing circuit faults microcontrollers random access memory timing industries programming;digital testing;digital core courses;test engineering;hands on learning;programming;timing	This paper presents a new digital test and product engineering course targeted to undergraduate seniors and master's-level graduate students. Through industrial guided labs, students were able to gain hands-on experience using an industry-grade automatic tester (ATE). Students indicated that the course provided an integration of many of the concepts from their digital core courses, and contributed to the development of skills essential to careers in test engineering or elsewhere.	automatic taxonomy construction;built-in test equipment;experience;hands-on computing;problem solving;product engineering;turing test	Christopher Miller;Tina A. Hudson;Shannon Sipes	2015	2015 IEEE International Conference on Microelectronics Systems Education (MSE)	10.1109/MSE.2015.7160006	microcontroller;embedded system;automatic test equipment;programming;simulation;engineering education;computer science;engineering;electrical engineering;software engineering;software testing;experiential education;computer engineering	Robotics	-54.57254613355904	4.827194681261177	32377
8767affbd27adacd9d40ce8080a15d7503bbffac	an mbse framework to support agile functional definition of an avionics system		In avionics domain, there have been many efforts in recent years to build a MBSE methodology with tooling support. The main purpose is often to improve quality and efficiency of system definition, architecture and integration. Sometimes there is also an additional objective to ease system verification and validation. This paper introduces an additional challenge with the support of an agile development cycle to ease impact analysis and incorporation of late and changing requirements at different times. It presents key principles and requirements of an agile MBSE approach and presents associated modeling activities with illustration on an avionics case study.	agile software development;avionics	Jian Tang;Shaofan Zhu;Raphaël Faudou;Jean-Marie Gauthier	2018		10.1007/978-3-030-04209-7_14	avionics;verification and validation;systems engineering;architecture;agile software development;computer science	Robotics	-57.017850047783895	26.08852716151798	32435
1db206a117d2a341b34f38b4e8d579041fcba18d	visual interactive systems for end-user development: a model-based design methodology	life cycle;interactive systems design methodology geology software systems humans computer science software tools mechanical engineering software design user centered design;end user development;user interface;visual interaction;software systems;user centered design;mechanical engineering;visual languages;software artifacts;human factors;interactive system;visual interactive systems;work organization;visual language;software environment design;user interfaces interactive systems user centred design;user centred design;participatory design;visual languages design methodology user centered design user interface human factors;model based design;interactive systems;user interfaces;software environment design visual interactive systems end user development model based design software artifacts;user interface human factors;design methodology	This paper is about the development of systems whose end users are professional people working in a specific domain (e.g., medicine, geology, mechanical engineering); they are expert in that domain, but not necessarily expert in nor even conversant with computer science. In several work organizations, end users need to tailor their software systems to better adapt them to their requirements and even to create or modify software artifacts. These are end-user development activities and are the focus of this paper. A model of the interaction between users and systems, which also takes into account their reciprocal coevolution during system usage, is discussed. This model is used to define a methodology aimed at designing software environments that allow end users to become designers of their own tools. The methodology is illustrated by discussing two experimental cases.	computer science;end-user development;interactivity;requirement;software system	Maria Francesca Costabile;Daniela Fogli;Piero Mussio;Antonio Piccinno	2007	IEEE Transactions on Systems, Man, and Cybernetics - Part A: Systems and Humans	10.1109/TSMCA.2007.904776	human–computer interaction;computer science;human factors and ergonomics;multimedia;subject-matter expert;user interface;model-based design	SE	-50.06112418655551	20.854191947668955	32489
0cb38f9b6ffc07d86b5ccea0bf26e9f3b7f7d3c4	application of pattern recognition techniques to fault tolerant software systems	fault tolerant;application software;application software pattern recognition fault tolerant systems software systems fault detection resource management estimation error system testing software design software engineering;resource management;software systems;software engineering;fault tolerant systems;fault detection;pattern recognition;system testing;estimation error;software design;system simulation	Inference techniques are applied to computing systems to improve the allocation of resources for fault tolerant performance. Using a general model for such systems, the influence of estimation errors for system parameters on the resulting system fault performance is examined. These results are then applied to the problem of error mode testing-finding the underlying error structure of the system. Simulation is used to illustrate the properties discussed.	fault-tolerant software;pattern recognition;software system	Stephen D. Shapiro	1979		10.1109/CMPSAC.1979.762599	reliability engineering;fault tolerance;application software;real-time computing;fault coverage;computer science;software design;software reliability testing;resource management;software engineering;software construction;software testing;life-critical system;system testing;fault detection and isolation;software fault tolerance;software system;computer engineering	Vision	-61.90217079704836	32.0637817162831	32535
357c470b9e553c6a0b9390785691329c34320699	matelo - statistical usage testing by annotated sequence diagrams, markov chains and ttcn-3	markov chain markup language matelo statistical usage testing annotated sequence diagram ttcn 3 time critical system system testing mcum markov chain usage model fdt formal description testing and test control notation version 3 test case definition specification based testing itu t msc message sequence chart nonfunctional requirement automated software testing real time system xml based representation format mcml;software testing;formal specification;specification based testing;automatic generation;non functional requirement;formal description technique;message sequence chart;critical system;program testing;statistical testing program testing formal specification xml software tools markov processes real time systems;software testing system testing automatic testing logic testing software quality application software mobile communication unified modeling language computer science time factors;xml;case definition;software tools;statistical testing;markov processes;markup language;sequence diagram;internal standard;real time systems;markov chain	In this paper, we present a general framework for testing time-critical systems and software, as it is proposed in the European IST project MaTeLo. The main focus is on automatically generating a MCUM (Markov chain usage model) starting from an FDT (formal description technique) description in order to derive TTCN-3 (testing and test control notation version 3) compatible test case definitions. Our approach is a combination of statistical usage testing based on a given MCUM and specification-based testing that is using FDT inputs. Within MaTeLo, special attention is given to international standardized FDT notations, specifically ITU-T MSC (message sequence chart). In addition, we make use of annotations to specify selected non-functional requirements to support the automated software testing of the real time systems. We also defined an XML-based representation format called MCML (Markov chain Markup Language) to build a common interface between various parts of the MaTeLo tool set.	functional requirement;markov chain;markup language;message sequence chart;non-functional requirement;powerflasher fdt;sequence diagram;software testing;ttcn-3;test automation;test case;window of opportunity;xml	Winfried Dulz;Fenhua Zhen	2003	Third International Conference on Quality Software, 2003. Proceedings.	10.1109/QSIC.2003.1319119	sequence diagram;markov chain;statistical hypothesis testing;xml;computer science;theoretical computer science;software engineering;formal specification;internal standard;database;software testing;markup language;case definition;markov process;programming language;non-functional requirement;message sequence chart	SE	-46.620583336720685	30.976164221128457	32560
b8743757b6bb7d12dae00a0e86cf7d2c356b5436	polynomial-time reasoning for semantic web service composition	semantic web service;web service matching;polynomial time reasoning;background ontology;ontology modelling constructs;inference mechanisms;web service;ontologies artificial intelligence;web services inference mechanisms ontologies artificial intelligence semantic web;polynomials semantic web ontologies web services artificial intelligence application software owl context aware services logic mediation;ontology modelling constructs polynomial time reasoning semantic web service composition worst case exponential reasoning background ontology web service matching polynomial time methods;web services;polynomial time;semantic web;semantic web service composition;polynomial time methods;worst case exponential reasoning;ontology matching	Automatic composition of semantic Web services should make use of the ontology in which the services are specified. While the approaches can strongly benefit from doing so, they have to deal with the frame and ramification problems, necessitating worst-case exponential reasoning even to determine the outcome of applying a single Web service. The existing approaches to composition either ignore the background ontology, matching Web services based on concept names and hence removing the need for reasoning; or they employ full-scale reasoning and suffer from the unavoidable performance deficiencies. In our work, we instead look for interesting classes of ontologies where the required reasoning is polynomial. We define a formalism for semantic Web service composition. We present polynomial-time methods for dealing with several of the most commonly used ontology modelling constructs; further extensions are possible. We prove that our methods are correct. We are currently developing an implementation of our techniques.	best, worst and average case;full scale;ontology (information science);ontology alignment;polynomial;ramification problem;semantic web service;semantics (computer science);service composability principle;time complexity	Jörg Hoffmann;James Scicluna;Tomasz Kaczmarek;Ingo Weber	2007	2007 IEEE Congress on Services (Services 2007)	10.1109/SERVICES.2007.51	knowledge representation and reasoning;computer science;social semantic web;data mining;database;reasoning system;world wide web;owl-s	AI	-44.29753197176244	14.48024615125956	32716
8f42b32a91422d1b9bd6dd0fc951d59403a52d89	transformation of a library catalogue into rda linked open data		The 200,000 records in the catalogue of the Biblioteca Virtual Miguel de Cervantes have been migrated to a new relational database whose data model adheres to the FRBR and FRAD specifications. The database content has been later mapped to RDF triples which employ the RDA vocabulary to describe the entities, as well as their properties and relationships. The intermediate relational model —ensuring, for example, referential integrity— provides tighter control over the process and, therefore, enhanced validation of the output. This RDF-based semantic description of the catalogue is now accessible online and supports browsing and searching the information.	linked data;remote database access	Gustavo Candela Romero;Maria Pilar Escobar Esteban;Manuel Marco Such;Rafael C. Carrasco	2015		10.1007/978-3-319-24592-8_26	bioinformatics;world wide web	NLP	-40.75075597981571	4.976211837272962	32724
bcc07aa05418d741a459f3c47515e95f5df5568e	transforming uml2.0 class diagrams and statecharts to atomic devs	statecharts;model transformation and integration;class diagrams;devs modelling methodology;uml2 0	"""We propose a translation process by which a UML2.0 Class Diagram model, along with Statechart models used to describe the behaviour of each of the instances of the classes in the Class Diagram, is transformed into a single, behaviourally equivalent Atomic DEVS model. Statecharts language features such as hierarchical and orthogonal states allow for intuitive modelling of reactive, timed behaviour. Variable structure and modularity are the prominent features of UML2.0 Class Diagrams. DEVS is a highly modular, hierarchical formalism that can be used as a semantic domain for a variety of modelling languages.#R##N##R##N#We validate our approach using a concrete example. We transform the UML2.0 Class Diagram + Statechart model of a digital watch to its Atomic DEVS equivalent and subsequently couple it with a model of a user (the """"environment"""") modelled as an Atomic DEVS."""	devs;diagram	Reehan Shaikh;Hans Vangheluwe	2011			real-time computing;simulation;computer science;devs;sp-devs;algorithm	SE	-38.06604959173496	29.875991261920905	32780
540fc9ae6cf38f31f6df5a8e128972b35784a3d9	a model of normative power	norms;power	A power describes the ability of an agent to act in some way. While this notion of power is critical in the context of organisational dynamics, and has been studied by others in this light, it must be constrained so as to be useful in any practical application. In particular, we are concerned with how power may be used by agents to govern the imposition and management of norms, and how agents may dynamically assign norms to other agents within a multi-agent system. We approach the problem by defining a syntax and semantics for powers governing the creation, deletion, or modification of norms within a system, which we refer to as normative powers. We then extend this basic model to accommodate more general powers that can modify other powers within the system, and describe how agents playing certain roles are able to apply powers, changing the system’s norms, and also the powers themselves. We examine how the powers found within a system may change as the status of norms change, and show how standard norm modification operations — such as the derogation, annulment and modification of norms — may be represented within our system.	autonomous system (internet);industrial and organizational psychology;interaction;multi-agent system;systems engineering;systems theory	Nir Oren;Michael Luck;Simon Miles	2010		10.1145/1838206.1838315	computer science;artificial intelligence;power;algorithm;norm	AI	-43.007576614824394	19.92965363212548	32785
d366e7a689f05a56a05a816d479d692399aad96c	from standards and regulations to executable rules: a case study in the building accessibility domain		Regulatory compliance check in the building industry is a complex task that involves cross-domain national and international standards and regulations. This paper introduces a refined approach to extract SWRL rules from building accessibility regulatory texts and then to transform them into executable rules for semi-automatic compliance checking of Building Information Models. The domain ontology model is a key input to the approach and is enriched by new knowledge extracted from the regulatory text. This semantic technology enhanced rule extraction approach standardized the rule extraction process by covering the whole lifecycle from regulatory text to executable rules. It is based on the open standards and applies open source tools and thereby portable and extendable. It conforms to the open BIM principle to support knowledge sharing cross domains and disciplines. The approach is also adaptable to other types of regulatory rules in the building industry.	accessibility;bim;building information modeling;executable;extensibility;information model;internationalized domain name;ontology (information science);open-source software;rule induction;semantic web rule language;semiconductor industry	Ling Shi;Dumitru Roman	2017			database;data mining;peer review;computer science;executable	AI	-42.43607685646925	4.590551328929209	32792
9744af0b5ef9ba089cb2edaee58b7f2b7154d1a8	recovering high-level structure of software systems using a minimum description length principle	developpement logiciel;legacy software;retroingenierie;software systems;langage evolue;algoritmo genetico;logiciel patrimonial;complex system;desarrollo logicial;software development;algorithme genetique;minimum description length principle;genetic algorithm;lenguaje evolucionado;qa0075 electronic computers computer science;high level language;information theoretic;ingeniera inversa;fitness function;reverse engineering	In [12] a system was described for finding good hierarchical decompositions of complex systems represented as collections of nodes and links, using a genetic algorithm, with an information theoretic fitness function (representing complexity) derived from a minimum description length principle. This paper describes the application of this approach to the problem of reverse engineering the high-level structure of software systems.		Rudi Lutz	2002		10.1007/3-540-45750-X_8	complex systems;genetic algorithm;computer science;artificial intelligence;theoretical computer science;software development;operating system;fitness function;high-level programming language;legacy system;algorithm;reverse engineering;software system	AI	-42.40037291026808	25.067282828852605	32799
0afdc64cdc376e08ca2cf663758bc9e0f159b8d8	a metamodel for the unified modeling language	developpement logiciel;uml metamodel;lenguaje uml;uml semantics;langage modelisation unifie;systeme ouvert;modeling language;metalangage;metamodel;metamodele;metalanguage;metamodelo;desarrollo logicial;unified modelling language;software development;unified modeling language;open systems;sistema abierto;metalenguaje	Nowadays models, rather than code, become the key artifacts of software development. Consequently, this raises the level of requirements for modeling languages on which modeling practitioners should rely in their work. A minor inconsistency of a modeling language metamodel may cause major problems in the language applications; thus with the model driven systems development the solidness of modeling languages metamodels becomes particularly important. In its current state the UML metamodel leaves a significant area for improvement. We present an alternative metamodel that was inspired by the RM-ODP standard and that solves the problems of UML. RM-ODP was mentioned in UML specifications as a framework that has already influenced UML. Our metamodel was formalized, thus its resulting models can be simulated and checked for consistency. So, our proposed solution with constructive potential towards improvement of the UML metamodel, may have a significant practical impact on the UML specifications.	categorization;coherence (physics);diagram;fits;rm-odp;requirement;software development process;type theory;unified modeling language	Andrey Naumenko;Alain Wegmann	2002		10.1007/3-540-45800-X_2	natural language processing;metamodeling;unified modeling language;model-driven architecture;uml tool;computer science;applications of uml;programming language;node;object constraint language	SE	-43.17566750807268	25.915195170670234	32808
e33493e9f58596705c559fd9c681c7557d11fe99	an application of algebraic petri nets specification for vendor management inventory	modelizacion;algebraic specification;inventory management;data flow diagram;traitement flux donnee;system modeling;analisis estructural;red petri;data flow graphs;decision table algebraic petri nets specification vendor management inventory system modeling informal specification structure analysis data flow diagram;decision tables petri nets inventory management algebraic specification data flow graphs;flux donnee;flujo datos;administracion deposito;modelisation;specification algebrique;table decision;data flow processing;tabla decision;gestion stock;vendor managed inventory;petri nets;analyse structurale;data flow;petri net;structural analysis;decision tables;modeling;inventory control;decision table;reseau petri;structure analysis;petri nets inventory management helium systems engineering and theory engineering management logic automation modeling automatic control control systems	In this work, the algebraic Petri nets (APN) is used to a vendor management inventory (VMI) system modeling. An APN specification for a simple VMI system is put out and a procedure to write APN specification is proposed. The procedure is based on informal specification of structure analysis. The data flow diagram and decision table are used in the procedure. An efficient process to write APN specification is achieved. It is named transition first method. The amount and time of replenishment can be achieved by such APN specifications.	algebraic petri net;data flow diagram;dataflow;decision table;it baseline protection;systems modeling	Wei Jian;Yuncan Xue;Jixin Qian	2004	2004 IEEE International Conference on Systems, Man and Cybernetics (IEEE Cat. No.04CH37583)	10.1109/ICSMC.2004.1401248	decision table;data flow diagram;systems modeling;computer science;database;structural analysis;petri net	EDA	-41.24962698629236	26.789602026117368	32821
630702f469a4aabd47ac9d41b61456990166511b	towards bidirectional higher-order transformation for model-driven co-evolution		In model-driven development (MDD), numerous metamodels, models, and model transformations need to be taken into account. These MDD-based artifacts—although highly interdependent—are autonomously maintained. Changes in one artifact (e.g., in a model) are not automatically reflected in other dependent artifacts (e.g., in a model transformation). The barrier for a tight integration of MDD-based artifacts stems from two limitations of current approaches. On the one hand, model transformations are unidirectional and changes can be propagated in one direction only. On the other hand, changes can only be propagated into output artifacts of transformations, not into transformation definitions themselves. In order to overcome these co-evolution problems, our approach is based on establishing bidirectional transformations (BX) between modeling artifacts and on applying higher-order transformations (HOTs) on first-class model representations of transformation specifications. In this paper, we present a generic approach and provide initial prototypes for an integrated tool support which integrates BX into well-established Eclipse-based MDD frameworks, thereby neither being restricted to a specific modeling nor model transformation language.	artifact (software development);bidirectional transformation;eclipse;interdependence;metamodeling;model transformation language;model-driven engineering;model-driven integration	Bernhard Hoisl;Zhenjiang Hu;Soichiro Hidaka	2014		10.1007/978-3-319-25156-1_10	theoretical computer science;computer science;model transformation language;model transformation	PL	-53.70152337672711	23.645047516063457	32830
7e760a22b466e48d4d03c10a5f710a1d7770853e	dl-learner - a framework for inductive learning on the semantic web	owl;system description;supervised learning;machine learning;semantic web;rdf	In this system paper, we describe the DL-Learner framework, which supports supervised machine learning using OWL and RDF for background knowledge representation. It can be beneficial in various data and schema analysis tasks with applications in different standard machine learning scenarios, e.g. in the life sciences, as well as Semantic Web specific applications such as ontology learning and enrichment. Since its creation in 2007, it has become the main OWL and RDF-based software framework for supervised structured machine learning and includes several algorithm implementations, usage examples and has applications building on top of the framework. The article gives an overview of the framework with a focus on algorithms and use cases.	algorithm;gene ontology term enrichment;inductive reasoning;knowledge representation and reasoning;machine learning;ontology learning;resource description framework;semantic web;software framework;supervised learning;web ontology language	Lorenz Bühmann;Jens Lehmann;Patrick Westphal	2016	J. Web Sem.	10.1016/j.websem.2016.06.001	multi-task learning;instance-based learning;algorithmic learning theory;semantic web rule language;computer science;sparql;artificial intelligence;machine learning;semantic web;rdf;social semantic web;data mining;semantic web stack;supervised learning;owl-s;active learning;information retrieval;rdf schema	Web+IR	-39.04605635324261	4.9461835620345465	32899
daf929540108cb61aff0e1199d6c0229673290de	what is a good textual representation of activity diagrams in requirements documents?		The use of graphical models has become a widely adopted approach to specify requirements of complex systems. Still, in practice, graphical models are often accompanied by textual descriptions to provide more detail, because of legal considerations, and to enable stakeholders with different backgrounds to understand a requirements document. One of our industry partners (Daimler AG) uses activity diagrams to specify vehicle functions in combination with a textual representation thereof in their requirements documents. Since graphical and textual representations serve different purposes, it is not obvious how textual representations of activity diagrams should be structured. In this paper, we present different textual representations of activity diagrams for use in requirements documents. The representation currently in use is presented as well as four alternatives. For each representation, we discuss advantages and disadvantages. To evaluate the representations, we asked five stakeholders of one system to create a preference ranking of the representations. The resulting ranking showed that the currently used representation is not considered to be the best possible option. The stakeholders' favorite textual representation emphasizes structural similarity with the activity diagram, which however does not resemble the diagram's structure exactly.	activity diagram;complex systems;feedback;graphical model;graphical user interface;microsoft outlook for mac;requirement;requirements engineering;structural similarity	Martin Beckmann;Andreas Vogelsang	2017	2017 IEEE 25th International Requirements Engineering Conference Workshops (REW)	10.1109/REW.2017.19		SE	-55.6956739827916	24.339910169233114	32916
3e6515b55596291fabc7f901db319a9f663b734e	a hybrid reputation model based on the use of organizations	service provider;organizational structure	In this paper we present a hybrid reputation model focused on organizational structures that attempts to solve problems associated with both centralized and decentralized reputation models. Agents in our approach are able not only to evaluate the behavior of others and store reputations values but also to send such information to a centralized mechanism and ask for reputations to this one and to other agents. The main objective of our approach is to allow agents to reason about the reputation values that they receive. Therefore, together with the reputation values, agents store and send information about norms violated and fulfilled and about the facts that contributed to such behavior. Furthermore, this model provides two different types of reputations, as service provider that is related to the behavior of an agent while providing a service to other agents and as reputation source that is related to the behavior of an agent while providing reputation of others.	agent-based model;autonomous agents and multi-agent systems;centralized computing;computation;computational intelligence;e-commerce;ieee internet computing;lecture notes in computer science;model-driven integration;multi-agent system;reputation management;reputation system;springer (tank)	Viviane Torres da Silva;Ramón Hermoso;Roberto Centeno	2008		10.1007/978-3-642-00443-8_8	public relations;marketing;business;computer security	AI	-43.55866508476728	17.667970118229714	32972
2789c502c0b968627074836f4636dae068010f8c	business process design based on communication and interaction	business process design	The easiest way that people describe their roles in an organization or the way that members of an organization make promises and commitments to fulfil a task is through communication and interaction. In such a communication language is used as a tool or facilitator of action when a customer requests a service and the supplier promises to provide such a service. In this paper we introduce a language-action based methodology for designing business processes for the Department of University Housing at Georgia Southern University planning to acquire a new information system for managing, supporting and improving the “process of rooms assignment” to some 4000 students. As stated, the methodology is based on languageaction perspective and therefore we have used the business transaction concept for mining atomic business processes. Each business transaction identifies an essential activity and reveals the actors and their roles as an initiator or executor of the transaction. Since the transaction concept is used as a conceptual basis, the methodology is complemented with Petri net graphical notations as a modelling technique.	business process;human-readable medium;information system;petri net;process modeling;requirements engineering;scsi initiator and target;simulation software;systems design;transaction processing;weatherstar	Joseph Barjis;Isaac Barjis	2006			business analysis;business transformation;business domain;business process reengineering;computer science;knowledge management;artifact-centric business process model;business process management;process modeling;business process model and notation;process management;business process;event-driven process chain;process mining;business process discovery;business rule;new business development;business process modeling;business activity monitoring;business architecture	HCI	-54.369487454599465	16.543807718627228	33010
774e190a2a776328c2be5c2e1a159984bdb686f0	formally describing the architectural behavior of software-intensive systems-of-systems with sosadl	software;complexity theory;semantics;computer architecture;software architecture;complex systems;concrete	Software-intensive systems are often independently developed, operated, managed, and evolved. Progressively, communication networks have enabled these independent systems to interact, yielding a new kind of complex system, i.e. a system that is itself composed of systems, the so-called System-of-Systems (SoS). By its complex nature, SoS exhibits emergent behaviors. Nowadays, none of the Architecture Description Languages (ADLs), which have been developed for modeling the architectural behavior of single software-intensive systems, has the expressive power to formally describe the architectural behavior of Software-intensive SoSs. For addressing this research challenge, we propose a novel ADL, called SosADL, specially conceived for formally describing the architecture of Software-intensive SoSs. It embodies SoS architectural concepts and constructs encompassing the formal description of software architectures from both the structural and behavioral viewpoints. This paper presents SosADL focusing on the description of the architectural behavior of Software-intensive SoSs. It describes SosADL from its behavioral viewpoint enabling to specify independent systems, mediators among these systems, coalitions of mediated systems, and the architectural conditions that enforce the production of emergent SoS behaviors. It illustrates SosADL through an excerpt of a real application for architecting a Flood Monitoring and Emergency Response SoS.	apple sos;architecture description language;complex system;constraint satisfaction problem;correctness (computer science);emergence;executable;field research;interaction;simulation;software architecture;system of systems;telecommunications network;trustworthy computing	Flávio Oquendo	2016	2016 21st International Conference on Engineering of Complex Computer Systems (ICECCS)	10.1109/ICECCS.2016.012	software architecture;complex systems;simulation;concrete;architectural pattern;computer science;systems engineering;operating system;software engineering;semantics	SE	-41.331150931690125	31.418949710052825	33013
b26a12bf0128d8535bd670733990bd63880ca6a1	an extension of a fuzzy ontology for flexible querying	databases;sqlf;multimodal transport information system fuzzy ontology flexible querying personalized approach information systems reasoning capabilities fuzzy dlr lite ontology sqlf language godel fuzzy implication;knowledge based system;information systems;query processing;process capability;sql;sql fuzzy set theory ontologies artificial intelligence query processing;personalization;fuzzy set theory;ontologies artificial intelligence;multimodal transportation;transportation;cognition;fuzzy sets theory;fuzzy dlr lite;ontologies;information system;ontology;flexible querying;ontologies knowledge based systems information systems databases fuzzy set theory transportation cognition;knowledge based systems;mobile terminal;multimodal transportation ontology flexible querying personalization fuzzy dlr lite sqlf fuzzy sets theory	In this paper, we propose a personalized approach for flexible querying of information systems. This approach consists in the combination of the reasoning capabilities of the fuzzy DLR-Lite ontology and the expressivity of the SQLf language. The interpretation of the gradual inclusion (subsumption) axioms of the ontology is based on the Gödel fuzzy implication. Its generalization to a tree of inclusions is also proposed. This tree and its property of propagation of degrees are the basic theoretical elements of our application, which consists in querying of a multimodal transport information system which is embedded in a mobile terminal characterized by limited storage and processing capabilities.	adobe flash lite;algorithm;description logic;dynamic language runtime;embedded system;fuzzy concept;gene ontology term enrichment;gödel;information system;knowledge base;mobile phone;multimodal interaction;personalization;sqlf;software propagation;subsumption architecture	Nouredine Tamani;Ludovic Lietard;Daniel Rocacher	2011	2011 IEEE International Conference on Fuzzy Systems (FUZZ-IEEE 2011)	10.1109/FUZZY.2011.6007307	computer science;artificial intelligence;knowledge-based systems;data mining;database;information retrieval;information system	Robotics	-37.64462854458072	7.616777828525392	33033
e4dd30dc1c96a3d184d4d5f30b0a8c3e66ee800c	network access to multimedia information	user requirements;world wide web;information system;point of view;project planning	This attribute contains a short description of the item. It may also include a Gopher reference to a longer abstract, held in a separate Gopher node. ASK This attribute is used for the interactive query extension. The interactive query facility in Gopher+ is used to obtain information from a user before retrieving the contents of a node. The client fetches the ASK attribute, which contains a list of questions for the user. His or her responses to those questions are sent along with the selector to the server, which then returns the contents of the node. This facility could be used as a very simple way of querying a database, for instance. Using the interactive query facility to supply a password for access control purposes is not a good idea there are too many opportunities for masquerading. The University of Minnesota maintains a registry of Gopher+ attribute types. For the VIEWS attribute, the registry contains a list of permitted view types. Note that these view types have a similar function to the type identifier described in the preceding section. The general format of a Gopher+ view descriptor is: xxx/yyy zzz: <nnnK> where xxx is a general type-of-information advisory, yyy is what information format you need understand to interpret this information, zzz is a language advisory (coded using POSIX definitions), and nnn is the approximate size in bytes. Possible values for xxx include text, file, image, audio, video, terminal. (It now appears that the University of Minnesota Gopher Team accepts the need to be consistent in the use of type/encoding attributes with the MIME specification. The Gopher+ Type Registry may thus eventually disappear, together with the set of xxx/yyy values it currently contains.)	access control;approximation algorithm;byte;computer terminal;content format;identifier;posix;password;server (computing);video	Chris Adie	1994	RFC	10.17487/RFC1614	computer science;knowledge management;web navigation;data mining;world wide web	DB	-34.85396900280105	16.66360408234755	33037
295f57aa22ab621212df6f35f54748b54496b2e2	hybrid simulation for cyber physical systems: state of the art and a literature review		This paper evaluates the state of the art of hybrid simulation support for cyber physical systems. The traditional definition for hybrid simulation is expanded to include recent research on multi-paradigm and other multi-faceted modeling approaches. Based on the review of current approaches, the focus of simulation support lies first in providing a virtual environment supporting development and testing, and second on utilizing simulation as part of the cyber physical system. A literature research on support of cyber physical systems within the simulation community shows common trends towards a common formalism, but an aligned research agenda has not been established.	simulation	Andreas Tolk;Ernest H. Page;Saurabh Mittal	2018			distributed computing;computer science;cyber-physical system;systems engineering;virtual machine;formalism (philosophy)	AI	-62.73155921668394	18.992725658603497	33038
006fb07dfbaa7f6e14f62453fad9d3e21062ac42	towards composable robotics: the r3-cop knowledge-base driven technology platform	composability;cognitive systems;co operative systems;certification;ontology based knowledge base;testing;robotics;reference technology framework;robotic vision;safety;building blocks;autonomous systems	The ARTEMIS project R3-COP (Resilient Reasoning Robotic Cooperating Systems) aims at providing European industry with leading-edge innovation that will enable the production of advanced robust and safe cognitive, reasoning autonomous and co-operative robotic systems at reduced cost. This is achieved by cross-sector reusability of building blocks, collected in a knowledge base, within a generic framework and platform with domain-specific instantiations. The R3-COP Framework is targeting at becoming basis for a European RTP (Reference Technology Platform) for robust autonomous systems by embodying methodologies, methods, and tools for safety-critical hard-real-time system development and verification supported by European tool vendors. To enable this, interoperability issues have to be resolved at several levels, including metamodels, models, tool interfaces and component descriptions. The link is established by the knowledge base described in more detail in this paper to allow composition of robotic applications from building blocks, guiding design & development as well as validation & verification (supporting certification in the end). The concept of the knowledge base could be re-used in the planned ARTEMIS Common Reference Technology Platform for critical systems engineering.	autonomous robot;autonomous system (internet);interoperability;knowledge base;metamodeling;real-time clock;real-time computing;reduced cost;systems engineering	Erwin Schoitsch;Wolfgang Herzner;Carmen Alonso-Montes;P. Chmelar;Lars Dalgaard	2012		10.1007/978-3-642-33675-1_40	embedded system;simulation;autonomous system;computer science;systems engineering;engineering;software engineering;software testing;robotics;certification;computer security	SE	-57.025031884892954	22.11627815362446	33042
911ca840e166c1292789bef337daab2ccd3bcca5	ecapnver: a software tool to verify active rule bases	verification;active rule;ecapnver;software tool;economic indicators redundancy petri nets software tools database systems automation;inconsistency analysis ecapnver software tool active rule base active system development petri nets ccpn;rule based;petri nets formal verification knowledge based systems;ecapnver active rule verification conditional colored petri net;petri nets ccpn;formal verification;redundancy;conditional colored petri net;database systems;active rule base;colored petri net;system development;software tools;petri nets;petri net;inconsistency analysis;active system development;knowledge based systems;economic indicators;automation	Active rules are a powerful mechanism to represent reactive behavior. Constructing an active rule base is not an easy work since errors may be (unnoticed) introduced during rule development. In this paper we describe ECAPNVer, a software tool that supports active systems development by automatically verifying an active rule base based on an extension of Petri nets CCPN. ECAPNVer can detected and correct structural errors as well as potential errors such as redundancy and partial redundancy, inconsistency and partial inconsistency, incompleteness and circularity. In this paper, an example of inconsistency analysis is used to demonstrate ECAPNVer tool functionality.	collaborative computing project for nmr;event condition action;petri net;programming tool;rule-based system;software development process;verification and validation	Lorena Chavarría-Báez;Xiaoou Li	2010	2010 22nd IEEE International Conference on Tools with Artificial Intelligence	10.1109/ICTAI.2010.94	rule-based system;computer science;artificial intelligence;knowledge-based systems;data mining;database;petri net	Robotics	-45.861994832599876	28.499471489963952	33045
ff0f3a86bf86ac1b7eea30fe9755cf2cba62b4a8	towards identifying spurious paths in combined simulink/stateflow models		MATLAB/Simulink and its state machine design toolbox State ̄ow are widely-used industrial tools for the development of complex embedded systems. Due to the dynamic as well as heterogeneous nature of models that contain both Simulink and State ̄ow components, their analysis poses a dif®cult challenge. This paper outlines an approach to relate the semantics of both Simulink and State ̄ow and how to use it to perform an information  ̄ow analysis on a combined Simulink and State ̄ow model. In the ®rst step, we analyze the State ̄ow automata and generate timed output traces for arbitrary inputs. In the second step, we use an existing timed path condition extraction algorithm for the Simulink components to identify conditions for information  ̄ow on paths of interest. Finally, we analyze whether the compiled sets of timed path conditions are contained in the timed output traces that we derive by using a novel trace notation for State ̄ow automata. This approach makes it possible to safely rule out the existence of information  ̄ow on speci®c paths through a model. Further, it presents a starting point to reason about non-interference between model parts, compliance with security policies as well as the generation of feasible, ef®cient test cases.	action potential;algorithm;automata theory;automaton;compiler;design pattern;embedded controller;embedded software;embedded system;information flow;information privacy;interference (communication);matlab;naruto shippuden: clash of ninja revolution 3;non-interference (security);scheduling (computing);simulink;stateflow;test case;tracing (software);usability	Marcus Mikulcak;Thomas Göthel;Paula Herber;Sabine Glesner	2016			control engineering;spurious relationship;stateflow;computer science	Embedded	-40.40761570698671	32.252307615824606	33047
97c2d47d56ab38f0caef9d31d97f5110d2740894	composition and tradeoff of non-functional attributes in software systems: research directions	quality attributes;reliability;component based software engineering;component based systems;component based development;reliability modeling;software systems;automatic generation;cost minimization;cost optimization;error propagation;service oriented architecture;software quality;optimization model	"""The domain of our work is focused on the study of the quality attributes of component-based systems and service-based systems. The qualities of a component-based system depend on those ones of the single components. The objective of our work is to support the selection of (COTS and in-house) components under the satisfactionof the quality attributes. First, we have introduced an optimization model, that supports the component selection activity. The selection criterion is based on cost minimization of the whole system subject to constraints on reliability and delivery time of the whole system. In addition, for each in-house developed component it suggests the amount of testing to perform in order to achieve the required level of reliability. In order to automatize the selection activity we have introduced CODER (Cost Optimization under DElivery and Reliability constraints), a framework that allows to annotate UML diagrams with cost, reliability and delivery time information and that automatically generates and solves the optimization model. In order to improve the formulation of our model we are working on the reliability expression. We express the reliability of the whole system as function of the reliability of the single components by assuming independence among components. We have relaxed this assumption and we have introduced a path-based reliability model for a Service-Oriented Architecture (SOA) that embeds the """"errorpropagation"""" property. Currently, we are working to introduce a framework that automatizes the process of selection of (COTS and in-house) components in all the phases of a component-based development process. In particular, we have introduced a framework thatsupports the selection of COTS components in the requirements phase. The framework lays on a tool that builds and solves an optimization model, whose solution provides the optimal COTS component selection. The selection criterion is based on cost minimization of the whole system while assuring a certain degree of satisfaction of the system requirements."""	component-based software engineering;diagram;feature selection;list of system quality attributes;mathematical optimization;requirement;service-oriented architecture;service-oriented device architecture;software system;system requirements;unified modeling language	Pasqualina Potena	2007		10.1145/1287624.1287716	reliability engineering;computer science;systems engineering;engineering;component-based software engineering;software engineering;programming language;engineering drawing	SE	-55.63696507205148	26.945733891644256	33121
07a37addde2d1d8b44a93322eefb4d0aacaa94db	structural matching of bpel processes	libraries;owl;service composition;web service discovery;case base reasoning;web service;engines;indexing;decision making process;web services libraries engines indexing informatics humans decision making owl knowledge representation algorithm design and analysis;web services;semantic description;informatics;humans;knowledge representation;institutional repository research archive oaister;use case;algorithm design and analysis	BPEL has emerged as the industrial standard language for modelling behavioral aspects of web services. To support business partners in dynamically and flexibly binding their services together, different BPEL processes need to be efficiently matched. This paper identifies and defines various types of structural matching for BPEL processes. The matching definitions are based on heuristics: they take behavioral interaction aspects of the compared services into account, but abstract from irrelevant syntactical differences. Since the definitions are structural, they can be efficiently computed, and thus are useful to support dynamic and flexible binding of services. The approach is illustrated with an example from an existing business scenario.	agile software development;business process execution language;expressive power (computer science);heuristic (computer science);interaction;lambda lifting;prototype;query language;relevance;web service	Rik Eshuis;Paul W. P. J. Grefen	2007	Fifth European Conference on Web Services (ECOWS'07)	10.1109/ECOWS.2007.22	web service;knowledge representation and reasoning;computer science;artificial intelligence;ws-policy;data mining;database;services computing;ws-i basic profile;law;world wide web	SE	-44.48104584775716	14.179838626303493	33124
7bb2a482cfc01e99ed0f7e01f27194d98d5b4c7a	precep: facilitating predictive event-driven process analytics	all items;business activity monitoring;operational business intelligence;event driven process analytics;business process management;complex event processing	The earlier critical decision can be made, the more business value can be retained or even earned. The goal of this research is to reduce a decision maker’s action distance to the observation of critical events. We report on the development of the software tool preCEP that facilitates predictive event-driven process analytics (edPA). The tool enriches business activity monitoring with prediction capabilities. It is implemented by using complex event processing technology (CEP). The prediction component is trained with event log data of completed process instances. The knowledge obtained from this training, combined with event data of running process instances, allows for making predictions at intermediate execution stages on a currently running process instance’s future behavior and on process metrics. preCEP comprises a learning component, a run-time environment as well as a modeling environment, and a visualization component of the predictions.	business activity monitoring;complex event processing;event-driven programming;programming tool;runtime system	Bernd Schwegmann;Martin Matzner;Christian Janiesch	2013		10.1007/978-3-642-38827-9_36	analytics;real-time computing;computer science;artifact-centric business process model;business process management;data science;complex event processing;process modeling;data mining;business process model and notation;business analytics;business intelligence;business process;process mining;business process discovery;business process modeling;business activity monitoring	Robotics	-53.62059216790664	17.484419468254647	33181
bb8415ed47d926c071e55af128f025e7cdd776ac	improving authoring-by-aggregation and using aggregation context for query expansion	learning resource;query expansion	Authoring-by-Aggregation is an authoring paradigm for creating new Learning Resources by composing several smaller ones. However finding suitable Learning Resources that can be reused in a particular course is a time-consuming task. The user has to query a repository and review the resulting list of Learning Resources whether they are applicable. In this paper we present a new method for narrowing the result set by taking the aggregation context into account. Context features are used as additional query attributes, leading to more precise query results. This paper also presents an improved Authoring-by-Aggregation process and a corresponding implementation, which facilitates the creation of new Learning Resources.		Marek Meyer;Christoph Rensing;Ralf Steinmetz	2007		10.1007/978-3-540-75195-3_45	online aggregation;sargable;query optimization;query expansion;web query classification;computer science;data mining;database;rdf query language;web search query;world wide web;active learning;information retrieval;query language	NLP	-35.635303333513406	4.707521516823868	33215
685f9f8660fe9a3be3829ea10d8021e8124afff7	a visual soa-based ontology alignment tool		Ontology alignment is the process of matching related concepts from different ontologies. We propose a semi-automatic, visual approach which combines two algorithms for finding candidate alignments with visual navigation and analysis tools. The implementation is based on a ServiceOriented Architecture (SOA) to achieve scalability.	algorithm;machine vision;ontology (information science);ontology alignment;scalability;semiconductor industry	Kow Weng Onn;Vedran Sabol;Michael Granitzer;Wolfgang Kienreich;Dickson Lukose	2011			ontology alignment;computer science;data mining;database;information retrieval;process ontology	HCI	-40.43791384412326	6.717126723036512	33299
b9610a60c3e1932aa59d4dae609371167e5025ec	the java community and rule engine standards.		"""Introduction The number one request from the Java rules community is a standard business rules language (source: http://www.javarules.org). Developers view a standard rule language as a key enabling technology, allowing them to build tools and applications that can generate and manage rules, and execute them on multiple rule engines. A standard rule language breaks the dreaded """"vendor lock in"""" and ensures that the considerable investment required to distill knowledge as business rules can be moved between execution environments. It also allows JSR-94, the Java Rule Engine API, to evolve to offer much more interesting services related to the semantics of execution and the internal structure of rules and rulesets. Underlying the request for a standard business rule language lurks the more difficult issue of semantic interoperability between rule engines. It is clearly not enough to have a standard XML Schema for business rules, and then have the rules execute differently on two rule engines! The difficulty of defining semantic interoperability is compounded by the diversity in rule engine products: ranging from RETE/AI/CLIPS heritage forward-chaining engines, through XML processing engines to decision trees and so forth. Consequently a major prerequisite for deriving significant value from a standard rule language is resolution of two major open questions: """"What is a rule engine?"""" and """"How does a rule engine execute rules?"""" The Java rule engine space is still very dynamic, with new vendor products and projects appearing monthly. There are approximately 25 commercial products and 18 open source software projects in the Java rule engine space (source: http://www.javarules.org)."""	application programming interface;business rules engine;clips;decision tree;forward chaining;java;open-source software;semantic interoperability;semantic reasoner;vendor lock-in;xml schema	Daniel Selman;Johan Majoor	2005			real-time computing;jsr 94;computer science;database;world wide web	DB	-35.0437606941493	8.45669179151207	33351
f4640c5df584e32e558fbc0d02fe609a0199ae13	systematic functional decomposition in a product line using aspect-oriented software development: a case study	aspect oriented software engineering;aspect oriented software development;product line;functional decomposition;article	Systematic configuration management is important for successful software product lines. We can use aspect-oriented software development to decompose software product lines based on features that can ease configuration management. In this paper, we present a military maintenance product line that employs such strategy. In particular, we applied a specific approach, feature based modeling (FBM), in the construction of the system. We have extended FBM to address properties specific to product line. We will discuss the advantages of FBM when applied to product lines. Such gains include the functional decomposition of the system along user requirements (features) as aspects. Moreover, those features exhibit unidirectional dependency (i.e. among any two features, at most one depend on another) that enables developers to analyze the effect of any modification they may make on any feature. In addition, any variations can be captured as aspects which can also be incorporated easily into the core asset if such variation is deemed to be important enough to be included in the product line for further evolution.	aspect-oriented software development;configuration management;domain engineering;feature model;functional programming;non-functional requirement;requirement;ripple effect;software product line;traceability;user requirements document	Tegegne Marew;Jungyoon Kim;Doo-Hwan Bae	2007	International Journal of Software Engineering and Knowledge Engineering	10.1142/S0218194007003112	functional decomposition;computer science;systems engineering;engineering;software development;engineering drawing;feature model;product engineering	SE	-55.55544545278087	28.03531287088082	33353
12785c163b358efec21454269eceb55a02aa5a7c	towards an ethical analysis of the w3c web services architecture model	web design;web services;ethical aspects;large-scale systems;software agents;floridi theory;w3c web service architecture model;artificial agent;autonomous software agent;complex system;ethical analysis;information ethic;moral agent;floridi's theory of information ethics;message oriented model;web services architecture model;level of abstraction;moral agent;moral patient	This article explores the relevance of information ethics, the field that concerns itself with the study of ethical issues arising from the development and use of such technologies, for a specific information technology viz. Web services. In particular, the Web services architecture, as conceptualised by the W3C, is analysed using Floridi's theory of Information Ethics (IE). Firstly, it is shown that a technology such as Web services (acting as autonomous software agents and artificial agents with moral agency) should and could be subjected to a systematic ethical analysis that yields useful results. Secondly, the suitability and applicability of Floridi's ethical theory of IE is demonstrated by applying it to a complex system such as the Web services architecture. It is shown how the central notion of IE, viz. so-called levels of abstraction, supports major software systems design principles such as top-down design, structured analysis and design, and stepwise refinement and affords us the opportunity of interrogating the ethical behaviour of Web services. This result is of particular significance since it opens up opportunities for the systematic and appropriate ethical analysis of any software system and may provide a general approach to “ethics by design”.	autonomous robot;complex system;information ethics;intelligent agent;principle of abstraction;refinement (computing);relevance;software agent;software system;stepwise regression;structured analysis;systems design;top-down and bottom-up design;viz: the computer game;web service;world wide web	Valiya Gangadharan;Laurette Pretorius	2010	2010 Information Security for South Africa		web service;web modeling;computer science;knowledge management;software agent;management science;information technology;computer security	SE	-44.38291012050515	19.908003999555586	33377
21893cab1d4aef54ac196ce982ce1a7c284ee684	rule base inspection using algorithmic approach for data-access oriented knowledge-based systems	context transition diagram algorithmic approach data access oriented knowledge based systems rule base inspection method knowledge base finite state diagram;inspection knowledge based systems artificial intelligence programming circuit testing knowledge engineering intelligent systems costs productivity data engineering;knowledge based system;rule based;data access;state diagram;knowledge engineering knowledge based systems;knowledge based systems;knowledge base;knowledge engineering	This paper describes an effective rule base inspection method that checks rule base consistency and completeness by using algorithmic approach. A knowledge base in this method is represented by one finite state diagram. Through this diagram some errors and anomalies of the rule base can be clearly illustrated and identified. The characteristics of those states representing such errors and anomalies in the state diagram are investigated, and the algorithms to effectively identify those defects are also introduced in this article.	algorithm;knowledge base;knowledge-based systems;rule-based system;state diagram	Fang-Yie Leu;Chien-Chiao Yang	1990		10.1109/CMPSAC.1990.139344	data access;legal expert system;knowledge base;state diagram;system context diagram;computer science;systems engineering;knowledge management;artificial intelligence;knowledge-based systems;open knowledge base connectivity;data mining;knowledge extraction	AI	-46.106210020409485	27.547895353413143	33387
b88bd6fdcc38db12c68e8315d823f0a62ed6d719	a conceptual model for network decision support systems	groupware;formal specification;sensors;software prototyping;collaboration;software prototyping computer networks decision support systems formal specification groupware;computer networks;decision making sensors decision support systems collaboration mobile communication knowledge engineering computational modeling;computational modeling;decision support systems;mobile communication;article;naval postgraduate school field experiments network decision support systems wireless technology decision making activities 3 tier conceptual model digital infrastructure transactive memory systems collaborative decision making sense analyze adapt memory leveraging agile collaborative requirements innovative nwdss services;knowledge engineering	We introduce the concept of a network DSS (NWDSS) consisting of fluid, heterogeneous nodes of human and machine agents, connected by wireless technology, which may enter and leave the network at unpredictable times, yet must also cooperate in decision-making activities. We describe distinguishing properties of the NWDSS and propose a 3-tier conceptual model comprised of digital infrastructure, transactive memory systems and emergent collaborative decision-making. We suggest a decision loop of Sense-Analyze-Adapt-Memory leveraging TMS as a starting point for addressing the agile collaborative requirements of emergent decision-making. Several examples of innovative NWDSS services are presented from Naval Postgraduate School field experiments.	agile software development;decision support system;emergence;experiment;multitier architecture;requirement	Alexander B. Bordetsky;Daniel R. Dolk	2013	2013 46th Hawaii International Conference on System Sciences	10.1109/HICSS.2013.32	r-cast;simulation;mobile telephony;decision support system;intelligent decision support system;decision engineering;computer science;knowledge management;sensor;artificial intelligence;operating system;software engineering;knowledge engineering;formal specification;database;management;computational model;world wide web;business decision mapping;collaboration	Robotics	-40.87626224564088	18.668857633967995	33388
a6e05fbac33f60de089c7917aca186700025c0de	aspect modelling at architecture design	developpement logiciel;modelizacion;architectural design;ciclo desarrollo;life cycle;componente logicial;architecture description language;aspect oriented software development;separation of concern;mantenimiento sistema;orientado aspecto;composant logiciel;concern separation;sistema complejo;software engineering;modelisation;software architecture;lenguaje descripcion;systeme complexe;complex system;desarrollo logicial;separation preoccupation;software development;software component;version management;cycle developpement;genie logiciel;separacion preocupacion;coordinacion;aspect oriented;concepcion arquitectural;software design;conception architecturale;modeling;system maintenance;ingenieria informatica;gestion version;architecture logiciel;langage description;oriente aspect;coordination;maintenance systeme;description language	The increment of the complexity of systems requires new techniques that allow manipulating it adequately. Software architecture is becoming an important part of software design, which helps developers to handle the complexity of large systems. In addition, the management of the evolution as well as the maintenance of complex systems are two of most important problems to be solved by software engineering. Several solutions have been considered, one of them being the separation of concerns. These concepts have been extended along the life cycle and thus, Aspect Oriented Software Development (AOSD) arose. In this paper the architectural design phase and Aspect Oriented concepts are considered jointly. A proposal introducing aspects modelling in the architecture design phase is presented. The research is based on the combined use of a conventional architecture description language and an exogenous co-ordination model. When new requirements are going to be included in the system, the proposal provides the required steps to allow its evolution and maintenance by specifying an Aspect Oriented Architecture, which will permit us to change the system easily.	acme;action description language;ambient occlusion;architecture description language;aspect-oriented programming;aspect-oriented software development;complex systems;interaction;iterative and incremental development;library of efficient data types and algorithms;requirement;separation of concerns;simulation;software architecture;software design;software engineering	Amparo Navasa Martínez;Miguel A. Pérez;Juan Manuel Murillo	2005		10.1007/11494713_4	enterprise architecture framework;reference architecture;biological life cycle;software architecture;space-based architecture;architecture description language;complex systems;simulation;systems modeling;database-centric architecture;aspect-oriented programming;separation of concerns;computer science;engineering;applications architecture;software design;component-based software engineering;software development;software design description;software engineering;software architecture description;programming language;resource-oriented architecture;systems architecture;systems design	SE	-39.839422141733635	25.07168081930223	33404
bc6fc374e31dd10ece3d77bd12d770f76ca96fb1	generic service composition platform for pervasive e-commerce	personalization;e commerce;soa;p2p;qos	In this paper, a generic E-Commerce process model with full E-Commerce service coverage is propose. Based on this model, a generic service composition platform is proposed as an individual middleware layer to support the pervasive E-Commerce. The platform consists of an orchestration component and several atomic service components (ASCs). It is in charge of dynamic and automatic general service (GS) construction taking the user preferences and demanded quality of service (QoS) into account. The designed platform is flexible and extensible thanks to the service oriented architecture (SOA) (service oriented architecture)-based atomic reusable and sharable service components (SCs). And it employs efficient peer-to-peer (P2P) interaction between two components. In our method, global QoS is guaranteed by the runtime QoS monitoring and dynamic adjusted two-dimensional orchestration plan. Copyright © 2009 John Wiley & Sons, Ltd.	e-commerce payment system;service composability principle	Jing Chi;Chunyang Yin;Meina Song;Junde Song;Xiaosu Zhan	2010	Wireless Communications and Mobile Computing	10.1002/wcm.749	e-commerce;mobile qos;simulation;telecommunications;differentiated service;computer science;service delivery framework;operating system;personalization;world wide web;computer security;computer network	Mobile	-45.75070339814091	15.777245264984424	33420
68cb2753ad6f950d243c6c1ee45200c714c7bfaa	testera: specification-based testing of java programs using sat	sat enumeration;java testing;fault tree;software testing;formal specification;java programming;specification based testing;automated test generation;automatic generation;alloy;testera;first order logic;dynamic networks	TestEra is a framework for automated specification-based testing of Java programs. TestEra requires as input a Java method (in sourcecode or bytecode), a formal specification of the pre- and post-conditions of that method, and a bound that limits the size of the test cases to be generated. Using the method's pre-condition, TestEra automatically generates all nonisomorphic test inputs up to the given bound. It executes the method on each test input, and uses the method postcondition as an oracle to check the correctness of each output. Specifications are first-order logic formulae. As an enabling technology, TestEra uses the Alloy toolset, which provides an automatic SAT-based tool for analyzing first-order logic formulae. We have used TestEra to check several Java programs including an architecture for dynamic networks, the Alloy-alpha analyzer, a fault-tree analyzer, and methods from the Java Collection Framework.	alloy (specification language);alloy analyzer;code coverage;computation;constraint satisfaction problem;correctness (computer science);experiment;fault tree analysis;first-order logic;first-order predicate;formal specification;information;jackson;java collections framework;postcondition;precondition;scalability;test automation;test case	Sarfraz Khurshid;Darko Marinov	2004	Automated Software Engineering	10.1023/B:AUSE.0000038938.10589.b9	real-time computing;fault tree analysis;computer science;software engineering;first-order logic;formal specification;software testing;programming language;algorithm	SE	-45.822063362251534	31.324052658079545	33444
0e4b7d6584b18c8914eb03b5759bac354c7b0f0d	semantic clipboard - semantically enriched data exchange between desktop applications		The operating system clipboard is used to copy and paste data between applications even if the applications are from different vendors. Current clipboards only support the transfer of data or formatted data between applications. The semantics of the data, however, is lost in the transfer. The Semantic Web, on the other hand, provides a common framework that allows data to be shared across application boundaries while preserving the semantics of the data. In this paper we introduce the concept of a Semantic Clipboard and present a prototype implementation that can be used to copy and paste RDF meta-data between desktop applications. The Semantic Clipboard is based on a flexible plugin architecture that enables the easy extension of the clipboard to new ontology vocabularies and target applications. Furthermore, we show how the Semantic Clipboard is used to copy and paste the meta-data from semantically annotated Web pages to a user’s desktop application.	clipboard (computing);cut, copy, and paste;desktop computer;operating system;prototype;resource description framework;semantic web;vocabulary;web page	Gerald Reif;Harald C. Gall;Martin Morger	2006				OS	-40.15163730823054	10.04150870137435	33487
c1f5c284d0918ca02b6a8575cde30f24a8ecd3e1	chronological fault-based mutation processes for ws-bpel 2.0 programs	mutation testing;ws bpel program testing;business process execution language for web services;semantics;chronological faults;web services;fault based mutation;workflow patterns	Business Process Execution Language for Web Services (WS-BPEL) is a powerful language developed to capture the semantics of business processes and to describe the interactions between involved systems. Limited research has been undertaken in the area of identifying faults manifested in WS-BPEL-based systems. In this paper, we propose an approach to assist in testing WS-BPEL programs, specifically with regard to chronological-oriented faults. This approach employs mutation testing to identify and detect mutants introduced into WS-BPEL programs. We describe the steps to generate such mutants for WS-BPEL programs. To reduce the mutant specification into a minimal set of generic mutant specifications, we work directly with the workflow patterns that exist in this language. Further, we utilise an extended version of Backus-Naur Form (BNF) to represent a simple subset of communicating sequential processes (CSP) notations, adapted to fit the descriptive needs of WS-BPEL-based systems, to provide a complete and minimal set of mutants of chronological-oriented faults that can exist in WS-BPEL systems of the future.	beta normal form;business process execution language;communicating sequential processes;interaction;mutation testing;workflow pattern	Adel Khaled;James Miller	2010	Int. J. Web Eng. Technol.	10.1504/IJWET.2010.038243	workflow patterns;web service;business process execution language;computer science;database;semantics;mutation testing;programming language;law;world wide web	SE	-44.05547536888218	27.65720712564071	33504
02cfdf271244a8bad454059a72871cf0c1a40b94	exception handling in agent systems	complex dynamics;multi agent system;exception failure handling detection and resolution;agent based system;agent systems;exception handling	A critical challenge to creating effective agent-based systems is allowing them to operate effectively when the operating environment is complex, dynamic, and error-prone. In this paper we will review the limitations of current “agent-local” approaches to exception handling in agent systems, and propose an alternative approach based on a shared exception handling service that is “plugged”, with little or no customization, into existing agent systems. This service can be viewed as a kind of “coordination doctor”; it knows about the different ways multi-agent systems can get “sick”, actively looks system-wide for symptoms of such “illnesses”, and prescribes specific interventions instantiated for this particular context &an a body of general treatment procedures. Agents need only implement their normative behavior plus a minimal set of interfaces. We claim that this approach offers simplified agent development as well as more effective and easier to modify exception handling behavior.	agent-based model;cognitive dimensions of notations;exception handling;multi-agent system;operating environment	Mark Klein;Chrysanthos Dellarocas	1999		10.1145/301136.301164	exception handling;real-time computing;complex dynamics;computer science;artificial intelligence;multi-agent system;computer security	SE	-38.868699864524245	20.03244189910293	33559
d99d9618bdb4c7c270d246c96f2306cc14e58499	two decades of software agent platform engineering - part 1			software agent	Michael Zapf	2013	Praxis der Informationsverarbeitung und Kommunikation	10.1515/pik-2013-0039		AI	-50.2872716478785	8.91342209380827	33573
fb3efc49d91b255c5069f799e3031b59605206d1	when user modeling intersects software engineering: the info-bead user modeling approach	info bead;component based user model;group model;info pendant;user modeling software engineering;user model reusability;user model;user modeling tool	User models (UMs) allow systems to provide personalized services to their users. Nowadays, UMs are developed ad-hoc, as part of specific applications, thus requiring repetitive development efforts. In this paper, we propose the info-bead user modeling approach, which is based on ideas taken from software engineering in general and component-based software development in particular. The basic standalone unit, the info-bead, represents a single user attribute within time-tagged information-items. An info-bead encapsulates an inference process that uses data received from sensors or other info-beads and yields an information-item value. Having standard interfaces, info-beads can be linked, thus creating info-pendants. Both info-beads and info-pendants can be assembled as needed into complex and abstract user models (UMs) and group models (GMs). The goal of the suggested approach is to ease the modeling process and to allow reuse of info beads developed for one UM in other UMs that need the same information. In order to assess the reusability and collaboration capabilities of the info-bead user modeling approach, we developed a prototype tool that enables UM designers, who are not necessarily software developers, to easily select and integrate info-beads for constructing UMs and GMs. We further demonstrated the use of the approach in a museum environment, for modeling of assistive technology ontology and for user modeling in various specific domains. Finally, we analyzed and assessed the characteristics of the approach with respect to existing generic user modeling criteria.	12-hour clock;abstract type;accessibility;application programming interface;assistive technology;component-based software engineering;fo (complexity);fractal dimension;heart rate variability;hoc (programming language);metamodeling;personalization;prototype;recursion;sensor;software developer;software development;unified model;unified modeling language;user modeling;xfig	Eyal Dim;Tsvi Kuflik;Iris Reinhartz-Berger	2015	User Modeling and User-Adapted Interaction	10.1007/s11257-015-9159-1	user interface design;user;simulation;user modeling;human–computer interaction;computer science;user requirements document;machine learning;user interface;world wide web	SE	-48.16096040543367	22.626632526278414	33600
a032999fd7b34b99c0e645de60e46ae9edc59bc3	a formal approach to component adaptation	component based software engineering	Component adaptation is widely recognised to be one of the crucial problems in Component-Based Software Engineering (CBSE). We present a formal methodology for adapting components with mismatching interaction behaviour. The three main ingredients of the methodology are: (1) the inclusion of behaviour specifications in component interfaces, (2) a simple, high-level notation for expressing adaptor specifications, and (3) a fully automated procedure to derive concrete adaptors from given high-level specifications. 2003 Elsevier Inc. All rights reserved.	component-based software engineering;high- and low-level	Andrea Bracciali;Antonio Brogi;Carlos Canal	2005	Journal of Systems and Software	10.1016/j.jss.2003.05.007	reliability engineering;computer science;systems engineering;component-based software engineering;programming language;engineering drawing	SE	-50.53245763040348	25.74081542525588	33603
2b3525af27763ea72e8773144956c09fba7c8828	case studies of autonomy	case studies	Autonomy is a quality for devices and creatures that perform tasks with relative independence from their designers and sources of authority. We discuss the idea and present two case studies to illustrate that the parameters for Autonomy are highly domain dependent.	autonomy	Henry Hexmoor	2000			knowledge management	HCI	-43.411376550142286	19.44036593656499	33627
3b90ac6325a3c16ff314ae73fdeeaefacc7ae11d	mfi based interoperability measurement of business models in service-based enterprises	interoperability mathematical model business computational modeling numerical models analytical models data models;interoperability features;service based enterprise;mfi;matrix algebra;business data processing;interoperability measurement;interoperability features interoperability measurement mfi heterogeneous business models service based enterprise;open systems;heterogeneous business models;interoperability measurement matrix mfi based interoperability measurement metamodel framework of interoperability business models service based enterprises partial semantic interoperability rgps dimension role goal process service dimension interoperability features;open systems business data processing matrix algebra	Various business models of service-based enterprise exist and are currently used in industry, whilst their definitions, structures, functions, and supporting tools are quite different from each other. For interoperability, the partial semantic interoperability between heterogeneous business models is challenging to achieve. Almost all of the enterprise business models can be described from the four major dimensions: Role, Goal, Process, Service (RGPS), consequently in this paper, a business model of service-based enterprise is actually a specific RGPS model, an approach for measuring the interoperability of RGPS models is proposed. At first, the RGPS interoperability features framework is constructed based on Meta-model Framework of Interoperability (MFI), and it is specified to be the interoperability features set of RGPS models, secondly, the interoperability features set and a mathematical method are proposed to identify and quantify a RGPS model and its interoperability features, then the model instance of the RGPS model is produced, next, we calculate the similarity between two model instances, and obtain the measuring results of interoperability between corresponding RGPS models, which is used to build the interoperability measurement matrix of RGPS models set.	metamodeling;semantic interoperability;while	Zhao Li;Peng Liang;Yi Zhao;Keqing He	2013	2013 Ninth International Conference on Computational Intelligence and Security	10.1109/CIS.2013.82	semantic interoperability;interoperability;knowledge management;data mining;database;open system	Web+IR	-57.08434914250539	18.543917456675892	33628
3450d41f2daab3b50ecc29b4c1d7a80b25760608	cross-platform development: software that lasts	software design;software portability;cross platform development;reflection;xml;software migration;formal specification;middleware;software change management;software systems;satisfiability;component based software engineering;object oriented programming;software maintenance;software engineering	The design of software that is easy to port or deliberately targeted for multiple platforms is a neglected area of software engineering. A promising solution is to link components and toolkits through XML and reflection. One of the more compelling definitions of software engineering is, the multiperson construction of multiversion software. The popular view of software engineering focuses on the first part of this definition - managing teams to produce a large product. But just as important is the view inherent in the second part of the definition - identifying specific parts of a product so that experts can design them and organizations can mass-produce them free of language and environment dependencies. Component-based software engineering has made tremendous strides toward satisfying both parts of the definition. Through the use of middleware constructed using reflection and controlled through XML specifications, it is possible to give the components in a large software system a high degree of platform and even language independence. The result is long lived software that can migrate gracefully as platforms improve and change	ccir system a;component-based software engineering;list of toolkits;middleware;reflection (computer programming);software system;xml	Judith Bishop;R. Nigel Horspool	2006	2006 30th Annual IEEE/NASA Software Engineering Workshop	10.1109/SEW.2006.14	verification and validation;xml;software engineering process group;software sizing;computer science;package development process;backporting;software design;social software engineering;software framework;component-based software engineering;software development;software design description;operating system;software engineering;middleware;software construction;database;software walkthrough;programming language;resource-oriented architecture;software deployment;software requirements;software system	SE	-52.65265952355518	29.44574360243702	33666
bbd2fa0bdb143eb33b19a403d183117fc4576c83	a first step towards a compiler for business processes		The verification of business processes is crucial since an erroneous execution causes high costs and damages the reputation of the providing company. The first step towards correct business processes is the verification of structural correctness, i.e., the absence of deadlocks and lack of synchronization.	business process;compiler	Thomas M. Prinz;Norbert Spieß;Wolfram Amme	2014		10.1007/978-3-642-54807-9_14	real-time computing;programming language	Vision	-45.48297060002201	31.79566014018185	33697
b4d9f9b6d68cfef4a030bed51427f7e8d98a4dae	an approach to software architecture analysis for evolution and reusability	product lines;product line;large scale;software architecture;software architecture analysis;software evolution;component reuse;software reusability;analysis;scenarios;software architectures	Software evolution and reuse is more likely to receive higher payoff if high-level artifacts—such as architectures and designs—can be reused and can guide low-level component reuse. In practice, however, high-level artifacts are often not appropriately captured. This paper presents an approach to capturing and assessing software architectures for evolution and reuse. The approach consists of a framework for modeling various types of relevant information and a set of architectural views for reengineering, analyzing, and comparing software architectures. We have applied this approach to large-scale telecommunications systems, where the approach is useful to reveal areas for improvement and the potential for reuse.	artifact (software development);code refactoring;high- and low-level;norm (social);software architecture;software evolution;third-party software component	Chung-Horng Lung;Sonia Bot;Kalai Kalaichelvan;Rick Kazman	1997		10.1145/782010.782025	domain analysis;reference architecture;software architecture;reusability;verification and validation;database-centric architecture;software sizing;package development process;backporting;software evolution;social software engineering;software framework;component-based software engineering;software development;software design description;software engineering;domain engineering;software construction;analysis;software architecture description;resource-oriented architecture;software deployment;software system	SE	-60.07067956624954	23.210495236200927	33712
8cb515289c5b6bde4b81599361d16cd7a5ff3d53	using diagrams to give a formal specification of timing constraints in z	formal specification;formal semantics;specification language;temporal constraints;time constraint	The need to represent timing requirements for computer systems in a formal way is being addressed by a growing number of specification techniques. However, a common weakness in these techniques is understandability, as a specification is often used to communicate between interested parties who may not possess the skills necessary to interpret a formal specification. Some atemporal specification languages deal with this problem by means of graphical notations with associated formal semantics (e.g. statecharts), although to the knowledge of the author, no such technique exists for dealing with temporal constraints in such a way. This paper presents causal timing diagrams, one possible approach for describing timing requirements graphically with an underlying formal semantics.	causal filter;causality;diagram;digital timing diagram;display resolution;formal methods;formal specification;refinement (computing);requirement;semantics (computer science);specification language;supercomputer education research centre;z notation	Andrew Coombes;John A. McDermid	1992		10.1007/978-1-4471-3556-2_9	formal system;formal methods;object language;specification language;formal verification;z notation;formal semantics;formal specification;database;refinement;programming language;programming language specification;algorithm;language of temporal ordering specification	SE	-43.20900672000949	29.42947138379142	33804
95252600eb7169b1104e195f9c5a06099e1393ed	e-commerce video annotation using goodrelations-based lods with faceted search in smart tv environment	e commerce;linked open data;video annotation;ontology	TV-commerce is a new form of shopping that allows consumer to view, select and buy products from Smart TV. To do so, sellers annotate videos and associate it with information from online e-commerce systems in a semantic manner. In this work, we propose an e-commerce information derivation mechanism for video annotation using Linked Open Data (LOD) with faceted search. Annotation information is derived from e-commerce LODs, which linked distributed data across e-commerce web. We incorporated faceted search to allow consumer to easily make a information derivation query defined by GoodRelations ontology. The derived information is displayed as a faceted graph facilitating information choice.	e-commerce;faceted classification;smart tv	Trong Hai Duong;Ahmad Nurzid Rosli;Visal Sean;Kee-Sung Lee;GeunSik Jo	2012		10.1007/978-3-642-34707-8_26	computer science;ontology;linked data;internet privacy;world wide web;information retrieval	AI	-38.36290678935024	7.6405363247270985	33807
3285f95db275bd395872fc5b835573b5894880ef	product lifecycle management model for new technology based enterprises	product lifecycle management;collaborative engineering;new technology based enterprise;product requirement	This research is focused in a Product Lifecycle Management (PLM) strategy for New Technology Based Enterprises (NTBE) for solving difficulties for integrating the product requirements and for improving the collaboration with the external contributors that occur in almost all the PLM stages, considering the limited resources of a Small Enterprise. In this work, we analyze a case study of the collaboration between a New Technology Based Enterprise, its Suppliers and Customers and we present a Product Requirement Representation considering the International Standard ISO 10303-0239. After the analysis and with the presented product representation, we propose a PLM Reference Model and an implementation of Open Source Software as a low cost solution for enabling PLM in this kind of business collaborative environment.	iso 10303;open-source software;reference model;requirement	David A. Medina-Barbosa;Héctor R. Siller	2013		10.1007/978-3-642-40840-3_15	product cost management;innovation management;systems engineering;engineering;knowledge management;product lifecycle;product design specification;product and manufacturing information;product management;application lifecycle management;new product development;mechanical engineering	SE	-59.23692307275368	11.83348722812801	33861
9d1a51067e32e77a83744c70ff063e83b4ab656d	a pragmatic approach to the formal specification of interactive systems	formal specification;interactive system	In the thesis an approach to the formal specification of interactive systems which embodies a number of pragmatic criteria is presented. The criteria we use for pragmatism are that any proposed approach to specification should directly support usability reasoning, that the specifications should be expressive, and that they should be reusable. We examine the concept of usability reasoning, and use a model of reasoning which includes as components representation, input, observation, system behaviour and object structuring. Frameworks for reasoning about these components, and syntheses of these components are proposed. Expressiveness and reuse issues are examined in an object-oriented context, and two models of object interaction examined with respect to a number of criteria. Based on the understanding gained from exploration of these issues of reasoning, expressiveness and reuse, we develop an approach to the specification of interactive systems. We build on the existing notation of Object Z, but present a new schema calculus to allow interactive behaviour to be described more conveniently. To demonstrate its pragmatism, we apply this approach to a substantial case study.	formal specification;object-z;usability	Gavin John Doherty	1998			formal methods;specification language;formal verification;system requirements specification;formal specification;refinement;language of temporal ordering specification	SE	-46.500210989595914	25.472204702065156	33870
0ed5223c475b45879cafd9932df19f72b5355692	service communities: applications and middleware	social communication;service communities;web service;service groups;marketplaces;middleware	Businesses increasingly provide and use services, applying formal (Web) services technology for the description, composition, and management of software as services. At the same time, social communities are emerging on the Web, applying less formal practices and Web 2.0 technology for the dissemination and aggregation of diverse content. In this paper, we are interested in the combination of these two trends in the form of service communities: social and business communities exchanging services. We discuss applications of service communities and introduce the concept of Service Clubs as a structuring mechanism for communities. Clubs have been specifically designed to support community-based, per-project interaction and composition of services.	middleware;web 2.0;world wide web	Stefan Tai;Nirmit Desai;Pietro Mazzoleni	2006		10.1145/1210525.1210531	service product management;differentiated service;knowledge management;service delivery framework;marketing;ws-policy;service design;business;services computing;world wide web;service system	Web+IR	-47.444913493225414	13.651709003375741	33886
e033389299ff9e1db096a8898b71cdd437949736	intelligent agents for coalition search and rescue task support	semantic web service;search and rescue;artificial intelligence applications institute;cooperative agents;conference paper;coalition;intelligent agent;semantic web;artificial intelligence;informatics;computer science;policy management;knowledge base	The Coalition Search and Rescue Task Support demonstration shows cooperative agents supporting a highly dynamic mission in which AI task planning, inter-agent collaboration, workflow enactment, policy-managed communications, semantic web queries, semantic web services matchmaking and knowledge-based notifications are employed.	intelligent agent;knowledge-based systems;semantic web service;technological convergence	Austin Tate;Jeff Dalton;Clauirton de Siebra;J. Stuart Aitken;Jeffrey M. Bradshaw;Andrzej Uszok	2004			knowledge base;computer science;knowledge management;artificial intelligence;semantic web;social semantic web;data mining;web intelligence;informatics;world wide web;intelligent agent	AI	-45.326695999564635	9.777259658948665	33946
e3cdd482609b63097f37999988a1636d603a1eec	decentralising the digital rights management value chain by means of distributed license catalogues	web engineering;business modelling;digital content;value chain;digital right management	Digital Rights Management (DRM) systems’ interoperability is becoming one of the main obstacles for their wider adoption, especially from medium and small size users. Interoperability issues affect, among others, the management of content usage rules by third parties (authorities) and the automation of licensing procedures upon the purchase of digital content. The fundamental question of who is handling content licenses in the national or global DRM value chain is complex, with business, social and technological extensions. In this paper, we discuss current trends in DRM systems technology and business modelling and briefly present a proposal for handling digital content licensing, Distributed License Catalogues (DLCs). The DLC concept, borrowed from web engineering, makes available (“advertises”) content or services concerning DRM functionalities, enabling multi-party	digital recording;digital rights management;e-commerce;ecosystem;interoperability;management system;service-oriented architecture;service-oriented device architecture;web engineering	Bill Vassiliadis;Vassilis E. Fotopoulos;Athanassios N. Skodras	2006		10.1007/0-387-34224-9_81	digital asset management;content management;value chain;knowledge management;multimedia;web engineering;world wide web	HCI	-49.33364527702573	15.087003886237625	34016
d3c0a74b8754ad10400eb0b4decc3bded0cb9fd7	bpaas: a platform for artifact-centric business process customization in cloud computing		As a new service paradigm of Software-as-a-Service (SaaS),Business Process-as-a-Service (BPaaS). BPaaS is used to build a cost-effective Business Process Management (BPM) system. Based on universal Artifacts, we develop a framework named SeGA (Self-Guided Artifact). In SeGA, a BPM system is capable of executing business processes from multiple clients, and responding query at runtime. what's more, by the template-based cascading data mapping method, entity to be synchronized with database automatically, so each BP instance can modify its process entity without worrying about the database access. In this paper, we conduct a deep research and implement a prototype system for Artifact process design.	artifact-centric business process model;beam propagation method;cloud computing;programming paradigm;prototype;run time (program lifecycle phase);software as a service	Min Gao;Yuyu Yin;Ying Li;Xingfei Wang;Lipeng Guo;Zaidie Chen	2017		10.18293/SEKE2017-196	personalization;systems engineering;business process;computer science;cloud computing	DB	-56.02632879424233	19.39192562970708	34072
471e5ec4444f0f7f730dcdb9e57e6ffdb31a6b08	service storm: a self-service telecommunication service delivery platform with platform-as-a-service technology	value added services;web 2 0 technology;dynamic topology deployment;customer services;capacity planning;cloud environment;service provider;telecommunication services customer services internet resource allocation software architecture;cloud based resource isolation;resource allocation;long tail;biological system modeling;business storms biological system modeling clouds web services telecommunication services;business model;dynamic topology deployment service storm self service telecommunication service delivery platform platform as a service technology telecommunication service provider cloud environment web 2 0 technology cloud based resource isolation;service delivery platform;software architecture;storms;internet;clouds;platform as a service;business;web services;service storm;platform as a service telecommunication sdp cloud computing;telecommunication services;telecommunication sdp;time to market;self service telecommunication service delivery platform;telecommunication service provider;platform as a service technology;cloud computing	To attract and serve an expanded customer base, telecommunication service providers need to provide more targeted, focused and personalized services, which brings challenges to both business model and technologies to development of value added services. In this paper, we introduce Service Storm, a novel self-service telecommunication Service Delivery Platform with Platform-as-a-Service technologies to support rapid and flexible construction and delivery of value added services in the cloud environment as an open developer community. Firstly, we analyze the characteristics of four categories of users including Individual User, Organization User, Telecommunication Operator, and Business Partner, and present the architecture of Service Storm to support new business model targeting at long tail applications as well as conventional business models. Then we highlight the key technologies including 1) Rapid assembly model and tools for codeless and off-premise integration of telecom services and application logic based on Web 2.0 technologies, 2) Cloud based resource isolation, management, capacity planning and scaling for dynamic topology deployment and elastic infrastructure support, and 3) Automatic deployment and monitoring in runtime. Finally we illustrate the sample of SMS and Web based mobile workflow for insurance order management to show the advantages of Service Storm. We demonstrate how these technologies and architectures enable the new business model for telecommunication operator and significantly enhance the diversity of value added services with lower cost and shorter time to market.	business logic;cloud computing;long tail;order management system;personalization;platform as a service;software deployment;web 2.0	Yu Chen Zhou;Liang Xue;Xin Peng Liu;Xi Ning Wang;Xiao Xing Liang;Chang Hua Sun	2010	2010 6th World Congress on Services	10.1109/SERVICES.2010.45	service delivery framework;business;services computing;world wide web;computer security;computer network	HCI	-50.628449646349544	16.488853756488176	34082
be491c7df70c67ba43ff61dfe9f4b3b8fb261dd1	the role of architecture and ontology for interoperability	610 medizin	Turning from organization-centric to process-controlled or even to personalized approaches, advanced healthcare settings have to meet special interoperability challenges. eHealth and pHealth solutions must assure interoperability between actors cooperating to achieve common business objectives. Hereby, the interoperability chain also includes individually tailored technical systems, but also sensors and actuators. For enabling corresponding pervasive computing and even autonomic computing, individualized systems have to be based on an architecture framework covering many domains, scientifically managed by specialized disciplines using their specific ontologies in a formalized way. Therefore, interoperability has to advance from a communication protocol to an architecture-centric approach mastering ontology coordination challenges.	as-interface;architecture framework;autonomic computing;bus mastering;communications protocol;computation (action);interoperability;ontology (information science);personalization;solutions;ubiquitous computing;sensor (device)	Bernd Blobel;Carolina González;Frank Oemig;Diego M. Lopez;Pirkko Nykänen;Pekka Ruotsalainen	2010	Studies in health technology and informatics	10.3233/978-1-60750-563-1-33	semantic interoperability;interoperability;computer science;systems engineering;knowledge management;data mining;cross-domain interoperability	HCI	-50.045736979516306	10.982201809392983	34091
e50afb4ac15cfc07296e4742a8fc6279f0e62f49	interaction semantics and its implications for an interaction oriented architecture of iot-type applications		"""Several synergistic trends, subsumed under the phrase""""Internet of things (IoT)""""massively drive the increasing importance of networking applications. In the past, the exponential growth of the Internet was mainly due to semantically agnostic transport protocols. In the future it is to be expected that, because of the increasing autonomy of technical systems, it becomes necessary to better understand the nature of the semantics of these interaction networks to create appropriate networking applications. Appropriate means that the architecture of these applications allows to minimize the effort to adapt these applications to the permanently changing interaction networks. The proposed interaction oriented architecture is based on a reference model of interaction semantics. It provides guiding principles on how to design networking applications. The reference model of interaction semantics provides: a unifying description of the things in the physical, the information and the human world; an interaction model that is of direct runtime relevance; an understanding for how hierarchical structured components can cooperate loosely coupled; a concept to determine how much semantics has to be common to enable components of different semantic domains to cooperate loosely coupled; and a data type model. The software reference architecture provides: a definition of software layers; means to express vertical interactions, that is interactions which demarcate a software layer; means to express horizontal interactions, that is, between processes in the same software layer; a definition of a component and how to distinguish it from other entities like systems or objects; and a model how to separate reusable from non-reusable parts of an application's functionality."""	entity;interaction network;internet;loose coupling;reference architecture;reference model;relevance;software architecture;synergy;time complexity	Johannes Reich	2017	CoRR		computer science;theoretical computer science;data mining;distributed computing	SE	-48.108398629566736	19.607887108238568	34099
343f9b1167d3867272bd755a0c3e4ecb1d40761f	workflow support for electronic commerce applications	extensible markup language;b to b and b to c commerce;electronic commerce;extensible routing;semantic information;xrl;document management architecture;xml;edi;inter organizational electronic commerce;document management	Internet-based electronic commerce is becoming the next frontier of new business opportunities. However, commerce on the Internet is seriously hindered by the lack of a common language for collaborative commercial activities. Although XML (Extensible Markup Language) allows trading partners to exchange semantic information electronically, it does not provide support for document routing. In this paper, we describe various interorganizational electronic commerce applications and discuss their needs for workflow support. Then, we propose a blueprint for XRL, an Extensible Routing Language that enables routing of commercial documents over the Internet and helps in creating truly intelligent documents. This routing language is simple, yet powerful enough to support flexible routing of documents in the Internet environment.	blueprint;e-commerce;intelligent document;internet;markup language;routing;xml	Akhil Kumar;J. Leon Zhao	2002	Decision Support Systems	10.1016/S0167-9236(01)00114-2	e-commerce;xml;computer science;data mining;database;world wide web	DB	-47.98245419900671	8.964012250725853	34118
5c7b902358a1a76bf87d4c32c2192343d501fd26	visual notation design 2.0: towards user comprehensible requirements engineering notations	analytical models;semantic transparency property;i notation;formal specification;prosumers;standards;semantic transparency property visual notation design 2 0 user comprehensible requirements engineering notations business analysts end users business stakeholders re notations i notation statistical analysis web 2 0 collective intelligence prosumers empirical research;prototypes;biological system modeling;semantics;business analysts;re notations;visualization;visual languages;internet;visual languages formal specification internet statistical analysis user centred design;statistical analysis;end users;semantics visualization prototypes business standards biological system modeling analytical models;business;web 2 0;user centred design;analysis;collective intelligence;end user communication;visual notation design 2 0;user comprehensible requirements engineering notations;requirements analysis visual languages empirical research modelling analysis end user communication;business stakeholders;empirical research;requirements analysis	The success of requirements engineering depends critically on effective communication between business analysts and end users, yet empirical studies show that business stakeholders understand RE notations very poorly. This paper proposes a novel approach to designing RE visual notations that actively involves naïve users in the process. We use i*, one of the most influential RE notations, to demonstrate the approach, but the same approach could be applied to any RE notation. We present the results of 5 related empirical studies that show that novices outperform experts in designing symbols that are comprehensible to novices: the differences are both statistically significant and practically meaningful. Symbols designed by novices increased semantic transparency (their ability to be spontaneously interpreted by other novices) by almost 300% compared to the existing i* notation. The results challenge the conventional wisdom about visual notation design: that it should be conducted by a small group of experts; our research suggests that it should instead be conducted by large numbers of novices. The approach is consistent with Web 2.0, in that it harnesses the collective intelligence of end users and actively involves them in the notation design process as “prosumers” rather than passive consumers. We believe this approach has the potential to radically change the way visual notations are designed in the future.	collective intelligence;requirements engineering;web 2.0	Patrice Caire;Nicolas Genon;Patrick Heymans;Daniel L. Moody	2013	2013 21st IEEE International Requirements Engineering Conference (RE)	10.1109/RE.2013.6636711	requirements analysis;the internet;end user;visualization;computer science;systems engineering;knowledge management;software engineering;analysis;data mining;formal specification;semantics;prototype;collective intelligence;programming language;empirical research;web 2.0	SE	-60.80132753696578	24.74613172396579	34119
2bf2b65183fc9928d31c9d3fa5c5d955d53473be	combining genetic programming and model-driven development	distributed algorithms;mofscript;genetic program;uml;genetic programming;model driven development;sensor networks;evolutionary algorithms;distributed systems;model driven architecture;xmi	Genetic Programming is known to provide good solutions for many problems like the evolution of network protocols and distributed algorithms. In most cases it is a hardwired module of a design framework assisting the engineer in optimizing specific aspects in system development. In this article we show how the utility of Genetic Programming can be increased remarkably by isolating it as a component and integrating it into the modeldriven software development process. Our Genetic Programming framework produces XMI-encoded UML models that can easily be loaded into widely available modeling tools, which in turn offer code generation as well as additional analysis and test capabilities. We use the evolution of a distributed election algorithm as an example to illustrate how Genetic Programming can be combined with model-driven development.	code generation (compiler);communications protocol;computation;correctness (computer science);distributed algorithm;distributed computing;genetic programming;model-driven architecture;model-driven engineering;programming language;simulation;software development process;software engineering;software testing;toolchain;unified modeling language;xml metadata interchange	Thomas Weise;Michael Zapf;Mohammad Ullah Khan;Kurt Geihs	2009	International Journal of Computational Intelligence and Applications	10.1142/S1469026809002436	unified modeling language;genetic programming;distributed algorithm;wireless sensor network;computer science;artificial intelligence;machine learning;evolutionary algorithm	SE	-54.07276201669257	30.222259008276843	34299
400259e11a9453b4f695aeb86f9d9cbe493a734f	a generic architecture for intelligent instruction for simulation modelling software packages	analytical models;front end;user interface;computer architecture;simulation software;computational modeling;development environment;graphical user interfaces;industrial training;object oriented;software package;graphic user interface;computer architecture software packages object oriented modeling computational modeling industrial training computer simulation graphical user interfaces analytical models courseware intelligent structures;technical report;intelligent structures;courseware;computer simulation;object oriented modeling;simulation modelling;software packages	This paper describes an architecture for an intelligent interactive instructional simulation modelling environment. It revolves around the production of tutorial and courseware authoring for different simulation software packages with a generic user interface shell. The generic shell is a 'front end' which provides a uniform graphical user interface to diverse simulation modelling software tutorials. An object oriented perspective is combined with tutorial activities based on the task classification structure to form the interactions between objects. The development environment brings together objects that are functionally coherent and allows them to share common resources within the shell.	coherence (physics);graphical user interface;interaction;simulation software	Tajudeen A. Atolagbe;Vlatka Hlupic	1996	Informatica (Slovenia)	10.1145/256562.256830	computer simulation;human–computer interaction;computer science;theoretical computer science;graphical user interface;computer engineering	Robotics	-35.150617124778535	26.83083999408873	34385
da389be7c1315e8f3353e9739034a5b71dfbae8d	acquiring cots software selection requirements	commercial off the shelf software;component based software engineering;software systems;component based software engineering process cots software selection requirements acquisition commercial off the shelf software development time customer needs cots product features user requirements commercial off the shelf products complex cots software system customer requirements pore procurement oriented requirements engineering template based method state of the art requirements acquisition;commercial off the shelf;systems analysis;requirement engineering;user requirements;development time;software tools software engineering design engineering systems engineering and theory testing software packages packaging guidelines iterative methods software systems;software packages;software selection;systems analysis software packages software selection	Commercial off the shelf software can save development time and money if you can find a package that meets your customer's needs. The authors propose a model for matching COTS product features with user requirements. To support requirements acquisition for selecting commercial off the shelf products, we propose a method we used recently for selecting a complex COTS software system that had to comply with over 130 customer requirements. The lessons we learned from that experience refined our design of PORE (procurement oriented requirements engineering), a template based method for requirements acquisition. We report 11 of these lessons, with particular focus on the typical problems that arose and solutions to avoid them in the future. These solutions, we believe, extend state of the art requirements acquisition techniques to the component based software engineering process.	requirement	Neil A. M. Maiden;Cornelius Ncube	1998	IEEE Software	10.1109/52.663784	reliability engineering;systems analysis;requirements analysis;software requirements specification;verification and validation;requirement prioritization;software engineering process group;software sizing;software verification;systems engineering;engineering;package development process;software design;social software engineering;user requirements document;component-based software engineering;software development;requirement;software engineering;software construction;requirements engineering;software measurement;software deployment;software requirements;software system;software peer review	SE	-60.97956562120295	27.036154235435674	34435
c130560173f5a4b7f1dcee1574be3029d06c0d28	formal methods: foundations and applications	computer science	An important question in software engineering is whether a program (or system) is correct with respect to its specification. The model-driven engineering discipline (MDE) is an approach to software development that supports domain-engineering, is generative and language-driven. We believe that this set of characteristics enable MDE as a suitable approach for the rigorous development of correct software systems as it allows us to focus on models rather than code. In this paper, we illustrate how programming languages theory, through operational semantics, and logic in computer science, through Description Logics, may help us identify meta-properties and techniques to reason about MDE models.	description logic;domain engineering;formal methods;logic in computer science;model-driven architecture;model-driven engineering;operational semantics;programming language;software development;software engineering;software system	Takeo Kanade;Josef Kittler;Alfred Kobsa;John C. Mitchell;Moni Naor;Demetri Terzopoulos	2013		10.1007/978-3-642-41071-0	computational science;applied mathematics;computer science	SE	-45.31250961374266	27.457370809569195	34442
df7f5770b4bb069c95985dc783b15cc0692de270	correctness of aspect-oriented business process modeling		Purpose Business process models, while primarily intended for process documentation, communication, and improvement, are often also used as input for developing process-oriented software systems [1]. Ensuring correctness, handling complexity and improving reusability and maintainability of business process models are important for all these goals. The purpose of this paper is to propose an aspect-oriented business process modeling and correctness controlling method based on Petri nets to satisfy these goals. Design/methodology/approach The aspect-oriented paradigm provides a proper mechanism to modularization, and thus reduces the complexity of models, and also improves reusability and maintainability. However, weaving aspects into base processes may bring in mistakes or errors. To ensure correctness of modeling, this paper presents a formal approach to modeling aspect-oriented business processes and a method to ensure modeling correctness. Petri net is used as the process modeling language and its analys...	aspect-oriented software development;business process;correctness (computer science);process modeling	Xu Wang;Xuan Zhang;Tong Li;Junhui Liu;Qingyi Chen	2018	Business Proc. Manag. Journal	10.1108/BPMJ-04-2016-0083	management science;maintainability;systems engineering;documentation;business process;petri net;correctness;computer science;business process modeling;reusability;process modeling	DB	-56.465531626559965	21.048828961427507	34452
e1f5097a846bcef8ebf7fb91ddca5f28692af227	ausms : un environnement pour l'extraction de sous-structures fréquentes dans une collection d'objets semi-structurés	document structure;estructura de documento;mise a jour;red www;structure document;reseau web;subestructura;data mining;recherche connaissance;semistructured data;semi structured data;dato semi estructurado;fouille donnee;estructura datos;sous structure;substructure;web mining;world wide web;structure donnee;puesta al dia;donnees semi structurees;structured documents;decouverte de sous structures frequentes;data structure;busca dato;data retrieval;updating;structured data;donnee semistructuree	Mining knowledge from structured data has been extensively addressed in the few past years. However, most proposed approaches are interested in flat structures. With the growing popularity of the Web, the number of semi-structured documents available fastly increases. Structure of these objects is irregular and it is clever to think that a query on documents structure is almost as important as a query on data. Moreover, manipulated data is not static because new updates are constantly realised. Problem of maintaining such substructures is then prior on researching them because, every time data is updated, found sub-structures could become invalid. In this paper we propose a system, called A.U.S.M.S. (Automatic Update Schema Mining System), allowing data retrieval, researching frequent sub-structures and maintaining extracted knowledge after sources evolutions. MOTS-CLES : découverte de sousstructures fréquentes, données semi-structurées, web mining.	data retrieval;document;information retrieval;semi-continuity;semiconductor industry;web mining;world wide web	Pierre-Alain Laur;Pascal Poncelet	2003			art;art history;cartography	DB	-36.125817402667494	10.661202878820506	34514
f7fef6c95e26d7544eed92b15df19579ffd49c73	simulation-based performance analysis of channel-based coordination models	composite web service;exponential distribution;performance evaluation;service orientation;coordination language;transient analysis;performance analysis;quality of service;coordination model;steady state	Quantifying the performance of component-based or serviceoriented systems is a complex task, e.g., it is non-trivial to calculate the end-to-end quality of service of a composite Web service. An established approach to reason about such systems in general is the use of coordination models, which can provide a formal basis for both their verification and implementation. An example of such a model is the channel-based coordination language Reo and its probabilistic extension Stochastic Reo. However, all existing performance analysis approaches for Stochastic Reo are restricted to the use of exponential distributions. To this end we introduce a transition structure, which enables a simulation approach for performance evaluation in Reo, enabling the use of arbitrary distributions and predefined probabilistic behaviors. Our approach supports steadystate and transient analysis and, moreover, scales much better than the existing automata-based algorithms.	agent-based model;algorithm;automata theory;automaton;component-based software engineering;end-to-end principle;performance evaluation;profiling (computer programming);quality of service;simulation;state space;steady state;time complexity;transient state;transition system;web service;windows steadystate	Chrétien Verhoef;Christian Krause;Oscar Kanters;Robert D. van der Mei	2011		10.1007/978-3-642-21464-6_13	exponential distribution;real-time computing;simulation;quality of service;computer science;theoretical computer science;steady state	AI	-36.47812586774336	30.938757692563378	34539
e08f04188e84c3dacaae72fe32afbbd51e639391	on the impact of layout quality to understanding uml diagrams: diagram type and expertise	unified modeling language layout quality impact uml diagrams diagram type;diagrams;unified modeling language;layout unified modeling language analytical models visualization sociology statistics accuracy;unified modeling language diagrams	Practical experience suggests that the use and understanding of UML diagrams is greatly affected by the quality of their layout. In previous work, we have presented evidence supporting this intuition. This contrasts with earlier experiments that yielded weak or inconclusive evidence only. In the current paper, we expand on our earlier experiments by varying both diagram types and populations studied. We find no difference in the beneficial evidence of good layout wrt. diagram types. We also find support for the hypothesis that experts benefit less than novices. While still lacking independent replication of our earlier results, these results add further evidence in support of our hypothesis.	diagram;unified modeling language	Harald Störrle	2012		10.1109/VLHCC.2012.6344480	timing diagram;state diagram;package diagram;communication diagram;activity diagram;systems modeling language;uml tool;interaction overview diagram;computer science;systems engineering;unified process;theoretical computer science;applications of uml;class diagram;story-driven modeling;engineering drawing;component diagram	HCI	-59.2674800932179	30.235499821261236	34545
8f648726ef362a0dd8e7605403561de78995d3d2	a design method of distributed workflow engine	wfes;activity diagram;workflow management software distributed processing purchasing systems analysis unified modeling language;distributed workflow engine design method;distributed processing;purchasing;wfms;design method;systems analysis;unified modeling language;online purchase books workflow engine distributed wfms wfes;enterprise workflow engine architecture;workflow management software;online purchase book;design methodology engines workflow management software distributed computing collaborative work computer architecture books application software table lookup computer applications;distributed;uml activity diagram distributed workflow engine design method enterprise workflow engine architecture concreted instance analysis online purchase book;workflow engine;concreted instance analysis;online purchase books;uml activity diagram	"""The technique of distributed workflow is a newer researching direction in the realm of computer's application, and the distributed execution of workflow engine is an inevitable trend of the development of workflow. Aimed at the practical requirement of enterprise, the architecture of workflow engine is put forward, the function of each part in the engine's architecture is described, and the executive process of workflow engine is analyzed. Finally, the design thought of workflow is applied to the concreted instance's analysis - """"online purchase books"""", and the executive process of the instance is described by the activity diagram of UML"""	activity diagram;book;unified modeling language;workflow engine	Qiuyu Zhang;Peng Huang	2006	2006 10th International Conference on Computer Supported Cooperative Work in Design	10.1109/CSCWD.2006.253001	workflow;xpdl;activity diagram;computer science;workflow management coalition;software engineering;database;windows workflow foundation;world wide web;workflow management system;workflow engine;workflow technology	DB	-51.04257101901654	17.47306066946817	34563
d5d95c9ad81daa9422353ca0c185b23cfcca17c3	formal framework and necessary properties of the fusion of input modes in user interfaces	multimodal interface;user interface;fusion;formal methods;interface design;formal method;multiple input devices;ambiguity;multimodal interfaces	Multiple input devices are increasingly used in user interfaces to make human-computer communication more efficient and effective. Interface designers have not only to decide on which input modes should be supported, but also how to fuse them into a single representation format that can be processed by the underlying application system. Drawing appropriate decisions requires, however, a sufficient understanding of the properties of fusion itself. While others have informally characterized input fusion as a transformation between information types, the purpose of this paper is to explore fusion by means of formal process modelling. That is, fusion processes are defined in a formal framework which allows to proof the existence of necessary properties following directly from the process definitions. The presented approach can be applied to analyze and compare fusion processes in existing systems, as well as an aid for interface designers, who have to verify the behaviour of their systems.	description logic;deterministic algorithm;formal methods;formal system;input device;multimodal interaction;one-to-many (data model);process modeling;user interface design	Giorgio P. Faconti;Monica Bordegoni;Klaus Kansy;Panos E. Trahanias;Thomas Rist;Michael D. Wilson	1996	Interacting with Computers	10.1016/0953-5438(96)01029-6	formal methods;human–computer interaction;fusion;computer science;theoretical computer science;interface design;user interface	SE	-44.41411193388435	26.147441494766507	34575
7b4b12474a9ab750d29c62a90faf61b61b90f1e1	extending assl: making uml metamodel-based workflows executable	model validation	ASSL is a language that enables UML developers to test and certify UML and OCL models [5]. Snapshots of system states are semi-automatically created and main parts of the UML action semantics is implemented by the language. Its interpreter is the well-known UML modeling tool USE. The article proposes a number of language extensions to ASSL. These include (sub-) procedure calls and preand postcondition checks on entering and exiting of operations using OCL. The paper motivates the need for these extensions as well as their usage and development along the problem of metamodel-based execution of workflow models. Executable workflow models, driven by ASSL procedures, are introduced in detail to present the usage of ASSL and our extensions.	action (uml);action semantics;control flow;executable;imperative programming;invariant (computer science);metamodeling;object constraint language;postcondition;precondition;runtime system;semiconductor industry;sequence diagram;uml tool;unified modeling language;whole earth 'lectronic link	Jens Brüning;Lars Hamann;Andreas Wolff	2011	ECEASST	10.14279/tuj.eceasst.44.619	computer science;applications of uml;database;programming language	PL	-46.73317044305353	26.719898530647576	34576
ae91fa20fb3cfdb049723827752a245463a51b8e	using ocl in the formal specification of the library standards	uml;library metadata;ocl;marc	The goal of the research was to check whether we can use a formal specification language such as OCL — Object Constraint Language to express all constraints on the library records proposed by the MARC 21 library standard. The main results are the classification and systematization of the constraints on the structure and the content of the MARC records as well as the specification of the constraints on the data model of MARC 21 in OCL. The obtained results are used in the implementation of the editor for MARC records for validation of the user input. The originality of the work is the adoption of the formal approach in specification of the constraints instead of writing source code in programming language.	formal specification;object constraint language	Gordana Rudic;Bojana Dimic Surla	2013	International Journal of Software Engineering and Knowledge Engineering	10.1142/S0218194013500101	unified modeling language;computer science;software engineering;database;programming language;object constraint language	SE	-47.80652986921422	26.785980888687757	34617
29cda824324ddf84b3b07e0900f164217f38d462	towards a rule-based approach for context-aware applications	context aware application;context awareness;context aware;rule based systems;eca pattern;rule based system;rule based;domain specific language;eca dl	ion, in computer science, is a mechanism and practice to reduce and factor out details so that one can focus on few concepts at a time; Symbolism is the systematic or creative use of symbols as abstracted representation of concepts.	business rules engine;clips;computer science;context awareness;correctness (computer science);domain-specific language;emoticon;event condition action;expert system;high-level programming language;information model;integrated development environment;java;jess;knowledge base;level structure;logic programming;machine translation;mandarax;problem domain;prototype;replay attack;requirement;rule-based system;separation of concerns	Laura Daniele;Patricia Dockhorn Costa;Luís Ferreira Pires	2007		10.1007/978-3-540-73530-4_5	computer science;data mining;database;world wide web	AI	-47.48468243925643	22.161133146343452	34620
ec9b838f5e94d8213ad0832673aebba099525452	model transformation dependability evaluation by the automated creation of model generators	qa75 electronic computers computer science;qa76 computer software	This thesis is on the automatic creation of model generators to assist the validation of model transformations. The model driven software development methodology advocates models as the main artefact to represent software during development. Such models are automatically converted, by transformation tools, to apply in different stages of development. In one application of the method, it becomes possible to synthesise software implementations from design models. However, the transformations used to convert models are man-made, and so prone to development error. An error in a transformation can be transmitted to the created software, potentially creating many invalid systems. Evaluating that model transformations are reliable is fundamental to the success of modelling as a principle software development practice. Models generated via the technique presented in this thesis can be applied to validate transformations. In several existing transformation validation techniques, some form of conversion is employed. However, those techniques do not apply to validate the conversions used there-in. A defining feature of the current presentation is the utilization of transformations, making the technique self-hosting. That is, an implementation of the presented technique can create generators to assist model transformations validation and to assist validation of that implementation of the technique.	dependability;model transformation;model-driven engineering;self-hosting;software development process	Seyyed Madasar Ali Shah	2012			verification and validation;computer science;systems engineering;software development;computer engineering	SE	-55.00457503662765	25.774399929230096	34642
b27ff2f337f4b4c0e8a4f894240fdd8f5d494c47	a template for requirement elicitation of dependable product lines	fault tolerant;product line;requirements elicitation;software component;development time;software product line	Engineering software quickly and at a low cost, while preserving quality, is a well-known objective that has not been reached. Reducing the development time can be achieved by reusing software components, as proposed in the software product line development approach. Dependability may be one of the most important attributes concerning quality, due to negative consequences (health, cost, time, etc.) induced by non-dependable software. Our proposal, presented in this article, is to offer a means to elicit the requirements of a product line, such that the dependability attribute would be explicitly considered, and such that reuse would be achieved by differentiating commonalities and variabilities between products. The proposed semi-formal template includes product commonality and variability elicitation, as well as elicitation of normal, misuse and recovery scenarios. Furthermore, we allow the elicitation of the advanced transactional nature of scenarios, since it provides us with a way to elicit fault tolerance requirements, which is our targeted means to achieving dependability.		Barbara Gallina;Nicolas Guelfi	2007		10.1007/978-3-540-73031-6_5	reliability engineering;fault tolerance;real-time computing;requirement prioritization;software quality management;computer science;systems engineering;engineering;component-based software engineering;requirement;requirements elicitation;product engineering	Logic	-59.12136736207798	27.6089976472354	34645
2ff3c1ff16f8b26ba4d27bcdc0728e9c56a4cea7	delta-oriented model-based integration testing of large-scale systems	variable software architectures;regression testing;model based testing;large scale systems	Software architecture specifications are of growing importance for coping with the complexity of large-scale systems. They provide an abstract view on the high-level structural system entities together with their explicit dependencies and build the basis for ensuring behavioral conformance of component implementations and interactions, e.g., using model-based integration testing. The increasing inherent diversity of such large-scale variant-rich systems further complicates quality assurance. In this article, we present a combination of architecture-driven model-based testing principles and regression-inspired testing strategies for efficient, yet comprehensive variability-aware conformance testing of variant-rich systems. We propose an integrated delta-oriented architectural test modeling and testing approach for component as well as integration testing that allows the generation and reuse of test artifacts among different system variants. Furthermore, an automated derivation of retesting obligations based on accurate delta-oriented architectural change impact analysis is provided. Based on a formal conceptual framework that guarantees stable test coverage for every system variant, we present a sample implementation of our approach and an evaluation of the validity and efficiency by means of a case study from the automotive domain.	integration testing	Malte Lochau;Sascha Lity;Remo Lachmann;Ina Schaefer;Ursula Goltz	2014	Journal of Systems and Software	10.1016/j.jss.2013.11.1096	test strategy;reliability engineering;black-box testing;regression testing;model-based testing;simulation;orthogonal array testing;software performance testing;white-box testing;system integration testing;computer science;systems engineering;acceptance testing;software reliability testing;software engineering;conformance testing;functional testing;risk-based testing;software testing;system testing;test management approach	SE	-57.47793590087023	28.734005693433332	34677
186d86876cf31e7cdc658a66231dcb91e9d00d45	software process models	life cycle model;software process model;software life cycle	(1) Specification. The functionality of the software and its operating constraints are specified in detail. (2) Design and implementation. The overall structure of the software is designed and specific software components identified. These are implemented using some programming language, often by separate individuals or teams. (3) Integration and testing. Individually developed modules are integrated into a complete system and tested. (4) Operation and maintenance. The software is delivered to the customer and modified to meet changing requirements and to repair errors discovered in use. The problem with this model is the lack of feedback from one stage to another. Specification, design, and implementation problems are often discovered only after implementation when the system has been integrated. Once a specification has been frozen, it is difficult to change in response to changing user needs. However, stakeholders in the system (end-users, managers, and so on) find it difficult to anticipate their real needs for software support, and both organizational and end-user requirements change during the development process. There is therefore a constant pressure for specification change. This means that, in practice, there is always some iteration between the phases of the model, but this is invariably fairly limited and the delivered software may not meet the real needs of the customer. This led to widespread criticism of the waterfall model [Gladden 1982; McCracken and Jackson 1982] and the development of alternative software processes. Incremental models [Mills et al. 1980] are a development of the waterfall model that attempt to provide some development stability while allowing users some opportunity for specification change. In this approach, the system functionality is partitioned into a series of increments and these are developed and delivered one by one. While one increment is being developed, its specification is frozen, but the specification of other increments may change. A version of the system is delivered early to users and they may experiment with it to help clarify their needs for later system increments.	component-based software engineering;feedback;incremental backup;iteration;jackson;programming language;requirement;software testing;user requirements document;waterfall model	Ian Sommerville	1996		10.1145/234313.234420	verification and validation;software sizing;computer science;software development;software construction;systems development life cycle;empirical process;goal-driven software development process;software development process	SE	-60.17846683376746	27.29225923743268	34719
11c7ce6a5bad409646fe482e901d2b7cf87921af	data integration, semantic data representation and decision support for situational awareness in protection of critical assets		This paper presents the design and development of a system for data integration, data representation, situational awareness and decision support that has been developed in the EC-co-funded research project MOSAIC. The paper motivates the architecture and describes the data representation model and the developed system components. It discusses the approach for improved situational awareness and decision support as a novel integration of systems developed under the MOSAIC project as deployed for the protection of critical assets as a demonstrator.	data (computing);decision support system;ncsa mosaic	Atta Badii;Marco Tiemann;Daniel Thiemert	2014	2014 International Conference on Signal Processing and Multimedia Applications (SIGMAP)		decision support system;computer science;knowledge management;information security;semantic web;data mining;database;external data representation	Robotics	-51.638485887373996	5.01475864602191	34726
5ae5763fbc28dbeadf60893cacc38cd7ac5b0a21	the quality management metamodel in the enterprise architecture		"""The paper presents the methodology for determining, management, simulation and optimization of the quality of an enterprise architecture based on defined by the author of two metamodels: classes and processes for quality management of this architecture. The second of them (the process metamodel) of quality management developed in BPMN has undergone simulation and optimization using ARIS Business Process Simulator. The results of this simulation and optimization are presented in the article. The presented research method developed by the author, and the results are related to and are a creative extension of the following ISO standards: ISO/IEC 24744 [1], ISO/IEC 12207 [2], ISO / IEC 42010 [3] and the well-known methodologies: """" A Framework for Information Systems Architecture """" .-Zachman, J. A., and TOGAF : """" The Open Group Architecture Framework """""""	aris express;business process model and notation;capability maturity model integration;enterprise architecture;iso/iec 12207;iso/iec 42010;information system;mathematical optimization;metamodeling;partial template specialization;refinement (computing);simulation;systems architecture;the open group architecture framework;whole earth 'lectronic link	Jerzy Roszkowski;Agata Roszkowska	2013		10.1007/978-3-642-41947-8_2	enterprise architecture framework;functional software architecture;reference architecture;the open group architecture framework;model-driven architecture;enterprise software;nist enterprise architecture model;systems engineering;architecture domain;service-oriented modeling;enterprise architecture management;solution architecture;process management;enterprise architecture;enterprise integration;view model;enterprise information security architecture;enterprise information system;business architecture;enterprise life cycle	EDA	-57.42864440743378	16.49585407432906	34729
e32a5e18a88e226cf273fc3e4348c865b9cf92f7	dynamic web service composition within a service-oriented architecture	institutional repositories;web services service oriented architecture learning automation runtime quality of service cost function availability pressing resource management;service composition;fedora;cost function;learning;operant conditioning;availability;service orientation;reinforcement learning;resource management;user preferences;web service;runtime;multicriteria driven service composition;vital;web service composition;pressing;reinforcement learning algorithm;service oriented systems;web services;dynamic web service composition;reinforcement learning algorithm dynamic web service composition service oriented architecture distributed systems service oriented systems dynamic adaptation multicriteria driven service composition;learning artificial intelligence;quality of service;vtls;distributed systems;service oriented architecture;dynamic adaptation;ils;web services learning artificial intelligence;automation	Increasing automation requires open, distributed, service-oriented systems capable of multicriteria-driven, dynamic adaptation for appropriate response to changing operating conditions. We combine a simple architecture with a novel algorithm to enable openness, distribution, and multi-criteria-driven service composition at runtime. The service-oriented architecture involves mediator Web services coordinating other Web services into compositions necessary to fulfil user requests. By basing mediator services' behavior on a novel multicriteria-driven (including quality of service, deadline, reputation, cost, and user preferences) reinforcement learning algorithm, which integrates the exploitation of acquired knowledge with optimal, undirected, continual exploration, we ensure that the system is responsive to changes in the availability of Web services. The reported experiments indicate the algorithm behaves as expected and outperforms two standard approaches.	algorithm;concurrency (computer science);experiment;graph (discrete mathematics);openness;quality of service;reinforcement learning;rich representation language;run time (program lifecycle phase);service composability principle;service-oriented architecture;service-oriented software engineering;user (computing);web service	Ivan Jureta;Stéphane Faulkner;Youssef Achbany;Marco Saerens	2007	IEEE International Conference on Web Services (ICWS 2007)	10.1109/ICWS.2007.79	web service;computer science;knowledge management;resource management;ws-policy;database;services computing;law;world wide web;reinforcement learning	Robotics	-45.36372800878796	16.41067893951613	34735
c65a97de8ca3461c68979616eaa2305916b4fd59	modelling scm as a multi-layer interconnected constraint satisfaction problem	multi agent system;raw materials;job shop scheduling;software agent;constraint satisfaction;supply chains;software agents;qa75 electronic computers computer science;multi agent system constraints satisfaction;multi agent system constraints satisfaction supply chain model;production facilities;intelligent agent;supply chain;supply chain model;constraint satisfaction problem;intelligent networks;computer science;supply chain management;multiagent systems;supply chains intelligent agent decision making supply chain management intelligent networks production facilities software agents multiagent systems computer science job shop scheduling	The supply chain is a network of suppliers, factories, warehouses, distribution centres and retailers through which raw materials are acquired, transformed and delivered to customers. In recent years, the emergence of software agents has offered a new dimension to fulfill the desire for automating supply chains. Software agents are employed in supply chains to handle processes and decision making, especially at the operational level of the chain. In this paper we focus on modeling the three decision layers of supply chain management into a multi layer interconnected constraints satisfaction problem. Furthermore, we propose a multi agent system to accommodate the formalisation of the constraints model.	constraint satisfaction problem;emergence;multi-agent system;software agent	Areej Malibary;Maria Fasli	2009	2009 IEEE/WIC/ACM International Joint Conference on Web Intelligence and Intelligent Agent Technology	10.1109/WI-IAT.2009.292	supply chain management;service management;computer science;knowledge management;artificial intelligence;software agent;multi-agent system;supply chain	AI	-52.304584071091185	12.100759305338702	34858
a260735baf2c175a2bd277a3b5eec62cfebda7fb	cutter path simulation and product visualization using autocad	cad/cam;product visualization;simulation;numerical control cutter path;solid model;numerical control;computer aided design;solid modeling;computer aided manufacturing;cad cam;virtual machine	In this paper, a software tool for NC (numerical control) cutter path simulation and product visualization, 3D-Sim, is presented. 3D-Sim utilizes a commercial computer-aided design (CAD) software tool, AutoCAD, to perform virtual NC veri®cation. An NC program is interpreted and transformed into an AutoLISP program, which once loaded in AutoCAD allows the user to visualize the virtual machining operations and obtain a 3D solid model of the ®nal part. Incorporating NC veri®cation capability into CAD software tools not only reduces software cost but also shortens user training time. The resulting 3D solid model allows the user to visualize the ®nal product as well as perform more detailed analysis such as measuring the dimensions. 3D-Sim has been used in the senior/graduate level computer-aided manufacturing (CAM) course and was well-received by the student. This work is part of a longterm research effort to establish an integrated manufacturing environment where students can receive rigorous training and gain hands-on experience in collaborative manufacturing through the use of integrated computerized systems. ß2000 John Wiley & Sons, Inc. Comput Appl Eng Educ 8:	3d modeling;autocad;autolisp;computer-aided design;cutter expansive classification;eng-tips forums;hands-on computing;john d. wiley;nc (complexity);numerical analysis;programming tool;simulation;solid modeling;virtual machining	Samuel H. Huang;Kapil R. Bhura;Ge Wang	2000	Comp. Applic. in Engineering Education	10.1002/1099-0542(2000)8:2%3C113::AID-CAE6%3E3.0.CO;2-X	simulation;computer science;engineering;virtual machine;electrical engineering;artificial intelligence;operating system;computer aided design;numerical control;solid modeling;engineering drawing;computer-aided technologies;computer-aided manufacturing;mechanical engineering	EDA	-56.231253227828184	7.544664498637018	34883
7fc92ac2a177c4e382680b6003d1fc5196e150fb	everything-as-a-service platform for on-demand virtual enterprises	service oriented architectures;service oriented computing;web based services;dynamic collaborations;cloud computing;virtual enterprises	While constructing virtual enterprises, it is crucial to flexibly integrate heterogeneous business resources and processes of different business partners and make them collaborate dynamically. Keeping involved IT systems or components as autonomous and loose-coupled services, the “Everything as a Service” concept supports flexible integration of heterogeneous applications. We adopt this concept and analyze the challenges in virtual enterprise construction, then propose a service platform for on-demand virtual enterprises. The platform supports flexible integration of networked resources, and facilitates virtual enterprise construction with business process utility, trusted service composition and data service centric business collaborations. At the end of the paper, together with a case study, experimental evaluations in contexts of concurrent multi-users are presented, showing the effectiveness and performance of the platform.		Gang Li;Mingchuan Wei	2014	Information Systems Frontiers	10.1007/s10796-012-9351-3	knowledge management;operations management;database;world wide web	DB	-51.81950251255364	13.942543477265248	34884
93e762eb82e9322935b184dd81317ff94f2e1269	conceptual modeling in the classroom	conceptual model;focal point;database design	The conceptual model is the focal point of the process of database design. All activities either converge upon or emanate from the conceptual model. All structures, through mappings either into or out of the conceptual model, must be to some extent compatible with it. Students generally find it difficult to manage the complexity surrounding the conceptual model, its development and usage. This article describes one approach to overcoming this difficulty through an exercise in conceptual modeling and shows some of the results of this approach.	converge;database design;focal (programming language)	Andrew Pletch	1989	SIGMOD Record	10.1145/382272.382417	data modeling;conceptual model;data model;computer science;knowledge management;conceptual schema;conceptual model;conceptual system;domain model;data mining;conceptual design;conceptual framework;database;database design	AI	-34.27355512878968	12.483214333485096	34889
323fe35b737ccaccdae2b2267245fd856e53f619	model checking airline tickets reservation system based on bpel	protocols;web service;safety properties;automata;web services automata petri nets protocols safety software systems genetics writing formal verification software design;computational modeling;formal verification;model checking;fsm;business;web services;promela model checking airline tickets reservation system bpel business flow language web services fsm;business flow language;bpel;reservation computer systems;atmospheric modeling;petri nets;formal analysis;web services formal verification reservation computer systems;airline tickets reservation system;promela	BPEL is a business flow language which describes the composition of web services. Since business flow is very complex, the method of formalized analysis can help ensure the accuracy of composition of web services. For the Airline Tickets Reservation System described by BPEL, we provide a formalized analysis process with FSM in this paper, and finally translate it into programs described by Promela. The safety property and behavior property are verified with model checking tool SPIN, the results of experiment show no flaw in this system.	automata theory;business process execution language;finite-state machine;flaw hypothesis methodology;model checking;promela;spin;web service	Zhao Wei;Rongsheng Dong;Xiangyu Luo;Fang Liu	2009	2009 Third International Conference on Genetic and Evolutionary Computing	10.1109/WGEC.2009.86	web service;real-time computing;business process execution language;computer science;database;computer security	SE	-45.52687429609644	32.226795310805024	34903
3ef7dd4cbcdb59fd161254eff7a4fc25df07bc77	part iii. model-based test case generation	model based testing	  The previous parts of this book have, in general, been concerned with checking models against models. A theoretical underpinning  with, among other things, respect to completeness of these approaches has been given.    	test case		2004		10.1007/11498490_12	model-based testing;underpinning;econometrics;completeness (statistics);mathematics	NLP	-44.180932873644814	28.74784877602456	34917
b959ff2b45fd9b579efd2ceffd91d11016c179de	adaptation in mobile workflow management systems	workflow management;software systems;mobile computer;emerging technology;workflow management system;mobile systems;business process;mobile user	Workflow management systems (WFMS) are an emerging technology for supporting the coordinated execution of business processes by a group of users. One goal of introducing a WFMS into an enterprise is to integrate all personnel working on a business process into the system. This article describes a new approach to the integration of mobile users into a WFMS. This is of special interest because key personnel such as sales representatives and executives are often travelling and can only be integrated into the WFMS through mobile computing technologies. After introducing an architecture for mobile WFMS, we focus on the handling of one specific feature of mobile systems: the high diversity of environments in which mobile users operate. For handling this feature we have to implement adaptable software systems. In our approach, we start by introducing a formal model of mobile systems. This model offers a basis for the use of optimisation techniques to realise an adaptive mobile WFMS.	business process;mathematical model;mathematical optimization;mobile computing;software system	Olaf Zukunft	1997	Personal Technologies	10.1007/BF01299654	workflow;simulation;computer science;knowledge management;mobile business development;business process;emerging technologies;mobile computing;workflow management system;software system	DB	-54.933524296359	14.086288893827403	34935
ee9667f3e383fc1e91fdca734186b36ee00be7f6	classifying software requirements using kano's model to optimize customer satisfaction	qa76 computer software	Requirements elicitation is a critical and error-prone stage in software development where user requirements should be defined accurately to ensure the success of the software system. In a highly competitive market, businesses are focusing more on satisfying customer needs which largely affect customers decision to buy the software product, providing the potential for the success of the software in the market. This study aims to investigate whether eliciting and thus fulfilling most of the individual software requirements imply a high level of customer satisfaction, and what type of requirements that define the perceived product quality and as a result customer satisfaction. To achieve this goal, a questionnaire is conducted based on Kano’s model for customer satisfaction in an academic environment. The results showed the priorities that should be followed in the implementation of user requirements which may lead to a higher customer satisfaction and as a consequence to the success of the software.	cognitive dimensions of notations;high-level programming language;requirement;requirements elicitation;software development;software requirements;software system;user requirements document	Balsam A. Mustasfa	2014		10.3233/978-1-61499-434-3-271	voice of the customer;requirements analysis;software requirements specification;verification and validation;requirement prioritization;software quality management;business requirements;computer science;systems engineering;knowledge management;software development;requirement;customer satisfaction;customer retention;software deployment;software quality control;software quality;software quality analyst	SE	-61.71985367126394	26.817778173726527	34989
a1129ac7748fb4bb5a36482d1dfc37204ad263f7	knowledge integration in collaborative environments using supervised ontological alignment		The increasing demand for new technologies allow greater interactivity and participation of people in online environments. This interaction occurs, mainly, by social relationships in different levels, and the multimedia resource's search and sharing. These interactions produce a large amount of data and information. These have provided the rise of social networks, which operate with information and resource sharing tools. The information and resources produced in these collaborative environments are heterogeneous in essence, and stored in different kinds of data repositories. In order to provide a more easily and efficient way to found and share those data more efficiently, those repositories must be integrated in a single uniform format, automatically, and negotiated safe. Based on these aspects, this paper proposes ontological alignment method that allow integrate semantically different data and information repositories through an ontological layer, used to data conceptualization. This integration allows a collaborative system's users to exchange resources in a optimally way, using its own concepts as a filter to execute any tasks in the collaborative en-	conceptualization (information science);interaction;interactivity;knowledge integration;social network	Leandro Pupo Natale;Nizam Omar	2016		10.1007/978-3-319-53480-0_93	collaboration;interactivity;conceptualization;data mining;computer science;emerging technologies;ontology;knowledge integration;social network;shared resource;knowledge management	AI	-46.5050812768551	7.968087314473889	35019
e86483bf02944671ea22090f9bf0f73a6a8faf0b	design and implementation of an intelligent product agent architecture in manufacturing systems		Present-day manufacturing companies encounter a variety of challenges due to the dynamically changing industrial environment. Current control frameworks lack the adaptability and flexibility to effectively deal with challenges such as broken-down machines or altered customer orders. Multi-agent control has been proposed to improve the performance of manufacturing systems in uncertain or dynamic environments. Some multiagent architectures have been introduced with promising results. A key component of these architectures is the product agent, which is responsible for guiding a physical part through the manufacturing system based on the production requirements of the part. Even though the product agent has been previously used in multi-agent frameworks, a well-defined internal architecture for this agent has yet to be proposed. This work specifies a product agent architecture that can be utilized in multi-agent systems. The proposed architecture is tested using a manufacturing system simulation. The simulation results showcase the reactivity, proactiveness, and autonomy of the proposed product agent.	agent architecture;agent-based model;algorithm;autonomous robot;complex system;multi-agent system;requirement;simulation	Ilya Kovalenko;Kira Barton;Dawn M. Tilbury	2017	2017 22nd IEEE International Conference on Emerging Technologies and Factory Automation (ETFA)	10.1109/ETFA.2017.8247652	architecture;proactivity;real-time computing;systems engineering;engineering;adaptability;agent architecture;multi-agent system	Robotics	-53.43231446285022	12.074336754532679	35031
fadc80a83789b257e44cede12214003787bcc206	automated architectural evaluation of web information systems	quality attributes;automatic evaluation;scenario;scenario based methods;architecture;web systems	Traditional scenario-based architectural analysis methods rely on manual review-based evaluation that requires advanced skills from architects and developers. They are usually applied when the architecture is under development, but before its implementation has begun. The system implementation is one additional and fundamental element that should be used and considered during the software architecture evaluation. In this paper, we propose an approach to add information, which ideally should come from traditional evaluation methods, about scenarios and quality attributes to the source code of web-based systems using metadata. The main aim is to enable the automatic architecture analysis by producing a report with information about scenarios, quality attributes and source code assets, such as: (i) the potential tradeoff points among quality attributes, (ii) the execution time for scenarios and if it has failed or not. Up to now, the approach has been applied mainly to web-based systems, but it can be adapted to other software domains. The paper also presents the tool used to perform static and dynamic analysis, and the results of its application to an e-commerce web system and an enterprise information web system.	e-commerce;information system;list of system quality attributes;run time (program lifecycle phase);software architecture;software development;usability;web application	Felipe Pinto;Uirá Kulesza;Eduardo Martins Guerra;João Maria Júnior;Leo Silva	2013		10.1145/2526188.2526193	web modeling;simulation;computer science;scenario;architecture;operating system;database;world wide web	SE	-59.596133038127846	26.462900086583964	35077
0fadea14df41d08c74f36cc3803afc6984e6e1eb	knowledge-based support for object-oriented software design and synthesis: a category theoretic approach	collaboration relationship;programming language semantics;explicit semantics;theoretical model;formal specification;software design object oriented modeling collaborative software design engineering knowledge engineering software prototyping prototypes knowledge representation programming systems engineering and theory;object oriented design;object oriented software design;object oriented software;abstraction;object oriented programming;category theoretic approach;reasoning about programs;object oriented;levels of abstraction;granularity;software refinement knowledge based support object oriented software design category theoretic approach collaboration relationship interdependency relationship reasoning abstraction granularity explicit semantics formal object oriented specification automated software composition;software reusability formal specification knowledge based systems object oriented programming programming language semantics reasoning about programs;software reusability;interdependency relationship reasoning;software refinement;formal object oriented specification;automated software composition;dynamic adaptation;knowledge based systems;knowledge based support;software composition;knowledge base	To reuse previous knowledge of object-oriented design and adapt them to solve new problems, the collaboration relationships and the responsibility distribution among software objects need to be thoroughly understood and precisely formulated. The paper proposes a knowledge-based approach that employs category theoretic models to formalize and mechanize object-oriented software design and synthesis by focusing concern on reasoning about the interdependency relationships at different levels of abstraction and granularity. The major benefit of our approach is twofold: first, it provides an explicit semantics for formal object-oriented specifications, and therefore enables a high-level of reusability and dynamic adaptability. Second, it utilizes the ability of categorical computations to support automated software composition and refinement. A prototype tool that demonstrates the feasibility and effective of our approach is also presented	artificial intelligence;category theory;component-based software engineering;computation;formal system;function composition (computer science);high- and low-level;information management;interdependence;knowledge acquisition;knowledge engineer;knowledge-based systems;principle of abstraction;profile (uml);prototype;refinement (computing);software design;software development;software system;systems design;test case;unified modeling language	Yujun Zheng;Qimin Hu;Jinyun Xue	2006	Sixth International Conference on Intelligent Systems Design and Applications	10.1109/ISDA.2006.180	knowledge base;computer science;knowledge management;programming language;object-oriented programming	SE	-48.75536082335328	28.257089920793195	35083
712f98fb1b6db3049068807d50906996e0b18c84	a knowledge-based computer environment for the conceptual design of small electromechanical appliances	design engineering;knowledge based systems concurrent engineering design engineering;conceptual design;design environment;containers home appliances assembly concurrent engineering humans light sources wires capacitive sensors electrical capacitance tomography electric motors;qualitative simulation knowledge based computer environment conceptual design small electromechanical appliances concurrent engineering kitchen appliances lighting specification acquisition;knowledge based systems;concurrent engineering;knowledge base	A knowledge-based computer environment that supports the concurrent engineering of small electromechanical appliances such as kitchen appliances and lighting is described. The environment integrates and provides active assistance for the following engineering activities: specification acquisition, conceptual design and redesign, and qualitative simulation. The design environment is examined by reviewing the steps in a redesign sequence that transforms a manual juicer into an electric juicer.<<ETX>>	simulation;specification language	Chris Tong;Andrew Gomory	1993	Computer	10.1109/2.179161	knowledge base;simulation;computer science;artificial intelligence;conceptual design;concurrent engineering	AI	-56.503896068114415	9.900381211588451	35153
ae138743befc1c054a5fe319c960a8b49830bae5	a conceptual modelling pattern for roles	conceptual schema;role models	A pattern identifies a problem and provides the specification of a generic solution to that problem. Conceptual modelling patterns are aimed at representing a specific structure of knowledge that appears in different domains. Roles are meant to capture dynamic and temporal aspects of realworld objects. This paper identifies common semantics of different role models found in the literature. Moreover, it presents a conceptual modelling pattern for the role concept that includes both the static and dynamic aspects of roles. In particular, we adapt the pattern to the UML. The use of this pattern eases the definition of roles in conceptual schemas. We also discuss the advantages of our approach over previous ones.	conceptual schema;olami–feder–christensen model;pattern language;programming language;software design pattern;unified modeling language	Ruth Raventós;Jordi Cabot	2003				AI	-44.15302797303335	25.32067457444727	35174
15449e5957e4afa5c4f7cb3ce6b0b3f37efcf4f3	application and platform independent storage of organisational data.techniques, issues and concerns of secure, central data administration via the www			www	Ioakim Marmaridis;Steve Hansen	2000				Theory	-49.15142664547703	8.416344472808346	35261
619024d69d10a463da78c61d4b5a3a5ad7696f32	a framework to support interoperability and multi-channel delivery among heterogeneous systems: trame project	heterogeneous systems	The e-commerce has become a point of strength for the companies that desire to increase their billing enlarging their clients park and reducing the management costs. Therefore the demand has been born to use platforms able to support the interoperability between heterogeneous systems and the multi-channelling with variegated devices to access different services in reliable manner and to allow, so, a spread of the market toward partner with particular needs. Furthermore, many available services have been typically designed for a single channel the web one. In a real world scenario, an ever-growing number of users take advantage of different kind of communication channel and devices. In this paper we propose a B2B oriented framework able to support the interoperability among heterogeneous systems developed according to the ebXML reference model for the business messages interchange suitable to any B2B marketplace that foresees the commercial interaction among partners with different roles and profiles (including channel and device). Such framework has been developed and experimented for the TRAME research project that has as objective to create a room of district compensation of the peaks of productive ability demands within the Textile/Clothing sector and to give the needed infrastructure for the business messages exchange among the partners of the productive spinneret.	channel (communications);e-commerce;ebxml;electronic billing;fax;hypertext transfer protocol;interoperability;java platform, enterprise edition;modal logic;peer-to-peer;reference model;sequence diagram	Ugo Barchetti;Alberto Bucciero;Luca Mainetti;Stefano Santo Sabato	2008			computer science	Web+IR	-49.82021907190828	14.930037319467448	35276
c88ff3c9284a151635005f8193e4250d1d50ccda	dynamic simulation modeling of an inspection-based software lifecycle process	developpement logiciel;modelizacion;eficacia sistema;architecture systeme;simulation;performance systeme;simulacion;ingenieria logiciel;program verification;software engineering;system performance;analisis programa;dynamical system;modelisation;systeme dynamique;verificacion programa;desarrollo logicial;analyse performance;software development;performance analysis;genie logiciel;arquitectura sistema;dynamic simulation;program analysis;sistema dinamico;analyse programme;system architecture;verification programme;modeling;analisis eficacia	demonstrates the effects of performing inspections and other managerial policies. The dynamic effects are tracked throughout the time history of a project to show resource usage, task completions and defect trends per phase. Cumulative metrics and development tradeoffs for decision making are also presented. Several types of validation tests are performed against industrial data, existing theory and other prediction models. The results indicate a valid model that can be used	dynamic simulation;iso/iec 12207;software bug	Raymond J. Madachy;Behrokh Khoshnevis	1997	Simulation	10.1177/003754979706900104	program analysis;dynamic simulation;verification and validation;simulation;systems modeling;computer science;systems engineering;engineering;software development;dynamical system;application lifecycle management;goal-driven software development process;system lifecycle	SE	-62.39775548580194	28.956956986857872	35281
16cd112b8f3283a5f915b57c3e56ad10ffb45b09	class-based graph anonymization for social network data	social network	The recent rise in popularity of social networks, such as Fac ebook and MySpace, has created large quantities of data about inte ractions within these networks. Such data contains many privat e details about individuals so anonymization is required prior t attempts to make the data more widely available for scientific r esearch. Prior work has considered simple graph data to be ano nymized by removing all non-graph information and adding or deletin g some edges. Since social network data is richer in details about t he users and their interactions, loss of details due to anonymizatio n limits the possibility for analysis. We present a new set of techniq ues for anonymizing social network data based on grouping the en tities into classes, and masking the mapping between entities and the nodes that represent them in the anonymized graph. Our techn iques allow queries over the rich data to be evaluated with high acc uracy while guaranteeing resilience to certain types of attack. T o prevent inference of interactions, we rely on a critical “safety con dition” when forming these classes. We demonstrate utility via empi rical data from social networking settings. We give examples of co mplex queries that may be posed and show that they can be answer ed over the anonymized data efficiently and accurately.	e-book;entity;graph (discrete mathematics);interaction;naruto shippuden: clash of ninja revolution 3;social network;ues (cipher)	Graham Cormode;Divesh Srivastava;Smriti Bhagat;Balachander Krishnamurthy	2009	PVLDB	10.14778/1687627.1687714	computer science;data mining;database;internet privacy;world wide web;social network	DB	-35.31722086410051	20.46551843071	35300
a103f10b54f28900ae9a5b0d1980baf02e7aeb0d	a rule based approach to the service composition life-cycle	application development;value added services;service composition;business process execution language;electronic commerce;service provider;life cycle;rule based system;rule based;best practice;distributed computing;web service;software engineering;web service composition;dynamic binding;internet;web services standards development context aware services best practices software engineering distributed computing web and internet services application software packaging human factors;electronic business;software engineering knowledge based systems electronic commerce internet;knowledge based systems;flexible service compositions rule based approach service composition life cycle web services distributed computing electronic business service providers application developers value added services reservcom project business process execution language for web services software engineering parameterization support dynamic binding	Web services are becoming the prominent paradigm for distributed computing and electronic business. This has raised the opportunity for service providers and application developers to develop value-added services by combining existing web services. However the current web service composition solutions, even for the applications developed on the basis of the standard Business Process Execution Language for Web Services (BPEL for short) , are rather restricted and inflexible as they lack proper support for generating dynamic compositions and for managing the service composition life cycle. The ReServCom project proposed here aims to remedy this situation by introducing a rule based approach for web service composition which combines best practices from rule base systems and software engineering to support parameterization, dynamic binding, and flexible service compositions.	best practice;business process execution language;distributed computing;electronic business;late binding;programming paradigm;rule-based system;service composability principle;software engineering;web service	Jian Yang;Mike P. Papazoglou;Bart Orriëns;Willem-Jan van den Heuvel	2003		10.1109/WISE.2003.1254497	rule-based system;service provider;web service;biological life cycle;web modeling;the internet;business process execution language;differentiated service;web standards;computer science;knowledge management;service delivery framework;ws-policy;service-oriented architecture;service design;database;services computing;rapid application development;law;world wide web;universal description discovery and integration;best practice	Web+IR	-47.56007327295511	18.08255996085395	35301
4ec6052dee00bf7fd2b2cc50963943a1d2fb141a	an agent based multilevel architecture for robotics vision systems.	design process;agent based;mobile robot;indexing terms;agent based software engineering;cognitive architecture;robot vision;design and implementation;unified modelling language;distributed architecture	An approach to the design and implementation of a robotics vision system based on agent inserted in a generic multi-level architectures for mobile robotics is presented, that is based on the Unified Modelling Language. The main goal of the work is to provide a framework to perform a rigorous agent-based design process for cognitive architectures both in the case of a single robot, and in a multi-robot scenario. Details of the methodology, system implementation using FIPA-OS environment, along with real experiments are reported..	agent-based model;automatic programming;code generation (compiler);cognitive architecture;experiment;mobile robot;multi-agent system;operating system;robotics;unified modeling language	Ignazio Infantino;Massimo Cossentino;Antonio Chella	2002			enterprise architecture framework;agent architecture;reference architecture;software architecture;computer vision;simulation;computer science;applications architecture;artificial intelligence;solution architecture;software architecture description	Robotics	-43.449425748360284	22.270070965794726	35327
4e6a1a953db238b0a2bb587984e1cd2dc45bbee0	a dynamic web service composition algorithm based on topsis	multi period hybrid qos;service composition;topsis;web service;quality of service qos;multi attribute decision making	Multi-period QoS evaluations have to be considered for obtaining a reliable decision in the service selection process. Besides, open and dynamic Internet environment increased the uncertainty of decision-making. To solve the above difficulties, this paper presents a novel hybrid data type (including real numbers, interval numbers, triangular fuzzy numbers and intuitionistic fuzzy numbers) QoS model, multi-period hybrid QoS aggregating operator and a strategy for aggregating composition service QoS firstly. Furthermore, a dynamic Web service composition algorithm based on TOPSIS (DWSCA_TOPSIS) is presented to evaluate multi-period hybrid QoS data. DWSCA_TOPSIS includes four main steps: converting hybrid QoS into intervals, calculating weighted normalized decision-matrix, determining the positive-ideal and negative-ideal solution, calculating the close-degrees of candidates. Finally, some experiments are given using actual QoS data to demonstrate the benefits and effectiveness of our approach.	algorithm;experiment;internet;quality of service;selection algorithm;service composability principle;user experience;web service	Longchang Zhang;Hua Zou;Fangchun Yang	2011	JNW	10.4304/jnw.6.9.1296-1304	web service;topsis;computer science;data mining;database	Web+IR	-45.61844507598228	15.328718306498416	35338
63bd1d86bef6926f905320a6fff82d653d15b821	a formal object-oriented approach to defining consistency constraints for uml models	object z formal object oriented metamodeling approach integrity consistency constraint uml model;uml model;formal object oriented metamodeling approach;formal specification;data integrity;information technology;object z;object oriented programming;software engineering;object oriented;specification languages;unified modeling language;object oriented approach;data integrity specification languages formal specification object oriented programming;unified modeling language object oriented modeling metamodeling australia information technology software engineering;280302 software engineering;metamodeling;700199 computer software and services not elsewhere classified;object oriented modeling;australia;integrity consistency constraint	We discuss how integrity consistency constraints between different UML models can be precisely defined at a language level. In doing so, we introduce a formal object-oriented metamodeling approach. In the approach, integrity consistency constraints between UML models are defined in terms of invariants of the UML model elements used to define the models at the language-level. Adopting a formal approach, constraints are formally defined using Object-Z. We demonstrate how integrity consistency constraints for UML models can be precisely defined at the language-level and once completed, the formal description of the consistency constraints will be a precise reference of checking consistency of UML models as well as for tool development.	metamodeling;unified modeling language	Soon-Kyeong Kim;David A. Carrington	2004	2004 Australian Software Engineering Conference. Proceedings.	10.1109/ASWEC.2004.1290461	reliability engineering;uml tool;computer science;systems engineering;consistency model;software engineering;applications of uml;programming language;object-oriented programming;information technology	SE	-47.95305660874847	28.404425097060688	35343
2e573866519dc3d397f77e44a56a3cbcf6a37589	ontology gateway - enabling interoperability between fipa complaint agents and owl web services	web service	The introduction of Ontology Web Language (OWL) which is a W3C standard for providing explicit semantics for establishing and sharing ontologies on the World Wide Web, has made it easier to embed semantics with web data. Similarly FIPA Semantic Language is the core of the agent platforms due to its high expressive power. Ontology plays an important role in the knowledge representation, reuse and communication between web services. Similarly in an Multi-agent system ontology also plays an important role, where the messages exchanged between agents should conform to an Ontology so that they could be understood. In this paper we will introduce a technology enabling bidirectional interoperability between FIPA compliant software agents and the Web services published in OWL. This is an extension of previous work in which we proposed the development of semantic translations in such a way that the agents can communicate with web services in an efficient manner. We will also describe and discuss the implementation in which a FIPA complaint software agent will invoke and use a web service published in OWL. Our goal for this paper is to show how a FIPA complaint agent can invoke and use the web services published on the World Wide Web by the help of ontological transformations.	autonomous robot;interoperability;knowledge representation and reasoning;multi-agent system;natural language processing;ontology (information science);semantic web;semantic grid;software agent;testbed;web language;web ontology language;web service;world wide web	Sabih ur Rehman;Maruf Pasha;Farooq Ahmed;Hiroki Suguri	2007			web service;web standards;computer science;database;internet privacy;ws-i basic profile;world wide web;owl-s	AI	-43.19184849931178	12.412118757282364	35399
a49baf2c7ac0848b0fd34f9aa5dc349098b0bb83	a formal model for embedded brain reading	rehabilitation;telepresence;robots;man machine interface;inspection and testing	Purpose – The presented work contributes to research in the field of advanced man-machine interaction and to research in the field of formalisation and verification of complex systems. This work was motivated by the need to provide a detailed and well understandable formal description of embedded brain reading (eBR). The paper aims to discuss these issues. Design/methodology/approach – The paper first introduces eBR and points out its main features. Next, a general model for eBR is developed to describe the overall architecture, integral parts and dependencies between those parts. The model is developed and presented in a formal structured form that allows for application of optimisation as well as verification techniques. Findings – The paper demonstrates using implementations that the application of the formal model allows to check for completeness and correctness to detect errors in implementation, which were invisible without formalising eBR. In summary, the presented work contributes a formal model for a complex system and shows that such a formal model can improve the overall system’s functionality. Research limitations/implications – For future work, the results support the application of formal modelling and verification techniques at the system level and the development of methods to prove for correctness and completeness of complex systems during their development. Originality/value – The paper describes for the first time eBR and presents a formal model for it. It illustrates how an error-prone approach like BR can be applied safely by embedding it into the control of a real system and by applying mechanisms that control for its correct function.	cognitive dimensions of notations;complex system;complex systems;correctness (computer science);embedded system;formal language;formal system;formal verification;human–computer interaction;mathematical model;mathematical optimization	Elsa Andrea Kirchner;Rolf Drechsler	2013	Industrial Robot	10.1108/IR-01-2013-318	human–machine interface;robot;simulation;computer science;engineering;artificial intelligence;engineering drawing;mechanical engineering	Robotics	-45.95506488542778	28.38631881758017	35403
65b6fd9c2e50a52a1290ec163af21653ecdc0b65	workflow validation framework in distributed engineering environments	process observation;workflow integration and validation;process mining;process improvement;automation systems engineering	Automation systems, like power plants and industrial production plants, usually involve heterogeneous engineering domains, e.g., mechanical, electrical, and software engineering, that are required to work together to deliver good products and services to customers. However, the heterogeneity of workflows used in different engineering domains make it hard for project managers to integrate and validate such workflows. We propose to add the Engineering Service Bus (EngSB) notion with a framework to integrate and validate heterogeneous workflows from different engineering fields and to link connections between different types of signals. For evaluation, we perform a feasibility study on a signal change management of our industry partner in hydro power plant engineering domain. Major result shows that the framework can support workflow validation and improve the observability of heterogeneous workflows in distributed engineering environments.	automation;emoticon;software engineer;software engineering	Wikan Danar Sunindyo;Thomas Moser;Dietmar Winkler;Richard Mordinyi;Stefan Biffl	2011		10.1007/978-3-642-25126-9_34	reliability engineering;system of systems engineering;systems engineering;engineering;knowledge management	SE	-62.00788866372907	15.523523785559185	35500
3570e2f62604b18b5bc955963a7c090dbcdb7de3	a security concept for olap	decision support;security model;data integrity;query processing;data warehouse dwh;security management;discretionary access control dac;database security;online analytical processing olap;data warehousing;mandatory access control mac;n dimensional cube security concept olap data warehouse heterogeneous sources decision support data warehousing view materialization data integration;security of data query processing;data warehouse;security of data;data security data warehouses information security access control distributed databases warehousing protection privacy data models content management	A data warehouse collects and integrates data from multiple, autonomous, heterogeneous sources with the purpose of efficiently implementing decision support or OLAP queries. Much working data warehousing has been performed on view materialization and data integration, we focus on access and security management in OLAP and N-dimensional cube. Since data in data warehouse are valuable and an important cooperate resource, we define a security model for data warehouses which describes security constrains for roles in the data warehouse. Each user in the data warehouse has a role and each role has a security constrain list that builds the security profile of the role. According these role profile the user is authorized to query data from the data warehouse.	database security;online analytical processing	Remzi Kirkgöze;Nevana Katic;Mladen Stolda;A Min Tjoa	1997		10.1109/DEXA.1997.617386	computer security model;security management;dimensional modeling;computer science;data warehouse;data integrity;data mining;database;world wide web	DB	-33.747682367636784	10.54506619004015	35536
aef72499bb0d0aa6592ef9753faeda2e9d13d0e7	using knowledge-based e-mail system to support office workflow management: a scenario-based approach		Computer-based information technologies and the communication they facilitate are the essential foundations for supporting and managing distributed work teams. One such technology is Electronic Mail System (EMS). Particularly, Knowledge-based Mail System (KMS) can effectively manage the dissemination and receipt of EMS messages via management rules on the contextual information and the content of messages. Recent research show that the scenarios of message processing might be especially advantageous in office workflow management. However, very little research has been conducted on the effect of using contextual scenarios with KMS to manage work processes of distributed teams. This paper presents a scenario-based approach for message management, which provides an alternative to knowledge-based mail system in support office workflow management. The scenario-based approach improves the prior KMS designs by (1) managing the messages as a task-based sequence rather than an individual message, (2) scheduling group activities not only based on relatively static knowledge of organizational policies but also the knowledge of work processes or activities that are often dynamically formed and changed, (3) managing documents routine via the contextual information of messages. Experience with a prototype demonstrates the viability of integrating the scenarios-based approach with the knowledgebased mail system.	document;email;prototype;scheduling (computing)	Liquin Hwang;Kunihigo Higa	2001			workflow;knowledge management;workflow management coalition;document management system;windows workflow foundation;workflow management system;workflow engine;workflow technology	HCI	-52.141069022978066	9.807925434231068	35561
fbe1089704c1f65a32afbb72d85861913d9424ab	modeling framework for mining lifecycle management	plm;mlm;standard;mining information system	In the development process of the information of the mining engineering, it is difficult to directly exchange and share information in the different phases and different application system, which causes the information isolation and information gap due to lack of unified data exchange standards and information integration mechanism. The purpose of this research is to build a modeling framework for mining lifecycle information management. The conception of mining lifecycle management (MLM) is proposed based on product lifecycle management (PLM) and Hall three dimension structures. The frame system of mining lifecycle management has been established by the application route of the information integration technologies and information standards. The four-layer structure of the realization of MLM system is put forward, which draws up the development method of MLM system. -The application indicates that the proposed theories and technologies have solved the problem of information isolation in different phases and application in mining engineering, and have laid a foundation for information exchange, sharing and integration in mining lifecycle.	frame language;information exchange;information management	Na Lu;Caiwu Lu;Zhen Yang;Yishuang Geng	2014	JNW	10.4304/jnw.9.3.719-725	multi-level marketing;computer science;knowledge management;technical standard;product lifecycle;information integration;data mining;configuration management;application lifecycle management;system lifecycle	DB	-59.17091429548712	13.77478845316351	35564
99004e7f2e37df227ffac39e23ca8c664a70039c	proposal of an integrated object-oriented environment for the design of supervisory software for real-time industrial automation systems	application development;supervisory control systems integrated object oriented environment supervisory software real time industrial automation distributed real time systems case tools;software tool;supervision simulation;object oriented programming software tools programming environments industrial control;programming environments;supervisory control;real time;object oriented programming;real time industrial automation systems;distributed real time system;object oriented;rio grande do sul;industrial control;case tool;software tools;industrial automation;use case;object oriented paradigm	The object-oriented paradigm has been used extensively both in CASE tools for modeling and design of distributed real-time systems as well as in software tools for developing supervisory control systems. Supervisory tools are very useful in the context of real-time industrial automation systems. Recent researches prove that the use of object-orientation paradigm in the development of these systems tend to produce better-structured and more reusable programs. This paper analyses, using case studies, some of the widely used commercial tools for modeling and supervisory control generation. After that, some case studies using the analyzed tools are reported and finally a proposal of an integrated object-oriented environment for application development and monitoring is made. This work is part of an ongoing research project that has been developed at the Industrial Automation Lab. of Federal University of Rio Grande do Sul in Brazil.	automation;compactrio;computer-aided software engineering;control system;programming paradigm;real-time clock;real-time computing;real-time locating system;real-time transcription	Leandro Buss Becker;Wilson Pardi Junior;Carlos Eduardo Pereira	1999		10.1109/WORDS.1999.806598	real-time computing;simulation;systems engineering;engineering	Embedded	-49.125235984976165	29.789744994399534	35610
24fa129b562fabfbe6835e81ade3264f564932b9	automated attribute inference in complex service workflows based on sharing analysis	databases;task performance;business data process;service composition;sharing analysis;history;automated attribute inference;lattices;top down;complex service workflows;horn clause;horn clauses;inference mechanisms;horn clause based representation;workflow management software business data processing horn clauses inference mechanisms knowledge representation peer to peer computing;data dependence;business data processing;licenses;process control;workflow management software;workflow;business domain specific attributes;embedded component services;peer to peer computing;knowledge representation;static analysis;embedded component services business data process automated attribute inference complex service workflows sharing analysis business domain specific attributes horn clause based representation;static analysis workflow business process service composition horn clause;context;lattices context history databases process control licenses;domain specificity;business process	The properties of data and activities in business processes can be used to greatly facilitate several relevant tasks performed at design-and run-time, such as fragmentation, compliance checking, or top-down design. Business processes are often described using workflows, and we present an approach to mechanically infer business domain-specific attributes of workflow components, including data items, activities, and elements of sub-workflows, from known attributes of workflow inputs and the structure of the workflow by modeling these components as concepts and applying sharing analysis applied to a Horn clause representation of the workflow. The analysis is applicable to workflows featuring complex control and data dependencies, embedded control constructs, such as loops and branches, and embedded component services.	branch (computer science);business process execution language;business domain;control flow;data dependency;embedded system;emergence;emoticon;fork (software development);formal concept analysis;horn clause;logic programming;process specification;state (computer science);top-down and bottom-up design;xpdl	Dragan Ivanovic;Manuel Carro;Manuel V. Hermenegildo	2011	2011 IEEE International Conference on Services Computing	10.1109/SCC.2011.85	workflow;computer science;knowledge management;data mining;database;event-driven process chain;workflow management system;workflow engine;workflow technology	DB	-46.69292872284698	18.843649686312546	35691
a19aba798076f1bee0b70224a6e78163320ab771	an object-oriented modeling method for algebraic specifications in cafeobj	obj;algebraic specification;concurrent rewriting;algebraic specifications;object oriented model;formal specification;executable specification;design engineering;object oriented design;object oriented modeling formal methods executable specifications algebraic specifications concurrent rewriting obj cafeobj;collaboration;formal methods;formal method;executable specifications;permission;guidelines;object oriented;specification languages;cafeobj;rewriting logic;logic functions;object oriented modeling guidelines permission logic functions collaboration software quality design engineering laboratories national electric code specification languages;national electric code;object oriented modelinng;excutable specifications;object oriented modeling;software quality;equational logic	A scenario-based object-oriented modeling method for algebraic specifications is proposed. The method is based on the integration of a new algebraic specification language, CafeOBJ, and a multiparadigm design notation, GIL0-2 (Generic Interaction Language for Objects). CafeOBJ is a successor of the algebraic specification language OBJ and supports object-oriented formal specifications based on hidden order sorted rewriting logic. GIL0-2 provides collaborations as well as classes of objects to capture behavioral aspects of scenarios in object-oriented modeling. Given a problem description of the system to develop, the proposed method provides guidelines for decomposing the problem into executable CafeOBJ specification modules through scenario-based object-oriented design in GIL0-2; the decomposition reflects the structure of the problem domain. The proposal also indicates how formal executable specification in CafeOBJ can be systematically obtained from the design in GIL0-2.	algebraic specification;executable;problem domain;rewriting;specification language;wavefront .obj file	Shin Nakajima;Kokichi Futatsugi	1997	Proceedings of the (19th) International Conference on Software Engineering	10.1145/253228.253238	national electrical code;formal methods;equational logic;rewriting;computer science;theoretical computer science;object-oriented design;formal specification;database;programming language;object-oriented programming;software quality;collaboration	SE	-49.44373146406886	27.475602338669667	35693
ecf6e31ed66a7b111cba20c3d7edd44f50a51f44	design of deadlock avoidance compensators for anthropocentric production systems	anthropocentric production system;deadlock avoidance compensator;production system	The advances in networked industrial enterprises to meet the demands for high productivity level as well as for quality and operational flexibility has driven the development of anthropocentric system that emphasize the importance of human operator. However, greater flexibility and autonomy means greater complexity in the flow of items (material and information) in a system. Thus, this work discusses the concept of Anthropocentric Production Systems (APS) and how it should be implemented do avoid deadlock problem. In particular, the techniques based on Petri nets and Request-Allocation Graphs (RAG) are introduces to the design of deadlock avoidance compensators, employed to support the task of system control program redesign, the only solution in case of extreme changes in the environmental conditions.	deadlock	Paulo E. Miyagi;Diolino J. Santos Filho;Wilson M. Arata	2000			control engineering;simulation;engineering;operations management;deadlock prevention algorithms	Robotics	-54.009466965872114	11.27984747423999	35712
c6ee8b247ace108225ac6ef667b24e18dea0ab07	parallel transportation management and control system for subway systems based on acp approach	control systems;reliability;personnel generators planning maintenance engineering computational modeling control systems safety;artificial subway systems acp approach parallel transportation management and control system for subway systems ptms subway multiagent modeling computational experiment platform interactive parallel execution system;simulation;traffic control;会议论文;transportation multi agent systems road traffic control;quality of service;automatic train protection;subways	This paper presents a framework of Parallel Transportation Management and Control System for Subway Systems (PTMS-Subway) based on ACP approach. Firstly, based on multi-agent modeling, Artificial Subway Systems is constructed. Then, the design, content, and process of Computational Experiments Platform are performed. Finally, through an interactive Parallel Execution System between the actual and artificial subway systems, a set of practical strategies of management and control can be achieved. PTMS-Subway can improve the reliability, efficiency, safety, and service level of subway systems.	computation;control system;multi-agent system	Xisong Dong;Yuan Liu;Gang Xiong;Fenghua Zhu;Zhenjiang Li	2014	17th International IEEE Conference on Intelligent Transportation Systems (ITSC)	10.1109/ITSC.2014.6958156	embedded system;simulation;engineering;transport engineering	Robotics	-38.268191401775326	22.07814018344821	35725
149b618674985c5f88ddcc474248da92b6dfe2aa	combining mediation and bidding mechanisms for agent-based manufacturing scheduling	believable agents;agent based;contract net protocol;avatars;interactive drama	2. INTRODUCTION Future manufacturing systems need to be dynamically reconfigurable to produce customized products in small batches, even down to lot sizes of one unit, with fast turnaround in a cost-efficient manner. Such systems must be implemented with dynamic scheduling mechanisms for rapidly responding to emergent production tasks and orders, and other unforeseen situations such as production tardiness and machine failures.	cost efficiency;emergence;reconfigurability;scheduling (computing)	Weiming Shen;Douglas H. Norrie	1998		10.1145/280765.280908	simulation;multimedia;contract net protocol	AI	-53.24732215561884	12.068371100580581	35754
7a791203a78d71e172fc111f51a6b348b693d4d3	share vs. own: software reuse using product platforms	software;technical relationship;functional capability;multinational development organization;resource allocation;software relationship;software reusability resource allocation;cost benefit analysis software reuse product platform application platform technology platform product line architecture;product line;technical relationship software reuse sap multinational development organization target market resource allocation functional capability product platform custom product strategy product line functional relationship software relationship;product platform;computer architecture;software business ecosystems computer architecture production manufacturing buildings;ecosystems;software reusability;business;product line architecture;manufacturing;production;functional relationship;application platform;sap;custom product strategy;software reuse;technology platform;cost benefit analysis;target market;buildings	SAP is a complex multi-national development organization with a large number of diverse products and changing target markets. Effective allocation of resources is a difficult at the best of times. Of late, the target markets, and supporting technologies, change every couple of years exponentially increasing the complexity, necessitating a way of recalibrating that keeps pace with new realties. SAP, with a mature understanding of functional, software and technical relationships, has adopted a platform approach covering both functional and technology capabilities. However, a variety of factors, many in the management space, prevent that from being effective. This paper will explain why product-line/platform is a better strategy than platform or custom product strategies, in a way that can be understood, proven and adopted by management and developers alike. Specific recommendations of practices for delivering reuse effectively are also provided.	code reuse	Paul Abraham;Vishal Sikka;Gordon Simpson	2010	2010 International Conference on e-Business (ICE-B)		ecosystem;resource allocation;cost–benefit analysis;operations management;manufacturing;management	SE	-62.32097546516102	22.486470788186793	35764
e40f76f2cde1ba9b23ff2363fd2817e4e8b35cb5	collecting experience on the systematic development of cbr applications using the inreca methodology	developpement logiciel;raisonnement base sur cas;razonamiento fundado sobre caso;systeme intelligent;systeme apprentissage;systeme aide decision;sistema inteligente;ingenieria logiciel;sistema ayuda decision;software engineering;learning systems;decision support system;software process model;desarrollo logicial;software development;intelligent system;genie logiciel;case based reasoning;experience base	This paper presents an overview of the INRECA methodology for building and maintaining CBR applications. This methodology supports the collection and reuse of experience on the systematic development of CBR applications. It is based on the experience factory and the software process modeling approach from software engineering. CBR development experience is documented using software process models and stored in different levels of generality in a three-layered experience base. Up to now, experience from 9 industrial projects enacted by all INRECA II partners has been collected.	case-based reasoning;process modeling;software development process;software engineering	Ralph Bergmann;Sean Breen;Emmanuelle Fayol;Mehmet H. Göker;Michel Manago;Sascha Schmitt;Jürgen Schumacher;Armin Stahl;Stefan Wess;Wolfgang Wilke	1998		10.1007/BFb0056356	case-based reasoning;simulation;decision support system;computer science;artificial intelligence;software development	SE	-62.47194481022761	13.719763402967228	35765
c79b5b42bb7471e5b5f14e4a2d2f050f5f57df88	zen-cc: an automated and incremental conformance checking solution to support interactive product configuration	software;manuals;conformance checking product line engineering variation point product configuration;zen configurator zen cc automated conformance checking solution incremental conformance checking solution interactive product configuration product line engineering model based ple automated product configuration large scale systems software abstract commonality specification product variability predefined conformance rules ocl derivation tool;vegetation;heuristic algorithms;variation point;unified modeling language;product line engineering;software product lines formal specification;conformance checking;vegetation unified modeling language manuals context educational institutions software heuristic algorithms;context;product configuration	In the context of product line engineering (PLE), providing immediate feedback on the correctness of a manual configuration step to users has a practical impact on whether a configuration process with tool support can be successfully adopted in practice. Model-based PLE has brought opportunities to enable automated product configuration and derivation for large-scale systems/software, in which models are used as the abstract specification of commonalities and variabilities of products of a product line. In our previous work, we have proposed a UML-based variability modeling methodology and an interactive configuration process. Based on these work, in this paper, we propose an automated and incremental conformance checking approach to ensure that the manual configuration to each variation point conforms to a set of pre-defined conformance rules specified in OCL. The proposed approach, called Zen-CC is implemented as a component of our product configuration and derivation tool, named as Zen-Configurator. The proposed approach is evaluated with two real-world case studies and results showed that the performance of Zen-CC is significantly better than a baseline algorithm checking all the conformance rules at each configuration step. Moreover, the performance of Zen-CC rarely varies during the configuration process, suggesting that our approach is scalable for configuring products with a large number of configuration points.	algorithm;baseline (configuration management);cc system;conformance testing;correctness (computer science);creative zen;knowledge-based configuration;scalability;software bug;spatial variability;test case;unified modeling language	Hong Lu;Tao Yue;Shaukat Ali;Kunming Nie;Xiang Lin	2014	2014 IEEE 25th International Symposium on Software Reliability Engineering	10.1109/ISSRE.2014.13	reliability engineering;unified modeling language;computer science;systems engineering;product design specification;engineering drawing;vegetation	SE	-57.3609253249025	30.6830632097931	35771
ecfde47c1ba06fdcd13c5499b89fff4df9b99307	a methodology for secure interactive systems	human computer interaction;computersicherheit;formal methods;formale methoden;computer security;mensch maschine interaktion	This dissertation introduces a methodology for formal spec ification and verification of user interfaces under security aspects. The methodo logy allows to use formal methods pervasively in the specification and verificatio n of human-computer interaction. This work consists of three parts. In the first p art, a formal methodology for the description of human-computer interaction is de veloped. In the second part, existing definitions of computer security are adapted for human-computer interaction and formalized. A generic formal model of human-c omputer interaction is developed. In the third part, the methodology is applied t o the specification and verification of a secure email client.	computer security;email encryption;formal methods;human–computer interaction;mathematical model;spec#;user interface	Gerd Beuster	2008			formal methods;formal verification;computer science;systems engineering;theoretical computer science;software engineering;formal specification;refinement	HCI	-45.53802201804084	30.570669662902855	35792
f0f3dd449ce0fb839e12af011922d95691f781f4	design solution analysis for the construction of situational design methods		Situational design methods provide problem solving guidance that can be configured to fit a range of different design goals and contexts. While the formal aspects of situational method engineering are well researched, the specification of method fragment instances and their configurations is often left open and regarded as specific to the respective design problem class. We propose an approach that analyzes variations of existing design solutions to explore the underlying design factors and to identify design situations. This knowledge is then used to derive method fragments and configuration rules that represent the explored variety of design solutions. The proposed approach has been applied for several design problem classes to construct concrete situational design methods. As an illustrative example, the construction of a situational design method for enterprise architecture management is used in this paper. Based on the exploration of eight design factors and three design situations, six method fragments are derived that are combined into four situational method configura-	enterprise architecture management;method engineering;problem solving	Robert Winter	2011		10.1007/978-3-642-19997-4_4	probabilistic design;systems engineering;engineering;knowledge management;management science;generative design	EDA	-55.5333857869305	22.270586293745893	35827
7e3fba1202c3f13e79e90d55691d833db5d0817d	raising the abstraction of domain-specific model translator development	automatic code generation;analytical models;microsoft net c language domain specific model translator development model based development methodologies system analysis automatic code generation domain specific application programming interface generic modeling environment;pediatrics;domain specific modeling;domain specific model translator development;application software;probability density function;code generation domain specific modeling metamodeling translator;program interpreters;biological system modeling;code generation;software systems;application program interface;data mining;software engineering;automatic generation;domain specific modeling language;support system;mathematical model object oriented modeling metamodeling application software software systems unified modeling language domain specific languages conferences automation informatics;systems analysis;application program interfaces;model based development methodologies;unified modeling language;microsoft net c language;mathematical model;model based development;system analysis;domain specific application programming interface;informatics;generic modeling environment;time to market;translator;systems analysis application program interfaces program interpreters software engineering;metamodeling;object oriented modeling;domain specificity;conferences;domain specific languages;modeling tool;automation	Model-based development methodologies are gaining ground as software applications are getting more and more complex while the pressure to decrease time-to-market continually increase. Domain-specific modeling tools that support system analysis, simulation, and automatic code generation can increase productivity. However, most domain-specific model translators are still manually written. This paper presents a technique that automatically generates a domain-specific application programming interface from the same metamodels that are used to define the domain-specific modeling language itself. This facilitates the creation of domain-specific model translators by providing a high-level abstraction hiding all the cumbersome modeling tool-specific implementation details from the developer. The approach is illustrated using the Generic Modeling Environment and the Microsoft .NET C# language.	.net framework;apl;application programming interface;automatic programming;code generation (compiler);domain-specific language;domain-specific modeling;gme of deutscher wetterdienst;generic modeling environment;high- and low-level;map;metamodeling;metaprogramming;modeling language;programming language;programming tool;simulation;system analysis;traverse	Tamás Vajk;Róbert Kereskényi;Tihamer Levendovszky;Ákos Lédeczi	2009	2009 16th Annual IEEE International Conference and Workshop on the Engineering of Computer Based Systems	10.1109/ECBS.2009.30	metamodeling;unified modeling language;systems analysis;probability density function;application software;application programming interface;computer science;domain-specific language;theoretical computer science;automation;software engineering;mathematical model;system analysis;programming language;informatics;model-based design;code generation;software system	SE	-49.03564160005989	26.84538421345365	35843
3371295ebe1eb467334712a1a1834195b74f5082	leveraging patterns on domain models to improve uml profile definition	domain model;design process;tool support;model transformation;domain specific modeling language;uml profile;design pattern;domain specific language;real time systems	Building a reliable UML profile is a difficult activity that requires the use of complex mechanisms -stereotypes and their attributes, OCL enforcementto define a domain-specific modeling language (DSML). Despite the ever increasing number of profiles being built in many domains, there is a little published literature available to help DSML designers. Without a clear design process, most such profiles are inaccurate and jeopardize subsequent model transformations or model analyses. We believe that a suitable approach to building UML based domain specific languages should include systematic transformation of domain representations into profiles. This article therefore proposes a clearly-defined process geared to helping the designer throughout this design activity. Starting from the conceptual domain model, we identify a set of design patterns for which we detail several profile implementations. We illustrate our approach by creating a simplified profile that depicts elements belonging to a real-time system domain. The prototype tool supporting our approach is also described.	directory services markup language;domain model;domain-specific modeling;eclipse;model transformation;object constraint language;plug-in (computing);profile (uml);prototype;real-time clock;real-time computing;real-time locating system;real-time operating system;requirement;software design pattern;traceability;unified modeling language	François Lagarde;Huáscar Espinoza;François Terrier;Charles André;Sébastien Gérard	2008		10.1007/978-3-540-78743-3_10	domain analysis;design process;domain;business domain;uml tool;computer science;systems engineering;domain-specific language;software engineering;applications of uml;domain engineering;domain model;data mining;design pattern;programming language;engineering drawing	SE	-53.12125065479311	25.337146684964978	35884
ade69061247f42fb3bc6d97faa3818366abae517	a framework for managing optimization models for supply chain software agents	resource limitation;software agent;rule based;optimization models;optimization agents;scheduling problem;supply chain;supply chain management;optimization model	As third party logistic services become popular, the role of software agents increases in importance in terms of the logistics scheduling of buyers and sellers. To support many models in such a portal site focused on logistics, automatic formulation and modification of optimization models embedded in the multiple software agents is necessary. The stakeholders like manufacturers and third party deliverers have their objectives and constraints in terms of delivery requirements and resource limitations. Since a variety of situations require many combinations of models, it is not easy to prepare all the necessary models in advance. To resolve this issue, we propose the primitive model approach which identifies a base model first and then modifies it to meet the modeling requirements. A prototype architecture AGENT-OPT2 is designed with the capability of rule-based model modification. This framework is demonstrated with the cooperative delivery scheduling problems.	embedded system;logic programming;logistics;mathematical optimization;prototype;requirement;scheduling (computing);software agent	Jae Kyu Lee;Yong Sik Chang	2006		10.1145/1151454.1151516	simulation;systems engineering;engineering;operations management	AI	-52.21425741762748	12.221529230507677	35958
4a5a432956ad119ee2731f3b439dfb75184c57f1	extending a conceptual modelling approach to web application design	developpement logiciel;class diagram;interfase usuario;object oriented methods;navegacion informacion;red www;user interface;navigation information;information browsing;web interface;conceptual model;web application design;conceptual modelling;desarrollo logicial;software development;methode orientee objet;world wide web;interface utilisateur;reseau www;information system;systeme information;sistema informacion	This article presents OO-HMethod, an extension of the OOMethod conceptual modelling approach to address the particulars associated with the design of web interfaces. It is based on the OO-Method class diagram, which captures the statics of the system. The design of the interface appearance and the navigation paths are driven by the user navigation requirements. To achieve its goal, OO-HMethod adds several navigation and interface constructs to the OO-Method conceptual model, which define the semantics suitable for capturing the specific functionality of web application interfaces. A new kind of diagram, the ’Navigation Access Diagram’ (NAD) is introduced. All the concepts represented in the NAD are stored in a repository, and from there a functional interface is generated in an automated way. One of the main contributions of this paper is not the proposal of yet another method for web modelling but the extension of an existing conceptual modelling approach.	a new kind of science;categorization;class diagram;formal methods;formal specification;network access device;point of view (computer hardware company);requirement;software design pattern;software development process;software engineer;software repository;usability;user interface;user requirements document;web application;yet another	Jaime Gómez;Cristina Cachero;Oscar Pastor	2000		10.1007/3-540-45140-4_7	conceptual model;web modeling;simulation;computer science;operating system;database;user interface;world wide web	SE	-46.77131580258069	22.56696866206781	35969
dc8442210e9f3433f82e21b42f2f778041021775	expressive scoping of dynamically-deployed aspects	code generation;software refactoring;object oriented;aspect oriented programming;change impact analysis;static program analysis	Several aspect languages and frameworks have recognized the need for dynamic deployment of aspects. However, they do not provide sufficiently expressive means to precisely specify the scope of deployed aspects. As a result, programmers have to resort to unnecessarily complex pointcut definitions that hinder the reuse potential of aspects. To address the issue of precise and expressive scoping of aspects at deployment time, we propose deployment strategies for parameterized dynamic aspect deployment. This novel mechanism gives full control over the propagation of the aspect on the call stack and within created objects or functions, and permits a deployment-specific refinement of its pointcuts. We discuss and illustrate the gain in expressiveness, and provide the operational semantics of deployment strategies with Scheme interpreters, for both functional and object-oriented based aspect languages.	call stack;operational semantics;pointcut;programmer;refinement (computing);scheme;scope (computer science);software deployment;software propagation	Éric Tanter	2008		10.1145/1353482.1353503	simulation;aspect-oriented programming;computer science;programming language;object-oriented programming;code refactoring;code generation;change impact analysis;static program analysis	PL	-41.80901537430119	28.691657502093175	36002
247647073c3b382325f099ec83506b0c7b199bc1	configuration logics: modeling architecture styles	component interaction;bip;configuration logics;architecture styles;coordination	We study a framework for the specification of architecture styles as families of architectures involving a common set of types of components and coordination mechanisms. The framework combines two logics: 1) interaction logics for the specification of architectures as generic coordination schemes involving a configuration of interactions between typed components; and 2) configuration logics for the specification of architecture styles as sets of interaction configurations. The presented results build on previous work on architecture modeling in BIP. We show how propositional interaction logic can be extended into a corresponding configuration logic by adding new operators on sets of interaction configurations. In addition to the usual set-theoretic operators, configuration logic is equipped with a coalescing operator + to express combination of configuration sets. We provide a complete axiomatization of propositional configuration logic as well as decision procedures for checking that an architecture satisfies given logical specifications. To allow genericity of specifications, we study first-order and second-order extensions of the propositional configuration logic. First-order logic formulas involve quantification over component variables. Second-order logic formulas involve additional quantification over sets of components. We provide several examples illustrating the application of the results to the characterization of various architecture styles. We also provide an experimental evaluation using the Maude rewriting system to implement the decision procedure for the propositional flavor of the logic.		Anastasia Mavridou;Eduard Baranov;Simon Bliudze;Joseph Sifakis	2017	J. Log. Algebr. Meth. Program.	10.1016/j.jlamp.2016.05.002	dynamic logic;zeroth-order logic;t-norm fuzzy logics;discrete mathematics;classical logic;interval temporal logic;intermediate logic;theoretical computer science;mathematics;substructural logic;algorithm;autoepistemic logic	Logic	-37.891309684052516	30.17861548799477	36026
743d78a1962d1873fef7ba873f47ba42390f3315	dynamic, context-specific son management driven by operator objectives	minimization;handover;unified modeling language;context context modeling unified modeling language handover minimization mobile computing;mobile computing;context modeling;context	The management and operation of a Self-Organizing Network (SON)-enabled mobile network still requires considerable human effort. On the one hand, SON Functions need to be configured through low-level parameters in order to control the optimization of the network. On the other hand, an operator wants to steer the system with solely technical objectives, and the underlying network should be adapted accordingly. This opens up a gap in network management that is currently closed manually. This paper presents an approach that overcomes the manual gap between technical objectives and SON Functions by choosing the best values for the SON Functions' configurations automatically. Main advantage of this approach is that it allows to manage a system at a high level of abstraction and, at the same time, reduces manual effort. The approach is explained by applying it in a case study in the field of mobile networks with four SON Functions, namely Mobility Load Balancing (MLB), Coverage and Capacity Optimization (CCO), Energy Savings Management (ESM) and Mobility Robustness Optimization (MRO).	capacity optimization;closing (morphology);function model;high- and low-level;high-level programming language;human-readable medium;load balancing (computing);machine learning;map;mathematical optimization;program optimization;single customer view;social network;state space;time complexity	Christoph Frenzel;Simon Lohmuller;Lars-Christoph Schmelz	2014	2014 IEEE Network Operations and Management Symposium (NOMS)	10.1109/NOMS.2014.6838256	unified modeling language;real-time computing;simulation;telecommunications;computer science;artificial intelligence;handover;operating system;context model;mobile computing;computer security;computer network	Networks	-45.46509065998626	23.46560476277435	36052
10098c18affe00306dfa7ae09de2d9a81b73079d	a portal-based approach for user-centric legacy application integration in collaborative environments	004 informatik	“Networked enterprises”are characterized by distributed teams of partner organizations, humans, computer applications, autonomous robots, and devices collaborating with each other in order to achieve higher productivity and to collaborate in joint projects or produce joint products that would have been impossible to develop without the contributions of multiple collaborators. In networked enterprises, special consideration must be paid to the IT systems which are in the position to integrate different applications across company boundaries as known from enterprise application integration. At the same time, high requirements are imposed on the employees within such alliances. The contribution of this paper is an architecture for legacy application integration in web-based portal systems, specifically tailored to the requirements of networked enterprises and focusing on a user-centric approach, allowing the user to customize his workspace to his own needs. Following its presentation, the proposed architecture is validated by a prototypical implementation.	autonomous robot;computer;enterprise application integration;enterprise software;humans;legacy system;requirement;web application;workspace	Oliver Gmelch;Günther Pernul	2011			computer science;knowledge management;data mining;management;world wide web	DB	-52.13430179056075	13.927082189688022	36064
dd7491b6959bebd47ec4e86a1c6ec2c6a25ddfe9	erratum to: exploiting smart spaces for interactive tv applications development		The integration of semantic technologies and TV services is a substantial innovation to improve the services to users in an environment that is extended beyond the fixed home environment. But currently, this integration is mainly limited to provide personalized recommendation services and systems by matching user static preferences. Designing and development of interactive TV (iTV) applications using semantic technologies are not realized yet. In this work, we explore the potential of introduction semantic technologies and smart spaces in design and development of iTV applications. We use an example scenario to show how future iTV applications include the mesh-up of information from different sources. We proposed a methodology and show how ontology-driven approach can help to design and develop these iTV applications. We demonstrate the suitability of our ontology-driven application development tools and rule-based approach for the development of highly dynamic context-aware iTV applications.	e-services;logic programming;personalization;programming tool;smart tv	M. Mohsin Saleemi;Natalia Díaz Rodríguez;Johan Lilius	2014	The Journal of Supercomputing	10.1007/s11227-014-1296-5	multimedia;computer science;distributed computing;semantic technology;interactive television	HCI	-46.59818583560479	12.40898725891314	36068
bcc67c828d5c19ed2df12ad128851ff29fa0ddbf	ontology learning for the semantic web : an approach based on self-organizing maps			ontology learning;organizing (structure);self-organization;self-organizing map;semantic web	Jorge Rafael Gutierrez-Pulido	2004			natural language processing;upper ontology;ontology alignment;semantic similarity;semantic computing;data web;web mapping;bibliographic ontology;ontology inference layer;semantic grid;ontology;semantic web;social semantic web;semantic web stack;ontology-based data integration;owl-s;information retrieval;process ontology;semantic analytics;suggested upper merged ontology	AI	-39.70299561693919	6.724986083743396	36070
2f2f430909920f77ee8493e0742dd7da46b7b39f	discovery of constraints from data for information system reverse engineering	bottom up;information systems;data integrity;top down;noisy data;software performance evaluation;functional dependency;design recovery;information systems reverse engineering databases data mining process design software maintenance information technology australia maintenance engineering design engineering;knowledge acquisition;error tolerant functional dependency discovery constraint discovery information system reverse engineering functional dependencies database design recovery process computational expense legacy database performance erroneous data collective fd algorithm top down approach attribute list algorithm noisy data data errors;information system;very large databases;database design;2200 engineering;reverse engineering;data integrity information systems reverse engineering knowledge acquisition very large databases software performance evaluation	The extraction of functional dependencies is a fundamental activity in the database design recovery process which is part of on an overall information systems reverse engineering effort. Existing algorithms for this task are computationally expensive and appear to be infeasible if applied to large legacy database instances, e.g., their performance deteriorated when number of attributes or/and instances is large and they cannot tolerate erroneous data that may occur in deployed commercial systems. The contributions of this paper are as follows. We propose two algorithms for discovering functional dependencies from data. The collective-FD algorithm, which is based on top-down approach, eliminates redundant specialised functional dependencies to be proposed. The attribute-list algorithm, which is based on bottom-up approach, enables more accurate functional dependency hypotheses to be discovered. In anticipating noisy data, we propose an effective method to discover possible data errors and compute partial functional dependencies. The result is an error-tolerant functional dependencies discovery approach that is more applicable to real world databases for design recovery.	algorithm;analysis of algorithms;bottom-up parsing;database design;effective method;error-tolerant design;functional dependency;information system;reverse engineering;signal-to-noise ratio;top-down and bottom-up design	Wie Ming Lim	1997		10.1109/ASWEC.1997.623753	dependency theory;computer science;data science;top-down and bottom-up design;data mining;database;information system	DB	-46.91067165824241	7.1194774499481275	36077
23c82c411a7638851e4b836ac3ff49de791879c6	leveraging standard software from the cloud with service-oriented eam		The SOA Innovation Lab has investigated the use of standard software packages in a service-oriented context. As a result, a method for developing a service-oriented enterprise architecture with custom and standard software has been obtained. It starts on enterprise level with the identification of domains where both the SOA paradigm and standard software are of relevance. Here SOA capabilities of products from different vendors can be evaluated within a dedicated maturity framework. After pre-requisites and dependencies between distributed components are determined, a high-level architecture can be developed. Currently this approach is extended to address also cloud computing operations of standard software.	capability maturity model;cloud computing;embedded atom model;enterprise architecture;high-level architecture;programming paradigm;relevance;service-oriented architecture;service-oriented device architecture	Helge Buckow;Hans-Jürgen Groß;Gunther Piller;Norbert Strumpf;Oliver F. Nandico;Johannes Willkomm;Alfred Zimmermann	2011			database;software;cloud computing;computer science	SE	-58.12626396515211	17.240301367098944	36085
bae95453dc2c2ddf58ef7647fb60386ba5d6c142	a proposal for a knowledge market based on quantity and quality of knowledge	e decisional community;knowledge quality;knowledge market;decisional dna;soeks;kaas;knowledge quantity	Autonomous market environments have been proposed in the literature as the future of electronic markets. The ability to delegate complex negotiation processes and obtain similar or better results than their human counterparts has generated a great interest in agent-based markets. More recently, such a paradigm has been applied in the field of knowledge management and, more specifically, to knowledge sharing and exchange; however, most of the knowledge market proposals in the literature fail to give details on a key component of their models: knowledge quality. This article presents a new proposal for an agent-based market environment that aims at filling the previously mentioned gap in research. The main contribution of our research is the integration of formal mechanisms for knowledge quality and quantity measurement and the use of these values to set a price for knowledge and select the most suitable agent for negotiation.	knowledge market;knowledge-based systems	Leonardo Mancilla-Amaya;Edward Szczerbicki;Cesar Sanín	2013	Cybernetics and Systems	10.1080/01969722.2013.762233	organizational learning;knowledge management;knowledge-based systems;data mining;management science;procedural knowledge;personal knowledge management;knowledge value chain	AI	-51.732901226745206	12.489851846264754	36092
3df3dc730de898ac6a5aacf7227389da96bcb7e1	rdote - transforming relational databases into semantic web data	relational databases to ontology transformation;rdf dump;rdb2rdf	During the last decade, there has been intense research and development in creating methodologies and tools able to map Relational Databases with the Resource Description Framework. Although some systems have gained wider acceptance in the Semantic Web community, they either require users to learn a declarative language for encoding mappings, or have limited expressivity. Thereupon we present RDOTE, a framework for easily transporting data residing in Relational Databases into the Semantic Web. RDOTE is available under GNU/GPL license and provides friendly graphical interfaces, as well as enough expressivity for creating custom RDF dumps.	declarative programming;gnu;graphical user interface;relational database;resource description framework;semantic web	Konstantinos N. Vavliakis;Theofanis K. Grollios;Pericles A. Mitkas	2010			computer science;sparql;social semantic web;data mining;semantic web stack;database;world wide web	Web+IR	-34.98185742607443	7.658621914844665	36104
7ee8337621ba4c979a5dbdd60b9aa42e6e7be694	towards semantic composition of geospatial web services - using wsmo in comparison to bpel		Geospatial Web Services (GWS) provide access to geospatial data and expose basic processing functionality using Web Service technology. The complexity of geo-processing tasks necessitates the combination of basic Web Services to user-oriented and application-specific service compositions. Semantic heterogeneity and lack of automation have been identified as core problems that hinder the full exploitation of GWS. Current composition approaches do not address these problems. This paper presents an analysis of the use of Business Process Execution Language (BPEL), a state-of-the-art composition approach. Its major limitations in composing GWSs are highlighted. Semantic Web Services (SWS) composition using the Web Services Modeling Ontology (WSMO) is proposed as improvement. As basis for comparison a use-case application is developed in BPEL and in WSMO.	business process execution language;business logic;emergence;extensibility;geoweb;interoperability;ontology (information science);otto h. schade;semantic web service;semantic heterogeneity;service composability principle;sinewave synthesis;sven jaschan;swing (java);wsmo;web coverage service;world wide web	Moses Gone;Sven Schade	2008	IJSDIR			Web+IR	-43.80426237298784	11.680595994758187	36123
1534b6046dbc661d081cbadc1e1908bd6b1d37ee	an unabridged method concerning capability matchmaking of web services	distributed system;service composition;web services logic computer networks distributed computing ip networks web and internet services xml artificial intelligence;capability matchmaking;description logic reasoner;inference mechanisms;web service;web services formal logic inference mechanisms;internet;description logic reasoner unabridged method capability matchmaking web services distributed system internet service discovery service composition iope matchmaking semantic matchmaking;unabridged method;semantic matchmaking;web services;formal logic;description logic;service discovery;iope matchmaking	In recent years Web services has become prevalent and be looked as the best way in constructing distributed system over the Internet. Matchmaking is the key technique concerning Web services because it is the foundation of doing service discovering and composition. The matchmaking of Web services consists of the so called IOPE matchmaking. The capability information carried by IO is different from PE. The IO is the signature of the services while the PE is the actual capability description of the services. The technique used to describe and manipulate IO is different from PE. Previous work are mainly concentrate on the matchmaking of IO. The PE are still lack of means to deal with. In this paper we proposed a method based on description logic to resolve this problem. The main contribution about this method is the possibility of doing the whole semantic matchmaking just using one description logic reasoner	algorithm;correctness (computer science);description logic;distributed computing;input/output;internet;precondition;semantic reasoner;semantics (computer science);web ontology language;web service	Hai Wang;Zeng-zhi Li;Lin Fan	2006	2006 IEEE/WIC/ACM International Conference on Web Intelligence (WI 2006 Main Conference Proceedings)(WI'06)	10.1109/WI.2006.40	web service;computer science;data mining;database;law;world wide web	DB	-43.43049066916397	14.194280434662678	36125
80be98fce640b75213684c7e6bee5051fb81ce1c	on enabling time-aware consistency of collaborative cross-organisational business processes		Collaborative Inter-Organisational Business Processes (IOBPs) are a major step in automating and supporting collaborations of organisations. In this context, collaborative IOBP are usually constrained by hard timing requirements. This paper proposes an approach for analyzing temporal consistency of collaborative IOBPs. The aim is to verify temporal consistency of IOBP and to provide the enactment service with largest intervals as starting time windows of the processes. The proposed approach enables organisations to detect, early on, temporal inconsistencies that may constitute obstacles towards their interaction. Indeed, it provides an enactment service, which provides each partner with information about temporal restrictions to respect by its own processes in accordance with the overall temporal constraints of all involved processes.	business process;eclipse;microsoft windows;requirement	Saoussen Cheikhrouhou;Slim Kallel;Nawal Guermouche;Mohamed Jmaiel	2014		10.1007/978-3-662-45391-9_24	knowledge management;artifact-centric business process model	SE	-54.40397239287103	17.896156940443763	36136
6b17699a0f36e96d428a2e3cee7cfb97ebd4d638	enhancing the utilization of iot devices using ontological semantics and reasoning		This research in progress work demonstrates how the formal, model-theoretic semantics of ontologies can be used for complementing the technical specifications of Internet of Things (IoT) devices with additional high-level information derived from domain ontologies in order to enhance utilization and interoperability. The presented approach substantiates the assumption that a more elaborated description about a device’s capabilities and its features helps in integrating it in different system contexts and fosters interoperability among different IoT devices. We show how basic technical information represented as RDF data can be used to automatically classify IoT devices, how default capabilities can be deduced from these classifications, and how advanced features can be inferred using domain semantics and formal reasoning. The applicability of the presented approach in real world settings is demonstrated by a concrete example from an IoT use case. c © 2016 The Authors. Published by Elsevier B.V. Peer-review under responsibility of the Conference Program Chairs.	baseline (configuration management);denotational semantics;high- and low-level;internet of things;interoperability;ontology (information science);open world;open-world assumption;theory	Stefan Zander;Nicole Merkle;Matthias Frank	2016		10.1016/j.procs.2016.09.015	computer science;knowledge management;data mining;database	AI	-44.39751163811091	6.853335257962758	36159
1d1d3a6d69ce2be5f40ecda5768af817bb917303	decentralised process modelling	local development;development process;process modelling;consistency checking;process model;regular expression	In this paper, we advocate decentralised process modelling and suggest that understanding and modelling the development processes of individual development participants is the key to supporting collaborative development. Our approach relies on recognising individual developers’ states (“situations”) by analysing local development histories. Different situations can be used to trigger a variety of further development actions, such as consistency checks between process models of different development participants. We report on experience using regular expressions to specify particular situations and rules to associate actions with these situations. 1. Motivation and Background A significant proportion of large software development projects involve the participation and collaboration of many development participants, who in turn may be physically distributed. Software process modelling and technology address a wide range of issues surrounding the specification and development of complex systems, including the description of the activities by which software is developed, and supporting this with automated tools [6]. While an understanding of the processes by which software systems are developed is valuable, we believe that understanding and describing “fine-grain” software processes is equally worthwhile, and an effective approach to tackling many of the problems associated with decentralised development is therefore particularly useful. By “fine-grain” we are referring to (a) developer level processes which describe the activities of individual development participants rather than organisations, and (b) representation level processes which can manipulate elements of representation schemes (e.g., specification languages) rather than treating them as “vanilla” objects whose structure and content is irrelevant or unknown [11]. To perform fine-grain process modelling and reap its benefits, many issues of decentralised software development need to be addressed. These include the specification of coordination behaviour between both individual development participants and teams of developers. Ben-Shaul and Kaiser [1] for example, adopt an “international alliance” metaphor in which participating “countries” adhere to “treaties” (c.ƒ. process models) and engage in “summits” (at which process models are enacted). This approach addresses the broad problem of decentralised development between teams of developers rather than individual participants. Engels and Groenewegen [3] propose an approach to specifying the coordinated behaviour of different “objects” using a formalism called Paradigm which, in * (to appear in) Proceedings of EWSPT ’95, Noordwijkerhout, Holland, 3-5th April 1995, Springer-Verlag.	complex systems;emoticon;eventual consistency;mental representation;process modeling;programming paradigm;regular expression;relevance;semantics (computer science);software development;software system;specification language;springer (tank)	Bashar Nuseibeh;Jeff Kramer;Anthony Finkelstein;Ulf Leonhardt	1995		10.1007/3-540-59205-9_55	data science;management science;regular expression;state diagram;local development;computer science;process modeling	SE	-43.833375126801606	21.246486631073886	36163
c95df58e578da34e03726809e6ca8503993d8c02	computer-aided operation planning for an actual machine tool based on updatable machining database and database-oriented planning algorithm	database oriented algorithm;machining database;actual machine tool;updatable database;operation planning		algorithm;automated planning and scheduling	Shinji Igari;Fumiki Tanaka;Masahiko Onosato	2012	IJAT	10.20965/ijat.2012.p0717	database tuning;computer science;data mining;database;engineering drawing;database design	Robotics	-58.30236579954863	9.507647158758859	36208
5500b89dd122ab077a2c5f43cc9de90bf92e0421	exe-spem: towards cloud-based executable software process models		Executing software processes in the cloud can bring several benefits to software development. In this paper, we discuss the benefits and considerations of cloud-based software processes. EXE-SPEM is our extension of the Software and Systems Process Engineering (SPEM2.0) Meta-model to support creating cloud-based executable software process models. Since SPEM2.0 is a visual modelling language, we introduce an XML notation meta-model and mapping rules from EXE-SPEM to this notation which can be executed in a workflow engine. We demonstrate our approach by modelling an example software process using EXE-SPEM and mapping it to the XML notation.	algorithm;cloud computing;executable compression;meta-process modeling;metamodeling;model-driven engineering;modeling language;shortest seek first;software development process;trustworthy computing;video synopsis;workflow engine;xml	Sami Alajrami;Barbara Gallina;Alexander Romanovsky	2016	2016 4th International Conference on Model-Driven Engineering and Software Development (MODELSWARD)		software distribution;programming language	SE	-53.350191120360655	22.59690014107848	36249
b0f8e7430c0e6751dce5805650cf78a69dd03d52	knowledge maps for composite e-services: a mining-based system platform coupling with recommendations	decision support;service provider;topic maps;data mining;collaborative filtering;knowledge maps;composite e service;recommendation;article	Providing various e-services on the Internet by enterprises is an important trend in e-business. Composite e-services, which consist of various e-services provided by different e-service providers, are complex processes that require the cooperation among cross-organizational e-service providers. The flexibility and success of e-business depend on effective knowledge support to access related information resources of composite e-services. Thus, providing effective knowledge support for accessing composite e-services is a challenging task. This work proposes a knowledge map platform to provide an effective knowledge support for utilizing composite e-services. A data mining approach is applied to extract knowledge patterns from the usage records of composite e-services. Based on the mining result, topic maps are employed to construct the knowledge map. Meanwhile, the proposed knowledge map is integrated with recommendation capability to generate recommendations for composite e-services via data mining and collaborative filtering techniques. A prototype system is implemented to demonstrate the proposed platform. The proposed knowledge map enhanced with recommendation capability can provide users customized decision support to effectively utilize composite e-services. 2006 Elsevier Ltd. All rights reserved.	cognitive map;collaborative filtering;data mining;decision support system;e-services;electronic business;knowledge management;prototype;topic maps	Duen-Ren Liu;Chih-Kun Ke;Jia-Yuan Lee;Chun-Feng Lee	2008	Expert Syst. Appl.	10.1016/j.eswa.2006.10.005	service provider;topic maps;decision support system;computer science;knowledge management;artificial intelligence;data science;collaborative filtering;data mining;knowledge extraction	AI	-47.50957826060848	8.809332407787446	36277
04b89e9ea5cf48cd495f5bafa0ed08525924e419	a method of design improvement with the structured product concept	human centered design;secure system;product concept;manufacturing industry;small enterprise;usability;new products;product development	"""The product development in service science will become important for manufacturing industry. Therefore, the introduction of the """"service science"""" concept is necessary in product development. This paper proposes a design improvement method based on HCD (Human Centered Design) concept, which can be introduced to middle/small enterprises, with the structured product concept. A case study of the operation panel design of home security system is discussed in this paper. This method is effective not only in making new products but also in improving developed products. Making a structured product concept is also effective to get consensus among the developers."""		Ichiro Hirata;Toshiki Yamaoka	2007		10.1007/978-3-540-73279-2_18	service product management;systems engineering;engineering;knowledge management;operations management;product lifecycle;product design specification;design review;product management;product design;new product development;product engineering	EDA	-61.737732785386534	10.488369437713077	36305
538f1917e568bc971d4013e94eb5ab641207e6fa	the concurrency factory: a development environment for concurrent systems	real time;large scale system;development environment;concurrent systems;communication protocol;process algebra;process control system	The Concurrency Factory supports the speciication, simulation , veriication, and implementation of real-time concurrent systems such as communication protocols and process control systems. While the system uses process algebra as its underlying design formalism, the primary focus of the project is practical utility: the tools should be usable by engineers who are not familiar with formal models of concurrency, and it should be capable of handling large-scale systems such as those found in the telecommunications industry. This paper serves as a status report for the Factory project and brieey describes a case-study involving the GNU UUCP i-protocol.	concurrency (computer science);concurrency control;control system;formal system;gnu;process calculus;real-time clock;simulation;uucp	Rance Cleaveland;Philip M. Lewis;Scott A. Smolka;Oleg Sokolsky	1996		10.1007/3-540-61474-5_88	communications protocol;process calculus;real-time computing;concurrent computing;computer science;process control;distributed computing;development environment;programming language	Embedded	-36.38547489619945	31.402516022606125	36310
7422465fca079e8a13c81fb2dc8c088b180aef9c	a mechanism for environment integration	developpement logiciel;sistema operativo;architecture systeme;programming environment;integrable system;ingenieria logiciel;software engineering;medio ambiente programacion;large scale;operating system;desarrollo logicial;software development;genie logiciel;arquitectura sistema;systeme exploitation;system architecture;environnement programmation	This paper describes research associated with the development and evaluation of Odin-an environment integration system based on the idea that tools should be integrated around a centralized store of persistent software objects. The paper describes this idea in detail and then presents the Odin architecture, which features such notions as the typing of software objects, composing tools out of modular tool fragments, optimizing the storage and rederivation of software objects, and isolating tool interconnectivity information in a single centralized object. The paper then describes some projects that have used Odin to integrate tools on a large scale. Finally, it discusses the significance of this work and the conclusions that can be drawn about superior software environment architectures.	centralized computing	Geoffrey Clemm;Leon J. Osterweil	1990	ACM Trans. Program. Lang. Syst.	10.1145/77606.77607	integrable system;simulation;software development;systems architecture	SE	-37.657914273400955	25.353732431134073	36314
6fccaf52a6e1231852e01712cb0a69e5faa69cf6	semantic enhancement for enterprise data management	data management;semantic query;semantic web technology;semantic web;mapping;reasoning;automatic classification;business process;master data management	Taking customer data as an example, the paper presents an approach to enhance the management of enterprise data by using Semantic Web technologies. Customer data is the most important kind of core business entity a company uses repeatedly across many business processes and systems, and customer data management (CDM) is becoming critical for enterprises because it keeps a single, complete and accurate record of customers across the enterprise. Existing CDM systems focus on integrating customer data from all customer-facing channels and front and back office systems through multiple interfaces, as well as publishing customer data to different applications. To make the effective use of the CDM system, this paper investigates semantic query and analysis over the integrated and centralized customer data, enabling automatic classification and relationship discovery. We have implemented these features over IBM Websphere Customer Center, and shown the prototype to our clients. We believe that our study and experiences are valuable for both Semantic Web community and data management community.	business process;centralized computing;conceptual schema;data model;database;ibm websphere;portal;prototype;sparql;semantic web;semantic query;trionic	Li Ma;Xingzhi Sun;Feng Cao;Chen Wang;Xiaoyuan Wang;Nick Kanellos;Daniel C. Wolfson;Yue Pan	2009		10.1007/978-3-642-04930-9_55	semantic computing;semantic grid;data management;computer science;knowledge management;semantic web;social semantic web;digital firm;semantic web stack;database;customer intelligence;enterprise data management;business process;semantic technology;world wide web;reason;enterprise information system;data mapping	DB	-47.95180548506856	8.444170810507302	36346
2d3a4ffde9ac43a9e9683bdc5d2c7a169617c283	a method towards modelling and analysis of semantically-enriched reconfigurable manufacturing systems		Modelling and simulation are two relevant facets for thorough and effective analysis of industrial systems that nowadays have to cope with the evergrowing complexity of the industrial processes and the need of modelling flexibility and knowledge sharing. For all these reasons, the following work seeks to explore and combine together different methodologies by exploiting their best features. In particular, the current research aims to combine semantic technologies, such as ontologies, and high-level Petri nets to revamp the actual assembly systems. Thus, key research concepts are presented, explaining such potential integration and providing a short example of the dynamic configuration of an assembly system within a semantically enriched modelling environment.		Damiano Nunzio Arena;Dimitris Kiritsis	2016		10.1007/978-3-319-51133-7_6	systems engineering;petri net;ontology (information science);semantic technology;knowledge sharing;computer science	Robotics	-60.540754654821164	16.434233551243935	36348
4eaf1f80eb7da138cfd1f85c5ed7ed8828c5f57c	a policy-based resource instantiation mechanism to automate software process management	resource allocation;policies;process centered software engineering environments;process centered software engineering environment;process management;process design;management strategy;software process instantiation;process model;software quality;meta model;software process	Process-Centered Software Engineering Environments (PSEEs) deal with activities that demand specialized personnel and limited resources. Characteristics about required resources and people (and their dynamic availability) are used by software process instantiation phase to define process allocation strategies. However, most of existing PSEEs do not allow precise resource specification, and the instantiation is often based on the knowledge of a process designer, mostly without automated support. Thus, process managers must make all major decisions based on their individual insights and experience: this constitutes a major obstacle for resource allocation analysis and optimization in process systems and can influence project management and overall software quality. This paper proposes Instantiation Policies as a compact formalism, integrated to a process modeling language, to allow user-defined reusable management strategies for resource instantiation. Through the proposed language it is possible to plan or automate allocation depending on process and organization current situation. This paper discusses the motivations for this solution, shows the proposed meta-model, language and some application examples for this approach.	mathematical optimization;metamodeling;modeling language;process architecture;process modeling;semantics (computer science);software development process;software engineering;software quality;universal instantiation	Carla Alessandra Lima Reis;Rodrigo Quites Reis;Heribert Schlebbe;Daltro José Nunes	2002		10.1145/568760.568896	metamodeling;process design;personal software process;verification and validation;team software process;design process;software engineering process group;software project management;resource allocation;computer science;systems engineering;engineering;knowledge management;business process management;package development process;software design;social software engineering;software framework;software development;software engineering;software construction;process modeling;management science;software walkthrough;empirical process;business process modeling;goal-driven software development process;software development process;software quality	SE	-55.97502862120057	21.1947370018403	36368
43da8416e2e36dd97e8e37fe053a21899f83a907	modeltalk: when everything is a domain-specific language	developpement logiciel;software;reusable software component domain specific language back end business application operational support system agile development process modeltalk model driven software development software product lines;operational support system;operations support systems;reusable software component;dsl;software product lines modeltalk domain specific languages model driven development;probability density function;specification languages business data processing object oriented programming product development software reusability;product line;object oriented programming;domain specific languages dsl java assembly lab on a chip xml terminology navigation feedback programming;by product;development process;data mining;agile development;model driven development;langage dedie;large scale;engines;specification languages;modeltalk;sous produit;business data processing;desarrollo logicial;subproducto;software reusability;business;software development;domain specific language;model driven software development;back end business application;architecture basee modele;estructura producto;agile development process;time to market;software product line;structure produit;model driven architecture;software product lines;modeltalk model driven software development;product structure;domain specific languages;arquitectura basada modelo;lenguaje dedicado;java;product development	"""Large-scale, complex, back-end business applications such as telecommunications software constitute a highly competitive and demanding market. These applications feature deep integration with other business and operational support systems. They must be tailored for each customer, and the customized systems must meet strict extrafunctional requirements, commonly called """"telco's five 9s"""" (99.999 percent availability). All this, combined with the need for an agile development process with a short time to market, presents a software development and business challenge. ModelTalk, model- driven software development framework, supports the creation of product lines by using domain-specific languages pervasively at the core of the development process."""	agile software development;domain-specific language;model-driven engineering;requirement	Atzmon Hen-Tov;David H. Lorenz;Assaf Pinhasi;Lior Schachter	2009	IEEE Software	10.1109/MS.2009.97	real-time computing;business requirements;computer science;systems engineering;domain-specific language;software development;requirement;software engineering;systems development life cycle;programming language;new business development;business process modeling;software development process	SE	-55.51417968109133	26.781315407242538	36425
263cdf395f960104d813e1683bc3b5674556f761	alarm based vs. historical trending performance management or really large unix installation performance management			unix	Mario F. Jauvin	1994			performance management;operating system;computer security;alarm;unix;engineering	HPC	-59.8748291569988	5.234122814540668	36441
6679516251a64f52890369657ce1a1c29f7652cd	applying the architectural semantics of odp to develop a trader specification	modele reference;odp trader;specifications;reference model;distributed processing;specification;semantics;architectural semantics;semantica;semantique;specification language;distributed computer systems;formal description technique;qa75 electronic computers computer science;systeme informatique reparti;lenguaje especificacion;traitement reparti;langage specification;lotos;tratamiento repartido;open distributed processing;modelo referencia	This paper provides an introduction to the role of Formal Description Techniques in the development of an architectural semantics for Open Distributed Processing (ODP). Following a brief overview of ODP and the Reference Model for ODP, an outline of the reasons for developing of an architectural semantics is given. The different approaches currently being taken for an ODP architectural semantics are presented. Finally, an ODP infrastructure component — the ODP Trader — is specified using the architectural semantics work.	formal methods;rm-odp;reference model;trader media east	Richard O. Sinnott;Kenneth J. Turner	1997	Computer Networks and ISDN Systems	10.1016/S0169-7552(96)00108-0	reference model;specification language;computer science;database;semantics;programming language;specification;algorithm	SE	-39.07431132613584	27.857347570174763	36460
68a4c566c09e353376c29108c8d283ca2749653a	semantic service composition framework for multidomain ubiquitous computing applications	service composition;constructive description logics;collaborative provisioning process;theorem proving	In this paper we propose a semantic framework based on constructive description logic. The main innovative aspect of our work consists in the formalization of a composition in the form of e-contract semantic statements where the semantic and logic correctness/soundness are formally checked. The e-contract model is based on cooperation ontology and includes control rules. This model improves on the one hand the common understanding between heterogeneous domains, and on the other hand, it ensures an efficient control of each service from remote requester and preserves the confidentiality of the know-how and the privacy of the local domains. In the conclusion of this paper we present a health care scenario that demonstrates the feasibility of our framework and the demonstration statements of the e-contract in $\mathcal{BCDL}_0$.	ubiquitous computing	Mohamed Hilia;Abdelghani Chibani;Karim Djouani	2012		10.1007/978-3-642-34321-6_30	computer science;knowledge management;data mining;database;automated theorem proving;programming language	HCI	-41.134310831514476	14.926613844333305	36497
3af8a2c1146b27f94855eb1adc9d1d37df888c55	a framework for multiuser distributed virtual environments	toy industry;interconnection model;groupware;formal specification;multi user distributed virtual environments;uml;distributed processing;system requirements;defense industry;virtual reality;service robots;interconnected components;multi user;indexing terms;medical robotics;lan interconnection;communication issues;telecommunication traffic;virtual reality multi user distributed virtual environments functional model interconnection model common functionality communication issues system requirements interconnected components unified modeling language uml case study distributed simulation networked virtual environment;industrial training;virtual environment lan interconnection unified modeling language virtual reality industrial training telecommunication traffic defense industry toy industry service robots medical robotics;common functionality;multi access systems;unified modeling language;distributed virtual environment;formal specification virtual reality groupware multi access systems distributed processing digital simulation modelling;functional model;interconnect modeling;virtual environment;distributed simulation;networked virtual environment;digital simulation	A framework for multi-user distributed virtual environments (DVEs) has been proposed. The proposed framework, incorporating two models (the functional model and the interconnection model), attempts to represent the common functionality, communication issues and requirements found in multi-user DVEs. The functional model concentrates on the DVE's functionality, while the interconnection model concentrates on how the components are interconnected to realize the required functionality. The models have been specified using the Unified Modeling Language (UML). An experimental case study demonstrates the applicability and generality of the proposed approach.	digital video effect;function model;interconnection;multi-user;numerous;requirement;unified modeling language;virtual reality exposure therapy	Maja Matijasevic;Denis Gracanin;Kimon P. Valavanis;Ignac Lovrek	2002	IEEE transactions on systems, man, and cybernetics. Part B, Cybernetics : a publication of the IEEE Systems, Man, and Cybernetics Society	10.1109/TSMCB.2002.1018762	unified modeling language;simulation;computer science;distributed computing;virtual reality	Visualization	-49.76974661347477	19.94536324469845	36587
45bf64a940a5af22f0fba49fd0b0e77831b07a85	exploiting types for improved schema mapping	type rules;heuristic knowledge;life sciences;schema mapping;layout mining	Schema mapping in life sciences is complicated by several factors - heterogeneity and non-standard naming of scientific objects. Traditional mapping techniques fail completely in many instances. This article suggests that exploiting type information and heuristic layout mining help map schemas in life science applications. In some cases, this method appears to be only approach that makes mapping possible in this area.	algorithm;attribute–value pair;bioinformatics;graph rewriting;heuristic;machine learning;type rule	Youngju Son;Hasan M. Jamil;Farshad Fotouhi	2007		10.1145/1244002.1244100	computer science;knowledge management;artificial intelligence;star schema;data mining;database	HPC	-34.105669528227914	8.912836952113452	36664
850759f61fb799f9a039926e878fe9d0a08013ad	an adaptive multi-agent system for cost collaborative management in supply chains	cost collaborative management ccm;context awareness;iocminter organizational cost management;ccmcost collaborative management;rbvresource based view;supply chains;masmulti agent system;caccontext aware computing;amasccm adaptive multi agent system for cost collaborative management in supply chains;ddsdecision support system;adaptive multi agent system	An area that has received much research attention in recent years is the design of self-adaptive multiagent systems (MAS) for cost collaborative management (CCM) of supply chains. We propose a new system that integrates multi-agents, context-aware computing, and context-aware reasoning to improve CCM in supply chains. The main conclusions of our study indicate that these concepts, methods, and mechanisms such as context-aware computing and context-aware reasoning can be used to create a framework for designing self-adaptive MAS-CCM systems, enhance the coordination and interaction of the system with the external environment, and strengthen the capability of the system for self-learning and self-adaptation. And we use a case study to confirm that environmental uncertainty can be automatically reduced to a win-win mode demonstrating the self-adaptive property of the AMAS-CCM system through a context-aware database, and collaborative capabilities can solve current adaptability and cost control optimization in supply chain members. & 2015 Elsevier Ltd. All rights reserved.	agent-based model;context awareness;feedback;intelligent agent;mathematical optimization;multi-agent system;network theory;programming paradigm;software system;supply chain network;synergy	Jianxi Fu;Yuanlue Fu	2015	Eng. Appl. of AI	10.1016/j.engappai.2015.05.002	service management;knowledge management;supply chain	AI	-43.85590687800627	20.129725565794992	36673
bd0f5a9da85d3a6a1e1d34f8afdfb77746bf0e9f	requirements bazaar: social requirements engineering for community-driven innovation	software;requirements prioritization social requirements engineering community of practice requirements elicitation requirements negotiation requirements traceability;community of practice;formal specification;technological innovation;social requirements engineering;uncertainty;prototypes;requirements negotiation;requirements elicitation;social sciences computing formal specification online front ends;niche communities social requirements engineering community driven innovation requirements bazaar browser based social software sre service providers requirements specification cocreation workflow workspace integration personalizable requirements prioritization;online front ends;social sciences computing;requirements prioritization;computer science;communities;requirements traceability;communities technological innovation software computer science educational institutions uncertainty prototypes	The innovation potential of niche communities often remains inaccessible to service providers due to a lack of awareness and effective negotiation between these two groups. Requirements Bazaar, a browser-based social software for Social Requirements Engineering (SRE), aims at bringing together communities and service providers into such a negotiation process. Communities should be supported to express and trace their requirements and eventually receive a realization. Service providers should be supported in discovering relevant innovative requirements to maximize impact with a realization. In this paper we present Requirements Bazaar with focus on four aspects: requirements specification, a workflow for co-creation, workspace integration and personalizable requirements prioritization.	niche blogging;requirement;requirements engineering;software requirements specification;web application;workspace	Dominik Renzel;Malte Behrendt;Ralf Klamma;Matthias Jarke	2013	2013 21st IEEE International Requirements Engineering Conference (RE)	10.1109/RE.2013.6636738	requirements analysis;requirements management;requirement prioritization;uncertainty;business requirements;computer science;systems engineering;engineering;knowledge management;requirement;software engineering;needs analysis;system requirements specification;requirements elicitation;formal specification;prototype;non-functional requirement;requirements traceability	SE	-57.71525844889211	20.715780891956168	36675
94b2bd238a3f17add3c3a031eef33a8c2e4f5609	reputation = f(user ranking, compliance, verity)	verity measuresthe degree;user rating;service contract;performance history;reputation mechanism;end user;web service;service provider;user ranking;expression confines reputation;novel qos metric;history;web server;knowledge representation;web services;internet;quality of service;software engineering;world wide web;service oriented architecture;computer science	The selection of Web services is typically based on both functional and nonfunctional attributes of the service, such as the quality of service (QoS) levels. Reputation, a widely acknowledged nonfunctional QoS attribute is currently expressed as the average of user ratings given to the service. However, this expression confines reputation to the subjective perception of the end user and is limited by the lack of an objective representation of performance history. In this paper, we address the need for a reputation mechanism that couples the subjective perception of the end user with the objective view of performance history. To represent performance history, we propose a novel QoS metric termed verity. Verity measures the degree of consistency exhibited by the service provider in delivering the quality levels laid out in the service contract, over a range of previous transactions. We express reputation as a composition of user rating, the compliance levels exhibited by the provider and the verity value. We contend that this reputation expression is a more viable attribute of quality than user rating alone.	quality of service;web service	Sravanthi Kalepu;Shonali Krishnaswamy;Seng Wai Loke	2004	Proceedings. IEEE International Conference on Web Services, 2004.	10.1109/ICWS.2004.1314740	web service;knowledge representation and reasoning;computer science;knowledge management;database;law;world wide web	Visualization	-44.91104846892976	15.121440860366254	36681
d09ad2b8e3c307ca825ff3472a02b49bb3c93da4	towards rigorous metamodeling	information system;complex system;relational model;development process	MDE has provided several significant improvements in the development of complex systems by focusing on more abstract issues than programming. However, improvments are needed on the semantic side in order to reach highlevel certification such as the one currently required for critical embedded systems (which will also probably be required in the near future for Information Systems as application of Basel II kind of agreements). This paper presents different means to specify models semantics at the metamodel level. We will focus on the definition of executable SPEM-based development process models (workflow related models) using an approach defined for the TOPCASED project.	complex systems;embedded system;executable;information system;meta-process modeling;metamodeling;model-driven engineering	Benoît Combemale;Sylvain Rougemaille;Xavier Crégut;Frédéric Migeon;Marc Pantel;Christine Maurel;Bernard Coulette	2006			systems engineering;metamodeling;computer science	Embedded	-54.55302420600582	23.686448524223145	36704
7b90e0aa3fec75fdbb53ee3fbbf7b9afd2609b43	aerial manets: developing a resilient and efficient platform for search and rescue applications		The ability of first-responders to react to the aftermath of natural disasters depends heavily on receiving accurate, real-time data about the structures that may have been affected. Because transportation infrastructure may be unusable, aerial assessments are the gold standard by which such assessments are performed. The advent of mobile ad-hoc networks (MANETs) and autonomous aircraft represents a unique opportunity to allow for rapid response, while minimizing the cost of deployment and increasing reliability and operator safety. This paper describes the key challenges to implement fault-tolerant and efficient deployments of collaborative autonomous aircraft to increase operational reliability and performance when performing aerial sensing and assessment. Some challenges are affected by mobility, such as wireless communication, group navigation, and data collection. Security also represents a challenge during the operation of the MANET. We consider the effects of limited resources (e.g., real-time processing power, battery packs) available on the aircraft. By understanding both the application context and the resource availability, networked aircraft can reorganize to ensure resiliency for the mission if a resource failure occurs within the network.	aerial photography;automatic parallelization;autonomous robot;context (computing);fault tolerance;half-life 2: episode one;hoc (programming language);real-time clock;real-time data;reliability engineering;single point of failure;software deployment;television antenna;unmanned aerial vehicle;usability	William H. Robinson;Adrian P. Lauf	2013	JCM	10.12720/jcm.8.4.216-224	embedded system;simulation;telecommunications;computer security;computer network	Mobile	-33.95095515868961	20.847302123155313	36755
50f8e888a5c470806d27d10dde5612ccccd3d6f6	algebraic specification of a model transformation engine	developpement logiciel;modelizacion;algebraic specification;model specification;formal specification;confluencia;metodo formal;methode formelle;model transformation;software development process;confluence;probleme terminaison;term rewrite system;formal method;specification formelle;modelisation;especificacion formal;specification modele;rewriting systems;especificacion modelo;desarrollo logicial;specification algebrique;software development;model driven engineering;architecture basee modele;termination problem;model management;book;rastreabilidad;tracabilite;traceability;modeling;systeme reecriture;problema terminacion;model driven architecture;modeling tool;arquitectura basada modelo	In Model-Driven Engineering, a software development process is a sequence of manipulation tasks that are applied to models, where model transformations play a relevant role. MOMENT (MOdel manageMENT) is a framework that is integrated in the Eclipse platform. MOMENT provides a collection of generic set-oriented operators to manipulate EMF models. In this paper, we present the model transformation mechanism that is embodied by the ModelGen operator. This operator uses the term rewriting system Maude as transformation engine and provides support for traceability. ModelGen has been defined in an algebraic specification so that we can use formal tools to reason about transformation features, such as termination and confluence. Furthermore, its application to EMF models shows that formal methods can be applied to industrial modeling tools in an efficient way. Finally, we indicate how the ModelGen operator provides support for the QVT Relations language in the MOMENT Framework.	algebraic specification;confluence;eclipse modeling framework;formal methods;maude system;model transformation;model-driven architecture;model-driven engineering;qvt;rewriting;software development process;traceability	Artur Boronat;José A. Carsí;Isidro Ramos	2006		10.1007/11693017_20	model-driven architecture;traceability;formal methods;systems modeling;computer science;systems engineering;software development;software engineering;formal specification;confluence;specification;software development process;algorithm	SE	-41.97212956501362	25.903787621446796	36760
ca61cd549cac12e20ef8258263cdfe25924ea8bc	reasoning about xacml policies using csp	xacml;semantic model;access control policy;santic models;model checking;csp;access control;process algebra	In this work we explore the use of process algebra in formalising and analysing access control policies. We do this by considering a standard access control language (XACML) and show how the core concepts in the language can be represented in CSP. We then show how properties of these policies may also be described in CSP, and how model checking may be used to verify that a policy meets the property.We further consider how we may introduce a notion of workflow into this framework, and show that a simple appreciation of the workflow context may limit the things we need to verify about a policy.	access control;model checking;process calculus;xacml	Jeremy Bryans	2005		10.1145/1103022.1103028	semantic data model;model checking;process calculus;computer science;access control;communicating sequential processes;data mining;database;programming language	AI	-37.44626301601357	19.25228712448898	36776
9532e720b5ae105649258be45b417173e6e7f0cf	binary software components in the undergraduate computer science curriculum	computer technology education;new technology;component technology;programming paradigm;computer science curriculum;constructivisim;software component;source code;modeling	"""At one time, commercial software applications were released as single binary executable files. Discussions of the notion of a """"software component"""" were almost always limited to the context of source code. However, with the proliferation of numerous new technologies, applications are now more typically released as collections of cooperating binary components. While there is significant industrial emphasis on binary component technologies, computer science curricula have not yet standardized upon a corpus of fundamentally sound concepts to support education within this paradigm. In this paper, we describe our efforts to define a fundamental core set of concepts to support this important programming paradigm, as well as our efforts to integrate these concepts into a typical undergraduate computer science curriculum."""	commercial software;component-based software engineering;computer science;programming paradigm;text corpus	Allen S. Parrish;Brandon Dixon;David Cordes	2001		10.1145/364447.364615	computing;systems modeling;computer science;component-based software engineering;software engineering;programming paradigm;programming language;constructivism;source code	SE	-47.710093191771065	26.30963445103406	36818
4fe7a96cc3b9663ca6838fbf97327acde3c806ae	repeatability and re-usability in scientific processes: process context, data identification and verification		eScience offers huge potential of speeding up scientific discovery, being able to flexibly re-use, combine and build on top of existing tools and results. Yet, to reap the benefits we must be able to actually perform these activities, i.e. having the data, processing components etc. available for redeployment and being able to trust them. Thus, repeatability of e-Science experiments is a requirement of validating work to establish trust in results. This proves challenging as procedures currently in place are not set up to meet these goals. Several approaches have tackled this issue from various angles. This paper reviews these building blocks and ties them together. It starts from the capture and description of entire research processes and ways to document them. Regarding data, we review the recommendations of the Research Data Alliance on how to precisely identify arbitrary subsets of potentially high-volume and highly dynamic data used in a process. Last, we present mechanisms for verifying the correctness of process reexecutions.	computation;correctness (computer science);documentation;dynamic data;e-science;experiment;high- and low-level;prototype;repeatability;usability;verification and validation	Andreas Rauber;Tomasz Miksa;Rudolf Mayer;Stefan Pröll	2015			simulation;computer science;data mining;database	SE	-62.68416181657786	19.779715241944572	36982
25fc28f57433f5122ef11d7878b7e2946b1c8fa8	towards architectural information in implementation: nier track	agile methods;software;software prototyping;computer architecture java documentation software architecture software unified modeling language programming;python architectural information nier track agile development methods software architecture costumer needs fast faced agile project automatic documentation software validation java architectural annotations;system documentation;architectural reconstruction;program verification;agile development;computer architecture;software architecture;system documentation java program verification software architecture software prototyping;unified modeling language;software architecture agile methods architectural reconstruction;programming;documentation;java	Agile development methods favor speed and feature producing iterations. Software architecture, on the other hand, is ripe with techniques that are slow and not oriented directly towards implementation of costumers' needs. Thus, there is a major challenge in retaining architectural information in a fast-faced agile project. We propose to embed as much architectural information as possible in the central artefact of the agile universe, the code. We argue that thereby valuable architectural information is retained for (automatic) documentation, validation, and further analysis, based on a relatively small investment of effort. We outline some preliminary examples of architectural annotations in Java and Python and their applicability in practice.	agile software development;documentation;iteration;java annotation;python;software architecture	Henrik Bærbak Christensen;Klaus Marius Hansen	2011	2011 33rd International Conference on Software Engineering (ICSE)	10.1145/1985793.1985948	computer architecture;architectural pattern;computer science;systems engineering;software engineering;architectural technology;agile software development;programming language	SE	-52.3510656137903	31.492343988868896	37042
b7611116473e1d43d9ee217a676a3b34e09e4aac	a lightweight architecture for rss polling of arbitrary web sources	way.;web service	We describe a new Web service architecture designed to make it possible to collect data from traditional plain HTML Web sites, aggregate and serve them in more advanced formats, e.g. as RSS feeds. To locate the relevant data in the plain HTML pages, the architecture requires the insertion of some meta tags in the commented text. Hence, the extra markup remains totally transparent to users and programs. Such annotated HTML documents are then routinely pulled by our Web service, which then aggregates the data and serves them over several channels, e.g. RSS 1.0 or 2.0. Also, a REST-style Web Service allows users to submit XQuery queries to the feeds database. Finally, we discuss scalability issues w.r.t. polling frequencies.	aggregate data;html;markup language;meta element;polling (computer science);rss;scalability;web service;xquery	Sergio Bossa;Giacomo Fiumara;Alessandro Provetti	2006			architecture;meta element;rss;mashup;world wide web;xquery;data web;web service;scalability;computer science	Web+IR	-39.44494059267988	10.124771546585077	37049
656a60d846d0fc1dc8c463d1ba9e4a57fd0a38a5	hierarchical and cooperative approaches to logic control design in industrial automation	cooperative approach;software;iec 61499 standard;programmable controllers;color;control design;logic control design;testing;generalized actuator framework;iec standards;drilling;logic design control design industrial control design automation iec standards automatic control object oriented modeling computer industry electrical equipment industry standardization;iec 61131 standard;cooperative systems;unified modeling language;generalized actuator framework hierarchical approach cooperative approach logic control design industrial automation iec 61499 standard iec 61131 standard;programmable controllers control engineering computing cooperative systems iec standards;control engineering computing;industrial automation;gallium;design methodology;hierarchical approach	In this work a general partitioning of logic control design strategies into two main approaches, cooperative and hierarchical, is proposed and some lines for a comparison are drawn. In the authors' opinion, the cooperative approach basically collects methods inspired by IEC 61499 and agent paradigms while, the hierarchical approach, generally collects design procedures inspired by IEC 61131. Among the elements of the latter category, particular attention is devoted to the design methodology based on the Generalized Actuator framework, recently proposed by the authors. A case-study is considered to derive some starting considerations on the properties of the considered approaches	automation;iec 61131;logic control	Andrea Tilli;Andrea Paoli;Matteo Sartini;Claudio Bonivento;Daniele Guidi	2009	2009 IEEE Conference on Emerging Technologies & Factory Automation	10.1109/ETFA.2009.5347063	control engineering;unified modeling language;embedded system;design methods;drilling;computer science;systems engineering;engineering;automation;programmable logic controller;software testing;gallium;computer engineering	EDA	-56.31619384851359	10.36326761633729	37096
f83b58f48f6b02b89946f659e8f401c0aa7c6c4b	analyses of conflict among exception in multi-agent system and an integrated management mechanism	groupware;multiagent systems humans collaborative work chromium collaboration knowledge management concurrent computing technology management information technology taxonomy;multiagent system;knowledge based system;multi agent system;integrated management;software agents groupware multi agent systems exception handling;computer supported collaborative design;conflict taxonomy;software agents;conflict management;multi agent systems;human design agent;machine based design agent;exception handling;integrated conflict management mechanism;human design agent multiagent system exception handling conflict resolution computer supported collaborative design conflict taxonomy integrated conflict management mechanism knowledge based system machine based design agent;collaborative design;system architecture;conflict resolution	Currently much research has been made on multi-agent system (MAS) in CSCD field, especially on exception handling, which is not yet well-addressed due to its sophistication. Conflict between and among agents is of primary in exception presentation, consequently conflict resolution (CR) still plays a central role in collaborative design system. In this paper we discuss the taxonomy of conflict, as well as an integrated conflict management mechanism focusing on conflict resolution in a knowledge-based system consisting of both machine-based and human design agents. To date, there has been little research involving conflict resolution in such a system. A general CR scheme and system architecture is also presented.	exception handling;knowledge-based systems;multi-agent system;systems architecture	Yi Jiao;Qi Zhu;Hui Lv;Baifeng Wu	2005	Proceedings of the Ninth International Conference on Computer Supported Cooperative Work in Design, 2005.	10.1109/CSCWD.2005.194210	exception handling;computer science;knowledge management;artificial intelligence;software agent;multi-agent system;management science	Robotics	-40.102066419384975	18.146929101591237	37139
a4c17ca5a8aef20a6a21669a30713a78be62b129	conditional preferences in software stakeholders' judgments	hierarchical structure;model analysis;goal oriented requirements engineering;analytical hierarchical process	In reality, many of the stakeholders' decisions about their desirable requirements can be dependent on other internal or external factors. Such dependencies entail conditionality between the requirements that have been defined, e.g., a requirement is desirable for the stakeholders only if a certain condition is met or some other requirements are excluded. In this paper, we propose a novel framework that tackles the challenge of capturing and processing software stakeholders' conditional preferences. Our proposal extends the Stratified Analytic Hierarchical Process (S-AHP) method that we have previously introduced. S-AHP is built on top of the Analytic Hierarchical Process method, which performs a pairwise comparison of stakeholders' preferences. The current main framework for handling conditionality is TCP-nets, which suffers from the inability to handle hierarchical structure of comparisons and cycles in dependencies defined by the condition al requirements. Also, TCP-nets is primarily developed for qualitative preferences and its quantitative extensions cannot completely capture quantitative relative importance. We show that our framework is able to address these shortcomings of TCP-nets while preserving many of its advantages.	internet protocol suite;judgment (mathematical logic);requirement;the current	Ivana Ognjanovic;Dragan Gasevic;Ebrahim Bagheri;Mohsen Asadi	2011		10.1145/1982185.1982335	computer science;data mining	Web+IR	-52.11025323654289	18.929322525788262	37159
0b55ee962947ff5f5d88e626ebb1df5c10053a4b	adaptive support of inter-domain collaborative protocols using web services and software agents	ws cdl;agents;eurecom ecole d ingenieur telecommunication centre de recherche graduate school research center communication systems;web services;choreography;b2b collaborations	"""This paper explores the challenges of constructing an architecture for inter-organisational collaborative interactions based on Service Oriented Architecture (SOA), Web services choreographies and software agents. We present an approach to harmonisation of the """"global"""" or neutral definition of business collaborations, with partner-specific implementations, which can differ in terms of platform, environment, implementation technology, etc. By introducing the concept of pluggable business service handlers into our architecture we draw on the work carried out by ebXML initiative, business services interfaces, in particular. Due to increasing need for better management of collaborative interactions, Virtual Organisations (VO) become an important tool for creation and maintenance of federated trust domains among the collaboration partners. We look into the software agents abilities to serve as the background support mechanism for the automation and management of the Virtual Organisations lifecycle."""	business process execution language;compiler description language;correctness (computer science);ebxml;inter-domain;interaction;interoperability;java;object language;plan 9 from bell labs;requirement;service-oriented architecture;software agent;software propagation;swedish institute of computer science;transaction log;trust management (information system);web service	Adomas Svirskas;Michael D. Wilson;Bob Roberts;Ioannis Ignatiadis	2006			systems engineering;engineering;knowledge management;world wide web	SE	-42.36156447443134	17.791629573841853	37171
b726ca418fdd5a7fb5d2847946213fdcd0c585ba	semantic framework for dsls	activity diagram;graph transformation systems;programming language;system modeling;operational semantics;graph transformation;model checking;visualization technique;software development;domain specific language;domain specific languages	Domain-Specific Languages (DSLs) enable domain experts to participate in software development tasks and to specify their own programs using domain abstractions. To define programs using domain concepts, rather than programming language concepts, model-based syntax and semantic specification techniques may offer advantages over current approaches. The purpose of the research described in this paper is to provide a semantic framework that can be used visually by DSL designers, yet has formal underpinnings such that interoperation with verification tools is possible to realize model checking tasks. This research is focused on a visual technique based on activity diagrams and graph transformation rules to define the semantics of DSLs.	activity diagram;digital subscriber line;domain-specific language;graph rewriting;interoperation;model checking;programming language;software development	Zekai Demirezen	2009		10.1145/1639950.1640037	natural language processing;programming domain;computer science;domain-specific language;theoretical computer science;domain model;programming language	SE	-44.76117421141206	27.523736521962597	37180
f02b1bdd814c3ac2bec033285c28a31ca0092779	treating social dimension in software ecosystems through reuseecos approach	software reusability dp industry social aspects of automation software architecture software development management;components;social network social dimension software development process software ecosystem software engineering system development third part developer software industry architectural environment business based environment social based environment software reuse process seco management seco engineering reuseecos;knowledge engineering context organizations communities software reusability;dp industry;software development process;social aspects of automation;software engineering;software ecosystems;social network;software architecture;social networks;software reusability;software industry;value based software engineering;organizations;communities;software reuse software ecosystems components social networks value based software engineering;software reuse;context;software development management;ufrj;knowledge engineering;product development	Since systems and software development processes present challenges beyond the technical side, Software Ecosystems (SECOs) have emerged as an approach to improve Software Engineering (SE) mindset in industry, considering relations among companies and stakeholders. Developing a system has been changed to designing and maintaining a platform and its interface in order to support multiple products developed by a set of distributed and different third-part developers. This fact changes software industry because it requires linking an architectural, a business and a social-based environment in an integrated way and it focuses on software reuse processes. This concern motivated a proposal of a framework for SECOs management and engineering called ReuseECOS. The approach aims at outlining a set of steps that combines those three bases (or dimensions) of SECOs and joins different perspectives in SECOs research literature through a survey. In this paper, the focus is on the last dimension, that is, the social one. A preliminary analysis, done on a Software Reuse Lab's SECOs at COPPE/UFRJ, points out that concepts explored by researchers can be merged in a broader SE approach.	code reuse;scientific literature;software development;software ecosystem;software engineering;software industry	Rodrigo Magalhães dos Santos;Cláudia Maria Lima Werner	2012	2012 6th IEEE International Conference on Digital Ecosystems and Technologies (DEST)	10.1109/DEST.2012.6227914	systems engineering;engineering;knowledge management;social software engineering;software development;software engineering	SE	-61.50304855730493	21.473162246868743	37282
01a69acb93f13918439fe15f7a629e4499ac96f4	performance variability in software product lines: a case study in the telecommunication domain	variability;software product line;architecture	In the research on software product lines, product variants typically differ by their functionality, and quality attributes are more or less similar across products. To accumulate empirical evidence, this paper presents a descriptive case study of performance variability in a software product line of mobile network base stations. The goal is to study the motivation to vary performance, and the strategy for realizing performance variability in the product line architecture. The results highlight that the evolution of customer needs motivates performance variability; performance variability can be realized either with software or hardware variability strategy, with the latter often being prevailing; and the software strategy can be kept focused by downgrading performance.	downgrade;heart rate variability;list of system quality attributes;software product line;spatial variability	Varvana Myllärniemi;Juha Savolainen;Tomi Männistö	2013		10.1145/2491627.2491631	reliability engineering;systems engineering;engineering;operations management;architecture;product engineering	SE	-61.430224849847264	26.3721014480671	37287
8c5e524812656ac00195a639b47af74947c0b7e6	evaluation of the design metric to reduce the number of defects in software development		Software design is one of the most important and key activities in the system development life cycle (SDLC) phase that ensures the quality of software. Different key areas of design are very vital to be taken into consideration while designing software. Software design describes how the software system is decomposed and managed in smaller components. Object-oriented (OO) paradigm has facilitated software industry with more reliable and manageable software and its design. The quality of the software design can be measured through different metrics such as Chidamber and Kemerer (CK) design metrics, Mood Metrics & Lorenz and Kidd metrics. CK metrics is one of the oldest and most reliable metrics among all metrics available to software industry to evaluate OO design. This paper presents an evaluation of CK metrics to propose an improved CK design metrics values to reduce the defects during software design phase in software. This paper will also describe that whether a significant effect of any CK design metrics exists on total number of defects per module or not. This is achieved by conducting survey in two software development companies.	computer-aided design;programming paradigm;software design;software development process;software industry;software system;synchronous data link control;systems development life cycle	M. Rizwan Jameel Qureshi;Waseem Qureshi	2012	CoRR	10.5815/ijitcs.2012.04.02	verification and validation;software sizing;package development process;software design;software reliability testing;software development;software design description;software construction;software quality;software metric;software quality analyst;avionics software	SE	-61.75409007277142	27.59126453852684	37307
76118b6c822c3b1f61a810df60f6929c3af9efc5	e-scape : an extendible sonic composition and performance environment			extensibility;sugarscape	Tim Anderson	1993				HPC	-47.534738724162175	22.982986474701775	37319
eb8badc61292711e261444798d20e94eb55042d0	emerging research themes in services-oriented systems	service science services and distributed systems service engineering process monitoring and management;information technology;process monitoring and management;service science;service oriented architecture information technology;services and distributed systems;service oriented architecture mobile communication business semantics context protocols;international federation of information processing emerging research themes services oriented systems soa it solutions ifip;service oriented architecture;service engineering	Service-oriented Architecture (SOA) is one of the most recent trends in IT solutions. From a technical perspective SOA, can be considered a method for designing and developing IT systems where applications are constructed from loosely coupled and au-tonomous building blocks. For a thorough analysis and discussion of SOA at large, and of the applications it enables, IFIP (International Federation of Information Processing) has recently established a new working group on Services-oriented Systems (WG 2.14/6.12/8.10). The paper presents some first results of the analysis aimed to identify the relevant trends and shape emerging research themes. The goal is to highlight the peculiarities of each area, the main opportunities, and also some possible synergies with the others.	international federation for information processing;loose coupling;service-oriented architecture;service-oriented device architecture;synergy	Luciano Baresi;Nikolaos Georgantas;Kristof Hamann;Valérie Issarny;Winfried Lamersdorf;Andreas Metzger;Barbara Pernici	2012	2012 Annual SRII Global Conference	10.1109/SRII.2012.44	computer science;systems engineering;knowledge management;software engineering;oasis soa reference model	EDA	-61.00561063581399	18.244177869865467	37353
8ee49b6b1e455352a04b1fb8605784fef9987588	togaf usage in outsourcing of software development	application development;outsourcing;togaf;software application architecture;enterprise architecture	TOGAF is an Enterprise Architecture framework that provides a method for developing Enterprise Architecture called architecture development method (ADM). The purpose of this paper is whether TOGAF ADM can be used for developing software application architecture. Because the software application architecture is one of the disciplines in application development life cycle, it is important to find out how the enterprise architecture development method can support the application architecture development. Having an open standard that can be used in the application architecture development could help in outsourcing of software development. If ADM could be used for software application architecture development, then we could consider its usability in outsourcing of software development.	applications architecture;enterprise architecture framework;outsourcing;software development process;the open group architecture framework;usability	Aziz Ahmad Rais;Rudolf Pecinovský	2013	Acta Informatica Pragensia	10.18267/j.aip.25	enterprise architecture framework;functional software architecture;reference architecture;software architecture;the open group architecture framework;architecture tradeoff analysis method;tafim;systems engineering;engineering;architecture domain;applications architecture;service-oriented modeling;software engineering;enterprise architecture management;service;solution architecture;software architecture description;architecture framework;enterprise architecture;view model;resource-oriented architecture;data architecture;computer engineering;business architecture	SE	-57.48965620926983	16.72987838929884	37450
5d34d05c3cc2ebc4598086958c6076803e29c6f7	a multi-agent system for integrated control and asset management of petroleum production facilities - part 2: prototype design verification	control systems;multiagent system;multi agent system;design and development;prototypes artificial intelligence centralised control control system synthesis multi agent systems petroleum industry;asset management;prototypes;real time;artificial intelligence multiagent system integrated control asset management petroleum production facilities prototype design verification petroleum industry;intelligent control control systems usa councils;conceptual model;usa councils;intelligent control;petroleum production facilities;artificial intelligent;oil and gas;multi agent systems;centralised control;control system synthesis;integrated control;petroleum industry;for profit;artificial intelligence;design verification;operation and maintenance;prototype design verification	This three-part paper thoroughly addresses the design and development of multi-agent system for asset management for the petroleum industry, which is crucial for profitable oil and gas facilities operations and maintenance. A research project was initiated to study the feasibility of an intelligent asset management system. Having proposed a conceptual model, architecture, and implementation plan for such a system defined its autonomy, communications, and artificial intelligence (AI) requirements, and initiated the preliminary design of a simple system prototype, we are extending the build of a system prototype and simulate it in real-time to validate its logical behavior in normal and abnormal process situations and analyze its performance. The second-part paper addresses the ICAM system prototype design verification and its logical behavior during sensor faults in the plant.	ant colony optimization algorithms;artificial intelligence;autonomy;institute for complex adaptive matter;integrated computer-aided manufacturing;middleware;multi-agent system;netware;profiling (computer programming);prototype;real-time clock;real-time computing;requirement;simulation;systems design	Atalla F. Sayda;James H. Taylor	2008	2008 IEEE International Symposium on Intelligent Control	10.1109/ISIC.2008.4635951	simulation;systems engineering;engineering;operations management	Robotics	-38.69520493875327	22.162827196456	37468
fe65b6897fc8f826573678c47064f2448731085d	metadata management and sharing in multimedia open learning environment (mole)		This paper presents a framework and an architecture for learning resource management and sharing aiming at facilitating the implementation of such functionality on top of existing Learning Management Systems. It also presents the implementation of this framework and its integration with the MOLE (Multimedia Open Learning Environment – http://www.moleportal.eu/) system. Main components of this architecture are: (a) the LOM Editor, an intuitive web based tool that is able to accommodate different Application Profiles, while getting adapted accordingly; (b) The LOM Repository that stores the metadata generated by the LOM Editor and implements the common repository services (search/expose, submit/store, request/deliver) for the management of metadata records; (c) the user interfaces that exploit those services to expose the metadata management functionality to end-users; and (d) an OAI-PMH interface that allows for harvesting of the repository metadata from large repositories/federations (e.g. ARIADNE, Organic.Edunet etc.) on top of the repository.	application programming interface;consortium;emoticon;learning object metadata;learning organization;management system;requirement;user interface;user profile	Manolis Mylonakis;Polyxeni Arapi;Nikos Pappas;Nektarios Moumoutzis;Stavros Christodoulakis	2011		10.1007/978-3-642-24731-6_29	computer science;knowledge management;multimedia;world wide web	DB	-41.485487123942285	10.927315914453306	37510
9b2b9844353ce6ea51834790dc73a2eeec4fa174	uml profile for the platform independent modelling of service-oriented architectures	service orientation;development process;uml profile;pim level modelling;uml profiles;platform independent model;service oriented architecture;model driven architecture	The vast diversity of implementation and support platforms for service-oriented architectures (such as Web, Grid or even CORBA) increases the complexity of the development process of service-based systems. To reduce it, both the architectural properties of the SOC paradigm and a development approach based on the MDA proposal can be studied. This work describes a UML profile for the PIM-level service-oriented architectural modelling, as well as the correspondent metamodel. PIM (Platform Independent Model) level is chosen because it does not reflect constraints about any specific platform or implementation technology. The proposal sketched in this article is part of our research of a service-oriented development method (SOD-M) called MIDAS.	profile (uml);service-oriented architecture;service-oriented device architecture;unified modeling language	Marcos López Sanz;César J. Acuña;Carlos E. Cuesta;Esperanza Marcos	2007		10.1007/978-3-540-75132-8_30	embedded system;real-time computing;uml tool;computer science;systems engineering;engineering;software engineering;applications of uml;service-oriented architecture;software development process	Vision	-51.836745568426196	25.726722694085243	37518
74501efb5193f59726c3680fc2d4ac12c9aeea0d	advanced widgets for eclipse	information visualization;uml class diagram;complex data	Information Visualization Toolkits are often in the form of applications or complex frameworks and do not integrate into existing applications very easily. In this paper we introduce three Advanced Widgets for Eclipse (AWE) to help create visualizations of complex data. These widgets are packaged as a set of JFace components. The widgets include a Simple UML Class Diagram widget, a Simple Graph Widget and a Nested Zoomable Graph Widget. Each widget conforms to the JFace standards and therefore can easily be incorporated by Java Developers into Eclipse Plug-ins or stand-alone applications.	class diagram;eclipse;information visualization;java;unified modeling language	R. Ian Bull;Casey Best;Margaret-Anne D. Storey	2004		10.1145/1066129.1066131	information visualization;human–computer interaction;computer science;operating system;class diagram;database;programming language;world wide web;complex data type	HCI	-48.72230229189702	25.04487461581174	37522
fad5d915baac1fe98c073cf661d356ff01416464	a methodology and tool set for supporting the development of graphical user interfaces	developpement logiciel;interfase usuario;metodologia;ada;user interface;computer graphics;abstract data types;hci;methodologie;representation descriptor;desarrollo logicial;gks;software development;building blocks;gui;graphic user interface;interface utilisateur;vdm;easel;ood;methodology;grafico computadora;uims;infographie	A methodology and tool set for building application (assumed to be inherently non-graphical) software with graphical user interface is described. Initially, pure application software is built from a set of basic building blocks; subsequently, graphical representations for application objects are defined without direct coding and then the graphical user interface is generated automatically. This paper concentrates on the graphical representation aspects of the user interface. Portability, configurability and sound software engineering principles are major considerations in the design of the overall system architecture. The prototype implementation is based on VDM (Vienna Development Method), Object-based Design, GKS (Graphical Kernel System) and the programming language ADA. An example from CIM (Computer Integrated Manufacturing) is used to illustrate the methodology presented here.	ada;computer-integrated manufacturing;graphical kernel system;graphical user interface;programming language;prototype;software engineering;systems architecture;vienna development method	Francis Neelamkavil;O. Mullarney	1991	Comput. Graph. Forum	10.1111/1467-8659.1010037	look and feel;shell;human–computer interaction;computer science;operating system;graphical user interface;skin;event-driven programming;programming language;user interface;graphical user interface testing;computer graphics (images)	HCI	-47.912149725851144	24.773593471383663	37533
95b2952b2c7097cd947183565a9b413dd7e79648	visualization models and technologies for collaborative product development: status and promise	visualization product development design automation collaborative work collaborative tools solid modeling international collaboration research and development internet mechanical engineering;groupware;visualization schemes;product model;collaborative product development;data visualisation;research and development;internet;internet visualization schemes collaborative product development;internet visualization model collaborative product development light weight representation scheme;light weight representation scheme;product development data visualisation groupware internet;visualization model;product development	Recently, research and development is being actively conducted to develop light-weight representation schemes for product models and visualization-based systems to support collaborative product development. In this paper, several mainstream light-weight representation schemes and visualization-based systems are surveyed. Meanwhile, technologies to integrate visualization-based systems with other functional systems to establish collaborative product development environments are discussed	agent architecture;agent-based model;algorithm;automated planning and scheduling;collaborative product development;computer-aided design;data model;design for manufacturability;download;dynamic dispatch;holon (philosophy);internet;interoperability;new product development;plug-in (computing);scheduling (computing);scientific visualization;simulation;streaming media;system integration;world wide web	W. D. Li;Lian Ding;Chris A. McMahon	2006	2006 10th International Conference on Computer Supported Cooperative Work in Design	10.1109/CSCWD.2006.253247	the internet;information visualization;human–computer interaction;computer science;marketing;multimedia;law;data visualization;collaborative software;new product development	EDA	-51.66454848483724	10.130243630779415	37576
46a1df3a0e6f9eadde294aa54a4510d05131ee2f	a use-case driven approach to formal service-oriented modelling	service orientation;book chapter;software systems;computer science;article;use case	We put forward a use-case based approach for SRML – a formal framework that is being defined by the SENSORIA consortium for serviceoriented modelling. We expand on the way SRML contributes to the engineering of software systems and we propose a number of extensions to the UML for supporting that approach. We use a mortgage brokerage scenario for illustrating our approach.	service-oriented architecture;service-oriented device architecture;service-oriented modeling;software system;unified modeling language	Laura Bocchi;José Luiz Fiadeiro;Antónia Lopes	2008		10.1007/978-3-540-88479-8_12	use case;computer science;software engineering;software system	SE	-51.47026139628934	25.69177899590065	37622
780b76064e9319f6ea80d26d29b9d1c57d2f147b	models of reactive systems - communication, concurrency, and causality		  In this chapter, communication, concurrency, and causality are introduced as basic aspects of reactive systems together with different levels of abstraction for each aspect, giving  prominent examples of specific models as specifically useful combinations. By relating models along different dimension, we  show how to set up development processes allowing not only to support step-wise adding of implementation details, but also  to treat different aspects of a system in isolation and to combine the results, leading to a fork-and-join approach.    	causality;concurrency control	Bernhard Schätz;Holger Giese	2007		10.1007/978-3-642-16277-0_1		OS	-39.09583187419977	29.04544453601744	37661
fffff43f754a3435dbb44c4858b6048b31460fa5	statecharts: their use in specifying and dealing with performance models				Nandamudi Lankalapalli Vijaykumar	1999				Vision	-36.60862654443208	28.376209757512452	37673
6794b5ee309b733738d1eca9ea2ddda2d6511b34	product, process and resource model coupling for knowledge-driven assembly automation		Accommodating frequent product changes in a short period of time is a challenging task due to limitations of the contemporary engineeringapproach todesign, build and reconfigure automation systems. In particular, the growing quantity and diversity of manufacturing information, and the increasing need to exchange and reuse this information in an efficient way has become a bottleneck. To improve the engineering process, digital manufacturing and Product, Process and Resource (PPR) modelling are considered very promising to compress development time and engineering cost by enabling efficient design and reconfiguration of manufacturing resources. However, due to ineffective coupling of PPR data, design and reconfiguration of assembly systems are still challenging tasks due to the dependency on the knowledge and experience of engineers. This paper presents an approach for data models integration that can be employed for coupling the PPR domain models for matching the requirements of products for assembly automation. The approach presented in this paper can be used effectively to link data models from various engineering domains and engineering tools. For proof of concept, an example implementation of the approach for modelling and integration of PPR for a Festo test rig is presented as a case study.	automation;best practice;bottleneck (engineering);case-based reasoning;complexity;data model;download;industry 4.0;mathematical model;population;portland pattern repository;programming paradigm;requirement;sensor;simulation	Borja Ramis;Bilal Ahmad;Daniel Alexandre Vera;Andrei Lobov;Robert Harrison;José L. Martínez Lastra	2016	Automatisierungstechnik		systems engineering;engineering;artificial intelligence;manufacturing engineering;product engineering	SE	-56.52612372170586	11.72887043009139	37680
3704840012774c4619cc1345edfe61a946e4ac1d	compositionality and modularity in process specification and design : a trace-state based approach	top down;priority queue	A top down development is presented of a distributed priority queue. The crucial characteristic that enables this development is the compositionality of the formalism used. Actually we argue that a stronger requirement is needed which combines compositionality with the ability to adapt given specifications, called modularity.		Job Zwiers;Willem P. de Roever	1987		10.1007/3-540-51803-7_34	reliability engineering;real-time computing;computer science;distributed computing	SE	-39.101703493819215	29.13641832140026	37706
c3b21cb45e133cbaef322062a877a6a4c6528e3f	controlled and extensible variability of concrete and abstract syntax with independent language features		Software languages are software too”, hence their creation, evolution, and maintenance is subject to the same challenges. Managing multiple stand-alone variants of similar DSLs raises the related maintenance and evolution efforts for the languages and their associated tooling (analyses, transformations, editors, etc.) to a higher power. Software variability management techniques can help to harness this complexity. Research in software language variability focuses on metamodels and consequently mainly supports managing the variability of abstract syntaxes, omitting concrete syntax variability management. We present an approach to manage controlled syntactic variability of extensible software language product lines through identification of dedicated syntax variation points and specification of variants from independently developed features. This fosters software language reuse and reduces creation, maintenance, and evolution efforts. The approach is realized with the MontiCore language workbench and evaluated through a case study on architecture description languages. It facilitates creating, maintaining, and evolving the concrete and abstract syntax of families of languages and, hence, reduces the effort of software language engineering. CCS CONCEPTS • Software and its engineering → Source code generation; Domain specific languages; Software product lines;	abstract syntax;architecture description language;automatic programming;code generation (compiler);diagram;directory services markup language;domain-specific language;heart rate variability;language workbench;metamodeling;parse tree;programming language;push-button;software product line;spatial variability	Arvid Butting;Robert Eikermann;Oliver Kautz;Bernhard Rumpe;Andreas Wortmann	2018		10.1145/3168365.3168368	software engineering;systems engineering;reuse;independent language;syntax;computer science;software;language workbench;software architecture description;abstract syntax;extensibility	SE	-52.253867986641055	30.373180808724502	37761
fe6c48b599fd251887cf70e6bda1ac2f664e66bf	transformation of the bpmn design model into a colored petri net using the partitioning approach		Formal verification is a process to ensure that the business process model and notation (BPMN) design model is free of deadlock, livelock, and other undesirable properties that can cause a system crash. Formal verification is a complicated procedure involving model abstraction and model checking tools used for property checking. There are several existing transformation techniques that yield an abstract model, but the data perspective is not considered. These techniques are also inappropriate for the large-scale BPMN design model. An automated transformation can reduce the flaws, time consumption, and complexity of the large-scale BPMN design model. This paper proposes a transformation technique and provides a framework for transforming the BPMN design models into colored Petri nets (CPNs). Our techniques cover both the control-flow and data-flow perspectives. The partitioning technique of the BPMN design model is applied to reduce the complexity and leads to a CPN model that can support the hierarchical and compositional verification techniques that are suitable for the large-scale BPMN design models. The proposed transformation has been implemented as a transformation framework and is able to consistently transform the BPMN design models into CPN models.	business process model and notation;coloured petri net;control flow;dataflow;deadlock;formal verification;model checking;process modeling	C. Dechsupa;Wiwat Vatanawood;Arthit Thongtak	2018	IEEE Access	10.1109/ACCESS.2018.2853669	task analysis;distributed computing;business process model and notation;model checking;theoretical computer science;computer science;data modeling;deadlock;petri net;formal verification;crash	SE	-43.41771331387507	31.009434876032905	37826
2f9c797df8534dfa26da6eb03d118e105d96b759	the design and realization of swabbing wells liquid recovery interpretation software	software;well testing;mice;fluids;hydrocarbon reservoirs;liquid recovery well testing swabbing well;production engineering computing;pressure measurement;simulation methods;percolation theory;software mice production fluids graphics pressure measurement permeability;swlris swabbing wells liquid recovery interpretation software working fluid level data liquid level detector interpretation formation parameter reservoir percolation theory numerical simulation method vs2010 well testing software;production;permeability;production engineering computing hydrocarbon reservoirs oil technology;oil technology;swabbing well;graphics;liquid recovery	To get the working fluid level data by using the liquid level detector and to interpret formation parameters isundoubtedly the hot direction  of interpretation formationparameters in future; because it overcomes the traditionaltechnical shortcomings: there are higher input costs and thehigh construction risks; but, it just only need install a set ofliquid level detector in the wellhead of the swabbing well. Thispaper is based on the reservoir percolation theory and thenumerical simulation method, using VS2010 in Windows, anddeveloping a set of well testing software, which is namedswabbing wells liquid recovery interpretation software(referred to as SWLRIS). This software deems the workingfluid level data as input, calculates the downhole pressure andflowrate, and then interprets formation parameters. Thesubsequent instance application  results show that the resultsthat this software uses liquid recovery data to interpret isconsistent with the results that Saphir uses measured pressureto do.	microsoft visual studio;microsoft windows;multitier architecture;percolation theory;requirement;requirements analysis;simulation;software engineering	Bo-Tao Liu;Xin-Hai Wang;Hong Liu;Guoliang Li	2011	2011 Second International Conference on Innovations in Bio-inspired Computing and Applications	10.1109/IBICA.2011.67	petroleum engineering;simulation;engineering;forensic engineering	SE	-60.861921042233384	31.949069699092565	37835
a082b9f3a580063e6737537df3aa0a00a711cd4f	a conversation protocol design between heterogeneous agents using kqml	protocols;multiagent system;multi agent system;waste materials;kqml conversation protocol agent heterogeneous;heterogeneous agents;message content;protocol design;semantics;mas;software agents;agent;multi agent systems;heterogeneous;synchronization;kqml;disparate agents;conversation protocol;ontologies;conversation protocol design;protocols ontologies synchronization waste materials semantics multiagent systems;software agents multi agent systems protocols;disparate agents conversation protocol design heterogeneous agents kqml mas multiagent system message content;multiagent systems	In a MAS (Multi-Agent System) agents may be heterogeneous. Two disparate agents require a common understanding of messages and message content in order to interact with each other. So a conversation protocol is needed for the communication of agents. Several conversation protocols have been proposed, but these don’t work well in an environment of heterogeneity where an agent wishing to interact with a large number of other disparate agents cannot be expected to have knowledge of how to initiate or maintain a conversation with all other agents it may encounter. This paper proposes an application independent conversation protocol is defined at first in which a sequence of activities an agent has to perform to solve the problems in the communication using KQML with the notation of FSM.	knowledge query and manipulation language;multi-agent system;peer-to-peer	Shaolong Zhang;Qiang Wang	2010	2010 International Conference on E-Business and E-Government	10.1109/ICEE.2010.8	communications protocol;synchronization;real-time computing;computer science;ontology;artificial intelligence;software agent;multi-agent system;distributed computing	Robotics	-41.12188721618717	17.650985892441863	37956
f052dd5e8d6f46157a266222fb5774ca9b714288	issues for evaluating reliability in software architectures	reliability;software architecture;quality evaluation	Currently, the requirements of Business sector promote more and more complex Information Systems. Reliability is one of the quality characteristics widely expected by users and developers. This characteristic is architectural by nature since it can be directly promoted by software architecture. This relation determines the importance of designing architectures that guarantee reliable systems. This article presents a research in progress whose objective is developing an architectural evaluation method based on Reliability. The first step considered for designing the method included: the construction of a Conceptual Model, a model to specify the architectural quality based on Reliability (Utility Tree), a set of scenarios associated to this characteristic. The first model allows identifying the concepts inherent to Reliability and their relationships; the second one covers all quality features related to Reliability in order to specify it; and the scenarios guide the software architect for anticipating context stimulus and evaluating the architectural responses.	americas conference on information systems;architecture tradeoff analysis method;information system;reliability engineering;requirement;software architect;software architecture;systems architecture	Anna Grimán;Luis Valdosera;Luis Mendoza;Maria Perez;E. Méndez	2005			reliability engineering;architectural pattern;systems engineering;engineering;software reliability testing;computer engineering	SE	-60.263818225439515	25.700100298231643	37971
616eda29b01ed73751085e2c2f1dd0af20ef049a	selection of cloud delivery and deployment models: an expert system approach			expert system;software deployment	Mustafa I. M. Eid;Ibrahim M. Al-Jabri;M. Sadiq Sohail	2018	IJDSST	10.4018/IJDSST.2018100102	data mining;software deployment;cloud computing;expert system;computer science	HCI	-50.18543658776148	7.999344292996178	38005
801d19bd18834209e9846d7a4d29b4b2058cd280	multiple instances and symbolic variables in executable sequence charts	lenguaje programacion;multiple instance;representacion conocimientos;object interaction;programming language;system modeling;lenguaje uml;systems engineering;semantics;langage modelisation unifie;corba;sequence chart;program verification;diagramme sequence;semantica;semantique;portability;verificacion programa;multiple objectives;serialization;requirement engineering;unified modelling language;ingenierie systeme;langage programmation;open compilers;knowledge representation;verification programme;representation connaissances;sequence diagram;reflection;live sequence chart	We extend live sequence charts (LSCs), a highly expressive variant of sequence diagrams, and provide the extension with an executable semantics. The extension involves support for instances that can bind to multiple objects and symbolic variables that can bind to arbitrary values. The result is a powerful executable language for expressing behavioral requirements on the level of inter-object interaction. The extension is implemented in full in our play-engine tool, with which one can execute the requirements directly without the need to build or synthesize an intra-object system model. It seems that in addition to many advantages in testing and requirements engineering, for some kinds of systems this could lead to the requirements actually serving as the final implementation.	chart;executable;requirement;requirements engineering;sequence diagram	Rami Marelly;David Harel;Hillel Kugler	2002		10.1145/582419.582429	sequence diagram;unified modeling language;systems modeling;reflection;serialization;computer science;theoretical computer science;common object request broker architecture;semantics;programming language;algorithm	SE	-39.89450600174727	26.20409707329448	38009
8d1a9ab4ae345413e72e371fa5bc46bb9bf8a9c7	demonstrating and testing the bml compliance of bml realizers	automatic testing framework;bml standard;example corpus;video corpus;example bml script;bml specification language;bml compliance;bml script;standardized interface;test script;bml realizers	BML realizers are complex software modules that implement a standardized interface –the BML specification language– to steer the behavior of a virtual human. We aim to promote and test the compliance of realizers that implement this interface. To this end we contribute a corpus of example BML scripts and a tool called RealizerTester that can be used to formally test and maintain adherence of realizers to the BML standard. The standardized interface of realizers allowed us to implement RealizerTester as an automatic testing framework that can test any realizer. RealizerTester can 1) help in maintaining the stability and extensibility that is crucial for realizers and 2) contribute to the formalization of the emerging BML standard, both by providing test scripts and a formal description of their constraints and by identifying and resolving execution inconsistencies between realizers. We illustrate the testing practices used in the development of two realizers and demonstrate how RealizerTester is integrated with these practices. The scripts in the example corpus were executed on both realizers. This resulted in a video corpus that demonstrates the semantic equivalences and differences in execution of BML scripts by the two realizers.	battle management language;ca-realizer;extensibility;specification language;text corpus;virtual actor	Herwin van Welbergen;Yuyu Xu;Marcus Thiébaux;Wei-Wen Feng;Jingqiao Fu;Dennis Reidsma;Ari Shapiro	2011		10.1007/978-3-642-23974-8_30	real-time computing;computer science;operating system;database;programming language	SE	-42.4209004792793	30.110807532064413	38100
2b76da2859775aa67e28b16aecf79ce77d22dba8	application of agent-based system for bioprocess description and process improvement	bioprocess interaction;decision support;professor gary montague;information systems;dr mark willis;operant conditioning;agent based;technology;eprints newcastle university;process monitoring;science technology;agent based system;open access;artificial intelligence;process improvement;computer science;bioprocess modelling;product quality;professor jarka glassey;fermentation	An agent-based system framework is developed to provide a flexible environment for analysing bioprocesses based on a whole process understanding. In this system, agent components cooperate with each other in performing their tasks. These include the description of the whole process behaviour, evaluating process operating conditions, monitoring of the operating processes, predicting critical process performance, and providing decision support when coping with process deviations. In all cases the function of the system is to ensure an efficient manufacturing process and to maintain the product quality. The implementation of the agent-based approach is illustrated via a process monitoring scenario.		Ying Gao;Katie Kipling;Jarka Glassey;Mark J. Willis;Gary A. Montague;Yuhong Zhou;Nigel John Titchener-Hooker	2008		10.1007/978-3-540-85565-1_32	advanced process control;engineering;operations management;industrial engineering;process engineering	NLP	-60.347749978055845	10.626734938849872	38164
b39c01e50a7b24928d0da35be4162d338eda1658	kathaa: a visual programming framework for nlp applications		In this paper, we present Kathaa1, an open source web based Visual Programming Framework for NLP applications. It supports design, execution and analysis of complex NLP systems by choosing and visually connecting NLP modules from an already available and easily extensible Module library. It models NLP systems as a Directed Acyclic Graph of optionally parallalized information flow, and lets the user choose and use available modules in their NLP applications irrespective of their technical proficiency. Kathaa exposes a precise Module definition API to allow easy integration of external NLP components (along with their associated services as docker containers), it allows everyone to publish their services in a standardized format for everyone else to use it out of the box.	application programming interface;directed acyclic graph;docker;natural language processing;open-source software;out of the box (feature);thinking outside the box;tinker	Sharada Prasanna Mohanty;Nehal J. Wani;Manish Shrivastava;Dipti Misra Sharma	2016			artificial intelligence;inductive programming;computer science;natural language processing;visual programming language;programming domain	NLP	-40.124781891847626	11.536609535512794	38212
c9ee510f507041ec250132ca5484575746760572	information requirements for an integrated transit/traffic management and traveler information system	automatic vehicle location avl;advanced traveler information systems atis;transportation networks;transit;intelligent transport systems its;automatic vehicle location;advanced traffic management systems atms;public transport;intelligent transportation systems;intelligent vehicle highway system;advanced systems;advanced traveler information system;traffic management;integrated design;information gathering;advanced public transportation systems;advanced traveler information systems;advanced traffic management systems;transport network;public transit;intelligent vehicle highway systems ivhs;advanced traffic management system;information system;transportation operations;operations and management;advanced public transportation systems apts	Abstract This paper documents the assessment of the information requirements for the development of an Integrated Transit/Traffic Management and Traveler Information System. The identification of information requirements represents one of several phases of the information gathering process which was necessary to evaluate the suitability of available technologies, IVHS elements, and architectures for the design of an operational test of the integration of transit and traffic management and traveler information system. The integration design includes the automated transfer of operations and management information between agencies and to the public in order to realize efficiencies in the transportation network. The paper details the information requirements of three public agencies involved in transportation management together with transportation information requirements of the traveling public. Availability of the required data is assessed and existing and potential data sources are identified.	information system	Barbara Neenan;Greta P. Y. Huang	1993	J. Intellig. Transport. Systems	10.1080/10248079308903790	simulation;computer science;engineering;civil engineering;management information systems;transport engineering;public transport;risk management information systems;structure of management information;computer security;advanced traffic management system;information system	HPC	-51.68562557237166	4.9030402327807066	38229
94bf5082b181eccaa1a21aca0bf25f3026a10947	semantics-based composition of factory automation processes encapsulated by web services	web service composition semantic web services web ontology language for services owl s;domain services semantics based composition factory automation processes semantic web services production process management production systems web service interfaces web ontology language for services owl s event notifications;ontologies artificial intelligence;production engineering computing;knowledge representation languages;web services factory automation knowledge representation languages ontologies artificial intelligence production engineering computing semantic web user interfaces;web services;semantic web;factory automation;user interfaces;web services monitoring ontologies semantics semantic web software agents	This paper presents an approach to using semantic web services in managing production processes. In particular, the devices in the production systems considered expose web service interfaces through which they can then be controlled, while semantic web service descriptions formulated in web ontology language for services (OWL-S) make it possible to determine the conditions and effects of invoking the web services. The approach involves three web services that cooperate to achieve production goals using the domain web services. In particular, one of the three services maintains a semantic model of the current state of the system, while another uses the model to compose the domain web services so that they jointly achieve the desired goals. The semantic model of the system is automatically updated based on event notifications sent by the domain services.	algorithm;automated planning and scheduling;automation;domain model;owl-s;ontology (information science);planning domain definition language;sparql;semantic web service;web ontology language	Juha Puttonen;Andrei Lobov;José L. Martínez Lastra	2013	IEEE Transactions on Industrial Informatics	10.1109/TII.2012.2220554	web service;web application security;web development;web modeling;business process execution language;data web;web mapping;web standards;computer science;knowledge management;artificial intelligence;automation;ws-policy;semantic web;web navigation;social semantic web;web page;ws-addressing;semantic web stack;database;services computing;web intelligence;ws-i basic profile;user interface;web 2.0;world wide web;owl-s	Web+IR	-43.79384951730284	13.945018176067272	38266
60e82b8150f753211c7c628295367a90a1efd267	issues in expressing metadata application profiles with description logics and owl 2	xml schema;metadata;application profile;integrity constraints;xml;semantic web;ontologies;interoperability;description logic	This paper gives an account of how traditional metadata application profiles are related to Web ontologies and Description Logics. It is shown that metadata profiles can be formalized into Description Logics; oddly enough though, OWL 2, with its current expressivity, is shown to be inadequate for this purpose. First, we give an overview of the recent proposal for representing metadata profiles using the notion of Description Set Profiles and XML Schema. We point out the necessity of an additional representation scheme, using also ontological languages. Following, we introduce a possible translation of Description Set Profiles to Description Logics and identify the required expressivity characteristics that are essential for such a translation. The relationship of this representation to OWL Integrity Constraints is also examined. Finally, we discuss what expense do these characteristics put on to the complexity of reasoning.	data integrity;description logic;ontology (information science);ptc integrity;web ontology language;xml schema	Dimitrios A. Koutsomitropoulos;Georgia D. Solomou	2010		10.1145/1839707.1839718	computer science;document structure description;data mining;database;web ontology language;information retrieval;metadata repository	AI	-37.421290828087876	7.116508449712987	38293
dffb53887788903c2c6d039562cd507ee2986eaa	object-oriented implementation of telecommunication software using the otso environment	object oriented			Juha Koivisto;Juhani Malka;James Reilly	1992			component-based software engineering;software development;object-oriented design;software engineering	SE	-50.840286314999844	28.12845617129456	38297
a4093c383ce4df9fca4a85dfd4ea52942932d3b7	building a software requirements specification and design for an avionics system: an experience report		As with many of the products and systems that pervade us, aircraft rely more and more on software for controlling the behaviour of their systems. In consequence, the field has seen increased work around more up-to-date, effective software engineering technologies for aiding avionics software providers in reducing software and development complexities and supporting them in their certification endeavours. However, there is a lack in the literature of reusable, comprehensive references about avionics software developments in conformance with DO-178C. Moreover, there is a need for a benchmark specification to support the evaluation of proposed engineering approaches in the field. This paper presents a software development case study of an avionics control software for a landing gear system. All the documentation for the software's requirements specification and design has been developed to conform with the DO-178C guideline and the applicable DO-331 and DO-332 supplements for model-based and object-oriented development, respectively. A requirements specification and design methodology is proposed and followed for the construction of the software in the case study. Furthermore, the paper discusses the observations, and challenges and issues experienced throughout the process.	airborne ranger;avionics software;benchmark (computing);black box;conformance testing;content-control software;do-178c;list of version control software;naruto shippuden: clash of ninja revolution 3;natural language;open road tolling;requirement;software design;software development process;software documentation;software engineering;software requirements specification;text-based (computing);traceability;tracing (software);unified modeling language	Andrés Paz;Ghizlane El-Boussaidi	2018		10.1145/3167132.3167268	documentation;certification;software requirements specification;software development;software;systems engineering;do-178c;engineering;software design;avionics software	SE	-57.71406954295888	24.88097495788668	38317
61595a6e658de55b8d2f1a19182d44485758f532	feature-based transfer learning for network security		New and unseen network attacks pose a great threat to the signature-based detection systems. Consequently, machine learning-based approaches are designed to detect attacks, which rely on features extracted from network data. The problem is caused by different distribution of features in the training and testing datasets, which affects the performance of the learned models. Moreover, generating labeled datasets is very time-consuming and expensive, which undercuts the effectiveness of supervised learning approaches. In this paper, we propose using transfer learning to detect previously unseen attacks. The main idea is to learn the optimized representation to be invariant to the changes of attack behaviors from labeled training sets and non-labeled testing sets, which contain different types of attacks and feed the representation to a supervised classifier. To the best of our knowledge, this is the first effort to use a feature-based transfer learning technique to detect unseen variants of network attacks. Furthermore, this technique can be used with any common base classifier. We evaluated the technique on publicly available datasets, and the results demonstrate the effectiveness of transfer learning to detect new network attacks.	feature vector;machine learning;network security;performance evaluation;sensor;supervised learning;vii	Juan Zhao;Sachin Shetty;Jan Wei Pan	2017	MILCOM 2017 - 2017 IEEE Military Communications Conference (MILCOM)	10.1109/MILCOM.2017.8170749	computer network;robustness (computer science);supervised learning;knowledge engineering;transfer of learning;machine learning;feature extraction;network security;computer science;invariant (mathematics);artificial intelligence	Vision	-34.99721203356705	23.111433271265053	38338
54f5e091867168d3df9751ab4b27aa95636cab27	interoperability among cad/cam/cae systems: a review of current research trends	cam;information loss;cad;computational geometry;data exchange;computer aided engineering;cad cam;neutral file format;software package;interoperability;product design;open systems;geometrical data exchange;geometric centric design interoperability cad cam cae product design product development geometrical data exchange software package neutral file format;computer aided manufacturing cadcam computer aided engineering design automation solid modeling geometry history product design software packages redundancy;software packages cad cam computational geometry computer aided engineering open systems product design product development;cae;software packages;geometric centric design;product development	Interoperability among CAD/CAM/CAE systems is a well known problem in product design and development. At present geometrical data exchange among different software packages is usually carried out through neutral file formats (IGES or STEP) or through proprietary formats. Data exchange processes are usually afflicted by several problems, such as: information loss, redundancy, one-way data exchange and static data exchange. These drawbacks do not permit a really geometric-centric design, and even if the model is transmitted without loss of information, the exchanged data do not incorporate details such as sketches, constraints and features, which represent the designer's intent. As a result, the model can hardly be modified, and the original intent of the designer may be misunderstood. During the last five years various solutions have been proposed to solve the above mentioned problems. The aim of this work is to investigate and discuss recent research trends in this topic	application programming interface;computer-aided design;constraint (mathematics);feature model;geometric modeling;human-readable medium;iges;iso 10303;interoperability;one-way function;synchronicity;x/open	Francesco Bianconi;Paolo Conti;Luca Di Angelo	2006	Geometric Modeling and Imaging--New Trends (GMAI'06)	10.1109/GMAI.2006.30	data exchange;interoperability;cam;computational geometry;computer science;cad;open system;product design;new product development;computer-aided technologies;mechanical engineering	DB	-57.94119579204351	9.985971358258348	38390
c10769609655be81bfd1a14089f65bb65ce2b371	cooperation services in the construct structural computing environment	user needs;interoperabilite;interoperabilidad;programming environment;cooperation;systeme ouvert;cooperacion;medio ambiente programacion;hypermedia;computing environment;structural computing;informatique structurelle;interoperability;open systems;sistema abierto;hipermedia;environnement programmation;desktop	Environments for structural computing have seen significant recent development. Generally, they provide different hypermedia structuring facilities to standard desktop applications. Users within these environments may perform activities involving several standard desktop applications and handle several types of hypermedia structures. In this working context, users need cooperation facilities that help them coordinate their activities and manage their roles in cooperation. This paper describes the design, development, and integration of a range of cooperation services into the Construct structural computing environment. q 2003 Elsevier Science Ltd. All rights reserved.	desktop computer;hypermedia;login;monica s. lam;user interface design	Uffe Kock Wiil;Samir Tata;David L. Hicks	2003	J. Network and Computer Applications	10.1016/S1084-8045(02)00065-6	interoperability;simulation;human–computer interaction;telecommunications;computer science;knowledge management;operating system;open system;cooperation	SE	-37.768316950954976	25.241322771529738	38396
942d2131f34d8b2dbb479d96dc3ee98c9cf2b7e7	innovative design of palletizing system for china's local industries		Some old state-owned industries in China, such as sugar companies, still remain traditional production lines, which are dirty, dangers, inefficient, and difficult to transform. Technical revolution has become an indispensable approach. This paper introduces some real cases during the revolution, where robotic techniques, equipment and manipulators have taken the place of labors. The paper also discusses the reasons, proposal, and verification of the innovative designs and techniques. All of these efforts will guide the local companies enter a new stage for the preparation of global competition.	robot	Jianjun Yuan;Chunxiang Wang	2016	2016 IEEE International Conference on Real-time Computing and Robotics (RCAR)	10.1109/RCAR.2016.7784031	simulation;engineering;operations management	Robotics	-61.57497805092409	5.63851940553614	38499
c1ce8de249158f18e8b2b9828f1654b870642ce1	modeling and implementation of unified semantic web platform	software platform;simulation;greedydual;open architecture;algorithm;cache replacement;semantic web;data flow;web caching	"""More and more infrastructure software for semantic web has emerged with the popularity of Semantic Web. Now Semantic Web applications are calling for different infrastructure software to support essential ontology operations, such as ontology persistence, ontology consistency, ontology query, ontology management, reasoning and so on.This paper brings forward the vision about integration of ontology operations based on the unified semantic web software platform.It introduces a model in which varied operations of ontology are added, updated and deleted dynamically.Furthermore, a USWP (""""Unified Semantic Web Platform"""") is implemented according to this model.As an ontology platform using the standard of RDF and RQL, the key characteristic of the USWP is that the platform has a """"total solution"""" for the semantic web applications built on an expansible, flexible, scalable and open architecture.Third part's ontology operation modules can be deployed into USWP with a wrapper under the standard of OOU (""""Ontology Operation Unit"""") and can share data flow with other modules using DOOD (""""Dynamical Operatin Ontology Domain"""") dynamically."""	dataflow;ontology (information science);open architecture;persistence (computer science);scalability;semantic web;web ontology language;web application	Jianjun Xu;Qian Zhu;Juan-Zi Li;Po Zhang;Kehong Wang	2004	IEEE/WIC/ACM International Conference on Web Intelligence (WI'04)	10.1109/WI.2004.100	upper ontology;data flow diagram;ontology alignment;web modeling;data web;bibliographic ontology;ontology inference layer;open architecture;web standards;computer science;ontology;semantic web;social semantic web;data mining;semantic web stack;database;ontology-based data integration;world wide web;owl-s;process ontology;semantic analytics;suggested upper merged ontology	Web+IR	-38.90125551774117	7.8874329588857135	38513
68933a5324b9a8b26b4b5b3e1e44fe970a49c799	a morphogenetically assisted design variation tool	functional blue prints;morphogenetic engineering	The complexity and tight integration of electromechanical systems often makes them “brittle” and hard to modify in response to changing requirements. We aim to remedy this by capturing expert knowledge as functional blueprints, an idea inspired by regulatory processes that occur in natural morphogenesis. We then apply this knowledge in an intelligent design variation tool. When a user modifies a design, our tool uses functional blueprints to modify other components in response, thereby maintaining integration and reducing the need for costly search or constraint solving. In this paper, we refine the functional blueprint concept and discuss practical issues in applying it to electromechanical systems. We then validate our approach with a case study applying our prototype tool to create variants of a miniDroid robot and by empirical evaluation of convergence dynamics of networks of functional blueprints.	blueprint;constraint satisfaction problem;prototype;requirement	Aaron Adler;Fusun Yaman;Jacob Beal;Jeffrey Cleveland;Hala Mostafa;Annan Mozeika	2013			computer science;artificial intelligence;machine learning	AI	-50.91597742683328	21.508711514872342	38520
e3a1777121fd27c2a1405b2ca46b1fd229bcb5eb	in log and model we trust? a generalized conformance checking framework		While models and event logs are readily available in modern organizations, their quality can seldom be trusted. Raw event recordings are often noisy, incomplete, and contain erroneous recordings. The quality of process models, both conceptual and data-driven, heavily depends on the inputs and parameters that shape these models, such as domain expertise of the modelers and the quality of execution data. The mentioned quality issues are specifically a challenge for conformance checking. Conformance checking is the process mining task that aims at coping with low model or log quality by comparing the model against the corresponding log, or vice versa. The prevalent assumption in the literature is that at least one of the two can be fully trusted. In this work, we propose a generalized conformance checking framework that caters for the common case, when one does neither fully trust the log nor the model. In our experiments we show that our proposed framework balances the trust in model and log as a generalization of state-of-the-art conformance checking techniques.	conformance testing;model checking	Andreas Rogge-Solti;Arik Senderovich;Matthias Weidlich;Jan Mendling;Avigdor Gal	2016		10.1007/978-3-319-45348-4_11	reliability engineering;database;computer security	Logic	-52.23095922804808	18.890215602681813	38582
e94b14ace3770a8fc73a86c5cef1dc66bd355f9f	sql2xmi: reverse engineering of uml-er diagrams from relational database schemas	erbium;software;source transformation technology;xml meta interchange;uml;sql;xml meta interchange sql2xmi reverse engineering uml er diagrams relational database schemas application modeling data modeling source transformation technology;prototypes;sql2xmi;sql source transformation uml er database schema;relational database;software engineering;application modeling;data model;data modeling;er;computational modeling;unified modeling language data models erbium object oriented modeling computational modeling software prototypes;source transformation;unified modeling language;database schema;relational databases;metacomputing;uml er diagrams;relational database schemas;object oriented modeling;open standard;reverse engineering;data models;unified modeling language metacomputing relational databases reverse engineering sql	Data modeling is an essential part of the software development process, and together with application modeling forms the core of the model-driven approach to software engineering. While UML is considered the standard for application modeling, there is really no corresponding open standard for data modeling. In this paper, we propose an approach and a tool to help bridge the gap between application and data modeling based on source transformation technology. The tool, called SQL2XMI, automatically transforms an SQL schema into a UML-ER model expressed in XML meta interchange (XMI) 2.1. By bringing the data model to the UML world, both data and application models can be manipulated using the same UML-based tools.	data model;data modeling;entity–relationship model;model-driven architecture;relational database;reverse engineering;sql;software development process;software engineering;source transformation;unified modeling language;xml metadata interchange	Manar H. Alalfi;James R. Cordy;Thomas R. Dean	2008	2008 15th Working Conference on Reverse Engineering	10.1109/WCRE.2008.30	metamodeling;idef1x;unified modeling language;data modeling;model-driven architecture;entity–relationship model;systems modeling language;uml tool;relational database;computer science;applications of uml;data mining;database;programming language;story-driven modeling	SE	-49.15724903881777	26.094525506072653	38584
224fd2accccdb59b0f9f9dfbbd1d025d965b1f17	an agent architecture for manufacturing control: manage	control algorithm;multi agent system;building block;manufacturing control;agent technologies;multi agent systems;cad cam;agent technology;agent systems;agent architecture;distributed control;process and production planning	In this paper we introduce agent concepts to implement control algorithms and application architectures for flexible control in manufacturing. We list requirements for the implementation of the agent itself, assess existing concepts of agent architectures, and give a more detailed overview about the building blocks of an adequate agent system architecture by describing the “manAge” agent system implementation.	agent architecture	Tapio Heikkilä;Martin J. Kollingbaum;Paul Valckenaers;Geert-Jan Bluemink	2001	Computers in Industry	10.1016/S0166-3615(01)00130-0	control engineering;agent architecture;computer science;systems engineering;engineering;artificial intelligence;autonomous agent;multi-agent system;intelligent agent;computer-aided technologies;manufacturing engineering	Robotics	-53.7608156840717	11.63604271319532	38601
ce0d924d044159061a9bb8056d7b3334449b6bfb	a rewriting semantics for abel with applications to hardware/software co-design and analysis	hardware software co design;temporal logic;maude;hardware description languages;program semantics;co verification;rewriting logic;co design;hardware description language;formal analysis;embedded software	We present a rewriting logic semantics in Maude of the ABEL hardware description language. Based on this semantics, and on Maude’s underlying LTL model checker, we propose a scalable formal analysis framework and tool for hardware/software co-design. The analysis method is based on trace checking of finite system behaviors against LTL temporal logic formulas. The formal properties of the hardware, the embedded software, and the interactions between both can all be analyzed this way. We present two case studies illustrating our method and tool.	control system;embedded software;embedded system;executable;formal specification;graphics software;hardware description language;hybrid system;interaction;maude system;model checking;real life;real-time clock;real-time computing;real-time locating system;real-time transcription;rewrite (programming);rewriting;scalability;semantics (computer science);software system;temporal logic;verification and validation	Michael Katelman;José Meseguer	2007	Electr. Notes Theor. Comput. Sci.	10.1016/j.entcs.2007.06.007	formal methods;formal verification;computer science;theoretical computer science;formal semantics;hardware architecture;hardware description language;programming language;register-transfer level;algorithm	Logic	-39.69177187523591	31.8700633513797	38618
905e6d9896420b691b8df2f47cf9f812e8a8edfe	using virtual reality data mining for network management	virtual reality;network management;data mining		data mining;virtual reality	Kathryn E. B. Thornton;C. Radix	2001			data mining;network management;computer science;virtual reality	DB	-50.2371050452041	7.2575843278207115	38707
db3872c86be662d4fef713465146040bacfadd76	a systematic review of model-driven security	protocols;systematic review;security unified modeling language data mining protocols data models business taxonomy;model transformations systematic review survey model driven security model driven security model;data mining;model driven security;mds publications model driven security security threats secure systems model driven engineering approach mds formally designed review protocol;model transformations;business;unified modeling language;taxonomy;model driven;model;security;survey;security of data;data models	To face continuously growing security threats and requirements, sound methodologies for constructing secure systems are required. In this context, Model-Driven Security (MDS) has emerged since more than a decade ago as a specialized Model-Driven Engineering approach for supporting the development of secure systems. MDS aims at improving the productivity of the development process and quality of the resulting secure systems, with models as the main artifact. This paper presents how we systematically examined existing published work in MDS and its results. The systematic review process, which is based on a formally designed review protocol, allowed us to identify, classify, and evaluate different MDS approaches. To be more specific, from thousands of relevant papers found, a final set of the most relevant MDS publications has been identified, strictly selected, and reviewed. We present a taxonomy for MDS, which is used to synthesize data in order to classify and evaluate the selected MDS approaches. The results draw a wide picture of existing MDS research showing the current status of the key aspects in MDS as well as the identified most relevant MDS approaches. We discuss the main limitations of the existing MDS approaches and suggest some potential research directions based on these insights.	authentication;authorization;benchmark (computing);business logic;confidentiality;model-driven engineering;model-driven security;modeling language;profile (uml);relevance;requirement;systematic review;taxonomy (general)	Phu Hong Nguyen;Jacques Klein;Yves Le Traon;Max E. Kramer	2013	2013 20th Asia-Pacific Software Engineering Conference (APSEC)	10.1109/APSEC.2013.64	unified modeling language;data modeling;communications protocol;systematic review;computer science;data mining;world wide web;computer security;taxonomy	SE	-58.32173633405246	21.989936019088173	38709
65c7952c25011c635477b74a765415f31c356da2	integrating uml and uppaal for designing, specifying and verifying component-based real-time systems	components;uml;development process;uppaal;formal method;control system;model checking;system design;corba component model;timed automata;real time systems	A new tool for integrating formal methods, particularly model checking, in the development process of component-based real-time systems specified in UML is proposed. The described tool, TANGRAM (Tool for Analysis of Diagrams), performs automatic translation from UML diagrams into timed automata, which can be verified by the UPPAAL model checker. We focus on the CORBA Component Model. We demonstrate the overall process of our approach, from system design to verification, using a simple but real application, used in train control systems. Also, a more complex case study regarding train control systems is described.	automata theory;common object request broker architecture;component-based software engineering;control system;diagram;formal methods;formal specification;machine translation;model checking;real-time clock;real-time computing;systems design;timed automaton;uml state machine;uppaal;unified modeling language;verification and validation	André L. N. Muniz;Aline Maria Santos Andrade;George Lima	2009	Innovations in Systems and Software Engineering	10.1007/s11334-009-0103-6	model checking;reliability engineering;unified modeling language;real-time computing;formal methods;uml tool;computer science;systems engineering;engineering;control system;applications of uml;software development process;systems design	SE	-44.028624652642435	31.90077597666478	38727
70bb7dae27585a9ac7209578d0bcb8875d6a9935	an approach for the specification and the verification of multi-agent systems interaction protocols using auml and event b	multi agent system	This paper suggests an approach for the specification and the verification of interaction protocols in multi-agent systems. This approach is based on Agent Unified Modelling Language (AUML) and the Event B method. The interaction protocol, are initially modelled using the AUML protocol diagram which gives graphical and comprehensive models. The resulting model is then translated into Event B and enriched which required interaction protocols properties. We obtain a complete requirement specification in Event B which can be verified using the B powerful support tool like the B4free. In this paper, we focus on the translation process of AUML protocol diagrams into Event B and by an example of multi-agent systems interaction protocol, we illustrate our approach.	b-method;communications protocol;contract net protocol;diagram;graphical user interface;interaction protocol;multi-agent system;unified modeling language	Leila Jemni Ben Ayed;Fatma Siala	2008			real-time computing;database;programming language	SE	-40.58001932883699	28.06583968978871	38745
e9689a4a7e5e96ec001b367090331ce31059b896	composition of multi-site software (chaims)	multi-site software			Gio Wiederhold;Dorothea Beringer;Neal Sample;Laurence Melloul	2000	ACM SIGSOFT Software Engineering Notes	10.1145/340855.341082	software;systems engineering;computer science;composition (visual arts)	SE	-62.39476804798594	24.822984313654295	38769
af85a7f0375772c3eb5f81ee97334efb0cbeedcc	integration of distributed manufacturing nodes in smart factory		In this paper, we propose a new approach for the integration of distributed manufacturing networks in the Smart Factory with encapsulation of production/assembly processes in unified node structure. Standard MES and ERP systems are based on the centralization of all data and execution of decision-making algorithms in cloud server. However, the newest IT trends use new decentralised management systems to store data and execute decision-making algorithms to shorten the response time of the network and increase security and data change traceability. Using the guidelines of newest IT trends, we propose a new decentralized production concept that can bring the same benefits as IT technologies.		Miha Pipan;Jernej Protner;Niko Herakovic	2018		10.1007/978-3-030-03003-2_33	distributed manufacturing;traceability;cloud computing;management system;communications protocol;factory;response time;data flow diagram;distributed computing;computer science	Robotics	-54.42236739492394	13.938526802705871	38785
30bc0205d25f3867cce9fc25532cdbb105abeccf	assist as a research framework for high-performance grid programming environments	programming environment;inf 01 informatica;network of workstation;research framework;high performance	ASSIST is a programming environment supporting the development of parallel and distributed high-performance applications on a wide range of target architectures including massively parallel clusters/networks of workstations and Grids. We discuss how ASSIST can act as a valid research vehicle to study, experiment and realize Gridaware programming environments for high-performance applications. Special emphasis is put on the innovative methodologies, strategies and tools for dynamically adaptive applications that represent the necessary step for the success of Grid platforms. We start considering which are the fundamental features of Grid-aware programming environments, based upon structured parallel programming and components technology. Then we show how ASSIST evolved from its very first version, only targeting workstation clusters, to the current version, targeting Grids and solving many critical problems related to expressive power, flexibility, interoperability and efficiency. We also discuss how ASSIST deals with interoperability issues. Eventually we discuss how an ASSIST-based model for supporting dynamically adaptive applications can be derived.	assist (computing);distributed computing;grid computing;integrated development environment;interoperability;parallel computing;workstation	Marco Aldinucci;Massimo Coppola;Marco Vanneschi;Corrado Zoccolo;Marco Danelutto	2006		10.1007/1-84628-339-6_10	real-time computing;simulation;reactive programming;functional reactive programming;computer science;extensible programming;operating system;conceptual framework;database;distributed computing;procedural programming;inductive programming	HPC	-34.18311792115996	28.055625826504144	38800
0755a648f896ae5467f873bc832b4e310c128f8d	agent-based brokerage for virtual enterprise creation in the moulds industry	virtual enterprise creation;moulds industry;agent-based brokerage	Brokerage and partners search is an important activity in the creation phase of a virtual enterprise (VE), where the most adequate consortium of enterprises should be selected to respond to a given business opportunity obtained by a broker. This paper proposes a multi-agent-based architecture to support this functionality in the context of a cluster of twelve enterprises in the moulds and die sector. The system includes a broker agent, a facilitator and consortium agents that plan the possible VEs, and a set of agents representing the enterprises participating in the cluster. The contract-net protocol is used to collect bids from cluster members and to select the most adequate ones. In case the cluster does not cover all the requirements a more general search for partners can be performed on Internet-based directories of enterprises.	agent-based model;contract net protocol;internet;multi-agent system;requirement;virtual enterprise	Ricardo J. Rabelo;Luis M. Camarinha-Matos;Rolando Vargas Vallejos	2000			enterprise software;knowledge management;operations management;business;manufacturing engineering	Web+IR	-52.40658234962297	12.910606302698463	38829
c4db94912987e0484a5e359d3d492708dac8a749	public versus published interfaces	java publishing programming profession writing concrete application software software design monitoring;software engineering;published interfaces software design public interfaces;user interfaces software engineering;software design;user interfaces	One of the growing trends in software design is separating interface from implementation. The principle is about separating modules into public and private parts so that you can change the private part without coordinating with other modules. However, there is a further distinction-the one between public and published interfaces. This distinction is important because it affects how you work with the interface.		Martin Fowler	2002	IEEE Software	10.1109/52.991326	user interface design;personal software process;verification and validation;human–computer interaction;computer science;engineering;package development process;backporting;software design;social software engineering;software framework;component-based software engineering;software development;software design description;software engineering;software construction;adapter pattern;software walkthrough;user interface;resource-oriented architecture;software deployment;software requirements;software system;computer engineering;software peer review	Visualization	-53.050212124624075	28.79846414045304	38969
99407b19adde6fed5fa2be8fe6977ac117519dc1	formalizing architectural connection	architectural connection;government;software systems;software engineering;systems analysis;formal semantics;programming language;computer science;software architecture;computer languages;formal specification;protocols;programming languages	As software systems become more complex the overall system structure { or software architecture { becomes a central design problem. An important step towards an engineering discipline of software is a formal basis for describing and analyzing these designs. In this paper we present a theory for one aspect of architectural description: the interactions between components. The key idea is to de ne architectural connectors as explicit semantic entities. These are specied as a collection of protocols that characterize each of the participant roles in an interaction and how these roles interact. We illustrate how this scheme can be used to de ne a variety of common architectural connectors. We provide a formal semantics and show how this leads to a sound deductive system in which architectural compatibility can be checked in a way analogous to type checking in programming languages.	entity;formal system;interaction;programming language;semantics (computer science);software architecture;software system;type system	Robert J. Allen;David Garlan	1994		10.1145/257734.257745	software architecture;systems analysis;verification and validation;software design pattern;computing;formal methods;architectural pattern;computer science;systems engineering;design by contract;engineering;software design;social software engineering;theoretical computer science;software framework;component-based software engineering;software development;software design description;software engineering;software construction;formal semantics;formal specification;software architecture description;programming language;resource-oriented architecture;software development process;systems architecture;software system	SE	-39.85960126446897	28.190223344385355	39015
45766002a85d2a0150ca5821fd1612a386faa793	software requirements definition for specification database	specification database;requirements definition;relational data model;query language;formal specification;query processing;software requirements language;relational database;query languages;software requirements;computer aided software engineering;visual languages;specification languages;data structures;query processing formal specification computer aided software engineering relational databases specification languages visual languages software quality data structures query languages;relational database management system;relational databases;software requirements specification;relational databases database languages visual databases software maintenance information retrieval humans data models instruments computer science spatial databases;software quality;maintenance software requirements definition specification database relational database software requirements specifications textual specification visual specification requirements model requirements frame text based requirements language visual requirements language tuple relational table query language	The author proposes a method to build a relational database of soffware requirements specifications (SRSs) from textual and visual SRSs automatically. The author has been developing a requirements model named Requirements Frame, a text-base requirements language and a visual requirements language based on the model in order to improve the quality of SRSs. Since Requirements Frame can be transformed into relational data model, each of requirement sentences can be regarded as a tuple of a relational table. The author has been developing both a query language and a relational database management system for an SRS database. One of the features of the SRS DB system is to show an answer with a requirement sentence as an examplekounter-example. This feature contributes to verify the SRS from a developer 5 own viewpoint. Another feature is to detect changed requirements in modification of the SRS. This feature contributes to effective maintenance of the SRS.	data model;query language;relational database management system;relational model;requirement;software requirements	Atsushi Ohnishi	1997		10.1109/APSEC.1997.640215	software requirements specification;data structure;entity–relationship model;relational database;computer science;software engineering;data mining;database;programming language;database design;query language	SE	-51.523497155906604	21.89293392648259	39056
19a5b2cc06c87fca664dd2e832d80e3e3e12dce6	user interaction metadata for healthcare information systems	user interaction metadata;medical informatics;healthcare information systems;data quality healthcare information systems medical informatics usability user analytics user interaction metadata;user analytics;data quality;usability	Semantically consistent understanding of data/content in information systems is a key issue in collaborative work settings. Even simple data -- such as timestamps -- can be a source of misunderstandings both in data entry and reporting tasks. Healthcare information systems generate timestamps during data entry situations. Timestamped data are used for various purposes, such as efficiency calculations, organizational development, and research. However, timestamps are often generated ambiguously in different ways: they are a source of semantic interpretation errors. In this paper we illustrate the phenomena of timestamp ambiguity in medical settings. We suggest that User Interaction Metadata (UIM) could reduce the problems caused by ambiguous and erroneous timestamps. UIM may reveal hidden heterogeneity in data interpretation. Additionally, it can be used to identify user behavior patterns that are currently unrecognizable from raw transaction data.	ambiguity function;information system;report;semantic interpretation;transaction data;trusted timestamping;uim	Sami Laine;Marko Nieminen	2014		10.1145/2639189.2670266	health informatics;data quality;usability;human–computer interaction;computer science;data mining;database;world wide web;metadata repository	HCI	-38.39481577438188	4.273844315613494	39063
858fb8b94896cc8b58a54166a4977bc2356097e8	water resources modelling and simulation software: an integrated approach			simulation software	Fadi El Dabaghi;Driss Ouazar;Nissrine Souissi	2003			computer engineering;simulation software;computer science;distributed computing;water resources	SE	-54.55687405277057	8.09466037218739	39083
2c66de87419cc2c455228583ca08e08cf7321b99	analog systems education: an integrated toolset and fpaa soc boards	mixed signal designs analog systems education integrated toolset fpaa soc boards open source software suite;systems analysis electronic engineering education mixed analogue digital integrated circuits system on chip;field programmable analog arrays electronic mail hardware system on chip open source software system analysis and design	Augmenting lectures in the classroom is desired when teaching analog system design. We present an all-in-one open source software suite and FPAA boards as one solution. The tools are capable of simulating and getting experimental results of mixed signal designs discussed in class. There are two options for students to get data, either remotely or locally. There is an option for students to create their own blocks, which will be shared with the class. Our goal is to empower students to gain intuition of system design and appreciate the value of circuit reuse.	field-programmable analog array;mixed-signal integrated circuit;multi-function printer;open-source software;simulation;software suite;system on a chip;systems design	Michelle Collins;Jennifer Hasler;Suma George	2015	2015 IEEE International Conference on Microelectronics Systems Education (MSE)	10.1109/MSE.2015.7160011	embedded system;electronic engineering;engineering;electrical engineering;operating system;computer engineering	Robotics	-54.023760656563944	4.662374837397341	39128
6fa1b21e0a8a5ec51a557be03751c089d4649c86	solutions d'interopérabilité sémantique pour la surveillance de l'antibiorésistance en europe		This article deals with the problematic of biomedical information sharing in the study of antibioresistance growth in Europe. Our general working hypothesis is: how can we share biomedical information in Europe in a non ambiguous way, in a fast way, and on demand? Many issues are raised by this working hypothesis: the issue of the quality of the data, the issue of the representation of data through structure, vocabulary, and semantics. We also address the problem of alignment of data with domain ontologies and the problem of data mediation using domain ontologies. We then present a system of semantic interoperability based on rules addressing the problem of semantic alignment of heterogeneous systems applied to our domain. Finally we discuss how semantics can contribute to the improvement of information sharing and we also discuss the limits of the current tools and methods. Titre&→&TNR&18& Gras,&bordure&¼&a& 20pts&au9dessus& 18&apres&s’il&y&a&un& sous9titre,& 24&apres&s’il&n’y&a& pas&de&sous9titre&	linear algebra	Rémy Choquet;Ariane Assélé Kama;Jean Charlet;Marie-Christine Jaulent	2013	Ingénierie des Systèmes d'Information	10.3166/isi.18.6.59-82	computer science;artificial intelligence;data mining;computer security;algorithm	Crypto	-44.00462061077352	4.913128738764798	39145
4a2a535975598c511aa0a524b4e87836b790e56c	improving web service descriptions for effective service discovery	web service discovery;web service discoverability anti patterns;web service;web service publication;web services;service discovery	Service-Oriented Computing (SOC) is a new paradigm that replaces the traditional way to develop distributed software with a combination of discovery, engagement and reuse of third-party services. Web Service technologies are currently the most adopted alternative for implementing the SOC paradigm. However, Web Service discovery presents many challenges that, in the end, hinder service reuse. This paper reports frequent practices present in a body of public services that attempt to prevent the discovery of any service. In addition, we have studied how to solve the discoverability problems that these bad practices cause. Accordingly, this paper presents a novel catalog of eight Web Service discoverability anti-patterns. We conducted a comparative analysis of the retrieval effectiveness of three discovery systems by using the original body of Web Services versus their corrected version. This experiment shows that the removal of the identified antipatterns eases the discovery process by allowing the employed discovery systems to rank more relevant services before non-relevant ones, with the same queries. Moreover, we conducted a survey to collect the opinions from26 individuals aboutwhether the improved descriptions are more intelligible than the original ones. This experiment provides more evidence of the importance of correcting the observed problems. © 2010 Elsevier B.V. All rights reserved.	algorithm;anti-pattern;code refactoring;discoverability;discovery system;distributed computing;incidence matrix;information privacy;intelligibility (philosophy);maxima and minima;outsourcing;pict;physical address extension;point of view (computer hardware company);programming paradigm;qualitative comparative analysis;refactoring software, architectures, and projects in crisis;service discovery;service-oriented device architecture;software engineering;web services description language;web service	Juan Manuel Rodriguez;Marco Crasso;Alejandro Zunino;Marcelo R. Campo	2010	Sci. Comput. Program.	10.1016/j.scico.2010.01.002	web service;web application security;web development;web modeling;web mapping;web standards;computer science;service delivery framework;ws-policy;service design;data mining;database;service discovery;web 2.0;world wide web;devices profile for web services;universal description discovery and integration	Web+IR	-49.714377973752654	17.7444672487644	39248
aaed28a5a421271ea18ba590a39805811ae54072	behavioral types for component-based software systems	semantics;software engineering;behavioral types;osgi	We present work on behavioral types for software component systems. Components are annotated with automata-based descriptions of their behavior such as possible interactions observable at components' interfaces. The descriptions act as component types and facilitate comparison of components, compatibility checks, correctness and discovery operations. Behavioral types are motivated, introduced and discussed in the context of the OSGi component system and its semantics. Different applications of behavioral types are presented. The work presented in this paper unifies previously published papers and is intended as an introduction for the behavioral types concept in general.	automata theory;component-based software engineering;correctness (computer science);interaction;osgi;observable;software system	Jan Olaf Blech	2017		10.1145/3014812.3014842	reliability engineering;computer science;theoretical computer science;database	SE	-42.46698259067364	29.6053514708853	39257
cba5782197d4ebed95bc29c926fa4303742bff8c	extension mechanism in extensible xml query language x2ql	data models query languages hypermedia markup languages query processing;extensibility;hypermedia markup languages;query language;aggregation function;java binding extension mechanism extensible xml query language x sup 2 ql application domains domain dependent functions user defined foreign functions data model;query processing;foreign function;data model;query languages;xml;language extension;xml database languages data models java data structures remote sensing computer languages web server internet feature extraction;data models;generic programming	"""XML has been used to code various types of data in a wide range of application domains, and the volume of XML data has been rapidly increasing. XML query languages provide a clue to manipulating huge amounts of XML data. XML data in each application domain have their own structures and associated semantics. Therefore, to appropriately process them, we sometimes need domain dependent functions, taking into account content characteristics. To utilize such functions in XML queries, we need extensibility because they can not be covered by built-in functions. We have developed eXtensible XML Query Language X/sup 2/ QL and its processing system, which feature user-defined foreign functions in the context of XML-QL-based query facilities. Foreign functions are implemented using general programming languages. Extensibility is based on an XML data model in which elements are modeled as stateful objects. This gives """"dynamic aspects"""" (concepts of methods and processing-time properties) to elements, which have been treated as static data in general XML query languages. Our extensibility also enables user-defined aggregation functions and facilities such as sort and top-N selection. This paper explains X/sup 2/QL and its extensibility. Focus is on the data model, Java binding of foreign functions, and how to implement them. The paper also describes development of an X/sup 2/QL query processor working with XML servers."""	query language;xml;xquery	Norihide Shinagawa;Hiroyuki Kitagawa	2001		10.1109/WISE.2001.996479	xml validation;xml encryption;regular language description for xml;simple api for xml;.ql;xml;relax ng;xml schema;streaming xml;computer science;theoretical computer science;document structure description;xml framework;xml database;xml schema;database;rdf query language;xml signature;programming language;world wide web;xml schema editor;query language;efficient xml interchange;object query language;sgml	DB	-33.815754425868725	8.290071185326335	39282
9e0a5f65ffb6d6f5e52b62bf3ad4a4ee62cf1828	how to annotate educational multimedia with non-functional requirements	architectural design;educational multimedia;non functional requirement;educational software;design rationale	We develop a scheme for representing critical non-functional requirements (NFRs), and apply it to the domain of multimedia educational software (MES) to validate it. Our approach extends the model for representing design rationale by making explicit evaluation goals, providing the means to improve the quality of MES. Further research issues will be discussed including the need to relate NFRs to the architectures and a set of architectures to an application domain.	application domain;design rationale;functional requirement;manufacturing execution system;non-functional requirement	Giovanna Avellis;Anthony Finkelstein	2002	Educational Technology & Society		computer science;systems engineering;multimedia;educational software;non-functional requirement;design rationale;computer engineering	SE	-53.27299467140662	24.35008310163386	39315
95898d16d73800315394c8061fdd0dca2b5c7528	flexibility and compliance in workflow systems - the kitcom prototype		Managing workflows is becoming increasingly flexible on both the conceptual and the technical level. However, workflow flexibility has to be accompanied by comprehensive access to information and the processing of it. Validating compliance is a still disregarded but crucial aspect though in flexible workflows where a lot of information is processed. In this contribution, a novel prototype named “KitCom” is presented, aiming at an automated adaptation of controls to realize flexible and compliant workflows. 1 Flexibility and Compliance – Precondition for Effective	freedom of information laws by country;precondition;prototype	Kai Kittel;Stefan Sackmann;Kevin Göser	2013			precondition;workflow management system;workflow technology;systems engineering;workflow;computer science	DB	-58.70172248056686	18.272096575565836	39331
33e49184493a2833f61b641c02532320edcc2f82	computing refactorings of behavior models	modele comportement;developpement logiciel;modelizacion;behavior model;behavior modeling;diagramme etat;modelo comportamiento;espace etat;semantics;semantica;semantique;modelisation;diagrama estado;state space method;methode espace etat;desarrollo logicial;state space;software development;state diagram;architecture basee modele;espacio estado;modeling;computational semantics;software process modelling;mdd;model driven architecture;sp metamodel;process modelling languages;metodo espacio estado;arquitectura basada modelo	For given behavior models expressed in statechart-like formalisms, we show how to compute semantically equivalent but structurally different models. These refactorings are defined by user-provided logical predicates that partition the system's state space and that characterize coherent parts—modes or control states—of the behavior.	code refactoring;coherence (physics);state diagram;state space	Alexander Pretschner;Wolfgang Prenninger	2005		10.1007/11557432_10	behavioral modeling;computer science;artificial intelligence;semantics;algorithm;computational semantics	SE	-40.62215523387986	26.01505942384727	39372
175a7fdc9b7466fb2fc3b689b00ee5a42f0ab145	an assistant tool for concealing personal information in text	graphic user interface;information leakage	This paper describes an assistant tool for concealing personal information in text. This is an important procedure for protecting privacy when public documents are disclosed, preventing accidental leaks of personal information, and other purposes. However, finding personal information in text is very time-consuming and laborintensive. To make it easier to conceal personal information, we have developed a graphical user interface (GUI) tool that extracts candidate personal information in text, indicates candidate personal information using different colors according to its class, and creates rules for extracting personal information from text, including annotations of personal information. In one experiment, our GUI tool enabled users to conceal personal names in Japanese text about three times faster than when the task was done without candidate personal information.	algorithm;color;dictionary;error-tolerant design;experiment;graphical user interface;machine learning;naruto shippuden: clash of ninja revolution 3;personally identifiable information;privacy;randomness extractor	Tomoya Iwakura;Seishi Okamoto	2007		10.1007/978-3-540-73354-6_5	computer science;personal information management;group information management;multimedia;internet privacy;world wide web;personal information manager	NLP	-50.124180844816756	5.187211992296261	39383
2990174b187c38f7a1a39f10a53770618c3d4448	web service composition: a reality check	composite web service;semantic annotation;empirical study;web service discovery;service provider;web service;web service composition;service discovery;service oriented architecture	Automated web service composition is one of the major promises of serviceoriented architecture, where services can be discovered and composed dynamically and automatically. To investigate the methods for composite web service construction, we conducted an experiment on creating useful composite web services from real existing web services where semantic annotations are not available. The empirical study reveals the difficulties and research challenges in the discovery, invocation, and composition of web services. The automation of web service composition requires the inputs from both services providers and service consumers. Service providers need to develop high quality services in a disciplined and collaborative way, and service consumers need to be equipped with tools providing helps such as service discovery and matching.	display resolution;service composability principle;service discovery;web service	Jianguo Lu;Yijun Yu;Debashis Roy;Deepa Saha	2007		10.1007/978-3-540-76993-4_44	service provider;web service;service level requirement;web development;web modeling;differentiated service;web standards;postback;computer science;service delivery framework;ws-policy;service-oriented architecture;service design;social semantic web;ws-addressing;semantic web stack;database;service discovery;internet privacy;empirical research;law;world wide web;devices profile for web services;universal description discovery and integration	Web+IR	-45.63497590202783	15.74583505505329	39384
8f0be956217020994f0d532d1092c02bdbcf6592	a semantic-based fully visual application for matchmaking and query refinement in b2c e-marketplaces	e marketplaces;matchmaking;semantic web	This paper presents a visual application in the framework of semantic-enabled e-marketplaces aimed at fully exploiting semantics of supply/demand descriptions in B2C and C2C e-marketplaces. Distinguishing aspects of the framework include logic-based explanation of request results, semantic ranking of matchmaking results, logic-based request refinement. The visual user interface has been designed and implemented to be immediate and simple, and it requires no knowledge of any logic principle to be fully used.	refinement (computing);user interface	Simona Colucci;Tommaso Di Noia;Eugenio Di Sciascio;Francesco M. Donini;Azzurra Ragone;Raffaele Rizzi	2006		10.1145/1151454.1151489	computer science;data mining;database;information retrieval	AI	-42.63680976663683	13.791133031828656	39425
72ab2b95375f505fe3145b0008aad8d8ef0d1187	a semantic knowledge base construction method for information security	information security;ontologies information security knowledge based systems data mining semantics;semantics;information security knowledge base development semantic knowledge base construction method knowledge entities information technology information security analysis risk evaluation formal semantic model shareable semantic model information security knowledge base construction ontology knowledge base construction method ontology construction processes security analysis applications security management applications;data mining;ontology construction information security knowledge base semantic web;semantic web;ontologies;security of data knowledge based systems ontologies artificial intelligence risk analysis;ontology construction;knowledge based systems;knowledge base	Information security contains many concepts and knowledge entities. As the development of information technology, the complexity of increasing information security knowledge need an overview representation and organization for security analysis and risk evaluation. Ontology as a formal and shareable semantic model, which is often used to define domain knowledge schema, can also be applied for information security knowledge base construction. In this paper, we propose ontology knowledge base construction method for information security, discuss the ontology construction processes, and design the knowledge schema. The ontology contains main concepts in information security and related properties and relations about these concepts with semantics. It supplies related information, such as assets and weakness, to security management and analysis applications. We introduce each step of the proposed method, and valid it using a practical information security knowledge base development.	entity;information security;knowledge base;security management	Yuangang Yao;Xiaoyu Ma;Hui Liu;Jin Yi;Xianghui Zhao;Lin Liu	2014	2014 IEEE 13th International Conference on Trust, Security and Privacy in Computing and Communications	10.1109/TrustCom.2014.106	computer security model;upper ontology;knowledge base;computer science;knowledge management;ontology;body of knowledge;knowledge-based systems;open knowledge base connectivity;data mining;database;knowledge extraction;commonsense knowledge	DB	-42.7004807767862	6.349318610929725	39429
e4443d1147a431ef495260cc6aeca78ee6dde566	modeling and generating context-aware agent-based applications with amended colored petri nets	context aware application;context awareness;context aware;multi agent system;java programming;modeling and simulation;model system;agent based;distributed computing;colored petri nets;distributed computing system;agent based system;mobile distributed computing;concurrency control;colored petri net;modeling methodology;context aware systems	Context-awareness is become more crucial in mobile distributed computing systems. However, sophisticated modeling methods to analyze context-aware systems are still very few. Among those, the Colored Petri Net (CPN) is promising because it is proven to be useful for modeling system dynamics and concurrency control in more efficient ways. However, to support managing multiple configurations of components of context-aware applications, some features need to be added to specialize the CPNs. To address these challenges, our research has two idea: (a) to decompose a system into several meaningful subsystems, each of which we will call a pattern, and (b) to separate context from the patterns to realize context-pattern independence. Hence, we propose a modeling methodology to represent and analyze a context-aware agent-based system, which tends to be highly complex. We introduce CPNs as a method of capturing the dynamics of this contextual change. We define CPNs and a way to apply them in context-aware agent-based systems. We also describe a prototype system that we have developed called CPN Generator, which translates CPN specification into Java programs.	agent-based model;petri net	Oh Byung Kwon	2004	Expert Syst. Appl.	10.1016/j.eswa.2004.06.008	real-time computing;computer science;theoretical computer science;concurrency control;modeling and simulation;distributed computing	HCI	-38.77882197529482	30.389428119641316	39468
03a9860c4185375357fd5aa6fb56e8a64221e00d	user queries for specification refinement treating shared aspect join points	interference detection;programming language semantics;shared join points formal specification semantics aspect interference;shared join point;formal specification;encryption;query processing;temporal logic;semantics;interference;semantics interference weaving authorization encryption cognition;ltl assumption;formal verification;linear temporal logic;shared join points;aspect interference;aspect oriented programming;aspects sharing;natural language;cognition;modular verification;authorization;weaving;base program computation;state transition diagram;interactive semiautomatic procedure;indepth semantics analysis;specification refinement;interactive semiautomatic procedure natural language linear temporal logic base program computation indepth semantics analysis shared join point aspects sharing specification refinement state transition diagram ltl assumption modular verification interference detection formal specification;temporal logic aspect oriented programming formal specification formal verification programming language semantics query processing	We present an interactive semi-automatic procedure to help users refine their requirements formally and precisely, using knowledge the user possesses but does not notice as relevant and has difficulty formalizing. Questions in natural language are presented to the user, and augmentations to specifications, written in Linear Temporal Logic, are automatically created according to the answers. We apply our approach to a case study on specifying the desired aspect behavior in a delicate case when multiple aspects can share a join-point, i.e., be applied at the same state of base program computation. The questions used in the case study are derived from an in-depth analysis of semantics and mutual influence of aspects at a shared join-point. Aspects sharing a join-point might, but do not have to, semantically interfere. Our analysis and specification refinement enables programmers to distinguish between potential and actual interference among aspects at shared join-points, when aspects are modeled as state transition diagrams, and specifications are given as LTL assumptions and guarantees. The refined aspect specification, obtained from the procedure we describe, enables modular verification and interference detection among aspects even in the presence of shared join-points.	computation;correctness (computer science);diagram;formal verification;interaction;interference (communication);join point;linear temporal logic;natural language;programmer;refinement (computing);requirement;semiconductor industry;state transition table	Emilia Katz;Shmuel Katz	2010	2010 8th IEEE International Conference on Software Engineering and Formal Methods	10.1109/SEFM.2010.16	linear temporal logic;state diagram;cognition;aspect-oriented programming;temporal logic;formal verification;computer science;theoretical computer science;formal specification;database;semantics;interference;authorization;natural language;programming language;encryption;weaving	SE	-42.711480259159636	29.254880886708207	39483
668d267b3ad6895b656ca7228b3a47cae7be0f9b	towards conformance testing of rest-based web services		Despite the lack of standardisation for building REST-ful HTTP applications, the deployment of REST-based Web Services has attracted an increased interest. This gap causes, however, an ambiguous interpretation of REST and induces the design and implementation of REST-based systems following proprietary approaches instead of clear and agreed upon definitions. Issues arising from these shortcomings have an influence on service properties such as the loose coupling of REST-based services via a unitary service contract and the automatic generation of code. To overcome such limitations, at least two prerequisites are required: the availability of specifications for implementing REST-based services and auxiliaries for auditing the compliance of those services with such specifications. This paper introduces an approach for conformance testing of REST-based Web Services. This appears conflicting at the first glance, since there are no specifications available for implementing REST by, e.g., the prevalent technology set HTTP/URI to test against. Still, by providing a conformance test tool and leaning it on the current practice, the exploration of service properties is enabled. Moreover, the real demand for standardisation gets explorable by such an approach. First investigations conducted with the developed conformance test system targeting major Cloud-based storage services expose inconsistencies in many respects which emphasizes the necessity for further research and standardisation.	automatic programming;cache (computing);cloud computing;cloud storage;code generation (compiler);computer security;conformance testing;discoverability;elasticity (cloud computing);field research;hypertext transfer protocol;interoperability;loose coupling;microsoft outlook for mac;quality of service;representational state transfer;requirement;service-oriented architecture;software deployment;software developer;software system;streaming media;technical documentation;test automation;uniform resource identifier;version control;web service	Luigi Lo Iacono;Hoai Viet Nguyen	2015		10.5220/0005412202170227	web testing	SE	-59.15968663493467	21.73951252890596	39533
436d55ca34b8dfb4974489a9c96fe9b4f915777c	using shared procedural knowledge for virtual collaboration support in emergency response	manuals;collaboration;planning artificial intelligence;information services;emergency management;internet;web sites emergency management planning artificial intelligence;web sites;knowledge sharing;issues node constraint and annotations extension shared procedural knowledge virtual collaboration support emergency response wiki i n c a representation hierarchical task networks ai planning collaborative editing knowledge engineering;virtual collaboration;planning;knowledge sharing planning collaboration knowledge engineering manuals information services electronic publishing internet virtual collaboration artificial intelligence planning procedural knowledge;procedural knowledge;electronic publishing;emergency services collaboration knowledge engineering information services electronic publishing internet;emergency services;artificial intelligence planning;knowledge engineering	A framework is described for developing and deploying procedural knowledge in emergency situations where collaboration is needed. In this framework, procedural knowledge is represented in a wiki using an informal, textual description that's marked up with formal tags based on the I-N-C-A representation for hierarchical task networks used in AI planning. The tight integration of collaborative editing with deployment is new in this system and advances knowledge engineering for planning domain (procedural) knowledge, which can reduce uncertainty in emergency situations.	automated planning and scheduling;knowledge engineering;software deployment;wiki	Gerhard Wickler;Austin Tate;Jeffrey Hansberger	2013	IEEE Intelligent Systems	10.1109/MIS.2013.31	planning;the internet;computer science;knowledge management;artificial intelligence;knowledge engineering;procedural knowledge;electronic publishing;world wide web;information system;emergency management;collaboration	AI	-45.56628780145628	8.640984187380443	39543
daf084b003c177efd38697944b79b511490745f1	towards a lightweight soa framework for enterprise cloud computing	wsdl extension;complex enterprise product family cloud lightweight soa framework enterprise cloud computing wsdl semiautomation semantic web service composition algorithm critical factors real world service composition business applications statistical software engineering data;enterprise cloud computing;business continuity;web services;semantic web;dynamic service composition enterprise cloud computing wsdl extension version;version;web services business continuity business process re engineering cloud computing semantic web service oriented architecture;semantics quality of service cloud computing algorithm design and analysis impedance matching organizations;business process re engineering;service oriented architecture;dynamic service composition;cloud computing	Cloud computing has become an emerging new computing paradigm. However, the issue of providing complex enterprise product family cloud is not well addressed so far. This article presents a framework featuring an in-depth extension to WSDL and an application oriented semi-automation semantic web service composition algorithm to solve the problem. The extension captures critical factors required by real world service composition scenario. The algorithm presents a complete step set which effectively addresses real application issues in service composition. The presented framework has been applied in three real business applications. Statistical software engineering data verifies its efficiency and applicability on solving the major challenges in complex enterprise product family cloud.	algorithm;cloud computing;programming paradigm;semantic web service;semiconductor industry;service composability principle;software engineering;web services description language	Yi Jiao;Lin Li;Nanrong Ye	2011	Proceedings of the 2011 15th International Conference on Computer Supported Cooperative Work in Design (CSCWD)	10.1109/CSCWD.2011.5960103	web service;service catalog;cloud computing;computer science;service-oriented modeling;software engineering;service-oriented architecture;semantic web;cloud testing;database;utility computing;enterprise integration;data as a service;law;world wide web	HPC	-47.78906303167519	16.66638276457476	39558
f3005c03603e0b597005ae24dbfcef09c9eed91e	a framework for incorporating usability into model transformations.	usability evaluation;user interface;model transformation;software development	The usability of user interfaces is crucial for the success of an application. Model driven user interface (UI) development speeds up the production of UIs and improves the maintainability of UIs. However, the usability evaluation of UIs is usually conducted by end-users or experts after UIs are generated. Such a user centric evaluation is usually time consuming and expensive, especially when the usability problems are detected in the last phase of the software development. In this paper, we propose a framework that incorporates the usability evaluation as an integral part of automatic processes for UI generation. To link the usability goal into the UI generation process, we model the usability using a goal graph for each intermediate UI model and associate the usability goals to the attributes of the models. Our proposed framework detects and addresses usability problems in the early phase of the software development.	floor and ceiling functions;software development;usability goals;user interface	Xulin Zhao;Ying Zou	2007			pluralistic walkthrough;component-based usability testing;usability;human–computer interaction;agile usability engineering;computer science;systems engineering;software development;software engineering;usability engineering;user interface;heuristic evaluation;usability lab;usability inspection	SE	-58.70351425291506	28.68557793831062	39591
9949abb2b763deae737502f9d2fb55f5a9a83ac3	model-driven approach to the integration of multiagent systems and semantic web services	semantic web service;multiagent systems semantic web service oriented architecture web services artificial intelligence outsourcing face detection collaboration humans engines;multiagent system;owl s;grounding;agent based;probability density function;model transformation;agent oriented software engineering;data mining;domain specific modeling language;software agents;knowledge representation languages;agent oriented software engineering model driven agent based coordination approach multiagent system semantic web service matchmaker agent platform independent metamodel model transformation owl s domain specific modeling language;multi agent systems;model driven agent based coordination approach;platform independent metamodel;business;web services knowledge representation languages multi agent systems semantic web software agents;web services;semantic web;semantic web service matchmaker agent;ontologies;meta model	This paper discusses an innovative mean on model-driven agent-based coordination of semantic Web services. The general idea is to define a platform independent meta-model for semantic Web services and integrate it into a platform independent metamodel for multiagent systems. A model-driven semantic Web services matchmaker agent in combination with model transformations between the platform independent metamodel and existing semantic Web service formats like OWL-S allow the seamless integration of semantic Web services into multiagent systems.	agent-based model;domain-specific modeling;metamodeling;model-driven architecture;modeling language;multi-agent system;owl-s;ontology definition metamodel;seamless3d;semantic web service;service-oriented architecture	Christian Hahn;Stefan Nesbigall;Stefan Warwas;Ingo Zinnikus;Matthias Klusch;Klaus Fischer	2008	2008 12th Enterprise Distributed Object Computing Conference Workshops	10.1109/EDOCW.2008.43	ground;metamodeling;web service;probability density function;semantic computing;web development;web modeling;semantic web rule language;data web;semantic search;semantic grid;web standards;computer science;knowledge management;ontology;artificial intelligence;software agent;ws-policy;semantic web;social semantic web;multi-agent system;semantic web stack;database;web intelligence;world wide web;owl-s;semantic analytics	Web+IR	-44.129177302189426	13.580499765152902	39592
f4ba560bf12f85df9a88ff3edd52905f04c4405a	supporting business intelligence by providing ontology-based end-user information self-service	conceptual query design;user needs;enduser development;data model;heterogeneous information;information integration;data access;middleware;enterprise system;business intelligence;system architecture;use case;ontology;business process	Business users need to analyse changing sets of information to effectively support their working tasks. Due to the complexity of enterprise systems and available tools, especially technically unskilled users face considerable challenges when trying to flexibly retrieve needed data in an ad-hoc manner. As a consequence, available data is limited to information artefacts like queries or reports which have been predefined for them by IT experts. To improve information self-service capabilities of business users, we present an ontology-based architecture and end-user tool, enabling easy data access and query creation for business users. Our approach is based on a semantic middleware integrating data from heterogeneous information systems and providing a comprehensible data model in the form of a business level ontology (BO). We show how our end-user tool Semantic Query Designer (SQD) enables convenient navigation and query building upon the BO, and illustrate its usage and the processing of data over all layers of our system architecture in detail, using a comprehensible use case example. As flexible query creation is a crucial precondition of leveraging the usage of enterprise data, we contribute to the enablement of business users of making better informed decisions, thus increasing effectiveness and efficiency of business processes.	business process;data access;data model;enterprise system;hoc (programming language);information system;middleware;precondition;semantic query;systems architecture;virtual artifact	Michael Spahn;Joachim Kleb;Stephan Grimm;Stefan Scheidl	2008		10.1145/1452567.1452577	business domain;computer science;knowledge management;artifact-centric business process model;process modeling;data mining;database;business process model and notation;enterprise architecture;business system planning;ontology-based data integration;business rule;business process modeling;business activity monitoring;enterprise information system;data architecture;enterprise information integration;business architecture	DB	-44.11535676301792	9.267521164522512	39638
e89b45bd65148fa07b80cda07bb7092293623dad	incentive compatible mechanism for trust revelation	trust;opinion based filtering;incentive compatibility;recommender agents	Most of the work on trust is build around the assumption that agents entertain beliefs or estimates of other agents’ trustworthiness. Such beliefs help agents make decisions and reason about other agents’ trustworthiness. Obtaining and maintaining trust beliefs and estimates, however, is a serious practical problem for which no satisfactory solution has been found. Trust assessment and evaluation usually runs into the following problems. First, trust learning requires long-term interaction and is usually costly for the learning agent who has to accept the risk of being abused for learning purposes. Learning costs may include information search costs, costs for obtaining additional guarantees from trusted third parties, etc. If the costs are prohibitively high, then an interaction may fail, regardless of the trustworthiness of the other party. Second, trust typically is learned gradually, but can be destroyed in an instant by misfortune or a mistake. Once trust is lost, it may be costly or it may take a long time to rebuild it. This reflects certain fundamental mechanisms of human psychology known as the asymmetry principle [6]. Third, the process of trust learning seldom produces complete and accurate estimates. Inaccurate beliefs could lead to interaction failures and inefficiencies. For example, an agent with an inaccurate estimate of his partner’s trustworthiness might decide not to participate in an interaction, even when the other party is completely trustworthy. In our previous research [1] we analyzed the impact of trust on market efficiency, and we showed that the accuracy of trust beliefs and estimates is a crucial factor for market efficiency. We proved that inaccurate trust estimates reduce	interaction design;trust (emotion);trusted third party;uncertainty principle;ws-trust	Sviatoslav Braynov;Tuomas Sandholm	2002		10.1145/544741.544814	incentive compatibility;computer science;internet privacy;trustworthy computing	AI	-43.38224006404105	16.609171851216246	39699
405299d0daf732944ce84ac7b2121162abd6652e	view-based near real-time collaborative modeling for information systems engineering		Conceptual modeling is a creative, social process that is driven by the views of involved stakeholders. However, few systems offer view-based conceptual modeling on the Web using lock-free synchronous collaborative editing mechanisms. Based on a (meta-)modeling frame- work that supports near real-time collaborative modeling and meta- modeling in the Web browser, this paper proposes an exploratory app- roach for collaboratively defining views and viewpoints on conceptual models. Viewpoints are defined on the metamodeling layer and instan- tiated as views within a model editor instance. The approach was suc- cessfully used for various conceptual modeling languages and it is based on user requirements for model-based creation and generation of next- generation community applications. An end-user evaluation showed the usefulness, usability and limitations of view-based collaborative model- ing. We expect that Web-based collaborative modeling powered by view extensions will pave the way for a new generation of collaboratively and socially engineered information systems.	information system;real-time transcription;systems engineering	Petru Nicolaescu;Mario Rosenstengel;Michael Derntl;Ralf Klamma;Matthias Jarke	2016		10.1007/978-3-319-39696-5_1	human–computer interaction;computer science;systems engineering;engineering;knowledge management;artificial intelligence;software engineering;data mining;database;world wide web	DB	-49.57293635641212	21.64059375782677	39703
6eac3bfcba800a9eb5d834271fc2a7a1a336fd9c	alignment of business models and software: using an architecture-centric method to the case of a healthcare information system		The alignment of business issues with technological service-oriented solutions has proven to be a crucial aspect of modern business development. In this regard, the provision of methods to solve the gap between business and technology becomes absolutely necessary. This paper presents a proposal to systematize that leap by defining a development method centred on the concept of Architecture. The use of different architectural models at different levels of abstraction (along with the definition of model transformations between them) allows for the establishment of a trace between the business-level elements and software elements that are derived from them. Key benefits of our proposal are, on the one hand, the provision of a method for business-technology alignment and, on the other hand, the definition of a new model to represent the structure of a business. This proposal has been refined and validated using the case of an information system for the management of paediatric percentiles.	information system;model transformation;principle of abstraction;service-oriented infrastructure	Marcos López Sanz;Valeria de Castro;Esperanza Marcos	2015			business software;information system;business activity monitoring;software construction;architecture;software;process management;business;abstraction;systems engineering;business model	SE	-57.32718809323343	18.29390719880586	39734
b4bb27fe1b074c1d3947c54c3f0aa8ffe05043b5	active models: a possible approach to the integration of objective and subjective process models	developpement logiciel;modelizacion;ingenierie connaissances;tacit knowledge;software engineering;modelisation;desarrollo logicial;software development;genie logiciel;process model;modeling;ingenieria informatica;knowledge engineering	This paper suggests that the workshop problem of managing the integration of processes based on both explicit and tacit knowledge needs to be addressed by questioning the classical software engineering paradigm. It illustrates a possible approach through a short description of the recently prototyped ArchWare system.		Brian Warboys	2005		10.1007/11608035_11	systems modeling;knowledge management;artificial intelligence;software development;knowledge engineering;process modeling	AI	-62.48735357354881	14.193967975010153	39741
b61a4d901aee3a82fd578beece5a749adab781d5	modelling languages for functional analysis put to the test of real life		ARCADIA is a system u0026 software architecture engineering method, based on architecture-centric and model-driven engineering activities. It targets systems whose architecture is largely constrained by issues such as performance, safety, security. This paper focuses on functional analysis concerns in ARCADIA, and return of real life experiments around use of existing standards such as Architecture frameworks, SysML/UML, for this purpose.	modeling language;real life	Jean-Luc Voirin	2012		10.1007/978-3-642-34404-6_9	natural language processing;computer science;algorithm	PL	-51.677884577405706	25.53219292908807	39765
6fdaa4a68ec1c5b7d9a956d3a767784b64e97ebd	a semantic web approach to request for quote in e-commerce	semantic web service;commerce electronique;ontologie;multiagent system;comercio electronico;multi agent system;normalisation;e commerce;software agent;web semantique;service web;semantics;matchmaking;intelligence artificielle;web service;agent logiciel;semantica;semantique;software agents;web semantica;normalizacion;semantic;semantic web;artificial intelligence;ontologia;inteligencia artificial;sistema multiagente;rfq;ontology;standardization;electronic trade;servicio web;systeme multiagent	It is challenge for an interoperable multi-agent system (MAS) to understand the communications among software agents. With the standardization of ontology, the semantic Web services can make the communication more flexible and automated. This paper presents an ontology-based, runtime semantic solution for solving the interacting problem between two agents. The paper demonstrates how to employ the OWL description and service ontology to a Request for Quote (RFQ) scenario, and how to develop a methodology for runtime semantics.		Wen-ying Guo;Deren Chen;Xiaolin Zheng	2006		10.1007/11610496_122	computer science;artificial intelligence;software agent;ontology;social semantic web;data mining;semantic web stack;database;semantics;world wide web;owl-s	AI	-38.90145270360248	12.748311872065795	39770
f5ef745244dd750b28b64642cbe6c7037b6d230d	intelligent techniques for configuration knowledge evolution	automated debugging;feature models;configuration	Automated testing and debugging of knowledge bases (such as configuration knowledge bases and feature models) is an important contribution to manage knowledge evolution efficiently. However, existing approaches rely on the assumption of consistent test suites which are always kept up-to-date within the scope of different knowledge base maintenance cycles. In this paper we introduce diagnosis techniques that actively guide stakeholders (knowledge engineers and domain experts) in the process of testing and debugging knowledge bases. These techniques take into account faulty test cases and constraints and recommend diagnoses which are the source of a given inconsistency.	debugging;feature model;knowledge base;knowledge engineer;test automation;test case;test suite	Alexander Felfernig;Stefan Reiterer;Martin Stettinger;Juha Tiihonen	2015		10.1145/2701319.2701320	computer science;systems engineering;knowledge management;data mining;configuration;domain knowledge	AI	-58.3655260941189	28.845814203168295	39806
c90fd85839d7de8e04abb2a3b00416078617fc87	an integer programming based approach for verification and diagnosis of workflows	verification;model error;integer programming;control flow;business process management;workflow;process model;integer program;workflow patterns;open source	Workflow analysis is indispensable to capture modeling errors in workflow designs. While several workflow analysis approaches have been defined previously, these approaches do not give precise feedback, thus making it hard for a designer to pinpoint the exact cause of modeling errors. In this paper we introduce a novel approach for analyzing and diagnosing workflows based on integer programming (IP). Each workflow model is translated into a set of IP constraints. Faulty control flow connectors can be easily detected using the approach by relaxing the corresponding constraints. We have implemented this diagnosis approach in a tool called DiagFlow which reads and diagnoses XPDL models using an existing open source IP solver as a backend. We show that the diagnosis approach is correct and illustrate it with realistic examples. Moreover, the approach is flexible and can be extended to handle a variety of new constraints, as well as to support new workflow patterns. Results of testing on large process models show that DiagFlow outperforms a state of the art tool like Woflan in terms of the solution time.	control flow;integer programming;open-source software;solver;workflow pattern;xpdl	Rik Eshuis;Akhil Kumar	2010	Data Knowl. Eng.	10.1016/j.datak.2010.03.003	workflow patterns;workflow;real-time computing;verification;integer programming;computer science;business process management;theoretical computer science;errors-in-variables models;process modeling;data mining;database;programming language;control flow;workflow management system;workflow technology	AI	-41.19912024510645	31.69071015540873	39809
0f291aae9a2c0b46a027a74ad2f4711a5eb62036	model based specification, verification, and test generation for a safety fieldbus profile	verification;model based specification;model based testing;spenat	"""This paper suggests methods, and a tool chain for model based specification, verification, and test generation for a safety fieldbus profile. The basis of this tool chain is the use of an UML profile as a specification notation, a simple high level Petri net model called """"Safe Petri Net with Attributes"""" (SPENAT) and analysis methods found in Petri net theory. The developed UML profile contains UML class diagrams and UML state machines for specification modeling. Verification and developed test generation methods are shown to be applicable after mapping the specification model onto SPENAT. The practical use of this tool chain is exemplarily demonstrated for a safety fieldbus profile."""	fieldbus	Jan Krause;Elke Hintze;Stephan Magnus;Christian Diedrich	2012		10.1007/978-3-642-33678-2_8	reliability engineering;real-time computing;model-based testing;verification;uml tool;computer science;systems engineering;engineering;software engineering;applications of uml	EDA	-44.28170974756177	31.76839340193679	39829
8f3141f41812fe3d223ab75c95d37267c62ca1c0	conformance validation between choreography and orchestration	protocols;collaborating services interoperability;formal specification;collaborative work;service orientation;engineering drawings;endpoint projection;formal language conformance validation choreography large service oriented systems specification protocol single service behavior endpoint projection orchestration generation process refinement verification collaborating services interoperability;formal languages;skeleton software engineering protocols collaborative work international collaboration web services engineering drawings joining processes proposals building services;conformance validation;large service oriented systems;formal verification conformance testing formal languages formal specification;satisfiability;software engineering;automatic generation;skeleton;orchestration generation;formal verification;conformance testing;design and implementation;single service behavior;web services;specification protocol;joining processes;building services;choreography;proposals;process refinement verification;formal language	Referring to the design and implementation of large service oriented systems, two different approaches, choreography and orchestration, need to be concerned and studied. Choreography is a specification protocol defining a global picture of the way services interact with each other. Whereas orchestration is a local view focusing on the behavior of a single service. A critical issue, the so called conformance problem, is to validate whether a specific orchestration can play as a participant whose observable behavior is required by a given choreography. In this paper, we introduce two languages for describing choreography and orchestration respectively. Based on the two languages, we give a definition of endpoint projection which is used for automatic generation of orchestrations. Therefore, conformance validation is reduced to verification of process refinement between two orchestrations. Further, we mention that not all choreography models can be locally implementable. In other words, some global models cannot be translated into sets of orchestrations satisfying the global behavioral rules. To ensure that a choreography model is locally implementable, some conditions are required to be satisfied. As a consequence of our work, the skeleton codes for service implementations can be automatically generated, on the other hand, the interoperability between collaborating services is guaranteed.	blocking (computing);business process execution language;code;communication endpoint;compiler description language;conformance testing;formal language;interoperability;observable;operational semantics;orchestration (computing);refinement (computing);scott continuity;service choreography;service-oriented architecture;simulation;specification language;verification and validation	Jing Li;Huibiao Zhu;Geguang Pu	2007	First Joint IEEE/IFIP Symposium on Theoretical Aspects of Software Engineering (TASE '07)	10.1109/TASE.2007.16	formal language;computer science;database;programming language	SE	-39.98672822939378	28.198098293369785	39834
8eb40fbd6341ff050ae2c753684d8370dbc3eb8b	accelerating the successful reuse of problem solving knowledge through the domain lifecycle	organizational learning;problem solving knowledge reuse;investments;domain lifecycle;software prototyping;application software;software development management problem solving case based reasoning software reusability;case based organizational memory repository;broad spectrum reuse;reuse repositories;inference mechanisms;formality levels;organizational memory;spectrum;product centric view;acceleration;computer aided software engineering;project experiences;software development practices;software reusability;software development;product family;software development organization;domain analysis;computer science;case based reasoning;acceleration problem solving programming computer aided software engineering computer science knowledge engineering application software software prototyping embedded software investments;software product families;broad spectrum reuse problem solving knowledge reuse domain lifecycle product centric view software development organization software product families formality levels project experiences application domain refinement case based organizational memory repository software development practices domain analysis organizational learning reuse repositories;programming;software reuse;software development management;problem solving;embedded software;application domain refinement;software design development;knowledge engineering	The inability of software reuse to reach its full potential lies partially in the product-centric way in which we view software development. Methods are needed that help us reason about product families and degrees of support that can be offered for problem domains. This paper uses a “domain lifecycle” to formalize a process in which increasing levels of formality can be provided as a domain matures. The first step in this process is to collect and disseminate project experiences that can accelerate the process of identifying and refining application domains with significant impact in a software development organization. This approach facilitates the reuse of a broad spectrum of knowledge at multiple levels of formality. Based on empirical investigations of a software development organization, a prototype of a case-based organizational memory repository for software development practices is presented and assessed for its impact on reusing software development knowledge.	adobe streamline;apache continuum;code reuse;computer-aided software engineering;design rationale;domain analysis;domain engineering;embedded system;problem domain;problem solving;prototype;software deployment;software development;software development process;spreading activation;user-centered design	Scott Henninger	1996		10.1109/ICSR.1996.496120	domain analysis;personal software process;team software process;software quality management;software engineering process group;computer science;systems engineering;knowledge management;package development process;software development;software design description;feature-oriented domain analysis;software engineering;domain engineering;software construction;software walkthrough;empirical process;goal-driven software development process;software development process	SE	-61.19106953458967	22.97076346881592	39866
24deb46b4464d933f331bdaebf855413b2eec42b	translating xml web data into ontologies	documento electronico;distributed system;web documents;xml schema;ontologie;systeme reparti;data integrity;red www;integration information;xml language;web semantique;interrogation base donnee;reseau web;service web;interrogacion base datos;semantics;web service;semantica;semantique;document electronique;information integration;semantic mapping;sistema repartido;internet;web semantica;integracion informacion;semantic web;xml document;world wide web;ontologia;ontology;database query;langage xml;lenguaje xml;electronic document;servicio web	Translating XML data into ontologies is the problem of finding an instance of an ontology, given an XML document and a specification of the relationship between the XML schema and the ontology. Previous study [8] has investigated the ad hoc approach used in XML data integration. In this paper, we consider to translate an XML web document to an instance of an OWL-DL ontology in the Semantic Web. We use the semantic mapping discovered by our prototype tool [1] for the relationship between the XML schema and the ontology. Particularly, we define the solution of the translation problem and develop an algorithm for computing a canonical solution which enables the ontology to answer queries by using data in the XML document.	adobe flash lite;algorithm;conjunctive query;exptime;hoc (programming language);nexptime;ontology (information science);prototype;semantic web;semantic mapper;web ontology language;web page;xml schema	Yuan An;John Mylopoulos	2005		10.1007/11575863_118	well-formed document;xml catalog;xml validation;xml encryption;xml base;simple api for xml;xml;relax ng;xml schema;streaming xml;computer science;document type definition;document structure description;xml framework;soap;ontology;xml database;xml schema;database;semantics;xml signature;world wide web;xml schema editor;information retrieval;efficient xml interchange	Web+IR	-36.84185387335683	11.113271588177337	39909
7726faa244d6153afd3e2483ff1c7a31a6431318	agent-oriented engineering of trust management systems		This article is concerned with the engineering of societal information systems where technical components of a system software agents support the social network around which the system is centered. By software agent, we mean an autonomous software entity that can act in the system, perceive events and reason [1]. In information systems, software agents work on behalf of their owners in order to achieve the goals set for the societal information system, such as “find a store with a minimal overall price for my shopping basket” [2]. As opposed to multiagent systems consisting of just software agents, we focus on sociotechnical systems, where each software agent is paired with it principal participating in a social network. For achieving the goals set for a sociotechnical system, agents interact and exchange knowledge. As socio-technical systems are generally large open distributed systems, the interactions may be performed between agents that are not known to each other. The agents make decisions based on information provided by other agents. Moreover, their success may depend on actions performed by other agents. The question arising here is as follows: (To what extent) should an agent representing its principal in a social network trust another agent representing another person? To answer this question, we propose to extend a socio-technical systems with a trust management subsystem. Because of the limited scope of this paper, we hereby provide an overview of a general model of a trust management subsystem using agent-oriented modeling (AOM) [1], which is an approach for developing sociotechnical systems.	agent-based model;associate-o-matic;autonomous robot;distributed computing;information system;interaction;management system;multi-agent system;social network;sociotechnical system;software agent;trust management (information system);trust management (managerial science)	Eva Zupancic;Denis Trcek;Kuldar Taveter	2012			information system;management system;software;sociotechnical system;computational trust;systems engineering;system software;software agent;multi-agent system;computer science	AI	-43.28794276891737	18.17957078177352	39927
d78c9d92defb47861cb54106297679defbee3cf1	an experimental study of computer mediated collaborative design	groupware;design automation;collaborative work;design engineering;cad;prototypes;collaboration;collaborative session;space exploration;multi user software;multi user;data coding schemes;computer networks;network technology;computer mediated collaborative design;computer aided engineering;statistical results;cmcd;collaboration collaborative work design automation computer networks space exploration australia ice prototypes object oriented modeling data models;statistical results experimental study computer mediated collaborative design network technology multi user software cmcd design semantics collaborative session data coding schemes;collaborative design;ice;object oriented modeling;australia;design semantics;data models	The use of computer technology in design practice is moving towards a distributed resource available to a team of designers. The development of software to support designers has been based largely on the assumption that there will be a single person using the software at a time. Recent developments have enabled the feasibility of software for two or more simultaneous users, leading to the possibility of computermediated collaborative design. Research in integrated CAD, virtual design studios, and design protocol studies provide the basis for a formal study of computer-mediated design. We develop an experimental study of computer-mediated collaborative design with the aim of collecting data on the amount and content of design semantics documented using computer applications when designing alone as compared to designing collaboratively. The experiment includes the definition of an hypothesis, aim, methodology, data collection and coding schemes. The experiment and some preliminary observations are presented, followed by directions for further research.	computer programming;computer-aided design;experiment	Mary Lou Maher;Anna Cicognani;Simeon J. Simoff	1996		10.1109/ENABL.1996.555233	data modeling;simulation;electronic design automation;human–computer interaction;computer science;space exploration;software engineering;cad;database;prototype;management;world wide web;collaboration	HCI	-50.04031546624056	18.933542169040095	39938
de89830194aeaee966feeb7b762722702859acd2	discovering characteristics that affect process control flow	process mining;decision analysis;chapitre d ouvrage	In flexible environments like healthcare and customer service, business processes are executed with high variability. Often, this is because cases’ characteristics vary. However, it is difficult to correlate process flow with characteristics because characteristics may refer to different perspectives, their number can be real big or even because deep domain knowledge may be required to state hypotheses. The goal of this paper is to propose an effective exploratory tool for discovering the characteristics that are causing the process variation. To this end, we propose a process mining approach. First, we apply a clustering approach based on Latent Class Analysis to identify subtypes of related cases based on the case-wise process characteristics. Then, a process model is discovered for each cluster and through a model similarity step, we are able to recommend the characteristics that mostly diversify the flow. Finally, to validate our methodology, we applied it to both simulated and real datasets.		Pavlos Delias;Daniela Grigori;Mohamed Lamine Mouhoub;Alexis Tsoukiàs	2014		10.1007/978-3-319-21536-5_5	engineering;knowledge management;data science;data mining	HCI	-53.93408148247227	17.557618342030462	40029
83688276f1b8e1cc9f953de9e648d6d1d47d97ef	salt: a spoken language interface for web-based multimodal dialog systems	design principle;user interface;software engineering;spoken language interface;object oriented;graphic user interface;user interface design;distributed computing environment	This paper describes the Speech Application Language Tags, or SALT, an emerging spoken language interface standard for multimodal or speech-only applications. A key premise in SALT design is speech-enabled user interface shares a lot of the design principles and computational requirements with the graphical user interface (GUI). As a result, it is logical to introduce into speech the object-oriented, event-driven model that is known to be flexible and powerful enough in meeting the requirements for realizing sophisticated GUIs. It is hopeful that reusing this rich infrastructure can enable dialog designers to focus more on the core user interface design issues than on the computer and software engineering details. The paper centers the discussion on the Web-based distributed computing environment and elaborates how SALT can be used to implement multimodal dialog systems. How advanced dialog effects (e.g., cross-modality reference resolution, implicit confirmation, multimedia synchronization) can be realized in SALT is also discussed.	dialog system;distributed computing environment;event-driven programming;graphical user interface;ietf language tag;modality (human–computer interaction);multimodal interaction;requirement;software engineering;speech application language tags;synchronization (computer science);user interface design;web application;world wide web	Kuansan Wang	2002			user interface design;natural language processing;user;interface description language;10-foot user interface;user experience design;interface metaphor;shell;human–computer interaction;natural language user interface;computer science;marker interface pattern;graphical user interface;interface control document;adapter pattern;natural user interface;programming language;object-oriented programming;user interface;graphical user interface testing;multiple document interface;distributed computing environment	PL	-48.13651875995604	21.340654136313248	40092
3c24e5ac422ac04ab4d1fbbcd8d69bf707e9e1ff	agentx: an environment for coordinating distributed problem solving in product development	computer program;groupware;design process;magnetic heads;axiomatic negotiation concurrent engineering agentx distributed problem solving product development parametric design process computer programs design problem solving knowledge agent operation;design problem solving knowledge;agentx;parametric design;process design;computer programs;computer architecture;cooperative systems;process control;distributed problem solving;axiomatic negotiation;problem solving product development object oriented modeling process design process control concurrent engineering algorithm design and analysis context modeling computer architecture magnetic heads;agent operation;parametric design process;context modeling;groupware concurrent engineering cooperative systems;algorithm design and analysis;object oriented modeling;concurrent engineering;problem solving;product development	This paper describes AgentX, a program that facilitates distributed problem solving in the context of a parametric design process. The “agent” in “AgentX” refers t o com,puter programs that act on behalf of people, encapsulating design problem-solving knowledge in the form of const.raints on parameters. The “X’) designates the capabilities t o coordinate design process by controlling the sequence of agent operation and resolving conflicts by axiomatic negotiation.	agent extensibility protocol;axiomatic semantics;cooperative distributed problem solving;new product development;parametric design	Jim Davis;Srikanth Kannapan	1993		10.1109/ENABL.1993.263058	process design;algorithm design;simulation;design process;computer science;process control;distributed computing;management science;context model;management;new product development;concurrent engineering	AI	-41.008485546107885	18.523984555029898	40123
cf585dc60fcaa612d97bc42988efc28890293ed2	a quagmire of terminology: verification and validation, testing, and evaluation	verification and validation	Software engineering literature presents multiple definitions for the terms verification, validation and testing. The ensuing diA~culties carry into research on the verification and validation (V&V) of intelligent systems. We explore both these areas and then address the additional terminology problems faced when attempting to carry out V&V work in a new domain such as natural language processing (NLP). at very different levels in the software development process. In one usage, the term refers to testing in the small, the exercise of program code with test cases, with a goal of uncovering faults in code by exposing failures. In another usage, the term refers to testing in the large, the entire overall process of verification, validation, and quality analysis and assurance.	data validation;natural language processing;software development process;software engineering;software testing;test case;verification and validation	Valerie Barr	2001			verification and validation;verification and validation of computer simulation models;verification and validation;verification;software verification;computer science;data mining;software testing;runtime verification;validation rule;intelligent verification;functional verification	SE	-62.69890226067471	29.943757095661027	40145
97cee337bffc8dd03786750f32c7ede9af4348d8	an enhanced graph-oriented approach for change management in distributed biomedical ontologies and linked data	graph theory;linked data;change management;ontology evolution;rule based;bio ontologies;fungal genomics;graph transformation;ontologies artificial intelligence;ontologies artificial intelligence category theory graph theory management of change medical computing;medical computing;category theory;levels of abstraction;fungal genomics bio ontologies ontology evolution category theory graph transformation;ontologies diseases high definition video knowledge based systems taxonomy lattices semantics;management of change;rule based hierarchical distributed graph transformation graph oriented approach change management distributed biomedical ontologies linked data bioontologies fungalweb ontology category theory	This paper reports the summary and results of our research on providing a graph oriented formalism to represent, analyze and validate the evolution of bio-ontologies, with emphasis on the FungalWeb Ontology. In this approach Category theory along with rule-based hierarchical distributed (HD) graph transformation have been employed to propose a more specific semantics for analyzing ontological changes and transformations between different versions of an ontology, as well as tracking the effects of a change in different levels of abstractions.	british informatics olympiad;category theory;graph rewriting;linked data;logic programming;ontology (information science);semantics (computer science)	Arash Shaban-Nejad;Volker Haarslev	2011	2011 IEEE International Conference on Bioinformatics and Biomedicine Workshops (BIBMW)	10.1109/BIBMW.2011.6112439	natural language processing;computer science;theoretical computer science;change management;linked data;data mining;category theory	Robotics	-38.347738212712244	4.633366864839328	40155
ce1edbfe030828133f57aa2b338c07ce37b85649	gin: a graphical language and tool for defining itask workflows	article in monograph or in proceedings	Workflow Management Systems (WFMSs) are software applications that coordinate business processes. The coordination is based on a workflow model, expressed in a domain-specific Workflow Description Language (WDL). WDLs are typically graphical languages because the specification has to be understandable for domain experts as well as workflow application developers. Commonly, only simple workflows can be described while additional coding is needed to turn the description into a running application. The iTask system is a combinator library, embedded in Clean, to construct WFMSs. Complex workflows can be defined declaratively from which a complete web-based application is generated. However, the textual specification is less suitable for domain experts who are used to graphical notations. In this paper we address this problem and present GiN: a graphical notation for iTask workflows, as well as a prototype implementation of a tool to construct GiN workflows interactively and graphically. The tool is fully integrated in the iTask system: it is just another iTask component, and workflows created with GiN can be subsequently added and executed dynamically as part of other workflows.		Jeroen Henrix;Marinus J. Plasmeijer;Peter Achten	2011		10.1007/978-3-642-32037-8_11	computer science;data mining;programming language;world wide web	HCI	-47.04867531869791	25.01684516998912	40215
8f35f4bb27db46004320af901a286f0fe3de4cb8	an agent-oriented approach to change propagation in software maintenance	design model;life cycle;software maintenance and evolution;software maintenance;belief desire intention;software systems;agent oriented software engineering;unified modelling language uml;bdi agents;era2015;change propagation;object constraint language	Software maintenance and evolution is a lengthy and expensive phase in the life cycle of a software system. In this paper we focus on the change propagation problem: given a primary change that is made in order to meet a new or changed requirement, what additional, secondary, changes are needed? We propose a novel, agent-oriented, approach that works by repairing violations of desired consistency rules in a design model. Such consistency constraints are specified using the Object Constraint Language (OCL) and the Unified Modelling Language (UML) metamodel, which form the key inputs to our change propagation framework. The underlying change propagation mechanism of our framework is based on the well-known Belief-Desire-Intention (BDI) agent architecture. Our approach represents change options for repairing inconsistencies using event-triggered plans, as is done in BDI agent platforms. This naturally reflects the cascading nature of change propagation, where each change (primary or secondary) can require further changes to be made. We also propose a new method for generating repair plans from OCL consistency constraints. Furthermore, a given inconsistency will typically have a number of repair plans that could be used to restore consistency, and we propose a mechanism for semi-automatically selecting between alternative repair plans. This mechanism, which is based on a notion of cost, takes into account cascades (where fixing the violation of a constraint breaks another constraint), and synergies between constraints (where fixing the violation of a constraint also fixes another violated constraint). Finally, we report on an evaluation of the approach, covering effectiveness, efficiency and scalability.	agent architecture;algorithm;belief–desire–intention software model;clisp;central processing unit;conditional (computer programming);cost per action;design tool;device driver;disk staging;emoticon;eventual consistency;executable;expect;experiment;gnu;heuristic;intelligent agent;iteration;java;lazy evaluation;loss function;metamodeling;microsoft windows;object constraint language;prometheus;prototype;random-access memory;run time (program lifecycle phase);scalability;semiconductor industry;software maintenance;software propagation;software system;synergy;uml tool;unified modeling language;usability;whole earth 'lectronic link;xojo	Khanh Hoa Dam;Michael Winikoff	2010	Autonomous Agents and Multi-Agent Systems	10.1007/s10458-010-9163-0	biological life cycle;computer science;artificial intelligence;software maintenance;object constraint language;software system	AI	-54.83848876529231	29.13098319126187	40219
8f0d03cb64478e3436bb1d29a762d022871d1fa9	modeling role-based agent team	plan;role;distributed environment;agent teamwork	The problem of ensuring agents work as an effective team in dynamic distributed environments still remains a challenging issue. In this paper we proposed a role-based team model. In our model, the role characterizes the responsibilities and provides logic patterns to achieve certain goals and cooperate with others. The agent is an autonomous execution unit and follows the logic patterns that the role provides. We also developed algorithms and mechanisms to evolve the plan of a role to the plan of an agent. Our role-based team model allows the split of roles (who define the plans) and agents (who execute the plans) in team plans, and dynamic role-agent assignment. It also achieves a certain level of plan reusability. We present two experiments which show plan reusability and its flexibility in supporting simultaneously plan invocation.	algorithm;autonomous robot;execution unit;experiment;high- and low-level;mental state	Yu Zhang	2007		10.1007/978-3-540-72665-4_1	simulation;computer science;knowledge management;role;plan;distributed computing environment	AI	-42.464852931850814	19.401245537038967	40275
28d97abf728a230041446644203a60e1472cad1f	increasing the expressive power of task analysis: systematic comparison and empirical assessment of tool-supported task models	design process;empirical assessment;task models;tool support;tool supported task modelling;task model;software engineering;expressive power;interactive system;task analysis;task modelling	Task analysis is a critical step in the design process of interactive systems. The large set of task models available today may lead to the assumption that this step is well supported. However, very few task models are tool-supported. And in this latter category, few of them are based on a clear semantics (in this article, the word semantics is used with the following definition: ‘‘the meaning of a word, phrase, sentence, or text’’ from Compact Oxford English Dictionary ). This paper focuses on tool-supported task models and provides an assessment of the features that have been considered as essential in task modelling. It compares the different tool-supported methods, and evaluates the actual use of these features in KMADe, a tool aimed at contributing to the incorporation of ergonomics into the design process of interactive systems through activity and task analysis. The originality of the K-MADe tool is to be based on a model whose expressive power lies on computable syntax while trying to be usable by every modelling knowledge designer. This facilitates task description and analysis, but also model query and the migration within software engineering models and software lifecycle steps. Evaluation results demonstrate the usefulness of an increased expressive power for task models, and their acceptance by users. They also enlighten some weaknesses in the K-MAD method and suggest further improvements. 2010 Elsevier B.V. All rights reserved.		Sybille Caffiau;Dominique L. Scapin;Patrick Girard;Mickaël Baron;Francis Jambon	2010	Interacting with Computers	10.1016/j.intcom.2010.06.003	natural language processing;simulation;design process;computer science;artificial intelligence;software engineering;function;task analysis;programming language;expressive power	SE	-55.308134118525075	24.05305629898072	40280
1b2f8d6ea56b04b047533a6f2ada9b1d5de7ea58	the ontolingua server: a tool for collaborative ontology construction	information integration;world wide web;ontology construction;geographic distribution;knowledge base	Reusable ontologies are becoming increasingly important for tasks such as information integration, knowledge-level interoperation, and knowledgebase development. We have developed a set of tools and services to support the process of achieving consensus on common shared ontologies by geographically distributed groups. These tools make use of the worldwide web to enable wide access and provide users with the ability to publish, browse, create, and edit ontologies stored on an ontology server. Users can quickly assemble a new ontology from a library of modules. We discuss how our system was constructed, how it exploits existing protocols and browsing tools, and our experience supporting hundreds of users. We describe applications using our tools to achieve consensus on ontologies and to integrate information. The Ontolingua Server may be accessed through the URL http://ontolingua.stanford.edu/	amortized analysis;browsing;consensus (computer science);exploit (computer security);human-readable medium;hypertext;input/output;interoperation;knowledge base;mathematical model;ontology (information science);referential integrity;refinement (computing);semantics (computer science);server (computing);software agent;uptime;virtual community;web application;world wide web	Adam Farquhar;Richard Fikes;James Rice	1997	Int. J. Hum.-Comput. Stud.	10.1006/ijhc.1996.0121	knowledge base;computer science;artificial intelligence;information integration;data mining;database;world wide web	Web+IR	-41.71719220982484	9.969706911915416	40297
82c5509d158619ef78b008b1762d009854ac7047	model independent assertions for integration of heterogeneous schemas	distributed database;conceptual modeling;heterogeneous databases;conceptual model;schema integration;distributed databases;interoperability;database design and integration;database design;federated databases	Due to the proliferation of database applications, the integration of existing databases into a distributed or federated system is one of the major challenges in responding to enterprises' information requirements. Some proposed integration techniques aim at providing database administrators (DBAs) with a view definition language they can use to build the desired integrated schema. These techniques leave to the DBA the responsibility of appropriately restructuring schema elements from existing local schemas and of solving inter-schema conflicts. This paper investigates theassertion-based approach, in which the DBA's action is limited to pointing out corresponding elements in the schemas and to defining the nature of the correspondence in between. This methodology is capable of: ensuring better integration by taking into account additional semantic information (assertions about links); automatically solving structural conflicts; building the integrated schema without requiring conforming of initial schemas; applying integration rules to a variety of data models; and performing view as well as database integration. This paper presents the basic ideas underlying our approach and focuses on resolution of structural conflicts.	conformity;data model;database schema;federation (information technology);heterogeneous system architecture;heterogeneous database system;norm (social);requirement	Stefano Spaccapietra;Christine Parent;Yann Dupont	1992	The VLDB Journal	10.1007/BF01228708	idef1x;schema migration;database theory;semi-structured model;computer science;knowledge management;three schema approach;conceptual schema;conceptual model;data mining;database;database schema;distributed database;database testing	DB	-34.0965352610158	11.444957902410103	40359
0a5b1a77a1f1a5f370c4c1f89b1051973739ae95	research on dynamic reconfigurable manufacturing process model based on model driven architecture	analytical models;manufacturing systems;manufacturing systems manufacturing processes;dynamic reconfiguration;model driven architecture mda;integrable system;manufacturing process model;dynamic reconfigurable manufacturing process;platform specific model psm;information integration;manufacturing processes;model driven architecture methodology;platform independent model pim;manufacturing system functionality specification;manufacturing processes manufacturing systems virtual manufacturing pulp manufacturing mass production computer aided manufacturing mass customization production systems delay management information systems;solid modeling;unified modeling language;manufacturing enterprises;platform specific model;enterprise modeling;manufacturing system functionality specification dynamic reconfigurable manufacturing process model driven architecture methodology manufacturing enterprises information integration;platform independent model;process model;manufacturing system;platform specific model psm dynamic reconfiguration manufacturing process model model driven architecture mda platform independent model pim;model driven architecture	With the characteristic analysis of manufacturing process in various manufacture enterprises, Model Driven Architecture methodology is applied to construct dynamic reconfiguration manufacturing process model, which can solve the problems of portability, information integration, and interoperability effectively. A dynamic reconfigurable modeling process framework based on model driven Architecture is introduced for manufacture enterprises in this paper. It separates the manufacturing system functionality specification from its implementation on any specific technology platform, and makes the system reconfigurate the manufacturing progress through the transformation of models and transmission of information. Based on MDA methodology, a PIM was built with UML for dynamic reconfiguration manufacturing process model. Then, the PIM was transformed into several indispensable PSMs. At last, the integrated system was applied to a discreet manufacturing process and the application result proves that the system is practical and effective.	discrete manufacturing;interoperability;model-driven architecture;process modeling;unified modeling language	Hailong Huang;Fei Liu;Qifeng Wang	2009	2009 WRI World Congress on Computer Science and Information Engineering	10.1109/CSIE.2009.755	manufacturing execution system;unified modeling language;integrable system;integrated computer-aided manufacturing;enterprise modelling;computer science;information integration;process modeling;computer-integrated manufacturing;solid modeling	Robotics	-56.38004140634295	15.838260268045989	40375
846a6a77423e13fb8843ff7701c62c23312a324e	prover: an smt-based approach for process verification		Business processes are used to represent the enterprise’s business and services it delivers. They are also used as a means to enforce customer’s satisfaction and to create an added value to the company. It is then more than critical to seriously consider the design of such processes and to make sure that they are free of any kind of inconsistencies. This paper highlights the issues with current approaches for process verification and proposes a new approach called ProVer. Three important design decisions will be motivated: 1) the use of UML AD as a process modeling language, 2) the formalization of the UML AD concepts for process verification as well as a well-identified set of properties in first-order logic (FOL) and 3) the use of SMT (Satisfiability Modulo Theories) as a mean to verify properties spanning different process’s perspectives in a very optimal way. The originality of ProVer is the ability for non-experts to express properties on processes than span the control, data, time, and resource perspectives using the same tool.	algorithm;dataflow;eclipse modeling framework;experiment;file spanning;first-order logic;first-order predicate;model checking;modulo operation;process modeling;satisfiability modulo theories;semantics (computer science);simultaneous multithreading;solver;unified modeling language;usability	Souheib Baarir;Reda Bendraou;Hakan Metin;Yoann Laurent	2018				Logic	-42.53390393076083	30.16387988437131	40389
1bdb4d2cc869e22acc4dba64708c0e9a173106a0	a simulator for uavs management in agriculture domain		Drones or Unmanned Aerial Vehicles (UAVs) receive a growing interest for agricultural purposes. The aim is to provide inspiring insights in this domain from a technological and computational point of view. In these last years, indeed, there is an enormous potential that UAV technologies presents to support the agricultural domain in monitoring the land for checking and countering the presence of parasites that can damage the crop. However, to properly manage a UAVs team, equipped with multiple sensors and actuators, it is necessary to test these technologies and design proper strategies and coordination techniques able to efficiently manage the team. At this purpose, the paper proposes a simulator suitable for the agriculture domain in order to design novel coordination and control techniques of a UAVs team. Moreover it is possible to define the main variables and parameters of this domain of interest. The work presented many coordination techniques both for monitoring the area and both for coordinating the actions of the drones in the presence of parasites in order to analyze how the performance can significantly change if more constraints, such as energy, communication range, resource capacities, are accounted.	as-interface;algorithm;computation;distributed web crawling;link-state routing protocol;sensor;simulation;unmanned aerial vehicle	Floriano De Rango;Nunzia Palmieri;Amilcare F. Santamaria;Giuseppe Potrino	2017	2017 International Symposium on Performance Evaluation of Computer and Telecommunication Systems (SPECTS)	10.23919/SPECTS.2017.8046780	simulation;wireless sensor network;computer science;agriculture	EDA	-34.11884491146921	20.892049689798633	40438
2229496d78e17e7d741e17029b90de093e304c5c	an approach for composing web services on demand	service composition;collaborative work;constraint optimization;design engineering;web and internet services;qos constraints;soa;web service;satisfiability;web service composition;service oriented architecture web service composition sla qos constraints description language process oriented composition language business process service grid system;sla;business data processing;web services;merging;user requirements;semantic web;process oriented composition language;service grid system;service discovery;quality of service;service oriented architecture;grid system;business process;web service service composition soa;web services service oriented architecture quality of service collaborative work semantic web constraint optimization educational institutions design engineering web and internet services merging;web services business data processing;description language	The Web services composition plays a more and more important role in SOA environment nowadays. Composing Web services on user's demand proves to be essential for both B2B and B2C applications. However, existing composition approaches and services composition description languages, such as BPEL4WS, are insufficient for satisfying user requirements. In this paper, we present an approach for Web services composition on demand. Our approach defines a description language for describing user's demand and supporting dynamic services binding for flexible service composition, and applies SLA to service discovery that can automatically adapt the change of QoS constraints. The description language can be applied to any process-oriented composition language that supports executable business processes. Finally, our approach is applied to a service grid system where it provides a fully automatic, stable service composition on user's demand	b2b e-commerce;business process execution language;executable;interface description language;login;quality of service;requirement;rewrite (programming);service composability principle;service discovery;service-level agreement;service-oriented architecture;service-oriented modeling;user requirements document;web service;world wide web	Tiezheng Nie;Ge Yu;Derong Shen;Yue Kou;Jie Song	2006	2006 10th International Conference on Computer Supported Cooperative Work in Design	10.1109/CSCWD.2006.253170	web service;constrained optimization;business process execution language;computer science;knowledge management;ws-policy;service-oriented architecture;database;services computing;ws-i basic profile;law;world wide web;universal description discovery and integration	SE	-46.83324824955782	16.62076546710995	40609
31ba8fceb95a90ea4b11eb759c6e5425f747348a	expanding the envelope of the object oriented approach	3d animation;programming environments;object oriented methods;behavior modeling;soft computing;continuous variable;squeak language object oriented approach information system modeling fuzzy object and behavior modeling fobm technique soft computing technique complexity handling noisy environment incomplete environment vague environment 3d animation robotics intelligent autonomous agent message broadcasting event broadcasting weighing attenuation continuous message emitters sensors degrees of membership presence relationship variable object tolerant environment fobm framework;object oriented programming;smalltalk object oriented programming object oriented methods fuzzy logic programming environments message passing software agents computer animation;software agents;fuzzy logic;autonomous agent;object oriented modeling intelligent robots intelligent sensors information systems fuzzy systems working environment noise animation robot sensing systems intelligent agent autonomous agents;object oriented approach;smalltalk;message passing;information system;computer animation	In this paper we will discuss a new approach to modeling information systems, namely Fuzzy Object and Behavior Modeling (FOBM) technique. FOBM is a fusion of the object-oriented approach with soft computing techniques. It is especially useful for dealing with increased complexity and noisy, incomplete and vague environments and mainly target areas such as 3D animation, robotics and intelligent autonomous agents. FOBM introduces many new concepts and integrates and enhances some existing ones. Concepts highlighted in this paper include message and event broadcasting, weighing and attenuation, continuous messages with emitters and sensors, degrees of membership, presence and relationships, continuously variable objects, and tolerant environments. Some of these concepts are demonstrated using a simple FOBM framework implemented in Squeak.	autonomous robot;computer animation;information system;robotics;sensor;soft computing;squeak;vagueness	Mehmet Tansel Ersavas	2003	First Conference on Creating, Connecting and Collaborating Through Computing, 2003. C5 2003. Proceedings.	10.1109/C5.2003.1222333	real-time computing;simulation;computer science;artificial intelligence;distributed computing;computer animation;soft computing	Robotics	-36.737526572165315	21.501919577720013	40620
8e648abc9db274c8d8b433a7f89d1b7fc17c573c	tavant system architecture for sell-side channel management	system architecture			Srinivasa Narayanan;Iyer N. Subramanian	2001			multilayered architecture;enterprise architecture framework;reference architecture;computer science;applications architecture;solution architecture;distributed system security architecture;data architecture;systems architecture	Robotics	-56.81542045489674	16.106086942964204	40635
08eaa20ab5802fd152ef5f801c16b8cc0991b080	un cadre de conception pour réunir les modèles d'interaction et l'ingénierie des interfaces	developpement logiciel;modelizacion;interaction architecture;patron conception;architectural design;human computer interaction;reutilizacion;relacion hombre maquina;logicial personalizado;patron concepcion;design models;man machine relation;software development process;development methods;reuse;intergiciel;modelisation;software architecture;metamodel;metamodele;metamodelo;desarrollo logicial;design pattern;software development;interaction engineering;conteneur;interaction models;architecture basee modele;middleware;interaction paradigm;concepcion arquitectural;relation homme machine;information system;software design pattern;software design;contenedor;conception architecturale;modeling;model driven architecture;systeme information;architecture logiciel;reutilisation;container;arquitectura basada modelo;sistema informacion	We present HIC (Human-system Interaction Container), a general framework for the integration of advanced interaction in the software development process. We show how this framework allows to reconcile the software development methods (such MDA, MDE) with the architectural models of software design such as MVC or PAC. We illustrate our approach thanks to two different types of implementation for this concept in two different business areas: one software design pattern, MVIC® (Model View Interaction Control) and one architectural model, IM (Interaction Middleware).	bibliothèque des ecoles françaises d'athènes et de rome;middleware;model-driven engineering;model–view–controller;software design pattern;software development process	Jérôme Lard;Frédéric Landragin;Olivier Grisvard;David Faure	2007	Ingénierie des Systèmes d'Information	10.3166/isi.12.6.67-91	metamodeling;software architecture;software design pattern;simulation;systems modeling;computer science;artificial intelligence;software design;software development;middleware;reuse;design pattern;container;software development process;information system	SE	-46.541532269137605	23.00413910103292	40687
4c4168aa927016f23fd3b926d8323ab0a6ceb990	disk capacity assessment program planning of the dasd resource				Bill Lulofs	1985			systems engineering;computer science	AI	-61.4787710713107	7.402561549569065	40741
a273adf436a5fb7106d4e906eed2659a33d87d65	ieee access special section editorial: advances in vehicular clouds		Connected vehicles are seen as the next frontier for the mobile revolution. By bringing Internet connectivity to vehicles, not only infotainment of the vehicles can be enriched, but also safety and driving experience of the drivers can be enhanced. Connected vehicles can access real-time information about traffic conditions to make the journey more time efficient. They can also share local traffic information in real-time to assist other vehicles making better route planning. Consolidating various transportation data from individual vehicles and other transportation infrastructure can further enhance Intelligent Transportation System (ITS).		Chuan Heng Foh;Burak Kantarci;Periklis Chatzimisios;Jinsong Wu;Deyun Gao	2016	IEEE Access	10.1109/ACCESS.2017.2652283	telecommunications	Visualization	-34.331259782759155	19.677376230480753	40745
de1092053864499927b46aa0c383c163f48250c1	using physical quantities in robot software models		One of the challenges of modeling any software application that deals with real-world physical systems resides in the correct representation of numerical values and their units. This paper shows how both measurement uncertainty and units can be effectively incorporated into software models, becoming part of their basic type systems, and illustrates this approach in the particular case of a robot language. We show how our approach allows robot modelers to safely represent and manipulate units and measurement uncertainties of the robots and their elements in a natural manner, statically ensuring unit-safe assignments and operations, as well as the propagation of uncertainty in the computations of derived attributes and operations.		Loli Burgueño;Tanja Mayerhofer;Manuel Wimmer;Antonio Vallecillo	2018	2018 IEEE/ACM 1st International Workshop on Robotics Software Engineering (RoSE)	10.1145/3196558.3196562	unified modeling language;cyber-physical system;control engineering;model-driven architecture;propagation of uncertainty;software;robot kinematics;computer science;robotics;artificial intelligence;robot software	SE	-45.15330432448853	24.236103741164094	40749
d12b51417429fef0cbc0912a88fca694da6315a1	specification and synthesis of communicating finite state machines.	communicating finite state machine			H. Belhadj;Laurent Gerbaux;Marie-Claude Bertrand;Gabriele Saucier	1992			control engineering;discrete mathematics;theoretical computer science;virtual finite-state machine	EDA	-34.92146042364675	30.553332527310097	40798
313050bdae89e1bb4482615cf13efbdeda80f23a	discrete-event simulation of queues with spreadsheets: a teaching case	parallel server;teaching case;discrete-event simulation;subsequent statistical analysis;one-semester course;management science;single server;industrial engineer;simulation run;simple vba code;different case;queueing theory;teaching;discrete event simulation;queuing system;queuing theory;computer science education;statistical analysis;industrial engineering	This paper describes the use of spreadsheets combined with simple VBA code as a tool for teaching queuing theory and discrete-event simulation. Four different cases are considered: single server, parallel servers, tandem queuing, and closed queuing system. The data obtained in the simulation run are conveniently stored in spreadsheets for subsequent statistical analysis. This approach was successfully deployed in a second one-semester course on management science for industrial engineers undergraduate students.	management science;queueing theory;server (computing);simulation;spreadsheet;tandem computers;visual basic for applications	Marco Aurélio de Mesquita;Alvaro Euzebio Hernandez	2006	Proceedings of the 2006 Winter Simulation Conference		education;simulation;computer science;theoretical computer science;queueing theory;statistics	HPC	-56.26403635744326	7.45057037776796	40821
18b9fb45b9a2fde3c8b932d4ff96953f2bf6fde6	the owl-s editor – a development tool for semantic web services	semantic web service;distributed system;ontologie;systeme reparti;plugicial;web semantique;distributed computing;service web;web service;development tool;sistema repartido;lenguaje descripcion;internet;web semantica;logiciel libre;algorithme reparti;semantic web;calculo repartido;software libre;ontologia;algoritmo repartido;plugiciel;intranet;plug in software;distributed algorithm;ontology;calcul reparti;langage description;servicio web;open source software;description language	Semantic Web Services (SWSs) promise to provide solutions to the challenges associated with automated discovery, dynamic composition, enactment, and other tasks associated with managing and using service-based systems. One of the barriers to a wider adoption of SWS technology is the lack of tools for creating SWS specifications. OWL-S is one of the major SWS description languages. This paper presents an OWL-S Editor, whose objective is to allow easy, intuitive OWL-S service development and to provide a variety of special-purpose capabilities to facilitate SWS design. The editor is implemented as a plugin to the Protégé OWL ontology editor, and is being developed as open-source software.	owl-s;ontology (information science);open-source software;protégé;semantic web service;sinewave synthesis;web ontology language	Daniel Elenius;Grit Denker;David L. Martin;Fred Gilham;John Khouri;Shahin Saadati;Rukman Senanayake	2005		10.1007/11431053_6	web service;distributed algorithm;the internet;computer science;operating system;semantic web;ontology;database;distributed computing;world wide web;owl-s	HCI	-40.75683347293761	23.674737631611432	40839
2b3dbc50dd5a424e3d4d02fdc645267c5d55098a	applying use cases to design versus validate class diagrams - a controlled experiment using a professional modelling tool	class diagram;software quality object oriented methods formal specification program verification software tools diagrams;object oriented methods;formal specification;computer aided software engineering object oriented modeling unified modeling language process design laboratories pattern analysis collaboration cyclic redundancy check inspection software systems;object oriented design;use cases;controlled experiment;diagrams;program verification;development process;controlledexperiment;empirical validation;software tools;functional requirement;use case driven process class diagram validation class diagram design controlled experiment professional modeling tool functional requirements object oriented design empirical validation development process responsibility driven process use case model tau uml suite;use case;software quality;modeling tool	Several processes have been proposed for the transition from functional requirements to an object-oriented design, but these processes have been subject to little empirical validation. A use case driven development process is often recommended when applying UML. Nevertheless, it has been reported that this process leads to problems, such as the developers missing some requirements and mistaking requirements for design. This paper describes a controlled experiment, width 53 students as subjects, conducted to investigate two alternative processes for applying a use case model in an object-oriented design process. One process was use case driven, while the other was a responsibility-driven process in which the use case model was applied as a means of validating the resulting class diagram. Half of the subjects used the modeling tool Tau UML Suite from Telelogic; the other half used pen and paper. The results show that the validation process led to class diagrams implementing more of the requirements. The use case driven process did, however, result in class diagrams with a better structure. The results also show that those who used the modeling tool spent more time on constructing class diagrams than did those who used pen and paper. We experienced that it requires much more effort to organize an experiment with a professional modeling tool than with only pen and paper.	diagram	Bente Anda;Dag I. K. Sjøberg	2003		10.1109/ISESE.2003.1237964	reliability engineering;computer science;systems engineering;software engineering	HCI	-58.60876868394458	29.76442901172038	40871
62dbaf213ebc590766d7aa042622ce29b40ff5e0	evaluating agent architectures: cougaar, aglets and aaa	new technology;general and miscellaneous mathematics computing and information science;software agent;software systems;computer networks;computer architecture;performance software agents;research and development;architecture evaluation;agent technology;next generation;evaluation;agent architecture;network computing;competitive advantage;pacific northwest	Research and development organizations are constantly evaluating new technologies in order to implement the next generation of advanced appli- cations. At Pacific Northwest National Laboratory, agent technologies are per- ceived as an approach that can provide a competitive advantage in the construc- tion of highly sophisticated software systems in a range of application areas. To determine the sophistication, utility, performance, and other critical aspects of such systems, a project was instigated to evaluate three candidate agent toolkits. This paper reports on the outcomes of this evaluation, the knowledge accumu- lated from carrying out this project, and provides insights into the capabilities of the agent technologies evaluated.	aaa (video game industry);aglets;cougaar	Ian Gorton;Jereme Haack;David McGee;Andrew J. Cowell;Olga A. Kuchar;Judi Thomson	2003		10.1007/978-3-540-24625-1_15	simulation;systems engineering;engineering;software engineering	Vision	-59.056521027179656	5.097846552873489	40917
6cb6af020d97798d61602a895fde32d6de7841a3	a study of artifact creation and use in collaborative object-oriented software design	uml;object oriented software;software design;collaborative design	Many tools for object-oriented software design focus on assisting individuals in creating UML models for documentation and implementation purposes. Since software design is a highly collaborative activity, one must ask whether the requirements for facilitating collaborative design are similar.We report on a study of design teams, focusing on their use of notations and artifacts. Our findings highlight the unique characteristic of the use of UML in these settings and emphasize the importance of context and relations between artifacts over the details of specific artifacts.	artifact (software development);documentation;requirement;software design;unified modeling language	Uri Dekel	2006		10.1145/1176617.1176706	unified modeling language;human–computer interaction;uml tool;computer science;software design;software design description;object-oriented design;applications of uml;software construction;node;goal-driven software development process	HCI	-53.719782324911684	24.771729737361216	41060
f7b4d207e72c882a4be150026c502009fd027641	organizing web services to develop dynamic, flexible, distributed systems	distributed system;electronic contracts;service orientation;feature modeling;web service;model driven development;requirement engineering;web services;quality of service;price	Web services are increasingly behaving as nodes in a digital, dynamic ecosystem. On the one hand, this new situation requires flexible, spontaneous and opportunistic collaboration activities to be identified and established among (business) parties. On the other hand, it also requires engineering approaches able to integrate new functionalities and behaviors into running systems and active, distributed, interdependent processes. In this paper we present a multi-level architecture, combining organizational and coordination theories with model driven development, for the implementation, deployment and management of dynamic, flexible and robust service-oriented business applications.	cyber-security regulation;distributed computing;ecosystem;interdependence;model-driven engineering;select (sql);service-orientation;service-oriented architecture;service-oriented infrastructure;software deployment;sourceforge;spontaneous order;web service	Frank Dignum	2009		10.1145/1806338.1806342	web service;web modeling;simulation;engineering;operations management;services computing;world wide web	SE	-51.124842472476246	15.497634567486742	41082
493ecf852cfebe5b9ed90dcf16b1b77ab297437a	mining components for a software architecture and a product line: the options analysis for reengineering (oar) method	product line;software architecture;software component;software product line;legacy system;reengineering;software architectures;software product lines;reverse engineering	This tutorial discusses the problem of identifying candidate software components from legacy systems and determining their reuse potential for insertion in a new architecture, particularly in a software product line architecture. The tutorial outlines Options Analysis for Reengineering (OAR), which is a systematic method for evaluating the feasibility and benefits of mining existing components for a product line. OAR operates like a funnel in which a set of potential assets is screened out so that the effort can focus on those components that will most effectively meet the technical and programmatic needs of the target architecture. The method incorporates a set of scalable techniques and exercises to collaboratively analyze existing components, determine viable mining options, and evaluate the most promising options. It provides a structured approach to determine the cost, effort, and risk of mining a set of software components from legacy systems.	code refactoring;component-based software engineering;legacy system;opensimulator;projection screen;scalability;software architecture;software product line	Dennis B. Smith;Liam O'Brien;John Bergey	2001			functional software architecture;reliability engineering;reference architecture;software architecture;reusability;architecture tradeoff analysis method;verification and validation;software sizing;business process reengineering;computer science;systems engineering;engineering;package development process;software framework;component-based software engineering;software development;software design description;operating system;software engineering;software construction;hardware architecture;software architecture description;resource-oriented architecture;software deployment;legacy system;reverse engineering;software system;software peer review	SE	-61.27609491797215	26.158186751260523	41096
017e30a2b60a22556409ac102785c5f9ab5c83ab	a performance and usability comparison of automated planners for it change planning	databases;automated planning;information technology infrastructure library;object oriented model;temporal logic configuration management database management systems management of change planning artificial intelligence;change management;database management systems;temporal logic;resource manager;resource management;hierarchical task network;planning artificial intelligence;satisfiability;infrastructure as a service;planning resource management databases object oriented modeling usability;management of change;planning;usability;configuration management;object oriented modeling;temporal logic performance comparison usability comparison automated planners it change planning change management information technology infrastructure library itil business goals planning algorithms automated planning algorithm infrastructure as a service deployment case study three tier business application configuration management databases cmdb planning domain hierarchical task network algorithms search control	Change Management, a core process of the Information Technology Infrastructure Library (ITIL), is concerned with the management of changes to networks and services to satisfy business goals and to minimize costly disruptions on the business. As part of Change Management, IT changes need to be planned for. Despite previous efforts to use planning algorithms to generate IT change plans, it remains unknown as to which automated planning algorithm does best solve the IT change planning problem. To answer this question, we compare four domain independent automated planners in the context of an Infrastructure as a Service deployment case study of a three-tier business application. We focus on two aspects: (1) The scalability of the planners to large Configuration Management Databases (CMDBs) comprising thousands of resources and (2) their usability by a change manager, in particular how easily a change manager can specify the planning domain and rules to guide the search. For the deployment case study we conclude that Hierarchical Task Network algorithms scale to significantly larger CMDBs than all other examined algorithms. Furthermore, we find that their way to formalize search control naturally matches to the domain of IT change planning compared to that of others who require change managers to have a profound knowledge of the planning algorithm or temporal logic.	algorithm;approximation algorithm;automated planning and scheduling;business software;cloud computing;computer performance;configuration management;data center;database;debugging;experiment;forward chaining;graph (discrete mathematics);hierarchical task network;itil;linear temporal logic;multitier architecture;planner;precondition;prodigy;refinement (computing);scalability;software deployment;temporal logic;usability	Sebastian Hagen;Alfons Kemper	2011	2011 7th International Conference on Network and Service Management		planning;change control;information technology infrastructure library;usability;temporal logic;computer science;knowledge management;resource management;change management;change management;management science;configuration management;management;hierarchical task network;satisfiability	SE	-54.54248681495693	19.36950743728748	41142
dc23a0db3cd3f06b338e15f6191789278362f4a0	stcml: an extensible xml-based language for socio-technical modeling	socio technical congruence;modeling languages;software engineering;modeling language;software development;language design	Understanding the complex dependencies between the technical artifacts of software engineering and the social processes involved in their development has the potential to improve the processes we use to engineer software as well as the eventual quality of the systems we produce. A foundational capability in grounding this study of socio-technical concerns is the ability to explicitly model technical and social artifacts as well as the dependencies between them. This paper presents the STCML language, intended to support the modeling of core socio-technical aspects in software development in a highly extensible fashion. We present the basic structure of the language, discuss important language design principles, and offer an example of its application.	sociotechnical system;software development;software engineering;xml	John C. Georgas;Anita Sarma	2011		10.1145/1984642.1984657	natural language processing;model-driven architecture;verification and validation;systems modeling language;computer science;systems engineering;engineering;package development process;software design;social software engineering;software development;software engineering;software construction;software technical review;modeling language;software walkthrough;programming language;goal-driven software development process;software development process	SE	-52.62575130483935	25.475434026992776	41169
b4530c955118ce482de84c205f2b1818dde78a03	managing adaptive pervasive computing using knowledge-based service integration and rule-based behavior	semantic web service;service composition;service provider;service orientation;pervasive computing;rule based;state observer;resource manager;non controlled indexing;automated reasoning;semantic web ubiquitous computing computer network management knowledge based systems telecommunication services;resource use;input output;collective behavior;conference paper;policy based management adaptive pervasive computing computer network management knowledge based service integration rule based behavior interoperability knowledge service oriented techniques ontology based semantics semantic web services dynamic adaptivity knowledge based service composition;access control policy;policy based management;computer network management;semantic web;telecommunication services;event condition action;ubiquitous computing;description logic;dynamic adaptation;service integration;knowledge based systems;knowledge management pervasive computing ontologies context aware services computer architecture context modeling resource management runtime merging centralized control;knowledge base	The commonly articulated vision of pervasive computing represents a huge increase in the number of independently developed components that must interoperate and in the level of autonomy they must demonstrate. This motivates a shift to exchanging interoperability knowledge between components at runtime coupled with the ability of components to adapt themselves dynamically to the requirements of users moving between spaces and tasks. The confluence of the service-oriented techniques and ontology-based semantics, as semantic Web services, offers such dynamic adaptivity through knowledge-based service composition. We aim to establish a conceptual architecture for pervasive computing that integrates semantic service composition and policy-based management in providing a collective behavior that adapts to the user's changing needs, but which conforms to the goals of those responsible for the resources used by those services.	confluence;interoperability;logic programming;requirement;run time (program lifecycle phase);semantic web service;service composability principle;service-oriented device architecture;ubiquitous computing	David Lewis;Owen Conlan;Declan O'Sullivan;Vincent P. Wade	2004	2004 IEEE/IFIP Network Operations and Management Symposium (IEEE Cat. No.04CH37507)	10.1109/NOMS.2004.1317790	service provider;input/output;description logic;context-aware pervasive systems;computer science;knowledge management;telecommunications service;semantic web;collective behavior;database;automated reasoning;state observer;world wide web;ubiquitous computing	SE	-43.966984561130744	14.95797035108321	41277
282d4ab670bca80fa97515b82b3399c597cd5a22	semantic representation of cloud patterns and services with automated reasoning to support cloud application portability	cloud portability cloud computing cloud patterns cloud service discovery cloud service composition cloud interoperability;cloud computing semantics ontologies home appliances cognition interoperability	During the past years the Cloud Computing offer has exponentially grown, with new Cloud providers, platforms and services being introduced in the IT market. The extreme variety of services, often providing non uniform and incompatible interfaces, makes it hard for customers to decide how to develop, or even worse to migrate, their own application into the Cloud. This situation can only get worse when customers want to exploit services from different providers, because of the portability and interoperability issues that often arise. In this paper we propose a uniform, integrated, machine-readable, semantic representation of cloud services, patterns, appliances and their compositions. Our approach aims at supporting the development of new applications for the Cloud environment, using semantic models and automatic reasoning to enhance potability and interoperability when multiple platforms are involved. In particular, the proposed reasoning procedure allows to: perform automatic discovery of Cloud services and Appliances; map between agnostic and vendor dependent Cloud Patterns and Services; automatically enrich the semantic knowledge base.	automated reasoning;categorization;cloud computing;gene ontology term enrichment;graphical user interface;human-readable medium;interoperability;knowledge base;machine translation;ontology (information science);semantic web;software portability;usability;web ontology language	Beniamino Di Martino;Antonio Esposito;Giuseppina Cretella	2017	IEEE Transactions on Cloud Computing	10.1109/TCC.2015.2433259	ontology (information science);cloud computing;data mining;interoperability;cloud testing;computer science;cloud computing security;services computing;distributed computing;software portability;automated reasoning	Web+IR	-45.17158386405272	13.395374829917243	41394
2ce88232af82a0ab11ca5cc845418322bf17e2dd	world megatrend of intelligent robotics and ai: impact on vlsi-dat		The recent report from CITI Group stated that there are 10 disruptive innovation and technology in which robotics and digital economy are included. As the society facing the reality of aging and the industry encountered increased salary/wage levels as well as lack of skilled labors, the need of robots become obvious. Service robotics is finally emerging as a commercial technology after decades of focused Ru0026D. Robots at last have begun moving from shop floors to homes, offices, hospitals, museums, and other public places. The demand for world robots is $ 33,600 million US dollar by the year of 2020. The compound growth rate will be 20%. Apple, Amazon and Google are investing in intelligent robotics technology. Others are likely to follow, further to stimulate investment and innovation.	intel dynamic acceleration;robotics;very-large-scale integration	Ren C. Luo	2017		10.1109/VLSI-DAT.2017.7939690	very-large-scale integration;liberian dollar;real-time computing;wage;robot;operations management;simulation;salary;disruptive innovation;artificial intelligence;engineering;robotics;digital economy	Robotics	-61.85693302033435	5.005311825834498	41424
0a65d7c5125ba780f390168db02870d7657f9436	towards a process-oriented software architecture reconstruction taxonomy	application software;packaging;data mining;software architecture reconstruction;computer architecture;software architecture;visualization;software development software architecture reconstruction taxonomy;software development;taxonomy;humans;programming;information analysis;software architecture taxonomy computer architecture application software data mining packaging visualization programming information analysis humans	To maintain and understand large applications, it is crucial to know their architecture. The first problem is that unlike classes and packages, architecture is not explicitly represented in the code. The second problem is that successful applications evolve over time, so their architecture inevitably drifts. Reconstructing the architecture and checking whether it is still valid is therefore an important aid. While there is a plethora of approaches and techniques supporting architecture reconstruction, there is no comprehensive state of the art and it is often difficult to compare the approaches. This article presents a state of the art on software architecture reconstruction approaches	software architecture	Damien Pollet;Stéphane Ducasse;Loïc Poyet;Ilham Alloui;Sorana Cîmpan;Hervé Verjus	2007	11th European Conference on Software Maintenance and Reengineering (CSMR'07)	10.1109/CSMR.2007.50	multilayered architecture;enterprise architecture framework;functional software architecture;reference architecture;software visualization;software architecture;programming;packaging and labeling;space-based architecture;computer architecture;architecture tradeoff analysis method;application software;database-centric architecture;visualization;computer science;applications architecture;software development;software design description;service-oriented modeling;software engineering;hardware architecture;solution architecture;software architecture description;data analysis;view model;resource-oriented architecture;taxonomy;data architecture;systems architecture;computer engineering	SE	-54.53311786875017	28.12437829817374	41449
15d95925ade05aa5f537aa809d0e85fe09b5265b	scml: an information framework to support supply chain modeling	modelizacion;extensible markup language;decision support;logistique;interoperabilite;model system;interoperabilidad;systeme aide decision;model analysis;reutilizacion;analisis decision;modeling systems and languages supply chain management decision support systems xml supply chain modeling;sistema ayuda decision;modeling language;decision analysis;reuse;user assistance;modelisation;decision support system;sharing;assistance utilisateur;particion;logistics;modeling systems and languages;decision support systems;asistencia usuario;xml;supply chain;supply chain modeling;interoperability;partage;simulation tool;modeling;markup language;analyse decision;supply chain management;reutilisation;logistica	We develop an open information standard to assist supply chain modeling, analysis, and decision support. The Supply Chain Modeling Language (SCML) is a platform- and methodology-independent Extensible Markup Language (XML)-based markup language for storing supply chain structural and managerial information. SCML enables supply chain problem instance reuse and sharing, provides a common format for analytical software interoperability, and can improve the quality of the supply chain description. We develop several pieces of software to aid both users and developers in the utilization of SCML. We demonstrate SCML's applicability by developing a supply chain simulation tool (SISCO) that utilizes the SCML format.	information framework	Dean C. Chatfield;Terry P. Harrison;Jack C. Hayya	2009	European Journal of Operational Research	10.1016/j.ejor.2008.03.027	xml;decision support system;computer science;knowledge management;marketing;database	Robotics	-59.21295669196076	11.899185919864843	41493
9676b7091ef79d9642cf9c3f7c64121f28e86467	a lightweight approach for defining the formal semantics of a modeling language	operational semantics;formal semantics;modeling language;type checking;abstract syntax;formal language;meta model	To define the formal semantics of a modeling language, one normally starts from the abstract syntax and then defines the static semantics and dynamic semantics. Having a formal semantics is important for reasoning about the language but also for building tools for the language. In this paper we propose a novel approach for this task based on the Alloy language. With the help of a concrete example language, we contrast this approach with traditional methods based on formal languages, type checking, meta-modeling and operational semantics. Although both Alloy and traditional techniques yield a formal semantics of the language, the Alloy-based approach has two key advantages: a uniform notation, and immediate automatic analyzability using the Alloy analyzer. Together with the simplicity of Alloy, our approach offers the prospect of making formal definitions easier, hopefully paving the way for a wider adoption of formal techniques in the definition of modeling languages.	abstract state machines;abstract syntax;alloy (specification language);alloy analyzer;formal language;formal methods;iterative and incremental development;mathematical model;metamodeling;modeling language;object constraint language;operational semantics;programming language;rewriting;sms language;semantics (computer science);type system;unified modeling language	Pierre Kelsen;Qin Ma	2008		10.1007/978-3-540-87875-9_48	natural language processing;formal system;metamodeling;abstract syntax;formal language;formal methods;formal semantics;action semantics;object language;specification language;formal verification;syntax;computer science;communicating sequential processes;formal semantics;formal specification;semantics;formal grammar;modeling language;programming language;operational semantics;denotational semantics;semantics;computational semantics	PL	-43.99108990340752	26.825648390860316	41635
3d6c2fdd121315e79fb0a21186708471ba16b81c	folded interaction systems and their application to the survivability analysis of unbounded systems		Modeling the fulfillment of global properties like survivability is a challenging problem in unbounded systems such as Grids, peer-to-peer systems, or swarms. This paper proposes Folded Interaction Systems (FIS), an extension of the classic I-Systems framework, to overcome the modeling issues. FIS is applied to a case of survivability assessment in Grids and demonstrates the identification of essential capabilities, the modeling of harmful incidents, and the derivation of standard strategies to sustain the survival of a system's mission. FIS is not restricted to survivability, it can be used for investigating the preservation of any global property.	authorization;bilateral filter;grid computing;interaction;norm (social);peer-to-peer;serial ata;swarm robotics	Michael Schiffers;Dieter Kranzlmüller	2011	Proceedings of the ITI 2011, 33rd International Conference on Information Technology Interfaces		swarm behaviour;simulation;computer science;distributed computing;survival analysis;computer security;software quality;grid computing;statistics	Robotics	-38.13815133247649	20.298926533900413	41639
27aaa1764146b4731942a9a9860f43e6ec4f41a2	sqfd: qfd-based service quality assurance for the lifecycle of services	service system;performance evaluation;service provider;performance management;design evaluation;service oriented architecture;performance optimization;service engineering;model driven architecture;service quality;business process	Based on a service system, service providers offer services to customers. Quality of a service system has great influence  on customer. Therefore in order to provide better services to customer, it is necessary to assure quality for the lifecycle  of services. With the experiences accumulated in developing and implementing some typical IT systems in manufacturing enterprises  from past decade, we have proposed a new service engineering methodology named SMDA, to assist service providers to build  better service system. As part of the SMDA, the Service Quality Function Deployment (SQFD) has been proposed to consider quality  aspects of a service system. SQFD, which is adopted from QFD, focuses on designing, evaluating and optimization of service  quality in lifecycle of services. The three phases of SQFD, i.e., build-time QFD-oriented service quality design, run-time  service performance evaluation and service performance optimization, are illustrated in this paper.  	quality function deployment	Shu Liu;Xiaofei Xu;Zhongjie Wang	2008		10.1007/978-1-84800-221-0_35	reliability engineering;service level requirement;service level objective;information technology infrastructure library;service assurance;performance engineering;service product management;application service provider;business service provider;systems engineering;service delivery framework;service design;service;process management;business;customer service assurance;service quality;service system	ECom	-58.18974638290683	18.561714759850226	41690
e560430e5fa76ff886413447002014c030eac266	towards providing debugging in the domain-specific modeling languages for software agents		Domain-specific modeling languages (DSMLs) for Multi-agent Systems (MAS) mostly provide checks and validations on modeled systems according to the related syntax and semantics descriptions. However, they do not have a built-in support for debugging MAS models which makes the control of model correctness difficult. Hence, in this paper, we present our ongoing work which aims at providing debugging inside MAS DSMLs. We describe two possible ways of deriving debuggers for MAS DSMLs. The first alternative is based on the construction of a mapping between MAS model entities and the generated code while the second one considers the metamodel-based description of the operational semantics of executing agents. Pros and cons of each approach are also discussed.	code;correctness (computer science);debugger;debugging;directory services markup language;domain-specific language;domain-specific modeling;entity;executable;metamodeling;modeling language;noise shaping;operational semantics;semantics (computer science);software agent	Baris Tekin Tezel;Geylani Kardas	2018				SE	-44.30255618535139	25.54075749042548	41741
3ea2c866aee7900c71a84931b65773392b052767	a mas for access control management in cooperative information systems	multi agent system;cooperative information systems;access control;interoperability;security policy	This proposition deals with interoperation of data and security policies in cooperative information systems. We use the agent paradigm for the treatment of distributed programs and perform complex tasks through cooperation and interactions. A combination of two methods -- GAIA and AUML-- and a set of models are used. Two protocols are defined related to the features of the system: (i) a knowledge management protocol to address interoperability problems between different modes of data representation and security access models and, to generate the matches between these models, (ii) a query resolution protocol using global knowledge. Agents are described in their goals, their interactions, their knowledge by defining their roles for each protocol, including the key role of the security mediator. A prototype is implemented on the JADE platform (Java Agent Development Environment).	access control;data (computing);gaia hypothesis;information system;interaction;interoperability;interoperation;jade;java;knowledge management;programming paradigm;prototype	Leslie Huin;Danielle Boulanger;Eric Disson	2013		10.1145/2536146.2536170	interoperability;computer science;knowledge management;security policy;access control;multi-agent system;data mining;database;computer security	Security	-40.51753912296264	14.66786946711136	41802
56bd7147735739d0e32781c19e5c519726646673	an extension to a corba trader to support xml service descriptions	keyword search;service discovery;document type definition	Search functionality of a CORBA trader is restricted to search for service offers and assumes clients’ knowledge of service types of those offers. It would be more flexible if the clients can also import other information, i.e. service types and interfaces, before trading for service offers, or conduct keyword search. With this requirement, making service descriptions into XML format can be helpful. This paper focuses on the trader extension that can transform service types and service offers within a CORBA trader into XML service descriptions, and vice versa. The transformation is based on our Document Type Definitions for service types and service offers. This transformer module can be used to create XML service descriptions that will enable flexible XML-based service discovery. The transformer also facilitates clients in viewing details of CORBA services from Web browsers and helps with exporting service descriptions to the trader.	common object request broker architecture;search algorithm;service discovery;trader media east;traders;transformer;xml	Twittie Senivongse;Wuttichai Nanekrangsan	2001		10.1007/0-306-47005-5_7	well-formed document;xml catalog;computer science;document type definition;operating system;database;service discovery;world wide web;information retrieval	Web+IR	-39.56791940074071	10.0009630899373	41823
1d0f314dff1cb0afe6f2ad6eee6656af3778f01b	content-oriented composite service negotiation with complex preferences	take the best;e commerce;consumer preference;automatic generation;automated negotiation	In e-commerce, for some cases the service requested by the consumer cannot be fulfilled by the producer. In such cases, service consumers and producers need to negotiate their service requirements and offers. Whereas some multiagent negotiation approaches treat the price as the primary construct for negotiation, we consider that the service content is as much important as the price. Therefore, this study mainly focuses on the content of the service described in a common ontology accessed by both agents for common understanding. Acquiring user’s preferences and acting upon these preferences are crucial tasks for a consumer agent as far as the negotiation is concerned. Since the size of complete preference information increases exponentially with the number of attributes and size of domain, it is required to keep these preferences in a compact way. There are a variety of ways of representing preferences and using these structures for automatic generation of consumer’s request. This research develops an automated negotiation approach in which the consumer takes the preferences of the user in an efficient way and uses these preferences in the generation of request. For this purpose, we design several strategies to generate requests to take the best offer by the producer. On the other side, in order to obtain a more effective negotiation results the producer tries to learn the consumer preferences from the bid exchanges incrementally in order to refine its offer over time. Furthermore, for some complicated services desired by the consumer, a single producer by itself may not meet the consumer’s needs. In such cases, the system should allow consumers negotiating with multiple service producers as far as composite services are concerned.	agent-based model;e-commerce;requirement;service-oriented architecture;service-oriented modeling;traffic exchange;web service	Reyhan Aydogan	2008		10.1145/1402782.1402784	e-commerce;computer science	AI	-44.93174530010538	15.725776548075984	41849
853a3b3e1e467a05c58c157a677e748256612245	analysis of compositional conflicts in component based systems	developpement logiciel;incompatibility;behavioral analysis;componente logicial;component based systems;abstraction;composant logiciel;software development process;abstraccion;incompatibilite;desarrollo logicial;analyse comportementale;software development;doctoral thesis;software component;analisis conductual;incompatibilidad	Today, incompatibilities in component specifications make their composition hard to handle in practical terms. Incompatibilities can be classified into three conflict categories: type conflicts, behavioral conflicts, and property conflicts. This paper describes a framework for the identification of compositional conflicts in component-based systems that analyses conflicts of all three categories. Furthermore, the framework supports conflict analysis from within the software development process and handles component transformations between different abstraction levels.	algorithm;bisimulation;cliff shaw;common object request broker architecture;component-based software engineering;enterprise javabeans;requirement;semiconductor industry;server (computing);simulation;software deployment;software development process	Andreas Leicher	2005		10.1007/11550679_6	computer science;component-based software engineering;software development;abstraction;programming language;software development process;algorithm	SE	-41.02828318949753	26.035501487544927	41881
180dc1b0529dbf5aa618a9e02f11e687fd2fa07e	formalizing exception handling in ws-cdl and ws-bpel for conformance verification	conformance;formal specification;ws cdl;web services exception handling formal specification formal verification software architecture;bepress selected works;communicating sequential process;message events timeout exception handling web services communicating sequential processes document ordering delivery process choreography description language ws cdl;ws bpel ws cdl conformance exception handling;web service;web services automata service oriented architecture information systems software libraries petri nets algebra document handling parallel programming unified modeling language;software architecture;formal verification;web services;ws bpel;exception handling;conformance ws cdl ws bpel exception handling	We have previously developed a formal approach to verifying conformance for web services choreography based on the formalism of Communicating Sequential Processes (CSP). In this paper, we extend the approach to cover exception handling, which is commonly used in specifying the choreography as well as orchestration of web services. In particular, we show how timeout exceptions and message events are handled in the formal approach and illustrate it using a document ordering and delivery process as an example.	business process execution language;communicating sequential processes;compiler description language;conformance testing;exception handling;semantics (computer science);timeout (computing);verification and validation;ws-security;web service	Wing Lok Yeung	2009	2009 IEEE International Conference on Service-Oriented Computing and Applications (SOCA)	10.1109/SOCA.2009.5410265	web service;real-time computing;computer science;database;programming language;law	SE	-45.31276602795855	18.58046789398745	41897
81a63f828a890d59e9dfb62ec81dc5eedf15cee9	a novel digital twin-centric approach for driver intention prediction and traffic congestion avoidance		Road traffic has been exponentially growing with surging people and vehicle population. Road connectivity infrastructure has not been growing correspondingly and hence the research endeavors for optimal resource allocation and utilization of connectivity resources has gained a lot these days. Therefore, insights-driven real-time traffic management is turning out to be an important component in establishing and sustaining smarter cities across the globe. IT solution and service organizations have come forth with a number of automated traffic management solutions and the primary problem with them is they are unfortunately reactive and hence an inefficient solution for the increasingly connected and dynamic city environments. Therefore, unveiling real-time, adaptive, precision-centric and predictive traffic monitoring, measurement, management and enhancement solutions are being insisted as an indispensable requirement toward sustainable cities. We have come out with a novel approach leveraging a few potential and promising technologies and tools such as a reliable and reusable virtual model for vehicles, a machine learning model, the IoT fog or edge data analytics, a data lake for traffic and vehicle data on public cloud environments, and 5G communication. The paper details all these in a cogent fashion and how these technological advancements come handy in avoiding the frequent traffic congestions and snarls due to various reasons.	3d modeling;algorithm;cloud computing;deep learning;handy board;logistics;machine learning;machine perception;network congestion;real-time clock;real-time computing;real-time data;real-time locating system;traffic exchange	Sathish A. P. Kumar;R. Madhumathi;Pethuru Raj Chelliah;Lei Tao;Shangguang Wang	2018	Journal of Reliable Intelligent Environments	10.1007/s40860-018-0069-y	primary problem;computer security;computer science;population;globe;data analysis;cloud computing;internet of things;resource allocation;traffic congestion	Metrics	-34.33788991533602	19.51647466063129	41909
077f41cb4ad054aa1c48e34d3e857430e0a53967	model of trustrank evaluation based on fuzzy set for pervasive computing	ubiquitous computing computer network security fuzzy set theory;computational modeling pervasive computing vectors uncertainty adaptation models access control;fuzzy trust evaluation fuzzy set theory pervasive computing network security trust synthesis evaluation subjective trust rank evaluation model interval valued fuzzy set trust dynamic character;fuzzy set;computer network security;uncertainty;network security;pervasive computing;computer model;trust model;fuzzy set theory;trustrank evaluation;computational modeling;vectors;interval valued fuzzy set;ubiquitous computing;access control;interval valued fuzzy set pervasive computing trustrank evaluation;adaptation models	Trust model has become the focus of network security. The description of trust is given newly with fuzzy set theory for pervasive computing environment. In course of trust synthesis evaluation, the model of subjective trust-rank evaluation based on the interval-valued fuzzy set is proposed in this paper so that the evaluation of users trust-rank becomes more flexibility and more reliable. According to the dynamic character of trust, a novel model and method of trust-rank's calculation based on interval-valued fuzzy set theory is provided. The application instance shows that proposed fuzzy trust evaluation provides a new valuable way for pervasive computing.	fuzzy set;network security;set theory;trustrank;ubiquitous computing	Xunwen Xu;Zhanrong Chen	2011	2011 International Conference on Internet of Things and 4th International Conference on Cyber, Physical and Social Computing	10.1109/iThings/CPSCom.2011.24	computer science;theoretical computer science;network security;machine learning;data mining;fuzzy set;computer security;ubiquitous computing	Robotics	-36.85983657600138	19.987211047052043	41936
2b09b1309c6bab846f8ef91bc78dc920b9d7e460	spekl: a layered system for specification authoring, sharing, and usage	software;software libraries;writing;security;java	Compositional reuse of software libraries is important for productivity. To promote reliability and correctness, the field also needs a way to compose specifications for reuse. How-ever, specifications cannot be adapted by the use of wrappers in the same ways as code can, which leads to specifications being copied and modified. This copying and modification of specifications leads to poor maintainability and technical debt. We propose a system, Spekl, that solves these problems and makes compositional reuse of specifications possible in a way independent of the choice of specification languages and tools.	correctness (computer science);formal specification;library (computing);technical debt;verification and validation;wrapper function	John L. Singleton;Gary T. Leavens	2016	2016 IEEE 17th International Conference on Information Reuse and Integration (IRI)	10.1109/IRI.2016.24	computer science;information security;operating system;software engineering;database;programming language;java;writing;world wide web	SE	-51.82378674447722	31.277540407609617	41971
d37e103ec1d19ed4359f08c9fed2d6a9901d5bbf	a multiview framework driven by use cases to support the design of service components	information systems;uml;view;engineering process service component service design use case view uml traceability;unified modeling language information systems service oriented architecture;soa multiview framework use cases service component design software technologies service oriented architecture is service component models logical service block assembly model service consistency service traceability uml2 tool sca information systems;service component;unified modeling language;service design;service oriented architecture;traceability;use case;engineering process;unified modeling language collaboration business ports computers assembly service oriented architecture	In the field of software technologies, the adoption of Service Oriented Architecture for IS has been accompanied by the introduction of new service component models which are well-suited to realize services. While these service components offer new capabilities to simplify the construction and maintenance of IS, the issue of their design needs to be further examined as current existing works do not sufficiently bridge the gap between requirements and service component models. In this paper, we present a multi-view framework to support the design of services along the development process. The framework is grounded on the notion of Logical Service Block which represents a service from Use case to assembly model and acts as a pivot between views ensuring the consistency and the trace ability of services at different stages and levels of detail. The proposed framework has been implemented to provide a UML2 tool that helps designers in elaborating views and projecting services towards a specific platform like SCA.	component-based software engineering;experiment;functional requirement;interaction;non-functional requirement;requirement;service-oriented architecture;service-oriented device architecture;traceability	Emmanuel Renaux;Gilles Vanwormhoudt;Christophe Tombelle	2013	2013 IEEE Seventh International Symposium on Service-Oriented System Engineering	10.1109/SOSE.2013.47	unified modeling language;service catalog;information technology infrastructure library;service product management;application service provider;differentiated service;computer science;systems engineering;basic service;service delivery framework;software engineering;service design;database;service;service discovery;data as a service;service integration maturity model;engineering design process	SE	-54.70769940887188	22.08555909887297	42033
42bb21cc76753d49733d8b1ac900f345e47e73d7	automated instrumentation of contracts and scenarios for requirements validation in .net	contracts;non functional requirement;requirements;object oriented;reactive system;validation;scenarios;use case	During the development of an object-oriented reactive system, scenarios (such as UML's use cases) may be used for the elicitation of functional and non-functional requirements. The contribution of this paper is the overview of a framework for the specification of a testable requirements model and the automated instrumentation of this model into an implementation in order to validate the model's requirements against this implementation. Our testable model takes the form of contracts and is grounded in the notions of scenarios and responsibilities. More precisely, the validation of the requirements of this model depends on a user binding elements of contracts to actual procedures within a candidate implementation, (that also supplies test data). Once this is done, these requirements are validated against an execution. This validation consists in the invocation of both static and dynamic checks, the matching of scenarios, and the capture and evaluation of metrics for an execution. Metric evaluation allows our framework and testable model to also consider non-functional requirements.	functional requirement;non-functional requirement;test data;unified modeling language	Dave Arnold;Jean-Pierre Corriveau	2008		10.1145/1370042.1370056	use case;reliability engineering;requirements analysis;software requirements specification;requirements management;real-time computing;reactive system;goal modeling;computer science;systems engineering;engineering;software engineering;system requirements specification;non-functional testing;object-oriented programming;non-functional requirement	SE	-55.2921854679068	26.110476845893707	42061
d66aa16d438d18ed1ed0da24bd148534cd7fc123	a supply chain ontology conceptualization with focus on performance evaluation	performance evaluation;supply chain	Organizations all over the world are increasingly aligning in Supply Chains (SCs) in order to perform more efficiently and to achieve better results. This contribution presents a SC ontology that aims at conceptualizing and formalizing this domain knowledge. Its goal is to: a) enable a better understanding among the various stakeholders & b) set the basis for an effective information sharing and the development of integrations tools. The ontology introduces concepts associated with the SC structure, functions, resources, and management issues. Since one key component of management is performance assessment, which must be done along the whole SC, the proposed ontology focuses on performance evaluation issues.	conceptualization (information science);emoticon;enterprise modelling;entity;pict;performance evaluation;reference model;universal networking language;web ontology language	Alicia C. Böhm;Horacio P. Leone;Gabriela P. Henning	2008			computer science;knowledge management;supply chain	Web+IR	-60.151149206564334	14.48208893991439	42108
7be02088b32171670f2334ff6a0edfa51c006b97	exploiting pervasive enterprise chronicles using unstructured information management	enterprise mining;image storage;semiconductor technology;electronic chronicles;image converters;information retrieval;pervasive computing;pervasive enterprise chronicles;business communication;enterprise search;unstructured information management architecture;computer architecture;unstructured information management architecture pervasive enterprise chronicles semiconductor technology pervasive devices multimedia data electronic chronicles picasso system enterprise search enterprise mining;portable computers;information management;multimedia data;performance analysis;ubiquitous computing;pervasive devices;mobile computing;information retrieval information management ubiquitous computing;picasso system;information analysis;information management image storage information analysis performance analysis computer architecture portable computers mobile computing business communication pervasive computing image converters	Strides made in semiconductor technology and pervasive devices are fueling the ability to amass ever-increasing volumes of rich multimedia data chronicling the activities and experiences of enterprise employees. Rich content analytics are crucial to exploit the potential of such electronic chronicles, which represent a vital untapped resource in today's enterprises. This paper describes a system called Picasso that adds a new dimension to enterprise search and mining, by capturing and structuring information surrounding employee activities and making available vital insights from such information through our unstructured information management architecture (UIMA).	apache uima;information management;pervasive informatics;semiconductor	Anthony Levas;Gopal Sarma Pingali;Mark Podlaseck;J. William Murdock	2005	ICPS '05. Proceedings. International Conference on Pervasive Services, 2005.	10.1109/PERSER.2005.1506417	computer science;knowledge management;database;data analysis;world wide web;ubiquitous computing;enterprise information system	HPC	-49.630327806465644	6.636724151833206	42191
6674956e9d77fb4f33d213b9264ffe0099cefb16	modelling and analysing provenance awareness infrastructure for soc systems	service composition provenance awareness infrastructure model analysis service oriented computing soc;provenance awareness;service composition;service oriented computing soc;infrastructure model;web services graph theory query processing service oriented architecture;analysis;system on chip data models unified modeling language analytical models quality of service history system analysis and design;provenance awareness infrastructure analysis service oriented computing provenance data graphs generic algorithm provenance query answering infrastructure design template provenance infrastructure model composite services graph based structure data model system accountability provenance infrastructure behaviour dynamic composition service selection service discovery soc system execution cycle information recording soc system design provenance awareness infrastructure modelling	Provenance awareness adds a new dimension to SOC systems' design allowing them to answer different kinds of questions about the system's history processing by recording information during system execution. Incorporating provenance in SOC systems requires to carefully model and analyse provenance infrastructure requirements at system's design time in order to cope with the inherent complexity encapsulated into the SOC systems' execution cycle, considering the aspects of service discovery, selection and dynamic composition. Formally specifying provenance-infrastructure behavior assists in the design/analysis of the system's accountability by introducing provenance mechanisms to collect the respective provenance where the latter can be verified and revised beforehand the system's actual implementation. We have previously presented a data model to express the graph-based structure of the provenance data collected for composite services. In this paper we focus on a template provenance-infrastructure model specifying the behavior required in order to issue the respective provenance recording calls through the SOC execution cycle. We then bind the infrastructure design to specific SOC models in order to analyze whether this leads to actual recording of the provenance required for answering provenance queries. We accomplish this by proposing a generic algorithm that simulates the provenance-infrastructure behavior and generates sample provenance-data graphs.	algorithm;code refactoring;data model;formal specification;generic programming;prototype;requirement;service discovery;system on a chip	Paraskevi Zerva;Steffen Zschaler;Simon Miles	2015	2015 IEEE Symposium on Service-Oriented System Engineering	10.1109/SOSE.2015.31	computer science;theoretical computer science;operating system;analysis;database;world wide web	DB	-46.35657518286876	18.97456499039171	42254
8ebbc780bad269c2488096e7656b7058e48c90b9	a pattern based methodology for evolution management in business process reuse		Today, there are Process-Aware Information Systems (PAIS) with a set of business process models which vary over time to meet the new requirements. In a competitive environment, the key challenge of enterprises is to reduce the cost and time of process design and application development. For this purpose, research on reuse in business process management have introduced the concept of configurable process models which attempts to manage business process variability, by integrating a set of process variants in a single model. In this context, many research works were interested in creating and elaborating configurable process models. However, this has become insufficient since the configurable process model should itself evolve to add new variations. In turn, this requires a comprehensive support for managing the evolution of configurable process models. In this paper, we present a complete pattern based methodology for managing the evolution of configurable process models in terms of activities, data and resources. Our objective is to propose a process patterns system for guiding designers in modeling and evolving configurable process models. Furthermore, our process patterns system will be used for an automated support so as to manage the evolution of configurable process models.	business process;evolution;information system;process modeling;process patterns;prototype;requirement;spatial variability	Hanae Sbaï;Mounia Fredj;Laila Kjiri	2014	CoRR		systems engineering;engineering;knowledge management;artifact-centric business process model;business process management;process modeling;business process model and notation;process management;business process;process mining;business process discovery;business process modeling	SE	-56.39081371960816	18.167977959585787	42275
eb50b45f24fb0f4746f23d8fb24a1df0d9523fae	enterprise cloud service architecture	silicon;service design patterns;quality attributes;clouds service oriented architecture computer architecture cloud computing servers business silicon;service orientation;distributed computing;service design patterns enterprise cloud service architecture cloud computing enterprise service oriented architecture style enterprise service oriented formula distributed computing;enterprise service oriented formula;service architecture;computer architecture;software architecture;servers;internet;enterprise service oriented architecture style;business data processing;clouds;service oriented computing;business;hybrid architecture;service design;extended enterprise;service oriented architecture;enterprise cloud service architecture;software architecture business data processing internet;cloud computing;architectural style	Cloud computing, a new paradigm of distributed computing, introduces many new ideas, concepts, principals, technologies and architectural styles into enterprise service-oriented computing. The enterprise service-oriented architecture (ESOA) style is an abstraction of concrete enterprise service-orientated architectures, which includes SOA architectural elements, service design patterns as well as principles, and SOA quality attributes. It can be extended to a new style for realizing enterprise cloud computing. Meanwhile, the principles and style of enterprise service-oriented computing facilitate the enterprise-wide adoption of cloud computing. This paper extends the ESOA style to a new hybrid architectural style, Enterprise Cloud Service Architecture (ECSA). The style is described by extending enterprise service-oriented formula for ESOA. We model the style through specifying each element in the formula with both service-oriented and cloud architectural styles.	cloud computing;data center;design pattern;distributed computing;dynamic data;enterprise architecture;enterprise integration;formal methods;list of system quality attributes;programming paradigm;service-level agreement;service-oriented architecture;service-oriented modeling;synergy;verification and validation;vocabulary	Longji Tang;Jing Dong;Yajing Zhao;Liang-Jie Zhang	2010	2010 IEEE 3rd International Conference on Cloud Computing	10.1109/CLOUD.2010.10	enterprise architecture framework;functional software architecture;enterprise systems engineering;enterprise software;nist enterprise architecture model;computer science;architecture domain;operating system;service-oriented modeling;service-oriented architecture;enterprise architecture management;database;distributed computing;enterprise architecture;enterprise integration;enterprise information system;enterprise life cycle	HPC	-57.7773040554011	17.56938236090497	42289
55b9b066f4f43c7204ba3bfdb6b56577c155fd22	parametric, probabilistic, timed resource discovery system		This paper presents a fully distributed resource discovery and reservation system. Verification of such a system is important to ensure the execution of distributed applications on a set of resources in appropriate conditions. A semi-formal model for his system is presented using probabilistic timed automata. This model is timed, parametric and probabilistic, making it a challenge to the parameter synthesis community.	automata theory;best, worst and average case;cartography;discovery system;distributed algorithm;distributed computing;failure rate;formal verification;mathematical model;model checking;petri net;real-time clock;real-time computing;semiconductor industry;timed automaton	Camille Coti	2016		10.4204/EPTCS.220.5	real-time computing;simulation;computer science;distributed computing	Embedded	-36.54390488603125	30.91738411465499	42342
79e4a1aa07f6f48cb54db550bf90516cbd09e108	efficient product-line testing using cluster-based product prioritization		A software product-line comprises a set of products that share a common set of features. These features can be reused to customize a product to satisfy specific needs of certain customers or markets. As the number of possible products increases exponentially for new features, testing all products is infeasible. Existing testing approaches reduce their effort by restricting the number of products (sampling) and improve their effectiveness by considering the order of tests (prioritization). In this paper, we propose a cluster-based prioritization technique to sample similar products with respect to the feature selection. We evaluate our approach using feature models of different sizes and show that cluster-based prioritization can enhance the effectiveness of product-line testing.	algorithm;cluster analysis;feature model;feature selection;sampling (signal processing);software product line;software system	Mustafa Al-Hajjaji;Jacob Krüger;Sandro Schulze;Thomas Leich;Gunter Saake	2017	2017 IEEE/ACM 12th International Workshop on Automation of Software Testing (AST)	10.1109/AST.2017.7	kernel (linear algebra);software;agile software development;cluster analysis;requirement prioritization;sampling (statistics);feature selection;data mining;orthogonal array testing;engineering	SE	-59.720525197492584	29.399839519710806	42344
6eaeafc991025ec770afbfb4eeba12ef93335f1b	a reuse-based approach to the correct and automatic composition of web-services	service orientation;distributed computing;component composition;component container;web service;componentware;adaptation;component model;service level specification	Service oriented technologies, such as web services, can be considered one of the latest trends in distributed computing. Nowadays, the Internet arena is populated by an ever more increasing number of web services. This has led to the need for reuse-based approaches to the automatic construction of new services as a correct composition of existing ones. A composition of services is correct when it respects the Service Level Specification (SLS) specified for the composite service to be built. To this end, we propose an extension of our previous work on the automatic component assembly. The aim of this extension is to propose an automatic and specification-based approach for constructing composite services from existing ones, which are discovered from a service repository. We instantiate the proposal in the context of web services. This work has to be considered as an ongoing work. In this paper, we also raise some research questions concerning the current gap between what we are able to do by means of the proposed extension and what still remains an open issue.	distributed computing;internet;population;service-oriented modeling;standard sea level;web service	Paola Inverardi;Massimo Tivoli	2007		10.1145/1294904.1294908	web service;differentiated service;computer science;systems engineering;service delivery framework;ws-policy;database;services computing;world wide web	Web+IR	-47.40067220539473	18.12235482340399	42374
246037ea242334d24ccc13dfe9acc5a39138aaf2	intml: a case study on virtual reality development	intml;virtual reality;model driven development;domain specific language;virtual reality development;software product line;markup language;interaction technique	We present the Interaction Techniques Markup Language (InTml), a case study of the use of Domain Specific Languages (DSLs), Model Driven Development (MDD), and Software Product Lines (SPL) in the field of Virtual Reality (VR) applications, a challenging domain due a wide variety of hardware platforms, computational limitations, and available solutions. We use existing technologies around the Eclipse Platform in order to create an IDE in which families of VR applications can be generated and played.	domain-specific language;eclipse;interaction technique;markup language;model-driven engineering;software product line;virtual reality	Pablo Figueroa	2009		10.1145/1639950.1639994	simulation;human–computer interaction;computer science;domain-specific language;virtual reality;markup language;programming language;interaction technique;computer graphics (images)	Visualization	-48.7685135801308	23.633317602367647	42386
c1e4d3455fa0d5b1ef465f5c1af059e35584282c	perspectives on ontology learning	004 informatik	This chapter provides a self-contained first introduction to description logics (DLs). The main concepts and features are explained with examples before syntax and semantics of the DL SROIQ are defined in detail. Additional sections review light-weight DL languages, discuss the relationship to the Web Ontology Language OWL and give pointers to further reading.	description logic;ontology learning;web ontology language	Jens Lehmann;Johanna Völker	2014		10.3233/978-1-61499-379-7-i	upper ontology;ontology alignment;ontology components;bibliographic ontology;computer science;knowledge management;ontology;data science;data mining;ontology-based data integration;owl-s;process ontology;suggested upper merged ontology	AI	-39.09170897328483	6.0442370869668105	42453
bdbf33f27864ba233692199c1b0237a763f2ced2	exploiting semantic technologies in smart environments and grids	semantic technologies;smart grid;ontologies;smart environments;home automation	Semantic technologies are currently spreading across several application domains as a reliable and consistent mean to address challenges related to organization, manipulation, visualization and exchange of data and knowledge. Different roles are actually played by these techniques depending on the application domain, on the timing constraints, on the distributed nature of applications, and so on. This paper provides an overview of the roles played by semantic technologies in the domain of smart grids and smart environments, with a particular focus on changes brought by such technologies in the adopted architectures, programming techniques and tools. Motivations driving the adoption of semantics in these different, but strictly intertwined, fields are introduced using a strong applicationdriven perspective. Two real-world case studies in smart grids and smart environments are presented to exemplify the roles covered by such technologies and the changes they fostered in software engineering processes. Learned lessons are then distilled and future adoption scenarios discussed.	application domain;exemplification;grid computing;smart environment;software engineering	Dario Bonino;Giuseppe Procaccianti	2014	Sci. Comput. Program.	10.1016/j.scico.2014.02.018	home automation;simulation;computer science;knowledge management;ontology;data mining;smart grid;semantic technology;smart environment;internet of things	SE	-45.52304676602915	21.14112172867196	42470
23e9b8fa6ae45370eda8e87df4207c13c89a9130	a metamodel and uml profile for rule-extended owl dl ontologies	modelizacion;distributed system;ontologie;systeme reparti;lenguaje uml;web semantique;service web;langage modelisation unifie;semantic web rule language;web service;modelisation;sistema repartido;metamodel;visual modeling;metamodele;uml profile;metamodelo;web semantica;unified modelling language;semantic web;ontologia;modeling;ontology;servicio web	In this paper we present a MOF compliant metamodel and UML profile for the Semantic Web Rule Language (SWRL) that integrates with our previous work on a metamodel and UML profile for OWL DL. Based on this metamodel and profile, UML tools can be used for visual modeling of rule-extended ontologies.	extensibility;input method;language interoperability;list of unified modeling language tools;meta-object facility;metamodeling;neon (light synthesizer);object constraint language;ontology (information science);profile (uml);qvt;rule interchange format;semantic web rule language;visual modeling	Saartje Brockmans;Peter Haase;Pascal Hitzler;Rudi Studer	2006		10.1007/11762256_24	metamodeling;web service;unified modeling language;model-driven architecture;semantic web rule language;systems modeling;uml tool;computer science;applications of uml;semantic web;ontology;database;programming language;world wide web	AI	-36.98575505934881	12.80545016340665	42568
6b33acaf2ab86f4a4e75722a202dbdfdc49d50ef	an analysis of integration problems of xml-based catalogs for b2b electronic commerce	xml-based catalogs;integration problems;e-commerce;product catalogs;xsl-t;b2b catalog integration;b2b electronic commerce;electronic commerce;e commerce	Electronic B2B marketplaces bring together many online suppliers and buyers, each of which can potentially use his own format to represent the products in his product catalog. The marketplaces have to perform non-trivial mappings of these catalogs. In this paper we analyze the problems which occur during integration, taking several leading XML and non-XML formats as examples. We discuss the method for applying XSLT technology to the integration problems, propose typical solutions to these problems, and give the corresponding examples of integration rules.	e-commerce;xml;xslt	Borys Omelayenko;Dieter Fensel	2001			computer science;data mining;database	DB	-48.43872438922209	10.783261183839842	42600
2caf037412adf3799839c6b915794b9182c362ae	reassessing the roles of negotiation and contracting for interoperable databases		Negotiation and contracting have been traditionally used in the database context in connection with passing schema information between interconnected database nodes. Several protocols have been proposed to address the transmission of schema information. However, all of the approaches suggested so far are fairly simplistic, restrictive in nature as they do not result in alleviating connicts or formulating partial solutions in a collective manner. In contrast, Distributed AI (DAI) has taken the view that negotiation is a mechanism used by autonomous systems to resolve inconsistent views and reach agreement on how they can work together in order to cooperate eeectively. Although this approach may sound appealing it becomes an intractable problem in an environment as complex as interoperable database systems. In this paper we reassess the concepts of negotiation and contracting in both distributed databases and DAI and propose a exible framework tailored around the client/server model for interoperable databases. The approach taken is based on a selective fusion of several technologies such as distributed processing, databases, AI and object-orientation.	autonomous system (internet);client–server model;computational complexity theory;database schema;distributed artificial intelligence;distributed computing;distributed database;interoperability;server (computing)	Stephen Milliner;Mike P. Papazoglou	1994			database;computer science;interoperability;negotiation	DB	-37.14663896956594	15.521764019763808	42622
ed9e637af268d63ae0ff1421d1c32aab8704e6dc	supporting the validation of structured analysis specifications in the engineering of information systems by test path exploration	data flow diagrams;requirements validation;test cases;test paths;structured analysis;reviews	Requirements validation should be carried out early in the development process to assure that the requirements specification correctly reflects stakeholder’s intentions, and to avoid the propagation of defects to subsequent phases. In addition to reviews, early test case creation is a commonly used requirements validation technique. However, manual test case derivation from specifications without formal semantics is costly, and requires experience in testing. This paper focuses on Structured Analysis as a semi-formal technique for specifying information systems requirements, which is part of latest requirements engineering curricula and widely accepted practices in business analysis. However, there is insufficient guidance and tool support for creating test cases without the need for using formal extensions in early development stages. Functional decomposition as a core concept of Structured Analysis, and the resulting distribution of control flow information complicates the identification of dependencies between system inputs and outputs. We propose a technique for automatically identifying test paths in Structured Analysis specifications. These test paths constitute the basis for defining test cases, and support requirements validation by guiding and structuring the review process.	business analysis;control flow;information system;requirement;requirements engineering;semantics (computer science);semiconductor industry;software propagation;software requirements specification;structured analysis;test case	Torsten Bandyszak;Mark Rzepka;Thorsten Weyer;Klaus Pohl	2015		10.5220/0005342102520259	data flow diagram;simulation;computer science;software engineering;system requirements specification;test suite;data mining;database;test method;test case;structured analysis	SE	-57.02709304441102	24.306225481511365	42657
3fe07d9ef20afe438f0c05709cbbce4432e0e5ce	a proposal for the application of dynamic workflows in disaster management: a process model language customized for disaster management	disaster knowledge management;disaster response;disaster management;computer model;hazards adaptation models disaster management vocabulary computational modeling planning;vocabulary;knowledge management;hazards;dynamic workflow;disaster response dynamic workflow disaster management process model language disaster preparation response cycle dynamic adaptation knowledge management;computational modeling;disaster knowledge management disaster management dynamic workflow;planning;process model;public administration disasters knowledge management;adaptation models;dynamic adaptation;disasters;public administration	In recent years awareness for disasters increases. Handling response and managing experiences becomes more important and require sufficient support. Existing systems does not support the entire disaster preparation and response cycle and lags behind current technical possibilities. Therefore we propose a system based on a simplified process model notation and support for dynamic adaptation as well as knowledge management. This comprehensive support helps to improve quality and effectiveness of disaster response.	documentation;executable;experience;knowledge management;process modeling;vocabulary	Thomas Ziebermayr;Johannes Huber;Stefan Kollarits;Martin Ortner	2011	2011 22nd International Workshop on Database and Expert Systems Applications	10.1109/DEXA.2011.6	computer simulation;planning;disaster;hazard;computer science;knowledge management;process modeling;management science;computational model;disaster recovery;emergency management	DB	-56.29794295812308	14.294560976180188	42683
0f1a50c487357ae016ec9a4ae85d4ad50a342e4e	semantic rule processing for real-time data integration		Integration-as-a-service platforms arise as a modern strategy to integrate data from distributed environments. Nowadays, service interoperability strategies, such as workflows and static service-oriented architectures, are giving place to more dynamic environments, where the path from the original resource to the integrative destination is triggered autonomously and in real-time. However, these concepts still have not been applied to bioinformatics, in great part due to the complexity underlying the data validation and transformation tasks. In this manuscript we introduce a component to enhance these activities by enabling the execution of complex preand post-integration semantic algorithms. By leveraging on comprehensive Semantic Web constructs, these activities are better suited to the life sciences domain.	algorithm;bioinformatics;data validation;interoperability;real-time data;real-time transcription;semantic web;service-oriented architecture;service-oriented software engineering	Pedro Lopes;José Luís Oliveira	2013			ontology-based data integration;semantic data model;semantic interoperability;semantic computing;semantic integration;idef1x;semantic grid;theoretical computer science;semantic compression;computer science	AI	-43.57975929948295	9.99120704378321	42707
c29dea27e76374635b8fa658e3f610e0330b72c6	migrating to cloud-native architectures using microservices: an experience report		Migration to the cloud has been a popular topic in industry and academia in recent years. Despite many benefits that the cloud presents, such as high availability and scalability, most of the on-premise application architectures are not ready to fully exploit the benefits of this environment, and adapting them to this environment is a non-trivial task. Microservices have appeared recently as novel architectural styles that are native to the cloud. These cloud-native architectures can facilitate migrating on-premise architectures to fully benefit from the cloud environments because non-functional attributes, like scalability, are inherent in this style. The existing approaches on cloud migration does not mostly consider cloud-native architectures as their first-class citizens. As a result, the final product may not meet its primary drivers for migration. In this paper, we intend to report our experience and lessons learned in an ongoing project on migrating a monolithic on-premise software architecture to microservices. We concluded that microservices is not a one-fit-all solution as it introduces new complexities to the system, and many factors, such as distribution complexities, should be considered before adopting this style. However, if adopted in a context that needs high flexibility in terms of scalability and availability, it can deliver its promised benefits.	cloud computing;continuous delivery;high availability;microservices;on-premises software;scalability;software architecture	Armin Balalaie;Abbas Heydarnoori;Pooyan Jamshidi	2015		10.1007/978-3-319-33313-7_15	real-time computing;simulation;systems engineering;engineering;software engineering	HPC	-59.872338638573055	21.49501130402557	42712
55a9317a6ca3ee3f45c8a5111ebb8e61adae8450	engineering runtime requirements-monitoring systems using mda technologies	estensibilidad;modelizacion;verificacion modelo;confidencialidad;enterprise javabeans;ucl;componente logicial;surveillance;componente ejb;securite informatique;exigence usager;systems engineering;exigencia usuario;verification modele;discovery;recommandation;composant logiciel;langage ocl;theses;conference proceedings;almacen dato;contrato;confidentiality;computer security;modelisation;confidentialite;software architecture;monitoring system;vigilancia;digital web resources;metamodel;contract;model checking;monitoring;metamodele;object oriented;metamodelo;ucl discovery;user requirement;seguridad informatica;open access;estructura datos;consistency checking;software component;ingenierie systeme;enterprise javabean;recomendacion;architecture basee modele;oriente objet;recommendation;ucl library;service level agreement;structure donnee;extensibilite;scalability;monitorage;contrat;book chapters;open access repository;entrepot donnee;data warehouse;monitoreo;modeling;composant ejb;orientado objeto;data structure;model driven architecture;architecture logiciel;object constraint language;meta model;lenguaje forzado objeto;arquitectura basada modelo;ucl research	The Model-Driven Architecture (MDA) technology toolset includes a language for describing the structure of meta-data, the MOF, and a language for describing consistency properties that data must exhibit, the OCL. Off-the-shelf tools can generate meta-data repositories and perform consistency checking over the data they contain. In this paper we describe how these tools can be used to implement runtime requirements monitoring of systems by modelling the required behaviour of the system, implementing a meta-data repository to collect system data, and consistency checking the repository to discover violations. We evaluate the approach by implementing a contract checker for the SLAng service-level agreement language, a language defined using a MOF metamodel, and integrating the checker into an Enterprise JavaBeans application. We discuss scalability issues resulting from immaturities in the applied technologies, leading to recommendations for their future development.	enterprise javabeans;meta-object facility;metamodeling;model-driven architecture;model-driven integration;object constraint language;requirement;research data archiving;scalability;service-level agreement	James Skene;Wolfgang Emmerich	2005		10.1007/11580850_17	metamodeling;data structure;computer science;operating system;data warehouse;database;programming language;world wide web;computer security	SE	-41.4568278569667	24.579551684376256	42724
434efd255a75483f211f6041edd15efafa793902	web performance and behavior ontology	web system;software;web pages;system configuration;web performance;performance index;ontologies artificial intelligence;cache tier web system architecture ontologies knowledge base system;servers;internet;monitoring;cache tier;ontologies artificial intelligence internet knowledge based systems;web system architecture;knowledge base system;ontologies;servers ontologies knowledge based systems software monitoring web pages proposals;ontologies web performance;proposals;knowledge based systems;knowledge base	We present a Web system architecture using ontologies to improve the behavior of the system from the performance viewpoint. Since Web system performance indexes depend on state and parameter values on runtime period, the proposed system configuration will change during this period. In order to perform this change, the Web system is monitorized and gathered information stored into a knowledge base. We also model the performance of the different Web system elements intervening in the configuration using the knowledge base expressed by means of ontologies. An example of the use of this ontology in cache tier is also presented. We propose the use of performance reasoners to change the configuration during runtime period based on the information supplied from the knowledge base.	knowledge base;multitier architecture;ontology (information science);run time (program lifecycle phase);system configuration;systems architecture;web cache;web performance;world wide web	Carlos Guerrero;Carlos Juiz;Ramón Puigjaner	2008	2008 International Conference on Complex, Intelligent and Software Intensive Systems	10.1109/CISIS.2008.101	web modeling;computer science;knowledge management;database;world wide web	Robotics	-42.353207410763986	14.756541929304053	42758
0c64e3b3ed6e5ba37e087ca4c7edf33ccf0c3ab3	a semantic mapping of vra core 4.0 to the cidoc conceptual reference model	article δημοσίeυση πeριοδικού	In the recent decades, we have witnessed a tremendous pro- liferation of metadata schemas, particularly in the cultural heritage do- main. As a consequence, there is a growing need to integrate these schemas to solve a number of problems, mainly concerning interoper- ability issues and loss of implicit knowledge. In this paper, we present a semantic mapping of VRA Core 4.0, a cultural heritage metadata schema describing visual resources, to CIDOC CRM. The mapping rules are ex- pressed formally using a path-based mapping language called Mapping Description Language (MDL). This work is based on a semantic integra- tion scenario, where CIDOC CRM acts as a mediation schema.		Panorea Gaitanou;Manolis Gergatsoulis	2011		10.1007/978-3-642-24731-6_39	natural language processing;computer science;knowledge management;artificial intelligence;database;linguistics;programming language;world wide web	NLP	-42.40875184436926	5.33748669307666	42796
24ed18d8f0588fbadeac80b187a41d21217c7899	toward an integrated framework for modeling enterprise processes	tecnologia electronica telecomunicaciones;computacion informatica;grupo de excelencia;erp system;ciencias basicas y experimentales;next generation;process model;tecnologias	Enterprise process modeling is the most important element in the design of next-generation ERP systems.	erp;enterprise resource planning;process modeling	Nikunj P. Dalal;Manjunath Kamath;William J. Kolarik;Eswar Sivaraman	2004	Commun. ACM	10.1145/971617.971620	real-time computing;software engineering;process modeling	Graphics	-57.50303946399313	15.709028080535417	42808
07f40976ec0a6b1b32aa7a9d7f2e5500c08bd6b6	orchestrating dispersed productive systems	manufacturing systems;globalisation;product customisation;production engineering computing;computer architecture production service oriented architecture control systems virtual enterprises manufacturing process control;factory automation;control engineering computing;time to market;time to market control engineering computing factory automation globalisation manufacturing systems product customisation production engineering computing;customized products dispersed productive system orchestration technique dispersed ps supervision physically dispersed ps control supervisory control architecture complex productive process ps internal structure globalized market reconfigurable structure automated productive systems time to market	"""According to trends in demand for customized products with less time-to-market possible, it is noticeable the need for a composition of automated productive systems (PSs) with a reconfigurable structure to maintain competitiveness against the increasing challenges of globalized market. This ability to reconfigure involves not only the internal structure of the PS, but also their participation into an integrated and coordinated environment with more complex productive process. Thus, this work presents a supervisory control architecture that integrates and coordinates a set of physically dispersed PSs, whose functionalities are made available as services for the implementation of productive processes. For the supervision and control of dispersed PSs it is adopted the """"orchestration"""" technique."""	ps (unix)	Samira Souit;Caio C. Fattori;Fabrício Junqueira;Diolino J. Santos Filho;Paulo E. Miyagi	2013	2013 IEEE 18th Conference on Emerging Technologies & Factory Automation (ETFA)	10.1109/ETFA.2013.6648132	embedded system;computer science;systems engineering;engineering;electrical engineering;artificial intelligence;automation;manufacturing engineering	EDA	-54.90950329497386	11.398425423806057	42811
3aa3f72b9a7c9e29b39da2883f3808f4562ba61a	object-oriented analysis for evolving systems	online resources;information resources;scholarly research;information sources;automated teller machine;academic research;online databases;education resources;distributed computing;publishing;object oriented modeling microelectronics distributed computing machinery robustness testing design methodology;testing;research databases;australasian research information;south east asian information;information databases;full content;education databases;australian databases;robustness;microelectronics;object oriented analysis;commissioning;machinery;electronic publisher;online;object oriented modeling;e titles;design methodology;library resources	We are investigating the claim that object- oriented analysis (OOA) requirements models can be changed, reused, and integrated more easily than other kinds ofrequirements models. In thispaper, we describe one part of that investigation: an experiment involving an OOA method in which the requirementsfor an automated teller machine (ATM) system are changed and the effects on the model are assessed.	atm turbo;emergence;requirement	Mitchell D. Lubars;Greg Meredith;Colin Potts;Charles Richter	1992	International Conference on Software Engineering	10.1145/143062.143111	object-oriented analysis and design;project commissioning;machine;design methods;computer science;engineering;data science;software engineering;data mining;publishing;software testing;management;world wide web;microelectronics;robustness;research	SE	-59.99780503941878	28.595791636532837	42819
275d67cdfb5469ca80a6e5fcca8d07d8d7b57f6d	teaching hardware-based dsp: theory to practice	software;microwave integrated circuits;digital signal processing;computer languages;real time;texas instruments;computer languages headphones software microwave integrated circuits;headphones	The authors have developed a teaching model which includes theory, demonstrations, lab exercises, and real-time DSP experience using MATLAB and the Texas Instruments C6711 digital signal processing starter kit. This paper describes specific demonstrations' that can be used as part of this model.	digital signal processing;digital signal processor;matlab;real-time transcription	Cameron H. G. Wright;Thad B. Welch;Delores M. Etter;Michael G. Morrow	2002	2002 IEEE International Conference on Acoustics, Speech, and Signal Processing	10.1109/ICASSP.2002.5745571	embedded system;speech recognition;texas instruments tms320;computer science;digital signal processing	Robotics	-53.16877996865567	4.20348177703112	42822
10b1e2f55da1059b4e278aeec8bfce01352383ea	supporting concern-based regression testing and prioritization in a model-driven environment	supporting concern based regression testing;regression testing;bottom up;test prioritization model driven testing test development regression testing;code based approaches;uml;top down;uml supporting concern based regression testing model driven environment source code artifacts specification level design model based testing approaches code based approaches user defined properties;test development;model driven environment;program testing;specification level design;model driven testing;model based testing;regression analysis;source code;model test;source code artifacts;regression analysis program testing;model based testing approaches;test prioritization;black box testing;user defined properties	Traditional regression testing and prioritization approaches are bottom-up (or white-box). They rely on the analysis of the impact of changes in source code artifacts, identifying corresponding parts of software to retest. While effective in minimizing the amount of testing required to validate code changes, they do not leverage on specification-level design and requirements concerns that motivated these changes. Model-based testing approaches support a top-down (or black box) testing approach, where design and requirements models are used in support of test generation. They augment code-based approaches with the ability to test from a higher-level design and requirements perspective. In this paper, we present a model-based regression testing and prioritization approach that efficiently selects test cases for regression testing based on different concerns. It relies on traceability links between models, test cases and code artifacts, together with user-defined properties associated to model elements. In particular we describe how to support concern-based regression testing and prioritization using TDE/UML, an extensible model-based testing environment.	algorithm;best-effort delivery;black box;black-box testing;bottom-up proteomics;code generation (compiler);level design;model-based testing;model-driven integration;refinement (computing);regression testing;requirement;test case;test suite;top-down and bottom-up design;traceability;transparent data encryption;unified modeling language;user interface	Roberto Silveira Silva Filho;Christof J. Budnik;William M. Hasling;Monica McKenna;Rajesh Subramanyan	2010	2010 IEEE 34th Annual Computer Software and Applications Conference Workshops	10.1109/COMPSACW.2010.63	non-regression testing;test strategy;reliability engineering;regression testing;model-based testing;orthogonal array testing;software performance testing;white-box testing;manual testing;computer science;systems engineering;engineering;software reliability testing;software engineering;functional testing;top-down and bottom-up design;data mining;session-based testing;risk-based testing;software testing;non-functional testing;programming language;system testing;test management approach	SE	-56.50271970286908	31.271556263569206	42835
c5f5a7d2d8f337baad2bc95a8b60408efb130347	ontology-driven keyword-based search on linked data	linked data	Nowadays, the Web is experiencing a continuous change that is leading to the realization of the Semantic Web. Initiatives such as Linked Data have made a huge amount of structured information publicly available, encouraging the rest of the Internet community to tag their resources with it. Unfortunately, the amount of interlinked domains and information is so big that handling it efficiently has become really difficult for the final users. DBPedia, one of the biggest and most important Linked Data repositories, is a perfect example of this issue. In this paper, we propose an approach to provide the users with different domain views on a general data repository, allowing them to perform both keyword and navigational searches. Our system exploits the knowledge stored in ontologies to 1) perform efficient keyword searches over a specified domain, and 2) refine the user’s domain searches. We focus on the case of DBPedia, as it mirrors the information stored in the Wikipedia, providing a semantic entry to it.	coupling (computer programming);dbpedia;exploit (computer security);function overloading;inter-domain;internet;java annotation;linked data;ontology (information science);prototype;research data archiving;search algorithm;semantic web;semantic reasoner;taxonomy (general);usability;view (sql);wikipedia;world wide web	Carlos Bobed;Guillermo Esteban;Eduardo Mena	2012			information retrieval;the internet;linked data;ontology;semantic web;information repository;ontology (information science);exploit;computer science	Web+IR	-36.03382054896846	4.352936846155699	42932
5b0d10a9956766a3a0c7cdaee86b6f27a09547f5	integration of classical components into industrial cyber–physical systems	industrial plants;production facilities iec standards industrial plants cyber physical systems monitoring adaptation models automation;cyber physical systems;iec standards;monitoring;production engineering computing cyber physical systems manufacturing systems;cps industrial cyber physical systems industrial automation systems;production facilities;adaptation models;automation	Industrial automation systems continuously get more complex and growing over time. This leads to an ever growing demand for efficient integration task bridging the gap between technologies, tools used across the enterprise, and alongside the value chain. With the new challenges imposed by introducing cyber-physical systems (CPSs) into industrial applications and while addressing Industry 4.0 concepts, the matter of integration is becoming even more crucial for the introduction of new technologies and their acceptance to customers. This paper introduces integration tasks to be tackled and describes up-to-date technologies as they are used in today's automation industry. This is the basis for concepts addressing the integration issue when introducing CPSs and establishing mixed systems. Investigations are made regarding exploiting integration strategies for future systems.	automation;big data;bridging (networking);complex event processing;cyber-physical system;domain-specific language;embedded system;failure;fault detection and isolation;industry 4.0;interaction;manifold integration;open platform communications;property list;requirement;simulation;user agent	Thomas Bangemann;Matthias Riedl;Mario Thron;Christian Diedrich	2016	Proceedings of the IEEE	10.1109/JPROC.2015.2510981	computer science;systems engineering;engineering;electrical engineering;industrial engineering;automation;cyber-physical system;manufacturing engineering	EDA	-59.38836184308482	14.218084445781788	43019
55d56be3238a3d11ce8d50b671e99d41187ea251	combining communication and coordination toward articulation of collaborative activities	modelizacion;commerce electronique;groupware;comercio electronico;red www;reseau web;conversacion;modelisation;internet;conversation;world wide web;coordinacion;information system;collecticiel;modeling;systeme information;electronic trade;coordination;sistema informacion	In this paper, we present a proposal for the articulation of collaborative activities based on communication and coordination representation models. Articulation is essential in any kind of collaboration and involves prearticulation of the tasks, their management, and post-articulation. For the representation of preand post-articulation phases, conversation clichés (communication) are used. For the coordination phase, a model separating the tasks and their interdependencies is used. The articulation schema, which is especially suited to e-business applications, is then applied to a business-web example.	awareness;biconnected component;electronic business;hgnc;interdependence;large eddy simulation;personal and ubiquitous computing;winsock	Alberto Barbosa Raposo;Marco Aurélio Gerosa;Hugo Fuks	2004		10.1007/978-3-540-30112-7_11	the internet;simulation;systems modeling;computer science;artificial intelligence;multimedia;information system	HCI	-39.028907262592384	15.662387175692595	43070
b2587033232fae204ca8ffd62242aa6b0c26216d	a temporal framework for database specification and verification	satisfiability;software engineering;temporal constraints;specification and verification	A database specification consists of static and temporal constraints and a set of database operation descriptions. A database iS viewed as a dynamic object and a sequence of database states constitutes an evolution of the database. A formal method for verifying database specifications is proposed. The method checks if the static constraints are consistent, analyses the database operation descriptions with respect to the static constraints to ensure that each operation can ever be executed, and finally, it verifies that each permissible sequence of operations satisfies all the temporal constraints.	database;formal methods;verification and validation	David Chenho Kung	1984			software requirements specification;computer architecture;verification;formal methods;formal verification;software verification;database;high-level verification;programming language;intelligent verification;functional verification;language of temporal ordering specification;satisfiability	DB	-42.947032466274216	30.09809911299426	43088
a333405c1cad5a84ac4afa2eabea9f0d44ff3e5a	a course in digital system design using unified e2lp platform	digital systems education tutorials computers embedded systems field programmable gate arrays europe;teaching computer science education educational courses;computer engineering curriculum digital system design unified e2lp platform computer engineering education student teaching course material	Computer engineering education has a strong dependence on laboratory work. Teaching students in the lab does not always consist of teaching the required course material, but also of a vast number of tutorials on different platforms. In many cases, these tutorials take significant amount of time which could be better spent doing actual course material. For that reason, E2LP project has developed a platform to be used in multiple courses, covering majority of the computer engineering curriculum. This paper presents a first step in the curriculum - a course in digital system design with laboratory exercises which are implemented on E2LP platform. The platform not only gives students hands-on experience with design and verification of digital systems, but it also provides a bridge between hardware and software because using the same platform in future courses allows students to re-use their results from previous courses and continue building their knowledge. First impression of students is positive about the experience with the platform and their feeling of usefulness of the course for their career.	computer engineering;digital electronics;hands-on computing;signal processing;systems design	Ivan Kastelan;Nebojsa Pjevalica;Miodrag Temerinac	2015	2015 38th International Convention on Information and Communication Technology, Electronics and Microelectronics (MIPRO)	10.1109/MIPRO.2015.7160371	simulation;multimedia	EDA	-53.96528638496402	4.61516954643921	43098
eace8c2cecf6743df59ec3b4d165a9d1309dbaec	using uml models for performance calculation	distributed system;component based systems;uml;performance estimation;abstractions;information access;automated performance estimates;performance engineering;level of detail;case tool;distributed systems	UML models will quite often lack some of the detail required for performance estimation. This paper explores some ideas to automatically remove layers of indirection and abstraction that hinder straightforward performance evaluation of UML models. Using UML makes the information accessible (since it is a widely know language) and reduces the extra effort (and overhead) needed for performance engineering. Much information normally present in UML models can be used for performance engineering, and adding extra information is relatively straightforward. Using these ideas in a CASE tool allows automatic performance calculations based on models at varying levels of detail . And by breaking-down performance requirements at each design refinement they become tangible and more meaningful during development and testing.	computer-aided software engineering;indirection;overhead (computing);performance evaluation;performance engineering;refinement (computing);requirement;unified modeling language	Fried Hoeben	2000		10.1145/350391.350410	reliability engineering;unified modeling language;real-time computing;performance engineering;uml tool;computer science;systems engineering;applications of uml;level of detail;distributed computing;abstraction	SE	-51.90114133784804	31.49038297782859	43145
7482f33f2154fe09ca51a3bb5723bb96d8dc71d4	geo-spatial context-aware visualization	spatial context;context information;mobile device;mobile computing system;mobile phone;wireless communication;visualization technique;mobile information system;physical environment;quality of context	Mobile computer systems equipped with wireless communication and sensor technology—such as mobile phones with cameras—have become widely available. Context information, for example the user’s current location or their physical environment, plays an increasingly important role in simplifying the interaction between users and such mobile information systems. A generic framework for federating heterogeneous spatial context models is briefly described. The federated information serves as basis for the visualization of spatially referenced data. Visualization challenges include efficient rendering on mobile devices, automatic adaptation of visualization techniques to context information, as well as consideration of the quality of context in the form of uncertainty visualization.	information system;mobile computing;mobile device;mobile phone	Daniel Weiskopf	2009		10.2312/ega.20091001	mobile search;mobile web;computer science;spatial contextual awareness;mobile technology;multimedia;internet privacy;mobile computing;world wide web	Visualization	-35.5055139680065	14.353825931078575	43246
19d130316f61268d5fc8c11bcaad08e6d3724b57	on capturing information requirements in process specifications	process modelling;information modelling	"""Process and information modelling Business process modelling has been in vogue for nearly 20 years, and its origins are much older than that. The growth in the last 20 years can be attributed primarily to inexpensive and powerful computer graphics technologies, which enabled rapid display and modification of complex diagrams. Software process modelling goes back to the flowchart era of the 1950s and 1960s, and reached its high point in the Structured Analysis and Design era (1970-85). Structured analysis taught that one defined information systems by modelling the to-be business process at a high level and refining each high level activity to its component activities, flows and decisions, and repeating this process until the """"activities"""" could be reduced to a few machine instructions. But information requirements were described only at a very high level. In a language of the time, like IDEF0 [1], the basic idea of """"information"""" is essentially a """"document"""" idea. A body of information is characterised by a name and an overall description – the individual information units are not given at all. And this view of integrating information into process specifications is still very much alive in proprietary"""	automated reasoning;business process;computer graphics;design rationale;diagram;flowchart;high-level programming language;idef0;information model;information system;process modeling;requirement;software documentation;structured analysis	Edward Barkmeyer;Peter Denno	2007		10.1007/978-1-84628-858-6_41	systems engineering	HCI	-51.216881254904685	22.529453724707885	43272
54a5b107fe28d301ca4864b0f920a642b6f9d5e9	identifying optimal sets of standardized architectural features — a method and its automotive application	automotive engineering;standards;change management;publikationer;software systems;konferensbidrag;software engineering;computer architecture;industrial meta models;automotive engineering standards computer architecture software engineering software systems;artiklar;rapporter;optimization architectural features industrial meta models change management;optimization;architectural features;software tools automotive engineering configuration management mechanical engineering computing open systems software architecture software standards;tools;automotive software systems standardized architectural features industrial standards software engineering software architectural components domain specific metamodels interoperability software tools modeling tools autosar standard;computer science	Industrial standards are used to formalize procedures, rules and guidelines for the industry to follow. Following a standard requires continuous adoption of the new standardized features where only their subset is required by individual companies. Therefore the prioritization of the features and the assessment of their impact on the development projects is crucial for the success of the project. In software engineering, industrial standards are used increasingly often to standardize a language for designing architectural components of the system by defining domain-specific meta-models. The purpose is to assure the interoperability between a number of software tools exchanging the architectural models. In this paper, we present a method for identifying optimal sets of new standardized architectural features to be adopted in the development projects. The optimization is done based on the assessment of their benefit for the projects and the estimated cost of re-work in the modeling tools according to the changes in the standardized meta-model. We evaluate the method by applying it on 14 new architectural features of a new release of the AUTOSAR standard which is followed in the development of the automotive software systems.	autosar;automotive software;interoperability;mathematical optimization;metamodeling;software engineering;software system	Darko Durisic;Miroslaw Staron;Matthias Tichy	2015	2015 11th International ACM SIGSOFT Conference on Quality of Software Architectures (QoSA)	10.1145/2737182.2737184	architectural pattern;computer science;systems engineering;engineering;software engineering;change management;software system;computer engineering	SE	-57.22425755720497	26.64437609725715	43282
04e449eb1c9e31c421fc6e92ad787510fe3a7cc1	an architecture and a method for web services design: towards the realisation of service-oriented computing	business oriented approaches;it oriented approaches;service oriented computing soc;desirable properties of web services development;web service architecture;web service;it perspectives;service oriented computing;web services;comparative study;soc;comparison study;business perspectives;architecture;method	Service-Oriented Computing (SOC) is the computing paradigm that utilises services as fundamental building blocks. Currently, web services provide a standard-based realisation of SOC due to: (a) the machine-readable format (XML) of their specifications and (b) their messaging protocols built on top of the internet. However, their deployment is still hindered by some technical, semantic and methodological issues. This paper concerns an architecture that guides a methodology to identify, specify, design, organise, deploy and manage a sound and complete set of web services. First, the paper highlights what existing approaches, from both IT and business perspectives, have provided to web services with respect to the following: (1) architecture, (2) design process, (3) building blocks, (4) wrapping legacy (5) usage and reuse, (6) semantics, (7) quality factors and (8) organisation and management. Then a multiple abstraction level architecture is defined, composed of high layers to deal with business orientations and low layers to deal with IT. Finally, the architecture is used as a web services design methodology with respect to SOC.		Youcef Baghdadi;Najla Nasser Al-Rawahi	2006	IJWGS	10.1504/IJWGS.2006.010804	web service;web application security;website architecture;web development;web modeling;business process execution language;web design;web standards;computer science;operating system;ws-policy;service-oriented architecture;ws-addressing;database;distributed computing;services computing;ws-i basic profile;web 2.0;law;world wide web;computer security	DB	-48.95952439670394	17.358079122467082	43300
e8b17224d195ff6b1a44a99a217cee30508c22a7	analysis and design of an effective e-accounting information system (eeais)		E-Accounting (Electronic Accounting) is a new information technology terminology based on the changing role of accountants, where advances in technology have relegated the mechanical aspects of accounting to computer networks. The new accountants are concerned about the implications of these numbers and their effects on the decision-making process.This research aims to perform the accounting functions as software intelligent agents [1] and integrating the accounting standards effectively as web application, so the main objective of this research paper is to provide an effective, consistent, customized and workable solution to companies that participate with the suggested OLAP accounting analysis and services. This paper will point out a guide line to analysis and design the suggested Effective Electronic-Accounting Information System (EEAIS) which provide a reliable, cost efficient and a very personal quick and accurate service to clients in secure environment with the highest level of professionalism, efficiency and technology.		Sarmad Mohammad	2011		10.1007/978-3-642-21984-9_7	online analytical processing;management science;computer network;web application;intelligent agent;accounting standard;information system;e-accounting;software;information technology;computer science	HCI	-62.66528440918176	6.837231122514565	43307
4e9e2e0b0911a0ab808bc8fde172114d24c69abc	design and optimization of high-performance protocols with the do-it toolbox	multimedia;fdt-based implementation;high-performance protocol;do-it toolbox;xtp;fdt-based system and protocol engineering;tool support;performance modeling and optimization;sdl;parallel systems;msc;software development process;development process;formal specification	In the telecommunication industry, the Specification and Description Language (SDL) is a widely accepted technique to support the software development process. While several commercial SDL tools exist that focus on functional aspects, rather little research has been done concerning the integration of nonfunctional aspects in the development process. Our research is focusing on the integration of performance aspects in the development process. In the paper, we give an overview on the DO-IT toolbox and describe how the toolbox can be applied to develop a parallel implementation of a multimedia application on top of the XTP protocol suite. The DO-IT toolbox supports the formal specification of performance requirements (e.g. response time and throughput) and the selection of the appropriate design and implementation decisions.	formal specification;goto;program optimization;protocol stack;requirement;response time (technology);software development process;specification and description language;systems design;throughput	Andreas Mitschele-Thiel;Peter Langendörfer;Ralf Henke	1996			computer science;software engineering;programming language;software development process	SE	-36.50279806685638	32.14314850653669	43326
62ef02463277dfdd03c22ffff6c33eb55a3c73fb	towards collaborative knowledge engineering for improving local safety in urban environment		Web systems supporting collaborative knowledge engineering have attracted much attention recently. By using social software techniques and attractive yet simple user interface, the motivation of users increases and the process can be significantly improved. The willingness of community to invest their time as well as mutual encouragement can be achieved when users are convinced that their contribution is important and useful. We propose a social platform called Social Threat Monitor (STM) aimed at improving safety of local communities in urban environment. The main assumption of the system is the collaboration of users to build and maintain a knowledge base about threats in their neighborhood. Knowledge gathered in the system can be used by the citizens as well as local authorities and police. The system supports collaborative knowledge engineering and management using semantic methods and a GIS component.	application programming interface;category theory;code refactoring;embedded system;folksonomy;formal language;geographic information system;global positioning system;information processing;iterative method;knowledge acquisition;knowledge base;knowledge engineering;knowledge management;logic programming;mobile device;requirement;smartphone;software transactional memory;tag (metadata);user interface	Antoni Ligeza;Weronika T. Adrian;Przemyslaw Ciezkowski	2012				HCI	-48.6262574101903	5.586742527747719	43332
