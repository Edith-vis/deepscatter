id	title	keywords	abstract	entities	authors	year	journal	doi	fos	area	x	y	ix
ccb2114a8edd3fda78b1162ad291a743db3860d6	local minimizer of a nonconvex quadratic programming problem	quadratic programming;non convex programming;quadratic program;programmation quadratique;algorithme beale;programmation non convexe;minimizacion funcion;linear constraint;objective function;programacion no convexa;minimum local;function minimization;mathematical programming;programacion cuadratica;programmation mathematique;programacion matematica;minimisation fonction	A modified Beale's algorithm is described which computes the local minimizer of any quadratic objective function subject to linear constraints. Some extensions are given, first of all the possibility of movement to the neighbouring local minimizer with a reduced objective function value in some special cases. Es wird ein modifizierter Beale Algorithmus zur Bestimmung eines lokalen Extremums eines beliebigen quadratischen Programms bei linearen Restriktionen vorgestellt. Dazu werden einige Erweiterungen angegeben, etwa die Möglichkeit zu einem benachbarten lokalen Minimum mit kleinerem Zielfunktionalswert überzugehen.	algorithm;loss function;optimization problem;quadratic function;quadratic programming	Frantisek Mráz	1990	Computing	10.1007/BF02250640	mathematical optimization;combinatorics;mathematical analysis;mathematics;quadratic programming	ML	-97.03207442015152	35.940833693940675	33618
b6063ca0b9a07177c421a073f81cf33631193b53	über einige intervallarithmetische grundbegriffe		Die vorliegende Notiz betrifft einige grundlegende Begriffe der Intervallarithmetik, insbesondere die Definitionen„voneinander unabhängige Intervalle”, „abhängige Intervalle”, „voneinander abhängige Intervalle” und den Inhalt der erweiterten Intervallarithmetik selbst; man vergleicheApostolatos undKulisch, [1] und [2]. Diese Begriffe werden vom formalen Standpunkt aus untersucht und dabei in einen logisch befriedigenden Rahmen gestellt. Weiterhin wird eine in [1] aufgestellte Behauptung widerlegt. Es werden Hinweise auf formale Mehrdeutigkeiten gegeben, die einerseits durch eineIdentifizierung, anderseits durch einespezielle Darstellungsform rationaler Intervallfunktionen impliziert werden. In diesem Zusammenhang werden auch einige Forderungen an dieAbleitung einer Intervallfunktion erhoben. Im Anhang machen wir einen Vorschlag eines schärferen Aufbaues der einfachen und der erweiterten Intervallarithmetik. This paper is concerned with some basic notions of intervall arithmetic, particularly with the definitionsindependent intervals, dependent intervals, interdependent intervals, and with ideas of the extended interval arithmetic, cf.Apostolatos andKulisch, [1] and [2]. These notions will be investigated from a formal point of view and put into a logically satisfactory frame. We shall also demonstrate that the set of all intervals which aredependent on A and whose generating function is apoint function does not form a field, contrary to a theorem in [1]. Furthermore we shall consider two formal ambiguities resulting from a certainidentification as well as from aspecial form of representing rational interval functions. In this connection we shall also formulate several requirements that thederivative of an interval function should satisfy. In the appendix to the paper we shall propose a more precise and logically correct form of the simple and the extended interval arithmetic.	eine and zwei;interdependence;interval arithmetic;requirement	Helmut Ratschek	1969	Computing	10.1007/BF02236541	calculus;mathematics;algorithm	AI	-97.11864031966527	34.425259857062436	33974
f76f5ad548ad1af8a1b0846c620cab6ef5ff34b5	projekthafte entwicklung eines regelbasierten auswertungstools zur bestimmung der qualität von funktionalen anforderungen		Dieser Beitrag beschreibt die Erfahrungen von Lehrenden, welche bei einem Einsatz eines projektbasierten LehrLernarrangements im Bereich des Requirements Engineering mit Studierenden gesammelt werden konnten. Thematisiert werden, neben den Schwerpunkten des Projekts, die Ziele und Rahmenbedingungen der Umsetzung, sowie die eigentliche Durchführung. Es folgt eine abschließende Zusammenfassung des Projekts, in der die gewonnenen Erkenntnisse aus Sicht der Studierenden und Lehrenden dargestellt werden.	eine and zwei;requirements engineering	Alexander Bartel;Georg Hagel	2014			art;performance art	Crypto	-101.3615801735128	32.86617954767211	34267
116ace47a5207923123c7055f5e7399de5ee82f3	symplectic integration schemes for the abc flow	methode a pas;hamilton equation;hamilton s equations;integracion numerica;implementation;abc flow;methode runge kutta;metodo runge kutta;symplectic integrator;ejecucion;step method;numerical integration;ecuacion hamilton;equation hamilton;integration numerique;runge kutta method;integrateur symplectique;metodo a paso	Explicit symplectic integration schemes for the Arnold-Beltrami-Childress flows are presented and compared to a fourth order Runge-Kutta method. For moderate accuracy the symplectic schemes are more efficient for the calculation of stable orbits. The structure of the Hamiltonian prevents the implementation of symplectic methods with constant time steps. Es werden explizite symplektische Integrationsverfahren für Arnold-Beltrami-Childress Strömungen beschrieben und mit einer Runge-Kutta Methode vierte Ordnung verglichen. Für moderate Genauigkeit sind die symplektischen Verfahren leistungfähiger für die Berechnung stabiler Bahnen. Die Struktur der Hamilton-Funktion verhindert die Implementierung symplektischer Methoden mit konstanten Zeitschritten.	arnold tongue;die (integrated circuit);hamiltonian (quantum mechanics);runge–kutta methods;symplectic integrator;time complexity	Michael K. Tippett	1996	Computing	10.1007/BF02238358	symplectic manifold;mathematical analysis;runge–kutta methods;numerical integration;calculus;mathematics;geometry;semi-implicit euler method;leapfrog integration;implementation;symplectic integrator	DB	-96.106241219089	36.1647554510228	34371
742549de50e98f998d39908fea8b8bf6cc79b2c7	empirische ergebnisse zu big data		Der vorliegende Beitrag nähert sich dem Themenkreis Big Data auf der Basis unterschiedlicher empirischer Untersuchungen, die das Ziel verfolgen, das Themenfeld weiter auszuleuchten. Entsprechende Umfrageergebnisse liegen inzwischen in großer Vielfalt vor, was sicherlich durch dem immer noch existierenden Aufklärungsbedarf geschuldet ist, und wurden vor allem von Analysten und Produktherstellern publiziert. Die vorliegende Untersuchung konzentriert sich auf unterschiedliche unabhängige Studien zum Thema Big Data und hebt zentrale gleichartige sowie abweichende Ergebnisse in kondensierter Form hervor.	big data;die (integrated circuit);vhf omnidirectional range	Peter Gluchowski	2014	HMD Praxis der Wirtschaftsinformatik	10.1365/s40702-014-0037-9	library science;marketing;big data;engineering	DB	-101.04472422124276	35.40090005789543	34431
3788d06e3e66472d9f7628a3af43d7e884bc6189	projektmanagement spielend lernen		Um den Studierenden schon früh ein Gefühl für das Projektmanagement und den damit verbundenen Aufgaben und Probleme zu vermitteln, haben wir ein Spiel entwickelt, das auf dem Projektmanagementwerkzeug MS Project basiert. Unter Verwendung einer umfangreichen Simulation können damit die in MS Project erstellten Projektpläne simuliert werden. Die Studierenden können dadurch sofort erkennen, wie gut ihre Planung ist und wo Probleme auftreten. Ziel dabei ist es, den Studierenden eine Möglichkeit anzubieten, spielerisch und ohne Risiko verschiedene Projektmanagementstrategien unter verschiedenen Bedingungen auszuprobieren. Dabei können die Spieler alle in MS Project vorhandenen Funktionen und Werkzeuge nutzen. In diesem Beitrag beschreiben wir das Spiel in seinem Aufbau und Ablauf. Um unsere Arbeit besser bewerten zu können, haben wir das Spiel mittels einer Befragung evaluiert. Eine kurze Zusammenfassung dieser Evaluation findet sich am Ende dieses Beitrags.	eine and zwei;internet explorer;simulation;unified model	Alexander Nassal	2015				Logic	-105.3047527692804	32.354255558890166	34567
1c4ca7d271c37f901652071ca9223924237f0b2e	it-risikomanagement von cloud-dienstleistungen im kontext des it-sicherheitsgesetzes		Neben den Vorteilen von Cloud-Diensten ergeben sich durch ihren Einsatz häufig Risiken für die IT-Sicherheit von Unternehmen. Durch das am 12. Juni 2015 verabschiedete Gesetz zur Erhöhung der Sicherheit informationstechnischer Systeme sollen Betreiber Kritischer Infrastrukturen dazu verpflichtet werden, ihre IT besser vor Cyber-Attacken zu schützen. In diesem Kontext gilt es zu klären, welche Anforderungen Cloud-Betreiber als Dienstleister Kritischer Infrastrukturen umzusetzen haben oder inwiefern diese per Definition des IT-Sicherheitsgesetzes als Betreiber Kritischer Infrastrukturen angesehen werden können. Im Rahmen des IT-Risiko- und Sicherheitsmanagements bei Kritischen Infrastrukturen entstehen bei der Auslagerung von (zentralen) Prozessen und Funktionen zudem Unklarheiten, wie der Einsatz von Cloud-Dienstleistungen zu bewerten ist und welcher Handlungsbedarf auf die Cloud-Betreiber zukommt, zum Beispiel durch das geforderte Mindestsicherheitsniveau der IT-Systeme. In dem Beitrag werden ein Anforderungskatalog an Cloud-Dienstleistungen zur Umsetzung des IT-Sicherheitsgesetzes auf Grundlage von Experteninterviews entwickelt sowie Implikationen für das IT-Risikomanagement von Cloud-Dienstleistungen dargestellt. Abschließend werden Handlungsempfehlungen für Cloud-Betreiber und Betreiber Kritischer Infrastrukturen gegeben. Alongside the benefits of cloud computing IT security risks arise from the use of cloud services. The German act to increase the safety of information technology systems, which was issued on June 12, 2015, requires critical infrastructures to improve the protection of their IT against cyber-attacks. In this context, the requirements cloud operators have to implement as service providers of critical infrastructures, or whether they can be viewed as operators of critical infrastructures by definition of the IT security law, have to be clarified. Furthermore, concerning the IT risk management of critical infrastructures, questions arise when outsourcing (central) processes and functions to the cloud. Regarding this, the overall use of cloud services and the actions cloud operators have to take, for example in order to meet the required minimum level of safety of IT systems, have to be assessed. In this article, a requirements catalog for cloud services and service providers to implement the requirements of the IT security law is developed on the basis of expert interviews. Furthermore, implications for the IT risk management of cloud services and recommendations for cloud providers and critical infrastructures are presented.	3-methyl-2-oxobutanoate dehydrogenase (ferredoxin) activity;antilymphocyte serum;balbiani body;clarify;cloud computing;diethylstilbestrol;it risk management;international system of units;internet explorer;limited social function;outsourcing;radiology information systems;requirement;safety-net providers;tricyclic antidepressants tested for:prid:pt:ur:nar:screen;triple des;vhf omnidirectional range;zur protein, e coli;benefit	Michael Adelmeyer;Christopher Petrick;Frank Teuteberg	2016	HMD Praxis der Wirtschaftsinformatik	10.1365/s40702-016-0285-y	library science;knowledge management;engineering	Security	-100.19049867417466	34.58135097293435	35820
38269d6f991325298c50e4871dbf0480cab34bed	"""the user-generated state - von der informationsbereitstellung zu """"social collaboration"""""""		"""Mit der Verbreitung des Internets, der umfassenden Prasenz sozialer Medien und der damit einhergehenden Unterstutzung bestimmter Formen prosozialen Verhaltens werden kollaborative Produktions- und Entscheidungsprozesse als neue Werkzeuge des 21. Jahrhunderts diskutiert. Dieser Artikel gibt einen Uberblick uber die Trends, Bedingungen und Entwicklungen im Bereich """"Social Collaboration"""". Angesprochen werden Kollaborationsmodelle in einer vernetzten Gesellschaft sowie die Moglichkeiten, die sich fur Politik und Verwaltung aus dieser Perspektive stellen."""	social collaboration;user-generated content	Peter Parycek;Judith Schossböck	2012	Elektrotechnik und Informationstechnik	10.1007/s00502-012-0078-0		HCI	-104.65447962990677	37.40494847386142	36224
6f3677108bce63c678d1bd5d379813b21a9df584	toolunterstützung bei der vermarktungsorientierten entwicklung von web services als bausteine komplexer betrieblicher anwendungssysteme		Der Beitrag beschreibt die Notwendigkeit zur erweiterten Untersuchung von Vorgehensmodellen und Entwicklungs-Werkzeugen für den Web ServiceKontext, die sich aus der mangelnden Integrationsfähigkeit von Web Services ergibt, die von unabhängigen Organisationen entwickelt werden. Bei der Betrachtung von Web Services als Softwarekomponenten, deren formale oder informale Spezifikation zur ausgelagerten Entwicklung durch Dritte herangezogen werden kann, ergeben sich Möglichkeiten zum konkurrierenden Angebot dieser, woraus wiederum verschiedene Vorteile resultieren. Im Beitrag wird ein Vorgehensmodell zur ausgelagerten Entwicklung von Web Services beschrieben, deren Nutzung im Kontext komplexer betrieblicher Anwendungssysteme vorgesehen ist. Darauf aufbauend wird die Schaffung von Werkzeugen motiviert, die neben der Umsetzung des Vorgehensmodells ebenfalls die Interpretation und Erstellung von Web Service-Spezifikationen unterstützen. Zur zusammenfassenden Spezifikation sind unterschiedliche Standardtypen erforderlich, die sowohl funktionale als auch nichtfunktionale Eigenschaften beschreiben. Der Vermarktungsaspekt ist dabei jedoch bislang nur unzureichend behandelt worden. Es wird abschließend ein Prototyp zur werkzeuggestützten Entwicklung und Vermarktung von Web Services vorgestellt.	web service	Nico Brehm;Jorge Marx Gómez;Andreas Ziesenitz	2008				Web+IR	-102.48683369271	34.67744177436459	36353
dd9a441c6c6a193aab561d5ba804d241d4163ca0	frontends für führungskräfte — endlich zielgruppentauglich?		Die Zielgruppentauglichkeit von Führungsinformationssystemen (FIS) ergibt sich aus der Gegenüberstellung von Frontend-Fähigkeiten und Bedürfnissen bzw. Verhalten der Führungskräfte. Die Frontend-Werkzeuge werden gemäß ihren Schwerpunkten unterschiedlichen Kategorien zugeordnet. Die Führungskräfte lassen sich ihrerseits entsprechend ihrem Nutzungsverhalten in analytische Power User, opportunistische Analysten, generalistische Basisnutzer und faktische Nichtnutzer klassifizieren. Die existierenden Werkzeuge und mobilen Lösungen adressieren zentrale Anforderungen von Führungskräften, wie z.B. »Flexibilität in der Analyse« und »jederzeit Zugriff auf Informationen« und unterstützen somit im Wesentlichen die Zielgruppenkonformität.	gesellschaft für informatik;internet explorer;serial ata	Stefan Knopf;Felix Wortmann	2011	HMD Praxis der Wirtschaftsinformatik	10.1007/BF03340641	library science;knowledge management;engineering	DB	-103.21334945229913	33.02370164112731	36417
ce4454f9698e00caa939216615c44bda651027f4	inhalte und ergebnisse des verbundprojekts wissenswerkstatt rechensysteme (wwr)		Kurzfassung. Der vorliegende Beitrag gibt einen Überlick über das Verbundprojekt Wissenswerkstatt Rechensysteme (WWR), in dem ein Baukastensystem von multimedialen, skalierund rekombinierbaren Lehrund Lernmodule entwickelt wird. Anhand der Vorstellung beispielhafter Ergebnisse aus verschiedenen Bereichen des Projektes werden die Schwerpunkte der Projektarbeit vorgestellt. Zu den konzeptionellen Grundlagen des Vorhabens zählen ein innovatives dreidimensionales Modell, das die Skalierung der Materialien erlaubt, sowie dessen Umsetzung in der XML-basierten Sprache <ML>3. Primäre Produkte des Verbunds sind etwa 150 multimediale Lehrund Lernmodule zur Unterstützung von Vorlesung, Übung, Praktika und Selbstlernen, sowie eine große Zahl darin enthaltener Simulatoren und Medienobjekten. Darüber hinaus wurde begleitend ein umfangreiches Framework aus Werkzeugen für den gesamten Prozess der Erstellung, Evaluierung und Anwendung von Lehrund Lernmaterialien entwickelt.	bibliothèque de l'école des chartes;eine and zwei;v-model;xml	Lars Kornelsen;Ulrike Lucke;Djamshid Tavangarian;Denny Voigt;Matthias Waldhauer	2004	Softwaretechnik-Trends		software engineering;systems engineering;computer science	Crypto	-101.85428444326644	32.60287356152153	36549
68a85bd9c211cc2dd9126ca65abc6ba47155c745	photovoltaik - eine globale wachstumstechnologie		Entsprechend dem ,,BLUE Map‘‘-Szenario der Internationalen Energieagentur (IEA), das zur Erreichung der Emissionsreduktionsziele des International Panel for Climate Change (Globaler Temperaturanstieg limitiert auf 2,4 Grad) erforderlich ist, werden erneuerbare Energien im Jahr 2050 f€ ur 46 % der globalen Stromerzeugung sorgen. Photovoltaik wird dabei eine bedeutende Rolle spielen. Andere Szenarien sehen noch eine weit schnellere bzw. st€arkere Verbreitung der Photovoltaik. Die EPIA (Europea Photovoltaic Industry Association) sieht es als realistisch an, bereits im Jahr 2020 12 % des europ€aischen Strombedarfs durch Photovoltaik bereitzustellen. Die globale Entwicklung der Photovoltaik hat bislang nahezu alle Prognosen € ubertroffen. Die Steigerungsrate von 2008 gegen€ uber 2007 kletterte mit deutlich € uber 100 % (d. h. Marktverdoppelung) erstmals sogar auf einen dreistelligen Wert, was unserem Nachbar Deutschland beispielsweise einen Branchenumsatz von 7 Milliarden Euro bescherte. Viele Staaten sind mittlerweile dem deutschen Vorbild gefolgt und haben konsequente Markteinf€ uhrungsprogramme verabschiedet, die im Zeitraum bis zur Netzparit€at, d. h. der Kostengleichheit mit dem Verbraucherstrompreis, die Weichen f€ ur einen soliden Heimmarkt stellen sollen. Bereits heute arbeiten in der europ€aischen Photovoltaikindustrie etwa 100.000 Personen. Japan, traditionell eines der f€ uhrenden L€ander in der Photovoltaik, besch€aftigt sich mittlerweile bereits mit Gigawatt-Anlagen, wie der Beitrag von Keiichi Komoto darstellt, wobei die f€ ur Photovoltaik typische Dezentralit€at bei diesen Konzepten um die M€ oglichkeit der r€aumlich konzentrierten Kraftwerkskapazit€aten erg€anzt wird. F€ ur Technologiel€ander wie Deutschland, aber auch € Osterreich, bedeutet die Photovoltaik-Marktentwicklung auch eine besondere Chance f€ ur die produzierende Industrie, mit der Herstellung von Komponenten entlang der langen Wertsch€ opfungskette der Technologie einen entsprechenden Heimmarkt f€ ur innovative Produkte vorzufinden. Aus einer fr€ uhen Positionierung kann ein Wettbewerbsvorteil entstehen, der im global stark wachsenden Markt auch enorme Exportpotentiale er€ offnet. Neben der weltweit f€ uhrenden deutschen Photovoltaikindustrie haben sich aber auch € osterreichische Betriebe in diesem rasch wachsenden Weltmarkt – teilweise sogar in absoluten Spitzenbereichen – positioniert. Sei es in der Herstellung von Solar-Wechselrichtern, der hochqualitativen Folieneinkapselungen von Solarzellen oder komplexen Nachf€ uhreinrichtungen (Solar Tracker). Qualit€atssicherung und Pr€ ufung sind in der noch jungen Branche ein wesentlicher Erfolgsfaktor; laufend neue Technologieentwicklungen verleihen diesen wichtigen Aktivit€aten eine besondere Dynamik. Technologisch entwickeln sich Zellen und Module €außerst dynamisch, Wirkungsgrade von bis zu etwa 20 % bei marktf€ahigen Produkten stehen Spitzenwerten von derzeit bereits € uber 40 % in Forschungslabors gegen€ uber. D€ unnschichtzellen werden aufgrund des verringerten Einsatzes von teuren Grundmaterialien oftmals als die logische Weiterentwicklung angesehen, die kristallinen Technologien werden sich aber auch in den kommenden Jahren nicht wesentlich verdr€angen lassen. In den letzten Monaten sind aufgrund diverser Einfl€ usse generell stark sinkende Kosten zu beobachten. H€alt dieser Trend an, kann Photovoltaik schneller als vielfach erwartet den absoluten Durchbruch schaffen. Die nachfolgenden Fachbeitr€age sollen einen Einblick in die Entwicklungen der boomenden Photovoltaik-Technologieszene auf ihrem scheinbar unaufhaltsamen Weg zur Standardstromquelle geben.	blue gene;eine and zwei;epia;international ergonomics association;internet explorer;rasch model;solar tracker;the grid analysis and display system (grads);unified model	Hubert Fechner	2009	Elektrotechnik und Informationstechnik	10.1007/s00502-009-0663-z	control engineering;engineering;mechanical engineering	OS	-103.90317497407857	33.52719040153154	36822
998862e79a8650a477653b62c92c9ff1d58a2c79	a comparative performance evaluation of 27 nonlinear programming codes	computer program;performance evaluation;nonlinear programming;nonlinear optimization	The numerical performance of 27 computer programs, which are all designed to solve the general constrained nonlinear optimization problem, is to be evaluated. In contrast to Schittkowski [34], where besides of one exception, the same codes are compared on randomly generated test problems, the test examples are now given by the 115 hand-selected and real life problems published in Hock and Schittkowski [19]. The different type of the test examples requires the development of a special evaluation system based on priority theory. Detailed numerical results are presented allowing a quantitative comparison of the performance criteria efficiency and reliability. Es soll das Leistungsvermögen von 27 Computerprogrammen numerisch ermittelt werden, die alle zur Lösung des allgemeinen restringierten, nichtlinearen Optimierungsproblems entwickelt wurden. Im Gegensatz zu Schittkowski [34], wo bis auf eine Ausnahme dieselben Programme an Hand von zufallsmäßig erzeugten Testbeispielen verglichen wurden, sind die Testbeispiele jetzt die von Hock und Schittkowski [19] veröffentlichten 115 Optimierungsprobleme, die entweder per Hand konstruiert wurden oder einen praktischen Hintergrund besitzen. Die unterschiedliche Art dieser Testbeispiele erfordert die Entwicklung eines speziellen Auswertungssystems, das auf Prioritätstheorie basiert. Detaillierte numerische Resultate werden präsentiert, die einen quantitativen Vergleich der Leistungskriterien Effizienz und Zuverlässigkeit erlauben.	code;computer program;eine and zwei;mathematical optimization;nonlinear programming;nonlinear system;numerical analysis;optimization problem;performance evaluation;procedural generation;real life;triple des	W. Hock;Klaus Schittkowski	1983	Computing	10.1007/BF02242139	mathematical optimization;nonlinear programming;computer science;theoretical computer science;mathematics;algorithm	HPC	-98.44462024673174	35.17909894767553	37517
6428b7956a95c7b131266cedb95973f786e26170	architekturzentrierte software-entwicklung - elitäre technik-disziplin oder ökonomische notwendigkeit?		Der folgende Beitrag berichtet über Erfahrungen in der Nutzung einer Softwarearchitektur beim Aufbau neuer Anwendungssysteme in einer Versicherung. Nach kurzer Vorstellung der Architektur wird unter Betrachtung eines mehrjährigen Projektportfolios der „business case“ für die getätigten ArchitekturInvestitionen dargestellt.		Arno Schott	2004			software engineering;software;engineering	OS	-101.35949964775044	33.140321644866646	38011
1c6b2dc41f0440e9a2a15450800b763e9c141033	gesundheits-telematik — rechtliche antworten		Die rechtlichen Besonderheiten gesundheitstelematischer Anwendungen bieten oft Anlass zur Fehleinschätzung. So werden Aspekte des Datenschutzes auch dort problematisiert, wo es auf die Übermittlung personenbezogener Gesundheitsdaten nicht ankommt. Bei anderen Anwendungen — wie bei einer unzulässigen Delegation — werden rechtliche Risiken übersehen. Dieser Beitrag gibt einen Überblick über häufige Anwendungen in der Gesundheitstelematik und ihre rechtliche Einordnung..	bielefeld conspiracy;internet explorer	Christian Dierks	2006	Datenschutz und Datensicherheit - DuD	10.1007/s02045-006-0042-5	internet privacy;computer security;computer science	Crypto	-103.62141593956508	36.49047006340319	38771
6d5fecf0a049b60f2efd932b6393ee034e523694	informatik und neubau eines bürgebäudes - ein erfahrungsbericht über den neubau der hauptverwaltung der colonia versicherung ag in köln	neubau der hauptverwaltung der;colonia versicherung ag;ein erfahrungsbericht;ber den	Wer heute entscheidet, ein neues Verwaltungsgebaude zu errichten, steht unter anderem auch der Frage gegenuber, wie die Burokonzepte der Zukunft die Einsatzfahigkeit der neuen Gebaude beeinflussen werden. Die Szenarien, die diskutiert werden, sehen Moglichkeiten von der ausschlieslichen Heimarbeit uber “Weg von den Ballungsgebieten” bis hin zu der Aussage “Es wird sich gar nichts andern” vor. Als die Colonia Versicherungen in 1979 sich fur den Bau einer neuen Hauptverwaltung fur ca. 1.700 Mitarbeiter entschieden, war das Bild der elektronischen Zukunft noch unklarer als heute. Wir setzten damals zwei Pramissen, die wir auch heute noch als richtig und entscheidend ansehen: rnrnrnWir wollten grostmogliche Flexibilitat im baulichen Konzept, um auf die technologischen und organisatorischen Anderungen reagieren zu konnen.rnrnrnWir wollten nicht voreilig Technik einsetzen, aber alle organisatorischen Masnahmen durchfuhren, die im Hinblick auf die Konzepte der zukunftigen Technologien angemessen erschienen.		Friedrich K. Rauch	1986		10.1007/978-3-642-71380-4_3		NLP	-105.12567081354334	34.15141392134387	38904
67c22fdc4a5f483f3bf8a05885bc960627bbf596	e-business in der automobilzulieferindustrie - ein knebel für kmus?		E-Business ist für die Automobilund Automobilzulieferindustrie kein neues Phänomen mehr – im Gegenteil. Die Branche kann inzwischen auf einige Jahre der geschäftlichen Internet-Nutzung zurückblicken. Nicht zuletzt waren es die frühen Gründungen von branchenbezogenen, „vertikalen“ InternetPlattformen, die der Automobilherstellung den Ruf eines Vorreiters in Internet-Technologien verschafft haben. Die Gründungen der ersten Automobil bezogenen Internet-Marktplätze gelten als Meilensteine des E-Business; Namen wie Newtron, SupplyOn oder Covisint – alle in den Jahren 1998 bis 2000 gegründet – spielten und spielen eine wichtige Rolle für die Wahrnehmung des Internets, weit über die Zulieferindustrie hinaus.	eine and zwei;internet explorer;internets	Gernot Mühge;Hansjürgen Paul	2005	EMISA Forum		engineering management;systems engineering;electronic business;computer science	NLP	-101.50578405347188	34.24406402453217	38992
1a5ed2e64d0bc91d03979a356666a4fcd523b799	industrie 4.0	industrial internet	Industrie 4.0 wird den Industriestandort Deutschland upgraden. Bei der weiter zunehmenden internationalen Verflechtung der Handelsströme werden Automatisierung, Flexibilisierung sowie horizontale und vertikale Integration in einer modernen, konkurrenzfähigen Produktionsstruktur immer bedeutsamer. Speziell für Deutschland mit seinen besonders günstigen Grundvoraussetzungen bietet Industrie 4.0 längerfristig die große Chance, seine führende Position im globalen Wettbewerb zu sichern – auch gegenüber den schnell wachsenden Emerging Markets.	industry 4.0;mit/gnu scheme	Heiner Lasi;Peter Fettke;Hans-Georg Kemper;Thomas Feld;Michael Hoffmann	2014	Wirtschaftsinformatik	10.1007/s11576-014-0424-4		NLP	-102.2557270628263	33.58078204060761	39418
241a79e007ae3253963ace9a7a93905d7319e4ab	sind datenschutzbeauftragte zahnlose papiertiger?		Datenschutz erfordert eine effektive Datenschutzkontrolle. Im Beitrag ist dargestellt, welche Regelungen nötig sind, damit betriebliche und behördliche Datenschutzbeauftragte wirksam ihre Aufgabe erfüllen können. Die Verfasserin spricht sich für eine Stärkung der betrieblichen und behördlichen Datenschutzbeauftragten aus. Erforderlich seien zudem verpflichtende Regeluntersuchungen für automatisierte Verfahren der Verarbeitung von Personendaten in Anlehnung an die Untersuchungen für Dampfkessel und Kraftfahrzeuge.	eine and zwei;gesellschaft für informatik	Ingrid Pahlen-Brandt	2007	Datenschutz und Datensicherheit - DuD	10.1007/s11623-007-0007-2		NLP	-104.34667871938306	32.57270715369594	39500
69a5bea46a59811ddf3178fd733b44410ba6e642	"""elektronisches publizieren. mythen, leitbilder, visionen - und die """"wirklichkeit""""?"""		Der Beitrag versteht sich als Exposee und reflektiert verschiedene Möglichkeiten, das elektronische Publizieren Ausgang der 80er Jahre mit der heutigen Situation zu vergleichen. Ansätze, einen solchen Vergleich auf Mythen, Leitbilder und Visionen zu fokussieren, werden dargelegt. In der mündlichen Präsentation wird als Gegenstand „Hypertext“ aufgegriffen.	hypertext	Bernd Wingert;Ulrich Riehm	2003			performance art;history	NLP	-105.98638820936156	35.2187427137161	39761
d0339b615a7afe937922372f5491bc0852dd97ab	it und dienstleistungen für die energiewende und die elektromobilität (idee 2016)		der Workshop IT und Dienstleistungen für die Energiewende und die Elektromobilität (IDEE) fand bereits zum vierten Mal im Rahmen der GI-Jahrestagung statt. Der halbtägige Workshop am 30.09.2016 in Klagenfurt/Österreich wurde gemeinsam von Vertretern des Karlsruher Instituts für Technologie, der Universität Paderborn und der Westfälischen Wilhelms-Universität Münster veranstaltet und hatte die Entwicklung innovativer Informationssysteme und IT-gestützter Dienstleistungen für die Energiewende und die Elektromobilität sowie Methoden zur Entwicklung dieser Informationssysteme und Dienstleistungen zum Thema.	institut für dokumentologie und editorik	Gerhard Satzger;Daniel Beverungen;Martin Matzner;Carola Stryja	2015				NLP	-103.64045424331016	34.732509778447614	40031
f537949302ee78cf40baeaf6fa01f93b79cc14c1	erfolgsbedingungen für virtuelle selbstorganisierte lerngemeinschaften		Im virtuellen Umfeld von Hochschulen ist in letzter Zeit zunehmend ein Phänomen zu beobachten, das für die Zukunft von Bildungseinrichtungen von maßgeblicher Bedeutung sein könnte. Die Rede ist von selbstgesteuerten Lerngemeinschaften, die das Internet nutzen, um sich gegenseitig bei der Bewältigung des Studiums zu unterstützen. (Auf von Lehrenden didaktisch inszenierte Blended Learning Kurse wird im Rahmen dieses Beitrags nicht eingegangen.)	gesellschaft für informatik;unified model	Lotte Krisper-Ullyett;Max Harnoncourt;Paul Meinl	2005			multimedia;computer science	Theory	-103.0657339842771	33.005127945788416	40961
a2a5336caba3f0574537b3fb2e4b904ed3e33c0e	datenspuren bei der nutzung von digital rights management-systemen (drm)	digital right management	DRM-Systeme in aktuellen Shopan-wendungen werden in Bezug auf Kundendatenschutz untersucht. Beispielhaft werden die Systeme iTunes von Apple und der Windows Media Rights Manager von Microsoft analysiert. Die Analysestruktur folgt den gesetzlichen Datenschutzprinzipien. Daraus werden Empfehlungen für einen datenschutzfreundlicheren Umgang abgeleitet.	digital rights management;gesellschaft für informatik;windows media	Rüdiger Grimm;Stefan Puchta	2006	Datenschutz und Datensicherheit - DuD	10.1007/s11623-006-0022-8	computer science	AI	-102.92887883808831	37.30037758760997	41103
5dec14973160f94cfdeb0fb0b3652916bcb71a65	fehlerkultur à la ,,systemic overload“		"""Das ist irgendwie falsch aus-gedrückt: Man muss mit dem Unerwarteten umgehen und es als Innovator hervorprovozieren. Aber es gibt ja auch echte Fehler bei der Innovation – die stehen in jedem Buch: Man kümmert sich zu wenig um Märkte, Kunden, Wettbewerber und Finanzen, viele Innovatoren überschätzen sich selbst in ihrem Durchsetzungsvermögen oder haben vollkommen falsche Vorstellungen über ihr Unternehmen und dessen Managementprozesse. ,,Sie haben mir nur Steine in den Weg gelegt! Ich kann nichts dafür! """" Oder: ,,Alles ist gut, aber ich bekomme einfach kein Geld! In Amerika hätte ich Geld be-kommen, das sagen alle. Ich könnte heulen. """" Oder: ,,Da ist plötzlich eine andere Firma dagewesen, die wa-ren schneller, ich musste hier erst auf Genehmigungen warten. """" Das ist ,,LoserTalk """" von Leuten, die sich zu sehr mit ihrer Idee allein befas-sen; für sie kommt das feindliche"""	die (integrated circuit);eine and zwei;i/o controller hub;linear algebra;sie (file format);unified model;zentralblatt math	Gunter Dueck	2016	Informatik-Spektrum	10.1007/s00287-016-0960-y	world wide web;computer science;performance art	OS	-105.15487344134911	34.650281773663465	41188
52270ef4524c13a39bef73011acc8b7e1823b811	einfluss von umgebungsfaktoren, ergonomie und systemgestaltung auf den sicheren mobilen informationszugriff		Im Zuge der Modernisierung wird die Verwaltung zunehmend mobile Endgeräte einsetzen, um den Außendienst effizient zu unterstützen. Informationszugriff und -gewinnung vor Ort finden jedoch unter anderen Bedingungen statt als im Büro, woraus sich andere Anforderungen an Datenschutz und -sicherheit ergeben, die durch die Technikgestaltung gelöst werden müssen. Der Beitrag beschreibt die sich ergebenden Herausforderungen beim mobilen Informationszugriff sowie die mobile Dokumentation am Beispiel der Gewerbeaufsicht. 1 Informationszugriff und Dokumentation in der Gewerbeaufsicht Verwaltungshandeln ist insbesondere deshalb auf Information und Wissen angewiesen, weil für viele Entscheidungen Tatbestandsmerkmale einer Norm erfüllt sein müssen oder ein Ermessensspielraum besteht, zu dessen Ausübung Informationen über den gesamten Sachverhalt erforderlich sind. Information und Wissen stellen eine wesentliche Ressource der Arbeit eines Verwaltungsmitarbeiters dar, [WTL01] denn Verwaltungstätigkeit ist vor allem Informationsverarbeitung und ihre Prozesse sind hiervon stark geprägt [Le05, 43]. Wichtig für den vor Ort arbeitenden Verwaltungsmitarbeiter, z.B. einen Beamten der Gewerbeaufsicht, ist daher der Zugriff auf digital vorliegendes Wissen innerhalb der Verwaltung, wie Normen und Gesetze oder Angaben zu Betrieben. Außerdem werden kontinuierlich Informationen erhoben, verarbeitet und weitergegeben. Daher sind Produktund Prozessinnovationen in der Verwaltung sehr eng verknüpft. Das Zusammenwirken des Denkens in Geschäftsprozessen mit Potentialen der Informationstechnik und der Mobilisierung bietet die Möglichkeit, Verwaltungsverfahren hinsichtlich Qualität, Effektivität, Transparenz und Effizienz zu verbessern. Weitere Vorteile der Unterstützung der außendienstlichen Verwaltungstätigkeit durch mobile Endgeräte liegen im Wegfall von Mehrfacharbeiten (z.B. nachträgliche Digitalisierung erhobener Daten), der Fehlervermeidung bei Datenaufnahme, der Möglichkeit der unmittelbareren und abschließenden Beurteilung sowie der medienbruchfreien Bearbeitungsmöglichkeit. Vielfach führten jedoch Sicherheitsbedenken und praktische Hindernisse dazu, dass mobile	eine and zwei;internet explorer;open road tolling;unified model;vhf omnidirectional range	Angela Frankfurth;Michael Knopp	2006				OS	-106.2576868613401	33.99643196810088	41482
f415428a555959275884d46821e3c4830be4e392	security im produkt-lifecycle – lästige pflicht oder chance?		Die heute übliche vernetzte Struktur von Softwareprodukten und komplexe Kunden-Anbieter-Szenarien machen eine tiefgehende Beschäftigung mit dem Thema Security im Produktkontext unumgänglich. Ausgehend von der Frage, was Sicherheitseigenschaften von anderen Anforderungen unterscheidet, stellen wir in unserem Beitrag kurz die Methoden und Techniken vor, die für die Erhebung und das Monitoring von Sicherheitseigenschaften notwendig sind. Insgesamt plädieren wir für eine enge Integration von Sicherheitsbetrachtungen in die Aktivitäten des Produktlebenszyklus und zeigen die Chancen auf, die damit für den Qualitätsmanagementprozess insgesamt verbunden sind.	die (integrated circuit);eine and zwei;vhf omnidirectional range	Ruth Breu;Christian Sillaber;Michael Brunner	2015	Informatik-Spektrum	10.1007/s00287-015-0938-1	world wide web;computer science;performance art	DB	-103.19515186560065	34.93250453822154	41495
18656b02bd9a2443a993b8331021496ecf88afc0	modelle und wie man sie nutzt	sie nutzt;modelle und wie man	Was nützt die beste Kamera, wenn man sie nicht schnell zur Hand hat und die Bedienung kompliziert ist? Genau deshalb erfreuen sich Kompaktkameras mit integriertem Zoomobjektiv und einfachen Menüs hoher Beliebtheit. Zudem passen sie in jeden Hosensack. Die jüngste Generation der handlichen Knipser hat wieder einen Schritt nach vorn gemacht. Die Hersteller haben in ihren Minis Bewährtes verbessert und zusätzlich sinnvolle Funktionen integriert. Einige Kostproben: ultrakurze Auslöseverzögerung, Serienbildfunktionen,Weitwinkel, optischer Bildstabilisator sowie Gesichtsund Motiverkennung. Ausserdem hält erstmals HD-Video-Unterstützung (High Definition) mit einer Auflösung von 1280 x 720 Pixeln Einzug ins Kompaktlager. Insgesamt 6 der 10 Testkandidaten filmen hochauflösend. Alle Infos zu den Kameras sowie die Testergebnisse finden Sie in der Tabelle, S. 65.	die (integrated circuit);internet explorer;sie (file format)	Helmut Neunzert	1990		10.1007/978-3-642-76123-2_2		NLP	-105.62158056446056	33.31938686436527	42106
50c75797abfb0c08eab51a61ac6cc089df1c3ae0	bestimmung kostengünstiger standorte bei simultaner verbesserung der lager- und distributionspolitik	linear program	Diese Arbeit berichtet uber die Anwendung des Linear-Programming bei einer einmalig zu treffenden Management-Entscheidung. Die Entscheidungssituation, betriebswirtschaftliche und modelltechnische Aspekte sowie Erfahrungen beim Software-Einsatz werden dargestellt.		P. Goeck;K.-P. Schuster	1977	Math. Meth. of OR	10.1007/BF01918363	mathematical optimization;linear programming;mathematics	Logic	-98.29106159148648	35.31504836743458	42676
dfb0894db8df16bd3fce3cd5fb4686b54dddd68a	trusted channels and roots of trust in distributed embedded systems		Eingebettete Systeme werden zunehmend zur Automatisierung sicherheitskritischer Infrastrukturen eingesetzt. Typische Beispiele sind die Steuerung von Industrieanlagen, Heimautomatisierung, aber auch medizinische Implantate und Bordelektronik moderner Autos. Mit zunehmender Kritikalitat und Komplexitat sind solche Systeme aber auch zunehmend attraktive Ziele fur Angreifer.rnrnThema dieser Dissertation sind Losungen fur Trusted Computing-Funktionalitaten in verteilten eingebetteten Systemen. Speziell untersuchen wir effiziente Mechanismen zur Etablierung von Vertrauen und vertrauenswurdigen Kommunikationskanalen fur Systeme mit geringer Rechen- und Speicherkapazitat.rnrnHierzu wurden Technologien entwickelt, erweitert und analysiert, mit denen Teilnehmer sich gegenseitig ihrer Systemintegritat versichern und in vertrauenswurdigen virtuellen Netzwerken kommunizieren konnen.	embedded system	Steffen Schulz	2016			operating system;trusted computing;computer science	Embedded	-104.49415054741559	36.099866032248876	42704
8495fb72d63c9e3326ff05c567b890cf0644c270	überprüfung der gebrauchstauglichkeit von anwendungssoftware		Für die überprüfung der Gebrauchstauglichkeit von Anwendungssoftware steht eine Vielzahl von Methoden zur Verfügung. Eine Studie aus dem Jahr 2011 zeigt jedoch, dass 49 % der KMU in Deutschland diese Methoden nicht kennen. Dieser Beitrag dient dazu, die vorhandene Wissenslücke zu schließen, und stellt einen überblick der zentralen Methoden zur Verfügung. Den Ergebnissen dieses Beitrags liegen eine Literatur-sowie Marktanalyse zugrunde. Abschließend erfolgt eine exemplarische Integration von Methoden in den User-Centered-Design-Prozess.	eine and zwei	Boris Böttcher;Markus Nüttgens	2013	HMD Praxis der Wirtschaftsinformatik	10.1007/BF03342065	knowledge management;engineering;performance art	Vision	-103.71919465919655	33.03533683528235	42740
934e6ddde5542627c1fac967b212e19353259ed0	rechtsprobleme des identitätsmanagements		Die Diskussion um Bürgerportale und De-Mail ist verbunden mit der Hoffnung, ein rechtlich zulässiges, allseits akzeptiertes und leicht nutzbares elektronisches Identitätsmanagement zu realisieren. Der Beitrag umschreibt den Rechtsrahmen, zeigt Pro bleme auf und diskutiert mögliche Lösungen.	unified model	Sönke E. Schulz	2009	Datenschutz und Datensicherheit - DuD	10.1007/s11623-009-0157-5	internet privacy;computer science	NLP	-103.83739349541925	36.478195863271694	43114
f2100453cd509400fe20b354c0a6e67408be14db	dauerbrenner bdsg-novellierung		Die Novellierung des BDSG in der 17. Legislaturperiode des Deutschen Bundestags ist praktisch unausweichlich und dringend nötig. Dabei sollten nicht die Fehler der letzten Jahre gemacht werden. Der Beitrag stellt die Novellierung des Datenschutzrechtes in einen größeren grundrechtlichen Kontext und macht praktische Vorschläge für die politische Umsetzung.		Thilo Weichert	2010	Datenschutz und Datensicherheit - DuD	10.1007/s11623-010-0004-8	computer science;internet privacy	Crypto	-103.7934718717953	36.16729725802618	43429
c96b4d0bd768c80e241b5067d7d2bcccc2f5c4bd	media streaming systeme an der friedrich-schiller-universität jena	media streaming	Seit Entwicklung des Teleteaching Systems 1997 und dem Bau eines modernen Multimediazentrums 1999 wurden die multimedialen Technologien und Systeme an der FriedrichSchiller-Universität Jena stets weiterentwickelt [1][2]. Jüngstes Kind dieser Entwicklung ist ein komplexes System zum Video Streaming von universitären Veranstaltungen, basierend auf moderner Studiound Hörsaaltechnik, digitalen (stationären und mobilen) Encodern, Videoservern und der Anbindung an eine digitale Bibliothek. Gegenwärtig sind über 600 Vorlesungen, Vorträge von wissenschaftlichen Kongressen oder Workshops, medizinische Lehrvideos sowie Videos von allgemeinem Interesse im WWW verfügbar. Seit zwei Jahren im Projektstatus, erfreut sich das System bei Studenten, Wissenschaftlern und (dank DSL) auch zunehmend bei der breiten Öffentlichkeit einer wachsenden Beliebtheit. Wie die Zugriffsstatistiken zeigen, ist auch die internationale Resonanz beachtlich. Dieser Beitrag zeigt die technischen Grundlagen und organisatorischen Voraussetzungen, die für den Betrieb eines solchen Systems notwendig sind.	digital subscriber line;eine and zwei;institut für dokumentologie und editorik;internet explorer;www	Tino Tschiesche;Olaf Götz	2004	Praxis der Informationsverarbeitung und Kommunikation	10.1515/PIKO.2004.116	computer science	OS	-105.13207979700017	36.67059794275031	43437
41d0380ba640d1db357508fb5810a6d2be8a7114	on the convergence of some methods for determining zeros of order-convex operators	convergence theorem;banach space;word order;operator equation;linear space;partial order	LetF:X→Y be an order-convex operator, whereX, Y are partially ordered Banach spaces. Two related methods for the solution ofF(x)=0 are discussed, one of which has been studied by Pasquali (see [2]) and the other by Wolfe [12]. Existence-convergence theorems for the methods are given, and these are illustrated with the aid of example. Some remarks are also made on a method due to Traub [7] which has also been discussed by Wolfe [12]. SeiF:X→Y ein ordnungskonvexer Operator, woX, Y halbgeordnete Banachräume sind. Es werden zwei verwandte Verfahren zur Lösung der GleichungF(x)=0 diskutiert, von denen eines schon von Pasquali beschrieben worden ist (s. [2]), das andere von Wolfe [12]. Existenz- und Konvergenzsätze für diese Verfahren sind dargestellt und mit Hilfe von Beispielen illustriert. Ferner liegen einige Bemerkungen über ein Verfahren von Traub vor, das auch schon von Wolfe diskutiert worden ist [12].	convex function;eine and zwei;vhf omnidirectional range	M. A. Wolfe	1981	Computing	10.1007/BF02243422	partially ordered set;word order;mathematical optimization;mathematical analysis;discrete mathematics;mathematics;geometry;banach space;linear space	DB	-96.73238038083815	35.31221909113681	43468
fc94a17adc060f695960fe73b0d4fe781162857f	agil in großen organisationen: eine neue rolle im scrum-framework		Scrum ist zunächst definiert für einzelne Teams und ist auf dieser Ebene gut erprobt und weit verbreitet. Die Realität zeigt jedoch den Bedarf, das agile Framework auch im Konzern-Kontext zur Anwendung zu bringen. Und große Organisationen erhoffen sich die Agilität einer Kleinen. Die Anwendung von Scrum in großen Organisationen mit einer Vielzahl von Teams ist jedoch weit weniger gut beschrieben. Nach Scrum soll die Rolle des Product Owners explizit durch eine einzige Person und nicht durch ein Komitee wahrgenommen werden. Diese Singularität erschwert eine Skalierung von Scrum, zumal der Product Owner neben der Wertmaximierung des Produkts eine Fülle weiterer Aufgaben verantwortet. Der Product Owner wird so schon früh bei der Skalierung zum Engpass; entstehende Wartezeiten sind kontraproduktiv und widersprechen der „Lean“-Idee. Zur Lösungsfindung wird ein Vorgehen entsprechend Goldratt’s Theory of Constraints [Go90] aufgegriffen. Diesem Prinzip folgend werden mit wachsender Größe der Organisation verschiedene Lösungen diskutiert, die den Engpass „Product Owner“ jeweils voll auslasten und dann beseitigen. Zur finalen Beseitigung des Engpasses wird die Verteilung der Verantwortlichkeiten auf zwei Rollen vorgeschlagen: Der Product Owner übernimmt nur noch die Verantwortung für die Anforderungspriorisierung während eine weitere Rolle, der „Story Owner“, für die Detailausgestaltung und Klärung jeweils einer Story zuständig aber nicht einem festen Team zugeordnet ist. Der Story Owner lässt sich beliebig skalieren. Dieser Vorschlag folgt in Form von Delegation und Empowerment Prinzipien aus dem „Lean“-Konzept.	agile software development;eine and zwei;scrum (software development)	Patrick Daut	2014			sociology;performance art;scrum	OS	-101.67260460787162	33.44690013644293	43497
0bf69428177d0e0870a29c7683e0b5603402d718	entwicklung einer architektur zum schutz der privatsphäre bei der nutzung von kontextbezogenen diensten im mobilen umfeld		"""Die Nutzung von ortsbezogenen Diensten birgt für den Benutzer Risiken, da er mit der Positionsinformation, besonders, wenn er diese kontinuierlich bereitstellt, einem Dienstanbieter sensible Informationen überlässt. Anhand dieser sensiblen Informationen kann ggf. auf seine Identität, seine persönlichen Einstellungen oder Gewohnheiten geschlossen werden. Aktuell besitzen die Benutzer bei Diensten, die im Mobilfunknetz oder über spezielle """"Apps"""" bereitgestellt werden, noch nicht die notwendige Transparenz, um entscheiden zu können, ob der Dienstanbieter vertrauenswürdig ist. Es besteht immer das Risiko, dass seine sensiblen Daten neben der Diensterbringung noch für weitere Zwecke verwendet werden. Der Benutzer besitzt aktuell noch keine geeigneten Möglichkeiten, sein Recht auf informationelle Selbstbestimmung ausreichend wahrzunehmen. Problematisch ist dies dann, wenn der Anbieter die bereitgestellten Daten als Datensammlung verkaufen würde. Informationen darüber erhält der Benutzer nur anhand der AGB. Dieser Text eignet sich jedoch vom Umfang her nicht für das mobile Umfeld und von der Form her nicht zum Benutzerkreis. Zudem existieren auf dem Markt aktuell noch Akteure, die eine marktbeherrschende Position besitzen. Sie können darüber entscheiden, welche Anbieter, welche Dienste in welcher Form bereitstellen dürfen, so dass der Benutzer nur unter vorbestimmten Anbietern und Diensten wählen kann. Die zukünftige Entwicklung wird zu kontextbezogenen Diensten führen. Es handelt sich dabei um ein personalisiertes Dienstangebot, das die Situation des Benutzers mittels unterschiedlicher personenbezogener Informationen berücksichtigt. Ortsbezogene Dienste stellen dabei eine einfache Form von kontextbezogenen Diensten dar. Die Berücksichtigung unterschiedlicher Kontextinformationen führt dazu, dass mehr sensible Informationen bei einer Dienstbereitstellung anfallen. Dadurch erhält der Anbieter einen tieferen Einblick in die Privatsphäre des Nutzers. Daher benötigt der Benutzer geeignete Methoden, um seine Privatsphäre zu schützen. Im Rahmen dieser Arbeit wurde eine Architektur konzipiert und prototypisch implementiert, durch die dem Benutzer Ansätze und Mechanismen bereitgestellt werden, mit denen er seine Privatsphäre bei der Nutzung von kontextbezogenen Diensten schützen kann. Diese Architektur ist so gestaltet, dass die Bereitstellung der Funktionen und Dienste in eine Vielzahl von Instanzen aufgegliedert ist, so dass alle Akteure nur die minimal notwendigen Informationen erhalten und somit bei einer anonymisierten Nutzung nicht auf die Identität des Benutzers schließen können. Zudem besitzt keine Instanz innerhalb der Architektur eine marktbeherrschende Position, so dass ein freier Wettbewerb zwischen den Dienstanbietern entsteht. Der Benutzer erhält eine ausreichende Transparenz, um vertrauenswürdige Dienstanbieter zu erkennen und auszuwählen. Bei der Entwicklung der Architektur wurde ein offener Ansatz gewählt, so dass Kontextinformationen modular aus unterschiedlichen Quellen integriert werden können. Zudem existieren Instanzen zum Auffinden von ortsbezogenen Diensten und ein einheitliches Konzept zur Zahlung von kostenpflichtigen Diensten ist ebenfalls vorhanden. Dem Benutzer werden bei diesem Architekturansatz vielfältige Mechanismen bereitgestellt, um sein Recht auf informationelle Selbstbestimmung wahrzunehmen und so seine sensiblen Informationen zu schützen. Developing an Architecture for Privacy Protection by using Contextual Services in a Mobile Environment"""	citeseerx;eine and zwei;sie (file format);unified model	Stefan Stein	2010				OS	-103.77847149946619	37.44931528147552	43577
24f9b23e399d4557fee4a107af1b7b2a74d96384	kooperatives arbeiten im kontext wechselnder anwendungen		Computerunterstutztes kooperatives Arbeiten erleichtert es, mit mehreren Personen an verschiedenen Orten uber ein Problem zu diskutieren. Die Informationen zu dem Problem werden dabei mit Hilfe des Computers verwaltet und konnen aus verschiedenen Modalitaten zusammengesetzt sein (Text, Graphiken, Bilder).		Andreas Barth;A. J. Hewett;Peter Jensch	1992		10.1007/978-3-642-77810-0_35		Vision	-105.24426615550284	33.25564962837566	43697
da7c996753b48693355104d8c7a57b16c859d723	ip-telefonie und firewalls, probleme und lösungen	security policy	Kurzfassung Im Rahmen einer umfassenden Security-Policy stellen Firewall-Systeme eine wichtige Maßnahme zum Schutz eines privaten Netzes vor Angriffen aus dem Internet dar. Durch die Einführung neuer Applikationstypen, zu denen auch IP-Telefonie Applikationen gehören, ergeben sich neue Anforderungen denen ein Firewall-System gerecht werden muß. Diesen neuen Anforderungen werden existierende Firewall-Systeme nicht gerecht, weshalb IP-Telefonie Applikationen von Firewalls zur Zeit nicht zufriedenstellend unterstützt werden können. In diesem Beitrag werden wir zeigen, welche speziellen Probleme sich bei der Integration von IP-Telefonie Unterstützung in eine Firewall ergeben. Dazu werden wir ausgewählte, von einer Firewall zu unterstützenden Telefonieszenarien, erläutern, sowie ausgewählte vorhandene Firewall-Lösungen und ihre existierenden Beschränkungen beschreiben. Nachdem die Probleme identifiziert und klassifiziert sind, werden wir die daraus resultierenden Anforderungen, denen eine IP-Telefonie fähige Firewall gerecht werden muß, herleiten. Abschließend werden wir eine mögliche technische Umsetzung dieser Anforderungen, sowie den entsprechenden realisierten Prototypen beschreiben.	eine and zwei;firewall (computing);vhf omnidirectional range	Utz Roedig;Ralf Ackermann;Ralf Steinmetz	2001	Praxis der Informationsverarbeitung und Kommunikation	10.1515/PIKO.2001.32	computer science;security policy;computer security	OS	-103.29745342502244	37.22002028927781	43867
d3f3a3015ddae7b25c5cead6b9a4f7aa66b75ae5	einsatz einer datenorientierten entwurfsmethode in der prozeßrechnerpraxis	der proze	In den letzten Jahren haben sich datenorientierte Entwurfsmethoden in vielen Anwendungsfallen durchgesetzt. Es sind lehrbare und praktisch anwendbare Methoden erarbeitet worden. Diese Methoden basieren stark auf Gedankengangen und Datenverstandnis der kommerziellen Datenverarbeitung.		Max Herzog;Bernd Kühnel	1981		10.1007/978-3-642-67977-3_12		Vision	-104.27596085796945	33.169362463996116	44207
16572b28701ee52ae79aba5925a807d0eed71e59	web 2.0: konzepte, technologie, anwendungen		128 Millionen — das ist die Zahl, die Google als Treffer zum Suchbegriff «Web 2.0» zu Beginn des Jahres 2007 meldete. Neben der Fachpresse sind es die Wirtschafts- und Nachrichtenmagazine, ja selbst Frauenzeitschriften, die von einer Revolution im Internet sprechen. Zur Popularität von Web 2.0 haben im Wesentlichen zwei Phänomene beigetragen: Erstens das groβe Bedürfnis von Menschen, sich mithilfe des Internets auszutauschen, sowie zweitens der Ansatzpunkt, das WWW nicht mehr vorrangig als Informationsplattform, sondern als eine interaktive Plattform ähnlich dem PC-Desktop zu konzipieren. Während die einen noch überlegen, was daran revolutionär ist, profitieren bereits andere von den vielfältigen persönlichen und geschäftlichen Möglichkeiten.	eine and zwei;internet explorer;internets;triple des;www;web 2.0;world wide web	Astrid Beck	2007	HMD Praxis der Wirtschaftsinformatik	10.1007/BF03340282	marketing;world wide web;engineering;web 2.0	DB	-104.06153608338533	36.869995677838354	44281
3839646660529ec95b0f13551a7f9599a77be0cf	mitteilungen der schweizer informatik gesellschaft / 2_2014		Fachgruppe Cloud-Computing – GovCloud.CH Programm Die ZHAW ist mit anderen Fachhochschulen sowie diversen Industrie-Unternehmen am GovCloud.CH Programm beteiligt. Dieses Programm ist für die Umsetzung der Cloud-Computing Strategie der Schweizer Behörden zuständig und wird vom Informatiksteuerorgan des Bundes (IBS) geführt. Weitere Informationen zum Programm können unter folgenden Adresse gefunden werden: www.isb.admin.ch/themen/projekte_ programme.	cloud computing;industry 4.0;triple des	Bernhard M. Hämmerli	2014	Informatik-Spektrum	10.1007/s00287-014-0782-8	world wide web;software engineering;computer science	Crypto	-101.39169167989914	35.66690904448324	44290
6c0c12b778123affd83ac266eb7323a8462a5ecc	relevanz und messung von sense of community im virtuellen kontext		Ein ständig wachsender Zweig der Innovationsforschung versucht die Dynamik innerhalb von virtuellen Communities besser zu verstehen. Das Konzept Sense of Community (SOC), das in OfflineCommunities das Verhalten von Mitgliedern erklärt, leistet einen Beitrag zu diesem Verständnis und wird als Gefühl einer Verbundenheit mit der Gruppe und deren Mitgliedern beschrieben. Da dieses Konzept bisher noch nicht im virtuellen Kontext erprobt wurde, zielt dieser Aufsatz darauf ab folgende Fragestellungen zu beantworten: Entwickeln auch Mitglieder in virtuellen Communities einen „Sense of (Virtual) Community” (SOVC)? Kann SOVC mit Hilfe des Sense of Community Index 2 (SCI2) sinnvoll gemessen werden? Unsere Ergebnisse aus einer deutschen virtuellen Community für Senioren zeigen, dass auch Online-Communities einen Sense of Virtual Community entwickeln. Das von Chavis et al. entwickelte Instrument SCI2 kann zwar prinzipiell zur Messung dieses Konzepts verwendet werden, sollte jedoch stärker an den Online-Kontext und die Virtualität der Beziehungen angepasst werden. Insbesondere die Skala „Einfluss“ bedarf diesbezüglich einer Überarbeitung um zur Messung von SOVC herangezogen werden zu können. Acknowledgement: Wir danken den Teilnehmerinnen und Teilnehmern von feierabend.de für die Unterstützung bei dieser Studie und zwei anonymen Reviewern für wertvolle Hinweise zur Überarbeitung des Beitrags	eine and zwei;unified model;virtual community	Dagmar Abfalter;Melanie E. Zaglia;Julia Mueller;Florian Kraler	2011			gender studies;sense of community;sociology	NLP	-104.96387579803093	37.51653419686159	44433
9521474779a9f6fb45a939c1e99a827d6e1d0216	versuch einer lerndefinition für automaten ii			apple ii series	Dieter Barthel	1971	Elektronische Informationsverarbeitung und Kybernetik		pure mathematics;combinatorics;mathematics	NLP	-95.50343043002788	34.31820896894392	44572
3d44b9b894174781ae5b357f207676a5a53c2644	aufgaben und lösungswege für die datenverarbeitung in einem forschüngszentrum		Als zentrale Dienstleistungseinrichtung fur wissenschaftlich-technische Aufgabenstellungen versorgt das Rechenzentrum der GSI die am Forschungs- und Entwicklungsprogramm der GSI beteiligten Arbeitsgruppen mit dem DV-spezifischen Leistungs- und Funktionsspektrum. Als Grosforschungseinrichtung der Bundesrepublik Deutschland und des Landes Hessen (Finanzierung 9:1) betreibt GSI mehrere Grosgerate, darunter den zur Zeit leistungsfahigsten Schwerionenbeschleuniger UNILAC (Universal Linear Accelerator).		Hagen Hultzsch	1983		10.1007/978-3-642-69034-1_14	nuclear physics;universal linear accelerator;computer science	Crypto	-104.63935938678752	33.52175820868542	44825
17d5ee02a1c68eebbb95ac40ff57959b69bd6ca3	dvb-t-c-s digitales fernsehen über antenne, kabel und satellit, mhp echtzeitübertragung im digitalen fernsehen		Die Verteilsysteme fur den Rundfunk werden digitalisiert. Der Bericht beschaftigt sich mit der ubertragungstechnik fur das digitale Fernsehen uber Antenne, Kabel und Satellit. Dabei konnen sowohl Bilder, Ton als auch digitale Datendienste in Echtzeit an alle Empfanger im Empfangsbereich gleichzeitig verteilt werden. Diese digitale Verteiltechnologie ist kabelgebunden und kabellos fur Punkt-zu-Multipunkt Kommunikation einsetzbar. Als Ruckkanalsystem konnen ebenso kabelgebundene wie kabellose Individualkommunikationssysteme verwendet werden. Die Konvergenz aus Rundfunk und Mobilfunk wird die Zukunft beeinflussen. Die Rundfunk-Verteilsysteme werden zunehmend beeinflusst durch die Entwicklung im Internet. So findet man in neuen Entwicklungen immer die Option, an verschiedenen Stellen des ubertragungssystems IP-Schichten zu verwenden. Aktuelle Weiterentwicklungen von DVB (DVB-H, DVB-S2) rundet den Beitrag ab.	digital video broadcasting;television	Andreas Sieber	2006		10.1007/978-3-540-68217-2_2	dvb-t;telecommunications;digital video broadcasting;art	NLP	-105.48756029989937	34.39776432057703	44890
b99a95980c46c542d799bcfa7c03af8ba1aaa9e5	die ermittlung von rasterkoordination und deren genauigkeit	ermittlung von	Zur Messung der Verformungen bzw. der Kontur von technischen Bauteilen setzt man zunehmend optische Ganzfeldverfahren ein, da diese eine flachenhafte Information beruhrungsfrei in einem groseren Bereich der betrachteten Oberflache liefern. Fur sehr kleine Verformungen verwendet man holografische oder interferometrische Verfahren, wahrend man grosere Verformungen und Konturen bevorzugt mit Rastermethoden bestimmt. Hierzu bringt man auf die Oberflache des Objekts einen festen oder projizierten Raster auf, nimmt den Raster in verschiedenen Verformungsstufen oder aus verschiedenen Richtungen auf und ermittelt anschliesend die Rasterkoordinaten im Negativ. Mit nachverarbeitenden Programmen lassen sich daraus die gesuchten physikalischen Grosen berechnen.		K. Andresen;B. Morche	1988		10.1007/978-3-662-08895-1_38	art;performance art	Vision	-104.75833621922824	33.808669686890944	45567
52aba353f686f10408497cd37ddc473a9e1a7e95	erzeugung von huffman-sequenzen mit hoher energieeffizienz	erzeugung von	Huffman-Sequenzen sind zeitdiskrete Sequenzen, deren aperiodische Autokorrelationsfunktion in allen Nebenwerten, auser dem letzten, den Wert Null hat. Konstruktionsmethoden zur Erzeugung von Huffman-Sequenzen mit den hochsten Energieeffizienzen sind nicht bekannt. Daher werden reell- und komplexwertige Huffman-Sequenzen mit den hochstmoglichen Energieeffizienzen durch vollstandige Suche erzeugt. Die Ergebnisse der Suche sind in einer Tabelle angegeben.	huffman coding	Leopold Bömer;G. Nikol;Markus Antweiler	1990		10.1007/978-3-642-76062-4_54	algorithm;huffman coding;computer science	Crypto	-106.14399654567036	32.60647074128924	45969
3b93a3dff59858466ef77cc9bb28a418151f7476	algorithmus 41 ein algorithmus zum vollständigen durchlaufen eines ungerichteten, zusammenhängenden graphen		Der Algorithmus zum vollständigen Durchlaufen eines Graphen basiert auf dem Prinzip des Ariadnefadens. Ausgehend von einem Knoten wird der Graph so lange systematisch durchlaufen, bis alle Knoten mindestens einmal und alle Kanten genau zweimal berücksichtigt worden sind. Der Algorithmus arbeitet mitO(m), m=Anzahl der Kanten. The algorithm for the traversal of an undirected, connected graph is based on the principle of the thread of Ariadne. Starting with a node the algorithm handels the graph systematically until all nodes are reached at least once and all arcs traversed exactly twice. The complexity isO (m), m=number of edges.	algorithm;connectivity (graph theory);graph (discrete mathematics);graph theory;integrated circuit layout design protection;tree traversal	K.-P. Kugler;Uwe Pape	1980	Computing	10.1007/BF02281731	algorithm;mathematics;mathematical analysis;graph	Theory	-99.31979101104062	38.13364096661196	47485
d0ff2f1dc856ca871a6609e4cfab080fd5df3c25	relationale cloud-datenbanken, ein aktueller vergleich	cloud computing	Als wichtiger Bestandteil von Anwendungssystemen sind Datenbanken in der IT allgegenwärtig. Die zunehmende Bedeutung des Cloud Computing lässt auch in diesem Bereich neue Produkte und Dienstleistungen entstehen, die eine Verlagerung von Datenbanken in die Cloud ermöglichen. Der vorliegende Artikel zeigt die Gegebenheiten bei dem Betrieb einer relationalen Cloud-Datenbank auf und wendet diese in einem Vergleich abschließend an. Dabei werden mit den relationalen Datenbankdiensten von Microsoft SQL Azure und Amazon RDS die derzeit dominierenden Alternativen betrachtet und auf ihre Tauglichkeit für den Praxiseinsatz hin untersucht.	cloud computing;die (integrated circuit);eine and zwei;microsoft azure;microsoft sql server	René Bröcker;Johannes Tiemeyer	2010	Informatik-Spektrum	10.1007/s00287-010-0489-4	cloud computing;computer science	OS	-102.1966387127126	36.03755254057623	47639
b779af87be3484b25e173320ff627e39b606dc34	ein funktionalanalytischer beweis des maximumprinzips von pontrjagin und dessen verwendung zur herleitung der politikiteration von howard		Der umfangreiche, auf geometrische Überlegungen gründende Beweis des Maximumprinzips vonPontrjagin läßt sich vollständig durch funktionalanalytische Herleitungen ersetzen: anstelle der totalen Ableitung von Prozeß und Zielfunktional bei der direkten Methode sind hier nur die partiellen Ableitungen in Richtung der Zustandsvariablen nötig, während die Differenz in Richtung der Steuerungen nicht linearisiert wird. Die Kozustandsvariablen sind Hilfsgrößen, die zur Umformung eines Skalarproduktes dienen. (Sie ergeben sich als Lösung einer linearen Gleichung, deren Operator durch die Adjungierte zur partiellen Ableitung des Prozeßoperators gegeben ist und deren rechte Seite das teillinearisierte Zielfunktional bildet.) Dabei erhält man die bekannte Ungleichung der Hamiltonfunktionen, deren Gültigkeitsbereich in einem Widerspruchsbeweis globalisiert wird. Dieser funktionalanalytische Beweis ist kürzer, konstruktiver und allgemeiner: so ergibt sich die Politikiteration vonHoward als Anwendung des Maximumprinzips auf bewertete stationäre Markovprozesse. The tedious proof ofPontrjagin's maximum principle, based on geometric considerations, can be fully replaced by methods of functional analysis: instead of complete differentiation of the process and the objective functional in the direct method, only partial derivation in direction of state variables are used, while the difference in direction of the control is not linearized. The costate variables furnish a means to transform an innerproduct. (They are the solution of a linear equation whose operator is the adjoint of the partial derivative of the process operator and whose right side is formed by the partial linearized objective functional.) As result we obtain the wellknown unequality of the Hamiltonians, whose domain of validity is globalized in a proof by contradiction. This proof by methods of functional analysis is more concise, constructive and more general: application of the maximal principle to ergodic Marcovprocesses with rewards results inHoward's method of policy iteration.	citeseerx;direct method in the calculus of variations;ergodicity;iteration;linear equation;markov decision process;maximal set;sie (file format)	K. Spremann	1972	Computing	10.1007/BF02241608	calculus;mathematics;mathematical analysis	Logic	-96.88194947864763	35.54911015181973	48238
c51f168d43a2d869682eaac8a4e7d363c9f69b6d	sorgfaltspflichten im umgang mit passwörtern		Viele Dienste im Internet verlangen für die Benutzung ein Passwort. Im Umgang mit Passwörtern treffen sowohl die Nutzer als auch die Diensteanbieter Sorgfaltspflichten. Der Beitrag geht der Frage nach, welche Sorgfaltspflichten bestehen. Dazu werden die gängigen Angriffsmethoden und die daraus folgenden Sicherheitsvorkehrungen dargestellt.		Bernd Lorenz	2013	Datenschutz und Datensicherheit - DuD	10.1007/s11623-013-0082-5	computer science;the internet;internet privacy	ML	-103.90580921092126	36.43005971608741	48685
a11020db87d1aec7d6053dd9dc734c3fa818fb22	mass customization für it-dienstleistungen realisieren	mass customization	"""Die Entwicklung und kontinuierliche Innovation von IT-Dienstleistungen, beispielsweise der Betrieb von Anwendungssystemen und entsprechender Anwender-Support, ist heute noch wenig systematisiert. Oft sind die IT-Dienstleistungen monolithisch und relativ starr. Wir stellen einen methodischen Ansatz vor, wie komplexe IT-Dienstleistungen aus Komponenten aufgebaut werden können. Eine solche Plattformstrategie verspricht, im Sinne von Mass Custmization kundenspezifische Dienstleistungen anbieten zu können. Die systemgestützte Konfiguration neu komponierter Dienstleistungen enthält nicht-triviale Probleme, die durch Methoden der Wissensrepräsentation gelöst werden können. 1 IT-Dienstleistungen Innovation entsteht bei IT-Betreibern, indem das Dienstleistungsangebot kontinuierlich an den Anforderungen der Kunden ausgerichtet wird. Das strategische Portfoliomanagement wacht darüber, dass die angebotenen Dienstleistungen aufeinander abgestimmt sind, dagegen ist das Produktmanagement für den Lebenszyklus der einzelnen Dienstleistungen verantwortlich. Soweit unterscheidet sich das Geschäft eines IT-Dienstleisters nicht von anderen Branchen. Die Besonderheit bei der Entwicklung von Dienstleistungen liegt in der mangelnden Greifbarkeit. """"Den Betrachtungsgegenstand begriffen bzw. wahrgenommen zu haben, ist jedoch eine Grundvoraussetzung für die effiziente Gestaltung von Dienstleistungen"""" [ML02]. Im Fall von IT-Services wird aus diesem Grund fälschlicherweise oftmals das Greifbare, nämlich die physikalische Infrastruktur, mit der Dienstleistung gleichgesetzt. Dienstleistungen lassen sich durch vier Komponenten Beschreiben: (1) das Produktmodell, das ist die Spezifikation der Dienstleistung, (2) ein Prozessmodell, (3) ein Ressourcenmodell, und (4) ein Marketingkonzept. Letztgenanntes beinhaltet insbesondere Kundeninteraktionsmodelle und wird damit der Forderung aus [Br02] gerecht, dass speziell bei Dienstleistungen der Kunde stärker in den Erbringungsprozess eingebunden werden muss. Informationstechnologische Infrastruktur zählt neben """"Human Resources"""" und Betriebsmitteln zu den Ressourcen. Sie ist offensichtlich zwar ein wichtiger, aber doch nur ein Teil der Dienstleistung. Der von uns vorgeschlagene Ansatz, die IT-Dienstleistung greifbar zu machen, ist die systemgestützte Modellierung aller relevanten Bestandteile der IT-Dienstleistung."""	die (integrated circuit);eine and zwei;internet explorer;sie (file format);vhf omnidirectional range	Tonio Grawe;Klaus-Peter Fähnrich	2003			art;performance art	OS	-102.63906088526204	33.52138755512517	48718
b58a4f69d5187cd4f89979edc90afcc4645f8f6c	audioschnitt in digitalen noten		Trotz der inzwischen vollständig digitalen Aufnahme und Nachbearbeitung von Musik wird speziell bei Produktionen klassischer Musik in der Regel zusätzlich mit gedruckten Notenmaterialien gearbeitet. Dieser Bruch in der Medienverwendung führt bei der Nachbearbeitung des Audiomaterials zu Zeitverlusten, da stetig zwischen Computerbildschirm und Papiernoten gewechselt werden muss. Es wurde ein Lösungsansatz entwickelt, der diesen Medienbruch umgeht. Aufgenommenes Audiomaterial und die Darstellung digitaler Noten auf dem Computer werden dabei synchronisiert. In der Praxis wird dadurch die Navigation innerhalb der Aufnahmeprojekte effektiv beschleunigt. Eine Vorstudie konnte zeigen, dass die Zeit für das Auffinden von Audio-Positionen anhand von Noteneintragungen – eine während des Schnitts häufig wiederkehrende Aufgabe – um durchschnittlich 79% gesenkt wurde.		Simon Waloschek	2017		10.18420/in2017_13		OS	-105.39792100094365	32.410174558451914	48880
9fd925c95a540a39408cb7f28917326453bcc716	die gratwanderung zwischen qualitativ hochwertigen und einfach zu erstellenden domänenspezifischen textanalysen		Die Textanalyse ist zu einem entscheidenden Werkzeug in verschiedenen Domänen wie den Geisteswissenschaften, Naturwissenschaften sowie auch in der Industrie geworden. Eine der größten Herausforderungen bei domänenspezifischen Textanalyseprojekten besteht darin, das Wissen aus den Bereichen IT und Text Mining mit dem Wissen aus der Domäne zusammenzubringen. Viele Textanalysetoolkits werden deshalb speziell für den Gebrauch durch Domänenexperten ohne oder mit wenig IT und Textanalysewissen vereinfacht. In diesem Beitrag diskutieren wir, inwiefern diese Vereinfachungen zu Qualitätsproblemen bei der Analyse von unsauberen Daten führen können.	die (integrated circuit);eine and zwei;internet explorer;text mining	Cornelia Kiefer	2017				ML	-104.3601109311908	33.03870046673061	48890
fef42ba8df3d90a802b908206916f31bd6586829	mpeg-2 transport stream analyzer for digital television	pid;tdt;broadcast transport stream;tmcc;sdt;pat;analyzer;nit;pmt;transport stream	The present article describes the creation of a MPEG-2 Transport Stream (TS)/Broadcast Transport Stream (BTS) Analyzer for Digital Television. This analyzer recognizes TS and BTS files in a decimal or hexadecimal format and it shows the components of the PSI (Program Service Information)/SI (Service Information) Tables, such as: Program Association Table (PAT), Program Map Table (PMT), Network Information Table (NIT), and Service Descriptor Table (SDT); in the case of the BTS files it also shows the content of the Transmission and Multiplexing Configuration (TMCC) table. The software has a package search system where you can look for a package through his PID (Program Identification) number or his package number. It also allows surfing between all the packages or the packages with the same PID number.	attribute-value system;broadcast television systems inc.;fire emblem: path of radiance;hexadecimal;isdb;linear algebra;mpeg transport stream;mpeg-2;multiplexing;naruto shippuden: clash of ninja revolution 3;pid;process identifier;service description table;syntax-directed translation;time-domain reflectometry	Gonzalo F. Olmedo;Nelson Benavides;Freddy R. Acosta;Nancy Paredes	2016	2016 35th International Conference of the Chilean Computer Science Society (SCCC)	10.1109/SCCC.2016.7836052	embedded system;computer hardware;computer science;operating system	SE	-100.77420092450001	39.08717166975493	49013
04204b3f42e622fab13bea4d0a45e7d655d99969	die rolle der informatik im gesellschaftlichen diskurs: eine neupositionierung der informatik		Entwicklungen im Bereich der Informations- und Kommunikationstechnologie führen derzeit zu fundamentalen Umwälzungen der Gesellschaft. Eine Beschleunigung des Lebens und das Verschwimmen von Beruf und Privatleben sind nur zwei Beispiele hierfür. Ein Abweichen von dem gesellschaftlichen Ideal des mobilen, jungen und dynamischen Mitarbeiters erweist sich häufig als Weg in das Einsiedlerdasein eines Exoten. Ein Widerstreben gegen die wachsenden Begehrlichkeiten von Wirtschaft und Staat lässt das Individuum verdächtig erscheinen und kann zu einer weiteren Entkopplung aus der Gesellschaft führen. Eine entscheidende Aufgabe bei gesellschaftlichen Umwälzungen ist die der Reflexion und Kritik. Diese Rolle scheint mehr und mehr den Juristen zuzukommen. Insbesondere beim Thema Datenschutz erfolgt häufig eine Reduktion auf die Verfassungskonformität einzelner staatlicher Maßnahmen. Kritik sollte jedoch bereits weit früher geübt werden. Medien sollten diese zentrale Funktion unterstützen und der politische Diskurs sollte zu einer optimalen Lösung führen. Eine Gruppe, die in der Debatte viel beitragen könnte und müsste, wird häufig, wenn überhaupt, aufgrund ihres technischen Sachverstandes herangezogen – die Informatiker. Dies ist insbesondere verwunderlich, da Informatiker maßgeblich an der Veränderung der Gesellschaft beteiligt sind. Sie schaffen die technischen Grundlagen für neue Formen der Interaktion. Doch das daraus resultierende Bild der Informatik als Computerwissenschaft beraubt Informatiker ihrer gesellschaftskritischen Funktion, da sie auf die Rolle von Technikern reduziert werden. Eine Positionierung und Darstellung der Informatik als Struktur- und Koordinationswissenschaft sowie der Informatiker als interdisziplinäre Systementwickler und -analytiker würde es Informatikern ermöglichen die bedeutende Rolle der Gesellschaftskritiker einzunehmen und gehört zu werden.	eine and zwei;genetic editing;gesellschaft für informatik;intentionally blank page;sie (file format)	Timo Glaser	2009	Informatik-Spektrum	10.1007/s00287-009-0324-y	world wide web;computer science;performance art	OS	-105.9129200662832	33.73786935480906	49253
64408a112a0450623e64278ae399e47882f314d2	datenschutzrechtliche einwilligungen		Datenschutzrechtliche Einwilligungen zur Erfassung und Weitergabe persönlicher Daten dienen vielen Herren und vielen Zwecken, aber selten der Klärung von Kommunikationsbeziehungen. Was folgt, wenn die betroffene Person die Einwilligung ablehnt? Muss sie dann Nachteile hinnehmen? Lässt das Gesetz die Datenerhebung dennoch zu? Der Beitrag geht diesen Fragen an konkreten Fallbeispielen nach.	sie (file format)	Hans-Joachim Menzel	2008	Datenschutz und Datensicherheit - DuD	10.1007/s11623-008-0096-6		NLP	-104.92786917937019	33.676605023019064	49383
32084f884e4a7bceeef7f9c469b9f8ee09e4ceb2	ein umfassendes ganzheitliches modell für evaluation und akzeptanzanalysen von informationsdiensten: das information service evaluation (ise) modell		Informationsdienste werden heutzutage von großen Teilen der Bevölkerung im Berufswie im Privatleben genutzt. Es ist ein wichtiges informationswissenschaftliches Thema, Informationsdienste adäquat zu beschreiben und ihre Qualität zu bewerten. Unser Information Service Evaluation (ISE) Modell führt unterschiedliche Traditionen der Evaluationssowie der Technologieakzeptanzforschung zusammen und besteht aus fünf Dimensionen: Qualität des Informationsdienstes, Nutzer, Informationsakzeptanz, Informationsumfeld und Zeit. Der Überblicksartikel erläutert diese Dimension und bietet einen Einblick in ein flexibel handhabbares und umfassendes holistisches Modell der Beschreibung und Bewertung von Informationsdiensten.	american and british english spelling differences;v-model	Laura Schumann;Wolfgang G. Stock	2014	Inf. Wiss. & Praxis	10.1515/iwp-2014-0043	software engineering;business	OS	-102.83988174521252	33.48383462256644	49616
00acd44df7fe365c3fbb7eed96f1298ab50a43f8	on the convergence of a rule by monegato for the numerical evaluation of cauchy principal value integrals	convergence theorem;quadrature;convergence;cuadratura;polinomio legendre;legendre polynomial;convergencia;estimation erreur;error estimation;integral cauchy;estimacion error;formula cuadratura;quadrature formula;quadrature rule;polynome legendre;integrale cauchy;formule quadrature;large classes;cauchy integral	In this paper the authors examine the convergence of an interpolatory type quadrature rule proposed by G. Monegato for the evaluation of Cauchy principal value integrals. A convergence theorem is given for a large class of functions and some estimates of the remainder are established. In dieser Arbeit wird die Konvergenz einer von G. Monegato eingeführten Interpolations-Quadraturformel für die Auswertung Cauchyscher Hauptwertintegrale untersucht. Die Autoren geben ein Konvergenztheorem für eine große Klasse von Funktionen an sowie Abschätzungen für das Restglied.	eine and zwei;interpolation;numerical analysis	Claudia Chiodo;Giuliana Criscuolo	1988	Computing	10.1007/BF02242190	cauchy problem;mathematical optimization;mathematical analysis;cauchy's integral theorem;convergence;legendre polynomials;quadrature;cauchy condensation test;residue theorem;modes of convergence;calculus;cauchy's convergence test;mathematics;convergence tests;cauchy principal value;integral test for convergence;normal convergence;order of integration;cauchy's integral formula	ML	-96.38981886944217	35.974941459977074	49882
d9d1abcb4a12b9a2de40ea263c450fd0900b3cb7	televise: mobile elektronische unterstützung für den tutoriell begleiteten übungsbetrieb im fach mathematik		Zusammenfassung: Die Ausbildung im Fach Mathematik stellt in vielen ingenieurtechnischen Fachrichtungen, speziell an Fachhochschulen, eine permanente Herausforderung dar. Vorkenntnisse, Motivation und Leistungen der Studierenden weisen ein breites Spektrum auf. Zur Vermittlung praxisrelevanter Mathematikkenntnisse auf hohem Niveau erweist sich Frontalunterricht alleine in der Regel als nicht ausreichend. Ziel des Projekts teleVISE ist es, eine inhaltlich-technisch-organisatorische Infrastruktur zur Intensivierung des veranstaltungsbegleitenden Übungsbetriebs im Fach Mathematik an der Hochschule Bremen aufzubauen, deren technische Unterstützung aus einer speziellen internetbasierten Lehrund Lernumgebung besteht.	eine and zwei;fach	Heide-Rose Vatterrott;Jörn Loviscach;Barbara Grüter;Thomas Risse;Ulrike Wilkens	2003					-104.48927166664829	32.39589282067367	50103
7cafe66892b531b1b9dba6db0e457414560c612d	detektion und verfolgung mehrerer objekte in bildfolgen		Bei der automatischen Uberwachung und Analyse des Strasenverkehrs werden Informationen benotigt, z. B. die Anzahl der Fahrzeuge, deren Geschwindigkeit, die Besetzungsdichte der Fahrspuren, die mittlere Geschwindigkeit auf den Spuren, die Haufigkeit von Spurwechseln, die Anzahl der PKW und LKW. Diese Informationen konnen von den bekannten Mesmethoden wie Induktionsschleifen und Lichtschranken z. T. nur mit grosem Aufwand erhalten werden. Im vorliegenden Beitrag wird deshalb eine Methode zur Auswertung von TV-Bildfolgen des Verkehrsgeschehens vorgeschlagen, mit der diese Informationen zu einem grosen Teil gewonnen werden konnen. Fur eine Ubersicht uber Methoden der Bildfolgenverarbeitung siehe /1/.		C.-K. Sung;Georg Zimmermann	1986		10.1007/978-3-642-71387-3_32		NLP	-104.96079965459923	32.50170479026303	50176
40a51985e8e6162bb8a7904369e1cef8be24eef3	exponential-fitting methods for the numerical integration of the fourth-order differential equation y iv +f·y=g	differential equation;numerical integration	A class of multistep methods is derived from the Chebyshevian multistep theory of Lyche for the numerical integration of the fourth-order differential equation of the formy IV +f·y=g. The new methods are significantly more accurate than the classical methods iff(x) is a nearly constant function. Für die numerische Integration der Differentialgleichungy IV +f·y=g wird mittels der Chebyshev-Multisteptheorie von Lyche eine Klasse von Mehrschrittverfahren hergeleitet. Die neuen Methoden sind bedetend genauer als die klassischen Methoden wennf(x) eine annähernd konstante Funktion ist.	constant function;die (integrated circuit);eine and zwei;linear multistep method;numerical analysis;numerical integration	A. Raptis	1980	Computing	10.1007/BF02281728	mathematical optimization;mathematical analysis;numerical integration;calculus;mathematics;differential equation	Theory	-96.37978052706576	35.90477941806413	50185
97615c0a79fd36e9973780729ef0e22a6d07b5af	linucs - eine notation zur unterstützung von repräsentation und retrieval spezieller chemischer strukturen		Structure-oriented retrieval is an essential feature of substance information systems. Chemists most often perform standard retrieval projects on their own and therefore prefer user surfaces that allow input according to chemical notation rather than requiring knowledge of special retrieval languages. SWEETDB, a glycosubstance information system, offers structure retrieval by using an input matrix that is fully conform to IUPAC nomenclature. A structure parser converts graphical 2D structure input into linear notation that is used for storage and graph matching. 1 Die LINUCS-Notation im Kontext der SWEET-DB Die SWEET-DB [Loß2002] ist ein Substanzinformationssystem, das Molekülstrukturen einer bestimmten Substanzklasse enthält (Kohlenhydrate). Diese Spezialisierung erlaubt den Gebrauch entsprechender Notationen, die effiDieses Dokument wird unter folgender creative commons Lizenz veröffentlicht: http://creativecommons.org/licenses/by-nc-nd/2.0/de/ 395 Elke Lang, Andreas Bohne-Lang, Claus-Wilhelm von der Lieth, Alexander Loß zienter sind als substanzklassenunabhängige Beschreibungsverfahren. Derartige Spezialnotationen haben sich z.B. für die Deskription und Suche von Proteinsequenzen eingebürgert [Berman2000]. Seit einiger Zeit werden Versuche unternommen, ein derartiges Verfahren auch für Kohlenhydrate zu entwickeln, wobei deren höhere strukturelle Komplexität, vor allem die Verzweigung, erhebliche Schwierigkeiten verursacht [Laine1994]. Die meisten Verfahren verlangen über die Standard-Nomenklatur [IUPAC1997] hinaus die Einhaltung weiterer Konventionen [Engelsen1996]. Die LINUCS-Notation [Lieth2001] bietet die Möglichkeit, Suchstrukturvorgaben mit einer Eingabematrix zu erstellen, in die wie gewohnt zweidimensionale (verzweigte) Strukturgraphen eingetragen werden können, die aus Monomertypund Bindungstyp-Elementen kombiniert werden. Der LINUCS-Parser wird zum einen verwendet, um bei der Aufnahme neuer Substanzdatensätze deren lineare Strukturnotation als Speicherformat zu erzeugen. Zum anderen wandelt er bei der Struktursuche die graphisch erstellte Strukturvorgabe in die lineare Notation um. Diese wird anschließend zum Graphvergleich benutzt. Die LINUCS-Notation ist durch ihre lineare Form rechnergeeignet und ermöglicht eine schnelle Struktursuche; auch Ähnlichkeitsund Teilstruktursuche sind möglich. Bei der Aufnahme neuer Daten bietet LINUCS die Möglichkeit, neu aufgenommene Strukturen auf Plausibilität zu untersuchen. Das LINUCS-Verfahren und die SWEET-DB sind unter http://www.dkfzheidelberg.de/spec/ zugänglich, dort sind auch einführende Beispiele zu finden.	eine and zwei;graphical user interface;information system;intentionally blank page;internet explorer;matching (graph theory);parser;unified model;vhf omnidirectional range	Elke Lang;Andreas Bohne-Lang;Claus-Wilhelm von der Lieth;Alexander Loß	2002				AI	-106.66473473123047	35.168418529657494	50211
358a1f3ceddaff40c8f27c4fa23e0748ec6e91b1	toolunterstützte transformation fachkonzeptioneller verwaltungsprozesse mit der bflow toolbox.		Verwaltungsleistungen werden zunehmend über das Internet nachgefragt. Diese Entwicklung wird durch die EU-Dienstleistungsrichtlinie weiter verstärkt, die eine elektronische Abwicklung behördlicher Genehmigungsverfahren auch „aus der Ferne“ fordert. Durchgehend elektronische Prozesse sind jedoch in der öffentlichen Verwaltung die Ausnahme; Medienbrüche innerhalb der Prozessabläufe dagegen die Regel. Die Integration komplexer Verwaltungsprozesse in dynamische Workflows erfordert bereits auf der Ebene der fachkonzeptionellen Modellierung die Erhebung von transformationsrelevanten Informationen, die für eine spätere (Teil-)Automation der Prozesse erforderlich sind. Der Beitrag beschreibt einen Ansatz, wie auf Basis objektorientierter ereignisgesteuerter Prozessketten (oEPK), unter Einbeziehung von WSDL-Datenkonzepten, die Grundlage für eine durchgängige Prozessautomation gelegt werden kann. Auf Basis der bflow*Toolbox werden die dazu notwendigen Transformationsschritte dargestellt und prototypisch angewandt.	eine and zwei;internet explorer;web services description language	Beate van Kempen;Frank Hogrebe;Astrid Schranz	2010			computational science;toolbox;computer science	OS	-102.4008016124686	34.18751585696509	50267
bd3b0aabb6785ac1d25715a59b80284b5ea84629	vorgehensmodelle in deutschland: eine kurze diskussion über nutzen, qualität und reife		Aktuelle Studien zeigen, dass der „Stand der Praxis“ in Deutschland bezüglich der Verbreitung und Anwendung von Softwareentwicklungs-Vorgehensmodellen von hoher Disziplin und gleichzeitig von fehlendem Payoff in Form erfolgreicher Projekte geprägt ist. Daher ist ein besseres Verständnis der Qualität und Reife von Vorgehensmodellen dringend nötig. Dieser Beitrag formuliert einige Ansätze für eine erweiterte Sichtweise auf diese beiden Aspekte. 1 Vorgehensmodelle in der deutschen Software-Industrie Seit den frühen Initiativen zur Strukturierung des Softwareentwicklungsprozesses, u.a. durch die Pionierarbeiten von Boehm, hat sich eine breite Fülle an Vorgehensmodellen entwickelt. Von „schwergewichtig“ à la V-Modell 97 bis hin zu „agilen“ Methoden haben sich mehr oder weniger stark formalisierte und unterschiedlich detailliert beschriebene Verfahrensanweisungen und Prozessvorgaben entwickelt. Eine in diesem Jahr durchgeführte Umfrage unter deutschen Software-Unternehmen zeigt, dass Vorgehensmodelle von 87% der befragten Firmen, unabhängig von deren Größe, eingesetzt werden [FK07]. In 73,9% der Unternehmen gab es in den letzten beiden Jahren Schulungen zum jeweiligen Vorgehensmodell oder zum Entwicklungsprozess allgemein. Fast alle befragten Organisationen kontrollieren die Einhaltung ihres Vorgehensmodells, sei es durch Projekt-Assessments, Reviews oder gar durch Project Control Offices o.ä. Dass bemerkenswerte zwei Drittel in den letzten 12 Monaten IstAnalysen des Entwicklungsprozesses durchgeführt haben, mag angesichts der oben genannten Zahlen nicht überraschen. So positiv diese Zahlen sind, so niederschmetternd sind die regelmäßig publizierten Studien über die schlechten Ergebnisse von Software-Projekten. Dass diese leider auch für die deutsche Software-Industrie gelten, hat die 2006 erschienene SUCCESS-Studie gezeigt [BEJ06].	altran praxis;citeseerx;eine and zwei;gab;linear algebra;mag technology co.;opengl es;v-model	Patrick Keil	2007			performance art;history	OS	-104.49000338789871	34.05041978475884	50339
e3dd4bd373bfa49e970351260697c7180deabc52	effekt des metawissens beim kollaborativen aufbau eines informationspools	soziales dilemma;informationspool;social dilemma;shared database;information pool;metawissen;geteilte datenbank;public good;metaknowledge	Zusammenfassung. In Organisationen ermoglicht der Einsatz einer geteilten Datenbank den kollaborativen Aufbau eines Informationspools. Die Entscheidung des Einzelnen, eigenes Wissen in eine Datenbank einzugeben, stellt ein offentliches-Gut-Dilemma dar. Jede Person spart Zeit und Kosten, wenn sie keine Information in die Datenbank eingibt, wenn aber alle Personen so verfahren, bleibt die Datenbank leer und fur alle nutzlos. Dieses Dilemma wird durch die hohe Anonymitat der Datenbanksituation verstarkt, in der Personen uber nur wenig prospektives Metawissen (Wissen uber die Wichtigkeit ihrer Information fur andere) und retrospektives Metawissen (Wissen uber das Verhalten der anderen Gruppenmitglieder) verfugen. In zwei Experimenten wird der Einfluss dieser beiden Faktoren untersucht. Es zeigt sich, dass prospektives Metawissen die Qualitat der Datenbankinhalte beeinflusst, wahrend retrospektives Metawissen Auswirkungen auf die Quantitat der Inhalte hat.		Ulrike Cress	2005	Zeitschrift für Medienpsychologie	10.1026/1617-6383.17.4.147	public good;social dilemma	Crypto	-101.78214750569508	35.15601865517129	50475
a33a362533de7d6823fe4557b484d2f92949b515	dynamic force fields zur präzisionserhöhung von zeigegeräten	inproceedings;talk	Joystick-gestützte Zeigegeräte finden sich in vielen mobilen Informationssystemen, beispielsweise in Smartphones oder auch in Fahrzeugen. Sie sind auf engstem Raum in Systeme integrierbar und hierdurch äußerst flexibel einsetzbar. Sie unterstützen sowohl die Navigation in klassischen Menüstrukturen, wie sie in diesen Szenarien häufig vorzufinden sind, als auch die Steuerung eines Zeigers, beispielsweise für die Interaktion mit Webseiten. Im Vergleich zu Touchpads und -screens sind Joystickgestützte Zeigegeräte auch blind greifbar, mechanisch manipulierbar und bieten spürbare Wiederstände. Durch die Beschränkung auf zumeist 8 digitale Richtungen reduzieren sich jedoch die Präzision und der Bedienkomfort, gerade bei der Steuerung eines Zeigers. In diesem Beitrag wird eine Technik vorgestellt, die durch Analyse der dargestellten Benutzeroberfläche die Präzision und den Bedienkomfort von indirekten Zeigegeräten wie Joysticks signifikant erhöht. Hierzu wird die Nutzerbewegung des Zeigers durch dynamische Kraftfelder so beeinflusst, dass einzelne Oberflächenelemente schneller und fehlerfreier angesteuert werden können, ohne dass die Beeinflussung der Zeigerbewegung als störend empfunden wird. Vor allem bei komplexen Oberflächen mit vielen, gleichzeitig sichtbaren Elementen ist eine möglichst störungsund irritationsarme Optimierungstechnik von Vorteil. In einem kontrollierten Experiment konnte eine Verbesserung der Usability durch die Dynamic Force Fields statistisch nachgewiesen werden.	eine and zwei;internet explorer;joystick;parity (physics);sie (file format);smartphone;touchpad;usability;vhf omnidirectional range	Marcus Specht;Andrea Söter;Jens Gerken;Hans-Christian Jetter;Lorenz Bohrer;Harald Reiterer	2010			art;performance art	HCI	-107.65441632778234	32.918268363269206	50478
089502000ddf3cd88cf0f0ebd880f75d9eed6a49	rechtliche grundlagen für den einsatz betrieblicher elektronischer archivierungssysteme		Problemstellung und Zielsetzung Jeder Unternehmer ist zur Archivierung von betrieblichen Unterlagen verpflichtet. Unterlagen müssen u. U. bis zu 30 Jahre aufbewahrt werden. Über die Art und Weise der Archivierung bestehen keine einschlägige gesetzliche Vorschriften. Elektronische Archivierungssysteme eröffnen erhebliche Rationalisierungsund Kostenreduzierungspotentiale und sind eine wichtige Voraussetzung für eine Büroautomation. Insbesondere sind schnellere Zugriffszeiten, gezielte Suchmöglichkeit nach Dokumenteninhalten, elektronische Weiterverarbeitungsmöglichkeit (z.B. in Workflowmanagement-Systeme) sowie erhebliche Reduzierung von Lagerkosten1 zu nennen. Um diese Potentiale zu nutzen, sind einerseits gesetzliche Vorschriften einzuhalten und andererseits rechtlichen Risiken vorzubeugen. Neben der Aufbewahrung auf Papier oder Mikrofilm bietet sich die Möglichkeit der Archivierung auf elektronischen Speichermedien. Es stehen im wesentlichen folgende digitale Datenträger zur Verfügung: (1) Magnetband, z. B. DAT2, DLT; (2) Diskette; (3) Festplatte; (4) optical und magneto-optical Disc (CD, WORM, DVD). Hinsichtlich deren rechtlicher Zulässigkeit und den zu erfüllenden Anforderungen zur Ordnungsmäßigkeit des Aufbewahrungsverfahrens besteht jedoch häufig Unsicherheit. Daher werden im folgenden die zu beachtenden gesetzlichen Bestimmungen aufgezeigt und unter Einbeziehung von fachlichen Stellungnahmen für den Einsatz von elektronischen Archivierungssystemen interpretiert. Um eine branchenunabhängige Sichtweise zu wahren, werden hierbei die Vorschriften aus HGB, BGB, AO, ZPO und BDSG berücksichtigt. Ziel dieses Beitrags ist es, rechtliche Anforderungen an die elektronische Archivierung allgemein aufzuzeigen und die daraus resultierenden Konsequenzen für den Einsatz alternativer Speichermedien zu untersuchen. Zu diesem Zweck wird zunächst die rechtliche Zulässigkeit alternativer Datenträger belegt. Darauf aufbauend sollen die rechtlichen Anforderungen an das Archivierungsverfahren in den verfahrenstypischen Abschnitten Transformation, Aufbewahrung und Wiedergabe analysiert werden. Notwendig ist auch die Erläuterung der Forderungen	dlt;eine and zwei;floppy disk;système universitaire de documentation;unified model	J. Baader;M. Philipp	1997					-105.19611260258246	34.35695774797314	50571
1c8b7a11dd979733c8169b124cf09c4c71a2ce36	halbleiter als innovationsmotor im auto		In der mehr als 100-jährigen Automobilgeschichte sind besonders die letzten 30 Jahre gekennzeichnet durch eine stürmische Entwicklung vom überwiegend mechanischen Auto zu einem hoch komplexen, elektro-mechanischen System. Servolenkung, Airbags oder ABS sind aus modernen Autos gar nicht mehr wegzudenken. Trotz aller Fortschritte in der Automobilelektronik steht ihre Verbreitung immer noch relativ am Anfang. 90 % aller in den nächsten zehn Jahren erwarteten Innovationen im Auto sind elektronisch getrieben. Es wird in Zukunft eine Vielzahl von Anwendungen geben, die das Auto noch sicherer und umweltverträglicher machen werden. Österreich hat traditionell eine starke Position im Weltmarkt der Automobil-Zulieferindustrie. Die österreichische Halbleiterindustrie hat einen überdurchschnittlich hohen Anteil an Automobilelektronik. Die F&E-Leistungen auf diesem Gebiet sind auf weltweit sehr hohem Niveau. Durch die Stärke der österreichischen Automobil-Zulieferindustrie insgesamt und durch die Lage im innovativsten Automobilmarkt, nämlich Europa, sind weitere Wachstumsimpulse für Forschung und Entwicklung von Automobil-Halbleitern in Österreich zu erwarten.	die (integrated circuit);eine and zwei;elektro;europa	R. Petschacher	2006	Elektrotechnik und Informationstechnik	10.1007/s00502-006-0380-9	control engineering;engineering;computer engineering	OS	-103.81186333682872	33.73721285350298	50572
5ecec21cafd41dfed451fffb8c4a568b7f46b9b3	management von prozeßmodellen dezentraler bpr-projekte mit hilfe eines zentralen referenzprozeßmodells		Der Beitrag stellt ein Konzept vor, wie große Prozeßmodelle aus verschiedenen BPR-Projekten in ein unternehmensweites Referenzprozeßmodell integriert werden können. Es wird gezeigt, welche Erfahrungen die SKO bewogen haben, für die Geschäftsprozeßmodellierung ein Referenzprozeßmodell mit neutralen Geschäftsprozeßmustern zu verwenden. Es wird dargestellt, wie der Prozeß zur Modellfortschreibung bzw. wie die Koordination verschiedener BPR-Projekte gestaltet werden muß, damit das unternehmensweite Referenzprozeßmodell konsistent gehalten werden kann. Darüber hinaus wird beschrieben, wie die Wiederverwendung von Prozessen in der Modellfortschreibung berücksichtigt werden muß, damit Aufwände durch Mehrfachentwicklung vermieden werden können. 1 Die BPR-Methode der Sparkassenorganisation – Ausgangslage und Inhalt Auf Grund der guten Ertragslage der Kreditwirtschaft stand die organisatorische Optimierung der betrieblichen Abläufe in Kreditinstituten in der Vergangenheit nicht unmittelbar im Vordergrund. Durch die Deregulierung der Finanzmärkte, insbesondere durch das Auftreten von Nearund Nonbanks als Anbieter traditioneller Bankleistungen, hat sich die Marktsituation für Kreditinstitute nachhaltig verändert. Markterfolge werden künftig in zunehmendem Maße davon abhängig sein, wie es gelingt, die Serviceleistung für den Kunden zu erhöhen, ohne daß damit ein Anstieg der Kosten verbunden ist (Bierer et al. 1992; Gröschel 1992, Klee 1991; Lüthje 1993). Die Industrie hat dieses Problem, ausgelöst durch den internationalen Wettbewerbsdruck, wesentlich früher mit der Methodik des Business Process Reengineering bearbeitet. Hierbei wurde erkannt, daß infolge der Arbeitsteilung im Prinzip nur Teilzuständigkeiten für Teilschritte eines Prozesses in einem Unternehmen vorhanden waren. Für die übergreifenden Gesamtprozesse fehlte es in der Regel an Zuständigund Verantwortlichkeiten. Als Beweis führte Hammer (Hammer et al. 1993) seine oft an das Management von Unternehmen gestellten und nicht beantworteten Fragen an: • Wie lange dauert es in Ihrem Unternehmen, diesen oder jenen Prozeß durchzuführen? • Wie zuverlässig wird dabei gearbeitet? • Wie zufrieden sind die Kunden damit? • Wieviel kostet ein bestimmter Prozeß? Management von Prozeßmodellen dezentraler BPR-Projekte 377 Einen Unternehmensprozeß definiert Hammer als Bündel von Aktivitäten, für die ein oder mehrere unterschiedliche Inputs benötigt werden, um für den Kunden ein Ergebnis von Wert zu erzeugen. Um bankweit Prozesse zu etablieren, die die Kundensicht stärker berücksichtigen, hat die SKO beschlossen, das Thema Geschäftsprozeßmodellierung im Rahmen von BPR-Projekten aufzugreifen, mit dem Ziel die Marktführerschaft der einzelnen Institute langfristig und nachhaltig zu festigen. In einem ersten Schritt wurden deshalb die methodischen Grundlagen für die Durchführung von BPRProjekten in der SKO erarbeitet und durch die Anwendung auf ein konkretes bankfachliches Teilgebiet ausgetestet. Diese BPR-Projekte der Sparkassenorganisation unterscheiden sich in der Verfahrensweise und in ihren Zielen grundsätzlich von klassischen Organisationsprojekten, da in diesen Projekten bewußt auf die aufwendige IST-Analyse verzichtet wird, mit dem Ziel, Quantensprünge zu erreichen. Aus dieser Betrachtung ergibt sich die Frage nach einer geeigneten Vorgehensweise, die den Erfolg derartiger Projekte sicherstellt und ihre Ergebnisse für andere Projekte nutzbar macht: “Reengineering first determines what a company must do, then how to do it. It ignores what is and concentrates on what should be” (Hammer et al. 1993). Mit der Bereitstellung einer Methode zur Durchführung von BPR-Projekten sind eine Reihe weiterer Vorteile verbunden, neben der Standardisierung des Projektablaufs, auch die Verbesserung des Faktors time-to-market bzw. die Reduktion der Kosten von BPR-Projekten. Die zukünftig den Organisatoren der SKO zur Verfügung stehende BPR-Methodik besteht aus 3 Komponenten die untereinander über Schnittstellen verbunden sind. Im einzelnen sind dies die folgenden Komponenten. Vorgehensmodell Das Vorgehensmodell beschreibt die einzelnen Projektphasen, in denen über klar beschriebene Aktivitäten ganz bestimmte Ergebnisse erzielt werden sollen. Dabei werden in der ersten Phase die Ziele des Projektes definiert und die Projektplanung durchgeführt. In der zweiten Phase werden die relevanten Geschäftsvorfälle identifiziert, um nach der Strukturierung mit Hilfe des Referenzprozeßmodells neu gestaltet zu werden. Der Phase der Neugestaltung der Geschäftsprozesse schließt sich die Phase der Umsetzungsplanung an. In dieser Phase werden die Kennzahlen der Geschäftsprozesse erhoben sowie die notwendigen organisatorischen und ITtechnischen Anforderungen abgeleitet. 378 S. Gerber, A. Hiesterman, H.-B. Kittlaus institutsspezifisches BPR-Projekt Gesamtmodell neutrale Geschäftsprozeßmuster Vorgehensmodell (Beschreibung des Vorgehens) Prozeßmodellmanagement (SKO-weites Prozessmanagement) Referenzprozeßmodell (Modell der SKO) Geschäftsprozesse Änderungsspezifikation Methodenfilter für BPR-Ergebnisse Referenzgeschäftsprozesse Strategie	business process;code refactoring;die (integrated circuit);eine and zwei;gerber format;gesellschaft für informatik;intentionally blank page;internet explorer;the daily telegraph;unified model;v-model;vhf omnidirectional range	Stefan Gerber;Arno Hiestermann;Hans-Bernd Kittlaus	1999			knowledge management;performance art;computer science	OS	-101.87853269767012	33.609166686838314	50828
9169d5827905f743fcd7dce95c721b286873e140	format-übergreifende anpassungen von elektronischen lerninhalten		Wiederverwendung von elektronischen Lerninhalten ist ein Thema, das derzeit in verschiedensten Arbeiten untersucht wird. Eine sinnvolle Wiederverwendung ist jedoch in vielen Fällen nur möglich, wenn berücksichtigt wird, dass der neue Einsatzkontext eine Anpassung des Inhalts nötig machen kann. In dieser Arbeit wird ein auf Pattern basierendes Konzept und dessen prototypische Umsetzung vorgestellt, das Anwender bei der Durchführung solcher Anpassungen unterstützt, unabhängig vom Dokumentenformat, in welchem die Lerninhalte vorliegen.	die (integrated circuit);eine and zwei	Birgit Zimmermann;Christoph Rensing;Ralf Steinmetz	2006			philosophy;performance art	NLP	-104.87337786767095	32.84043297189317	51210
287c198720ba9657d7e4ffcd9f452c0f067b04a8	partizipation bei der schulwegeplanung - ein mobiler lernansatz für grundschüler		Verkehrsraumplanung ist vor dem Hintergrund eines erhöhten gesellschaftlichen Bewusstseins für nachhaltiges Mobilitätsverhalten ein wichtiger Teil der Empfehlungen für Verkehrserziehung. In diesem Beitrag stellen wir einen didaktischen Ansatz zur partizipativen Verkehrsraumplanung in der Primarstufe vor und zeigen, wie dieser Ansatz durch mobile Technologien unterstützt werden kann. Erste Erfahrungen mit dem Ansatz konnten in 6 Grundschulen in Venedig gewonnen werden und geben Hinweise, dass auch Grundschülerinnen und -schüler mit der richtigen Unterstützung durch mobile Technologie ein Bewusstsein für nachhaltige Verkehrsplanung entwickeln können.	citeseerx;internet explorer;vhf omnidirectional range	Till Schümmer;Martin Mühlpfordt	2014			philosophy;performance art	Mobile	-105.26085496675354	32.9998739682319	51378
df7dacec8b9f9d3ab61d4b3764a8976abe7abf85	über homomorphie und reduktion bei nicht-deterministischen automaten				Siegfried Neuber;Peter H. Starke	1967	Elektronische Informationsverarbeitung und Kybernetik		algebra;combinatorics;mathematics	NLP	-95.67033917644477	34.429768033310744	51395
57373f03e28f7bcbc548267b9e32d496b4c95b12	spezielle statistikmethoden für die wirtschafts- und ingenieurwissenschaften - entwicklung, methodik und erfahrungen mit einem interaktiven lernmodul		Der vorliegende Beitrag stellt zunächst kurz das BMBF-Projekt „Norddeutscher Methodenlehre-Baukasten“ vor und geht dann auf das darin integrierte Modul „Spezielle Methoden“ ein. Das Modul enthält besondere Inhalte für die Wirtschaftsund Ingenieurwissenschaften im Rahmen der Statistikausbildung. Die interaktiven Übungen wurden nach dem Konzept des „entdeckenden Lernens“ umgesetzt. Erste Erfahrungen wurden im Rahmen einer Evaluation gesammelt.	vhf omnidirectional range	Edelmiro Ricabal Delgado;Marco Zehner	2005				Crypto	-105.01508090479044	32.39340712675721	51647
b0696d2b440b95bc7001f5d19f50b65fd846ae5d	erfahrungen mit dem betrieb eines anonymisierungsdienstes	004 informatik;330 wirtschaft;ddc 330;ddc 004	An der TU Dresden wird seit September 2000 ein Anonymisierungsdienst betrieben, der ein weitgehend unbeobachtbares Surfen im Internet erlaubt. Mit bis zu 4000 Nutzern täglich erfreut sich dieser Dienst wachsender Beliebtheit und zählt inzwischen zu den fünf meistgenutzten Anonymisierungsdiensten dieser Art weltweit. Die für die Nutzung des Dienstes benötigte Client-Software JAP ist entstanden im Rahmen der Zusammenarbeit der Projekte „AN.ON – Anonymität.Online“, gefördert vom BMWi, und „Effiziente und skalierbare Realisierung von unbeobachtbarer und anonymer Kommunikation im Internet“, gefördert im DFG-Schwerpunktprogramm Sicherheit. Neben dem gesellschaftlichen Spannungsfeld, das beim Betrieb unseres Anonymisierungsdienstes zu Tage tritt, geht es in diesem Beitrag um „technische“ Erfahrung, die sich für den Betrieb von Internetbasierten Diensten verallgemeinern lassen.	java anon proxy;unified model;weatherstar	Stefan Köpsell;Hannes Federrath;Marit Hansen	2003	Datenschutz und Datensicherheit		internet privacy;performance art;computer science	OS	-103.91345782712938	36.280302767388434	51783
90d1986665aabd1c06c3d47d0958b471bdbf55f3	datenstruktur und statistische modelle zur dokumentanalyse		Der Beitrag zeigt praktische Ergebnisse und die Methode, um Druckvorlagen in eine einheitliche symbolische Beschreibung uberzufuhren und daraus Text-, Grafik- und Bildkomponenten zu erkennen. Hierzu wird das Wissen uber den Aufbau der Dokumente in Grammatiken festgelegt. Gemas ihrer Aussage wandelt ein Analyseverfahren die Dokumentmuster in hierarchisch organisierte Datenstrukturen um und klassifiziert diese durch Vergleich mit bekannten Modellen.		Wolfgang Scherl	1985		10.1007/978-3-642-70638-7_51		Vision	-104.9156968622811	33.08479847829645	52074
817e8758b96e793d8d3a1b251b988ec564f12cf8	durchsatzoptimale rechnerkern- und transportkanalvergabe für ein rechnermodell mit zwei arbeitsspeicherplätzen		Ein stapelverarbeitendes System besteht aus einem Rechner und einer Menge von Aufaben, die vom Rechner bearbeitet werden mussen. Nun ist ein Rechner ein derart komplexes Gebilde, das man stark vereinfachte Modelle betrachten mus, wenn man Aussagen uber das Verhalten des Systems gewinnen will. Ebenso bestehen Aufgaben aus so verschiedenartigen Anforderungen an die einzelnen Betriebsmittel, aus denen sich der Rechner zusammensetzt, das man sich auf stark vereinfachte Modellaufgaben beschranken mus. Als dritte Komponente geht schlieslich noch der Zugangsprozes neuer Aufgaben in das Modell des Stapel verarbeitenden Systems ein, der ebenfalls vereinfacht werden mus.	eine and zwei;gesellschaft für informatik	Hans-Jürgen Küspert	1972		10.1007/978-3-642-80732-9_26		NLP	-104.73878744240972	33.327915224558964	52101
28dca5f4b31672410ca7bd3594c396de6d353c2a	information retrieval	algorithms;general;information search and retrieval;languages	"""Workshop """"Information Retrieval"""" Gesellschaft für Informatik (GI) GMD-IPSI 24. und 25. Juni 1991. Am 24. und 25. Juni 1991 fand bei der GMD in Darmstadt ein Workshop mit dem generellen Thema """"Information Retrieval"""" statt. Das große Interesse an diesem Workshop spiegelte sich in den nahezu 100 Teilnehmern wider, die sich zum größten Teil aus Wissenschaftlern und Vertretern der Industrie zusammensetzten. Die Teilnehmer kamen aus Deutschland, Osterreich und der Schweiz. Die beiden eingeladenen Vortragenden (Prof. Keith van Rijsbergen und Prof. Bruce Croft) erweiterten dieses Spektrum auf Großbritannien und die USA. Veranstalter des Workshops waren die Gesellschaft für Informatik und die Gesellschaft für Mathematik und Datenverarbeitung/Institut für Integrierte Publikationsund Informationssysteme GMD-IPSI, die auch ihre Infrastruktur zur Verfügung stellte. Der Workshop sollte den Start bilden für die neue Fachgruppe """"Information Retrieval"""" innerhalb der GI. Die zweitägige Veranstaltung gliederte sich in sieben Sitzungen mit unterschiedlichen inhaltlichen Schwerpunkten, in welchen insgesamt 15 Vorträge gehalten wurden. Zum Teil ergänzten entsprechende Systemvorführungen die Referate. Höhepunkte des Workshops waren sicherlich die bei den eingeladenen Vorträge. Keith van Rijsbergen (Professor an der University of Glasgow) sprach über """"Information Retrieval and its Logic: Inference versus Relevance"""". Ausgehend von der Tatsache, Information Retrieval mittlerweile nicht nur mit Dokumenten beschäftigt, die in Form von Texten vorliegen, sondern auch Bilder, Videos, Objekte aus der Büroumgebung etc. (Hypermedia!) gespeichert und wiederaufgefunden werden sollen, müssen auch die Grundlagen des Information Retrievals, d.h. die Modelle, auf ihre Anwendbarkeit auf die multimedialen Anforderungen überprüft werden. Van Rijsbergen sieht bei der Verschmelzung eines Hypermedia-Systems mit dem probabilistischen IR-Modell das Problem darin, daß die Unsicherheit der Information durch das Hinzufügen von Information aus der Umgebung oder einem Thesaurus noch verstärkt wird. Van Rijsbergen zeigte, indem er auf das """"logical uncertainty principle"""" zurückgriff, daß Information Retrieval durchaus als eine Form von Inferenz angesehen werden kann. Bruce Croft (Professor an der University of Massachusetts, Amherst), der zweite eingeladene Redner, hielt einen Vortrag mit dem Titel """"Retrieval from Large Databases"""". Zunächst stellte er heraus, daß sich Information Retrieval in den USA nach wie vor großen Interesses erfreut, vor allem aufgrund der neuen Grössenordnungen im Bereich der Dokumentanzahl, auf seiten der Anfragen und last not least auch im Hinblick auf das individuelle Dokument (""""What is large?""""). Ausgehend von den amerikanischen IRForschungsaktivitäten der letzten Jahrzehnte zeigte er, inwieweit die erzielten Ergebnisse vereinbar seien mit den Anforderungen von Datenbanken, die den neuen Größenordnungen entsprechen. Er warf Fragen auf nach der Übertragbarkeit von Experimenten in bezug auf die Beurteilung von Effektivität und Effizienz bestimmter Algorithmen oder Funktionen, die auf der Grundlage kleiner Kollektionen bzgl. der einbezogenen Dokumente und Anfragen erzielt worden waren. Bruce Croft ging auf drei Projekte ein, an welchen er beteiligt ist (TIPSTER, WESTLAW und CONSTRUE), die beitragen sollen, dieses Defizit zu beheben. Durchaus"""	bibliothèque de l'école des chartes;database;eine and zwei;gnu variants;general material designation;gesellschaft für informatik;hypermedia;information retrieval;internet explorer;relevance;thesaurus;uncertainty principle;v-model;vhf omnidirectional range;w. bruce croft	Christa Womser-Hacker	1991	LDV Forum	10.1007/978-0-387-30164-8_403	visual word;human–computer information retrieval;concept search;relevance (information retrieval);query expansion;adversarial information retrieval;document retrieval;retrievability;information retrieval	Web+IR	-106.53151223502576	35.76865085447989	52374
dbf0ed251dc0737428f91139e6d19559ae0ecd25	benchmarking and performance modeling of event-based systems (modellierung und bewertung von ereignis-basierten systemen)	performance model;event based system	Event-based systems are used increasingly often to build loosely-coupleddistributedapplications.With their growing popularity and gradual adoption in mission critical areas, the need for novel techniques for benchmarking and performance modeling of event-based systems is increasing. In this article, we provideanoverviewof thestate-of-the-art in thisareaconsidering both centralized systems based on message-oriented middleware as well as large-scale distributed publish/subscribe systems. We consider a number of specific techniques for benchmarking and performance modeling, discuss their advantages and disadvantages, and provide references for further information. The techniques we review help to ensure that systems are designed and sized to meet their quality-of-service requirements. Zusammenfassung Ereignis-basierte Systeme werden immer häufiger beim Aufbau von hochverteilten Systemen und als Kommunikationstechnologie in Enterprise-Software eingesetzt. Durch den damit einhergehenden Bedeutungszuwachs treten Methodiken zur Bewertung und Vorhersage von Leistungsmerkmalen und Servicequalität wie Benchmarks und Performance Modellierungsansätze immermehr indenVordergrund. Indiesem Artikel geben wir einen Überblick über den aktuellen Stand der Forschung im Bereich Performance-Modellierung und Benchmarking von ereignis-basierten Systemen. Hierzu betrachten wir zwei verschiedene Ansätze: zentralistische Infrastrukturen (message-oriented middleware) und verteilte publish/subscribe Systeme. Dabei beleuchten wir Vorund Nachteile der bestehenden Benchmarkund Modellierungsansätze und gehen darauf ein, wie diese eingesetzt werden können, um mögliche Engpässe und Servicequalitätsmerkmale vorherzusagen und eine entsprechende Kapazitätsplanung vorzunehmen.	centralized computing;debs;eine and zwei;enterprise software;internet explorer;message-oriented middleware;mission critical;performance evaluation;performance prediction;publish–subscribe pattern;quality of service;requirement;simulation;système universitaire de documentation;unified model	Samuel Kounev;Kai Sachs	2009	it - Information Technology	10.1524/itit.2009.0550	computer science;electrical engineering;operations research	OS	-100.09049860845174	33.62225842977966	52710
2d8ef22390258577b06f5641373f6f8adbe72582	2. berliner symposium des bfdi zur informationsfreiheit		trafen sich am 6. und 7. September 2012 Abgeordnete, Verwaltungsrichter aller drei Instanzen, Informationsfreiheitsbeauftragte der Länder, Hochschullehrer, Anwender des IFG aus Ministerien und Bundesbehörden, Vertreter von Kirchen und Nichtregierungsorganisationen sowie Repräsentanten der Netzgemeinde und der Medien. Die Zahl von rund einhundert Teilnehmern belegt das stetig wachsende Interesse am Querschnittsthema „Informationsfreiheit“ auf Bundesund Landesebene. Das Hamburgische Transparenzgesetz war – kaum im Gesetzblatt veröffentlicht – das erste große, von meinem Kollegen Prof. Johannes Caspar vorgestellte, Thema des Symposiums. Mit diesem Gesetz, das insbesondere die proaktive Veröffentlichung von Verwaltungsinformationen sehr deutlich stärkt, spielt Hamburg, sportlich formuliert, im Spitzenfeld der ersten Bundesliga. Eine vergleichbare Regelung im Informationsfreiheitsgesetz des Bundes würde ich sehr begrüßen. Prof. Ingolf Pernice von der Humboldt-Universität Berlin lenkte den Blick auf die europarechtlichen Wurzeln und die Entwicklung des Umweltinformationsrechts. Mit dem Umweltinformationsrecht habe der Paradigmenwechsel vom arkanen zum offenen Staat eingesetzt. Dieser Paradigmenwechsel könne bei der Interpretation des Artikel 5 Abs. 1 Satz 1, 2. Halbsatz des Grundgesetzes nicht länger außer Betracht bleiben. Den zweiten Tag des Symposiums eröffnete Prof. Friedrich Schoch (Albert-Ludwigs-Universität Freiburg) mit seiner Analyse und pointierten Kritik der nationalen und der EuGH-Rechtsprechung im Spannungsfeld von Informationsfreiheit und Datenschutz. Prof. Schoch sprach sich auch für eine Ausdehnung meiner Beratungs-, Kontrollund Ombudsaufgaben auf das Umweltinformationsgesetz und das Verbraucherinformationsgesetz aus. Dr. Angela Spelsberg und Dieter Hüsgen (Transparency Deutschland) schilderten in ihrer Fallstudie die (Prozess-)Geschichte ihres IFG-Antrags bei der Kassenärztlichen Bundesvereinigung. Angesichts der Knappheit der Gesundheitskassen und der Notwendigkeit transparenter und rationaler Verwendung der Beiträge der Versicherten ist dies ein unbedingt auch mit den Mitteln des Informationsfreiheitsgesetzes weiter auszuleuchtendes Feld. Die im Wesentlichen stattgebende Entscheidung des Verwaltungsgerichtes Berlin vom 1. Juni 2012 (Az. VG 2 K 177.11) ist deshalb auch aus meiner Sicht ein weiterer informationsfreiheitsrechtlicher Meilenstein. Nachdem Dr. Elisabeth Musch vom Deutschen Forschungsinstitut für öffentliche Verwaltung Speyer im vergangenen Jahr beim 1. Berliner Symposium das „Design“ der vom Innenausschuss des Deutschen Bundestages in Auftrag gegebenen Evaluation erläutert hatte, konnte sie jetzt das Ergebnis der im letzten Frühsommer aufgenommenen Evaluation gemeinsam mit ihrem Kollegen Dr. Alfred Debus vorstellen. Der Justiziar des Bundeskartellamtes Jörg Nothdurft setzte sich in seinem Impulsreferat, pointiert mit anschaulicher und zugleich differenzierter Argumentation für den Schutz von Betriebsund Geschäftsgeheimnissen im Kontext des Informationszuganges beim Bundeskartellamt ein. Dr. Helene Groß aus dem Bundesministerium des Innern gab einen Überblick über den Stand des Open Government Projektes der Bundesregierung und der Zusammenarbeit mit den Ländern. Anfang 2013 soll der Prototyp eines ebenenübergreifenden Open-Data-Portals online gehen. Die Referentin verwies auch auf die im Auftrag des Bundesministeriums des Innern verfasste und veröffentlichte Studie „Open Government Data Deutschland“. Die nationale Perspektive wurde schließlich von einer europäischen abgelöst: Dr. Carl-Christian Buhr von der Europäischen Kommission referierte zur Funktion der öffentlichen Information als Wirtschaftsgut. Eines der zentralen Anliegen der Kommission sei die Stärkung der Verfügbarkeit und Weiterverwendung von Daten, wozu neben der Datenportabilität auch die Gewährleistung eines hohen Datenschutzniveaus durch die geplante EU-Datenschutzverordnung gehöre. Mein Fazit des 2. Symposiums: Bei einzelnen Bundesländern sehe ich eine sehr gute normative und technische Umsetzung des Open-Data-Gedankens; zugleich gibt es immer noch Bundesländer ohne Informationsfreiheitsgesetz. Auf Bundesebene ist insbesondere das proaktive Element endlich weiter zu entwickeln. Das Hamburgische Transparenzgesetz, aber auch der Entwurf eines neuen Berliner Transparenzund Informationsfreiheitsgesetzes der Fraktion Bündnis 90/Die Grünen sollten hier als Vorbild genommen werden. Abschließend möchte ich diese Gelegenheit auch nutzen, Sie auf die vom 18. bis 20. September 2013 von meinem Berliner Kollegen Alexander Dix und mir gemeinsam auszurichtende Internationale Konferenz der Informationsfreiheitsbeauftragten (ICIC) aufmerksam zu machen. Die Beiträge des Symposiums sowie Informationen zur Internationalen Konferenz finden Sie unter Informationsfreiheit.bund.de.	alan dix;eine and zwei;entscheidungsproblem;gab;gesellschaft für informatik;i/o controller hub;intentionally blank page;lvm;portals;sie (file format);triple des;vg 8020	Peter Schaar	2012	Datenschutz und Datensicherheit - DuD	10.1007/s11623-012-0291-3	computer science;computer security;internet privacy	OS	-103.36856832996573	35.2250867751337	52919
37cc08bfae7a1f1e283c31a94a982f9d5349cf7d	zur entwicklung exakter modelle in der psychologischen lerntheorie		"""Die Entwicklung der psychologischen Lerntheorien wird dargestellt. Mathematische Formulierungen von der Art des """"empirischen Kurvenanpassens"""" werden neuerdings abgelost durch ein """"rationales"""" Vorgehen: aus wenigen Grundpostulaten werden die funktionalen Beziehungen zwischen beobachtbaren Variablen abgeleitet. Ein stochastisches Modell dieser Art wird kurz dargestellt."""		Erich Mittenecker	1958	Unternehmensforschung	10.1007/BF01924493	discrete mathematics;mathematical economics;mathematics	Vision	-98.2843064085611	34.7115696931194	52929
76efb48b406db7a25ae167d1490f0c34eb390763	persönliche lernumgebung - architektur für smartphones		Die App myTU ist ein Begleiter durch den studentischen Alltag für iOS und Android Smartphones, der Informationen von Webseiten, Datenbanken und weiteren IT-Quellen der TU Bergakademie Freiberg aggregiert (backend) und auf dem Smartphone in gerätegerecht optimierter Form darstellt (frontend). Beispiele sind Stundenplan, Bibliothekskatalog und -konto, Campus-Map, Speiseplan der Mensa sowie Campus-Nachrichten. Darüber hinaus ist ein Vorlesungs-Feedbacksystem für Geschwindigkeitsbewertung und anonymes Fragen in der Lehrveranstaltung integriert. Über myTU ist bereits vielfach in Presse, Funk und Fernsehen berichtet worden: http://mytu.tufreiberg.de/category/press/ gibt einen Überblick. In diesem Bericht werden Funktionalität und Architektur der App, die aus einer studentischen Übung hervorgegangen ist, beschrieben. Besonders interessant ist das präsenzbasierte Feedbacksystem für Lehrveranstaltungen.	android;app store;smartphone;television;ios	Frank Gommlich;Georg Heyne	2013				OS	-105.52843144115404	37.10646269583409	52962
e3386cff0ab43cadd80472d2d5ca58ebaba244b5	transformation von sql in xquery-anfragen innerhalb föderierter informationssysteme.		In föderierten Informationssystemen steht man vor dem Problem, Daten und Informationen, die in verschiedenen Formaten und Systemen gespeichert sind, auswerten zu müssen. Die Daten können dabei in relationalen, objektrelationalen oder auch XML-Datenbanken vorliegen. Dazu werden AnfrageTransformationen benötigt, aber auch die Transformation von Daten und Ergebnissen in andere Formate ist erforderlich. Diese Arbeit beschäftigt sich mit der Anfragetransformation von SQL in XQuery innerhalb föderierter Informationssysteme. Der in dieser Arbeit entwickelte allgemeingültige Algorithmus führt eine solche Transformation unter bestimmten Vorbedingungen automatisch durch.	eine and zwei;sql;vhf omnidirectional range;xml;xquery	Heiko Jahnkuhn;Ilvio Bruder;Ammar Balouch	2005			database;sql;xquery;computer science	DB	-106.06558096344286	35.29910477955265	53138
e975c88d16a00931a5e1fa4ce33c8b9e84957ff3	value added services für das büro		Unter Value Added Services (VAS) versteht man Telekommunikations-Services, die uber den Bereich der reinen Informationsubermittlung hinausgehen und in der Regel Funktionen der Informationsverarbeitung und Informationsspeicherung bereitstellen. VAS sind sowohl in offentlichen als auch privaten Netzen (firmenintern oder branchenintern) von Bedeutung. Aus diesem Grund wird auch der Begriff VAS der entsprechenden deutschen Bezeichnung „Mehrwert-Dienste“ vorgezogen, da der Begriff “Dienst” allgemein fur Leistungen der Bundespost in offentlichen Netzen verwendet wird (z.B. Btx-Dienst). Eine Reihe von Beispielen fur VAS zeigt Bild 1.		Heribert Peuckert	1987		10.1007/978-3-662-01110-2_10		HCI	-104.49643627474259	33.37359365465559	53293
f017c87f1fd553e3ed331ce660396efc43bb3bd5	ausnutzung von beziehung in multimedia-dokumenten zur speicherung und retrieval in multimedia informationssystemen		Ziel des Projektes GETESS ist die Realisierung eines Suchdienstes, der sich von existierenden Suchmaschinen durch die inhaltliche Analyse der zu untersuchenden deutschen Texte, d.h. durch die Erzeugung von Informationskondensaten (Abstracts) dieser Texte auf Basis von linguistischem und Ontologie Wissen sowie die Verwendung einer natürlichsprachlichen Dialogschnittstelle abgrenzt. Auÿerdem werden die kondensierten Daten in objektrelationalen Datenbanken gehalten. Die Suchaufträge werden über eine neuartige Kombination von Information Retrieval Suchkommandos und Datenbankanfragen formuliert (IRQL). In diesem Beitrag wird ein Überblick über das Projekt gegeben. 1 Einleitung Suchmaschinen sind heutzutage ein wichtiges Hilfsmittel zur kostengünstigen Informationsrecherche im Internet. Die von den Suchmaschinen gelieferten Ergebnisse entsprechen jedoch nicht immer den Vorstellungen der Benutzer; sie sind häu g zu umfangreich, nicht zutre end oder unvollständig. Die Ursache dafür liegt u.a. darin, daÿ sich die für die Recherche eingesetzten Werkzeuge gröÿtenteils auf Schlüsselworte und sogenannte syntaktische Attribute von bereitgestellten Dokumenten (wie z.B. META Tags) konzentrieren, ohne die eigentliche Bedeutung der Informationen zu beachten. GETESS Idee. Die Idee der GETESS Suchmaschine besteht nun darin, die für die Suche verwendeten Dokumente bezüglich ihres Inhaltes detaillierter zu analysieren. Im Gegensatz zu den üblicherweise bei den Suchmaschinen verwendeten Schlüsselwort Indizes wird bei GETESS ein sogenannter Abstract Index benutzt. Zu den einzelnen Internet Dokumenten werden Abstracts gebildet, die Informationskondensate auf Basis von linguistischem und Ontologie Wissen darstellen. Desweiteren wird eine natürlichsprachliche Dialogschnittstelle bereitgestellt, die es dem Benutzer erlaubt, seine Suchanfrage in natürlichsprachlichen Phrasen zu formulieren und im Dialog zu konkretisieren. Für die Beantwortung der Suchanfrage werden die natürlichsprachlichen Phrasen auf die Abstracts abgebildet. Als Ergebnis wird eine Menge von Internet Dokumenten geliefert, deren Inhalt dem Benutzer natürlichsprachlich auf Basis der Abstracts als Zusammenfassung präsentiert wird. Automatische Übersetzung. Aufgrund der immer stärkeren Verbreitung des Internets kann mit Blick auf die Zukunft die Kenntnis der englischen Sprache nicht mehr vorausgesetzt werden. Deshalb wurde bei GETESS die deutsche Sprache als vorrangige natürliche Sprache gewählt. Die Suchdialoge werden in deutscher Sprache geführt und zu deutschen Internet Dokumenten werden Abstracts gebildet. Die Verwendung von Abstracts bietet jedoch den Vorteil, eine automatische Übersetzung in andere Sprachen auf Basis der Abstracts vorzunehmen. Der Benutzer Unter einer Ontologie verstehen wir eine Menge von Begri en, die über ihre inhaltliche Beziehung zueinander geordnet sind. Beispielsweise ist Unterkunft der Oberbegri zu Hotel, Jugendherberge, Pension usw. 2. IuK-Tage MV, Rostock, 17 19 Juni 1999 kann somit einen Überblick über die Suchergebnisse in verschiedenen Sprachen erlangen. Innerhalb von GETESS wird hinsichtlich der automatischen Übersetzung die englische und die japanische Sprache betrachtet. GETESS Partner. GETESS ist ein vom BMBF gefördertes 3 Jahres Projekt, daÿ von den Partnern DFKI Saarbrücken (automatische Sprachverarbeitung), Universität Karlsruhe (Konstruktion von Ontologien), GECKO mbH Rostock (Dialoggestaltung) und der Universität Rostock (Suchmaschinen mit Datenbanktechnik) getragen wird. Ziel des Projektes ist es, das Know how der verschiedenen Partner ([BNX98, DEFS99]) in einem Prototyp zu integrieren und als Synergiee ekt einen Suchdienst zu entwickeln, der als Basis für zukünftige Suchmaschinen dienen kann. Inhalt des Artikels. In Abschnitt 2 werden wir zunächst anhand eines Beispiel Szenarios den GETESS Problemkreis sowie den GETESS Lösungsansatz illustrieren. Anschlieÿend werden wir in Abschnitt 3, beginnend mit der GETESS Zielstellung, die GETESS Architektur sowie die verschiedenen GETESS Komponenten erläutern. Desweiteren werden die Rostocker Anteile des GETESS Projektes ausführlicher dargestellt. Zum einen werden wir in Abschnitt 4 die GETESS Suchmaschine mit Abstract Funktionalität beschreiben, zum anderen werden wir in Abschnitt 5 die bei der GECKO mbH entwickelten Strategien zur Dialogführung diskutieren. Desweiteren werden die in GETESS im Vergleich zu herkömmlichen Suchmaschinen erheblich erweiterten Suchanfrage Möglichkeiten sowie die Speicherung der Abstracts in Datenbanken beschrieben. Abschlieÿend werden wir in Abschnitt 6 unsere Erläuterungen noch einmal zusammenfassen.	bibliothèque de l'école des chartes;citeseerx;die (integrated circuit);eine and zwei;gecko;german research centre for artificial intelligence;information retrieval;internet explorer;internets;meta element;sie (file format);triple des;dialog	Ilvio Bruder;Temenushka Ignatova	2003			computer science;multimedia	OS	-106.4255388697693	35.14043018168437	53295
1af0cf19b74f577dc8fde7ebc52116354cc2baea	das zentrum für interaktion mit digitalen medien (zim) an der universität bremen, fb 3	poster	Das Zentrum fur Interaktion mit Digitalen Medien (ZIM) wird zum Sommersemester 2003 an der Universitat Bremen eroffnet. Das ZIM bietet Lehramtsstudierenden, Studenten der Medieninformatik und der Informatik einen gemeinsamen und fur eigene Projekte offenen Lern- und Arbeitsraum. Wir wollen damit an reformpadagogischen Ansatze von Lernwerkstatten anknupfen und neue Formen des Lernens mit Digitalen Medien erproben: offen, kooperativ, selbstorganisiert und interdisziplinar. Interaktion gilt uns als Prinzip der sozialen Organisation und des Umgangs mit dem Medium.	mit/gnu scheme	Heidi Schelhowe;Christina Dörge;Hendrik Bunke;Georg Sichma	2003				Vision	-107.19125030690243	33.531702415698625	53641
2fbd83a8103d75d1948dbd5a35180121def05b7c	modellbasierte oberflächenentwicklung ohne oberflächen- und verhaltensmodellierung		Der Beitrag beschreibt einen Ansatz der nicht den Anspruch erhebt eine umfassende modellbasierte Entwicklung von Oberflächen umzusetzen. Er beschreibt einen Weg der den Entwicklungsaufwand durch Kombination von manueller und modellbasierter Entwicklung minimieren soll. Grundlage des Ansatzes ist die Generierung von Oberflächen aus Definitionen der darzustellenden Datenstrukturen. Es wird gezeigt, dass durch die Einführung von Übergängen zwischen manueller und modellbasierter Programmierung effektive Möglichkeiten existieren, die benötigte Flexibilität der Oberflächengestaltung zu gewährleisten.	eine and zwei	Olaf Böde	2007				OS	-104.50818285882302	32.69012698006317	54345
756bf6eb2844db947d11392c357cc6414001dd0a	zur fortbildung von dv-mitarbeitern an wissenschaftlichen rechenzentren		Der Bereich der Datenverarbeitung unterliegt — eigentlich ständig — einem Wandel. Gegenwärtig führt die Nutzbarmachung neuer Kommunikationstechnologien zu einer verstärkten Integration von Text, Bild und Sprache in die bisherigen Formen digitaler Datenverarbeitung. Die Speicherung und Verarbeitung von Informationen erfolgt zunehmend in verteilten Systemen, die über lokale und überregionale Netze miteinander kommunizieren. Diese Tendenzen zur Dezentralisierung erzeugen zugleich eine geänderte Aufgabenverteilung bei der Anwendung der Datenverarbeitung. Dabei sei unterstellt, daß zumindest für komplexere Problemstellungen der wissenschaftlichen wie der betrieblichen Datenverarbeitung weiterhin Rechenzentren mit leistungsfähigen DV-Systemen, breitgefächertem Software-Spektrum und hohem Potential an DV-Fachwissen notwendig sein werden. Ihnen stehen allerdings zunehmend arbeitsplatz-orientierte Endbenutzersysteme gegenüber, die auf MikrocomputerBasis mit rasch wachsenden qualitativen und quantitativen Ausstattungsmerkmalen operieren und einen erheblichen Bedarf zur Kopplung mit zentralen Rechnern haben, vor allem, um dort vermittelte spezielle Dienstleistungen in Anspruch nehmen zu können. Mit dieser veränderten Topologie der Datenverarbeitung entwickelt sich zugleich ein verändertes Aufgabenspektrum von Rechenzentren. Standen in der Vergangenheit überwiegend betriebliche Aspekte zur Verfügbarmachung von DV-Ressourcen im Rechenzentrum im Vordergrund, Aufgaben also, die mit fortschreitender Entwicklung der DV-Technologie eine erhebliche Stabilisierung und Automatisierung erfahren haben, so sind zukünftig verstärkt Funktionen gefragt, die dem Anwender auf hohem Niveau fachlich-inhaltliche Unterstützung und Beratung sowie die Vermittlung der Nutzung neuer Kommunikationstechniken bieten. Hinzu kommt als quasi selbstverständliche Voraussetzung ein gesicherter, unter Umständen fehler-toleranter Betrieb der komplexer gewordenen und verteilten DV-Systeme. Befürchtungen, Rechenzentren könnten in ihrer Bedeutung stark verlieren oder gar überflüssig werden, sind solange unbegründet, wie erkannt wird, daß DV-technologischen Entwicklungen folgend ein kontinuierlicher Anpassungsprozeß der Rechenzentren erforderlich ist, der funktionale und strukturelle Veränderungen mit sich bringt. Die damit verbundenen erhöhten Anforderungen an die Mitarbeiter von Rechenzentren können nur erfüllt werden, wenn auch deren Wissenspotential ständig weiterentwickelt wird.	eine and zwei;institut für dokumentologie und editorik;internet explorer;rasch model;unified model;vhf omnidirectional range	Klaus Sternberger	1985	Praxis der Informationsverarbeitung und Kommunikation	10.1515/piko.1.1985.8.2.94	computer science;distributed computing	OS	-104.089412388906	32.88817789208089	54450
a5dcce83b27e089ca5f3a297f81c5b5a57ae0423	didaktische voraussetzungen für den einsatz von computerunterstütztem lernen	tztem lernen;den einsatz von computerunterst;didaktische voraussetzungen	Soll das grundlegende didaktische Postulat einer lernergemasen Vermittlung von Lehr-/Lerninhalten auch im Zusammenhang des computerunterstutzten Lernens (CUL) eine Bedeutung besitzen, dann sind Erkenntnisse uber den Zusammenhang von Zielgruppenvoraussetzungen und Gestaltungsvarianten von CUL grundlegend. Solche Erkenntnisse liegen derzeit nur fragmentarisch vor. Aus diesem Grunde wurde in einer qualitativ angelegten Untersuchung die verfugbare Literatur zu dieser Fragestellung ausgewertet und in Interviews validiert. Ziel der Untersuchung war es, zentrale Anhaltspunkte fur die Auswahl und Gestaltung von zielgruppenbezo- gener Lernsoftware bereitzustellen. Im einzelnen wird begrundet, unter welchen Voraussetzungen der Zielgruppe ein besonderer didaktischer Aufwand bei der Gestaltung von Ablaufsteuerung, Interaktion und Infor-mationsprasentation innerhalb einer Lernsoftware sinnvoll ist.		Dieter Euler	1991		10.1007/978-3-642-76982-5_22		Crypto	-104.89512088652438	32.74800484781057	54490
56bbc4bd78194abffe918cbc8dfb449472344330	elektronische identifikation in europa: die neue eu-verordnung		Am 4. Juni 2012 hat die EU-Kommission den Entwurf „Verordnung des europäischen Parlaments und des Rates über die elektronische Identifizierung und Vertrauensdienste für elektronische Transaktionen im Binnenmarkt“ [1] vorgestellt. Erstellt wurde der Entwurf von der Generaldirektion für Binnenmarkt und Dienstleistung (GD MARKT). Vorangegangen war eine öffentliche Anhörung im Kalenderjahr 2011. Die Neufassung soll die Signatur-Richtlinie der EU aus dem Jahr 1999 ablösen und die Nutzung von eID-Systemen vereinfachen. Dieser Beitrag stellt kritisch einige mögliche Konsequenzen für Technologie und Anwendungen zur Diskussion.	eine and zwei;europa;gesellschaft für informatik	Frank Byszio;Detlef Houdeau;Gisela Meister;Klaus-Dieter Wolfenstetter	2013	Datenschutz und Datensicherheit - DuD	10.1007/s11623-013-0055-8	computer science;internet privacy	Crypto	-103.64073276850264	36.32071844935511	54592
3e07a445f94978a9026345188fbbd7d0e9464cf9	bildungs- und arbeitsmarktplanung unter einsatz von verfahren der kontrolltheorie		In dieser Arbeit werden Modelle zur simultanen Bildungs- und Arbeitsmarktplanung entwickelt und dargestellt, wobei von Seiten der Kontrolltheorie das diskrete Maximum-Prinzip von Pontryagin besonders berucksichtigt wird. Die Modelle betrachten simultan den Arbeitsmarkt (‘manpower approach’), die Kapazitaten der ausbildenden Institutionen sowie Berufswunsche kunftiger Berufstatiger (‘social demand approach’). Die Modelle werden unterschieden nach Anzahl von Entscheidungs- und Zustandsvariablen. Sie werden anhand von Beispielen demonstriert.		Werner Burckhardt	1973	Zeitschr. für OR	10.1007/BF01980023	mathematical economics;pontryagin's minimum principle;mathematical optimization;mathematics	NLP	-98.29664169986712	35.055856263828	54718
b59173ad0f8ebd3f9998538b124643e3091b4b34	big data		1 Im Gegensatz zu den Club-of-Rome-Problemen, die vom Fortschritt reduziert werden, ist hier der tech-nische Fortschritt der Verursacher des Problems. 2 Die Spieltheorie wird (z.B. im Kalten Kriege) auch von der Politik angewandt.	big data	Liebe Leserinnen	2013	Datenschutz und Datensicherheit - DuD	10.1007/s11623-013-0105-2		NLP	-100.75089088453333	35.45262156293429	54805
0986e2b5a6fc393327a890e34ff3ebde4619c486	biometrie – wie einsetzen und wie keinesfalls?		Biometrie wird als Lösung vieler Authentifizierungs- und Identifizierungsprobleme angepriesen. Sie weist jedoch ein grundlegendes Sicherheitsproblem auf und verursacht zusätzlich Sicherheits- und Datenschutzprobleme. Was genau kann Biometrie, was nicht, und welche Gestaltungsaufgaben stellen sich?	internet explorer;sie (file format)	Andreas Pfitzmann	2006	Informatik-Spektrum	10.1007/s00287-006-0098-4	world wide web;computer science	Crypto	-103.42810269298299	37.459775496438375	54925
83853c001cd841fdf6869e8434bef85b1cf7fa4f	heuristische verfahren zur lösung quadratischer zuordnungsprobleme		Es wird ein Uberblick uber die wichtigsten in der Literatur beschriebenen heuristischen Losungsverfahren fur quadratische Zuordnungsprobleme gegeben.		Rainer E. Burkard	1975	Zeitschr. für OR	10.1007/BF01999750	calculus;mathematical optimization;mathematics	Vision	-97.2121401240212	34.90279698633256	55874
bf67eb10540ae8b3ab5657951b011b20921896da	fuzzy-entscheidungsmodelle im risikomanagement	shareholder value	In den letzten Jahren haben Unternehmen Milliardenverluste an den Finanzmärkten erlitten, u.a. weil die Risiken nicht ausreichend vom jeweiligen Management überwacht wurden oder werden konnten. Aus diesem Grund wurden verschiedene Methoden zur Quantifizierung von Risiken entwickelt, um auf diese Art eine effizientere interne Risikosteuerung zu etablieren. Traditionelle Ansätze verfehlen hierbei häufig das Ziel, wenn qualitativ Daten mit einfließen oder sehr unterschiedliche Risiken sachadäquat zu aggregieren sind. Die Fuzzy Logik basierte Bestimmung der Risikoposition eröffnet jedoch eine überzeugende Möglichkeit verbale Bewertungen mathematisch sinnvoll zu integrieren und Einzelrisiken flexibel zusammenzufassen.	eine and zwei;unified model	Susanne Eickemeier	2002			business	AI	-102.12965950671092	34.34224432584072	55952
5d7a92cb8e99c7dd4da2bff38d0306c9c24118aa	zur axiomatik der friedmanschen theorie der prädikate		In Analogie zur kumulativen Hierarchie der Mengen fuhrte FRIEDMAN in [2] eine kumulative Hierarehie von Pradikaten ein. Dabei benutzte er vier Konstruktionsprinzipien : I. Negat ionsprinzip. Die Negation eines Pradikats ist ein Pradikat. 11. Appl ika t ionspr inz ip . Zu jedem Pradikat x gibt es ein Pradikat, das auf genau die Pradikate. zutrifft, die auf x zutreffen. 111. Reprasenta t ionspr inz ip . Jede Menge M von Pradikaten w-ird durch ein Pradikat in dem Sinne reprasentiert,. daS es ein Pradikat gibt, das auf genau die Elemente der Menge M zutrifft. IV. Vereinigungsprinzip. Die Vereinigung einer Menge M von Pradikaten ist ein Pradikat', das heiBt, es gibt ein Pradikat, das auf genau jene Pradikat'e zutrifft, anf die mindestens ein Element von M zutrifft.. Die Friedmanschen Pradikate genugen auBerdem dem Extensional i ta tspr inzip, das heifit, Pradikate: die auf dieselben Pradikate zutreffen, sind identisch. Eine zur Friedmanschen Pradikatentheorie T von [ Z ] alternative Axiomatisierung PT w r d e in [51 vorgeschlagen. Beide Theorien, T und PT, sind Theorien der ersten Stufe. In elementaren Axiomatisierungen der Pradikatentlieorie konnen aber das Reprasentationsund das Vereinigungsprinzip nicht berucksichtigt werden, ueil darin von Mengen von Pradikaten die Rede ist. In der vorliegenden Arbeit uerden diese beiden Prinzipien formalisiert und in einer Pradikatentheorie PT2 der zweiten Stufe betviesen. Dariiber hinaus werden weitere elementare Axiomatisierungen der Pradikatent'heoric vorgeschlagen. In einer dieser Axiomatisierungen, PT' , fallen die Mengen mit den wohlfundierten Pradikat'en zusammen (eine wissenschaftstheoretisch int'eressante Tat sache). Ferner st'immt die ubertragung der von dem Begriff der Wolilfundiert,heit ausgehenden Churchschen Klassifizierung (low/high/interrnediate) auf PT' iiberein mit der in clieser Arbeit fiir PT' vorgeschlagenen Klassifizierung, die auf den1 Begriff der Beschranktlieit beruht. Die vorliegende Arbeit unterscheidet sich nicht wesentliclz von den1 Preprint, [4]. Hcrrn Dr. D. SCHWARTZ danke ich herzlich fur die kritische Durchsicht des Manuskript.s.	die (integrated circuit);eine and zwei;eddie (text editor);i/o controller hub;pro tools	Martin Kühnrich	1986	Math. Log. Q.	10.1002/malq.19860320702	combinatorics;pure mathematics;mathematics	OS	-96.43052268470804	34.73008459071497	55981
6e7aaa437f93579789ea7d2f39ac91c50b2a7f50	bericht über den workshop bsoa08 in leinfelden		Moderne Integrationsarchitekturen bestimmen zunehmend die Art und Weise, wie softwaretechnische Lösungen im Kontext industrieller Problemstellungen umzusetzen sind. Immer stärker wird den Verantwortlichen dabei bewusst, dass die erfolgreiche Umsetzung derartiger Lösungen von vielfältigen Einflussfaktoren beeinflusst wird. Im Kontext der Softwaremessung werden daher produkt-, prozessund ressourcenbezogene Aspekte sowohl qualitativ, als auch quantitativ aufgegriffen. Die BSOA-Initiative (Bewertungsaspekte serviceorientierter Architekturen) versucht die Erkenntnisse der Softwaremessung speziell auf serviceorientierte Architekturen zu übertragen und veranstaltet dazu jährlich einen entsprechenden Workshop. Der letzte Workshop griff insbesondere die folgenden Themenstellungen auf:	internet explorer	Andreas Schmietendorf	2009	Softwaretechnik-Trends		software engineering;computer science	AI	-101.74542618610461	32.41956343995921	57181
c07fbbe0996adb4c1c9aeee408f9853fe0cc6077	die polizeiliche videoüberwachung öffentlicher orte in niedersachen		Bei der Videoüberwachung handelt es sich um eine sicherheitspolitische Wunderwaffe: Im Vergleich zu im Streifendienst eingesetzten Beamten ist sie relativ kostengünstig und soll das subjektive Sicherheitsgefühl stärken. Die Kameras ermöglichen häufig eine nachträgliche Aufklärung der Straftat, auch wenn ihr Einfluss auf die Begehung von Straftaten umstritten ist. Trotz gewichtiger Bedenken gegen die Effektivität im Rahmen der Gefahrenabwehr wird ihr Einsatz hartnäckig verteidigt und im Zweifelsfall ausgebaut. Es ist verwunderlich, dass es so lange gedauert hat, bis Bürger begonnen haben, gerichtlich gegen polizeiliche Videoüberwachung vorzugehen.	die (integrated circuit);eine and zwei;sie (file format);unified model	Christoph Schnabel	2011	Datenschutz und Datensicherheit - DuD	10.1007/s11623-011-0206-8	computer science;internet privacy;performance art	DB	-104.01404920500472	36.12634066106206	57545
6606b57d48f358f6ccd987d9b51e6295c6dd9c0c	grainy numbers		"""Gilles CHAMPENOIS Collège Saint-André, Saint-Maur, France gilles_champenois@yahoo.fr ABSTRACT. Grainy numbers are defined as tuples of bits. They form a lattice where the meet and the join operations are an addition and a multiplication. They may be substituted for the real numbers in the definition of fuzzy sets. The aim is to propose an alternative negation for the complement that we’ll call supplement. """"Die ganzen Zahlen hat der liebe Gott gemacht, alles andere ist Menschenwerk."""" Leopold Kronecker (1823-1891)"""	fuzzy set	Gilles Champenois	2008	CoRR			DB	-95.37866357303263	34.35540850819846	57658
0ad1a5dc76c5c41be6b8f2641b4bc47a29451b92	when does the position vector of a space curve always lie in its rectifying plane?		1. Y. Baba, On maxima of Takagi–van der Waerden functions, Proc. Amer. Math. Soc. 91 (1984) 373–376. 2. P. Billingsley, Van der Waerden’s continuous nowhere differentiable function, this MONTHLY 89 (1982) 691. 3. A. M. Bruckner, J. B. Bruckner, and B. S. Thomson, Real Analysis, Prentice Hall, Upper Saddle River, NJ, 1997. 4. F. S. Cater, On van der Waerden’s nowhere differentiable function, this MONTHLY 91 (1984) 307–308. 5. H. Federer, Surface area II, Trans. Amer. Math. Soc. 55 (1944) 420–456. 6. , Geometric Measure Theory, Die Grundlehren der mathematischen Wissenschaften, vol. 153, Springer-Verlag, New York, 1969. 7. J. Marcinkiewicz, Sur les séries de Fourier, Fund. Math. 27 (1936) 38–69. 8. F. Riesz and B. Sz.-Nagy, Functional Analysis, Fredrick Unger, New York, 1955. 9. A. Shidfar and K. Sabetfakhri, On the continuity of van der Waerden’s function in the Hölder sense, this MONTHLY 93 (1986) 375–376. 10. , On the Hölder continuity of certain functions, Exposition. Math. 8 (1990) 365–369. 11. T. Takagi, A simple example of the continuous function without derivative, Proc. Phys.-Math. Soc. Tokyo Ser. II 1 (1903) 176–177. 12. B. W. van der Waerden, Ein einfaches Beispiel einer nicht-differenzierbaren stetigen Funktion, Math. Z. 32 (1930) 474–475. 13. H. Whitney, On totally differentiable and smooth functions, Pacific J. Math. 1 (1951) 143–159.	math-matic;maxima;rectifier;scott continuity;springer (tank);weierstrass function	Bang-Yen Chen	2003	The American Mathematical Monthly			Theory	-95.62169728601509	34.576471771553095	58546
8c274e12e3e4fe6752c2ff3cd508218c48f2e92b	die verbindung zwischen verkehrsplanung und sozialen netzwerken		  Die Verkehrsplanung versucht die Entscheidung von Personen während der Ausführung von Aktivitäten des täglichen Lebens zu  beschreiben, zu verstehen und zu modellieren (Ortuzar und Willumsen 2001). Das zugrunde liegende Paradigma dabei ist, dass  das Individuum versucht, seine Bedürfnisse zu befriedigen, während es seinen Nutzen durch die Ausübung von Aktivitäten maximiert.  Dazu müssen unterschiedliche Orte aufgesucht werden. Dabei werden in der Verkehrsplanung hauptsächlich die Raumnutzungsstrukturen,  welche Aktivitäten ermöglichen, die generalisierten Kosten der Nutzung der verfügbaren Infrastrukturen, welche Zugang zu den  Raumnutzungsstrukturen schaffen und die Eigenschaften der Personen als Randbedingungen betrachtet. Lange Zeit waren Aspekte  sozialer Interaktionen keine Erklärungsansätze für das Verkehrsverhalten. Dies lag vor allem an den Schwierigkeiten, solche  Daten zu erheben und der Darstellung von Verkehr als zonenaggregierte Herkunfts-Zielortflüsse, welche für die Bedürfnisse  der Raumplanung als zufriedenstellend präzise angesehen wurden.    	die (integrated circuit)	Andreas Frei;Matthias Kowald;Jeremy K. Hackney;Kay W. Axhausen	2010		10.1007/978-3-531-92575-2_78	lag;history;performance art	Robotics	-105.04900960914867	33.46167713382413	59052
e4902c8881032bd7b1b398a8fbbbb373034fdde4	digitalisierungseffekte in der automatischen bildverarbeitung				Klaus Voss	1975	Elektronische Informationsverarbeitung und Kybernetik		combinatorics;pure mathematics;mathematics	NLP	-95.46969797093006	34.32404920133706	59113
f12e2d1a0047b2b39c4ba9e004f4ab70ffa623df	soa und eu-dienstleistungsrichtlinie in der öffentlichen verwaltung		Die im Dezember 2006 verabschiedete EU-Dienstleistungsrichtlinie (Richtlinie 2006/123/EG) soll den Zugang zum Dienstleistungsmarkt in allen Mitgliedsstaaten der Europäischen Union vereinfachen, bestehende bürokratische Hindernisse für Dienstleistungserbringer abbauen und so die grenzüberschreitende Erbringung von Dienstleistungen in Europa fördern. Bis Dezember 2009 muss die Richtlinie in allen EU-Staaten in nationales Recht überführt werden. Für die Umsetzung haben die Regierungen und Verwaltungen der Mitgliedsländer eine ganze Reihe an Aufgaben zu erledigen, die mit umfangreichen Änderungen des Wirtschaftsund des Verwaltungsrechts verbunden sein werden. So sind im Sinne eines One-Stop-Government einheitliche Ansprechpartner (Artikel 6) für Dienstleistungserbringer einzurichten, die diese bei allen Prozessen mit der Verwaltung begleiten – über den gesamten Lebenszyklus von der Wiege bis zur Bahre: von der Aufnahme der Dienstleistungstätigkeit über die gesamte Ausübung der Dienstleistungstätigkeit bis zur Geschäftsauflösung. Diese einheitlichen Ansprechpartner sollen Dienstleistungserbringer aus anderen EU-Mitgliedsstaaten über alle relevanten Vorgaben und Zuständigkeiten informieren sowie bei der Abwicklung von Verfahren und Formalitäten mit der öffentlichen Verwaltung helfen (Artikel 7). Behörden aller Verwaltungsebenen müssen zudem dafür sorgen, dass die von der EU-Dienstleistungsrichtlinie betroffenen Verwaltungsverfahren elektronisch abgewickelt werden können (Artikel 8). Einheitliche Ansprechpartner und die elektronische Verfahrensabwicklung werden einen ganz wesentlichen Beitrag zur Vereinfachung von Strukturen, Verfahren und Formalitäten leisten. Eine konsequente Umsetzung entsprechender One-StopGovernment-Konzepte auf Basis einer serviceorientierten Architektur (SOA) wird beträchtliche Auswirkungen auf die gesamte öffentliche Verwaltung in allen Mitgliedsstaaten (nationale, subnationale und kommunale Ebene) haben, die weit über den Anwendungsbereich europäischer Dienstleistungsunternehmen hinausreichen.	eine and zwei;emoticon;europa;national cyberdefence centre;zentralblatt math	Ulrich Bode;Jörn von Lucke	2008			electrical connection;aperture;ballast;spark plug;materials science;mechanical engineering	OS	-103.74698080503633	33.48765741189582	59362
47357aeda447032b25c26ff1a29d596e0e4ff43a	open source aus ökonomischer sicht - zu den institutionellen rahmenbedingungen einer spenderkompatiblen rentensuche	crowding out;open source software development;institutional arrangement;rent seeking;open source	Das Phänomen der Open-Source-Software (OSS) betrifft das Management im allgemeinen und die Wirtschaftsinformatik, die sich unter anderem mit Software-Engineering befasst, im besonderen. Offenbar bietet sich hier nämlich eine Alternative zum traditionellen System der Softwareentwicklung – der Entwicklung von proprietärem geistigen Eigentum innerhalb hierarchischer Unternehmensstrukturen – , die überraschend gut zu funktionieren scheint: In sogenannten Open-SourceCommunitys schreiben unbezahlte Beitragsleister Codes, suchen Fehler und organisieren sich selbst, um größere Projekte zu realisieren. Das institutionelle Rückgrat dieser Communitys ist eine Form der Software-Lizenzierung, die mindestens drei Bedingungen erfüllen muss. Die Lizenz muss erstens die freie Redistribution der Software durch jedermann und ohne die Entrichtung von Lizenzgebühren erlauben. Sie muss zweitens sicherstellen, dass der sogenannte „source code“ eines Programms zugänglich ist. Und sie muss drittens Modifikationen und abgeleitete Arbeiten ausdrücklich zulassen und ermöglichen, dass diese unter den gleichen Lizenzbedingungen verteilt werden (http://opensource.org/docs/ definition).		Egon Franck	2003	Wirtschaftsinformatik	10.1007/BF03250917	crowding out;rent-seeking;simulation;computer security	OS	-100.63727485275021	33.691421796174076	59408
cfe17b5233f4a4e0d8c5c30430974a6ccac966d3	die ausfallwahrscheinlichkeit von speichermodulen mit fehlerkorrektur		Einund Mehrfehlerkorrektur zur Verbesserung der SpeicherZuverlässigkeit werden erläutert. An einem Modell, das die periphere Elektronik berücksichtigt und das bei den Speicherbausteinen die vier Ausfallkategorien Einzelzellen-, Spalten-, Zeilenund Totalausfälle unterscheidet, wird die Ausfallwahrscheinlichkeit eines Speichermoduls berechnet. Die durch Fehlerreduktionsfaktoren erfaßbare Wirkung der Teilausfälle verlängert — gegenüber Totalausfällen — die berechnete Zeit bis zum Erreichen einer vorgegebenen Modul-Ausfallwahrscheinlichkeit beispielsweise auf das Zweibis Dreifache. Für die Berechnung muß die relative Häufigkeit der wesentlichen Ausfallkategorien bekannt sein.	die (integrated circuit);v-model	Fritz Gliem	1978	Elektronische Rechenanlagen	10.1524/itit.1978.20.16.170		NLP	-104.30770259462253	32.393694287664495	59465
cffc8f9be94a1ff718af1b392b4ecdf79d735993	informationssysteme in krankenhaus und praxis und die selbstbestimmung des patienten		So segensreich sie bei der medizinischen Informationsverarbeitung auch sind — immer komplexere elektronische Informations- und Kommunikationssysteme im Gesundheitswesen drohen den Patienten zum Objekt technischer Sachzwänge zu machen. Zur Ausschöpfung der technischen Optionen werden ihm nicht nur Schweigepflichtentbindungen und Einwilligungen in Datenverarbeitungen abverlangt, sondern vielfach sogar die Behandlung verweigert, wenn er diese nicht erteilt. Ärztliches Berufsrecht und das Grundrecht auf informationelle Selbstbestimmung sind diesem Trend jedoch nicht schutzlos ausgeliefert.	altran praxis;sie (file format)	Hans-Joachim Menzel	2011	Datenschutz und Datensicherheit - DuD	10.1007/s11623-011-0201-0	praxis;internet privacy;library science;computer science	OS	-103.68309345020238	36.185201838116804	59889
80ce74655f6f8c4d40b87c2bda5202e0f0529daa	leider – ein kommentar zur heutigen it		Er hat seine Aussage sicher nicht auf das Internet und die heutige Informationstechnik bezogen. Und doch trifft sie leider auch auf diese zu. Finden doch das Internet und die heutige IT in immer mehr Bereichen unserer Gesellschaft und zunehmend auch in deren sicherheitskritischen Infrastrukturen Anwendung, obwohl sie diese aufgrund ihrer inhärent vorhandenen und durchaus täglich erfahrbaren Verletzlichkeit letztlich nicht verantwortbaren Gefährdungen aussetzen. Im Bewusstsein von Politik und Wirtschaft wird jedoch das Ausmaß der Gefährdung von Individuum und Gesellschaft durch Hacker, Wirtschaftsspione und Geheimdienste nur unzureichend reflektiert. Es herrscht offensichtlich die Hoffnung vor, dass Szenarien, wie sie z. B. Marc Elsberg in seinem Roman Black Out – Morgen ist es zu spät beschreibt, der schriftstellerischen Fantasie geschuldet sind, aber keine Realität werden können. Dabei kann seinen Szenarien der Realitätsbezug nicht abgesprochen werden; zum einen im Bezug auf die Abhängigkeit unserer Gesellschaft von einer funktionierenden Infrastruktur (bei Elsberg ist dies die Energieversorgung), zum anderen im Bezug auf deren prinzipielle Angreifbarkeit aufgrund der zunehmend eingesetzten und über das Internet global vernetzten IT-Systeme. Im Bewusstsein der normalen IT-Nutzer überwiegt dazu passend die Meinung, solange ich nichts zu verbergen habe, habe ich auch nichts zu befürchten. Aus dieser beruhigend wirkenden Grundüberzeugung resultiert dann die unreflektierte Akzeptanz von Technologien wie der Cloud, die deren Anbieter als Non-Plus-Ultra an Komfort, Verfügbarkeit und Sicherheit anpreisen. Wie fahrlässig naiv diese Grundüberzeugung ist, sollte die Dokumentation in der ARD Exclusiv im Ersten Reportage – Zugriff! Wenn das Netz zum Gegner wird (Montag, 7. Juli 2014) jedem vor Augen geführt haben. In diesem Beitrag wurde am individuellen, aber durchaus repräsentativen Fall eines Journalisten, gezeigt, welche ausufernde Menge an Information privater und beruflicher Art sich in einer Cloud über Jahre ansammelt und welche Möglichkeiten zu Eingriffen in die private wie berufliche Sphäre bis hin zum Identitätsdiebstahl dies für böswillige Angreifer eröffnet. Basis des demonstrierten Angriffs waren einige wenige Einzelaktionen, wie:	hacker;i/o controller hub;intentionally blank page;internet explorer;sie (file format);vhf omnidirectional range;zur farbenlehre	Heinz Jürgen Burkhardt;Rainer Prinoth	2014	Informatik-Spektrum	10.1007/s00287-014-0869-2	world wide web;software engineering;computer science	DB	-104.36515930145735	36.301008619404065	60164
7b7af751cbdfaf99e0b27aa3e3ce2a4d1b47c1e8	a successive approximation algorithm for an undiscounted markov decision process	optimal solution;approximate algorithm;optimal policy;space use;upper and lower bounds;markov decision process	In this paper we consider a completely ergodic Markov decision process with finite state and decision spaces using the average return per unit time criterion. An algorithm is derived which approximates the optimal solution. It will be shown that this algorithm is finite and supplies upper and lower bounds for the maximal average return and a nearly optimal policy with average return between these bounds. Diese Arbeit betrachtet den ergodischen Markov-Entscheidungsprozeß mit endlichem Zustandsraum und endlichen Aktionsmengen mit dem Kriterium des Durchschnittsertrags. Ein Algorithmus wird presentiert, der diesen Ertrag approximiert. Es wird bewiesen, daß der Algorithmus konvergiert, und es werden obere und untere Schranken zum optimalen Durchschnittsertrag gegeben. Außerdem wird eine Strategie bestimmt mit zugehörigem Durchschnittsertrag zwischen diesen Schranken.	approximation algorithm;eine and zwei;ergodicity;markov chain;markov decision process;maximal set;return statement	J. van der Wal	1976	Computing	10.1007/BF02276760	markov decision process;mathematical optimization;combinatorics;discrete mathematics;partially observable markov decision process;mathematics;markov process;markov model;upper and lower bounds	ML	-97.22613188756769	36.505783756880994	60221
294be4ca218a55a24e73eb9a9fa58dca94e0aa54	auffinden von spaltenkorrelationen mithilfe proaktiver und reaktiver verfahren		Zur Verbesserung von Statistikdaten in relativen Datenbanksystemen werden seit einigen Jahren Verfahren für das Finden von Korrelationen zwischen zwei oder mehr Spalten entwickelt. Dieses Wissen über Korrelationen ist notwendig, weil der Optimizer des Datenbankmanagementsystems (DBMS) bei der Anfrageplanerstellung sonst von Unabhängigkeit der Daten ausgeht, was wiederum zu groben Fehlern bei der Kostenschätzung und somit zu schlechten Ausführungsplänen führen kann. Die entsprechenden Verfahren gliedern sich grob in proaktive und reaktive Verfahren: Erstere liefern ein gutes Gesamtbild über sämtliche vorhandenen Daten, müssen dazu allerdings selbst regelmäßig auf die Daten zugreifen und benötigen somit Kapazität des DBMS. Letztere überwachen und analysieren hingegen die Anfrageergebnisse und liefern daher nur Korrelationsannahmen für bereits abgefragte Daten, was einerseits das bisherige Nutzerinteresse sehr gut widerspiegelt, andererseits aber bei Änderungen desWorkloads versagen kann. Dafür wird einzig bei der Überwachung der Anfragen DBMS-Kapazität benötigt, es erfolgt kein eigenständiger Zugriff auf die Daten. Im Zuge dieser Arbeit werden beide Ansätze miteinander verbunden, um ihre jeweiligen Vorteile auszunutzen. Dazu werden die sich ergebenden Herausforderungen, wie sich widersprechende Korrelationsannahmen, aufgezeigt und als Lösungsansatz u. a. der zusätzliche Einsatz von reaktiv erstellten Statistiken vorgeschlagen.	eine and zwei;eddie (text editor);internet explorer;unified model	Katharina Büchse	2013			history;performance art	OS	-105.14976112322353	33.18306114378079	60637
dc0f2deacad705d7485a58193e6d64fc6090e6d7	das electure-portal der universität freiburg	workshop	Seit den 90er Jahren sind Vorlesungsaufzeichnungen, sogenannte eLectures ein etablierter Bestandteil des alltäglichen e-Learnings geworden. Sie setzen sich an immer mehr Universitäten und Fachbereichen als Ergänzung der Präsenzlehre durch. eLectures repräsentieren den Lehrstoff anhand multimedialer Dokumente (”virtuelle Vorlesungen”). Bei den aufgezeichneten Medien handelt es sich um den gesprochenen Vortrag sowie die Präsentationsfolien, die synchron wiedergegeben werden. Hierbei wird auch die Interaktion des Vortragenden mit den Materialien erfasst wie z.B. das Zeigen auf bestimmte Teile einer Folie, Hervorhebungen oder handschriftliche Kommentare. Die zeitlich synchrone Wiedergabe dieser dynamischen Annotationen fördert die Verständlichkeit komplexer Inhalte. Weitere Medienströme, die aufgezeichnet werden können, sind das Videobild des Vortragenden bzw. gezeigter Gegenstände oder Experimente sowie auf dem Präsentationsrechner vorgeführte Applikationen. Die Datenmenge einer bearbeiteten Aufzeichnung einer Vorlesung als eLecture kann u.U. mehrere hundert Megabyte umfassen, weshalb anfänglich diese Aufzeichnungen mittels Kopien von CDs an die Studierenden verteilt wurden. Durch die fortschreitende technologische Entwicklung sowie durch immer schnellere breitbandige Internetzugänge ergibt sich ein ganz neues Nachfrageverhalten. Die Studierenden wollen die Vorlesungsaufzeichnungen nicht umständlich auf einer CD erhalten, sondern möglichst jederzeit gezielt auf einzelne Veranstaltungen zugreifen können. Aus diesem Grund wurde in der Informatik an der Universität Freiburg ein Portal entwickelt, welches zunächst die strukturierte Archivierung, sowie den Zugriff über das Internet auf die Vorlesungsaufzeichnungen ermöglichte.	die (integrated circuit);internet explorer;megabyte;sie (file format);unified model	Christoph Hermann;Wolfgang Hürst;Martina Welte	2006			performance art;art	OS	-103.47120025871331	32.57038120871546	60648
066cf778ceb1988116e87e6b3569ee199d483602	metriken für eigenentwicklungen in sap erp systemen		Für den Betrieb von großen SAP ERP-Systemen spielen Eigenentwicklungen eine wichtige Rolle. Sie tragen zwischen 15% und 35% der kompletten Betriebskosten der SAP-Systeme. In Upgrade-Projekten entfallen zwischen 60% und 80% der Kosten auf das Testen von Eigenentwicklungen. Von daher spielen Mengengerüste für Eigenentwicklungen eine wichtige Rolle in der Beurteilung von SAPKosten. Entsprechende Metriken werden hier dargestellt, basierend auf Auswertungen von Nutzungsdaten aus SAP-Systemen von jeweils mindestens einem Jahr. Wir liefern Metriken zur Nutzung von Eigenentwicklungen, zu den Kosten von Eigenentwicklungen und zu ihrer Performance. Datengrundlage sind Meßdaten von 118 verschiedene SAP ERP-Systeme. In diesen Systemen wurde für jede Transaktion und jeden Report pro Stunde die Zahl der Steps getrennt nach Tasktypen (Dialog, Batch, etc.) erfasst, dazu Ressourcenverbräuche wie CPU-Last, Datenbankzugriffe und die Laufzeit. Weiter wurden die Tcode-Tabelle und Master-Include Beziehungen des SAP-Systems vermessen um festzustellen, welche Transaktion oder welches Programm andere Programme, Includes, Screens, etc. aufruft. Zusätzlich zu diesen Meßdaten wurde für alle Systeme eine vollständige Erfassung der Betriebskosten durchgeführt. Die Betriebskosten enthalten laufende Kosten und Abschreibungen aus dem Rechenzentrumsbetrieb, für die Datenbank, die SAP-Basis, den vollständigen Applikationsbetrieb inkl. Support, Incident Management, Change Management, Benutzerverwaltung, Administration, etc. Ein wesentliches Resultat ist, dass die Zahl der tägliche genutzten kundeneigenen Transaktionen und Reports als unabhängige Variable sehr gut geeignet ist. Wir liefern Modelle für verschiedene Kennzahlen, z.B. die Zahl der verwendeten Eigenentwicklungen, die Zahl der verwendeten Programme oder die Zahl der vorhandenen Eigenentwicklungen in Abhängigkeit von der Zahl der tägliche genutzten kundeneigenen Transaktionen und Reports, außerdem Aussagen zur Performance und zu Kosten von Eigenentwicklungen. Ein Ergebnis ist auch, daß die Branche des Unternehmens, von dem das System genutzt wird, kein signifikanter Faktor ist.	central processing unit;eine and zwei;erp;gesellschaft für informatik;incident management;intentionally blank page;internet explorer;sie (file format);unified model;dialog	Andreas Mielke	2011				DB	-102.62618507205866	34.28087249898225	61217
b4f58d92a856cb68d61f7dd47b8ba0db1be115df	messung von herzwandbewegung mit mr-interferographie		MR-Interferographie 1] ist eine Methode in der Me-dizinischen Bildgebung, die das nichtinvasive Messen von Herzwandbewegung erm olicht 2]. Hierzu wird ein interferographisches Muster auf Kurzachsenschnitte des linken Ventrikels projiziert, welches die lokale Be-wegung des Myokards charakterisiert. Die Bestimmung phasensensitiver Parameter in der Signalverarbeitung mit Interferographie ist eine bekannte Messtechnik und beruht auf den Eigenschaften der Fouriertrans-formation fuer zwei oder mehr einander ueberlagerte Signale. MR-Interferographie erreicht eine funktionel-le Auuoesung, die durch das zugrunde liegende anato-mische Bild gegeben ist. Die funktionelle Abbildung ist ueber den gesamten EKG-Zyklus moeglich. Die Interferographie beruht auf der Uberlagerung zwei-er Signale, die sich gering in ihrer Phase unterschei-den. Dieses, bereits in der optischen Messtechnik aus-gen utzte Ph anomen resultiert aus dem Additionstheo-rem (Glg.1) und dem Verschiebungstheorem (Glg.3) der Fouriertransformation. Die Fouriertransformierte FT der Summe zweier Si-gnale ist identisch der Summe der FT der einzelnen Signale: F(s 1 (t) + s 2 (t)) = S 1 (!) + S 2 (!): (1) Hierbei steht F fuer den Fourier-Operator der FT und S(!) fuer die Fouriertransformierte des einzelnen Signals s(t). Fuer ein Signal s(t ?), das bis auf ei-ne Zeitverschiebung identisch ist, gilt das Verschie-bungstheorem: F(s(t ?)) = S(!)exp(?i!) = S(f)exp(?i2ft); (2) d.h. es resultiert aus der Anwendung dieses Theorems eine Modulation des fouriertransformierten Datensi-gnals s(!) im korrespondierenden Koordinatenraum. FT 0 0 t t s(t) s(t) ω ω S() ω S() ω FT Abbildung 1: Additionstheorem und Verschiebungs-theorem der 1D Fouriertransformation Werden nun simultan zwei Datensignale akquiriert, wobei das zweite Signal etwas zeitverzoegert aufge-nommen wird, dann ergibt sich nach der FT fuer diese beiden Signale durch das Additionstheorem und das Verschiebungstheorem: F(s(t) + s(t ?)) = S(!)(1 + exp(?i!)); (3) Der trigonometrische Term exp(?i!) f uhrt zu einer Amplitudenmodulation von S(!). Das resultierende sinusf ormige Modulationsmuster wird dem Datensi-gnal S(!) uberlagert dargstellt, wobei S(!) ein anato-misches MR-Tomogramm repr asentiert. Erf ahrt nun das zeitverz ogerte Signal s(t?) eine Phasenverschie-bung ' 0 bez uglich s(t), so f uhrt dies zu einer iden-tischen Phasenverschiebung der korrespondierenden Fouriertransformierten, w ahrend das zugrundeliegen-de Referenzsignal s(!) unver andert bleibt: S(!)+F(s(t?)) = S(!)(1+exp(?i!)exp(?i' 0)); (4) In Abbildung 1 ist das resultierende Modulationsmu-ster und die Phasenverschiebung des zweiten, zeitver-zoegerten Datensignals mit der korrespondierenden Phasenverschiebung nach der FT graphisch darge-stellt. In einem bewegungskodierenden MR-Experiment werden mit kurzer Zeitverz ogerung zwei Datensigna	citeseerx;comment (computer programming);eine and zwei;modulation	Simone Peschl;R. Strecker;Michael Markl;Dietmar Saupe;Jürgen Hennig	1996					-105.47838800638905	33.14497444141964	61853
3f5108a0d027e0c499b108c68144e65f32bf08a5	globale zyklische schedulingstrategie - ein ansatz zur garantie der harten zeitbedingungen inverteilten echtzeitsystemen				Ralf Agne	1992			mathematical physics;ansatz;mathematics	HCI	-97.00109636538379	34.30607181747414	61922
548ece0ab81d79f10311d3f2744d835e17132d51	entwicklungsmethodik für kommunikationsprotokolle auf der basis von software pattern		Ziel dieses Artikels ist eine Verbesserung des Entwicklungsprozesses von Kommunikationsprotokollen verteilter Systeme mit Entwurfsmustern. Dazu wird hier das“General Distributed Proxy” Pattern beschrieben. Es ist ein Entwurfsmuster für die Kommunikation verteilter Objekte das das “Distributed Proxy” Pattern [SRG 02], [SRGA 02] im Sinne der Offenhaltung des Kommunikationsprotokolls verallgemeinert. Es dient somit als allgemeine Basis für den Entwurf eines Kommunikationsprotokolls und zur Verbesserung dieses Prozesses. In diesem Artikel wird das “General Distributed Proxy” Pattern beschrieben, mit dem Distributed Proxy verglichen und seine Anwendung am Beispiel eines einfachen File Transfer Protokolls (FTP) demonstriert. This paper aims to improve the process of communication protocol development using Software Pattern. It presents a “General Distributed Proxy” pattern, a design pattern for distributed object communication based upon the “Distributed Proxy” Pattern [SRG 02], [SRGA 02]. Opposite to the “Distributed Proxy” pattern the “General Distributed Proxy” pattern does not predetermine the communication protocol of the distributed objects. The General Distributed Proxy serves as base of communication protocol design and as process improvement. This paper describes the “General Distributed Proxy” pattern and compares it to “Distributed Proxy” pattern. In addition, an example protocol is presented. It is a primitive file transfer protocol (FTP).	communications protocol;distributed object communication;eine and zwei;file transfer;institut für dokumentologie und editorik;proxy pattern;software design pattern;strongly regular graph	Beate Commentz-Walter	2002	Softwaretechnik-Trends		computer science;software engineering;software	HPC	-98.33072960651612	32.37792705320394	62041
39d1e617a19cd8cf7857d415efab9284538bdeb8	integration eines systems zur abrechnung personeller dienste in ein abrechnungssystem maschineller leistungen		Die Grundlage eines Systems zur Abrechnung von Leistungen, die ein wissenschaftliches Rechen- und Kompetenzzentrum erbringt, ist die Erfassung der erbrachten Leistungen. Diese Aussage bezieht sicht sowohl auf maschinelle Leistungen, die in lange bekannten Accountingsystemen aufgezeichnet werden, als auch auf personelle Dienste, die in Datenbanken festgehalten werden. Die personellen Dienste mussen dazu in Teilaufgaben zerlegt werden, die wiederum detailliert beschrieben sind. Jeder Teilaufgabe kann ein Wert zugewiesen werden. Die Gesellschaft fur wissenschaftliche Datenverarbeitung mbH Gottingen (GWDG) nennt die Werteinheit, in der die Teilaufgaben bewertet werden, „Arbeitseinheit“. Der Wert einer Teilaufgabe kann anhand der Kosten festgesetzt werden, die zur Erbringung der Teilaufgabe verursacht werden. Analog konnen auch die maschinellen Leistungen und die Netzdienste bewertet werden. Um die maschinellen Leistungen und die personellen Dienste in ein gemeinsames Abrechnungssystem zu integrieren, wird fur jede maschinelle Leistung und jede erbrachte Teilaufgabe ein Accounting-Record erzeugt, der die Daten der in Anspruch genommenen Leistung und des zugehorigen Werts in Arbeitseinheiten enthalt. Damit sind diese Daten auf einfache Weise einer statistischen Auswertung zuganglich.		Wilfried Grieger	1995				Arch	-104.60893725221034	32.4341478446386	62173
b1862b9db1736827c3c623ff35dc2df2a9e84d61	einordnung und terminologie des software reengineering	330 wirtschaft;design recovery;information management;reverse engineering	Der vorliegende Aufsatz ordnet das Software Reengineering in das Software Engineering ein und trifft Festlegungen fur die wichtigsten Begriffe des Software Reengineering.Er stellt das Ergebnis einer Arbeitsgruppe der GI-Fachgruppe 5.1.3 „Reengineering und Wartung betrieblicher Anwendungssysteme“ dar.Ziel der Arbeitsgruppe war es,eine einheitliche terminologische Grundlage fur Forschung und Praxis zu schaffen.Zu diesem Zweck wurde zunachst die Verwendung der Begriffe in der Literatur untersucht. Darauf#R##N#aufbauend erfolgte die Formulierung der Definitionen.	code refactoring	Ulrike Baumöl;Jens Borchers;Stefan Eicker;Knut Hildebrand;Reinhard Jung;Franz Lehner	1996	Informatik-Spektrum	10.1007/s002870050030	computer science;operating system;information management;reverse engineering	Crypto	-101.33636426560118	32.50638640048215	62261
5b2a4d6c3cd94937f799ed635911b11e659e9b87	geri's game	reversible markov chains;combinatorial optimizatiion;simulated annealing;randomization techniques	O curta se passa em uma tarde tranquila, Geri, como já foi dito, está sozinho jogando xadrez, ele joga dos dois lados da mesa, a cada jogada ele assume a posição do “outro” jogador, joga com ele mesmo. Geri assume duas personalidades, uma a qual mostra sua condição no presente e a outra se mostra como uma personalidade mais jovem de Geri. No decorrer do jogo a parte jovem de Geri começa a ganhar sem dar nenhuma chance para a parte idosa.		Karen Dufilho	1998		10.1145/281388.281876	mathematical optimization;combinatorics;simulated annealing;computer science;machine learning	ML	-97.35444921669155	37.51729850217864	62271
47061055d8ce3f71dc8e6bae607b5fe8d987a262	big data in der zivilen sicherheitsforschung - methoden zur datenvisualisierung für die explorative analyse von feuerwehreinsatzdaten		Dieser Beitrag gibt Einblicke in ein laufendes Dissertationssowie ein abgeschlossenes Studienprojekt des Masterprogramms Geoinformation und Visualisierung an der Universität Potsdam. Untersucht wird die räumliche und zeitliche Verteilung von Notfällen, die mit Fokus auf deutsche Feuerwehren bislang nur unzureichend wissenschaftlich betrachtet wurden. Eine Herausforderung stellen Big Data dar: enorme Datenmengen, die vorhanden (auch künftig erhoben werden) und deren Variablen untereinander verknüpft sind. Diese visuelle Datenpräprozessierung bildet eine Basis für statistische Analysen und (Geo-) Visualisierungen mit dem Ziel, statistische strategische, operationelle und taktische Planungen sowie Präventionsmaßnahmen zu unterstützen.	big data;eine and zwei;geographic information system	Julia Gonschorek;Hartmut Asche;Harald Schernthanner;Anja Langer;Caroline Räbiger;Benjamin Bernhardt;Marius Humpert	2015	AGIT Journal	10.14627/537557075	data science;big data;sociology	ML	-100.75664848296218	35.400094706562015	62425
3500b8950530b979da01860e632f1ef2e6988b39	translation sets of permutations: enumeration of selfcomplementary step-cycles		For given integern>2, there corresponds to each step-cycle a set of permutations, called a translation set. All the translation sets of permutations on the setS={1, 2, ...,n−1} form a set of equivalence classes on the set of all permutations onS. The selfcomplementary step-cycles are described and enumerated. A more general introduction to translation sets may be found in [4] and [3]. Für eine gegebene Zahln>2 gibt es zu jedem “step-cycle” eine Menge von Permutationen, genannt Translationsmenge. Alle diese Translationsmengen von Permutationen auf der MengeS={1, 2. ...,n−1} bilden eine Menge von Äquivalenzklassen auf der Menge aller Permutationen aufS. Die selbst-komplementären “step-cycles” werden beschrieben und abgezählt. Bezüglich der Translationsmengen kann man in [4] und [3] eine allgemeinere Einführung finden.	eine and zwei;turing completeness	Svein Mossige	1975	Computing	10.1007/BF02242313	calculus;mathematics;algorithm	Arch	-95.81076937847129	34.6155411157407	62552
4d4e62314c70456c1d1a62026f4201525246b38a	nichtbeweisbarkeit von gewissen kombinatorischen eigenschaften endlicher bäume	second order;proof theory;close relationships	In this paper we exposit some as yet unpublished results of Harvey Friedman. These results provide the most dramatic examples so far known of mathematically meaningful theorems of finite combinatorics which are unprovable in certain logical systems. The relevant logical systems, A T R o and I I l C A o , are well known as relatively strong fragments of second order arithmetic. The unprovable combinatorial theorems are concerned with embeddability properties of finite trees. Friedman's method is based in part of the existence of a close relationship between finite trees on the one hand, and systems of ordinal notations which occur in Gentzen-style proof theory on the other. Zusammenfassung. In der vorliegenden Arbeit stellen wir gewisse bis jetzt nicht ver6ffentlichte Forschungsergebnisse yon Harvey Friedman vor. Diese Ergebnisse liefern die eindrucksvollsten bis jetzt gefundenen Beispiele yon mathematisch bedeutsamen S/itzen der endlichen Kombinatorik, die in gewissen logischen Systemen nicht beweisbar sind. Die betroffenen logischen Systeme A T R o und 1-iI C A o sind als verhfiltnism/il3ig starke Teilsysteme der Arithmetik der zweiten Stufe bekannt. Die nicht beweisbaren kombinatorischen S/itze haben mit Einbettbarkeitseigenschaften endlicher B/iume zu tun. Friedmans Methode grfindet sich zum Teil aufeine enge Verbindung zwischen endlichen B/lumen einerseits und den Ordinalzahlbezeichnungssystemen andererseits, die in der an Gentzen anknfipfenden Beweistheorie vorkommen.	nat friedman;ordinal data;tun (product standard);vhf omnidirectional range	Stephen G. Simpson	1985	Arch. Math. Log.	10.1007/BF02007556	proof theory;mathematics;second-order logic	Theory	-95.27573801936134	35.050547806637404	62955
2a3e96e020a62ad5057cfda6051a054dc9c57436	die wirtschaftsinformatik im spannungsfeld zwischen vielfalt und profilbildung: auf der suche nach den kernkompetenzen einer vielfältigen disziplin		Dass die Wirtschaftsinformatik-Forschung durch eine ausgeprägte Vielfalt gekennzeichnet ist, wird schon bei der Durchsicht der Tagungsprogramme einschlägiger Konferenzen deutlich. Dazu kommt der Eindruck, dass Forschungsthemen der Wirtschaftsinformatik (WI) stark beeinflusst werden von i. d. R. kurzlebigen Hypes und Modethemen der Beratungsund Softwarebranche. Aus der Vielfalt der WI erwachsen der Disziplin deutliche Herausforderungen für die langfristige Profilbildung. Der folgende Beitrag widmet sich dem beschriebenen Spannungsfeld. Dazu werden im ersten Teil Dimensionen der Vielfalt der Forschung in der WI aufgezeigt und unter Rückgriff auf Diskussionsbeiträge in der Literatur sowie Ergebnisse verschiedener empirischer Studien näher untersucht. Der zweite Teil des Beitrags identifiziert charakteristische Merkmale der WI-Forschung und untersucht anhand der Kriterien des Ressourcenorientierten Ansatzes, inwiefern diese für eine langfristige Profilbildung der WI geeignet erscheinen. Auf Basis der Analyse werden abschließend Handlungsoptionen für eine zukünftige inhaltliche Ausrichtung der WI formuliert. 1 Motivation und Einführung Die Wirtschaftsinformatik (WI) ist eine anwendungsorientierte Disziplin. Daher ist es wenig überraschend, dass die Themen der WI seit jeher von Moden der Praxis stark beeinflusst werden. Dies gilt für Managementmoden ebenso wie für „Buzzwörter“ der Informationstechnik. Sowohl die Vielfalt der Modethemen und deren Wechsel im Zeitverlauf als auch ein breites Spektrum an Perspektiven auf den Forschungsgegenstand Informationssystem (IS) erzeugen den Eindruck einer vielfältigen, sehr breit interessierten Disziplin. Ein aktiver Entwicklungsprozess der Disziplin WI in Abgrenzung zu den Nachbardisziplinen Betriebswirtschaftslehre (BWL) und (Angewandte) Informatik sowie der Prozess der Internationalisierung können von einer einheitlichen Disziplin deutlich leichter geprägt und gesteuert werden als von einer durch übermäßige Vielfalt oder gar Beliebigkeit gekennzeichneten. Der aktuelle Druck zur Internationalisierung von Forschung und	altran praxis;eine and zwei;gesellschaft für informatik;information system;internet explorer	Carola Schauer;Hanno Schauer	2008			knowledge management;computer science;performance art	OS	-103.61789247531243	33.502957739982314	63055
4a8cfbfc14c70753b21e708abe8a2e1b450a6d88	wissensmanagement im rahmen der prozessorientierten einführung von e-procurement und supplier relationship management	supplier relationship management	Europas Konzerne investieren trotz Konjunkturfloute ungebremst i n den elektronischen Einkauf. E-Pr~urement stelk einen wesentlichen Baustein auf dem Weg zurn Supplier Relationship Monogement (SRM) dar. Die Komplexität der Projekte wird oft unterschätzt Um einen schnellen ROi sicherzustellen, ist eineprozessorientierte Einführung sowie aktives Wissensmanagement unerlässlich. Jede Projektphase generiert eine Füiie von Dokumenten, die inhaltlich auf vielfältige Weise zusammenhängen. Hierin manifestieri sich das Wissen der Projektmitglieder, das späterfür Schulungen und den Roll-out dringend benötigt wird. Anhand eines lmplementierungsprojektes mit dem SAF@ Enterprise Buyer ProfessionalN beschreiben wir den Einsatzdes Wissensmanagement-Werkzeuges CognoVisionTM. Neben der Umsetzung der formulierten Anforderungen wird darauf eingegangen, wie vordefinierter E-ProcurementiSRM-Content, zurn Beispiel Referenzmodelle, den Aufwand reduzieren und eine strukturierte Einführung ebenso wie das Change Management unterstützen konn.	e-procurement;eine and zwei;internet explorer;procurement;supplier relationship management;unified model	Volker Nissen;Andreas Mauß	2002	HMD - Praxis Wirtschaftsinform.		supplier relationship management;marketing;process management;e-procurement;engineering	OS	-101.25394668428928	34.27802312611917	63413
11e91b077656b54261ef97f1c507e21cefa970b2	enterprise meta modeling methods - combining a stakeholder-oriented and a causality-based approach	causal analysis;production engineering human work science and ergonomics;produktionsteknik arbetsvetenskap och ergonomi;computer and information science;information management;enterprise system;data och informationsvetenskap;causal models;enterprise architecture;meta model	..................................................................................................................... xix 1 Einleitung ................................................................................................................. 1 1.1 Motivation der Arbeit ..................................................................................... 1 1.2 Zielsetzung der Arbeit .................................................................................... 5 1.3 Aufbau der Arbeit ........................................................................................... 6 2 Grundlagen .............................................................................................................. 7 2.1 Business Engineering ..................................................................................... 7 2.2 Unternehmensarchitektur ............................................................................... 8 2.3 Planung in der Betriebswirtschaftslehre ....................................................... 10 3 Bestehende Ansätze ............................................................................................... 12 3.1 Ansätze zur Planung der Unternehmensarchitektur ..................................... 12 3.2 Ansätze zu Fokusthemen dieser Arbeit ........................................................ 14 3.2.1 Prozesse für die Planung der Unternehmensarchitektur .......................... 15 3.2.2 Metamodellierung .................................................................................... 16 3.2.3 Bewertung von Soll-Architekturen .......................................................... 17 4 Beiträge der Arbeit ............................................................................................... 20 4.1 Einordnung der einzelnen Beiträge .............................................................. 20 4.2 Forschungsprozess ........................................................................................ 25 4.3 Formale Anmerkungen ................................................................................. 27 vi Inhaltsverzeichnis 5 Zusammenfassung, Diskussion und Ausblick .................................................... 28 5.1 Zusammenfassung ........................................................................................ 28 5.2 Diskussion .................................................................................................... 29 5.3 Ausblick ....................................................................................................... 31 6 Beitrag A: Enterprise Architecture Design as an Engineering Discipline ...... 35 6.	business engineering;causality;enterprise architecture	Robert Lagerström;Jan Saat;Ulrik Franke;Stephan Aier;Mathias Ekstedt	2009		10.1007/978-3-642-01862-6_31	enterprise architecture framework;functional software architecture;metamodeling;enterprise system;enterprise software;computer science;systems engineering;knowledge management;architecture domain;integrated enterprise modeling;enterprise architecture management;database;management science;enterprise architecture;information management;enterprise integration;view model;management;enterprise information security architecture;enterprise information system;causal model;business architecture	OS	-100.83927817483142	33.15790771656967	63414
41c0e7764a1262c702102d03f796c506a792cb6b	verlustleistungsreduzierung bei dynamischen tspc-schaltungstechniken		Diese Arbeit stellt die neue, dynamische Schaltungstechnik Asynchronous-Chain-True-Single-Phase-Clock-Logik (AC-TSPC) mit sehr hoher Geschwindigkeit und verringerter Leistungsaufnahme vor. AC-TSPC weist ein extrem niedriges Power-Delay-Produkt auf und arbeitet nach dem „Global Synchron Lokal Asynchron“ Prinzip. Da Low-Power-Systemdesign der Berücksichtigung aller Entwurfsund Realisierungsebenen bedarf, wurden Untersuchungen in den verschiedenen Ebenen auch bezüglich ihrer Verträglichkeit untereinander durchgeführt. So zeigen die Ergebnisse der Single-rail-AC-TSPCLogik, dass diese besonders effektiv mit redundanten Signed-Digit-Zahlen eingesetzt werden kann. Dieses Zahlensystem stellt ebenfalls die Grundlage des von uns entwickelten Flächensparalgorithmus dar, wodurch ein durchweg optimiertes Design entstehen kann. Da in zukünftigen Prozessen neben der dynamischen Verlustleistung die statische Verlustleistung zu Zeiten geringer Aktivität einen großen Einfluss haben wird, wurden Ansätze für den Einsatz von Transistoren mit verschiedenen Schwellspannungen bei MVT-Technologien auf verschiedenen Entwurfsebenen untersucht. Die Verlustleistung kann damit ohne Einschränkungen in der Geschwindigkeit stark verringert werden. Für einen Einsatz neuer Schaltungstechniken ist ein weitgehend automatisierter Designflow notwendig. Daher wurde während der Arbeiten erstmals ein Designflow für dynamische Schaltungstechniken entwickelt, mit dem TSPC-Logiken, sowie Domino-Logik oder auch Clock-Delayed-Logiken nahezu vollständig automatisch synthetisiert werden können. Dieser Flow wurde in den industrieüblichen Designflow quasi nahtlos integriert und enthält bereits einige weiterführende Ansätze für eine nochmalige Reduzierung der Verlustleistung. Unsere Arbeiten haben wir mit der Untersuchung von diversen Beispielschaltungen abgeschlossen, wobei eine automatisierte Synthese für verschiedene Schaltungstechniken den Ausgangspunkt bildet. Darauf aufbauend wurden Testumgebungen für die Schaltungen entwickelt, die den Vergleich der Geschwindigkeit oder auch Leistungsaufnahme auf Transistorebene ermöglichen. Nur so kann überprüft werden, inwieweit eine optimale Verbindung z.B. zwischen Algorithmus und Schaltungstechnik erfolgt. Im Rahmen von Kooperationen mit großen Halbleiterherstellern wurden bereits Simulationen für die Integration dieser und weiterer dynamischer Schaltungstechniken auf Testchips durchgeführt.	eine and zwei;gesellschaft für informatik;intentionally blank page;low-power broadcasting;vhf omnidirectional range	Frank Grassert;Frank Sill;Claas Cornelius;Dirk Timmermann	2005			art;performance art	OS	-105.36450920063459	32.66323206458787	64195
23acc03ae2c293d08562bc5729d4846d62dc6c61	datenschutz und -sicherheit in einer zunehmend vernetzten welt		Die Nutzung mobiler Anwendungen setzt häufig die Einwilligung in die Verarbeitung und Weitergabe personenbezogener Daten voraus. Gleichseitig führt die oftmals sehr komplexe Datenverarbeitung dazu, dass Nutzerinnen und Nutzer kaum noch nachvollziehen können, welche Konsequenzen sich aus ihrer Einwilligung ergeben. Wir diskutieren im vorliegenden Artikel einige Ansätze, die zum Ziel haben, selbstbestimmtes Handeln in der digitalen Welt wieder zu ermöglichen.		Marian Margraf	2017	Datenschutz und Datensicherheit - DuD	10.1007/s11623-017-0719-x	internet privacy;computer science	AI	-103.87369103704704	36.28784319369379	64526
ec3277c91e4c4a06f6d94d1832d7314984abaf90	bereitstellung von geodaten mit marktplätzen und portalen	bereitstellung von geodaten mit	Ggw. bestehen Probleme bezüglich der Transparenz des Angebots und insbesondere in der physischen Verfügbarkeit der vorhandenen amtlichen und privatwirtschaftlichen Geodaten. Grundsätzliche Abhilfe können hierzu Geodatenhandelsplattformen schaffen, deren prinzipieller Wirkungsmechanismus am folgenden Beispiel erläutert wird. Mit einer solchen Geodatenhandelsplattform werden die Nutzenspotentiale der Geodaten instrumentalisiert und erschlossen. 1 Grundsätzliche Lösung Eine Geodatenhandelsplattform ist eine Basislösung für die internetbasierte Vermarktung von Geobasisdaten und Geoinformationsprodukten, welche die Schaffung spezieller Portale („Stände“ auf einem Marktplatz) für entsprechende Nutzergruppen ermöglicht. Solche Nutzergruppen sind interne Nutzer verschiedener Fachbereiche einer Kommune oder externe Nutzer, wie Bürger und Investoren sowie die Privatwirtschaft in zahlreichen Branchen, wie Immobilienwirtschaft, Utiliies u.s.w. Dabei hält die Geodatenhandelsplattform selbst grundsätzlich keine Daten vor, sondern greift internetbasiert auf Daten der Datenanbieter zu (Abb. 1). Die Grundidee besteht also darin, alle erforderlichen Daten nutzergruppenspezifisch auf Basis von Internet-Technologien online bereitzustellen: Nutzer benötigen Informationen und Entscheidungshilfen, um Aufgaben zu lösen. Dazu brauchen sie auf ihre Bedürfnisse zugeschnittene Informationen und Dienstleistungen. Hierzu müssen die verfügbaren Daten nutzerspezifisch aufbereitet und intern wie extern vermarktet werden. Für spezifische Nutzergrupppen der öffentlichen Verwaltung (in Abb. 1 für die Sachbereiche Geobasisdaten, Infrastrukturdaten Ver-/Entsorgung, Baugenehmigungsverfahren, Straßendatenbank, Immobilienbewertung) werden deshalb mit Hilfe der Geodatenhandelsplattform (z.B. auf einem “kommunalen Geomarktplatz”) auf speziellen Portalen nutzerspezifische Lösungen generiert. Diese werden für unterschiedliche interne wie externe Nutzer zu unterschiedlichen Konditionen bereitgestellt. Die Datenbasis bilden sowohl die in kommunaler Hand verfügbaren Geobasisdaten und GIS-Fachdaten. Zusätzlich können über die Plattform bezüglich einer Kommune oder einer Behörde externe raumbezogene Daten kommerziell bereitgestellt werden.	eine and zwei;external variable;geographic information system;internet explorer;sie (file format);unified model;vhf omnidirectional range	Uwe Bernhardt	2002				OS	-104.32191990214768	33.26766922637805	64989
50a63212e2979473477da62a1408bf2531ad247b	application of multiplicative weights update method in algorithmic game theory	game theory;algorithmus;optimierung;algorithm;spieltheorie	In this thesis, we apply the Multiplicative Weights Update Method (MWUM) to the design of approximation algorithms for some optimization problems in game-theoretic settings. Lavi and Swamy [LS05, LS11] introduced a randomized mechanism for combinatorial auctions that uses an approximation algorithm for the underlying optimization problem, so-called social welfare maximization and converts the approximation algorithm to a randomized mechanism that is truthful-in-expectation, which means each player maximizes its expected utility by telling the truth. The mechanism is powerful (e.g., see [LS05, LS11, CEF10, HKV11] for applications), but unlikely to be efficient in practice, because it uses the Ellipsoid method. In Chapter 2, we follow the general scheme suggested by Lavi and Swamy and replace the Ellipsoid method with MWUM. This results in a faster and simpler approximately truthful-in-expectation mechanism. We also extend their assumption regarding the existence of an exact solution for the LP-relaxation of social welfare maximization. We assume that there exists an approximation algorithm for the LP and establish a new randomized approximation mechanism. In Chapter 3, we consider the problem of computing an approximate saddle point, or equivalently equilibrium, for a convex-concave functions F : X × Y → R, where X and Y are convex sets of arbitrary dimensions. Our main contribution is the design of a randomized algorithm for computing an ε-approximation saddle point for F . Our algorithm is based on combining a technique developed by Grigoriadis and Khachiyan [GK95], which is a randomized variant of Brown’s fictitious play [Bro51], with the recent results on random sampling from convex sets (see, e.g., [LV06, Vem05]). The algorithm finds an ε-approximation saddle point in an expected number of O ( ρ2(n+m) ε2 log Rε ) iterations, where in each iteration two points are sampled from log-concave distributions over strategy sets. It is assumed that X and Y have inscribed balls of radius 1/R and circumscribing balls of radius R and ρ = maxx∈X,y∈Y |F (x, y)|. In particular, the algorithm requires O∗ ( ρ2(n+m)6 ε2 logR ) calls to a membership oracle, where O∗(·) suppresses polylogarithmic factors that depend on n, m, and ε. Zusammenfassung In dieser Doktorarbeit verwenden wir die Multiplicative Weights Update Method (MWUM) für den Entwurf von Approximationsalgorithmen für bestimmte Optimierungsprobleme im spieltheoretischen Umfeld. Lavi und Swamy [LS05, LS11] präsentierten einen randomisierten Mechanismus für kombinatorische Auktionen. Sie verwenden dazu einen Approximationsalgorithmus für die Lösung des zugrundeliegenden Optimierungsproblem, das so genannte Social Welfare Maximization Problem, und wandeln diesen zu einem randomisierten Mechanismus um, der im Erwartungsfall anreizkompatibel ist. Dies bedeutet jeder Spieler erreicht den maximalen Gewinn, wenn er sich ehrlich verhält. Der Mechanismus ist sehr mächtig (siehe [LS05, LS11, CEF10, HKV11] für Anwendungen); trotzdem ist es unwahrscheinlich, dass er in der Praxis effizient ist, da hier die Ellipsoidmethode verwendet wird. In Kapitel 2 folgen wir dem von Lavi und Swamy vorgeschlagenem Schema und ersetzen die Ellipsoidmethode durch MWUM. Das Ergebnis ist ein schnellerer, einfacherer und im Erwartungsfall anreizkompatibler Approximationsmechanismus. Wir erweitern ihre Annahme zur Existenz einer exakten Lösung der LP-Relaxierung für das Social Welfare Maximization Problem. Wir nehmen an, dass ein Approximationsalgorithmus für das LP existiert und beschreiben darauf basierend einen neuen randomisierten Approximationsmechanismus. In Kapitel 3 betrachten wir das Problem für konvexe und konkave Funktionen F : X × Y → R, wobei X und Y konvexe Mengen von beliebiger Dimension sind, einen Sattelpunkt zu approximieren (oder gleichbedeutend ein Equilibrium). Unser Hauptbeitrag ist der Entwurf eines randomisierten Algorithmus zur Berechnung einer -Näherung eines Sattelpunktes von F . Unser Algorithmus beruht auf der Kombination einer Technik entwickelt durch Grigoriadis und Khachiyan [GK95], welche eine zufallsbasierte Variation von Browns Fictitious Play [Bro51] ist, mit kürzlich erschienenen Resultaten im Bereich der zufälligen Stichprobennahme aus konvexen Mengen (siehe [LV06, Vem05]). Der Algorithmus findet eine -Näherung eines Sattelpunktes im Erwartungsfall in O( 2(n+m)6 2 log R ) Rechenschritten, wobei in jedem Rechenschritt zwei Punkte zufällig gemäß einer log-konkaven Verteilungen über Strategiemengen gezogen werden. Hier nehmen wir an, dass X und Y einbeschriebene Kugeln mit Radius 1/R und umschreibende Kugeln von Radius R besitzen und ρ = maxx∈X,y∈Y |F (x, y)|. Der Algorithmus benötigt dabei O∗( 2(n+m)6 2 logR) Aufrufe eines Zugehörigkeitsorakels, hier versteckt O∗(·) polylogarithmische Faktoren, die von n,m und abhängen. Acknowledgments I would like to thank my supervisors Kurt Mehlhorn and Khaled Elbassioni for their continuous support. Special thanks to Kurt for his guidance and providing me an opportunity to work in his group. I would like to express my appreciation to Khaled who introduced me to the field of Optimization and for helpful discussions during my PhD. I am sincerely grateful to my family for their great support and encouragement. Thanks, Ali, for your help, care and scientific discussion during my PhD and grateful to my little son, Mohammad Mahdi for his love.		Fahimeh Ramezani	2015			artificial intelligence;calculus;mathematics;mathematical economics	Theory	-96.98707141634162	35.6187045059391	65012
50b4b3898a313395668a28c954f8f4ee1024d513	wolkige zeiten		Cloud Computing ist das Hype-Thema des Jahres 2011, auf der diesjährigen CeBIT gab es kaum einen Stand, der das Thema nicht irgendwie mit auf der Agenda hatte. Auch wenn diese Technologie an sich enorme Vorteile mit sich bringen kann, sind die Risiken im Bereich der Informationssicherheit immer noch eines der Hemmnisse, das aktuell eine flächendeckende Nutzung der Cloud verhindert. Bei genauerer Betrachtung sind jedoch viele der Risiken in der Cloud nicht wirklich neu, zahlreiche Aspekte sind bereits aus dem klassischen IT-Outsourcing bekannt oder müssen etwa beim Einsatz von Virtualisierungstechnologien berücksichtigt werden. Die Cloud mit ihrer stark internationalen, grenzüberschreitenden Ausrichtung sorgt allerdings dafür, dass die Auswirkungen von Schwachstellen deutlich gravierender ausfallen können. Es ist also sicher an der Zeit, sich mit den Risiken der Cloud-Technologie im Allgemeinen und auch im Speziellen auseinander zu setzen. Wir wollen mit diesem Schwerpunktheft die Chance nutzen, Ihnen anhand von ausgewählten Beiträgen einen Überblick über die Risiken und ihre Beherrschbarkeit sowie Lösungsideen und -ansätze im Bereich der Informationssicherheit in der Cloud zu geben.	cloud computing;eine and zwei;gab;intentionally blank page;outsourcing	Christoph Wegener	2011	Datenschutz und Datensicherheit - DuD	10.1007/s11623-011-0074-2		OS	-102.5886399253967	36.17434218899342	65027
3436bcbd04b8c0b6fb79b090e68a2825e67e098f	transparente und effiziente prozesse im erdbau durch ereignisgesteuertes stoffstrommanagement auf basis von smart objects und business rule management	business rules	Intransparente und manuell ablaufende Prozesse im Erdbau erschweren die Kontrolle von Erdbewegungen und den dokumentierten Nachweis über die Einhaltung gesetzlicher Vorgaben. Dem kann durch die Einführung eines Stoffstrommanagements für Erdbewegungen entgegen gewirkt werden. Die technische Basis für das Stoffstrommanagement, welches auf aktuelle Informationen aus dem Erdbauprozess angewiesen ist, wird durch Smart Object Technologien geschaffen. Darauf aufbauend schafft ein Business Rule Management System die Voraussetzung für ein flexibel anpassbares, ereignisgesteuertes Stoffstrommanagement und führt zu transparenten und effizienten Prozessen im Erdbau. 1 Einleitung und Motivation 1.1 Intransparente und manuell ablaufende Prozesse im Erdbau erschweren die Kontrolle von Erdbewegungen und den dokumentierten Nachweis über die Einhaltung gesetzlicher Vorgaben Erdbauarbeiten, welche das Lösen, Laden, Fördern, Einbauen und Verdichten von Boden betreffen, fallen prinzipiell bei jeder Baumaßnahme an. Eine besondere Herausforderung dabei ist die Erbringung des Nachweises über die Einhaltung der zahlreichen Pflichten, welche Bauherrn und Bauunternehmern vom Gesetzgeber auferlegt werden. Dazu zählt unter anderem die Verpflichtung, Abfälle zu vermeiden, zu verwerten bzw. alle nicht vermeidbaren oder verwertbaren Stoffe schadlos zu beseitigen und zu diesem Zweck unterschiedliche Bodenarten sortenrein zu lagern. Während diese Pflichten vom Bauunternehmen einzuhalten sind, ist der Bauherr angehalten, ein Entsorgungskonzept für die jeweiligen Abfälle zu erstellen und dessen Umsetzung zu kontrollieren [KGW04, Me08]. Weiterhin wird von Bauunternehmern verlangt, einen statistischen Nachweis über Massenbewegungen zu führen. D.h. aus Gründen der Nachhaltigkeit soll nicht mehr	business rule management system;eine and zwei;gesellschaft für informatik;smart objects;zentralblatt math	Sebastian Lempert;Markus Harrer;Michael Krupp;Alexander Pflaum	2010			database;smart objects;computer science;business rule	DB	-103.00422990178195	33.5671666013174	65455
68ee88b1582e4d2d8f4b645e872ed166bd8e792c	unsere empfehlung für sie: präferenzen und personalisierung in der informatik		Präferenzen spielen im Alltag jedes Menschen eine groûe Rolle. Einfache Präferenzen wie z.B. ” Zum Frühstück mag ich lieber Kaffee als Tee, Schokocroissants sind besser als ein Käsebrota oder ” Eine Unterkunft in einem 4-Sterne Hotel in der Nähe der Konferenz ist mir wichtiger als eine möglichst günstige Übernachtunga sind uns allen bekannt. Häu®g müssen wir uns zwischen unzähligen verschiedenen Alternativen entscheiden. Systeme, die unsere Präferenzen, also die Benutzerwünsche, einbeziehen, helfen die bestmöglichen Entscheidungen zu treffen. Das Tutorium behandelt verschiedene Aspekte der Modellierung und Verarbeitung von Präferenzen in den Bereichen Datenbanken & Informationssysteme sowie Künstliche Intelligenz. Die Vorstellung von konkreten Einsatzgebieten und Anwendungen von Präferenzen sowie die Darstellung von Risiken, Chancen und Herausforderungen im Umgang mit Personalisierung runden das Tutorium ab. 1 Präferenzen in der Informatik In der Informatik gewinnen Präferenzen immer mehr an Bedeutung. So haben Präferenzen seit langem Einzug bei Touristikportalen oder Firmen wie Amazon, Google und Facebook gehalten, um personalisierte Produktempfehlungen vorzunehmen. Dabei zeigt sich, dass Kunden sehr viel mehr Wert als früher auf personalisierten Kundenservice anstelle von Standardprodukten legen. Eine Zusammenstellung einer Reise zum Beispiel, einschlieûlich Flug, Mietwagen, Hotelreservierung, Veranstaltungen und Exkursionen kann nicht mehr als Pauschalangebot verkauft werden, sondern erfordert immer mehr die individuelle Anpassung an die Wünsche der Kunden. Die Bedürfnisse der Benutzer spielen heutzutage insbesondere im Marketing eine bedeutende Rolle. Marketing-Lösungen, die komplett auf den Benutzer zugeschnitten sind, setzen sich durch. Das Stichwort lautet Personalisierung. Aus psychologischer Sicht bevorzugt der Mensch personalisierte Informationen, da er sich damit wertgeschätzt fühlt und Sympathie für sein ” Gegenübera emp®ndet. Durch personalisierte Informationen und die auf uns maûgeschneiderten Botschaften entwickelt man unbewusst auch ein Gefühl der Sicherheit. Zudem heben sich personalisierte Nachrichten von dem heutzutage herrschenden Überangebot von Informationen ab. Auch wenn dieser Prozess unbewusst statt®ndet, ist er enorm ein ̄ussreich und überzeugt ganz unterschwellig. So ist z.B. eine personalisierte E-Mail, in der man mit dem Vornamen angesprochen wird und die einen an die eigenen Interessen angepassten Inhalt hat, zugänglicher. Insbesondere nimmt man sich z.B. mehr Zeit Werbeinformationen zu sichten, wenn der Inhalt den eigenen Interessen entspricht. Dieser Effekt kehrt sich jedoch um, wenn bei der Personalisierung 1 Universität Augsburg, Universitätsstr. 6a, D 86159 Augsburg, endres@informatik.uni-augsburg.de 2 Technische Universität Wien, Favoritenstr. 9, A 1040 Wien und Universität Siegen, Unteres Schloû 3, D 57072 Siegen, pfandler@dbai.tuwien.ac.at 1928 Markus Endres und Andreas Pfandler Fehler unterlaufen: Etwa wenn ein Zelt auf einem Campingplatz einem Geschäftskunden als Tagungsraum empfohlen wird oder wenn sich der Benutzer ” bespitzelta fühlt. Es wird klar, dass es sich bei der Personalisierung und der Verarbeitung von Präferenzen um komplexe Aufgaben handelt, die offensichtlich Fingerspitzengefühl erfordern. Ein besonders positiver Eindruck entsteht wiederum, wenn präferierte Alternativen angeboten werden, die der Benutzer nicht bedacht hat, wie etwa günstigere Flugverbindungen zu einem nahe gelegenen anderen Flughafen. Personalisierte Inhalte können somit einen positiven Effekt auf die Marketing-Ef®zienz haben, da nicht relevante Inhalte aufgrund der vorliegenden Informations ̄ut ohnehin oft nicht beachtet werden. Wie oben bereits angedeutet, bedeutet Personalisierung aber nicht nur persönliche Daten in Dokumenten zu nutzen, sondern auch die Präferenzen der Benutzer bei Produktempfehlungen oder bei der Produktsuche zu berücksichtigen. Während bei der erstgenannten Art der Personalisierung meist nur die nüchternen Daten verwendet werden, benötigt die zweitgenannte Art Wissen über die Präferenzen und Methoden, um die richtigen Schlüsse daraus zu ziehen. Damit erhalten Benutzer z.B. bei der Produktsuche auf sie zugeschnittene Antworten und können unter verschiedenen bestmöglichen Alternativen auswählen. Letztendlich pro®tieren also nicht nur Unternehmen von personalisierten Inhalten, sondern auch die Kunden selbst. Eine weitere wichtige Bedeutung haben Präferenzen bei der gemeinsamen Entscheidungs®ndung etwa innerhalb einer Gruppe oder eines Freundeskreises. Hierbei ist es das Ziel eine Lösung zu ®nden, welche die Bedürfnisse bzw. Präferenzen der einzelnen beteiligten Personen berücksichtigt und dabei gleichzeitig möglichst fair ist. Ein einfaches Beispiel ist etwa das Finden eines Lokals für ein gemeinsames Mittagessen. Hier geben die Teilnehmer nicht nur an, wann sie Zeit haben, sondern teilen auch ihre Präferenzen bezüglich des Lokals mit. Gesucht ist dann das ” passendstea Lokal. Eine weitere wichtige Frage ist, wie man (komplexe) bedingte Präferenzen behandelt, bei denen die einzelnen Entscheidungsmöglichkeiten nicht unabhängig voneinander sind. So könnte zum Beispiel bei der Frühstücksplanung Tee nur dann Kaffee vorgezogen werden, wenn es ein Käsebrot zum Frühstück gibt, ansonsten ist Kaffee die erste Wahl. Dem Motto der INFORMATIK 2016 ” Informatik von Menschen für Menschena folgend, werden im Rahmen dieses Tutoriums Methoden vorgestellt, um Informationssysteme der Zukunft zu schaffen, die Präferenzverarbeitung als ein zentrales Konzept der Personalisierung ansehen. Im Folgenden werden wir einen knappen Überblick über die Grundlagen, aktuelle Forschung und praktische Anwendungen von Präferenzen in Datenbankanfragen sowie im Bereich der Künstlichen Intelligenz geben. 2 Präferenzen in Datenbankanfragen Im ersten Teil des Tutoriums werden wir Präferenzen innerhalb von Datenbanksystemen behandeln, da immer mehr Datenbankhersteller die Verarbeitung von Präferenzen als ein zentrales Konzept der Personalisierung ansehen. So existieren neben den rein akademischen Prototypen wie z.B. FlexPref [LMK10] oder Preference SQL [KEW11] auch kommerzielle Präferenzen und Personalisierung in der Informatik 1929 Abbildung 1: Screenshot einer präferenzbasierten Hotel-Suche in Istanbul [We12]. Systeme wie etwa das Skyline Feature in EXASolution [Ma15]. Dass es sich hierbei nicht nur um eine Spielwiese für Wissenschaftler handelt, zeigt das Szenario der Suche nach einem Hotel in einer Stadt, z.B. in Istanbul. Aufgrund der enormen Anzahl von Hotels aller Kategorien in dieser Stadt stellt die Kenntnis der Benutzerwünsche in dieser Anfrage eine groûe Hilfe dar, um irrelevante Hotels aus dem Datensatz auszublenden und den Fokus ausschlieûlich auf die relevanten Hotels zu legen. Präferenzen agieren als Filter, welche nur die relevanten Antworten bezüglich der Benutzerpräferenzen liefern. Abbildung 1 demonstriert solch eine personalisierte ortsbasierte Hotel-Suche, die es einzelnen Benutzern oder Benutzergruppen erlaubt, Hotels in Istanbul zu ®nden, wobei sowohl harte Kriterien als auch Benutzerwünsche berücksichtigt werden (vgl. [We12]). So lässt sich nicht nur die Hotel-Kategorie als hartes oder weiches Kriterium spezi®zieren, sondern auch die Präferenz bezüglich der Art der Unterkunft oder der Verfügbarkeit von WLAN. Die präferierten Stadtteile können nun etwa als weiches Kriterium formuliert werden, welches (sofern möglich) erfüllt sein sollte. Die Applikation unterstützt sowohl räumliche, numerische und kategorielle als auch komplexe Präferenzanfragen auf eine intuitive Art und Weise, sodass das Ergebnis bestmöglich den Benutzerwünschen entspricht. Die Verwendung von Präferenzen in Datenbankanfragen wirft allerdings viele komplexe Fragestellungen auf, etwa bzgl. der Darstellung/Modellierung, Auswertung, Sprache, etc., vgl. [SKP11]. Bereits im Jahre 1987 haben Lacroix und Lavency [LL87] sich diese Fragen gestellt und noch heute beschäftigen sich Wissenschaftler auf der ganzen Welt mit diesem Thema. Kieûling und andere haben mit ” Preference SQLa [KEW11] eine Methode zur Repräsentation von Präferenzen in SQL entwickelt. Die Grundlage bilden Striktordnungen (irre ̄exiv, transitiv, antisymmetrisch), z.B. ” Eine Unterkunft im Stadtteil Fatih in Istanbul ist mir wichtiger als ein 4-Sterne Hotela, welche durch Präferenz-Konstruktoren gebildet werden 3 Web-Applikation zu ®nden unter http://www.dbis.informatik.uni-augsburg.de/hotelfinder/ 1930 Markus Endres und Andreas Pfandler können. Um Präferenzen in Preference SQL spezi®zieren zu können, wurde die Syntax des SQL-Select-Statements um die PREFERRING-Klausel erweitert. Preference SQL folgt der ” Best Matches Onlya-Semantik: Das Ergebnis beinhaltet ausschlieûlich die besten Treffer bezüglich der gegebenen Präferenzen. Abbildung 2 zeigt eine einfache Preference SQL Anfrage, bei der die ortsbasierte Präferenz durch eine Priorisierung (PRIOR TO) mit dem Wunsch nach einem 4-Sterne Hotel verknüpft wird. Dabei wird der Stadtteil Fatih durch einen KML-String festgelegt, welcher erfüllt sein sollte. SELECT * FROM accommodation -Unterk ünfte in Istanbul PREFERRING -Präferenz -Query location WITHIN ’<KML -String >’ -Ortsbasierte Suche PRIOR TO -Priorisierung category = ’4*’ AND type = ’Hotel’; -Pareto -Präferenz Abbildung 2: Preference SQL Anfrage: Eine Unterkunft im Stadtteil Fatih (KML-String) ist wichtiger als ein 4-Sterne Hotel. Die Firma EXASOL AG setzt diesen Ansatz in ihrem kommerziellen Datenbanksystem EXASolution um [Ma15]. Auûerdem existiert ein präferenzbasiertes Empfehlungssystem auf Grundlage von Preference SQL [SEK06]. Die in Preference SQL vorhandene ” Pareto-Präferenza, bei der verschiedene Attribute als gleich wichtig erachtet werden, ist auch als ” Skyline Operatora [BKS01] bekannt. Chomicki stellt Präferenzen durch logische Ausdrücke dar. Auch in diesem Ansatz werden Präferenzen als Striktordnungen modelliert und zur personalisierten Ergebnis®l	die (integrated circuit);eine and zwei;es evm;gesellschaft für informatik;i/o controller hub;institut für dokumentologie und editorik;internet explorer;keyhole markup language;mag technology co.;needleman–wunsch algorithm;pareto efficiency;sie (file format);sql server compact;screenshot;triple des;unified model	Markus Endres;Andreas Pfandler	2016				OS	-105.6468732614849	35.08141440384134	66240
d3f3e531cc9070781db4087ca075af3e783cb4b1	studieren geht über probieren oder didaktik und methodik der fehlerpräventiven programmentwicklung		Es werden acht Prinzipien der fehlerpraventiven Programmentwicklung vorgestellt. Dabei wird erlautert, daβ jede Theorie der Programmierung Funktionen von Menschen zum Gegenstand haben muβ, die es zu erschlieβen gilt.	didaktik	Bleicke Eggers	1984		10.1007/978-3-642-69705-0_2		HCI	-104.53557004062806	33.37579278135423	67331
8faeee139d0c1f23180db2c0386dbe4305b80737	erfolgsfaktoren bei der einfürung von wissensmanagement-lösungen	von wissensmanagement-l;erfolgsfaktoren bei der einf	Wir betrachten Wissensmanagement als die Gesamtheit aller Planungen und Maßnahmen, durch die der Umgang mit Wissen, insbesondere dessen Erwerb, Austausch und Nutzung nachhaltig verbessert wird. Wissensmanagement bedient sich unterschiedlicher Methoden und Techniken verwandter Gebiete, wie etwa dem Informationsmanagement, der Kooperationsunterstützung oder wissensbasierter Systeme, und geht dabei von einem integrierten Ansatz aus, der Technikgestaltung, Organisationsund Personalentwicklung als miteinander verwobene Facetten eines einheitlichen Vorhabens ansieht. Zur Einführung und Verankerung von Wissensmanagement sollte demnach ein ganzheitlicher, nicht nur auf Technologien fokussierender Ansatz gewählt werden, der die Gestaltungsebenen Wissensarbeiter, Wissensprozesse, Geschäftsprozesse, Wissensbasis und Wissensorganisation gleichzeitig berücksichtigt.	internet explorer	Marc Diefenbruch;Thomas Herrmann;Marcel Hoffmann;Hans-Gerd Schaal	2002				DB	-104.51274123170847	32.72728753940698	67470
2acd703af2e79d2e160fa25f06e364bc120ebb69	quantifizierung der darmperistaltik mittels deformierbarer registrierung		Kurzfassung. In diesem Beitrag werden zwei neuartige Methoden zur Detektion von Bewegungsstörungen des Darms vorgestellt und evaluiert. Dazu werden aus dynamischen 3D MRT Datensätzen jeweils ein geeigneter koronarer 2D+t Datensatz ausgewählt und über mehrere Zeitschritte registriert. Aus den entstehenden einzelnen Bewegungskarten wird in der ersten Methode ein neues Bild generiert, das für jeden Bildpunkt alle dazugehörigen Vektorbeträge addiert. Für die zweite Methode werden die Beträge nur aus den lateralen Vektorkomponenten der Verschiebungsvektoren berechnet und somit überwiegend die Atembewegung künstlich entfernt. In einer ersten Evaluation werden für beide Methoden 5 Probanden mit 5 Patienten mit nachgewiesener eingeschränkter Darmperistaltik verglichen. Es wurde festgestellt, dass für die erste Methode mit Atmung eine Klassifizierung zwischen Probanden und Patienten nur bedingt möglich ist. Für die zweite Methode konnte jedoch gezeigt werden, dass die mittlere Bewegung in den Bewegungskarten mit Krankheitsbild ungefähr 35% geringer ist und somit erstmals eine Klassifizierung zwischen normaler und eingeschränkter Darmperistaltik ermöglicht wird.	eine and zwei;eddie (text editor)	Daniel Stein;Tobias Heye;Hans-Ulrich Kauczor;Hans-Peter Meinzer	2009		10.1007/978-3-540-93860-6_80	performance art;history	NLP	-105.73397762067846	32.44111513981008	67781
9c958ffae5eca943bab3f44504aa554fca114a1c	digitales work management zur leitungsauskunft und baubegleitung		Zur Unterstützung der eigenen technischen Aufgaben im Arbeitsbereich der Leitungsauskunft streben Leitungsbetreiber die Nutzung digitaler Prozesslösungen an. Um bauliche Maßnahmen in einem bestimmten Versorgungsgebiet planen und durchführen zu können, benötigen die daran beteiligten Firmen Informationen darüber, wo sich im Bereich der geplanten Maßnahme Leitungen oder Anlagen eines Betreibers befinden. Dabei besteht die Notwendigkeit der vollständigen und übereinstimmenden Informationsbereitstellung an alle Projektbeteiligten im Rahmen der Baumaßnahmen.	unified model	Jens Focke	2015	AGIT Journal	10.14627/537557038		DB	-104.27451930904064	33.18570954736038	68031
fd61a70292a0127b3f0fa156b62d8a49030379ee	autorisierung und zugriffsüberwachung in strukturell objekt-orientierten datenbanksystemen		Autorisierung und Zugriffskontrolle wurden fur Betriebssysteme und konventionelle (z.B. relationale) Datenbanksysteme intensiv untersucht. Objekt-orientierte Datenbanksysteme stellen jedoch neue Anforderungen und bieten neue Moglichkeiten, die es erforderlich machen, die Probleme und Losungen auf diesem Gebiet wiederaufzugreifen. Strukturell objekt-orientierte Datenbanksysteme bilden eine grosere Teilklasse und zeichnen sich dadurch aus, das sie komplexe Objektstrukturen speichern und bearbeiten konnen. Das vorliegende Papier stellt die wichtipten Konzepte eines Vertreters dieser Klasse vor. Anschliesend werden die Anforderungen, die strukturell objekt-orientierte Datenbanksysteme an Autorisierung und Zugriffskontrolle stellen, abgeleitet und es wird ein Schutzkonzept prasentiert, das diesen Anforderungen gerecht wird. Abschliesend werden einige Implementierungsaspekte diskutiert.		Heribert Pfefferle	1989		10.1007/978-3-642-74571-3_11		Crypto	-104.66470674228196	32.586733854372824	68075
74fc4941301409e96409013183d1d37a3313fa29	intelligent design - von der gestaltung interaktiver software zum design kooperativer medien	intelligent design	Die Gestaltung der Schnittstelle zwischen einem Computersystem und seinem Anwender ist so alt wie die Geschichte des Computers selbst. Immer geht es darum, eine dem Medium entsprechende Interaktionsschnittstelle zu gestalten, die einerseits die Möglichkeiten des Mediums angemessen vermitteln kann, andererseits auf Basis menschlicher Kommunikation möglichst natürlich abläuft. So verändern sich die Anforderungen an das Design mit den Veränderungen im Bereich der Technologien. Beim Intelligent Design geht es keineswegs darum, Intelligenz zu gestalten. Dabei löst sie sich von der klassischen Vorstellung, Design habe primär nur etwas mit visueller Kommunikation zu tun. Im Vordergrund der designerischen Tätigkeiten steht vor allem die Strukturierung und Gestaltung von lT-Systemen, die in der Lage sind, lernende Beziehungen mit ihrem Nutzer einzugehen. Im Allgemeinen geht es beim Intelligent Design zunächst darum, kooperative und intelligent agierende Medien zu konzipieren, um anschließend eine medium-adäquate Sprache zu kreieren, die deren Nutzern einen gewohnten, aber gleichzeitig neuartigen Umgang mit den Dingen erlauben. Diese in sich widersprüchlich erscheinende Aussage wird schnell verständlich, wenn man die klassische Interface-Entwicklung beWolfgang Henseler	eine and zwei;internet explorer;sie (file format);tun (product standard);unified model;vhf omnidirectional range	Wolfgang Henseler	2001	i-com	10.1524/icom.2001.0.0.34	computer science;intelligent design	Robotics	-105.74468140049883	33.63586482653	68352
e406601d9a6f2c5ba42677bce3a222e7ba7fe4df	zertifizierung der it nach iso 20000	information technology infrastructure library itil;certification;iso 20000;it service management			Georg Disterer	2009	Wirtschaftsinformatik	10.1007/s11576-009-0198-2	information technology infrastructure library;information security management system;iso 9000;certification;law	Crypto	-100.63998448001188	34.498250089583216	68784
73df7b342970497b3c4786f92738b59ef3112cc1	transformer mit g-zirkulanter struktur			transformer	Aivar A. Lorenc	1978	Elektronische Informationsverarbeitung und Kybernetik		discrete mathematics;mathematics;transformer	NLP	-95.26139173915429	34.12018353892682	68805
ef135fa0b1a326e8fffee512ad838c9d354d2762	umgang mit e-mail-accounts ausgeschiedener mitarbeiter		Nach dem Ausscheiden von Mitarbeitern aus dem Unternehmen sind einige grundsätzliche Tätigkeiten im organisatorischen sowie technischen Bereich erforderlich. Im organisatorischen Bereich muss beispielsweise in der Personalabteilung die Mitarbeiterakte mit einem entsprechendem Vermerk versehen und entsprechend abgeschlossen werden, ausgegebene Zutrittskarten zu Unternehmenseinrichtungen und gebäuden müssen zurückgefordert werden; des Weiteren sind Arbeitszeugnisse und Beurteilungen über die ausscheidenden Mitarbeiter anzufertigen. Im IT-Bereich sind ebenfalls einige Dinge zu erledigen, hier geht es vorwiegend um die Beendigung bzw. Aufhebung bestehender Zugriffsund Nutzungsrechte (Berechtigungen für bestimmte IT-Systeme, Laufwerke und Daten) und Zutrittsund Zugangsrechte besonderer Art (z. B. Nutzung bestimmter Datenverarbeitungssysteme, bestimmter Räumlichkeiten oder Unternehmensbereiche und insbesondere IT-kritischer Bereiche wie z. B. Serverräume). Dabei geht es auch allgemein um die Frage, wie mit den (noch) bestehenden Rechten und E-Mail-Accounts sowie den darin enthaltenen elektronischen Nachrichten in Gänze zu verfahren ist. Hier ergeben sich bedeutsame rechtliche Fragestellungen, die im Folgenden dargestellt werden. Die folgende Beurteilung bezieht sich primär auf datenschutzrechtliche bzw. IT-rechtliche Aspekte; arbeitsrechtliche Gesichtspunkte bleiben außer Betracht. 1 Beurteilungsrahmen	es evm;internet explorer;unified model	Thomas Schoen	2008	Datenschutz und Datensicherheit - DuD	10.1007/s11623-008-0066-z			-104.82447059377779	33.84856370457781	69103
f76db8d5a2dbd1c68fd0824020ab3c6b0d9d32ac	dab - das plattenspeicher-cache im bs2000		Datenverarbeitungs-Systeme(DV-Systeme) müssen mit steigender Parallelität der Verarbeitung und für umfangreiche Anwendungen immer größere Datenmengen leistungsfähig verwalten und verarbeiten können. Große Datenmengen sind aus wirtschaftlichen und technischen Gründen auf Sekundärspeichern (z.B. Magnetplatte) abgelegt (Abb. 1). Sekundärspeicher haben relativ lange Zugriffszeiten. Für einen schnelleren Zugriff können Teilmengen dieser Daten auf prozessornäheren Speichermedien mit kürzeren Zugriffszeiten verfügbar gehalten werden [2].	bs2000;gesellschaft für informatik	Paul Linser	1986	Praxis der Informationsverarbeitung und Kommunikation	10.1515/piko.1986.9.2.84		Theory	-104.6277338608241	33.18178679883211	69345
d97fd8ed7bb37badbce2f938459c467dc97f9e74	vg berlin: opt-in abfrage im rahmen von service-calls		allenfalls durch die arbeitgeberseitigen Vorgaben für die Erstattung von Reisekosten, nicht aber durch den Einsatz des Routenplaners. DUD RECHT	lvm;link rot	Verwaltungsgericht Berlin	2014	Datenschutz und Datensicherheit - DuD	10.1007/s11623-014-0245-z		Crypto	-104.01720981775743	34.35973403918178	69422
e09e164d73cec6737edc97f2ae65c97b9cd6640e	evaluierung von elearning-instrumenten im bereich der universitären lehre		Integration von eLearning in die Lehre gewinnt immer mehr an Bedeutung. Der Beitrag grenzt den Begriff des eLearnings ab und nennt die didaktischen Funktionen. Zur Qualitätssicherung und Evaluation wurde der Erfolg des Einsatzes von eLearning zur Unterstützung einer Vorlesung mittels einer schriftlichen Befragung der Studenten gemessen. Auf Grundlage der Untersuchungsergebnisse wird der Einsatz des eL arnings bewertet und optimiert.		Meike Wocken;Jens-Peter Loy	2011				Vision	-104.1491638872898	32.90582659487731	69469
7097c74e2d8b25b8157a4b1566814ff1750233ec	sharing als konzept, lösung und problem		Als Profession und Wissenschaft war die Informatik im 20. Jahrhundert stets „eingeklemmt“ zwischen den Ansprüchen möglicher Nutzer und den Anforderungen, Möglichkeiten und Limitationen, die der Computer vorgab. Die Informatik entwickelte in diesem Spannungsfeld Sharing-Konzepte der unterschiedlichsten Art. Im folgenden Gespräch unterhalten sich zwei Informatiker (Andreas Meier und Carl August Zehnder) und zwei Technikhistoriker (David Gugerli und Daniela Zetti) über eine Entwicklung, die seit mehr als 50 Jahren anhält, die aber nicht in immer mehr Sharing kulminierte, sondern die sich stets durch lebhaften Wandel auszeichnete. Es gibt unterschiedliche Qualitäten von Sharing und es gibt und gab auch dezidierte Anti-Sharing-Entwicklungen.	conley–zehnder theorem;eine and zwei;gab	David Gugerli;Andreas Meier;Carl August Zehnder;Daniela Zetti	2014	HMD Praxis der Wirtschaftsinformatik	10.1365/s40702-014-0085-1	knowledge management;engineering;performance art	AI	-103.28590528613655	35.15224909973973	69552
3cd522f38fa1cd77a4c72be0f1f62eec84f1b17a	ein durchgang durch das grundfach informatik (nur) mit dem elektronischen schulbuch inf-schule.de			gesellschaft für informatik	Heiko Jochum;Klaus Becker;Martin Zimnol;Daniel Jonietz;Oliver Schneider;Manuel Froitzheim	2017				NLP	-103.95740617855628	33.14709430053775	69707
2c477e0541662531aac80bac5313050c5c3a011b	computerreservierungssysteme (crs) und passenger name records (pnr)		Ein erheblicher Teil der Buchungen von Reisen (Hotelübernachtungen, Flüge, Kreuzfahrten, Mietwagen, Bahnreisen etc.), die von Reisebüros und Online-Portalen weltweit vermittelt werden, erfolgen heute in zentralen Computerreservierungssystemen (CRS). Sie bieten Reisebüros den Zugriff auf aktuelle Preise und verfügbare Plätze und sorgen für eine unmittelbare Platzreservierung beim jeweiligen Anbieter. Durch die Online-Anbindung von Reisebüros, Reise-Portalen und -Anbietern an ein zentrales CRS vereinfacht sich der Informationsfluss erheblich: Angebote und Preise sind ständig aktuell und lassen sich automatisch an die Nachfrage anpassen, und Buchungen erfolgen in Echtzeit. Insbesondere für Flugbuchungen erlauben CRS den Passagieren den Selbstausdruck von Tickets, sowohl über das Internet als auch an speziellen Terminals. CRS sind hoch komplexe Systeme, die für eine Vielzahl von Beteiligten eine extrem hohe Zahl an Transaktionen zu bewältigen haben (Buchung, Stornierung, Auskunft, Platzreservierung, ...) und riesige Datenmengen verarbeiten. Der Zugriff aus den Reisebüros erfolgt über einheitliche Masken; Online-Portale greifen über definierte Schnittstellen auf die Reservierungssysteme zu. Die Betreiber eines CRS rechnen die Kosten buchungsbezogen mit den Reiseanbietern ab und übernehmen teilweise auch die Verrechnung von Vergütungen der Reisebüros. Den weltweiten Markt teilen sich im Wesentlichen vier CRS-Anbieter: Amadeus, Galileo, Sabre und Worldspan.	eine and zwei;galileo;passenger name record;sie (file format);sabre (computer system);zentralblatt math	Dirk Fox	2010	Datenschutz und Datensicherheit - DuD	10.1007/s11623-010-0079-2	internet privacy;computer science;computer security	ML	-104.49394347434045	36.4872051474347	69938
d56631eba7708aedc6a3d3d2d0022dd5d77404a4	praktische angriffe auf die bitstromverschlüsselung von xilinx fpgas		Heute bedrohen Risiken wie Produktpiraterie und Industriespionage Technologiekonzerne mehr denn je. Weder wertvoll aufgebautes Know-How noch kostspielige Eigenentwicklungen dürfen in die Hände der Konkurrenz geraten. Über Gewinner und Verlierer dieses Wettkampfs entscheidet häufig, ob die Schutzmechanismen der verwendeten Baugruppen halten, was die Hersteller versprechen. In diesem Beitrag untersuchen wir am Beispiel von Xilinx Bauelementen, wie sich die Bitstromverschlüsselung zum Schutz der FPGA Konfiguration in der Praxis bewährt. Wir zeigen, wie sich mittels Seitenkanalanalyse sogar mit dem hochsicheren AES-256 geschützte Inhalte entschlüsseln lassen.	altran praxis;field-programmable gate array;internet explorer	Markus Kasper;Timo Kasper;Amir Moradi;Christof Paar	2011	Datenschutz und Datensicherheit - DuD	10.1007/s11623-011-0185-9	internet privacy;operating system;field-programmable gate array;computer science	OS	-104.50512690754226	35.877739908615084	70002
4e4c55a3ee659e6926c4096ebe3530d30ff5be57	blutspenden leicht (und datensicher) gemacht — dank handvenenscan		Das Speichern personenbezogener Daten, großer bürokratischer, zeitlicher, finanzieller und technischer Aufwand und das letztendliche Spenden von Blutplasma — für Mitarbeiter in Blutspendezentren, für die Spender selbst und für Datenschützer ist der oft lebenswichtige Prozess der Blutspende ein organisatorischer Albtraum. Sensible Daten wollen gesichert, sämtliche Vorschriften eingehalten und der Spender mit dem größtmöglichen Komfort versorgt werden. Dank biometrischer Erkennungsverfahren und eines ausgeklügelten Datensicherungssystems lassen sich diese so unterschiedlichen Anforderungen nun tatsächlich leicht erfüllen.		Gereon Tillenburg;Robin Tillenburg	2017	Datenschutz und Datensicherheit - DuD	10.1007/s11623-017-0802-3	computer science;internet privacy;performance art	NLP	-103.87330920752171	35.971091911035714	70287
ae1caf482521fc001a611c268a770354e16233f2	geometrische formen in vektorfeldern		Geometrischen Formen haben sich zu einem unverzichtbaren Kernbestandteil in einer Vielzahl von Anwendungsgebieten entwickelt. Hierzu zählen die digitale Entwicklung und Fertigung industrieller Produkte sowie Anwendungen in der Medizin, Architektur und der Unterhaltungsindustrie, um nur einige Beispiele zu nennen. Das Forschungsfeld der Geometrieverarbeitung beschäftigt sich als Teilgebiet der Informatik mit der effektiven computergestützten Verarbeitung von geometrischen Formen. In der vorgestellten Dissertation werden neue Lösungen für offene Probleme der Geometrieverarbeitung über kontinuierliche Beschreibungen mit Hilfe von Vektorfeldern vorgeschlagen und untersucht. Die Arbeit gliedert sich dabei in zwei Teile: Im ersten Teil werden Vektorfelder zur effektiven Manipulation von geometrischen Formen genutzt. Dabei werden kontinuierliche Deformationen sowohl zur interaktiven Modellierung als auch zur Optimierung von geometrischen Formen genutzt. In dem zweiten Teil der Dissertation werden Vektorfelder nicht mehr zur Repräsentation von Deformationen genutzt. Stattdessen werden sie als Strömungsfelder interpretiert, die charakteristische geometrische Formen, wie beispielsweise Stromflächen, definieren, und zur Visualisierung dieser komplexen Vektorfelder genutzt werden. Die in diesem Artikel vorgestellte Dissertation [Mar13] wurde von der Fakultät für Informatik der Universität Magdeburg angenommen und die vorgeschlagenen Beiträge in begutachteten internationalen Konferenzbänden und Zeitschriften veröffentlicht.	eine and zwei;internet explorer;magdeburg;sie (file format);unified model;zur farbenlehre	Janick Martinez Esturo	2013				OS	-105.40204465187941	32.568358519833446	70397
4ad40416837fee11d83099c288b8ff752f0a60c9	a one-table method for sampling from continuous and discrete distributions	loi discrete;discrete distribution;ley discreta;random number generator;fonction repartition;funcion densidad probabilidad;probability density function;echantillonnage;random number generation;sampling;fonction densite probabilite;funcion distribucion;distribution function;generation nombre aleatoire;ams subject classification;muestreo;high efficiency;generacion numero aleatorio	A practical method for sampling from largely arbitrary distributionsF with density functionsf(x) or probabilitiesp k (in discrete cases) is developed. The high efficiency of the sampling routine is achieved by means of only one auxiliary table which contains a subdivision of the range ofF. Examples of continuous and discrete distributions demonstrate that the procedure is easy to apply and that its speed does not much depend on the particular target distributionF. Für die Erzeugung von Stichproben aus weitgehend beliebigen VerteilungenF mit Dichtefunktionenf(x) oder Wahrscheinlichkeitenp k (in diskreten Fällen) wird eine praxisnahe Methode entwickelt. Die hohe Effizienz der Stichprobengewinnung wird mittels einer einzigen Hilfstafel erreicht, die eine Unterteilung des Bereiches vonF enthält. Beispiele stetiger und diskreter Verteilungen zeigen, daß die Prozedur einfach zu handhaben ist und daß ihre Geschwindigkeit nicht sehr von der speziellen VerteilungF abhängt.	die (integrated circuit);eine and zwei;sampling (signal processing);subdivision surface	Joachim H. Ahrens	1995	Computing	10.1007/BF02238128	probability distribution;sampling;probability density function;combinatorics;random number generation;distribution function;calculus;mathematics;statistics	ML	-97.23875525790517	37.123572826699004	70612
d15fb76a39e38cfbaa53dc00539620376f8ef08c	ein verfahren zum entwurf von asynchronen schaltwerken mit flankenempfindlichen speichergliedern				Reinhard Kirchner	1977	Elektronische Informationsverarbeitung und Kybernetik		combinatorics;pure mathematics;mathematics	Crypto	-95.55086677858061	34.3719368331903	70908
5408a564462e38116cfcaa9678d9f29ca3320590	a review of microblogging in the enterprise		As a worldwide phenomenon, Microblogging has gained increasing popularity. Twitter has not only attracted more than 100 Million active users in its six year history but is also said to have a considerable impact on public communication as is signified by its use during the Arab spring movement. In the corporate arena, the Enterprise Microblogging platform Yammer claims to have grown to more than 100 000 corporate users. Since Microblogging is claimed to have benefits in fostering communication and knowledge sharing within enterprises, it seems timely to take a closer look at the phenomenon. Our paper summarizes the state of the art on Enterprise Microblogging. It reviews three Enterprise Microblogging case studies and compares their key findings regarding implementation, use and created benefits. Zusammenfassung Das Phänomen Microblogging findet weltweit immer mehr Betrachtung. Twitter hat nicht nur mehr als 100 Millionen Nutzer weltweit, sondern beeinflusst auch wesentlich die öffentliche Kommunikation wie etwa am Beispiel des Arabischen Frühling zu sehen war. Auch die kürzlich von Microsoft aufgekaufte Enterprise Microblogging-Plattform Yammer wird in der Zwischenzeit von mehr als 100.000 Unternehmen genutzt. Die Möglichkeiten, mit Microblogging die interne Kommunikation und den Wissensaustausch zu verbessern, werden von vielen Unternehmen als sehr nützlich wahrgenommen. Daher erscheint es an der Zeit, sich tiefgehender mit dem Phänomen Enterprise Microblogging auseinander zu setzen. Unser Beitrag fast den State-of-the-Art zu Enterprise Microblogging zusammen. Er referenziert in der Community bekannte Fallstudien zu Microblogging in Unternehmen und vergleicht die Kernergebnisse zu Ausgangssituation, Nutzung und Mehrwert.	die (integrated circuit);internet explorer	Alexander Stocker;Alexander Richter;Kai Riemer	2012	it - Information Technology	10.1524/itit.2012.0682	knowledge management;internet privacy;world wide web	OS	-101.51444286531624	36.38205767114303	71069
65a02f5e1f4d51f67c9db5f30e9a3b3505debd48	die angebliche ausschaltung des risikos durch das gesetz der großen zahlen		Das Verhalten gegenuber Risiko zeichnet sich dadurch aus, das es sich nicht nur nach der mathematischen Erwartung einer Wahrscheinlichkeitsverteilung richtet, sondern diese durch mindestens ein Risikomas, etwa die Streuung, zu korrigieren sucht. Dabei kann es leicht geschehen, das ein Glucksspiel, das zwar einen positiven Gewinn-Erwartungswert besitzt, aber zugleich hohe Verlustmoglichkeiten zulast, ausgeschlagen wird. Vielfach wird aber in einer solchen Situation argumentiert, das bei haufiger und unabhangiger Wiederholung dieses Glucksspiels schlieslich doch der positive Erwartungswert den Ausschlag gebe und daher das wiederholte Spiel angenommen werde, weil namlich nach dem Gesetz der grosen Zahlen praktisch kein Risiko mehr zu befurchten sei. Ich habe fruher mit Hilfe des Begriffs des Sicherheitsaquivalents gezeigt, das dieses Argument zweifelhaft ist. Nun kommtSamuelson mit anderen Voraussetzungen zu einem ahnlichen Resultat. Ein Vergleich der beiden Ansatze ist das Thema dieses Aufsatzes.		Hans Schneeweiß	1968	Unternehmensforschung	10.1007/BF01918317	discrete mathematics;mathematics;performance art	Crypto	-105.44814522842982	33.92334062881338	71197
f4fac5b6866492d2e5b163c9de0df1594fed1c62	eine neue methode zur behandlung der integralgleichung von lindley und ihrer verallgemeinerung durch finch			eine and zwei;finch	Hans-Joachim Rossberg	1967	Elektronische Informationsverarbeitung und Kybernetik		combinatorics;mathematical physics;mathematics	NLP	-96.07661030821835	34.50196870118994	71409
7a02db52817c61f71e12f5442e1f9fe79d48813d	absorbierende nanomaterialien für neuartige emv - koaxialhöchstfrequenzleitungen		In der heutigen Zeit der Einführung neuer Technologien der Funkübertragung, der Mobilfunkkommunikation ( D-Netz, E-Netz, UMTS ), der Netzwerke, Bussysteme ( CAN, LON, INTERBUS ) , und Video/ Audio Anwendungen werden neue Übertragungsraten und hohe Taktfrequenzen genutzt. Für bisherige technische Anwendungen mit Frequenzobergrenzen bis 1000 MHz [1] waren HF-Materialien [ 2 ] mit Arbeitsbereichen der oben genannten Frequenzobergrenze ausreichend entwickelt und einsetzbar. Diese Materialien genügen aber nicht mehr den neuen Technologien. In Zukunft werden neuartige HF-Materialien als Absorbermaterialen [ 3 ], Entstörmaterialien, Materialien für Gehäusemodule und Höchstfrequenzleiterplatten und Koaxialleitungen zwingend für Frequenzen > 1000 MHz zu entwickeln sein. In der Arbeit wird insbesondere auf ferrimagnetische Schichtsysteme als EMV – Materialien für die neuen notwendigen Arbeitsgebiete eingegangen. Diese Dünnschichtsysteme setzten eine fundierte Analyse der Wechselwirkung HFAbsorption / Schichtcharakteristik voraus. Die Frage der Schichtanordnung eines Monolayersystems für HF-Koaxialleitungen wird experimentell diskutiert. Wichtig für das PVD-Verfahren Sputtering sind Targetgeometrie, Sputterdruck, Sputtertemperatur. Die EMV – Anwendbarkeit für einen Frequenzbereich f= 40 MHz – 18000 MHz wird diskutiert	die (integrated circuit);eine and zwei;gesellschaft für informatik;helicon filter;interbus;physical vapor deposition	Frank Gräbner;Stefan Hildenbrand;Axel Hungsberg;Hans-Georg Huck;Gudrun Liemann	2006				ML	-104.16097285377892	32.77507977694877	72028
640add5438ff9358a2015b50c74366e27e5e205d	ein wiki-basiertes vorgehensmodell für business intelligence projekte		Business Intelligence (BI) umfasst die Integration von Strategien, Prozessen und Technologien, um im Umfeld der entscheidungsunterstützenden Systeme aus fragmentierten, inhomogenen Unternehmens-, Marktund Wettbewerberdaten erfolgskritisches Wissen über Status, Potenziale und Perspektiven zu generieren und dies für Analyse-, Planungsund Steuerungszwecke geeignet darzustellen (Gluchowski et al., 2008; Kemper et al., 2006).	unified model;wiki	Stephan König	2009			world wide web;business intelligence;engineering	AI	-100.82615353163946	33.96861721822355	72358
31813bf06fa21711b30851ee5699e1f8d80594cf	powell-sabin splines in range restricted interpolation of scattered data	quadratic program;lower and upper bound;scattered data;quadratic optimization;ams subject classification;spline interpolation	The construction of range restricted bivariateC 1 interpolants to scattered data is considered. In particular, we deal with quadratic spline interpolation on a Powell-Sabin refinement of a triangulation of the data sites subject to piecewise constant lower and upper bounds on the values of the interpolant. The derived sufficient conditions for the fulfillment of the range restrictions result in a solvable system of linear inequalities for the gradients as parameters, which is separated with respect to the data sites. Since there exists an infinite number of spline interpolants meeting the constraints, the selection of a visually pleasant solution is based on the minimum norm modification of a suitable initial interpolant or on the minimization of the thin plate functional. While the first proposal reduces to the solution of independent local quadratic programs, the second proposal results in a global quadratic optimization problem. Behandelt wird die Interpolation unregelmäßig verteilter Daten durch quadratische Powell-Sabin-Splines, wobei stückweise konstante obere und untere Schranken für die Funktionswerte der Interpolierenden vorgegeben sind. Die hergeleiteten hinreichenden Bedingungen für die Einhaltung der zweiseitigen Schranken ergeben ein lösbares lineares Ungleichungssytem für die Gradienten als Parameter, welches bezüglich der Datenpunkte separiert ist. Die Auswahl von visuell gefälligen Interpolierenden erfolgt durch die Minimierung geeigneter Funktionale.	davidon–fletcher–powell formula;decision problem;gradient;linear inequality;mathematical optimization;optimization problem;powell's method;refinement (computing);spline (mathematics);spline interpolation	Bernd Mulansky;Jochen W. Schmidt	1994	Computing	10.1007/BF02252986	spline interpolation;mathematical optimization;combinatorics;mathematical analysis;discrete mathematics;inverse quadratic interpolation;mathematics;geometry;thin plate spline;quadratic programming	Theory	-96.42166037892068	35.97524577196276	72508
c1aaca72290d553435690114eff080d73b86a170	note on algorithm 21	markov decision process	In algorithm 21 Spremann and Gessner [1] present a new algorithm for an ergodic Markov decision process. This note shows that this algorithm not necessarily converges and suggest a modified algorithm. In Algorithmus 21 presentieren Spremann und Gessner [1] einen neuen Algorithmus für einen ergodischen Markov-Entscheidungsprozeß. Diese Notiz zeigt, daß der Algorithmus nicht notwendigerweise konvergiert und schlägt einen modifizierten Algorithmus vor.	algorithm;ergodicity;gesellschaft für informatik;intentionally blank page;markov chain;markov decision process;vhf omnidirectional range	J. van der Wal	1976	Computing	10.1007/BF02259650	forward algorithm;markov decision process;mathematical optimization;combinatorics;discrete mathematics;partially observable markov decision process;mathematics;markov algorithm;markov process;markov model;dinic's algorithm;id3 algorithm;hidden markov model	ML	-97.24026924368609	36.358515793282606	72539
03a255f30167026fc6b05294ed29a8f9b6b110e3	authentisierung an mobilen geräten mittels gangerkennung		Daten in mobilen Geräten sind meist nicht ausreichend geschützt. Die meisten Nutzer bleiben aus Bequemlichkeitsgründen ununterbrochen eingeloggt. Bekommt jemand Zugriff auf das Gerät bedeutet dies automatisch, dass er auch Zugriff auf die darin enthaltenen Daten hat. Daher werden Methoden benötigt, die eine kontinuierliche Authentisierung des Nutzers ohne dessen aktives Eingreifen ermöglichen und somit sowohl eine hohe Nutzerfreundlichkeit als auch den Schutz der Daten sicherstellen. Eine Möglichkeit ist die Authentisierung mittels Gangerkennung. Hierfür können aus den Daten der in neuere mobile Geräte integrierten Beschleunigungssensoren biometrische Templates des Gangs eines Nutzers erstellt werden, die anschließend zur fortlaufenden Authentisierung des gehenden Nutzers dienen.	eine and zwei	Claudia Nickel	2009	Datenschutz und Datensicherheit - DuD	10.1007/s11623-009-0085-4	internet privacy;computer science	Crypto	-104.08017649618834	36.716440347938764	72542
8f8f579fb1312dd4e138ab3166c4e6597aaefc71	über die mathematischen grundlagen einiger chiffrierverfahren		Der mathematische Hintergrund einiger Chiffrierverfahren, die neuerdings vorgeschlagen werden, wird untersucht. Die genaue Analyse der benutzten mathematischen Aussagen führt zu Erweiterungen der Verfahren und zeigt, welche Vorkehrungen nötig sind, um Sicherheit vor unbefugter Entschlüsselung zu erreichen. The mathematical background of some recently proposed cryptographic systems is investigated. The analysis of the mathematics behind these systems, leads to extensions and shows how to avoid insecurity.	cryptography;unified model;vhf omnidirectional range	A. Ecker	1982	Computing	10.1007/BF02246756	mathematics;calculus;mathematical analysis	AI	-97.22466053118075	34.42709463262444	72853
086a56f442c6812b8d99bee1cb000fedca5d2874	fallstudien zur alltagsrelevanz von zeit- und kalenderkonzepten	cognitive impairment;user study;time categories;assistive technology;embodied conversational agent;poster	Basierend auf zwei Fallstudien werden erste Ergebnisse zu alltäglichen Zeitund Kalenderkonzepten beim Terminmanagement von Menschen mit Unterstützungsbedarf beschrieben. Ausgehend von einer Interaktionsstudie mit einem Embodied Conversational Agent (ECA), in dem die Diskrepanz zwischen den Zeitkategorien des technischen Systems und denen der Nutzer hervortritt, werden auf Basis ethnographischer Feldforschung anhand zweier Fallstudien von Menschen mit kognitiven Einschränkungen die im Alltag relevanten Zeitkategorien dargestellt. Die Daten bieten erste Ansätze zur Formulierung von Implikationen für das Design des technischen Assistenzsystems hinsichtlich Kalender-Design, Übersetzerfunktion und Integration in das menschliche Unterstützungsnetzwerk.	eine and zwei;embodied agent	Katharina Cyra;Antje Amrhein;Karola Pitsch	2016		10.18420/muc2016-mci-0253	psychology;artificial intelligence;multimedia;communication	Logic	-108.33397793427407	32.84007169184259	72875
978b6fdda8bba1d18665d9f168aec7c5d858d8e4	text und data mining		Der deutsche Gesetzgeber wollte für Textund Data MiningAnalysen Rechtssicherheit schaffen. Deswegen hat er für wissenschaftliche, nicht-kommerzielle Zwecke eine neue Urheberrechtsschranke geschaffen (§ 60d UrhG). Der Beitrag stellt die Schranke vor und analysiert sie kritisch. Nach kurzer Einleitung zum Hintergrund (I.) werden der persönliche (II.), der gegenständliche (III.) und der zeitliche (IV.) Anwendungsbereich aufgezeigt, bevor auf die freigestellten Handlungen (V.) und das Zusammenspiel mit vertraglichen Beschränkungen (VI.) sowie die Vergütungspflicht (VII.) eingegangen wird.	data mining;eine and zwei;sie (file format);vhf omnidirectional range;vii	Benjamin Raue	2017	Computer und Recht	10.9785/cr-2017-1008	natural language processing;computer science;artificial intelligence	DB	-106.59345293564411	35.8197430905589	73172
f40543f47a01aaf92b13bb0e09b70e1910b7dcfb	exact solution of the evasive flow capturing problem				Okan Arslan;Ola Jabali;Gilbert Laporte	2018	Operations Research	10.1287/opre.2018.1756		Theory	-96.86378568466885	33.33962655729849	73176
d1b318eb016649f3a73d46b4b417ab9e1d56c627	eine differenzierte metadatennotation xml-basierter e-learning-ressourcen für ein zuverlässiges metadatenmanagement	talk	Zur Erstellung digitaler Lehrund Lernmaterialien hat sich XML als ein Beschreibungsmittel für Dokumenteninhalte durchgesetzt. Damit erstellte Inhalte lassen sich auf vielfältige Art und Weise in die unterschiedlichsten Präsentationsformen überführen, welche sich auch hinsichtlich ihrer Inhalte unterscheiden können. Für diese sind korrekte, konsistente und vergleichbare Metadaten eine essentielle Notwendigkeit, um deren Nachhaltigkeit, Wiederverwendbarkeit und Interoperabilität zu gewährleisten. Gängige Metadatennotationen zur Beschreibung XML-basierter Lehrund Lernmaterialien scheitern an ihrer Ausdrucksmöglichkeit, diese adäquat zu beschreiben. Der vorliegende Beitrag widmet sich dieser Problematik und stellt eine allgemeine Notationsform für Metadaten vor, deren praktische Anwendbarkeit anhand eines semiautomatischen Autorenwerkzeugs für Metadaten demonstriert wird. Der vorgestellte Ansatz ist nicht auf die genannte Domäne beschränkt, sondern lässt sich für jede andere Anwendung adaptieren, die ein zuverlässiges Metadatenmanagement erfordert.	eine and zwei;gesellschaft für informatik;unified model;vhf omnidirectional range;xml	Maik Bunschkowski;Marc Röser;Djamshid Tavangarian;Denny Voigt	2004			xml;performance art;art	OS	-105.75025970013006	34.1220236619129	73378
e6f0c456fa8899952b6f2cf0e989b4da08c785ec	privacyscore: analyse von webseiten auf sicherheits- und privatheitsprobleme - konzept und rechtliche zulässigkeit		PrivacyScore ist ein öffentliches Web-Portal, mit dem automatisiert überprüft werden kann, ob Webseiten gängige Mechanismen zum Schutz von Sicherheit und Privatheit korrekt implementieren. Im Gegensatz zu existierenden Diensten ermöglicht PrivacyScore, mehrere Webseiten in Benchmarks miteinander zu vergleichen, die Ergebnisse differenziert und im Zeitverlauf zu analysieren sowie nutzerdefinierte Kriterien für die Auswertung zu definieren. PrivacyScore verbessert dadurch nicht nur die Transparenz für Endanwender, sondern erleichtert auch die Arbeit der DatenschutzAufsichtsbehörden. In diesem Beitrag stellen wir das Konzept des Dienstes vor und wir erörtern, unter welchen Umständen das automatische Scannen und öffentliche „Anprangern“ von Schwächen aus rechtlicher Sicht zulässig ist.	citeseerx;vhf omnidirectional range	Max Maaß;Anne Laubach;Dominik Herrmann	2017		10.18420/in2017_107	computer security;computer science;performance art	DB	-104.75320826249124	32.432331115146646	73806
bc1a546e91b1e66e9d8bd50ded0f1a2a78b18e35	elektrische maschinen und antriebe	other	Univ.-Prof. Dr. phil. Dr. techn. habil. Harald Neudorfer Auf dem Fachgebiet der elektrischen Maschinen und Antriebe gibt es nach wie vor weitere neue Entwicklungen, die vor allem auf die Effizienz der Systeme eingehen. Obwohl die Grundprinzipien für elektrische Maschinen seit ca. 150 Jahren bekannt sind, können aufgrund von neuen Materialien, innovativen Regelungsalgorithmen und speziellen Anpassungen für den Anwendungsfall immer wieder Fortschritte erzielt werden. Große Anstrengungen in der Weiterentwicklung von elektrischen Antriebssystemen richten sich auch auf das Ziel, die Wirkungsgrade zu verbessern. Dabei werden auch bei Maschinen kleinerer Leistungsklassen die Einzelverluste noch präziser berechnet. Dies ist allerdings nur dann möglich, wenn der elektrische Antrieb als multi-physikalisches Gesamtsystem betrachtet wird, bei dem neben der elektromagnetischen Auslegung auch die mechanische, thermische, strömungstechnische und geräuschtechnische berücksichtigt wird. Daraus ergibt sich, dass nicht nur klassische Elektrotechniker, sondern auch Maschinenbauer, Strömungstechniker oder ganz allgemein Physiker in das Design des elektrischen Antriebes eingebunden werden. Ein weiterer wesentlicher Punkt für Neuentwicklungen bei elektrischen Maschinen und Antrieben ist der zwingende Wunsch nach Kostenreduzierung. Um diesem wirtschaftlichen Druck bezüglich Kostenoptimierung zu entsprechen, werden bei einigen nachvollziehbaren Anwendungen sogar Performanceeinbußen im technischen Bereich in Kauf genommen. Bei Maschinentypen mit großen Stückzahlen, wie zum Beispiel in der Automobilindustrie, kommt bei der Auslegung neben den oben angeführten Experten auch den Fertigungstechnikern große Bedeutung zu. Ihre Aussage über eine kostenoptimale Fertigungstechnologie kann das Maschinendesign wesentlich beeinflussen. Die Weiterentwicklung elektrischer Maschinen und deren optimierte Auslegung wird auch von immer aufwändigeren Finite Elemente-Programmen beeinflusst. Es kann durchaus behauptet werden, dass die Auslegung einer elektrischen Maschine im Forschungsund Entwicklungsbereich, aber auch bei der industriellen Anwendung, ohne Finite Elemente-Berechnung nicht mehr ausgeführt wird. Durchaus erfreulich ist die Tatsache, dass die Anzahl der Studierenden, die sich für das Gebiet der elektrischen Maschinen und Antriebe interessieren, in den letzten Jahren merkbar gestiegen ist. Die vor 10 bis 15 Jahren gängige Meinung, dass auf dem Gebiet der elektrischen Maschinen keine großartigen Weiterentwicklungen mehr zu erwarten sind, hat sich nicht bewahrheitet. Trotz längst bekannter Grundprinzipien elektrischer Maschinen stiegen laufend die Varianten von Anwendungen für elektrische Systeme. Zwei typische aktuelle Beispiele sind die Themenkreise ”Elektromobilität“ und ”Hybridisierung“. Diese durchaus auch sozialpolitischen Tendenzen werden von den Studierenden wahrgenommen und somit das Teilgebiet der Elektrotechnik ”Elektrische Maschinen und Antriebe“ vermehrt als Studienzweig angenommen. Durch die sehr große Resonanz seitens der angeschriebenen Autoren wurden für das vorliegende Themengebiet ”Elektrische Maschinen und Antriebe“ eine Vielzahl an Beiträgen eingesendet. Nach Rücksprache mit der e&i-Schriftleitung haben wir uns entschlossen, im Heft 1/2015 insgesamt 13 begutachtete Originalarbeiten aufzunehmen. Für die große Anzahl an hochwertigen Papers und die Bereitschaft des Herausgebers, ein Heft mit so vielen Beiträgen zu gestalten, möchte ich mich als Heftkoordinator bei allen Beteiligten sehr herzlich bedanken. Es ist dies als ein starkes Lebenszeichen aller mit dem Themengebiet befassten Institute an den Technischen Universitäten und in der einschlägigen Industrie zu werten. Die aktuelle Ausgabe der vorliegenden Zeitschrift beinhaltet folgende Beiträge: Weiss, Polt, Geschrey und Schrödl beschreiben stromrichterbedingte Verluste am Beispiel eines permanenterregten Synchrongenerators bei unterschiedlichen Schaltfrequenzen und den Unterschied bei oberflächenmontierten und vergrabenen Magneten. Schmidt untersucht mittels numerischer Analyse permanenterregte Synchronmaschinen (PSM) mit Bruchloch-Zahnspulenwicklungen und stellt die Einflüsse der Permanentmagnete und der Statorströme in Abhängigkeit von Rotorwinkellage und unterschiedlicher Sättigungszustände näher dar. Neubauer und Neudorfer thematisieren in ihrem Beitrag ebenfalls das Thema PSM mit Zahnspulenwicklungen. Vorgestellt wird ein neuartiger Traktionsgenerator mit geschrägten Nuten, mit dem kurze axiale Länge bei hoher Leistungsdichte realisiert wird. Lehr, Reis und Binder vergleichen Axialund Radialflussmaschinen für den Einsatz in Radnabenantrieben und gehen auch mit Hilfe der Finite Elemente-Methode unter besonderer Berücksichtigung der Lochzahl auf die Auslegung der Maschinen ein. Misir, Dobbert und Ponick stellen eine analytisch numerische Berechnung des magnetischen Luftspaltleitwertes für Rotoren einer Schenkelpolsynchronmaschine vor und vergleichen deren Abhängigkeit von unterschiedlichen Parametern. Bacher und Mütze vergleichen Asynchronmaschinen (ASM) mit verteilten und konzentrierten Wicklungen. Der Einsatz von konzentrierten Wicklungen bringt Kostenersparnisse bei der Fertigung, aber auch einen erhöhten Anteil an höheren Harmonischen bei diesem Maschinentyp. Herold, Franck, Böhmer, Schröder und Hameyer zeigen in ihrer Abhandlung ein transientes Simulationsmodel für lokale Kraftanregungen in elektrischen Antrieben. Damit ist es möglich, drehzahlund drehmomentdynamische Vorgänge zu bewerten.	circa;eine and zwei;es evm;file binder;heterogeneous earliest finish time;i/o controller hub;institut für dokumentologie und editorik;internet explorer;maschine;maschinen krieger zbv 3000;openbinder;schmidt decomposition;unified model;vhf omnidirectional range;zentralblatt math	Harald Neudorfer	2016	Elektrotechnik und Informationstechnik	10.1007/s00502-016-0400-3	physics	OS	-104.24028871208455	34.02447731787137	73818
77494f7e32d91f5eee38a765550635fc604bffbe	zur entwicklung der informationsverarbeitung in der tierzucht		Die verfügbare technische Ausstattung mit ihren immensen Kosten gestattete zunächst ausschließlich einen zentralen Einsatz der Datenverarbeitung. So begann die Datenverarbeitung für die Rinderzucht an 9 verschiedenen Orten mit jeweils eigenständigen Rechenzentren.		Otto Vogt-Rohlf	2010				Logic	-104.20387563851139	32.807559091665816	74176
ef53e4ca745070fe9df434213bb46c1faccf77a7	die berücksichtigung des stands der technik in der dsgvo		Die Datenschutz-Grundverordnung hebt die gesetzlichen IT-Sicherheitsanforderungen signifikant an und führt zu einem Systemwechsel gegenüber dem bislang national geltenden technischen Datenschutz. Die Unternehmen und die öffentliche Verwaltung werden verpflichtet, bei der Umsetzung technischer und organisatorischer Maßnahmen den Stand der Technik zu berücksichtigen. Es bedarf somit einer Methode zum gesetzeskonformen Berücksichtigen des Stands der Technik.		Karsten U. Bartels;Merlin Backer	2018	Datenschutz und Datensicherheit - DuD	10.1007/s11623-018-0910-8	internet privacy;library science;computer science	NLP	-103.40224089227843	36.01364585559444	74721
7c87a03273f717d71617f8c7a626908c56737abd	tfacet: hierarchisch-facettierte exploration semantischer daten mit hilfe bekannter interaktionskonzepte		Im Semantic Web gespeicherte Informationen werden auch für den durchschnittlichen Web-Nutzer immer interessanter. Auf Grund der komplizierten Bedienung bestehender Anwendungen stellt der konkrete Zugriff darauf allerdings noch ein Problem dar. In diesem Beitrag stellen wir daher tFacet vor, ein Werkzeug, das bekannte Interaktionskonzepte nutzt, um hierarchisch-facettierte Exploration auch für unerfahrene Nutzer zu ermöglichen. Ziel ist es, die Formulierung von semantisch eindeutigen Anfragen zu erleichtern und so den schnellen und gezielten Informationszugriff auch in der Breite zu unterstützen.	semantic web;unified model;vhf omnidirectional range	Philipp Heim;Sören Brunk	2011				AI	-106.45988890009085	35.487297871150844	75309
ff0343e41091349dfb50820413de19795f3a85e3	multimedia home platform (mhp) für das digitale fernsehen (dvb)	multimedia home platform	Mit der Multimedia Home Platform wird das digitale Fernsehen mit einer einheitlichen Bedienplattform bedient, d.h. der Zuschauer braucht nur eine Set-Top-Box fur den Empfang aller digitalen Sender. Heute verfugbare Empfanger konnen lediglich das digitale Programmangebot und die Zusatzdienste des jeweiligen Anbieters der Set-Top-Box empfangen, nicht jedoch die vielfaltigen Zusatzangebote anderer Anbieter, die einen wesentlichen Mehrwert dieser neuen Technik darstellen. Mit dem MHP-Standard wird es moglich sein, alle Angebote der verschiedenen Programmanbieter zu empfangen. Der MHP-Entwurf wird in verschiedenen Profiles realisiert. Es werden dabei Boxen mit einfachen Empfangseigenschaften bis hin zu multimedialen Geraten mit Internet-Anschluss auf den Markt kommen. Die Multimedia Home Platform wurde bei ETSI zur Standardisierung eingereicht Das Institut fur Rundfunktechnik (IRT) wird zu diesem Standard eine Referenzimplementierung schaffen. Diese soll der Uberprufung des Funktionsumfangs dienen und gleichzeitig etwa vorhandene Unscharfen in der Formulierung aufklaren helfen. Auf einer marktublichen PC-Plattform wird dazu die Spezifikation (ausgenommen HW-spezifische Teile) ausschlieslich in JAVA realisiert. Das Ergebnis wird Programmanbietern und Herstellern fur die Entwicklung und Uberprufung ihrer Produkte zu Verfugung stehen.	digital video broadcasting;television	Dietrich Sauter	2000		10.1007/978-3-642-59575-2_8	multimedia home platform;operating system;digital video broadcasting;computer science	HCI	-106.55833389723003	34.27554038462025	75656
5aa3690998a97089e5508caaef08c3ffc8de33e6	vitamin n - gender partnership: mint-frauen in virtuellen netzwerken		Was können Netzwerke zur Förderung der Chancengleichheit von Frauen und Männern im MINT-Bereich beitragen? Welche besondere Rolle spielen virtuelle Netzwerke dabei? Wie müssen virtuelle Netzwerke aufgebaut und belebt werden, um besonders Frauen als Nutzerinnen gerecht zu werden? Im Gender Partnership Programm der Beuth Hochschule für Technik Berlin wird das reale MINT-Netzwerk aus Mentor(inn)en und Mentees um ein virtuelles Netzwerk ergänzt, um Studentinnen beim Einstieg in den Beruf nachhaltig zu unterstützen. In diesem Artikel werden Konzeption und Umsetzung des Gender Partnership Netzwerkes vorgestellt.	internet explorer;unified model	Katrin Bohnet;Eva-Maria Dombrowski	2011			nursing;general partnership;vitamin;sociology	NLP	-102.78130547969864	33.6239124775728	75806
17450a841600f8b4f84c630eb2d29e4d8f871b4d	die m-das - eine modifizierte version der differentiellen affekt skala zur erfassung von emotionen bei der mediennutzung	emotions;factor analysis;differential emotions scale;media reception;positive affective states;emotionen;affektskalen;test reliability;medienrezeption;modified version;affect scales	Zusammenfassung. In einer Studie zur Modifikation der Differentiellen Affekt Skala (DAS) wurden die positiven Emotionen Zuneigung, Frohlichkeit, Zufriedenheit, Faszination, Vergnugen und Freude dahingehend gepruft, ob sie sich in medienpsychologischen Untersuchungen als zusatzliche Skalen zur Erfassung positiver emotionaler Befindlichkeiten eignen. 160 Versuchspersonen sollten sich an ein angenehmes Film- oder Fernseherlebnis erinnern und zu 62 emotionsbeschreibenden Begriffen (5-stufige Skala) angeben, wie intensiv sie dieses Gefuhl empfunden haben. Die interne Reliabilitatsermittlung und Faktorenanalysen fuhrten fur Vergnugen, Zufriedenheit, Zuneigung und Freude zu je drei Items, die zufrieden stellende Reliabilitaten erreichten und auf einem gemeinsamen Faktor hoch laden. Fur Faszination fand die Faktorenanalyse zwei Faktoren, die auf zwei Varianten dieser Skala (Faszination und Ergriffenheit) schliesen lassen. Eine zusatzliche Studie mit 600 Kinobesuchern ergab zufrieden stellende interne Konsistenzen...	eine and zwei	Dagmar Renaud;Dagmar C. Unz	2006	Zeitschrift für Medienpsychologie	10.1026/1617-6383.18.2.70	psychology;emotion;reliability;factor analysis;statistics	NLP	-107.53911074111568	33.169182411340415	75865
1c132a333e9f241b7b3159d6a45476cd49226d0b	von eletronischen märkten zu kooperationsplattformen: perpecktiven für die entwicklung web-basierter handels-plattformen	entwicklung web-basierter handels-plattformen;von eletronischen m	Ausgehend von der starken Ausweitung elektronischer Märkte untersucht der Beitrag aus einer institutionen-ökonomischen Perspektive Erfolgsfaktoren elektronischer Marktplätze und erörtert Gründe für das verbreitete Scheitern von Marktplatzinitiativen. Mit demselben konzeptionellen Rüstzeug wird die in zahlreichen Studien empfohlene Option einer Ausweitung des Serviceangebots hin zu einer Kooperationsplattform analysiert und die Frage erörtert, ob sich beide Modelle auf einer Plattform kombinieren lassen. 1 Move to the market Elektronische Märkte (oder Marktplätze) sind virtuelle Orte des Tauschs von Gütern und Leistungen [Sc99]. Sie reduzieren die Komplexität wirtschaftlicher Transaktionen durch ein starkes institutionelles Regime (Marktregeln) sowie die Fokussierung auf einen dominierenden Entscheidungsparameter, den Preis. Seit Ende der 80er Jahre wird in wissenschaftlichen Veröffentlichungen die Verbreitung elektronischer Märkte prognostiziert (z.B. [MBY87], für eine Zusammenfassung der Diskussion vgl. [Kl00]). Der Trend zur Verbreitung elektronischer Märkte im Geschäftskundensegment (B2B) setzt sich dabei aus drei Einzeltrends zusammen [AKK94]: § Traditionelle Märkte werden zu elektronischen Märkten. Beispiele für diese Entwicklung ist die Einführung des elektronischen Handels auf fast allen Finanzmärkten oder auch der Übergang zur elektronischen Blumenauktionen [HDKR97]. § Traditionelle Lieferbeziehungen werden in elektronische Märkte überführt. Für ein ausgesprochen weites Spektrum von Gütern und Dienstleistungen (Logistische Dienstleistungen, Softwarekomponenten, Dienstleistungen von Experten etc.) gibt es Initiativen zur Einrichtung elektronischer Märkte (vgl. [Be02a]). 1 Die Begriffe Markt und Marktplatz werden in der Literatur häufig synonym verwendet. Märkte weisen im Allgemeinen einen abstrakten, Marktplätze einen konkreten Bezug auf, d.h. ein Marktplatz ist vom Vorhandensein eines konkreten (auch virtuellen) Ortes des Handelsgeschehens abhängig.	eine and zwei;eddie (text editor);gesellschaft für informatik;sie (file format)	Stefan Klein;Marcel Gogolin	2002					-103.30563409575981	35.77473755735945	76003
31a3756889f82f813ff2814403086030433b9c47	alles falsch gemacht!		Ein Unternehmen mit 1700 gewerblichen Partnern betreiben und in 200 Städte liefern, ohne einen einzigen schriftlichen Vertrag zu haben. Allen Endkundinnen und Endkunden ein Vetorecht für alle geschäftlichen Entscheidungen geben. Nie einen Plan für die nächsten Monate haben, maximal für Wochen. Und das alles bitte ohne Investoren, ohne Werbung, ohne Management. Und bitte als Online-Zusammenarbeit organisiert, ohne Kontrolle der Mitarbeitenden. Geht nicht? Dass das geht, und wie das geht, erzählt der Gründer und zentrale Moderator des Premium-Getränkekollektivs. 1 PREMIUM, Uwe Lübbermann, Brauerknechtgraben 45, 20459 Hamburg, uwe@premium-cola.de	geometric median;gesellschaft für informatik;google moderator;internet explorer;maximal set	Uwe Lübbermann	2016				DB	-103.35103884588457	34.81273211887293	76266
cda58ff53b5ab55af9c531d8cb7f81ef48fe6190	business-entscheidungen und optimierungen mit qualicision von f/l/s		In Unternehmen werden täglich millionenfach Entscheidungen getroffen. Diese sind in mehr oder weniger stark formalisierten Geschäftsprozessen eingebunden, die bisher überwiegend nicht automatisiert ablaufen. Je weniger formalisiert die Geschäftsprozesse, desto stärker der Bedarf nach einer Systematisierung der Entscheidungsfindung. Überraschend ist, dass mit Hilfe der Qualicision-Technologie eine automatisierte Entscheidungsfindung selbst in Geschäftsprozessen möglich ist, deren Formalisierung bisher nicht stark ausgeprägt ist.	citeseerx;eine and zwei	Rudolf Felix	2007	KI		philosophy;performance art	NLP	-105.4435411972041	33.552246905995595	76581
ebebe350d90e21bb191ce5c453022b44b2852e1b	multiplan - tabellenkalkulationssoftware als hilfsmittel bei der konstruktion eines ökonomischen planspiels	konomischen planspiels;der konstruktion eines	Der Markt fur okonomische Planspiele bietet z. Zt. etwa 250 Modelle an, die sich sowohl hinsichtlich ihrer Komplexitat als auch hinsichtlich der Hohe ihrer Anschaffungskosten teilweise erheblich unterscheiden.	multiplan	Thomas Schwäbe	1986		10.1007/978-3-642-71648-5_14		ML	-104.5913527256328	32.79984088454957	76602
d2ebc41a32b351c8e303bed4e45665af9cf5174e	efficient algorithms for constraint propagation and for processing tree descriptions	efficient algorithm;csp	This thesis consists of two parts. In the first part we present propagation algorithms, which to solve a CSP is based on interleaving constraint progagation and search. The task of a propagation alogrithm is to prune portions of the search space which do not contain a solution so that the search does not have to explore them. We present propagation alogrithms for the following constraints: Sortedness, Alldiff, WeightedPartialAlldiff and NonOverlapping (of two convex polygons). The second part deals with a tree processing problem, which is represented as a dominance graph. The task is to assemble a collection of tree fragments into a tree T such that the ancestor relation of T satisfies some given constraints. We discuss efficient algorithms for deciding whether a dominance graph D has a solved form and for enumerating all (minimal) solved forms of D. #N#Diese Arbeit besteht aus zwei Teilen. Im ersten Teil behandeln wir Propagierungsalgorithmen zum Losen von Constraint-Problemen. Ein Losungsansatz basiert darauf, Constraint-Propagierung und Suche abzuwechseln. Durch die Propagierung werden Teile des Suchraums eliminiert, die keine Losung enthalten. Dadurch verringert sich der Raum, der von der Suche exploriert werden muss, und die Losung(en)werden oftmals schneller gefunden als durch Suche alleine. Wir beschreiben Propagierungsalgorithmen fur folgende Constraints: Sortedness, Alldiff, WeightedPartial Alldiff und NonOverlapping.#R##N#Der zweite Teil behandelt ein Baumverarbeitungsproblem, das durch einen Dominanzgraphen beschrieben wird. Das Problem besteht darin, Baumfragmente so zu einem Baum zusammen zu setzen, dass bestimmte Anforderungen an die Vorfahr-Relation des Baumes erfullt sind. Wir entwickeln einen Linearzeit Losbarkeitstest und effiziente Algorithmen zum Aufzahlen aller (minimalen) gelosten Formen eines Dominanzgraphen.	algorithm;local consistency;software propagation	Sven Thiel	2004			computer science;artificial intelligence;calculus;algorithm	AI	-98.55346714872107	35.98556845712429	76615
c60d5bc94ae808fa43c71e731d2df1065d0b0a2d	order monitoring mit mobilen internetgeräten		Die neue WAP-Technologie verbindet das Internet mit dem Mobilfunknetz. Damit entstehen völlig neue Möglichkeiten in Logistik und eCommerce. Kunden, Lieferanten und Entscheider im eigenen Unternehmen können von jedem Punkt der Welt aus sekundenaktuelle Daten zum Bearbeitungsfortschritt von Aufträgen, zu Beständen oder Produktivitätskennzahlen abfragen und online steuernd eingreifen. In Verbindung mit Navigationssystemen sehen sie, welcher Karton mit welchem Inhalt gerade in welchem Stau steckt.	e-commerce;parity (physics);sie (file format)	Georg Reichwein	2000				DB	-103.8818007945409	36.60905284381019	76759
e192e248d454c17a879b46bbe86560ad8e5c449c	zukunft von online-wahlen		Die Umsetzung elektronischer Wahlsysteme ist eine interdisziplinäre Aufgabe, bei der neben den technischen vor allem auch politische, gesellschaftliche und juristische Anforderungen zu erfüllen sind. Der vorliegende Beitrag zeigt offene Fragestellungen in den Disziplinen Recht, Gesellschaft und Politik auf. Er ist ein Gemeinschaftsprojekt von der ersten Arbeitstagung E-Voting in D/A/CH in Saarbrücken von 27.-29. Oktober 2006.	eine and zwei;gesellschaft für informatik;vhf omnidirectional range	Jörg Helbach;Robert Krimmer;Anastasia Meletiadou;Nils Meißner;Melanie Volkamer	2007	Datenschutz und Datensicherheit - DuD	10.1007/s11623-007-0155-4		OS	-103.64951326451215	34.371477182003595	76795
300b1c8b5ceb246657994014e13a22ce30a5572d	lernen und netzwerken: ein dualer ansatz zur selbstbestimmten nutzung neuer medien im alter		Das vom Schulungszentrum Uranschek koordinierte Projekt Learn & Network zielt darauf ab, ältere Menschen über einen dualen Ansatz – Lernen und Netzwerken – zur selbstbestimmten Nutzung Neuer Medien heranzuführen. Zu diesem Zweck wurde zu Beginn dieses Projekts von der Abteilung für Erwachsenenund Berufsbildung der Alpen-Adria Universität Klagenfurt eine Literaturstudie zu den Lernbesonderheiten älterer Menschen im Kontext von Informationsund Kommunikationstechnologien durchgeführt. Der vorliegende Beitrag präsentiert ausgewählte Aspekte aus dieser Studie.	eine and zwei;institut für dokumentologie und editorik	Alexander Stocker;Kurt Majcen;Harald Mayer;Anita Brünner;Cindy Wrann;Tatjana Prattes;Gertraud Hausegger-Grill;Markus Stoisser;Hannes Robier	2011			mathematical physics;ansatz;mathematics	ML	-106.15630842000212	33.32830785286761	76818
386c00470dc6c6ba4a4b35f36f6b56e8c5f92591	raumvorstellungen und biologische intelligenz: anmerkungen aus der sicht eines neurobiologen	anmerkungen aus der sicht;eines neurobiologen	Um zu untersuchen, wie Orientierungsleistungen zustande kommen, wie raumliches Wissen erworben, verarbeitet und angewendet wird, kann man zwei unterschiedliche — im Extremfall zueinander komplementare — Ansatze verfolgen: Zum einen kann man versuchen, eine Maschine zu bauen ‘die geht’, d.h. ein kunstliches System zu entwickeln, das ein Problem vollkommen unabhangig davon lost, wie es in naturlichen Systemen gelost wird. Der andere mogliche Ansatz ist, an einem naturlichen System zu untersuchen, ‘wie etwas gemacht wird’, d.h. menschliches und tierisches Verhalten zu untersuchen und die Funktionsweise von Gehirnen zu analysieren. Im folgenden werde ich einige von Neurobiologen mit diesem analytischen Ansatz gewonnene Ergebnisse vorstellen und versuchen, aus ihnen Konsequenzen fur die Synthese sich orientierender Systeme abzuleiten. Zuerst werde ich drei Patienten vorstellen, die als Folge eines Schlaganfalls Storungen in ihrer Raumvorstellung erlitten haben. Im zweiten Teil werde ich an Tierbeispielen zeigen, das in biologischen Systemen die Gestaltung der Sensoren und das Bewegungsmuster nicht unabhangig von dem zu bewaltigenden Orientierungsproblem ist und das Modell einer nicht topographisch organisierten Karte am Beispiel von Bienen vorstellen. Da fur Menschen, wie die meisten anderen Primaten, Sehen der wichtigste Fernsinn ist, steht bei allen vorgestellten Uberlegungen die aus der Analyse visueller Information abgeleitete Raumvorstellung im Vordergrund.		Werner Kriechbaum	1990		10.1007/978-3-642-84235-1_3	philosophy;performance art	Crypto	-105.97459827861694	32.423847290729235	76924
fc1463e6c22a97ccab2462c285c5bd1b810fb5ba	identitäten in mobilen ad hoc netzwerken.		Dieser Beitrag beschäftigt sich mit der Frage, welche Eigenschaften Identitäten in Ad hoc Netzen aufweisen müssen und beschreibt das Identifizierungssystem MANET-IDs.	hoc (programming language)	Frank Kargl;Stefan Schlott;Michael Weber	2005			computer science	Mobile	-107.97226549915257	34.992500380066744	77013
e0851ca2d5bdf8f5862093f2d01365fdae74a013	anonyme audit-daten im überblick - architekturen für anonyme autorisierungen und audit-daten.		Sicherheitsmaßnahmen in der digitalen Welt sind meist bereits vorhandenen Sicherheitsmaßnahmen der realen Welt nachempfunden. Das mag daran liegen, dass Vertrauen letztlich stets in der realen Welt begründet ist und Sicherheitsmaßnahmen gerade bei fehlendem Vertrauen der Akteure notwendig sind. Wie wir in der realen Welt mit Vertrauen umgehen, lässt sich am Beispiel eines Studierenden zeigen, der den Zoo besuchen möchte. Der Zoo tritt hier als Dienst(leister) auf und bietet Studierenden kostenlosen Eintritt. Nicht-Studierende könnten versuchen, sich einen geldwerten Vorteil zu verschaffen, indem sie sich an der Zoo-Kasse als Studierende vorstellen. Der Studierendenausweis fungiert als beglaubigte Eigenschaftsaussage, indem er den Namen des Aussage-Subjekts der Eigenschaft Studierender zuordnet. Die Zoo-Kasse akzeptiert diese beglaubigte Eigenschaftsaussage, wenn die vermerkte Universität als Aussteller akzeptiert wird, das Lichtbild zur vorlegenden Person „passt“, der Studierendenausweis noch nicht abgelaufen ist und „echt“ aussieht. Wenn die Zoo-Kasse den Studierendenausweis akzeptiert, autorisiert sie die vorlegende Person, den Zoo-Eingang zu passieren. Die Zoo-Kasse stellt eine Autorisierung in Form eines Eintrittstickets aus. Diese Autorisierung enthält eine dem Kunden zugeordnete Ticket-Nummer, es ist vermerkt, dass die Autorisierung zum ZooEintritt berechtigt, von welcher Kasse sie ausgestellt wurde, und sie trägt Gültigkeitsinformationen wie eine Geltungsdauer sowie schwer fälschbare Echtheitsmerkmale. Da das Ticket keine Information zur Authentisierung des Eintrittsberechtigten enthält, ist es prinzipiell übertragbar.	eine and zwei;internet explorer;mag technology co.;parity (physics);sie (file format)	Ulrich Flegel	2003	Datenschutz und Datensicherheit		internet privacy;computer science;performance art	OS	-105.031923316763	35.16405098533812	77240
38d9abd9a3083d267f96656de71d5a26594a69d9	vorwort der herausgeber		Das Verhaltnis der Politik zur Wirtschaft hat im Wesentlichen zwei Auspragungen. Einmal kann die Politik versuchen, das Problem der Knappheit selbst zu losen, und zwar in der Form machtbasierter Aneignung und Zuteilung. Dies ist das bis zur Durchsetzung des Marktes historisch vorherrschende Verhaltnis. Die Alternative des Marktes besteht darin, Menschen uber den Preisbildungsmechanismus aus der Knapp-heitssituation herauszuzwingen, sie also nicht dem Zwang der Politik, sondern des Geldbeutels zu unterwerfen. Dies ist die historisch jungere und, wie die Beitrage dieses Bandes zeigen, noch keineswegs perfektionierte Losung. Ihr Nachteil mag darin gesehen werden, dass auch der Markt weiterhin die Politik braucht. Es sind politische Vereinbarungen, aus denen die Regeln des Marktes hervorgehen, und es ist politischer Zwang, der sie gegen allfalligen Opportunismus durchsetzt. Diese zweite Variante des Verhaltnisses von Politik und Wirtschaft ist Gegenstand der folgenden Abhandlungen.		Timo Schmid;Markus Zwick	2017	AStA Wirtschafts- und Sozialstatistisches Archiv	10.1007/s11943-017-0217-5	labour economics;economics;performance art	NLP	-104.33756429762066	34.83953154876278	77487
ac1e9d2e63012ddff3660db177fe78548c24bfbb	einschließungssätze für periodische lösungen der liénardschen differentialgleichung		In dieser Arbeit werden Bedingungenn dafür aufgestellt, daß zwischen einer „Unterlösung” und einer „Oberlösung” einer nicht-autonomenLiénardschen Differentialgleichung mindestens eine periodische Lösung liegt. Ferner wird angegeben, wie die erhaltenen Einschließungen iterativ verbessert werden können. In this paper conditions are given which guarantee the existence of at least one periodic solution of a non-autonomousLiénard differential equation lying between a lower and an upper solution of this equation. This error estimation can be improved iteratively.	eine and zwei;internet explorer	Jochen Werner	1970	Computing	10.1007/BF02248024	mathematics;calculus;mathematical analysis	Theory	-96.58557398414324	35.75685171620224	77640
de96731ebe8495e69b4e7313624111667d181b95	skizzenblog: kollaboratives skizzieren im web		Skizzen habe eine große Bedeutung im Designprozess, sind im professionellen Designdiskurs im Web jedoch kaum präsent. Um die visuelle Diskussionskultur von Designern im Web zu befördern, haben wir den Skizzenblog (http://www.skizzenblog.net) geschaffen. Diskutieren über Design Die große Bedeutung von Skizzen im Designprozess als Denkwerkzeug [Cr06], [ML06] und „boundary object“ [St90] ist auch im Interaktionsdesign ungebrochen [Bu07]. Im Gegensatz dazu steht ihre fehlende Präsenz im „Social Web“. So werden in DesignerBlogs fast ausschließlich Designlösungen vorgestellt, deren Entstehung jedoch kaum erklärt oder gar gezeigt wird. Ebenso selten stellen Designer in ihren Online-Portfolios Designprozesse vor; noch weniger zeigen sie Skizzen aus der Entstehungszeit. Nichtsdestotrotz gibt es eine lebendige Diskussionskultur unter Designern im Web. In Design-Blogs etwa werden Werke von anderen Designern vorgestellt und kommentiert. Oft geraten Designer hier in die „Unmittelbarkeitsfalle“, die eigentlich Nicht-Designern vorbehalten ist: Fertige Designprodukte werden – ohne Kenntnis des Prozesses – mit eigenen Vorstellungen konfrontiert, und auf dieser ungenügenden Grundlage beurteilt. Auch werden oft Designlösungen allein aufgrund ihrer Oberflächenattribute unkritisch gelobt bzw. verurteilt. Regelmäßig reißen dann die Diskussionsfäden mit solchen Meldungen ab: „Diese allgemeine Engstirnigkeit hier und in anderen Foren gegenüber den Arbeiten bekannter Agenturen geht mir ehrlich gesagt ein wenig auf die Nerven. Wenn Ihr das alle besser könnt, warum ist die aktuelle große Kampagne XY dann nicht von Euch [...]?“ [@Fo]	blog;die (integrated circuit);eine and zwei;sie (file format);unified model;vhf omnidirectional range;zentralblatt math	Jan-Henning Raff	2008			beam (structure);display device;physical medicine and rehabilitation;foot supports;computer science	DB	-107.18305917459047	33.356949502478464	77723
43fad6538d73e675e45ab1a9fe9965f972343c82	zwei bemerkungen zur bestimmung von pufferzeiten in netzplänen		1. Die Berechnung der freien und der unabhiingigen Pufferzeit in Vorgangspfeilnetzen In der Literatur finden sich auch in neucren Ver6ffentlichungcn for die Bercchnung yon Puffcrzeiten bci Vorgangspfcilnctzen fast ausschlicl31ich Formcln, die bei Vorhandensein yon Scheinvorg~ingen nicht immcr zu Ergebnisscn fiihrcn, die den Pufferzeitdefinitioncn entsprechcn (DIN 69900). Ftir die Bcrcchnung der frcicn und der unabh~ingigcn Puffcrzeit werden folgende Formeln angcgcbcn [Behnke, 1970; Brandenberger und Konrad, 1969; H6her, 1969; Thumb, 1968; Wille, Gewald und Weber, 1966] FP(i,j) = FZ(j) FEZ(i,j) UP(i,j) -max [0; FZ(j) SZ(i) D(i,j)]. In dem einfachen Beispiel in Abb. 1 ergibt sich nach diesen Formeln f'tir den Vorgang (4; 5) F P ( 4 ; 5 ) = 1 3 13 = 0 UP(4; 5) = max(0; 13 17 3 = 7 ) = 0	arm architecture;eine and zwei	Jochen Schwarze	1973	Zeitschr. für OR	10.1007/BF01956728	discrete mathematics;calculus;mathematics	ML	-96.93881004729242	35.04906411598102	77924
88f88ff7b13dcd7da122e625a025c62931e29a2b	sicherer zugriff auf patientendaten		Im Hospital greifen über ein und den-selben Computer sowohl Ärzte als auch das Pflegepersonal auf sensible Daten zu. Beabsichtigte oder unbeabsichtigte Veränderungen an Daten und Informationen —etwa zur Medikation-können hier unter Umständen fatale Folgen haben. Zudem dürfen vertrauliche Daten nur von exakt definierten Personen zugreifbar sein.		Gunnar Siebert	2006	Datenschutz und Datensicherheit - DuD	10.1007/s02045-006-0046-1	internet privacy;computer science	Theory	-104.22049602188837	36.51852252879388	78757
f1a4347ecddc3c3ff009f216eb2f1d58ade2e96a	agile methoden in der praxis — studie zur anwendung und zufriedenheit		Agile Methoden werden von ihren Anwendern äußerst positiv bewertet. Dies zeigt eine Studie des Business-Process-Management- (BPM- )Labors der Hochschule Koblenz mit 350 Teilnehmern. Die Anwender agiler Methoden bewerten dabei die von ihnen genutzten Praktiken in allen Kriterien besser als die Anwender klassischer Projektmanagementmethoden. Besonders ausgeprägt ist die Zufriedenheit bei Anwendern der Scrum-Methodik. Die Anwendung agiler Methoden hat 2008 einen starken Aufschwung genommen. Besonders beliebte agile Methoden sind Scrum und Kanban. Auffallend ist, dass die Mehrheit der Studienteilnehmer agile Methoden nicht in Reinform, sondern in hybrider oder selektiver Form anwendet.	agile software development;altran praxis;eine and zwei;scrum (software development)	Ayelt Komus	2013	HMD Praxis der Wirtschaftsinformatik	10.1007/BF03340799	praxis;knowledge management;software engineering;agile software development;engineering	NLP	-101.12437792586542	33.13288785421884	78916
b6f3a35961d7eff1d930cceddb4abfe886973f45	der it-standort russland - bedeutung und entwicklung des it-outsourcing und die beziehung zu deutschland	it outsourcing	Über die Entwicklungen und die Verflechtungen des russischen und des deutschen IT-Marktes existieren bisher nur wenige Informationen. Ziel des vorliegenden Beitrags ist es, aktuelle Daten zum IT-Outsourcing-Markt und die Beziehung der beiden Länder in diesem Bereich darzustellen. Dabei wird auf die Eckwerte des russischen Marktes für IT-Outsourcing eingegangen, aber auch die Rolle des Exports für den Markt sowie die Motive für das Outsourcing in Russland und Deutschland werden dargestellt. 1 Einführung und Zielsetzung Das IT-Outsourcing wird seit Ende der 80er Jahre vor allem in den Industrieländern intensiv diskutiert. Inzwischen werden sogar ganze Geschäftsprozesse amerikanischer und westeuropäischer Unternehmen an spezialisierte Dienstleister übergegeben. Außerdem werden viele IT-Aktivitäten in Billiglohnländer ausgelagert. In Russland gewinnt das Thema erst seit einigen Jahren an Aktualität. Der russische IT-Ousourcing-Markt befindet sich noch in der Anfangsphase. Die Wachstumsraten des IT-Markts in Russland und des IT-Outsourcing-Marks als eines seiner Segmente im Besonderen sind allerdings viel versprechend. In Anbetracht der Attraktivität des russischen Marktes und seines Wachstumspotentials sind deutsche IT-Unternehmen schon seit Anfang der 90er Jahre mit Niederlassungen präsent und bieten eine breite Palette von IT-Dienstleistungen an. Von besonderem Interesse sind hier die zunehmenden Verflechtungen zwischen russischen und deutschen Unternehmen. Allerdings ist bisher wenig Information darüber verfügbar, zumal Untersuchungen dieses Marktsegments noch nicht existieren bzw. kaum Daten dazu bekannt sind. Hier liegt die Zielsetzung des vorliegenden Beitrags, in dem aktuelle Daten auf der Grundlage öffentlich zugänglicher Marktstudien präsentiert werden, welche im westlichen Europa aber kaum bekannt oder wegen der Sprachbarriere nicht zugänglich sind. Außerdem werden die Beziehung zwischen Deutschland und Russland in diesem Segment analysiert und zusammenfassend offene Forschungsfragen abgeleitet.	eine and zwei;europa;institut für dokumentologie und editorik;outsourcing;palette (computing);triple des;vhf omnidirectional range	Franz Lehner;V. Aleev	2008			baffle;systems engineering;casing;petroleum engineering;combustion chamber;computer science;combustion;flue	Crypto	-103.42345751193048	35.02268795252686	79134
c19766ac6038c0c454919473a8bbef18916e0134	europäische datenschutzreform: bfdi begrüßt änderungsvorschläge aus dem europäischen parlament		9. Sicherheit von Informationssystemen; und 10. Netzwerksicherheit. Das Einführen einer minimalen Reihe von Sicherheitsmaßnahmen erfordert den Konsens und die Kooperation von verschiedenen Interessenvertretern der Smart Grids. Eine Koordinationsinitiative könnte ermöglichen, dass eine einheitliche und allgemein akzeptierte Herangehensweise bei Sicherheitsvorfällen in Smart Grids gewährleistet wird. Darüber hinaus würde eine einheitliche Herangehensweise zum Thema Internetsicherheit sowohl den Regulatoren als auch Interessenvertretern zugutekommen, indem sie die komplexe Umgebung von Smart Grids in Einklang bringt und einen Anreiz bietet, die Internetsicherheit zu verbessern. Dieser Bericht kann die EU unterstützen durch: das Angleichen der unterschiedlichen Level an Sicherheit und Stabilität der Anbieter auf dem Markt an ein konsistentes Mindestmaß nationaler Rahmenbedingungen; das Bereitstellen von Anzeichen eines Mindestmaßes an Sicherheit und Stabilität in den Mitgliedsstaaten in Bezug auf die Smart Grids; das Sicherstellen eines Mindestmaßes an Anforderungen an Smart Grids in den Mitgliedsstaaten, wodurch die Einhaltungsund Betriebskosten reduziert werden; das Legen eines Grundsteins für ein Mindestmaß an Rahmenbedingungen überprüfbarer Kontrolle in Europa; das Generieren von Bereitschaft, Wiederherstellbarkeit, Rücklaufmaßnahmen und gegenseitiger Hilfe der Betreiber während einer Krise; das Beitragen, um ein angemessenes Level an Transparenz im internen Markt zu erreichen. Der Geschäftsführende Direktor der ENISA, Professor Udo Helmbrecht, sagt; “Um die ehrgeizigen EU2020 Ziele zu erreichen: 20% erneuerbare Energie, eine Reduktion von CO2 Emissionen um 20% und eine Zunahme von Energieeffizienz um 20%, ist es wesentlich, dass das Bereitstellen von Smart Grids für verteilte Energieerzeugung in zukünftigen Stromnetzen auf sichere Art und Weise erfolgt. Beide innovativen technischen Lösungen sind notwendig, zusammen mit neuen regulierenden und ökonomischen Systemen der EU. Wir hoffen, Smart Grids in der bevorstehenden Internet-Sicherheitsstrategie der EU zu sehen.” Den vollständigen Bericht finden Sie hier: https://www.enisa. europa.eu/activities/Resilience-and-CIIP/critical-infrastructure-andservices/smart-grids-and-smart-metering/appropriate-security-measures-for-smart-grids/	eine and zwei;eddie (text editor);europa;sie (file format);udo of aachen;unified model	Peter Schaar	2013	Datenschutz und Datensicherheit - DuD	10.1007/s11623-013-0064-7		HPC	-103.70037848221455	34.04454294009227	79200
b337801f5ffa6645ec6a264297810c24cbf7a02f	der 'nietzsche-thesaurus' des nietzsche-online-portals	information retrieval;portal	The ‚Nietzsche-Thesaurus’ ist part of an Internet-Portal to the German philosopher Friedrich Nietzsche (under construction). By using the complex Index of a Citation Lexicon (print version) and combining it with the lexikal data and structure of the ‘Deutscher Wortschatz’ (Wehrle/Eggers, a kind of transformation of the Roget’s Thesaurus), a relational access system is developed. Concept and State of the Art are described. 1 Zielsetzung Die im vorliegenden Beitrag beschriebenen Arbeiten sind Teil des Vorhabens der Entwicklung eines sog. Online-Portals zu Friedrich Nietzsche. In einem früheren Beitrag (Zimmermann 2000) wurde dazu die Frage der Präsentation der Nietzsche-Texte diskutiert, ein weiterer Teilaspekt ist die Entwicklung eines Kommunikationssystems für Experten und interessierte Laien (Zimmermann 2003). 281 1 Der etwas provokante Titel „So sprach Zarathustra“ (statt „also“ ...) sollte bereits auf das (dort diskutierte) Problem und die Möglichkeiten der Umsetzung der originalen NietzscheSchreibweise in eine moderne Rechtschreibung verweisen. Harald H. Zimmermann Im vorliegenden Beitrag wird ein ‚Thesaurussystem’ zum Werk von Friedrich Nietzsche vorgestellt. Wesentliche Grundlage sind die Vorarbeiten, die Johann Prossliner in und mit seinem Zitatelexikon („Das Lexikon der Nietzsche-Zitate“, Ausgabe Dezember 2001, im Folgenden kurz ‚Zitatelexikon’) geleistet hat (Prossliner 2001). Eine zweite Grundlage ist der sog. Wehrle/Eggers, ein nach dem Muster des Roget-Thesaurus gestaltetes deutschsprachiges Wörterbuch nach Sachgruppen (Wehrle/Eggers 1961). Im Ergebnis soll ein Verfahren entstehen, das es erlaubt, mit Hilfe des Thesaurus-Systems online via Internet oder Intranet zumindest die Zitatstellen des Zitatelexikons in dessen elektronischer Variante zu recherchieren. 3 2 Verfahrensweise Es sind verschiedene Recherche-Zugänge vorgesehen • Zugang über die ‚Aufbaustruktur’ des Zitatelexikons, d.h. über die Gliederung (Kapitel / Unterkapitel ...) des Zitatelexikons • Zugang über das Registersystem des Zitatelexikons 2 Im vorliegenden Zusammenhang soll nicht die grundsätzliche Frage behandelt werden, was unter einem ‚Thesaurus’ oder – etwa im Sinne der KI-Forschung – unter einer Ontologie verstanden wird. Auf keinen Fall sind die entwickelten Beziehungen als Thesaurus im Sinne von DIN 1463 als hinreichend zu verstehen. Insbesondere ist auf eines hinzuweisen: Bereits die 2.453 ‚Zitate’ (Extrakte) sind das Resultat einer subjektiven Auswahl (hier des Autors Prossliner), Entsprechendes gilt für die Stichwörter des Registers. Gerade bei Nietzsche dürfte es schwer fallen, einen (wissenschaftlichen) Konsens über eine Textselektion und ein begriffliches Zugangssystem zu erreichen. Man muss sich also im vorliegenden Falle stets bewusst sein, dass beide Teilbereiche – auch wenn man dem Autor Prossliner das Bemühen um Objektivität unterstellen kann – Resultat individueller Überlegungen sind. Anders gesagt: Ganz im Sinne von Kunz / Rittel (Kunz/Rittel 1972) sind das Korpus und das Zugangssystem (sicherlich deutlicher, als dies etwa bei einem Thesaurus in naturwissenschaftlichen Bereichen der Fall wäre) Element von ‚jemandes Informationssystem’. 3 Nicht wesentlich anders verhält es sich mit der Einbindung des „Deutschen Wörterbuchs“ von Wehrle/Eggers. Dabei wird allerdings von der Vorstellung ausgegangen, dass sich das vom vorliegenden Anwendungsfall (Nietzsche) losgelöste System gerade bei einem an philosophisch-psychologischen Fragen orientierten Autor gut eignet. Dennoch muss dieser Teil zunächst als ein Experiment angesehen werden. Erst die Praxis wird zeigen, ob diese Überlegungen fruchten. 4 Damit kein Missverständnis entsteht: Ein Zugang über die Einzelwörter des Registers soll daneben möglich sein, das gleiche gilt für einen Zugang über die Textstichwörter. Damit wird der Thesaurus-Zugang zu einem Angebot unter mehreren.	altran praxis;binary prefix;eine and zwei;es evm;eddie (text editor);gesellschaft für informatik;intranet;lexicon;parity (physics);portals;processor register;roget's thesaurus;triple des;unified model	Harald Zimmermann	2004					-105.78420734799299	34.91698080802048	79243
8bd535919245360c7a06d8c87c8848b4a7ae177a	geschäftsprozessorientieres wissensmanagement - forschungsbedarf aus sicht des change managements		Seit der Jahrtausendwende sind verschiedene Methoden für das prozessorientierte Wissensmanagement entwickelt worden. Diese orientieren sich an Geschäftsprozessen in denen Wissen wertschöpfend eingesetzt wird, um bedarfsorientierte Wissensmanagement-Lösungen zu gestalten. Fokus der Ansätze ist die Analyse des Umgangs mit Wissen im Geschäftsprozess. In dieser Arb eit werden bestehende Konzepte zur Gestaltung und Implementierung von Wissensmanagement-Lösungen näher untersucht und im Hinblick auf d ie wissenschaftliche Diskussion zum Change Management eingeordnet. Abschließend wird der Forschungsbedarf aufgezeigt und zentrale Forschungsfragen abgeleitet.	die (integrated circuit);intentionally blank page;unified model	Martin Alexander Ogaza;Peter Heisig	2011				SE	-103.96133448177318	32.50569708864128	79361
46f76e2c4e6599d7a3e7dbf299a8697cd0b71bac	untersuchungen kontextfreier stochastischer sprachen				Hans Werner Pohl	1975	Elektronische Informationsverarbeitung und Kybernetik		combinatorics;pure mathematics;mathematics	NLP	-95.43035257758652	34.29073903887316	79468
302960c77a9560fbfd066b22ca8061724da7bf33	steuerbare vierschicht-halbleiter und ihre verwendung als binärspeicher		Ein Halbleiterkristall — meist Germanium oder Silizium — mit vier abwechselnd pund n-dotierten Zonen (p-Emitter a, η-Basis g, p-Basis b, η-Emit ter c)) bildet einen Vierschicht-Halbleiter. Sind beide Randzonen mit Anschlüssen versehen, bezeichnet man das Element als Vierschichtdiode, Kippdiode oder Dynistor (Bild 1, 2) [1—7, 22—26], Die Kennlinie einer Vierschichtdiode setzt sich für Uac ^ 0 aus je einem Sperrbereich s(s'), einem negativen Bereich	die (integrated circuit);eddie (text editor);thyristor	Reinald Greiller	1965	Elektronische Rechenanlagen	10.1524/itit.1965.7.16.293	embedded system;computer science	AI	-104.97540806457319	33.41437549903312	79511
44562ec390557b84d987a0ca6508d6ba5e1bd4db	cowboy und prinzessin seit adam und eva	kinder;unterhaltung;selective exposure;media violence;mediengewalt;children;entertainment;medienselektion;geschlechterstereotype;gender stereotypes	Zusammenfassung. Um die Praferenzen bei Unterhaltungsangeboten untersuchen zu konnen, wurden vier- bis sechsjahrigen Vorschulkindern Videocover als Abbildungen zur konkreten Auswahl vorgelegt. Diese Abbildungen wurden in zwei Feldstudien in Kindergarten systematisch variiert, so dass die Kinder entweder zwischen einem aggressiven und einem friedvollen Thema oder aber einer mannlichen und einer weiblichen Hauptfigur aussuchen konnten. So konnte der Einfluss von Geschlecht und Altersstufe auf die Praferenz gewalthaltiger Inhalte beziehungsweise gleichgeschlechtlicher Medienfiguren analysiert werden. Jungen bevorzugten im Vergleich zu den Madchen deutlich die aggressiven Inhalte und zeigten uberdies ein hoheres Mas geschlechtsstereotyper Praferenzen. Madchen und Jungen favorisierten - gleichermasen - Medienfiguren des eigenen Geschlechts. Das Alter der Kinder hatte keinen Einfluss auf die Unterhaltungsselektion.		Silvia Knobloch-Westerwick;Annett Fritzsche	2004	Zeitschrift für Medienpsychologie	10.1026/1617-6383.16.2.68	entertainment;advertising	Crypto	-107.94983906224319	33.35984752067904	79755
b641f42c73a131c3b9177e4e564822e6476c691f	openreskit - herausforderungen und aktuelle entwicklungstendenzen bei der software-technischen unterstützung von ressourcen- und energieeffizienzfragestellungen auf der basis einer client-/server-architektur		Das Projekt OpenResKit beschäftigt sich mit der Erstellung von Open-Source-basierenden Softwarewerkzeugen zur Unterstützung von innerbetrieblichen Ressourcenund Energieeffizienzfragestellungen. Dabei werden vornehmlich kleine und mittlere Unternehmen (KMU) fokussiert, welche auf Grund ihrer Anzahl ein erhöhtes Potential zur Steigerung eben dieser Fragestellungen bieten (VDI Zentrum Ressourceneffizienz GmbH, 2011, S. 4). Der hier beschriebene Beitrag soll die Vision des Projektes, den Stand der aktuellen Methodenauswahl und deren softwaretechnischen Umsetzungsmöglichkeiten aufzeigen. Spezieller soll die umgesetzte Softwarearchitektur des Forschungsprojekts OpenResKit erläutert werden. 1. Motivation und Zielstellung Kleine und mittlere Unternehmen (im Folgenden KMU) bieten aufgrund ihrer Anzahl insgesamt ein riesiges Potential zur Steigerung der Ressourceneffizienz in Deutschland (vgl. VDI Zentrum Ressourceneffizienz GmbH, 2011, S. 4). Es ist häufig dabei erforderlich, jedes Unternehmen individuell zu analysieren und daraus unternehmensspezifische Maßnahmen zur Effizienzsteigerung abzuleiten. Durch den entstehenden Aufwand scheiterten bisherige Anstrengungen, Ressourceneffizienzfragestellungen in KMU nachhaltig zu verankern, da bisher nur allgemeine Leitfäden als Hilfestellung gegeben wurden und der individuelle Beratungsaufwand als zu hoch eingeschätzt wird (vgl. VDI Zentrum Ressourceneffizienz GmbH, 2011, S. 22). Es besteht die Notwendigkeit, methodisches Wissen im Unternehmen aufzubauen, um einen kontinuierlichen Verbesserungsprozess in bestehende Geschäftsprozesse zu integrieren, da der Ressourceneffizienz im Allgemeinem ein hoher Stellenwert zugemessen wird (vgl. Erhardt & Pastewski, 2010, S. 15). Um der finanziellen und personellen Situation in KMU gerecht zu werden, ist es ferner erforderlich, die Einstiegshürden zur Betrachtung von Ressourceneffizienzfragestellungen möglichst gering zu halten. Diese Hürden sind nach Bullinger & Beucker (vgl. Bullinger & Beucker, 2000): • Hohe Investitionskosten, • großer zeitlicher Aufwand zum Einstieg in die Thematik und ein • großer Datenbedarf bzw. Aufwand der Datenerhebung oder -aufbereitung. Durch die Erfahrung mit unterschiedlichen Praxispartnern, stellen die Autoren fest, dass es auch heute noch keine Seltenheit ist, dass umweltrelevante Informationen in KMU nur teilweise in digitaler Form vorliegen. KMU erfassen ihre Daten, insbesondere wenn Zählerstände bestimmter Stoffströme (Wasser, Gas, Energie, Druckluft etc.) verarbeitet werden müssen, mit Stift und Papier und digitalisieren diese im Anschluss zur weiteren Nutzung in Tabellenkalkulationsprogrammen (vgl. Demir, et al., 2008). Dieser in der Praxis auftretende Medienbruch stellt insbesondere für KMU ein Hemmnis zur Identifikation von 1 Alle Hochschule für Technik und Wirtschaft Berlin, Fachbereich II, Projekt OpenResKit, Wilhelminenhofstraße 75A, 12459	altran praxis;desktop virtualization;institut für dokumentologie und editorik;unified model	Peter Krehahn;Tobias Ziep;Lars Schiemann;Volker Wohlgemuth	2013			history;performance art	NLP	-105.40213359257365	33.03427747195928	79841
b3312a3265257052ca85193dc2b4d791fe0cccac	next generation outsourcing aus it-dienstleistersicht		Next Generation Outsourcing (NGO) ist eine neue Form des IT-Sourcings, die konsequent die Unterstützung der Geschäftsprozesse des Kunden in den Vordergrund stellt. IT-Dienstleister müssen auf diesen Trend reagieren und ihre IT-Architektur entsprechend neu ausrichten. Der Beitrag beschreibt anhand eines exemplarischen Fallbeispiels, wie dies in der Praxis aussehen kann, d. h., wie die Kriterien von NGO durch eine neue IT-Architektur erfüllt werden können.	altran praxis;eine and zwei;internet explorer;next-generation network;outsourcing	Holger von Jouanne-Diedrich;Jürgen Slaar;Simon Schmidt	2008	HMD Praxis der Wirtschaftsinformatik	10.1007/BF03341158	knowledge management;management;engineering;outsourcing	Security	-101.29084109311144	34.59033685496384	80036
4bfc3c756d868e8b25f50d4e385b7bf66a442862	sicherheit und effizienz in einer active-message-kommunikationsschicht	active messages	Active Messages haben sich als effizientes Kommunikationsverfahren insbesondere auf Kommunikationstechnologien durchgesetzt, die einen direkten Zugriff des Benutzers ohne Intervention des Betriebssystems zulassen. Als Nachteil der leichtgewichtigen Kommunikation erwiesen sich jedoch die nicht ausreichenden Schutzmechanismen, vor allem bei der Verwendung mehrerer Prozesse, die sich gleichzeitig einer Active-MessageBibliothek bedienen. Die Spezifikation 2.0 der Berkeley-Active-Messages unternimmt nun den Versuch, für das bekannte und schnelle Kommunikationsverfahren Schutzabstraktionen vorzusehen. Im Rahmen dieser Arbeit wird die Implementation eines solchen ActiveMessage-Layers der Version 2.0 auf einem Cluster von SCI-gekoppelten Arbeitsplatzrechnern beschrieben. Wir können zeigen, daß die zusätzlichen Schutzmechanismen nur wenig Einfluß auf die Leistung haben und somit der Vorteil der Active Messages, die leichtgewichtige, feingranulare Kommunikation, erhalten bleibt.	active message;die (integrated circuit);vhf omnidirectional range	Michael Eberl;Hermann Hellwagner;Wolfgang Karl;Markus Leberecht	1997			computer science	OS	-104.0980259895632	32.31837066934466	80160
e76ac98582d1e06d73a3a607ecfb13dfb0bf204b	vorlesungsaufzeichnung: vom experiment zum routinedienst		Wir skizzieren, wie sich das digitale Aufzeichnen von Vorlesungen von ersten Experimenten vor mehr als 20 Jahren bis heute zu einem Routinedienst an vielen Hochschulen entwickelt hat. Wir erläutern die verschiedenen technischen Möglichkeiten zur digitalen Aufzeichnung und schildern die Konsequenzen für die Wiederverwendbarkeit der multimedialen Dokumente, die sich daraus ergeben. Um Aufzeichnungen sinnvoll und nachhaltig nutzen zu können, benötigt man geeignete Techniken zur Archivierung und Suche sowie Systeme, die die aktive Auseinandersetzung von Lernern mit Aufzeichnungen unterstützen. Wir erläutern als Beispiele einen auf die Spezifika von Aufzeichnungen zugeschnittenen Empfehlungsdienst und ein ELectures Wiki. Dabei spielt insbesondere die geeignete Auswertung der gesammelten Nutzerdaten eine wichtige Rolle.	eine and zwei;internet explorer;unified model;vhf omnidirectional range;wiki	Thomas Ottmann	2012				NLP	-105.92824059697952	34.3562778312906	80260
0d25b185a90506a9bedf85eff6ce4d2c3f6d9fde	ablösung von legacy-systemen in zeiten des digitalen wandels		Betriebliche IT-Kernsysteme, die Unternehmen zur Unterstützung von Geschäftsprozessen einsetzen, zählen zu den langlebigen und komplexeren Systemen in der IT-Branche. Ihre Entwicklung ist zeitund kostenintensiv. Aber auch solche Systeme werden früher oder später abgelöst: Aussterbende Technologien, angestrebte digitale Transformation, Unternehmensfusionen oder das Herauslösen von Geschäftseinheiten sind die häufigsten Gründe dafür. Hierbei lassen sich unterschiedliche Strategien und Methoden verfolgen. Der folgende Artikel gibt eine Übersicht.	eine and zwei;système universitaire de documentation;zentralblatt math	Andreas Martens	2016	Wirtschaftsinformatik & Management	10.1007/s35764-016-0122-7		Vision	-103.26809910108706	32.67912043254997	80283
d2ea1bed716e0302d628c99806739f4b18451f57	projekterfahrungen spielend einfach mit der projectworld! – ein gamifiziertes projektwissensmanagementsystem		Wissensmanagement ist eine komplexe Aufgabe, welche oftmals von existierenden Wissensmanagementsystemen nur unzureichend unterstützt wird. Insbesondere in Projekten, in welchen Projektmitarbeiter meist einen heterogenen Hintergrund haben und nur für eine begrenzte Zeit zusammenarbeiten, ist das Wissensmanagement eine große Herausforderung. Projektwissen wird nur selten dokumentiert und noch seltener wiederverwendet, da die Projektmitglieder keine Zeit und wenig Motivation für dessen Dokumentation haben. Als Konsequenz daraus werden oftmals bereits bekannte Lösungen gefunden und Projektteams machen die gleichen Fehler wie ihre Vorgänger. Gamification stellt eine Lösung für dieses Problem dar, da es darauf abzielt, die aktive Teilnahme in Anwendungssystemen zu motivieren. Der vorliegende Beitrag beschreibt die Gestaltung und Umsetzung eines gamifizierten Projektwissensmanagementsystems, genannt ProjectWorld, in einem Unternehmen. Die ProjectWorld zielt darauf ab, Mitarbeiter zu motivieren, sich dauerhaft am Wissensmanagement zu beteiligen und ihr Wissen mit anderen Mitarbeitern zu teilen. Obwohl noch keine konkreten, empirisch fundierten Ergebnisse bezüglich langfristiger Effekte auf die Wissensdokumentation und –wiederverwendung vorliegen, kann man, basierend auf qualitative Aussagen der potentiellen Nutzer, positive Auswirkungen auf das Projektwissensmanagement im Unternehmen annehmen. Knowledge management is a complex endeavor which is often insufficiently supported by existing knowledge management systems. In particular, projects suffer from challenges of project knowledge management, since its team members are highly heterogeneous with regard to their background and work together for only a limited duration. Thus, project knowledge is rarely documented and even more rarely reused due to a lack of time and low motivation of team members. As a consequence, project teams are finding already known solutions or make the same mistakes like previous projects. Gamification is a new trend which promises to solve these issues, since it aims to motivate system users to engage in application systems. This article describes the design and realization of a gamified project knowledge management system named ProjectWorld in a company. ProjectWorld aims to motivate employees to engage in knowledge management and to share their knowledge within the organization. Although, at an early stage with no empirical results regarding the effects of the gamified system on knowledge documentation and reuse, it can be assumed—based on qualitative statements of potential users—that ProjectWorld will have positive impacts on the project knowledge management of the company.	antilymphocyte serum;assumed;coagulum lysis:prthr:pt:ppp:ord:coag;consult between primary care providers;die (integrated circuit);document completion status - documented;documentation;dopamine;eine and zwei;endometrial intraepithelial neoplasia;feeling/behaving old/senile;gamification;genetic heterogeneity;internet explorer;knowledge management;kristallviolett-lösung;limited stage (cancer stage);name;nuclear receptor subfamily 4, group a, member 2;reuse (action);tricyclic antidepressants tested for:prid:pt:ur:nar:screen;van der woude syndrome;teams	Silvia Schacht;Anton Reindl;Stefan Morana;Alexander Maedche	2015	HMD Praxis der Wirtschaftsinformatik	10.1365/s40702-015-0176-7		AI	-100.28553089321595	34.120380009924176	80380
bcb575a96c327585b0fa2fe425b9884d44d155c2	kontextsensitive dialogmodellierung		Die Anpassung von graphischen Benutzungsschnittstellen wird in vielen Anwendungsszenarien benötigt. Anwenderinnen möchten beispielsweise die Oberfläche personalisieren oder diese auf den Kontext des Einsatzes reagieren lassen. Wenn es gelingt die Anpassung zu modellieren, die entweder von Menschen definiert werden kann oder von der Maschine automatisch erlernt werden kann, dann kann das Software Engineering von Benutzungsschnittstellen verkürzt werden. Einerseits entsteht durch die Modellierung Mehraufwand. Andererseits verringert sich der Implementierungsaufwand durch modellgesteuerte, wiederverwertbare Komponenten oder durch Modell-zu-Quellcode-Transformationen. Der Beitrag fokussiert auf die gleichzeitige Modellierung anpassbarer Strukturen, Eigenschaften und Verhalten von Benutzungsschnittstellen. Der Beitrag stellt ein technologieunabhängiges, kontextsensitives Dialogmodell vor. Das Dialogmodell wurde zur Modellierung eines Web Portals verwendet.	maschine;portals;software engineering;v-model;vhf omnidirectional range	Jürgen Rückert;Barbara Paech	2009				SE	-102.42609367312527	32.90895890832634	80429
3d52c25b4e634c23922b51d35248d2f5a0753b3b	real world xml/xslt im web: ein framework zur verteilung der rollen zwischen redaktion, datenbanken und modularer funktionalität	der rollen zwischen redaktion;xslt im web;real world xml;ein framework zur verteilung	Die Einfachheit des XML Standards offenbart der Welt den universellen Anspruch dieses Formates. Die Vorstellung, das mit XML jede Informationseinheit unmittelbar einen semantischen berbau erhalte, suggerierte zudem die universelle Anwendbarkeit von XML. Der anfangliche XML-Hype unterschatzte, das jedes XML-Projekt Themen adressieren mus, die XML als solches nicht abdeckt, z.B.: rnrn1rnrnXML besitzt keine eingebaute Dynamikrnrnrnrnrn2rnrnXML ist fur den Otto-Normalanwender schwer zu editierenrnrnrnrnrn3rnrnXML ist (noch) nicht in die universell verfugbare Web-Infrastruktur integriertrnrnrnrnrn4rnrnXML stellt spezifische Anforderungen an die Abwicklung der Daten-Persistenzrnrnrnrnrn5rnrnXSLT bietet ein neues Paradigma und neue Details, bindet aber Entwicklerressourcenrnrnrnrnrn6rnrnDie Kommunikation mit Legacy-Anwendungen per XML erfordert zusatzliche Integration auf allen Ebenen		Henning Hinrichs	2001		10.1007/978-3-642-56687-5_39	world wide web;xml;xslt;computer science	NLP	-102.56065500896676	34.818762651511676	80828
fa684e56317983fb6c379f29de8f61b4e22d3087	modernisierung des datenschutzrechts		Zusammenfassung  Das Datenschutzrecht steht vor einer Generalberholung: Der Deutsche Bundestag hat am 29. Mrz 2007 mit Stimmen aller Fraktionen  eine Entschlieung verabschiedet, in der ein modernes Datenschutzrecht gefordert wird.  		Alexander Roßnagel;Andreas Pfitzmann;Hans-Jürgen Garstka	2001	Datenschutz und Datensicherheit		internet privacy;computer security;computer science	Crypto	-103.43219519742448	36.32208263017057	80983
388c782e783fb363c44c041ceaf7155da710754d	vorratsdatenspeicherung: wer spricht recht?		Das Bundesverfassungsgericht hat zur Verfassungsmäßigkeit der Vorratsdatenspeicherung noch nicht in der Hauptsache entschieden. Offen ist wegen der nationalen Verpflichtung zur Umsetzung der Europäischen Richtlinie zur Vorratsdatenspeicherung die Frage, ob und inwieweit eine Zuständigkeit des Europäischen Gerichtshofes begründet ist. Darüber hinaus untersucht der Beitrag auch die Zuständigkeit des Europäischen Gerichtshofes für Menschenrechte.	eine and zwei	Thomas Kahler	2008	Datenschutz und Datensicherheit - DuD	10.1007/s11623-008-0107-7	internet privacy;library science;computer science	Crypto	-103.74137562810525	36.21035802247689	80985
9bdba6a52835b3cf3794b7cd0090805cc76ffa55	fördern realitätsbasierte uis kollaborative rechercheaktivitäten?		Soziale Aktivitäten sind während eines Rechercheprozesses von essentieller Bedeutung, werden jedoch bisher in aktuellen digitalen Recherchesystemen nur unzureichend berücksichtigt. Social, Tangible und Surface Computing bieten erste Ansätze zur Lösung des Problems. Darauf aufbauend stellt dieser Beitrag drei verschiedene Benutzerschnittstellen für die Aktivität des gemeinsamen Filterns und Explorierens vor. Dabei wurden die Benutzerschnittstellen bewusst mit unterschiedlichen Interaktionstechniken umgesetzt, von sehr realitätsbasiert über rein virtuell bis hin zu einem eher klassischen Ansatz. Weiterhin werden Ergebnisse einer Evaluationsstudie vorgestellt, in der insbesondere die Auswirkungen der verschiedenen Ansätze auf das kollaborative Arbeiten untersucht wurden.	surface computing;vhf omnidirectional range	Mathias Heilig;Mischa Demarmels;Katrin Allmendinger;Jens Gerken;Harald Reiterer	2010				NLP	-105.4102749799707	32.93001158935621	81156
dc2dcd847ba8d4d2c7501ef03763b8be3d5d2a15	on the impact of memory corruption vulnerabilities in client applications		Diese Dissertation beschaftigt sich mit der Auswirkung von Speicherfehlern in clientseitigen Anwendungen - speziell Webbrowsern.rnrnDer Ausnutzungsprozess von Speicherfehlern kann in verschiedene, aufeinanderfolgende Schritte unterteilt werden.rnrnAls einen der ersten wichtigen Schritte benotigt der Angreifer Informationen uber den Adressraum des verwundbaren Programms.rnrnSobald der Angreifer genugend Wissen uber den Adressraum des Programms gesammelt hat, kann der nachste Schritt erfolgen. Dabei ist der Angreifer in der Lage, den Kontrollfluss des Programms zu ubernehmen und Code seiner Wahl ausfuhren.rnrnDiese Schritte des Ausnutzungsvorgangs werden unter offensiven und defensiven Gesichtspunkten beleuchtet.rnrnEinerseits werden softwareseitige Sicherheitsmasnahmen - die versuchen entsprechende Schritte zu unterbinden - untersucht, andererseits werden weitere Sicherheitsmasnahmen vorgeschlagen, welche die Ausnutzung von Speicherfehlern fur Angreifer erschweren.	memory corruption	Robert Gawlik	2016			world wide web;sociology	OS	-103.40932684119397	36.42213063409606	82158
11bbf8d10061c655ee8d9dbaf5aeaaded4c6ee98	die andere mondseite		in den Vorstellungen seiner frühen Befürworter sollte der Datenschutz einem wachsenden Übel, der so genannten „Verdatung“ der Gesellschaft, begegnen; ähnlich wie etwa ein Medikament einer Krankheit begegnen soll. Führt man den Vergleich weiter, stellt sich die Frage, ob der Datenschutz wie ein Medikament auch Nebenwirkungen zeigt. Im Pharmabereich müssen die Nebenwirkungen deklariert werden; nicht so hier. Aber es gibt sie doch. Der Gesetzgeber war bemüht, sie zu bedenken und zu berücksichtigen. Dabei hat er vor allem an den Staat gedacht. Ein konsequenter Datenschutz würde auch der Polizei und den Sicherheitsbehörden die Einsicht in die Daten der Bürger verbieten und damit die allgemeine Sicherheit gefährden. Also wurden solche Belange von den Bestimmungen des Gesetzes weitgehend ausgenommen. Wie detailliert das gelten sollte, konnte der Gesetzgeber wegen der schnellen Entwicklung nicht ausloten. Die Regelung blieb unbestimmt. Die zu erwartenden Konflikte sind nicht ausgeblieben. Kern dieser Konflikte ist die Kryptologie. Sie wird zur Datensicherung gebraucht. An ihr ist nicht vorbeizukommen. Anderenfalls wäre der Gesetzgeber in Erklärungsnot, warum er einem Grundrecht die wirksamste Sicherung verweigerte. Ein Dilemma für den Gesetzgeber, denn die Kryptologie war damals noch Geheimwissenschaft im staatlichen Gebrauch. Sie diente der Sicherung zumeist militärischer Geheimnisse. Damit hatte sie den Wert einer Waffe, und Waffen möchte ein Gesetzgeber nicht jedermann an die Hand geben. An dieser Stelle eine Anekdote: Ich hatte 1982 vom DIN Normenausschuss für Informationsverarbeitung den Auftrag, festzustellen, ob in der privaten Wirtschaft Bedarf für Kryptologie vorliege. Dazu waren dem zu Befragenden zunächst die Qualitäten der Kryptologie zu erklären. Der so vermittelte Stoff und die Umfrageergebnisse wurden als DuD-Fachbeitrag1 veröffentlicht. Man bemühte sich um Rezensenten für das Buch. Darunter war ein Mathematikprofessor, der einem Nachrichtendienst nahe stand. Er blätterte das Buch durch, geriet zunehmend in Zorn und sagte schließlich: Nein, nicht rezensieren, nicht veröffentlichen und schon gar nicht standardisieren, wieder einsammeln und die gesamte Ausgabe restlos einstampfen! Das mag die damalige Debatte um die Kryptologie kennzeichnen. Wer Kryptologie besaß, hatte Macht, und wer Macht hatte, enthielt sie anderen vor. Nun aber war die Kryptologie zu einer Geheimwissenschaft geraten, die sich nicht mehr geheim halten ließ. Der Gesetzgeber machte zwar für die Sicherheitsbehörden die erwähnten Ausnahmen. Das nützte denen aber nichts, wenn die aufgegriffenen Daten verschlüsselt waren. So geriet der Datenschutz in Konflikt mit den Ordnungsfunktionen des Staates. Darüber hinaus gab es auch Nebenwirkungen im weltumspannenden hermetischen Bereich der Geheimdienste und löste dort Reaktionen aus: vielerlei Unternehmungen ihrer Adepten, die Datenverarbeitung von der Kryp to logie abzubringen. Dazu brachte diese Zeitschrift kürzlich einen Aufsatz2, der eine Reihe internationaler Bemühungen aufzeigt, die Kryptologie gegen Fernmeldegeheimnis und Datenschutz vom Markt zu verdrängen. Man kann es, wie gezeigt, von der kausalen Abfolge her auch anders herum sehen: der Datenschutz beschädigt in Form seiner Nebenwirkung die Interessen der Sicherheitsbehörden; das hat die im Aufsatz beschriebenen Rückwirkungen zur Folge. Die ursächliche Nebenwirkung selbst tritt aber im hermetischen Bereich auf; ist also der Öffentlichkeit entrückt. Gleichwohl, liebe Leserinnen und Leser, ist sie vorhanden und erschwert es unserem Staat, für seine spezielle und die Sicherheit seiner Bürger zu sorgen. Es wäre deshalb interessant, wenn trotz aller Hermetik auch darüber berichtet würde, wie – gewissermaßen – die andere Seite des Mondes aussieht.	7 days to die;die (integrated circuit);eine and zwei;gab;i/o controller hub;internet explorer;mag (cryptography);max august zorn;sie (file format);unified model;vhf omnidirectional range;word error rate	Karl Rihaczek	2012	Datenschutz und Datensicherheit - DuD	10.1007/s11623-012-0235-y	computer security;computer science;internet privacy	OS	-104.7536256214127	35.964407887773085	82182
5c81e703d76c57d493b571203acecd2ece46ccab	embedded brain reading	formalization;lateralized readiness potential;physiological computing;robotic;target recognition;lrp;human machine interfaces;prospective memory;bereitschaftspotential;brain computer interfaces;electromyogram;electroencephalogram;human machine interaction;movement planning;brain reading	"""Current autonomous robots and interfaces are far from exhibiting the adaptability of biological beings regarding changes in their environment or during interaction. They are not always able to provide humans the best and a situation-specific support. Giving the robot or its interface insight into the human mind can open up new possibilities for the integration of human cognitive resources into robots and interfaces, i.e., into their intelligent control systems, and can particularly improve humanmachine interaction. In this thesis embedded Brain Reading (eBR) is developed. It empowers a human-machine interface (HMI), which can be a robotic system, to infer the human’s intention and hence her/his upcoming interaction behavior based on the context of the interaction and the human’s brain state. To enable eBR, an automatic context recognition or generation as well as online, single-trial brain signal decoding, i.e., Brain Reading (BR) for the detection of specific brain states, are required. The human’s electroencephalogram (EEG) recorded from the head’s surface is used in this work as a measure of brain activity. Experiments are conducted in controlled experimental setups, where subjects have to execute differently complex and demanding simple and dual-task behavior as it is performed during human-machine interaction. Using these experiments the applicability and reliability of BR is confirmed as well as training procedures for BR are improved. Furthermore, a formal model for eBR is developed and shown to be applicable for different implementations of eBR. The formal model is the first step to check implementations of eBR for their correctness and completeness. By means of robotic applications for tele-manipulation and rehabilitation it is further shown that eBR can be applied to either adapt or to drive HMIs, i.e., can be used to implement predictive HMIs for passive or active support. In case that eBR is applied for passive support, it is shown that malfunction of the whole system can be avoided. On the other hand, in case that eBR is applied for active support, i.e., to actively drive an HMI, it is shown that an individual adaptation of the support with respect to the requirements of different users can be facilitated by utilizing multi-modal signal analysis in eBR. Finally, it is shown that even in case of passive support eBR can measurably improve human-machine interaction. Zusammenfassung Autonome Roboter und Mensch-Maschine Schnittstellen sind heutzutage noch nicht so adaptiv und flexibel im Bezug auf Veränderungen in ihrer Umgebung oder sich ändernden Anforderungen ihres Interaktionspartners, wie es biologische Systeme sind. Aus diesem Grund erfüllen solche technischen Systeme nur eingeschränkt die Anforderung, Menschen situationsspezifisch und entsprechend wechselnden Gegebenheiten optimal zu unterstützen. Um dies zu ändern, ist es notwendig, dass robotische Systeme und ihre Schnittstellen Einsicht in die Gedankenwelt des Menschen erhalten. Dies ermöglicht es dem technischen System, menschliche kognitive Ressourcen zur Optimierung ihrer intelligenten Kontrolle und somit zur Optimierung der Interaktion zwischen Mensch und Maschine zu nutzen. In dieser Arbeit wird embedded Brain Reading (eBR) entwickelt. Es befähigt eine Mensch-Maschine Schnittstelle, die ein robotisches System sein kann, Annahmen über die Absichten des interagierenden Menschen aufzustellen und damit zukünftiges Verhalten im Kontext der Interaktion und basierend auf dem ermittelten Zustand des Gehirns vorherzusagen. Dementsprechend wird für die Realisierung von eBR eine automatische Erkennung des Kontextes der Interaktion als auch eine """"online"""" fähige Entschlüsselung von Gehirnaktivität im sogenannten """"single-trial"""" Verfahren, also die Erkennung spezifischer Gehirnzustände mittels Brain Reading (BR), benötigt. Das menschliche, von der Kopfoberfläche gemessene Elektroenzephalogramm (EEG) wird in dieser Arbeit als Methode zur Messung der Gehirnaktivität genutzt. Experimente, in denen Probanden unterschiedlich komplexe und anspruchsvolle Verhalten, so wie sie auch bei der Interaktion zwischen Mensch und Maschine auftreten würden, ausführen müssen, werden in kontrollierten Versuchsumgebungen durchgeführt. Anhand dieser Experimente werden die Zuverlässigkeit von BR gezeigt und Trainingsverfahren für BR verbessert. Des weiteren wird in dieser Arbeit ein formales Model für eBR entwickelt. Für dieses wird gezeigt, dass es für verschiedene Implementierungen von eBR anwendbar ist. Das formale Modell erlaubt Implementierungen von eBR zu verbessern und auf ihre Korrektheit und Vollständigkeit zu überprüfen. Basierend auf Anwendungen aus der Robotik, genauer auf Basis von Telemanipulationsund Rehabilitationsanwendungen, wird außerdem gezeigt, dass eBR genutzt werden kann, um Mensch-Maschine Schnittstellen entweder in ihrer Funktionalität anzupassen, also auf die Anforderungen des Menschen zu optimieren und passiv zu unterstützen oder um die Schnittstelle selbst aktiv zu steuern. Die durch eBR adaptierte oder gesteuerte Schnittstellen werden predictive HMIs genannt. Für den Fall, dass sie für die passive Unterstützung eingesetzt werden, wird gezeigt, dass Fehlfunktionen des Gesamtsystems, welche durch Fehlinterpretationen der Gehirnaktivität potentiell möglich sind, vermieden werden können. Andererseits wird gezeigt, dass der Einsatz von eBR für die aktive Kontrolle von solchen predictive HMIs eine individuelle Anpassung dieser an die Anforderungen des Nutzers oder der Situation, wie z.B. dem Stand der Therapie, ermöglicht. Schlussendlich wird mittels eines Experimentes gezeigt, dass auch für den Fall, dass eBR für die passive Unterstützung eingesetzt wird, die Interaktion zwischen Mensch und Maschine messbar verbessert wird."""	autonomous robot;brain-reading;control system;correctness (computer science);die (integrated circuit);eine and zwei;electroencephalography;embedded system;experiment;human–computer interaction;intelligent control;internet explorer;maschine;mathematical model;mind;modal logic;requirement;sie (file format);signal processing;television;triple des;unified model;user interface;v-model;zentralblatt math	Elsa Andrea Kirchner	2014			psychology;developmental psychology;artificial intelligence;communication;lateralized readiness potential	Robotics	-108.56853398517772	32.78868130900828	82424
828f784c71ae8f9548fbab7bdce3b9ebd271ccf0	perspektiven zur kombination von automatischem animationsdesign und planbasierter hilfe	kunstliche intelligenz;automatische programmierung;animationsverfahren	Aktuelle Themen auf dem Gebiet der intelligenten Benutzerschnittstellen behandeln derzeit die automatische Planung multimodaler Prasentationen. Hierbei stand bisher im wesentlichen die koordinierte Generierung von Text und Graphik im Vordergrund. In Zukunft wird hier aufgrund der Komplexitat der zu prasentierenden Information zunehmend auch die Einbeziehung realistischer animierter 3D-Graphiken gefordert sein. Einen anderen wichtigen Forschungsschwerpunkt bildet der Einsatz graphischer Ausgabekomponenten fur planbasierte Hilfesysteme. Die vorliegende Arbeit hat zum Ziel zunachst einen Uberblick uber den derzeitigen Stand der Forschung in diesen beiden Bereichen zu geben, als auch neue Anforderungen an die automatische Animationsgenerierung und an Systeme zur planbasierten graphischen Hilfe zu formulieren. Anschliesend wollen wir, basierend auf Ergebnissen und Erfahrungen aus WIP und PLUS, Perspektiven fur eine mogliche Weiterentwicklung und Integration von Techniken der Animationsplanung und graphischen Hilfe prasentieren.		Winfried Graf;Markus A. Thies	1992	KI			Vision	-104.83386111146125	32.395715789395645	82460
34dc069f3debc53adc73a28b86f22200dd6154fa	neue wege zum kunden - innovationen in der kunde-bank-interaktion	selected works;bepress selected works;information management;bepress;banking innovations kunde bank interaktion web 2 0 mobile banking tablet pcs virtuelle kreditkarten elektronische ids	Die interaktion einer Bank mit ihren Kunden hat sich in den vergangenen Jahrzehnten deutlich weiterentwickelt. Zwar sind auch nach dem E-Business-Hype die physischen Filialnetze weiterhin von Bedeutung, jedoch hat die Entwicklung zu stärkerer Beratung und dem zunehmenden Einsatz von Informationstechnologie (IT) sowohl die Filialen selbst als auch die Interaktionskanäle insgesamt verändert. Der vorliegende Beitrag beschreibt die Ergebnisse einer strukturierten Beispielsammlung innovativen IT-Einsatzes im Bereich der Kunde-Bank-Interaktion. Von Prof. Dr. Rainer Alt, Till Möwes und Dr. Thomas Puschmann	die (integrated circuit)	Rainer Alt;Till Möwes;Thomas Puschmann	2010	Wirtschaftsinformatik & Management	10.1007/BF03248273		DB	-103.14218651300627	36.92629224113302	82493
5c297d56c5703b08cca1e2f0bae83e2e915c70a1	anforderungserhebung mit cultural probes		Cultural Probes wurden ursprünglich von Gaver, Dunne und Pacenti (1999) eingesetzt, um von prospektiven NutzerInnen Anregungen für kreative Designlösungen zu erhalten. Durch eine Reihe von Materialien und Fragen werden die Beforschten dazu angeregt, ihren eigenen Alltag über einen bestimmten Zeitraum zu beobachten, zu dokumentieren und zu kommentieren. In der nutzerorientierten Softwaregestaltung werden Cultural Probes inzwischen zunehmend für die systematische Ist-Analyse und Anforderungserhebung verwendet (Maaß et al. 2016). Als Mittel der ethnografischen Selbstaufschreibung und Selbstauskunft und in Kombination mit Interviews oder Gruppendiskussionen erlauben sie einen detaillierten Einblick in Alltagsprozesse und -strukturen, die sonst nicht von außen beobachtet oder erfragt werden können (Boehner et al. 2007, 2012).	eine and zwei;sie (file format);unified model	Juliane Jarke;Susanne Maaß	2017		10.18420/muc2017-ws02-0420	engineering	NLP	-106.05069141923268	33.576242834607086	82643
cc6917add60080075d219fb58907bd52004cf732	aus- und weiterbildung: e-learning-angebote für den gartenbau		Es werden E-Learning-Angebote im Sinne von internetgestütztem Lehrangebot bzw. von Online-Angeboten als Ergänzung des Präsenzunterrichts in der gartenbaulichen Ausund Weiterbildung vorgestellt. Bei der Bestandsaufnahme wurden Angebote von Berufsschulen, Technikerund Meisterschulen, Hochschulen und Universitäten sowie Angebote der beruflichen Weiterbildung privater und staatlicher Stellen berücksichtigt. Auf einer erstellten Website werden alle Anbieter mit ihrem Profil näher vorgestellt.		Magdalena Tauch;Thomas Lohrer;Georg Ohmayer	2012				OS	-104.60429579030465	33.61651430093222	83026
3b4ebd6e955b03d861a7ab2be5683548779bb738	mitarbeiterschulung mit rollenspielen und workflow-management-systemen		Rollenspiele stellen ein beliebtes Instrument im Rahmen von Mitarbeiterschulungen dar. Im Zusammenhang mit der Optimierung ihrer Geschäftsprozesse setzen Unternehmen zunehmend auf Methodiken wie Six Sigma, die ausdrücklich die Einbindung der Mitarbeiter fordern. Dieser Beitrag basiert auf einem Rollenspiel, das sich eines Prozesses aus dem Bankenbereich bedient, um Mitarbeiter für Prozessverbesserungen zu gewinnen. Er beschreibt die Transformation eines papierbasierten Rollenspiels in ein Workflow-Management-System (WfMS). Es wird deutlich, dass der Einsatz von Softwarelösungen sehr gut geeignet ist, um Mitarbeiterschulungen zu unterstützen. Gleichzeitig führt der Softwareeinsatz aber auch zu einer Reihe von Herausforderungen.	internet explorer;unified model	René Börner;Jürgen Moormann	2011	HMD Praxis der Wirtschaftsinformatik	10.1007/BF03340628	library science;knowledge management;workflow;engineering	OS	-101.4716000997366	33.78356090598772	83453
18718e24bbaf01cf0bffef53de527a57dfcfb760	or.net: ein projekt auf dem weg zur sicheren dynamischen vernetzung in op und klinik		Der Aspekt der Integration und Vernetzung ist in den letzten Jahren sowohl bei der Verwendung von Medizinprodukten durch die Operateure, als auch bei der Au sstatt ng von Operationssälen insgesamt immer wichtiger geworden. Insbesondere g röß re internationale Hersteller bieten hier bereits heute verschiedene Lösungen an. Diese monolithischen Gesamtsysteme weisen jedoch eine eingeschränkte Modularitä t, Flexibilität und Austauschbarkeit auf, da gemeinsame Standards für den Daten austausch und die Vernetzung der einzelnen Medizinprodukte untereinander, sowie mit den angrenzenden IT-Systemen und -Strukturen fehlen bzw. nicht ausr eichen.	eine and zwei	Markus Birkle;Bjoern Bergh	2012			computer science	OS	-104.04857942949761	33.29318641547607	83592
b4d88ff25670fb080088cad668a1749cdac75770	unter modulhandbuchhaltern und sprintstudierenden – wer studiert heute ki? und warum?		Eher konservative Universitätsvertreter – betrachten wir pars pro toto den Deutschen Hochschulverband – und eher progressive Studierendenvertretende – sagen wir, von einem typischen AStA – sind sich seit Jahren verblüffend einig: Der Untergang der Deutschen Universität steht unmittelbar bevor. Die Begründungen sind gruppenund interessenspezifisch unterschiedlich, doch kommen die Begriffe Bologna, Verschulung, Studiengebühren und Prüfungsflut zuverlässig auf beiden Seiten vor. Über den Untergang der Universität bin ich mir nicht sicher. Doch dass sich das Studium in den letzten Jahren für alle Beteiligten verändert hat, das ist gewiss. Die Fächer sind dabei, ihren Lehrkanon durchzusehen und hinsichtlich der Strukturierung in Bachelorund Masterstudium neu zu sortieren – dabei beobachtet (kontrolliert? beargwöhnt? unterstützt?) von Akkreditierungsagenturen und -kommissionen. Die Studierenden optimieren ihre Studienpläne und entdecken dabei massenhaft das Kriterium Studiendauer, das es zwar immer schon gab, das mit oder ohne Studiengebühren mit Kosten zu tun hat, das aber früher irgendwie unwichtiger gewesen zu sein scheint. Alle Studieninhalte, die auch nur dem Anschein nach verzichtbar sind, laufen in dieser Lage Gefahr, auf Angebotswie auf Nachfrageseite gestrichen zu werden. KI scheint eine von diesen gefährdeten Arten innerhalb der Informatik zu sein (aber nicht die einzige). Zwar fordern die Empfehlungen der GI für Informatik-Studieninhalte im	binary prefix;die (integrated circuit);eine and zwei;gab;i/o controller hub;institut für dokumentologie und editorik;tun (product standard);vhf omnidirectional range	Joachim Hertzberg	2011	KI - Künstliche Intelligenz	10.1007/s13218-011-0124-9	machine learning;speech recognition;artificial intelligence;computer science	OS	-105.27437481699509	34.04432416697909	83926
274f38c966edef114976d6a67a894f9eb3b62405	adaptive lehrvideos		Lehrvideos erfreuen sich dank aktueller Entwicklungen im Bereich der Online-Lehre (Videoplattformen, Massive Open Online Courses) auf der einen Seite und einer riesigen Auswahl sowie einer einfachen Produktion und Distribution auf der anderen Seite großer Beliebtheit bei der Vermittlung von Lerninhalten. Trotzdem bringen Videos einen entscheidenden Nachteil mit sich, welcher in der Natur des Datenformats liegt. So sind die Suche nach konkreten Sachverhalten in einem Video sowie die semantische Aufbereitung zur automatisierten Verknüpfung mit weiteren spezifischen Inhalten mit hohem Aufwand verbunden. Daher werden die lernerfolg-orientierte Selektion von Lehrsegmenten und ihr Arrangement zur auf Lernprozesse abgestimmten Steuerung gehemmt. Beim Betrachten des Videos werden unter Umständen bereits bekannte Sachverhalte wiederholt bzw. können nur durch aufwendiges manuelles Spulen übersprungen werden. Selbiges Problem besteht auch bei der gezielten Wiederholung von Videoabschnitten. Als Lösung dieses Problems wird eine Webapplikation vorgestellt, welche die semantische Aufbereitung von Videos hin zu adaptiven Lehrinhalten ermöglicht: mittels Integration von Selbsttestaufgaben mit definierten Folgeaktionen können auf Basis des aktuellen Nutzerwissens Videoabschnitte automatisiert übersprungen oder wiederholt und externe Inhalte verlinkt werden. Der präsentierte Ansatz basiert somit auf einer Erweiterung der Lerntheorie der verzweigten Lehrprogramme nach Crowder, die auf den Lernverlauf angepasste Sequenzen von Lerneinheiten beinhaltet. Gleichzeitig werden mittels regelmäßig eingeschobener Selbsttestaufgaben Motivation sowie Aufmerksamkeit des Lernenden nach Regeln der programmierten Unterweisung und Verstärkungstheorie gefördert. Durch explizite Auszeichnung zusammengehöriger Abschnitte im Video können zusätzlich die enthaltenden Informationen maschinenlesbar gestaltet werden, sodass weitere Möglichkeiten zum Auffinden und Verknüpfen von Lerninhalten geschaffen werden.	7 days to die;eine and zwei;massive open online course	Ingolf Waßmann;Martin Müller;Djamshid Tavangarian	2015				OS	-107.44025531789774	34.26031879435355	83999
500a5e137150337c06b678c8126ea64de5cd301e	philosophie und die kognitiven wissenschaften		Seit nunmehr fast zwei Jahrzehnten treffen sich alljährlich im August in Kirchberg am Wechsel (Niederösterreich) Philosophen und andere Wissenschaftler, die direkt oder indirekt mit Forschungen zu Ludwig Wittgenstein befaßt sind. Das diesjährige 16. Internationale Wittgenstein Symposium, das vom 15. bis 22. August 1993 stattfand, hatte das Thema Philosophie und die kognitiven Wissenschaften. Mit dieser brisanten Thematik war eigentlich schon vorprogrammiert, daß der Kongreß auf großes Interesse der internationalen Wissenschaftlergemeinschaft stoßen wird. Und so war es dann auch keinesfalls überraschend, daß etwa 1000 Wissenschaftler aus allen Erdteilen anreisten. Aber nicht nur hinsichtlich der großen Teilnehmerzahl unterschied sich dieses Symposium von den vorhergehenden, sondern auch in bezug auf die Vorbereitung der Konferenz. Dazu bemerkte der Präsident der Österreichischen Ludwig-Wittgenstein-Gesellschaft, Rudolf Haller (Graz), in seiner Eröffnungsrede, daß dieses Symposium gewissermaßen einen Generationswechsel vollzog, insofern die Organisation in die Hand eines neuen Organisationsstabes gelegt wurde. In diesem Jahr hatte B. Smith (Schaan) die Betreuung der Konferenz übernommen. Während des einwöchigen Kongresses wurden 250 Vorträge gehalten. Eine Vielzahl der Beiträge war in einem Pre-Text-Reader gedruckt erhältlich. Unübersehbar wurde während der gesamten Konferenz deutlich, daß die Forschungen in den kognitiven Wissenschaften zu den aufsehenerregendsten Entwicklungen in der internationalen Wissenschaftslandschaft der letzten drei Jahrzehnte gehören. Anliegen der kognitiven Wissenschaften (wie der kognitiven Psychologie, der kognitiven Linguistik, Computerwissenschaft, Forschungen zur Künstlichen Intelligenz, der kognitiven Semiotik u.a.) ist es, die natürliche Intelligenz biologischer Organismen, insbesondere von Menschen, und die künstliche Intelligenz menschengemachter Maschinen, darunter vor allem von Computern, zu erforschen. Die in den kognitiven Wissenschaften erzielten Ergebnisse dienen vor allem dem Ziel, die Funktionsweise des menschlichen Geistes besser zu verstehen. Zur Realisierung der Aufgabenstellung der kognitiven Wissenschaften werden unterschiedliche Modelle angeboten. Erwähnt seien hier u. a. Komputationalismus, der Konnektionismus und die Ermergenztheorie. Verständlicherweise war der Kongreß ein Spiegelbild der miteinander konkurrierenden Theorien. Dies war nun keinesfalls ein Nachteil, sondern belebte die Diskussion. Die Plenarveranstaltungen waren folgenden Themen gewidmet:	eine and zwei;internet explorer;vhf omnidirectional range	Evelyn Dölling	1994	LDV Forum		engineering drawing;computer science;information retrieval;strips	Embedded	-104.73269504949619	34.54655882274899	84135
edf77f6a64374a71abfc4543fe64acfbb1d15300	das wissensportal der qualitätsicherung der volkswagen ag		In der Qualitätssicherung der Automobilindustrie steht heute die Früherkennung möglicher Qualitätsmängel im Vordergrund, da aus monetärer Sicht eine frühe Fehlerprävention immer günstiger ist als eine späte Fehlerbeseitigung. Grundlage für eine effektive Fehlerprävention ist das Wissen über Ursachen und Zusammenhänge. Daher stellt die Ressource Wissen, bereitgestellt für alle Mitarbeiter über alle qualitätsrelevanten Prozesse, den entscheidenden Wettbewerbsfaktor dar. Das Wissensportal der Qualitätssicherung der Volkswagen AG stellt aus diesem Grund die notwendige IT-Infrastruktur zur Auswertung und Analyse zur Verfügung. Der folgende Beitrag beschreibt Inhalte, Funktionalitäten sowie die zugrundeliegende Architektur des QS-Wissensportals.	eine and zwei;gesellschaft für informatik;zentralblatt math	Rolf Bergmann;Volker Kratzenstein;Wolfgang Behme	2003				AI	-104.81521422760018	33.2540058519189	84137
ca9fc1d548dc7df3e3ed921101ca8b986d5abad3	minimale und optimale blumsche maße				Gerd Wechsung	1975	Elektronische Informationsverarbeitung und Kybernetik		combinatorics;mathematics	NLP	-95.65829351454965	34.47422856166876	84297
d43265eb9348224403bc6b6fcdae704c3d8a2163	kausalanalytische untersuchung von akzeptanzproblemen ambienter technologien zur vermeidung von behandlungsfehlern in deutschen krankenhäusern		Die Besonderheit ambienter Technologien liegt vor allem in der Datenermittlung mittels Sensoren und mobiler Geräte, die in die Umgebung eingebettet sind und die gesammelten Informationen weiterleiten und auswerten. Die Einführung derartiger Technologien bringt häufig Akzeptanzprobleme mit sich. Ambiente Technologien werden von den Anwendern unter anderem wegen der damit verbundenen Überwachungsmöglichkeiten ihrer Tätigkeiten leicht als Eingriff in die Intimsphäre gewertet und in der Folge häufig abgelehnt. Im vorliegenden Beitrag werden die Wirkungszusammenhänge von Akzeptanzproblemen bezüglich ambienter Technologien in deutschen Krankenhäusern mittels empirischer Daten herausgearbeitet.	vhf omnidirectional range	Tyge-F. Kummer;Markus Bick	2009			software engineering;multimedia;computer science	AI	-103.62252446080653	32.624451994832306	84307
cf274faca0c579e4508d059279f38a64a0aa20d0	entwurf nichtlinearer beobachter mit linearer und näherungsweise linearer fehlerdynamik (design of nonlinear observers with linear and approximately linear error dynamics)		Zusammenfassung Der Beobachterentwurf mittels exakter Linearisierung ist der Fachwelt seit rund 25 Jahren bekannt. Aufgrund restriktiver Existenzbedingungen bzw. einer aufwendigen Berechnung ist dieser sehr elegante Ansatz in der regelungstechnischen Praxis kaum anzutreffen. Im Beitrag werden zunächst Existenzbedingungen und Berechnungsmethoden rekapituliert. Anschließend geht der Beitrag auf den erweiterten Luenberger-Beobachter ein, welcher auf einer lokalen Taylorlinearisierung basiert und wesentlich leichter zu berechnen ist. Zu diesem Beobachter werden Verallgemeinerungen entwickelt und globale Konvergenzbedingungen angegeben. Summary Observer design by exact linearization of the error dynamics is well-known in the control engineers’ community for roughly 25 years. Unfortunately, this approach is not widely used in control engineering due to restrictive existence conditions and a difficult calculation. In this paper we recall existence conditions and computation methods. Then, we consider the extended Luenberger observer, which is based on a local Taylor linearization and easier to compute. We discuss generalizations and global convergence conditions.	altran praxis;computation;control engineering;local convergence	Klaus Röbenack	2010	Automatisierungstechnik	10.1524/auto.2010.0868	control engineering;control theory;nonlinear system;computer science	DB	-96.25167893996617	36.005951815927055	84401
01dd63c9a194344fbe76a01a837e2e5ed04c509d	it-risiken im schadenversicherungsmodell: implikationen der marktstruktur		Versicherungen gelten als geeignetes Mittel um Schäden durch Computerpannen finanziell abzufedern und um gleichzeitig Anreize zur Konstruktion sicherer Computersysteme zu schaffen. Allerdings führt eine starke Dominanz weniger Systemplattformen zu Schadenkorrelationen, die nur unter Prämienaufschlägen wirtschaftlich versichert werden können. Dieser Beitrag beleuchtet anhand eines Schadenversicherungsmodells die Versicherbarkeit von IT-Risiken bei konzentrierter Anbieterstruktur. Dabei wird eine Prämiendifferenzierung für Nutzer einer dominierenden bzw. einer alternativen Plattform diskutiert. Ein Kostenvorteil für Nutzer wenig verbreiteter Plattformen könnte zu einer ausgeglicheneren Marktstruktur führen, indem er ein Gegengewicht zu den starken Skaleneffekten verbreiteter Plattformen bildet. 1 Ökonomie der Computersicherheit Es ist weithin bekannt, dass Sicherheitslücken in Computersystemen jährlich einen immensen wirtschaftlichen Schaden verursachen, auch wenn das wahre Ausmaß kaum durch seriöse Schätzungen beziffert werden kann. Mangelnde Computersicherheit hat jedoch nicht nur wirtschaftliche Konsequenzen, sondern mitunter auch ökonomische Ursachen. Ross Anderson [And01] begründet dies mit der Feststellung, dass weder Hersteller noch Nutzer Anreize haben, in ihrem Verantwortungsbereich angemessen in Schutzmaßnahmen zu investieren. 1.1 Versicherung von IT-Risiken Die Informatik und verwandte Disziplinen stellen eine Vielzahl an technischen Schutzmaßnahmen für alltägliche Probleme der Computersicherheit bereit. Diese können ihre Wirkung allerdings nur dann entfalten, wenn sie effektiv eingesetzt werden. Genau dies geschieht offenbar wegen fehlender Anreize zu selten [And94b]. Deshalb liegt es nahe, Computersicherheit nicht nur mit technischen Hilfsmitteln anzustreben, sondern auch die ökonomischen Aspekte zu berücksichtigen. So argumentiert der Ökonom Hal Varian [Var00], dass zunächst die Haftung für Schäden an die Partei übergehen müsste, die sie am einfachsten vermeiden kann. So müssten Hersteller für ihre Produkte haften, aber auch Netzknoten – bis hin zum Anwender – zur Verantwortung gezogen werden, wenn sie ih-	eine and zwei;gesellschaft für informatik;sie (file format);unified model	Rainer Böhme	2005			performance art;history	OS	-105.3249570537717	33.85994636981854	84421
09410b52a3013eafbd3ade71501b7f9a07479567	(verlorene) selbstbestimmung im datenmeer		Big Data hält große Versprechungen für die sozialnützliche Auswertung der vorhandenen großen Datenmengen bereit. Die unaufhörliche (und teils unbemerkte) massenhafte Erhebung personenbezogener Daten aus allen denkbaren Lebensbereichen und -situationen stellt andererseits den Schutz der grundrechtlich geschützten Selbstbestimmung und Privatheit vor neue Herausforderungen. Der folgende Beitrag erörtert die Grenzen des Grundrechtsschutzes und dessen Neukonzeption im Zeitalter von Big Data.	big data;die (integrated circuit);vhf omnidirectional range	Alexander Roßnagel;Maxi Nebel	2015	Datenschutz und Datensicherheit - DuD	10.1007/s11623-015-0449-x		ML	-100.90721442200598	35.5437952976945	85692
9a0c4c5974bc5c93c0db971407ba5dd2fbea18f7	use cases vs. geschäftsprozesse das requirements engineering als gewinner klarer abgrenzung	use case modelling;requirement engineering;use case;business process	Use Case Modelle Zunehmend gewinnen Use Case-Modelle in Ergänzung zu Geschäftsprozessmodellen Bedeutung für die Softwareentwicklung und das Business Process (Re-)Engineering. Diese pragmatische Vorgehensweise, die Vorzüge der Use Case-Technik mit der Methode der Geschäftsprozessanalyse zu kombinieren, führt jedoch seit längerem zu erheblicher Konfusion in Literatur und industrieller Praxis: Beide Konzepte sind nur ungenügend voneinander abgegrenzt und werden als überlappend und teilweise sogar als identisch erklärt. Wir zeigen jedoch die klare konzeptuelle Verschiedenheit, indem wir auf Basis der Systemtheorie beiden Konzepte einen eindeutigen Platz sowohl im Bezugsrahmen ,,Organisation“ wie auch im Bezugsrahmen ,,Software“ zuweisen, was darüber hinaus dazu geeignet ist, den Aussagewert des (auch nicht UML-basierten) Requirements und Business (Re-)Engineering erheblich anzureichern. Dadurch wird klar, wie beide Konzepte isoliert und kombiniert sowohl im Business (Re-)Engineering als auch im SW/HW Requirements Engineering zu verwenden sind.	altran praxis;business process;eddie (text editor);internet explorer;requirements engineering;unified modeling language	Hartmut Umbach;Pierre Metz	2006	Informatik-Spektrum	10.1007/s00287-006-0106-8	use case;systems engineering;engineering;industrial engineering;software engineering;requirements engineering;business process;management	SE	-101.202592700292	33.065615204595744	85753
2a20d75ca60bb33c607333444bb5f8047fa98d31	märkte als netzwerke		Die sozialwissenschaftliche Netzwerkanalyse hat seit den 1970er Jahren wesentlich zur neuen Wirtschaftssoziologie beigetragen. Letztere ist keine soziologische Ergänzung der Wirtschaftswissenschaften, sondern beansprucht aus soziologischer Perspektive die eigenständige Analyse der ökonomischen Institutionen aufnehmen zu können. Es sind insbesondere Netzwerktheoretiker, die die Analyse der ökonomischen Institution „Markt“ als soziologischen Forschungsgegenstand wieder erschlossen haben und die damit zugleich den Anspruch (erneut) formuliert haben, dass Märkte ein genuin soziologischer Forschungsgegenstand sind. Worin kann nun der eigenständige Beitrag eines soziologischen Ansatzes liegen, der „Märkte als Netzwerke“ (Baker 1981) auffasst? Allein die Feststellung, dass Markttransaktionen auch als Beziehungen in Netzwerken betrachtet werden können, verspricht zunächst keinen wesentlichen Erkenntnisgewinn, der über denjenigen des etablierten Marktmodells vom geldvermittelten freien Tausch zwischen vielen Anbietern und Nachfragern unter der Bedingung des Wettbewerbs hinausreichen würde. Es gibt verschiedene netzwerkanalytische Grundpositionen, die hier nun bedeutsam werden (Zuckerman 2003). 1. Netzwerkanalytiker gehen davon aus, dass Netzwerke Marktstrukturen aus Tauschbeziehungen darstellen, die dann die Eigenschaften und Funktionsweisen (Performativität) des Marktes je nach Art der Struktur in unterschiedlicher Weise bedingen. Das je konkrete Netzwerk aus Tauschbeziehungen ist dann als Marktstruktur nicht durch herkömmliche wirtschaftswissenschaftliche Marktmodelle zu erklären. Denn hier werden die Beziehungsformen nur als kurzfristige Transaktionen gedacht und die Struktur der Netzwerke wird nicht in Betracht gezogen. Viele Tauschstrukturen sind beständigere und keineswegs nur am einzelnen Tausch ausgerichtete Beziehungen. Struktureigenschaften dieser Netzwerke – wie die Dichte oder das Fehlen von Beziehungen – können sich voroder nachteilig für die Akteure im Markt auswirken und sie können Markteigenschaften (wie z. B. Effizienz) erst ermöglichen. 2. Mit dem Konzept der Einbettung wird zunächst die Einbettung von Akteuren und Beziehungen in umfassendere Netzwerke als Kontexte beschrieben. Diese Perspektive auf Einbettung lässt dann erklärlich werden, dass z.B. Akteure Handlungsorientierungen in Netzwerken erwerben und Beziehungen durch den Netzwerkkontext konditioniert werden. Weiter betrachten Netzwerkanalytiker die Einbettung von ökonomischen Tauschnetzwerken in andere soziale Beziehungsnetzwerke. Betrachtet wird, in welcher Weise nicht-ökonomische Beziehungen den ökonomischen Beziehungen voraus-	internet explorer;sie (file format)	Rainer Diaz-Bone	2010		10.1007/978-3-531-92575-2_53	sociology;performance art	NLP	-105.58132920270289	34.270620148617915	85903
24b51a161df4c92ff7453141fccbf2113e3a56a4	potenziale von grünvolumen und entsiegelung zur klimaanpassung am beispiel der landeshauptstadt potsdam		Im Rahmen einer Präsentation von LÜDEKE & WALTHER (PIK) zu Klimaanpassungsstrategien für Potsdam (13.05.2014) wurden folgende Entwicklungen für Potsdams Klima präsentiert (LÜDEKE & WALTHER 2014):  Die Durchschnittstemperaturen steigen bis 2050 im Durchschnitt um 2.5 °C.  Es wird zu mehr sogenannten tropischen Nächten und damit heißen Sommernächten aber auch Tagen kommen.  Hitzeperioden werden zunehmen, sie werden länger und häufiger auftreten als heute.  Die Jahresniederschläge werden leicht abnehmen.  Die Niederschlagsmuster werden sich aber in Hinblick geringere Niederschläge im Sommer (trockener) höhere im Winter ändern (feuchter).  Extremwetterlagen werden häufiger auftreten.	sie (file format);unified model;walther recursion	Steffen Tervooren	2015	AGIT Journal	10.14627/537557037			-104.64509474484	33.5904042822268	86178
beef5c9fa7f6fc93ebb5fdf1480ca2db51144b6c	ambiente lernräume		Ambiente Lernräume sind eine Form gemischter Realität (Mixed Reality), in der der Körper des Lernenden und der ihn umgebende Raum durch vernetzte digitale und personalisierte Medien angereichert werden. Hier wird sowohl individuelles als auch gemeinsames Lernen wirkungsvoll im Sinne einer systemisch-konstruktivistischen Pädagogik gefördert. Beispielhaft stellen wir einige Lernapplikationen für ambiente Lernumgebungen vor, welche mit einem cloud-basierten, semantisch modellierten System verbunden sind und neue Möglichkeiten der Kommunikation und Interaktion bereitstellen.	eine and zwei;gesellschaft für informatik;mixed reality;vhf omnidirectional range	Thomas Winkler;Florian Scharf;Michael Herczeg	2014	Informatik-Spektrum	10.1007/s00287-014-0817-1		OS	-107.37303252676682	32.48602714897192	86574
4933e3c8f9bc2c32b2891be3e107b961d0ff9624	dynamische generierung von protokollen zur steuerung automatisierter verhandlungen		In elektronischen Handelssystemen (E-Commerce) bekommt die Unterstutzung der Verhandlungsphase von Geschaftstransaktionen eine wachsende Bedeutung. Jedoch sind die meisten existierenden Systeme mit einem bestimmten Protokoll fest verbunden und daher eingeschrankt in ihrer Offenheit bzgl. der jeweiligen Anforderungen an eine Verhandlung. Um dem entgegenzuwirken, wird in diesem Beitrag eine Petrinetz-basierte Sprache zur Spezifikation von Verhandlungsprotokollen vorgestellt, welche dynamisch fur jeweils eine einzelne Verhandlung generiert und aktiviert werden konnen. Solche Protokolle und das entsprechende Verhandlungssystem sind daruber hinaus dafur konzipiert, vollstandig automatisierte Verhandlungsprozese mittels Anbindung von Softwareagenten zu steuern.		M. Tuan Tu;C. Langmann;Frank Griffel;Winfried Lamersdorf	1999		10.1007/978-3-662-01069-3_15		Robotics	-104.09887123734082	32.960032453773664	87196
bc623a5e983bb08224cf3fc6c5da7a0ea4862877	sicherheit in client-server-architekturen	client server	Business-Softwaresysteme enthalten über viele Jahre gewachsenes, geschäftsnotwendiges Expertenwissen, sind aber meistens nicht nach modernen Softwareentwicklungsmethoden entworfen und können daher oft nur schwer an sich wandelnde Hardund Softwaretechnologien angepasst werden. Diese als Legacy-Problematik bezeichnete Situation ist für viele Unternehmen vorhanden und verursacht evtl. nicht unerhebliche Kosten für Wartungsund Entwicklungsarbeiten. Eine häufige Fragestellung im Managementund Softwareentwicklungsbereich ist daher die kostengünstige und effektive Analyse, Dokumentation und Überführung solcher Softwaresysteme. Speziell wird in diesem Beitrag die Überführung erprobter, monolithischer Unternehmenssoftware in moderne verteilte oder service-orientierte Systeme betrachtet. Dabei soll die interne modulare logische Struktur der Softwaresysteme für die Überführung durch ein Transformationswerkzeug genutzt werden. Zur flexiblen Softwareerzeugung für unterschiedliche verteilte oder heterogene Systeme wird ein inkrementeller Transformationsprozess für Legacy-Software vorgeschlagen, durch den schrittweise aus der gegebenen Grobstruktur eine speziellen Bedürfnissen entsprechende, verteilte Software entsteht. Hier spielt eine Separation der Aspekte der Geschäftslogik einerseits von Aspekten der Verteiltheit, Sicherheit oder Heterogenität andererseits eine wesentliche Rolle. Zur Durchführung des Transformationsprozesses soll ein funktions-, korrektheitsund merkmalserhaltenden Transformationswerkzeug entwickelt und realisiert werden. Die Separation von Transformation und Verteiltheit soll durch die Bereitstellung eines offenen, erweiterbaren ClientServer-Frameworks erreicht werden.	die preparation;eine and zwei;gesellschaft für informatik;institut für dokumentologie und editorik;legacy system;système universitaire de documentation;triple des	Gerhard Klett	1993			server-side;operating system;client–server model;fat client;business	OS	-103.49547385473174	32.430743328242286	88000
1b867b7b245f56c94922e6d2a4eb518ff50e3969	agile methoden im softwareprojekt		Agile Methoden setzen sich sowohl in der Wissenschaft als auch in der Praxis mehr und mehr durch und werden auch in den universitären Lehrplan aufgenommen. Allerdings reicht ein theoretischer Charakter der Ausbildung nicht aus, um agile Methoden wirklich zu lernen und zu erfahren. Im praktischen Softwareprojekt lernen Studierende, das theoretische Wissen anzuwenden und können erste praktische Erfahrung damit sammeln. Um den Nutzen des Softwareprojekts zu erhöhen, wird es als Blockveranstaltung über einen Zeitraum von 3 Wochen während der vorlesungsfreien Zeit durchgefhrt. Im Vortrag wird es um Erfahrungen des Softwareprojekts als Blockveranstaltung und dem Einsatz von agilen Methoden gehen. Dabei wird besonders auf Rückmeldung durch Studierende eingegangen sowie auf den erhöhten Nutzen für die Projektbetreuer.	agile software development;altran praxis;unified model	Janet Siegmund;Thomas Thüm;Sandro Schulze;Elmar Jürgens	2013			systems engineering;agile software development;engineering		-101.3076145638907	33.095085618043	89160
3f87fb7f912cf596ea1bb45b923b4c2f013e6752	evolutionäre betriebliche informationssysteme - perspektiven und herausforderungen einer neuen generation von informationssystemen		Der vorliegende Artikel reflektiert bestehende und zukunftige Herausforderungen im Bereich „evolutionarer betrieblicher Informationssysteme“, einer Gattung von Systemen, die einen evolutionaren Softwareentwicklungsprozess erfordern und die eine „sekundare Gestaltung (secondary design)“ auf mehreren konzeptionellen Ebenen unterstutzen. Wir verorten sowohl bestehende Forschungsbeitrage und zukunftige Herausforderungen innerhalb einer idealisierten, vorlaufigen Systemarchitektur. Schlieslich betonen wir unsere pluralistische Sichtweise auf den Forschungsgegenstand und die daraus resultierende Notwendigkeit einer methodologischen Flexibilitat im Sinne interdisziplinarer Konfigurationen von Forschungsmethoden.		Gustaf Neumann;Stefan Sobernig;Michael Aram	2014	Wirtschaftsinformatik	10.1007/s11576-013-0397-8		NLP	-104.6175641583793	32.65289315813779	89242
8a87a1480c93d183c680243aba33548dbccaa9a1	industrielle konzepte bei der entwicklung und produktion von it-services		Bei der Strukturierung und Entwicklung von IT-Serviceangeboten steht vor allem der Produktansatz (IT-Services als Dienstleistungsprodukte) auf Basis eines Spektrums möglichst standardisierter, wiederverwendbarer, kombinierbarer Servicemodule im Vordergrund, während der Schwerpunkt bei der Leistungserbringung wiederum bei der Realisierung von Ratiopotenzialen mithilfe der Arbeitsteilung auf der Basis standardisierter Herstellungs- und Managementprozesse für jeweils gleichartige Tätigkeiten liegt. Erfahrungen bei der praktischen Umsetzung, insbesondere im Zusammenhang mit Outsourcing und unter Berücksichtigung des Business/IT-Alignments, zeigen allerdings auch Grenzen und Voraussetzungen der Anwendbarkeit industrieller Konzepte auf. Diese werden dann sichtbar, wenn der IT-Service zunehmend zum integrierten Bestandteil eines Geschäftsprozesses oder eines Produkts wird und eine deutliche Differenzierung des Unternehmens und seiner Produkte am Markt angestrebt wird. Um nicht auf die Vorteile industrieller Konzepte verzichten zu müssen, werden spezifische Konzepte wie die Kundenintegration in die Betrachtung einbezogen.	blitzkrieg;eine and zwei;internet explorer;outsourcing;unified model;vhf omnidirectional range	Titus Kaufmann;Michael Schlitt	2007	HMD Praxis der Wirtschaftsinformatik	10.1007/BF03340309	knowledge management;engineering;performance art	OS	-101.72669708471584	34.06249715844853	89353
cdd1044fea4efa6e78e3ff7de44801eb00d14fc1	ariel - e-learning für kmus	poster	In diesem Posterbeitrag wird aus der aktuellen Arbeit des Projekts ARIEL – Analysing and Reporting on the Implementation of Electronic Learning in Europe – berichtet. Es handelt sich dabei um ein von der Europäischen Kommission im Rahmen der eLearning Initiative finanziertes internationales Kooperationsprojekt, in dem die aktuellen Erkenntnisse über E-Learning für kleine und mittlere Unternehmen im Hinblick auf didaktische Ansätze, Nutzen und Einsatzbereiche – insbesondere vor dem Hintergrund der Steigerung der Handlungsfähigkeit der Unternehmen im „Europa der 25“ – untersucht werden.	europa;unified model;vhf omnidirectional range	Hansjürgen Paul	2005				OS	-107.52884011014078	34.24338268967003	89402
54b3a042369e0db90abc5fe5fe3980e4283fc0e4	a system-oriented approach to efficiency and quality of service for internet service providers	internet service provider;quality of service	Diese Dissertation untersucht, wie man die Effizienz und Dienstgüte eines IP Netzwerkes aus der Sicht eines Internet Netzwerkbetreibers optimieren kann und sollte. Da die Gesamteffizienz und -dienstgüte von verschiedenen Aspekten des Betriebs eines Netzwerkes abhängt, wird ein systemorientierter Ansatz in der Dissertation entwickelt und verwendet, d.h. es werden verschiedene Aspekte des Betriebs eines Netzwerks und ihre gegenseitigen Beeinflussungen untersucht. Die untersuchten Aspekte untergliedern sich in drei Bereiche: die Netzwerkarchitektur, die Interkonnektion (Anbindung an andere Netzwerke) und den Bereich der Verkehrsund Netzwerkanpassungsmaßnahmen (traffic and network engineering).	internet explorer;quality of service	Oliver Heckmann	2004			best-effort delivery;service level requirement;service level objective;cellular traffic;network intelligence;network planning and design;mobile qos;quality of service;business service provider;differentiated service;engineering;service delivery framework;operations management;value-added network;service design;data as a service;customer service assurance;computer security;computer network	Security	-101.52228955893949	36.417418405699195	89469
0135dca7f9505aa9e18b479820348e1a6e1f6e74	anwendung der blockchain außerhalb von geldwährungen		Die Blockchain ist nicht nur im Bereich der Finanzwelt angekommen, auch andere Branchen versuchen sich an ihrer Anwendung. In diesem Artikel werden Konzepte und Modelle von Blockchain-Anwendungen auserhalb des Finanzbereichs vorgestellt, indem die zugehorigen Veroffentlichungen referiert und diskutiert werden. Die Anwendungsbereiche variieren aktuell uber den Schutz personlicher Daten bis zur Sicherung und Uberwachung von Nahrungsmittelproduktionsketten.	bitcoin;vhf omnidirectional range	Stephan Wiefling;Luigi Lo Iacono;Frederik Sandbrink	2017	Datenschutz und Datensicherheit - DuD	10.1007/s11623-017-0816-x	computer science;internet privacy;blockchain	Crypto	-103.24046481881759	36.64952475082019	89486
96995758a30e15dc52950d5b4e71d090c4c83542	die herausforderungen nehmen zu — informationssicherheit und informationsschutz im umbruch		Mit organisatorischen Maßnahmen und technischen Vorkehrungen ist eine dem Unternehmen adäquate Abwehrstrategie gegen die zunehmende Bedrohungslage und die Herausforderungen an die Informationssicherheit zu implementieren. Zertifizierungen helfen beim kritischen Review der eingeführten Prozesse und sind heute oft entscheidend im Wettbewerb. Vorschläge für die Umsetzung in der Praxis zeigen, wie ein angemessenes Sicherheitsniveau mit überschaubarem Aufwand erreicht werden kann. Das Internet der Dinge und erhebliche Veränderungen der menschlichen Arbeit sorgen in den nächsten Jahren für eine notwendige Neuausrichtung von Informationssicherheit. Die heutigen Sicherheitsarchitekturen werden nicht genügen, um die Sicherheitsziele zu erreichen.	altran praxis;die (integrated circuit);eine and zwei;internet explorer;unified model	Jürgen Schoolmann	2011	HMD Praxis der Wirtschaftsinformatik	10.1007/BF03340619	knowledge management;engineering;performance art	OS	-103.11302638275298	33.62978376098452	89676
03fa026576655f4b4812082ea87ef0d5a65765af	näherungsverfahren zur ermittlung periodischer lösungen von systemen nichtlinearer periodischer differentialgleichungen		Zur Berechnung erzwungener Schwingungen bei nichtlinearen periodischen Systemen werden drei Methoden (Iterations-, Projektions- (P) und Projektions-Iterations (PI)-Verfahren) mit den entsprechenden Fehlerabschätzungen dargelegt. Es wird bewiesen, daß die Konvergenzbedingungen für das P-Verfahren auch die Konvergenz des PI-Verfahrens gewährleisten. Das PI-Verfahren hat folgende Vorteile: 1. Die Koeffizienten derm-ten Näherung können unmittelbar aus den Koeffizienten der vorangehenden Näherung berechnet werden. 2. Es müssen nicht mehr nichtlineare Gleichungssysteme gelöst werden. Three methods (iteration, projection (P) and projection-iteration (PI) methods) with the corresponding error estimations are given to compute the forced oscillations of nonlinear periodic systems. It is proved, that the convergence conditions for the P-method are also sufficient for the convergence of the PI-method. The PI-method has the following advantages: 1. The coefficients of the approximation of orderm can be calculated immidiately from the coefficients of the foregoing approximation. 2. It is no longer necessary to solve nonlinear equations.	3d projection;approximation;coefficient;es evm;iteration;nonlinear system	K. R. Schneider	1972	Computing	10.1007/BF02242382	mathematics;mathematical analysis;pi	AI	-96.52958358654128	35.866210275442604	89785
a288dc87725904e83097ee6c43c42f5dc97d9f0e	on the moore test for coupled equations	equation non lineaire;iterative method;ecuacion no lineal;systeme equation;iterative algorithm;coupled system;convergence numerique;metodo iterativo;algorithme;numerical convergence;algorithm;moore test;sistema ecuacion;methode iterative;equation system;non linear equation;convergencia numerica;algoritmo	In this paper an improved Moore test for the coupled system:f(x, y)=0,g(x, y)=0 is described: x+ is calculated from x and y in a forward-substep, and we use x+ and y to compute y+ in a backward-substep. It is shown that, if x+ ⊂ x, y+ ⊂ y, then a solution of the coupled system (x*,y*) ∈ (x+, y+) exists. On this foundation, we prove convergence of a point iterative algorithm for solving coupled systems. In der vorliegenden Arbeit wird ein veränderter Moore-Test für gekoppelte Gleichungssystemef(x, y)=0,g(x, y)=0 beschrieben, darin wird x+ aus x und y in einem Vorwärtsschritt berechnet, und y+ aus x+ und y in einem Rückwärtsschritt berechnet. Es wird gezeigt, daß eine Lösung der gekoppelten Systeme (x*,y*) ∈ (x+, y+) existiert, wenn x+ ⊂ x, y+ ⊂ y. Auf dieser Grundlage stellen wir ein Punktiterationsverfahren zur Lösung der gekoppelten Systeme vor, und ein Konvergenzsatz wird angegeben.	algorithm;eine and zwei;iterative method;moore's law;system f;vhf omnidirectional range	Yee Soon Ling	1997	Computing	10.1007/BF02684395	mathematical optimization;calculus;mathematics;iterative method;algorithm;algebra	Theory	-96.45796412777375	35.376324428614836	90057
f13ba1741f134d2ee48490a8aafa2bca4b523c99	über finalexperimente an determinierten automaten				Peter H. Starke	1972	Elektronische Informationsverarbeitung und Kybernetik		pure mathematics;combinatorics;mathematics	NLP	-95.43012862608859	34.30195648756969	90440
04ff18a62f0e69253025a41ffd47aa7e86ad9bb1	sicherheits-forschung für die cloud - heisse luft oder wolke sieben?		Seit dem Erscheinen von Cloud-Computing sind viele neue Bedenken gegenüber ”Big Brother“ aufgekommen. Dennoch nutzen Privatleute und Firmen heute die Cloud, weil sie so praktisch ist und behalten dabei ein mulmiges Gefühl im Bauch zurück. Ihre größten Bedenken betreffen die Sicherheit und Zuverlässigkeit von Cloud-Diensten. Da aber langfristige Erfahrungen mit der Cloud bis heute fehlen, sind beide Größen noch weitgehend Unbekannte. Besondere Sichtbarkeit erlangen daher Forschungsresultate, die darauf abzielen, die Benutzer und ihre Daten vor Problemen in der Cloud zu schützen. Diese Arbeiten sollen Geheimhaltung und Integrität der Daten garantieren und die Zuverlässigkeit der bezogenen Dienste sicherstellen. Dieser Vortrag präsentiert und analysiert einige Trends aus dieser Forschung: erstens, die Verarbeitung von verschlüsselten Daten durch ”Homomorphic Encryption“, zweitens, die Konsistenz von verteilten Speicherdiensten und, drittens, hochverfügbare Systeme, welche auch teilweise von einem Gegner unterwandert noch weiterlaufen können (sog. ”Byzantine Fault-Tolerant Systems“).	byzantine fault tolerance;cloud computing;eddie (text editor);homomorphic encryption;sie (file format);vhf omnidirectional range	Christian Cachin	2012			meteorology;cloud computing;art	OS	-102.12026381736862	36.14491702855128	90589
e35d0840ea6aeee37944cde2b14eea932a04f852	hochlexibles workforce management. herausforderungen und lösungsverfahren		Zunehmend ist bei Unternehmen ein Trend weg von der starren Schicht- oder Dienstplanung hin zu einer auf den Personalbedarf ausgerichteten Planung festzustellen. Mit Instrumenten wie der Planung untertägiger Arbeitsplatzwechsel, der Kombination aus Arbeitszeitmodellerstellung und Einsatzplanung sowie der kombinierten Personaleinsatz- und Tourenplanung kann der Personaleinsatz sehr gut an den Personalbedarf angepasst werden. U.a. wird in dieser Arbeit an beispielhaft ausgewählten Problemstellungen untersucht, ob sich eher klassische OR-Verfahren, Metaheuristiken oder Multiagentensysteme eignen. Es zeigt sich, dass klassische OR-Verfahren keine praktikablen Rechenzeiten aufweisen. Demgegenüber erweisen sich ausgewählte Metaheuristiken als überaus gut geeignet. Multiagentensysteme sind nicht zu bevorzugen, da ausgewählte Metaheuristiken bessere Ergebnisse liefern.	es evm;internet explorer	Maik Günther	2011	KI - Künstliche Intelligenz	10.1007/s13218-011-0123-x	simulation;computer science;performance art	OS	-101.902519378003	33.77065816935877	91507
ef1b56be46a18c8d0112f86941af516b341c2504	planung und betrieb von informationssicherheits-managementsystemen		Das Interesse an der Zertifizierungsnorm ISO/IEC 27001 für Informationssicherheitsmanagement systeme ist gro gemäß ISO/IEC 27001:2005 zertifiziert. Die Zahl der Organisationen, die sich das Management der Informationssicherheit zertifizieren ließen, wuchs gegenüber dem Vorjahr um 40 Prozent. Aber der Anteil der Unternehmen und Behörden, die aus ihrem ISMS-Projekt einen stabilen ISMS-Prozess machen, ist leider relativ klein.	iso/iec 27001:2005;iso/iec 27001:2013;unified model	Rainer Rumpel	2011	Datenschutz und Datensicherheit - DuD	10.1007/s11623-011-0005-2		Robotics	-102.97193283102813	33.49648875254575	91660
18b651121137f760c68a43be29b82607e98ed948	editorial: innovative anwendungen in neuen netzen		"""Die fortschreitende Vernetzung durch leistungsfähige und globale Kommunikationsinfrastrukturen eröffnet in nahezu allen Bereichen und Branchen eine neue Dimension in der Anwendung von ΓΓ-Technologien. In Verbindung mit Konzepten wie Electronic Business, Network Computing, Data Warehouse und Multimedia entstehen neue Ansätze für die Entwicklung und Einführung innovativer Anwendungslösungen. Die Realisierung solcher Lösungen schließt neben der Auswahl geeigneter Technologien und Lösungsbausteinen auch die Veränderung oder zumindest die Anpassung von Geschäftsprozessen, Organisationsstrukturen und Abläufen ein. Es ist deshalb nicht überraschend, daß das Ausschöpfen neuer Technikpotentiale für innovative Anwendungslösungen sich längst nicht mehr auf die Frage nach der Auswahl der jeweils geeignetsten technischen Lösung beschränkt, sondern zunehmend die Umsetzbarkeit und Wirtschaftlichkeit einer Lösung in den Vordergrund rückt. Das vorliegende Themenheft soll zum einen einen Überblick zum Entwicklungsstand innovativer Anwendungslösungen am Beispiel ausgewählter Anwendungsfelder und Branchen geben, zum anderen aber auch die mit der Umsetzung oder Erprobung gemachten Erfahrungen aufzeigen. Es ist eine schwierige Aufgabe, für dieses Thema eine Auswahl von Beiträgen zusammenzustellen, die auf der einen Seite einen möglichst umfassenden Einblick in die Entwicklung von innovativen Anwendungslösungen geben und auf der anderen Seite repräsentativ für unterschiedlichste Branchen sind. Wir haben uns daher als Herausgeber dafür entschieden, solche Beiträge auszuwählen, die in der Mischung beides auf hohem Niveau anbieten. Dies wurde insbesondere durch die Auswahl von Autoren sichergestellt, die dies selbst und über die Institutionen bzw. die Firmen, die sie vertreten, gewährleisten. Im ersten Beitrag beschäftigt sich N. Diehl, N. Gerfelder, A. Held und L. Neumann mit den Möglichkeiten der mobilen Datenkommunikation. Sie beschreiben zunächst die grundlegenden Charakteristika mobiler Anwendungen, geben einen Überblick über mögliche Systemkonzepte und stellen repräsentative Anwendungsbeispiele für dieses Gebiet vor. Der zweite Beitrag wurde von W. Effelsberg und C. Hornung verfaßt und behandelt das Thema „Lehren und Lernen im Internet"""". Es werden verschiedene Anwendungsszenarien sowie Netzkonzepte für den Informationszugriff und die Kommunikation beschrieben. Dieser Beitrag enthält auch einen Ausblick auf die zu erwartende Entwicklung Internet-basierter Schulungsund Trainingssysteme. Der Beitrag von M. Zimmermann, W. Johannsen und R. Kreft beschäftigt sich mit der Infrastruktur, den Technologien und den Diensten für ein unternehmensweites Intranet. Es wird zunächst eine Schichtenarchitektur vorgestellt, und dann auf die Intranet-Dienste eingegangen. Dabei stehen Dienste zur Unterstützung von Telekooperation und Telepräsenz im Vordergrund, die als integrale Bestandteile von Anwendungen betrachtet werden können. Diese drei Beiträge sind stark technologieorientiert und die verschiedenen Anwendungsszenarien werden auch unter dem Aspekt von Machbarkeitsfragen aus einer Technologiesicht heraus diskutiert. Dagegen nehmen die nachfolgenden Beiträge stärker die Anwendersicht ein und beschäftigen sich vorwiegend mit den Fragen der Umsetzung, Vermarktung, Wirtschaftlichkeit, aber auch den Grenzen bei der Erprobung innovativer Lösungsansätze. Der Beitrag von J. Ewers behandelt Multimedia-Marketing für die Tourismusbranche. Dies stellt eine besondere Form des Electronic Commerce dar. Der Beitrag zeigt, welche kommerziellen und technologischen Randbedingungen erfüllt werden müssen, um eine erfolgreiche Einführung zu erreichen. Dabei Dr. Martin Bever studierte Informatik an der Universität Karlsruhe und promovierte 1985 am Lehrstuhl für Datenbanken und Informationssysteme. Seit 1986 ist er Mitarbeiter der IBM Deutschland Informationssysteme GmbH und war zunächst am IBM Research Center in San Jose tätig. Von 1990 bis 1996 leitete er den Bereich Telekooperation am Europäischen Zentrum für Netzwerkforschung der IBM in Heidelberg und übernahm anschließend die Leitung eines Internationalen Marketingprogramms zur Entwicklung innovativer Anwendungslösungen für den Gesundheitsbereich. Seit 1997 ist er als Project Executive im Bereich Business Process Outsourcing tätig."""	business process;e-commerce;eine and zwei;electronic business;gesellschaft für informatik;gunnar johannsen;ibm research;institut für dokumentologie und editorik;internet explorer;intranet;outsourcing;sie (file format);unified model;vhf omnidirectional range	Martin Bever;José L. Encarnação	1998	it+ti - Informationstechnik und Technische Informatik	10.1524/itit.1998.40.2.5	software engineering;embedded system;computer science	DB	-102.65990799183415	34.84752328760107	91894
4294177100922ad2d60de16d3947813e9e14de24	geschlechterstereotype in persona-beschreibungen	personas;nutzungszentrierter gestaltungsprozess;gender;talk	Im nutzungszentrierten Design werden Personas als zentraler Teil des Gestaltungsprozesses genutzt. Um zu untersuchen, welche Rolle Personas beim Fortschreiben bestehender Geschlechterstereotype spielen, wurden in einer empirischen Analyse 170 Persona-Beschreibungen hinsichtlich des dargestellten sozialen Umfelds, der Freizeitbeschäftigungen und der Technikkompetenz untersucht. Die Ergebnisse zeigen geschlechterstereotype Darstellungen auf der Dimension Wärme/Gemeinschaft. Diese werden diskutiert und es werden Empfehlungen für die Gestaltung mit Personas gegeben. 1 Personas zur Repräsentation von Nutzenden Gendergerechtigkeit spielt in der Forschung zu Human-Computer Interaction eine immer wichtigere Rolle (Breslin & Wadhwa, 2015; Grudin & Williams, 2013). Dabei ist die Berücksichtigung von Nutzerinnen und Nutzern mit ihren diversen Lebenslagen zentral (Marsden & Kempf, 2014). Die Persona-Methode ist eine Herangehensweise, die hier häufig als Werkzeug eingesetzt wird (Grudin, 2006; Nielsen, 2013; Pruitt & Adlin, 2006). In der Persona-Methode werden fiktive Repräsentanten von Nutzerinnen und Nutzern geschaffen. Personas werden im Rahmen des Gestaltungsprozesses als prototypische Stakeholder genutzt, um eine aktive Auseinandersetzung mit den Nutzerinnen und Nutzern, die Kommunikation zwischen Gestaltungsund Entwicklungsteam sowie zwischen Auftraggebenden und nehmenden zu unterstützen. Personas können im gesamten menschzentrierten Gestaltungsprozess eingesetzt werden und sowohl als formatives als auch als evaluatives Werkzeug eingesetzt werden (Nielsen, 2013). Der Einsatz von Personas birgt die Gefahr, dass unreflektiert Stereotype zum Einsatz kommen – wobei in einem gewissem Maße Stereotype in der Arbeit mit Personas unumgänglich sind (Turner & Turner, 2011). Die Gründe für die Anwendung von Stereotypen auf Personas sind vielfältig. In erster Linie handelt es sich hier um den Einsatz der I-Methodology (Bath, 2014a, 2014b; Oudshoorn, Rommes, & Stienstra, 2004) bzw. des fundamentalen GestalS. Diefenbach, N. Henze & M. Pielot (Hrsg.): Mensch und Computer 2015 Tagungsband, Stuttgart: Oldenbourg Wissenschaftsverlag, 2015, S. 113-122. Dieses Werk ist lizenziert unter der Creative Commons Attribution-NonCommercial-NoDerivatives 3.0 Lizenz. © 2015, Diefenbach, Henze, Pielot. Unauthenticated Download Date | 7/24/18 2:04 AM Geschlechterstereotype in Persona-Beschreibungen 2 tungsfehlers (Ritter, Baxter, & Churchill, 2014): Die Entwickelnden gehen von sich selbst aus und attribuieren die eigenen Vorstellungen, Herangehensweisen, Ziele etc. auf die Personas und konzipieren diese dann entweder als ihnen ähnlicher oder – entsprechend dem psychologischen Kontrasteffekt – als unähnlicher, als sie de facto sind. Auch andere Faktoren wie Zeitmangel oder Gruppenzugehörigkeiten fördern einen Rückgriff auf Stereotype bei Gestaltung und Einsatz von Personas (Marsden, Link, & Büllesfeld, 2014), ebenso eine wenig detaillierte Beschreibung von Personas (Nielsen, 2013). Als Lösung zur Vermeidung bzw. Reduzierung von sterotypen Beschreibungen im menschzentrierten Gestaltungsprozess gilt es in erster Linie, mit echten Nutzerinnen und Nutzern zu arbeiten (Buchmüller, Joost, Bessing, & Stein, 2011; Holtzblatt & Beyer, 2015; Ritter et al., 2014). Darüber hinaus gibt es eine Reihe von Herangehensweisen, um problematische Vergeschlechtlichungen in der Human-Computer Interaction zu entdecken, zu thematisieren oder zu vermeiden werden, z.B. das „Gender Extended Research and Development“ (GERD)-Modell (Draude, Maaß, & Wajda, 2014) Mind Scripting (Allhutter, 2012), geschlechterund intersektionalitätskritische Softwaregestaltung (Paulitz & Prietl, 2014), Diffractive Design (Bath, 2014a; Ernst, 2014), das intersektionale „Sanduhr-Modell“ (Lucht, 2014), die verschiedenen Möglichkeiten feministischer Interventionen in den Gestaltungsprozess (Rommes, 2014), die Reflective/Reflexive Methods (Bardzell & Churchill, 2011) etc. Einige Ansätze der Vermeidung von Geschlechterstereotypen fokussieren spezifisch auf den Einsatz von Personas (Marsden et al., 2014), nutzen Personas, um eine Reflexion von Geschlechterstereotypen zu unterstützen (Källhammer & Nilsson, 2012) oder gezielt dafür, die Anliegen beider Geschlechter im Gestaltungprozess von Software zu berücksichtigen (Burnett et al., 2014). Um ein weitergehendes Verständnis davon zu bekommen, welche Rolle Geschlechterstereotype in der Arbeit mit Personas spielen, wurde eine Untersuchung von im Einsatz befindlichen Personas durchgeführt. Im Folgenden wird zunächst der theoretische Hintergrund von Geschlechterstereotypen skizziert, dann wird die Untersuchung beschrieben, die Ergebnisse werden vorgestellt und diskutiert und Implikationen für den Gestaltungsprozess abgeleitet. 2 Geschlechterstereotype Geschlechterstereotype beinhalten Wissen darüber, welche Eigenschaften und Verhaltensweisen für Männer und Frauen ein einer Gesellschaft bezeichnend sind und bei ihnen vermeintlich zu beobachten sind (Kite, Deaux, & Haines, 2008). Als soziokognitive Strukturen haben Stereotype eine duale Struktur dahingehend, dass es sich einerseits um individuelles Wissen der jeweiligen Person handelt, andererseits um sozial geteiltes Wissen, das durch Kultur und zwischenmenschlichen Konsens hergestellt und verfestigt wird (Eckes, 2008). Die kognitive Komponente (der Stereotyp im engeren Sinne) geht einher mit einer emotionalen Komponente und einer Verhaltenskomponente. Der Dreiklang von geschlechtsbezogenen Stereotypen, Affekten und Verhaltensweisen, die in einen ungleichen sozialen Status von Männern und Frauen resultieren, wird als Sexismus bezeichnet (Swim & Campbell, 2003). Geschlechterstereotype sind häufig nicht bewusst und werden automatisch und ohne aktives 114 Nicola Marsden, Jasmin Link, Elisabeth Büllesfeld Unauthenticated Download Date | 7/24/18 2:04 AM Geschlechterstereotype in Persona-Beschreibungen 3 Zutun angewendet (Banaji & Hardin, 1996), d.h. sie entfalten ihre Wirksamkeit oft in Form von impliziten Assoziationen (Greenwald, McGhee, & Schwartz, 1998). Durch die duale Struktur von Geschlechterstereotypen ist es so, dass durch jeden Akt der Stereotypisierung der Stereotyp erneut konsensuell validiert, d.h. das vermeintliche Wissen über für Männer oder Frauen typische Eigenschaften und Verhaltensweisen wiederum fortgeschrieben wird. Hinsichtlich der Inhalte von Geschlechterstereotypen zeichnet die Forschung ein klares Bild: Frauen werden Eigenschaften zugesprochen, die eher auf der Dimension Wärme, Soziales oder Gemeinschaftsorientierung angeordnet sind. Merkmale, die häufiger Männern zugeordnet werden, sind auf der Dimension der aufgabenbezogenen Kompetenz, Instrumentalität oder Selbstbehauptung zu verorten (Fiske, Cuddy, & Glick, 2007), ein Ergebnis, welches interkulturell und auch für Deutschland bestätigt wird (Ebert, Steffens, & Kroth, 2014; Eckes, 2002). Neben diesen Globalstereotypen von Männern und Frauen gibt es Substereotype, d.h. Globalstereotype sind strukturell heterogen und setzen sich aus einer Reihe in sich homogener Kategorien zusammen. So werden zum Beispiel arbeitende Mütter und arbeitende Väter sehr unterschiedlich wahrgenommen: Arbeitende Mütter werden als kompetenter eingestuft, verlieren aber auf der Dimension Wärme, die mit Mütter und Hausfrauen verbunden ist. Arbeitende Väter hingegen werden als eine erfolgreiche Kombination in den Dimensionen Wärme und Kompetenz wahrgenommen (Cuddy, Fiske, & Glick, 2004). Für die Globalstereotype, mit denen Frauen eher Eigenschaften der Dimension Wärme/Gemeinschaftsorientierung und Männer eher Kompetenz/Instrumentalität zugeschrieben wird, hat sich gezeigt, dass sie über die Zeit sehr stabil sind. Allerdings hat sich in den letzten Dekaden die von Frauen über sich selbst berichtete Instrumentalität kontinuierlich erhöht – die selbstberichtete Expressivität von Männern bleibt dabei gleichzeitig unverändert (Twenge, 1997, 2009). Für die Globalstereotype gibt es zwei Erklärungsansätze: Die Theorie der sozialen Rollen (Eagly, Wood, & Diekman, 2000) zeigt auf, dass Menschen davon ausgehen, dass Frauen und Männer diejenigen Merkmale aufweisen, die für ihre jeweiligen sozialen Rollen, insbesondere für ihre Familienund Berufsrollen, typisch sind. Menschen verallgemeinern dann vom beobachteten Rollenverhalten unmittelbar auf Eigenschaften der Rolleninhabenden und vernachlässigen dabei den Einfluss der verhaltenswirksamen Rollenanforderungen. Ergänzend werden die Globalstereotype durch das Stereotypinhaltsmodell erklärt (Fiske, Cuddy, Glick, & Xu, 2002). Es besagt unter anderem, dass der Status einer Gruppe die Einordnung auf der Kompetenzdimension bestimmt, und zwar dahingehend, dass Gruppen mit hohem Status als kompetent eingeschätzt werden. Die Einordnung einer Gruppe auf der Wärmedimension dagegen wird durch die Art der Interdependenz bestimmt, und zwar so, dass kooperative Gruppen als warm bzw. als unbedrohlich für die eigenen Gruppenziele und kompetitive Gruppen als kalt bzw. als bedrohlich eingeschätzt werden. Es gibt eine Vielzahl von Methoden zur Messung von Stereotypen (Eckes, 2008; Kite et al., 2008). Um medial vermittelte stereotype Darstellungen der Geschlechter zu untersuchen, werden meist inhaltsanalytische Verfahren angewendet (Collins, 2011; Rudy, Popova, & Linz, 2011), sie zeigen, dass Frauen in der medialen Vermittlung eher unterrepräsentiert sind, untergeordnet, in stereotyp femininen Rollen oder negativ dargestellt werden (Collins, 2011). Bisher wurden Persona-Beschreibungen noch nicht als mögliche Kristallisationspunkte von Geschlechterstereotypen in den Blick genommen. Diese Forschungslücke sollte mit l t r t r t i r r i 115 Unauthenticated Download Date | 7/24/18 2:04 AM Geschlechterstereotype in Persona-Beschreibungen 4 der vorliegenden Untersuchung geschlossen werden, vor allem vor dem Hintergrund dass eine geschlechterstereotype Darstellung an dieser Stelle den gesamten Gestaltungsprozess beeinflussen kann. Eine Forschungsfrage lautet e	baxter (robot);die (integrated circuit);download;eine and zwei;es evm;gesellschaft für informatik;human–computer interaction;institut für dokumentologie und editorik;intentionally blank page;internet explorer;jasmin;medial graph;sie (file format);shin megami tensei: persona 4;stereotype (uml);unified model;v-model;vhf omnidirectional range	Nicola Marsden;Jasmin Link;Elisabeth Büllesfeld	2015			persona;art;performance art	AI	-107.73331748193307	32.73575802773555	93358
2b0a47556b9e8f7f40f376a66e6eb778eb40f8bf	ein mehrseitig sicheres abrechnungsystem für wireless lan hotspots		In jüngster Zeit nimmt die Verbreitung öffentlicher WLAN Hotspots immer mehr zu. Bisherige Systeme berücksichtigen jedoch den berechtigten Wunsch der Nutzer nach Schutz ihrer personenbezogenen Daten nur unzureichend. Wir stellen daher ein mehrseitig sicheres Abrechnungssystem vor, welches eine anonyme HotspotNutzung ohne aufwändige Authentifizierung ermöglicht. Hierdurch wird sowohl die Erstellung von Nutzerprofilen erschwert als auch ein Roaming zwischen Hotspots unterschiedlicher Anbieter vereinfacht.	eine and zwei;hotspot (wi-fi);vhf omnidirectional range;wireless access point	Stephan Groß;Sabine Lein;Sandra Steinbrecher	2005			wireless;computer network;business	Mobile	-103.18662537311376	37.200226518949975	94619
0cc5929a8d0c4b29bfd30022fdebc7c97c572034	solution of nonlinear systems of equations by an optimal projection method	equation non lineaire;ecuacion no lineal;systeme equation;projection method;local convergence;optimal control;sistema ecuacion;methode projection;resolucion ecuacion;equation system;metodo proyeccion;nonlinear equation;resolution equation;equation resolution;nonlinear system;system of equations;non linear equation;algoritmo optimo;algorithme optimal;optimal algorithm	We consider a block version of the Nonlinear Projection Method under an optimal control. This method is applied to the solution of systems of equations where the number of equation is less than or equal to the number of unknowns. A local convergence theorem is proved. We present a numerical comparison with the cyclic Nonlinear Projection Method. Wir betrachten eine Block-Version des Nichtlinearen Projektions-Verfahrens mit einer optimalen Kontrolle. Dieses Verfahren wird zur Lösung von Gleichungssystemen verwendet, bei denen die Gleichungsanzahl kleiner oder gleich der Anzahl der Unbekannten ist. Ein lokaler Konvergenzsatz wird bewiesen. Ein numerischer Vergleich mit dem zyklischen Nichtlinearen Projektions-Verfahren wird angestellt.	eine and zwei;local convergence;nonlinear system;numerical analysis;optimal control;optimal projection equations;projection method (fluid dynamics)	José Mario Martínez	1986	Computing	10.1007/BF02252734	local convergence;system of linear equations;mathematical optimization;mathematical analysis;optimal control;nonlinear system;calculus;dykstra's projection algorithm;control theory;fundamental resolution equation;mathematics;projection method;algebra	HPC	-96.68897575097122	35.86344146307495	94910
1de52b3a4f78902dc0ca1ab5297881f25e31eef3	datenschutz compliance in sozialen netzwerk anwendungen		Die Bedeutung von Sozialen Netzwerk Anwendungen im Internet ist in den letzten Jahren kontinuierlich gestiegen. Die bekanntesten Anbieter Facebook und MySpace ziehen nach eigenen Angaben weltweit jeden Monat jeweils weit mehr als 100 Millionen Besucher auf Ihren Webseiten an und können immer mehr Werbegelder für sich gewinnen. Auch der Web-Informationsdienst Alexa zählt Soziale Netzwerk Anwendungen seit einigen Jahren kontinuierlich unter die Top Internet Seiten. Umfragen unter Internetnutzern zeigen auf, dass Soziale Netzwerkdienste im Internet inzwischen häufiger genutzt werden als kommerzielle Dienste wie z.B. das Online-Einkaufen oder Online-Banking. Begleitet wird dieses Phänomen mit einem gestiegenen öffentlichen Interesse an dem Schutz der Privatsphäre der Anwender solcher Applikationen und dem Ruf nach Einführung technischer Datenschutzlösungen um bestehende Datenschutzgesetze zu erfüllen. Eine Anforderung, bei der sich Anbieter der Anwendungen schwer tun, da existierende Datenschutzlösungen momentan noch an Grenzen stoßen, die hier aufgezeigt werden sollen.	die (integrated circuit);eine and zwei;gesellschaft für informatik;internet explorer;online banking;tun (product standard);unified model	Stefan Weiss	2010	Datenschutz und Datensicherheit - DuD	10.1007/s11623-010-0126-z	internet privacy;computer science	OS	-103.79961485029493	36.78435977467627	95500
07ab1330a9473eebcca9fe9d39fbd8805f548fd1	soa-frontends: serviceorientierte ansätze helfen bei der konsolidierung von client-landschaften		Die Konsolidierung der Benutzeroberflachen ist der nachste logische Schritt in der Optimierung von Enterprise-Landschaften. Um die dafur benotigte hohere Client-Flexibilitat zu erreichen, bedarf es fachlich geschnittener Frontend-Komponenten, die das Zusammenspiel mit dem Rest der Anwendungslandschaft erleichtern. Ziel ist es, diese Frontend-Komponenten uber Kanal- und Anwendungsgrenzen hinweg wiederzuverwenden. Dadurch konnen auch im Frontendbereich Synergien genutzt werden, die sich positiv sowohl auf Realisierungs- als auch auf Wartungskosten auswirken. Wesentliche Prinzipien, die dieser Losung zugrunde liegen, lassen dabei Analogien zu serviceorientierten Architekturen (SOA) erkennen.	oracle soa suite	Werner Steck	2010	Wirtschaftsinformatik & Management	10.1007/BF03248269		OS	-103.97494585093128	32.67445718786097	95900
18ac8bf93dc83b28d6b849dd418caee96e758d14	die strafbarkeit von berufsgeheimnisträgern nach § 203 stgb beim cloud computing		Ob Berufsgeheimnisträger sich beim IT-Outsourcing nach § 203 StGB strafbar machen, wird bereits seit Jahren diskutiert, beispielsweise im Zusammenhang mit der Nutzung des externen Anwaltssekretariats oder der professionellen Aktenarchivierung, und gilt immer noch als ungelöstes Problem. Bei der Nutzung von Cloud Computing stellen sich teilweise parallel gelagerte, teilweise weitergehende Fragen. Im Folgenden wird insbesondere untersucht, ob Berufsgeheimnisträgern bereits de lege lata der Weg offen steht, Geheimnisse „in die Wolke“ zu verlagern, ohne hierbei ein Strafbarkeitsrisiko einzugehen, ob der am 25.5.2016 in Kraft getretenen EU-Datenschutz-Grundverordnung in diesem Kontext Bedeutung zukommt und welche Lösungsmöglichkeiten de lege ferenda zu begrüßen wären.1	cloud computing;outsourcing	Tamina Preuß	2016	Datenschutz und Datensicherheit - DuD	10.1007/s11623-016-0707-6	computer science;internet privacy;cloud computing	HPC	-102.23096807932745	36.07169696216683	95940
b5f6f601f49ea602fbde2eeb07396e32f5fdd80e	performance von akademischen spinoff-gründungen in österreich	academic spinoffs;control group;akademische grundungen;kontrollgruppenanalyse;academic start ups;austria;firm performance;control group analysis	Vergleicht man akademische Spinoff-Grundungen mit anderen forschungs- und wissensintensiven Grundungen, zeigt sich, dass Spinoff-Grundungen signifikant forschungs- und wissenschaftsorientierter sind. Dies druckt sich in hoherer Forschungsintensitat, hoherer Patentierneigung und intensiveren Kontakten zur Wissenschaft aus. Spinoff-Grundungen besetzen ein besonders forschungsintensives Segment innerhalb der forschungs- und wissensintensiven Branchen und stellen eine Verbindung zwischen Wissenschaft und Markt her. In diesemPapier wird fur Osterreich untersucht, ob sich die Performance von Spinoff-Grundungen von der anderer Grundungen in den forschungs- und wissensintensiven Wirtschaftszweigen unterscheidet. Okonometrische Modellrechnungen zeigen, dass Spinoff-Grundungen hinsichtlich Umsatz- und Beschaftigungswachstum nicht erfolgreicher sind als andere Grundungen in den forschungs- und wissensintensiven Branchen.		Jürgen Egeln;Helmut Fryges;Sandra Gottschalk;Christian Rammer	2009	AStA Wirtschafts- und Sozialstatistisches Archiv	10.1007/s11943-009-0072-0	mathematics;scientific control;statistics	NLP	-107.14635794053338	33.00463424891208	96423
da738ff26bcdc0dc2c7456b1df961a217e0f3d60	verlustlose datenkompression auf grundlage der burrows-wheeler-transformation	burrows wheeler transform	Die verlustfreie Datenkompression auf Grundlage der Burrows-Wheeler-Transformation ist in den letzten Jahren aufgrund Ihrer Effizienz und bemerkenswerten Eleganz auf ein großes Interesse gestoßen. Selbst einfache Implementierungen erreichen Geschwindigkeiten und Kompressionsraten von bekannten kommerziellen Pr ogrammen. Die Burrows-Wheeler-Transformation basiert auf einer Permutation von Eingabedaten, durch welche Zeichen mit ähnlichem Kontext nahe beieinander angeordnet werden. Im vorliegenden Artikel wird das Verfahren der Transformation sowie der Rücktransformation erläutert und zusammen mit einer typischen Implementierung vorgestellt. ________________________________________________________________________	burrows–wheeler transform	Jürgen Abel	2003	Praxis der Informationsverarbeitung und Kommunikation	10.1515/PIKO.2003.140	computer science;burrows–wheeler transform	DB	-105.94661066182492	32.585055688214176	96451
08411736f46b224c38f833e30995932eeb2919ea	wikipedia als methode und gegenstand der lehre	information management	Wikipedia ist eine erfolgreiche Wiki-Anwendung, eine offene Online-Enzyklopadie mit insgesamt mehreren Hunderttausend Autoren. Der Beitrag beschreibt Moglichkeiten und Grenzen sowie erste Erfahrungen beim Einsatz von Wikipedia in der Lehre. Es stehen dabei weniger Wissensvermittlung und Problemlosung durch das Lexikon im Vordergrund, sondern mehr die Aspekte der Veroffentlichung und Zusammenarbeit. Der Autor setzte Wikipedia in Lehrveranstaltungen der PH Weingarten ein. Die Studierenden schrieben wahrend und auserhalb des Unterrichts an bereits vorhandenen Beitragen mit. Der Einsatz von Wikipedia in der Lehre lohnt offenkundig in verschiedener Hinsicht: Die Studierenden entlassen ihre Erkenntnisse in die Welt, um sie – ahnlich wie in einer Scientific Community – begutachten und korrigieren zu lassen, und sie erproben Konzepte der E-Collaboration im kleinen, kontrollierbaren wie im grosen, unkontrollierbaren Raum. Nicht zuletzt finden sie in Wikipedia einen faszinierenden und sich standig verandernden Gegenstand.	wikipedia	Oliver Bendel	2006	HMD - Praxis Wirtschaftsinform.		computer science;knowledge management;electrical engineering;information management	Robotics	-102.89022041024083	34.001965011035445	96685
8bf9fa2e34d3bb0f2d3d0964a1278bed463d3232	maschinen, die den menschen verstehen - it-methoden und it-standards bei der gestaltung mobiler sprachdialogsysteme		Sprachgestützte Datenerfassungstechnologien auf Basis verschiedener moderner IT-Methoden sind praxistauglich und bieten eine Reihe von Vorteilen. Eine benutzergerecht gestaltete Dialogschnittstelle erhöht die Akzeptanz und die Datenqualität, Sprachtechnologie reduziert den Erfassungsaufwand und macht die Konzentration auf den Arbeitsinhalt möglich. 1 Sprachtechnologie für mobile Anwendungen Mobiles Arbeiten gehört für immer mehr Menschen zum Alltag. Sprache kann dabei einen wichtigen Beitrag leisten, um mobile Datenerfassung sicherer, bequemer und effizienter zu machen. Vor dreißig Jahren war für uns der sprechende Bordcomputer aus dem Film Raumschiff Enterprise sensationelle Science Fiction. Heute betrachten wir mobiles Telefonieren und die Sprachkommunikation mit Maschinen als ebenso natürlich wie den Plausch mit dem netten Kollegen. Sprachanwendungen, wie z. B. Siri, bieten die Möglichkeit, schnell bestimmte Funktionen auf unserem iPhone aufzurufen. Mehr und mehr Geräte und Softwareanwendungen lassen sich per Sprache bedienen. Dennoch scheint es, dass die meisten Einsatzmöglichkeiten von Sprache (in der Industrie und Wirtschaft jenseits von Consumer-Anwendungen) noch brach liegen. Sprachgesteuerte Software ermöglicht die bequeme Bedienung eines Gerätes und gibt Augen und Hände für andere Aufgaben frei. Die Vorteile einer sprachgestützten Maschinen-Mensch-Kommunikation sind: • Sprechen ist für die meisten Menschen einfacher als tippen und lesen • Sprachsteuerung kann gegebenenfalls auf Anzeigeund Tastaturmedien verzichten. Die notwendige Hardware kann also handlicher, leichter und billiger werden	eine and zwei;es evm;gesellschaft für informatik;internet explorer;maschinen krieger zbv 3000;siri;unified model;vhf omnidirectional range	Dirk Nordwig	2014			verstehen;psychoanalysis;philosophy		-105.35491984223592	34.85762129027408	96837
ac58da859f730a1797a6a6d2125be4e8652499ed	segmentierung und volumetrie der hirnventrikel mit mrt-datensätzen		Gehirn und Ruckenmark sind von einem mit Liquor gefullten Flussigkeitskissen umgeben, das als sogenannter externer Liquorraum mit dem Ventrikelsystem, dem inneren Liquorraum, kommuniziert. Bei unterschiedlichen Krankheiten kann es zu Veranderungen des Volumens der internen und externen Liquorraume kommen. Das intracerebrale Ventrikelvolumen ist daher ein wichtiger Faktor bei der Diagnose und Behandlung verschiedener Hirnerkrankungen. Obwohl diese komplexe Problematik schon lange bekannt ist, gibt es bis heute keine objektivierbare, systematische Bestimmung des Volumens der Liquorraume.	ferranti mrt	Thomas Schindewolf;Uwe Frese;Joachim Meissner	1999				NLP	-104.95952509745861	32.71840613842343	97831
9a9806a51d87049d95db89cfd0c05b5c117da115	on the generation of random numbers with at choice distribution	random process;random numbers;statistical distribution;poisson distribution	This paper deals with a method supplying truly random numbers in cycle-free sequences of any length and with a specified statistical distribution as desired. The method is based on an appropriate randomness-conserving rearrangement of truly random numbers delivered by a random process. Here the radioactive decay of nuclei is employed as the random process that produces a basic set of truly random numbers with a Poisson distribution. However, any other random process can be used with the method. The paper contains the theory and some essential points of programming for a computer. Die Arbeit behandelt eine Methode zur Erzeugung echter Zufallszahlen mit einer gewünschten statistischen Verteilung in zyklenfreien Folgen beliebiger Länge. Die Methode beruht auf einer geeigneten Umordnung von echten Zufallszahlen aus einem Zufallsprozeß unter Erhaltung der Zufälligkeit. Hier wird der radioaktive Kernzerfall als Zufallsprozeß benutzt. Er liefert eine Grundmenge von echten Zufallszahlen mit einer Poisson-Verteilung. Jedoch kann genausogut jeder andere Zufallsprozeß der behandelten Methode zugrundegelegt werden. Die Arbeit enthält die Theorie und einige wesentliche Punkte zur Programmierung.	die (integrated circuit);eine and zwei;institut für dokumentologie und editorik;randomness;stochastic process	W. Lünow	1974	Computing	10.1007/BF02268389	independent and identically distributed random variables;random variate;probability distribution;random graph;stochastic process;combinatorics;random permutation;discrete mathematics;random field;multivariate random variable;random element;convergence of random variables;random compact set;mixture distribution;central limit theorem;degenerate distribution;random function;stochastic simulation;gaussian process;point process;mathematics;poisson distribution;convolution random number generator;statistics;probability integral transform	Theory	-97.2947678274442	37.27186825534318	97938
a7121dc42e63a93563de13fb4b9b97c1d0e36848	weltbilder und bilder der informatik		In der Einleitung wurde der Weltbildbegriff ganz allgemein beschrieben, hier nun wird er für die genannten Ziele der Untersuchung operationalisiert. Es erscheint plausibel, dass Technik- und Menschenbilder dafür relevant sind, auch das Bild der Informatik selbst. Erklärungsbedürftig könnte sein, dass wir auch die Wirklichkeitsauffassung der Studierenden für wichtig erachtet haben, und zwar deshalb, weil die Informatik Ausschnitte der Realität erfasst, um sie mit einer erwünschten Problemlösung zu verändern. Die Antworten der Studierenden zu all diesen Fragestellungen sind aufschlussreich, auch weil sie in nicht unmittelbar erwartbarer Weise mit den Fragen der später behandelten Sekundärevaluation, wie Diversity, Geschlecht und Ethik zusammenhängen.	gesellschaft für informatik;internet explorer;sie (file format);unified model	Britta Schinzel	2013	Informatik-Spektrum	10.1007/s00287-013-0694-z	world wide web;computer science;performance art	OS	-105.34827776468359	34.825033054506385	97987
fe35d205eee031ee72ab8f8ce4a97db8d0453630	information sharing und wissensaustausch in unternehmen		Zum Thema „Information Sharing“ gibt es auffallend wenig Bücher und Spezialliteratur, obwohl die Wichtigkeit in der gesamten Literatur zum Wissensmanagement und zum organisatorischen Lernen uneingeschränkt betont wird. Ziel des vorliegenden Beitrags ist ein Überblick, welcher eine Bewertung des aktuellen Wissensstandes erlaubt. Nach einer einführenden Begriffsklärung wird die Thematik anhand ausgewählter Modelle näher dargestellt. Ein wesentliches Auswahlkriterium für die Modelle war die Verbindung zu empirischen Untersuchungen. Abgerundet werden die Ausführungen durch eine zusammenfassende Bewertung und einen Ausblick. Durch die empirische Abstützung der Ergebnisse soll die Zusammenführung von Teilergebnissen und in der Folge eine Grundlage für weitere integrative Studien geschaffen werden 1. Einführung und Begriffsklärung „Der Fortschritt lebt vom Austausch des Wissens.“ [Be95] Durch die veränderte Situation in Gesellschaft und Wirtschaft geht es um eine höhere Verfügbarkeit von Wissen, das mittels Kommunikationsprozesse und dem kontinuierlichen Willen zum Lernen erreicht werden kann. Der Wandel von der Industriegesellschaft zur Wissensund Informationsgesellschaft weist dabei auf eine soziokulturelle Transformation hin. Konzepte wie TQM und BPR übernahmen bis zur Mitte der 90er Jahre die Optimierung der „hard-facts“, doch die langfristigen suboptimalen Erfolge zeigten [GF98] , dass in den „soft-facts“, den unternehmenskulturellen Aspekten wie z. B. Change Management, Teambildung und Lernkonzepte [NF98] , weiteres Potential verborgen ist. Gesucht waren ab diesem Zeitpunkt nicht leicht zu kopierende Diversifikationsfaktoren, die man schließlich in den Köpfen der Mitarbeiter in Form von Ideen, Wissen und Kreativität fand. Die Leitbegriffe in diesem Umfeld sind Daten, Informationen und Wissen. Die Vielfalt der Verwendung dieser Begriffe und ihre Interdisziplinarität lassen keine vollständige oder endgültige Klassifikation zu. Wegen seiner alltäglichen Verwendung scheint der	citeseerx;eine and zwei;internet explorer;triple des;unified model	Franz Lehner	2003			history;performance art	OS	-101.52178069136814	34.87208932565423	98083
aa5a912f5c4f57e00ac9a2ab0d29c1d4cb0c76e1	exponential spline interpolation		Piecewise cubic polynomial spline interpolation [3] or smoothing [4] often gives undesirable inflexion points. We describe a spline interpolation method that allows to avoid these inflexion points and contains cubic splines as special case. The method is a generalization of the work in [2]. The proof of the theorem motivating the use of exponential splines is simplified. An ALGOL procedure is presented that allows to mix piecewise cubic and exponential spline interpolation suitably. Interpolation [3] oder Glättung [4] von Daten mittels Splinefunktionen dritten Grades ergeben häufig unerwünschte Wendepunkte. Wir beschreiben eine Methode zur Spline-Interpolation, die es erlaubt, solche Wendepunkte zu vermeiden und die kubische Polynome als Speziaflall enthält. Das Verfahren in [2] wird verallgemeinert. Der Beweis, der die Verwendung von exponentiellen Splines motiviert, wird vereinfacht. Eine ALGOL-Prozedur wird angegeben, die es gestattet, kubische Polynome und Exponentialfunktionen bei der Spline-Interpolation geeignet zu kombinieren.	algol;cubic function;eine and zwei;polynomial;smoothing;spline (mathematics);spline interpolation;time complexity	Helmuth Späth	1969	Computing	10.1007/BF02234771	spline interpolation;spline;interpolation;mathematical optimization;mathematical analysis;discrete mathematics;perfect spline;smoothing spline;monotone cubic interpolation;interpolation;polynomial interpolation;cubic hermite spline;hermite spline;bicubic interpolation;mathematics;thin plate spline;polyharmonic spline;linear interpolation;nearest-neighbor interpolation;multivariate interpolation;m-spline;box spline	Graphics	-96.65336132312123	35.9100811439643	98989
34b677776e4fe8cd78451ec57b6b294a3cf87434	what is a vpn?		Bitte stellen Sie eine Verbindung zum VPN nur dann her, wenn Sie sich nicht im Netzbereich (WLAN/Institutsnetz) der TU Clausthal befinden. Das VPN läuft ausschließlich im „Full-Tunnel“-Modus. Es wird nach dem Start der VPNVerbindung der gesamte Datenverkehr über die VPN-Infrastruktur der TU Clausthal geleitet. Damit werden auch ihre übrigen privaten Daten über die Server der TU Clausthal gesendet.	eine and zwei;sie (file format);virtual private network;zentralblatt math	Perry B. Gentry	2001	Inf. Sec. Techn. Report	10.1016/S1363-4127(01)00103-0		DB	-104.50294912287342	36.22238780188268	99298
7b8b68c963886446c38db3f98128ced2dcf82ecc	coordinating autonomous problem solvers: the 2 dimensions of nested negotiations	004 datenverarbeitung;informatik			Stefan Kirn;Gunter Schlageter	1992			combinatorics;mathematics;algorithm;algebra	Robotics	-95.31764390306824	34.1863054527151	99648
eacc869ba66d016dd1ea8d4379dbbc0a6b93e778	konzeption und entwicklung eines genehmigungsmanagements für kmu unterstützt durch die augmented reality		Die Augmented Reality (AR) ist ein spannender Bereich für die Erkennung von Objekten, ohne das weitere Maßnahmen des Anwenders benötigt werden. Dieses Verfahren ist nicht wirklich neu, da schon in den 1990er Jahren viele Artikel zu diesem Thema veröffentlicht wurden. Jedoch erfährt die AR erst seit einigen Jahren ein steigendes Interesse. Viele Anwendungen insbesondere mobile Applikationen verwenden AR-Ansätze. Für die betriebliche Umweltinformatik spielt die AR bisher jedoch kaum eine Rolle. In diesem Beitrag wird deshalb die Anwendbarkeit von AR-Ansätzen im Kontext der betrieblichen Umweltinformatik analysiert und eine Anwendung im Anwendungsfeld des Genehmigungsmanagements von Anlagen nach dem BundesImmissionsschutzgesetz (BImSchG) prototypisch umgesetzt.	augmented reality;citeseerx;eine and zwei	Patrick Piltz;Volker Wohlgemuth	2015			computer graphics (images);augmented reality;computer science	HCI	-106.51811392455878	32.71842809805077	100059
d408fcdae1b445f5d4a7a0bd7ae7fb9ec1aa6bc2	trustee - beratung beim kauf von technischen produkten		Selbstberatung am Rechner beim Kauf eines technischen Produktes ist durch die Informationsvielfalt des Internets möglich, aber auch zeitaufwändig, da die benötigten Informationen auf vielen Webseiten verstreut zu finden sind. Möchte man die Produktwahl insbesondere auf einen bestimmten Anwendungszweck ausrichten, so sind vor allem technischen Bedingungen bzgl. der Produkte zu ermitteln. Der Beratungsvorgang lässt sich durch gezielte Informationsextraktion aus dem Internet beschleunigen. Am Beispiel von Digitalkameras zeigen wir die notwendigen Schritte auf: Extraktion von Eigenschaften der Kameras, von Produktinstanzen und -meinungen sowie Diagnose von technischen Eigenschaften bzgl. eines Anwendungszweckes. Allen Verfahren gemeinsam ist eine möglichst flache explizite Wissensrepräsentation, umWartungsprobleme von Wissensbasen zu umgehen.	citeseerx;eine and zwei;internet explorer;internets;vhf omnidirectional range	Sebastian Schmidt;Herbert Stoyan;Bernd Ludwig	2007			art;performance art	OS	-104.41675124481952	35.68042363021869	100530
c320ec3b7519efc9a91359b90471a338eaf7aee0	bringt die neue norm iec 62271-200 mehr sicherheit für die betreiber von schaltanlagen?	international electrotechnical commission	Die International Electrotechnical Commission (IEC) hat die Normengruppe fur Hochspannungsschaltgerate und Schaltanlagen in eine Nummerngruppe zusammengefasst. Gleichzeitig wurde die Norm IEC 62271-200 (alt IEC 60298) neu aufgelegt. Daraus entstand eine Unsicherheit um die Gultigkeit von Produkten, die nach alter Norm gepruft waren. Der Artikel beschreibt die neue Gliederung der Normengruppe, die wichtigsten Anderungen, Anwendungsbereich und Gultigkeit der neuen Norm IEC 62271-200. Weiters werden das Risiko von Storlichtbogen und Moglichkeiten zur Optimierung von Sicherheit fur das Bedienpersonal und Verfugbarkeit aufgezeigt.		R. Schmidt;U. Samitz	2007	Elektrotechnik und Informationstechnik	10.1007/s00502-007-0490-z	computer science	Theory	-103.03211753490146	34.629368670776664	100694
5f6b08eb6a06b3ad4163623daebdd42703044d3a	stellen die ingenieurwissenschaften noch den karriereweg für soziale aufsteiger dar?		Die Ingenieurwissenschaften sind der traditionelle Weg für soziale Aufsteiger. Diese Nachwuchsquelle ist auf dem Wege, deutlich  nachzulassen. Gründe sind die soziale Selektivität des Bildungssystems, insbesondere für Kinder von Migranten. Hinzu kommen  die gestiegenen Kosten für das Studium und die unsicheren Berufsperspektiven.  		Michael Hartmann	2008		10.1007/978-3-540-89609-8_19		NLP	-104.3254375255876	33.20153534674117	101073
1c902113966e020db5057157f32d5eeb6dd2bf3f	implementation of defect correction methods for stiff differential equations	ordinary differential equation;differential equation;defect correction	There is a large gap between the theoretical results about iterated defect corrections (IDeC) and practical implementations of IDeC methods for stiff systems. This paper tries to close this gap by providing general principles which are essential for the construction of efficient IDeC codes. Numerical results gathered with one particular IDeC based experimental code furnish evidence of the inherent power of the defect correction concept in the context of stiff systems of ordinary differential equations. Zwischen den theoretischen Resultaten über die iterierte Defektkorrektur (IDeC) und praktischen Implementierungen von IDeC-Verfahren für steife Differentialgleichungen klafft eine beträchtliche Lücke. Die vorliegende Arbeit versucht diese Lücke zu schließen, indem allgemeine Konstruktionsprinzipien für IDeC-Programme angegeben werden. Die im IDeC-Prinzip potentiell vorhandenen Möglichkeiten kommen in numerischen Resultaten zum Ausdruck, die mit einem Experimentierprogramm zur Lösung steifer Differentialgleichungen gewonnen wurden.	code;eine and zwei;iteration;software bug;stiff equation	Christoph W. Ueberhuber	1979	Computing	10.1007/BF02252129	l-stability;ordinary differential equation;mathematical optimization;mathematical analysis;calculus;mathematics;differential equation;quantum mechanics	SE	-96.97057319665616	34.09777853389176	101081
0beceb90e0d99becd91c9b14f8b661a8c18c3d82	zur benutzbarkeit der ausweisapp2		Die Akzeptanz und Nutzung der Online-Ausweisfunktion des deutschen Personalausweises liegt hinter den Erwartungen zurück. Sie verlangte in der Vergangenheit vom Anwender den Einsatz der AusweisApp, die eine Reihe von Usability-Schwächen zeigt. Aus diesem Grund wurde bei der Neuentwicklung des Nachfolgers ─ der AusweisApp2 ─ auf den frühzeitigen und stetigen Einbezug des Anwenders geachtet. Im Rahmen von entwicklungsbegleitenden Usability-Untersuchungen konnten so frühzeitig Schwächen identifiziert und für die finale Version der AusweisApp2 eliminiert werden. Es zeigt sich jedoch auch, dass schwerwiegende Usability-Schwächen erst in der Interaktion des Gesamtsystems (Personalausweis, Kartenleser, AusweisApp2, Browser, Diensteanbieter) zum Vorschein treten und nicht durch die AusweisApp2 allein, sondern nur in der Betrachtung des Gesamtsystems zu lösen sind.	eine and zwei;sie (file format);usability	Jörg Willomitzer;Andreas Heinemann;Marian Margraf	2016		10.18420/muc2016-ws03-0002		Crypto	-104.64900130291564	33.70181532754806	101085
114076a5b6ff803e92e0ef03cb906cf268f2d07b	the construction of cubature formulae by continuation	equation non lineaire;homotopie;ecuacion no lineal;representation graphique;cubature formula;multiple integral;integracion numerica;integral multiple;representacion grafica;homotopia;methode continuation;homotopy;formula cubicacion;resolucion sistema ecuacion;resolution systeme equation;triangulacion;numerical integration;triangulation;equation system solving;continuation method;system of equations;non linear equation;integration numerique;formule cubature;integrale multiple;graphics	A cubature formulaQ is an approximation of ann-dimensional integralI. Q is exact for the space spanned by the polynomialsf 1, ...,f d if it verifies the system of equations: $$Q[f_i ] = I[f_i ] i = 1,...,d.$$ The unknowns are knots and weights of the cubature formula. We suppose that there are as many unknowns as equations. For searching solutions to this system, we construct a family of systems depending continuously on a parametert: $$Q[f_i (t)] = I[f_i (t)] i = 1,...,d,$$ coinciding with the previous system fort=1 and whose solutions att=0 are easily computed. The solution curves originating from these solutions are followed numerically and may yield a solution fort=1. Eine KubaturformelQ ist eine Approximation für einn-dimensionales IntegralI. Q ist exakt für den von den Polynomenf 1, ...f d aufgespannten Vektorraum, wenn $$Q[f_i ] = I[f_i ] i = 1,...,d.$$ Die Unbekannten sind die Knoten und Gewichte der Kubaturformel. Wir nehmen an, daß es soviele Unbekannte wie Gleichungen gibt. Zur Bestimmung von Lösungen dieses Systems konstruieren wir eine Familie von Systemen, die stetig von einem Parametert abhängt: $$Q[f_i (t)] = I[f_i (t)] i = 1,...,d,$$ die fürt=1 mit dem ersten System zusammenfällt und fürt=0 eine einfach zu bestimmende Lösungsmenge hat. Die Lösungszweige, die in jeder Lösung dieser Menge beginnen, werden numerisch verfolgt und können eine Lösung fürt=1 liefern.	approximation;continuation;die (integrated circuit);eine and zwei;internet explorer;numerical analysis;numerical integration	Pierre Verlinden;Ann Haegemans	1990	Computing	10.1007/BF02247880	mathematical analysis;calculus;mathematics;geometry;multiple integral	Theory	-96.50639900005906	35.894968008541525	101139
efb4e37e3ef661467f11b919c83cd71a4bc2a12a	a class of simple stochastic online bin packing algorithms	bin packing problem;small deviation;online algorithm;bin packing;approximate solution;probability distribution;performance ratio	In the one-dimensional bin packing problem a list ofn items has to be packed into a minimum number of unit-capacity bins. A class of linear online algorithms for the approximate solution of bin packing with items drawn from a known probability distribution is presented. Each algorithm depends on the distribution and on a parameter controlling the performance of the algorithm. It is shown that with increasing number of items the expected performance ratio has an arbitrary small deviation from optimum. Beim eindimensionalen Packungsproblem besteht die Aufgabe darin, eine Liste vonn Eingabegrößen in möglichst wenige “Behälter” der Höhe 1 zu packen. Es wird eine Klasse von linearen Online-Algorithmen zur näherungsweisen Lösung des Packungsproblems mit Eingabegrößen, die einer bekannten Wahrscheinlichkeitsverteilung unterliegen, vorgestellt. Jeder dieser Algorithmen hängt von der Wahrscheinlichkeitsverteilung und einem Parameter ab, der die Güte des Algorithmus beeinflußt. Es wird gezeigt, daß sich der Erwartungswert der relativen Packungsdichte bei wachsender Anzahl der Eingabegrößen beliebig dicht dem Optimum nähert.	approximation algorithm;bin packing problem;computer performance;eine and zwei;online algorithm;set packing	Ulrich Hoffmann	1982	Computing	10.1007/BF02241699	mathematical optimization;combinatorics;discrete mathematics;bin packing problem;best bin first;apx;mathematics;bin;algorithm;square packing in a square	Theory	-97.32792596173257	36.748497483841284	101301
67ab3a56d4f9e49d4527f336a4db1824addefd78	creative commons: ein stück autonomie in der wissenschaft zurückgewinnen		Welcher Wissenschaftler hat sich nicht schon über ein Vertragsformular geärgert, das ihm ein Verlag anlässlich einer anstehenden Publikation zur Unterschrift zugeschickt hatte. Die Unterschrift soll bestätigen, dass mit dem Recht auf Publikation in der vorgesehenen Zeitschrift oder in einem Buch auch alle weiteren Rechte, z.B. auf Übersetzung, elektronische Versionen etc., an den Verlag übergehen – ganz gleich, ob für den Beitrag ein Honorar gezahlt wird oder nicht. Jüngere Wissenschaftler müssen das in der Regel zähneknirschend akzeptieren, etablierte streichen solche Passagen oft einfach durch. Manche Verlage reagieren darauf nicht, andere weigern sich dann, den Text zu publizieren. Eine unbefriedigende Situation.	die (integrated circuit);eine and zwei	Jochen Brüning;Rainer Kuhlen	2004				AI	-105.83652725967353	34.528829856699794	101306
ef5417ccebdc7dfe072b4e1e1c3e2930a7781cba	mathletfactory: komponentenframework und autorenumgebung für mathematische applets interaktiver elearning-plattformen.	java applet	Neue Medien und Neue Technologien schaffen die technischen Grundlagen für einen breiten Einsatz visuell-orientierter Unterrichtsmaterialien und für die Integration interaktiver Komponenten in den Lernprozess. Java-Applets, die gerade die Potentiale kombinieren, sind deshalb von herausragender Bedeutung für anspruchsvolle eLearning-Umgebungen. Für die mathematische Ausbildung spielen Interaktivität und Visualisierung eine besondere Rolle, weil sie in der Lage sind, die hier notwendigen Veränderungen in der Unterichtsmethodik umfassend zu unterstützen. Der Einsatz von Applets erweitert zudem die möglichen Verifikationsmethoden von Nutzereingaben in intelligenten Übungsumgebungen. Aus der Forderung, mit Hilfe von Applets Mathematik bzw. ihre abstrakten Objekte und Konzepte tatsächlich “erfahrbar” zu machen, leiten sich weitreichende Forderungen an das Softwaredesign ab, die insbesondere konzeptionelle Trennung des abstrakten Objektes von seinen verschiedenen Präsentationsformen, Interaktionsmechanismen zwischen den mathematischen Objekten und Design der Klassenbibliothek betreffen. Eine weitere wesentliche Herausforderung liegt im Authoringprozess. In dieser Arbeit stellen wir die wesentlichen Konzepte der MathletFactory (Teilprojekt des Plattformprojekts Mumie) vor.	applet;eine and zwei;java;parity (physics);sie (file format);vhf omnidirectional range	Volker Enss;Matthias Holschneider;Sabina Jeschke;Tim Paehler;Ruedi Seiler	2005			java applet;world wide web;computer science		-103.06429849632691	32.37697212969591	101356
71d10e3013753e1e31542e1754dbb3c7656f57b9	risikomanagement durch banken entlang agrarischer wertschöpfungsketten: betriebs-/finanzwirtschaftliche aspekte und anforderungen		Kreditfinanzierungen im Agrarbereich betreffen Agr arunternehmen und Agribusiness-Unternehmen entlang der jeweiligen Wer tschöpfungskette. Zur Vermeidung bzw. Minderung dabei auftretender Kreditris iken praktizieren Banken ein geeignetes spezifisches Risikomanagement. Dieses bas iert im Wesentlichen auf einem entsprechenden Agrarrating. Dessen Einsatz erfo rd t die Berücksichtigung wichtiger betriebsbzw. finanzwirtschaftlicher Anf orderungen in möglichst enger Zusammenarbeit zwischen Landwirt und Banker als Unte rnehmer.	broadcast auxiliary service;word error rate	Gerd Wesselmann	2014				AI	-105.52981205648891	32.64473169489439	101530
5820692ad9889e573eefdbe3ef988a41c09a2466	anforderungen an den computerunterstützten arbeitsplatz im industriellen umfeld	den computerunterst	Die Einbindung von Sichtschirm-Arbeitsplatzen in den Entwurfsund Konstruktionsprozes wird zunehmend in der Industriepraxis angenommen. Allerdings gibt es nach einer anfanglichen Begeisterung auch Ernuchterungen. Es ist eben nicht damit getan, das man Computersysteme mit haufig schon sehr guten analytischen Losungen fur viele Planungs-, Konstruktions- und Fertigungsaufgaben einsetzt, in der Regel als sog. Insellosungen. Sie mussen heute weitere grundsatzliche Anforderungen erfullen, wenn sie wirtschaftlich einsetzbar sowie ergonomisch und sozial vertretbar sein sollen.		Hermann Flessner	1989		10.1007/978-3-642-75177-6_5		EDA	-104.93800927213532	32.667301706441364	101974
6ccd049ce58a53afd81572bb9914fdb81ed5bca3	über den software-qualitätsbegriff - teil 2: anforderungen und merkmale am beispiel solftware-ergonomie (usability)		Dieser Beitrag führt die Diskussion um den Begriff Software-Qualität fort [Petr99b]. Ausgangspunkt war die Feststellung, dass es nicht genügt, den Qualitätsbegriff zu definieren, um ein einheitliches Verständnis für Qualität bei den Beteiligten zu erreichen. Vielmehr sind qualitätsbestimmende Begriffe wie Forderung und Merkmal zu klären. Auch stellt sich die Frage nach der Verwendung dieser Begriffe im Rahmen von Entwicklungsprozessen und Vorgehensmodellen (vgl. [Petr99a]). In die Kritik geraten dabei Normen und Standards wie beispielsweise die ISO 9001 oder das V-Modell 97, die kaum zur Klärung beitragen. Die Problematik des Qualitätsbegriffes auch in Verbindung mit Prozessstandards sei daher nochmals kurz erläutert. Weiterhin seien einige kontroverse Argumente vorgestellt, und um das Problem mit der Software-Qualität zu veranschaulichen, ist ein Beispiel aus dem Bereich Software-Ergonomie gegeben. Allerdings kann und will dieser Beitrag keine „Küchenrezepte“ liefern, sondern hauptsächlich auf die Schwierigkeiten beim Umgang mit Qualität hinweisen und die Diskussion beleben. 1. Was ist Software-Qualität? Das Begriffspaar Forderung und Merkmal nehmen eine zentrale Stellung bei vielen Definitionen für Qualität ein, z.B. bei der ISO 8204: „Gesamtheit von Merkmalen [...] einer Einheit bezüglich ihrer Eignung, festgelegte und vorausgesetzte Erfordernisse zu erfüllen“ [DIN8204]. Allerdings finden sich in der Literatur unterschiedliche Bezeichnungen für Forderung und Merkmal. So werden Forderungen oftmals auch als Anforderungen, Requirements, Needs oder Bedürfnisse bezeichnet. Merkmale finden sich in der englischsprachigen Literatur als Characteristics. Nun ist leicht einsehbar, dass sich hinter Forderungen und Merkmale außerordentlich komplexe Sachverhalte verbergen, so dass z.B. eine Strukturierung, Verfeinerung und Hierarchisierung notwendig wird, damit Anforderungen operationalisierbar und prüfbar werden, denn Requirements wie Aufgabenangemessenheit (als Beispiel für eine ergonomische Anforderung als Teil der nicht-funktionalen Anforderungen) können kaum direkt im SoftwareEntwurf bzw. der Implementierung umgesetzt werden. Wichtig erscheint insbesondere die Prüfoder Testbarkeit: Es genügt bekanntlich nicht, von „ausreichender Antwortzeit“ zu sprechen, da diese Anforderung nicht testbar ist. Auch die Quantifizierbarkeit bei der Bewertung kann ein Problem darstellen, denn das Ergebnis einer Prüfung lautet nicht immer „erfüllt“ oder „nicht erfüllt“, d.h. das Skalenniveau ist zuweilen recht unterschiedlich. Weitere Aspekte tragen zur Komplexität bei, z.B. die externe und interne Qualität sowie die Quality in use [DIN9126], die quasi „Sichtweisen“ auf eine Software darstellen. Auch ist zwischen Prozessund Produktqualität zu unterscheiden. Zusammenfassend lässt sich feststellen, dass erst die Zuordnung von Merkmalen zu den Forderungen eine Qualitätsaussage ermöglicht. Nur wenn geklärt ist, was die Anforderungen sind und welche Merkmale einer Software Relevanz für deren Erfüllung haben, ist Software-Qualität ermittelbar. 2. Stand der Diskussion Angesichts des o.g. leicht verständlichen Konzeptes für Qualität stellt sich die Frage, was am Qualitätsbegriff bzw. an dessen Verwendung diskussionswürdig sein soll. Zwei Punkte sind hier in erster Linie zu nennen: • Obwohl mit der ISO 8204 eine Definition für Qualität vorliegt und einige Normen diese Festlegung auch übernehmen, ist dennoch eine einheitliche Verwendung weder in der Standardliteratur, noch in den einschlägigen Normen und Standards zu beobachten. Nicht einmal innerhalb der ISO scheint es eine klare und konsistente Linie zu geben: Die ISO 9126 [DIN9126] beispielsweise verwendet den Begriff Quality (Sub-)Characteristic, z.B. in Verbindung mit Usability, während die ISO 9241-10 [ISO9241] von Ergonomic Requirements spricht, welche ebenfalls die Usability betreffen. Dies ist zumindest auf der terminologischen Ebene verwirrend. • Viele Prozessnormen bzw. Vorgehensmodelle greifen das Konzept von Anforderungen und Merkmalen überhaupt nicht auf. Dies betrifft z.B. die ISO 9001 [DIN9001], die ISO 15504 [ISO15504] oder das VModell 97 [Bund97]. Es ist zwar oftmals von Anforderungen (Requirements) die Rede, aber auf Merkmale und deren Prüfung gegen die Anforderungen findet sich nichts oder kaum etwas. Dabei wäre dies zwingend notwendig – nicht nur um Prüfungen durchführen zu können, sondern beispielsweise auch für das Requirements Tracing. Die begriffliche Vielfalt wiegt sicherlich nicht so schwer, wie die mangelhafte Unterstützung durch die Prozessnormen und Vorgehensmodelle: Um die Behauptung zu stützen, dass sich eine hohe Prozessqualität auch positiv auf die Produktqualität auswirkt, wäre eine prozessorientierte und detaillierte Beschreibung notwendig, wie Anforderungen als Ausgangspunkt mit Merkmalen des Produktes zu verbinden sind, so dass sich Qualität auch auf der nicht-funktionalen Ebene (z.B. bei softwareergonomischen Anforderungen) nachweisen lässt. Bevor näher auf das Thema Software-Ergonomie eingegangen wird, seien einige Gegenargumente bzgl. der o.g. Kritikpunkte genannt, wobei zu beachten ist, dass die Autoren der Argumente nicht namentlich genannt werden, hauptsächlich aber Vertreter von Prozessnormen und Vorgehensmodelle im positiven Sinne sind: • Gegenargument #1: Einige Normen (z.B. ISO 9001) unterscheiden nicht zwischen Anforderungen und Merkmalen, weil diese Differenzierung einen zu hohen Detaillierungsgrad bewirken würde. Wenn also in den Werken von Qualität bzw. Anforderungen gesprochen wird, dann ist damit der Qualitätsdefinition ausreichend genüge getan. Eine genauere Betrachtung bzgl. Anforderungen und Merkmale ist nicht notwendig. • Gegenargument #2: Einige Standards wie das VModell 97 enthalten einige Verweise auf andere Normen, was völlig ausreichend ist. Es ist nicht das Ziel von Standards bzw. Vorgehensmodellen, genaue Angaben über die Anforderungen und Merkmale zu machen. • Gegenargument #3: Um methodenunabhängig zu sein, können Prozessnormen und Vorgehensmodelle nun einmal nicht detaillierter sein. Schließlich soll nur der Prozess, nicht das Produkt beschrieben werden. • Gegenargument #3: Es ist gar nicht möglich, zu jedem Merkmal eine Anforderung zu definieren. Im Falle von ergonomischen Merkmalen, z.B. einem CancelButton, müsste es dann zu jedem Element eine separate Anforderung geben, was nicht realistisch ist. Bei genauer Betrachtung, sind die Gegenargumente nicht schlüssig: Bei, Argument #1 stellt sich die (Gegen-)Frage, warum Qualität erst mit den beiden Begriffen Anforderungen und Merkmalen definiert wird und dann genau diese beiden Begriffe praktisch keine Rolle mehr spielen. Würde also das Argument stimmen, dann sollte auch die Qualitätsdefinition abstrakter werden, was allerdings wenig hilfreich wäre, da die Software-Entwicklung einen Bedarf nach einer möglichst konkreten Unterstützung hat. Ähnliches gilt für das Argument #2: Wieso ist ein Vorgehensmodell wie das V-Modell 97 nicht in der Lage, methodenunabhängig das Vorgehen zur Transformation von Anforderungen zu Merkmalen sowie die Prüfung von Merkmalen beschreiben? Das ist nicht nachvollziehbar. Auch das Argument #3 ist bereits durch die Realität widerlegt: Praktisch jeder Style Guide für das User Interface, der technische Anforderungen an eine Benutzungsoberfläche definiert, gilt für eine beliebige Anzahl von Dialogen und Interaktionselementen, d.h. es muss durchaus 1 Interessante Kritikpunkte bzgl. Normen finden sich auch in [Balz95]. 2 Diese Gegenargumente erreichten mich als Feedback auf den ersten Artikel „Über den Software-Qualitätsbegriff“ [Petr99b]. 3 Außerdem sind die Argumente nicht wörtlich, sondern nur sinngemäß wieder gegeben, da z. T. nur mündliche Gespräche geführt wurden. 4 Zur Erinnerung: Finden sich im Submodell SE (Systemerstellung) teilweise noch die Begriffe „Anforderung“ und „Merkmal“, kommt der Begriff „Merkmal“ im gesamten Regelungsteil des Submodells QS (Qualitätssicherung) überhaupt nicht mehr vor. nicht für jedes Merkmale eine separat definierte Anforderung existieren. Dass sich das Qualitätskonzept mit Anforderungen und Merkmalen durchaus in einer allgemeinen Vorgehensweise unterbringen lässt, zeigt das Quality Function Deployment (QFD): In einer Art Matrix, dem House of Quality, ist das WAS (Kundenanforderungen) und das WIE (Merkmale) abgebildet, wobei einerseits die Korrelation der Merkmale und andererseits der Unterstützungsgrad der Merkmale in Bezug auf die Anforderungen anzugeben sind ([Zoll02, S. 124], [DGQ], s. Bild 1).	citeseerx;eine and zwei;gesellschaft für informatik;human factors and ergonomics;iso/iec 15504;iso/iec 9126;institut für dokumentologie und editorik;internet explorer;quality function deployment;unified model;usability;user interface;v-model;vhf omnidirectional range;web standards	Roland Petrasch	2004	Softwaretechnik-Trends		computer science;software engineering;performance art	OS	-102.27353811413639	32.91727247365176	102119
4e33069f76f52565f5474ec6b37749da6d8f2733	d-stability and kaps-rentrop-methods	strong coupling	In this paper we give an analysis of the effect of stiff nonlinearities on the behavior of a Kaps-Rentrop method. To that end we introduce two quantities related to a simple model. The values of these quantities determine to some extent the behavior of a Kaps-Rentrop method in case of a strong coupling between the smooth component and the transient one. Numerical examples illustrate the theoretical results. In dieser Arbeit wird die Stabilität des Kaps-Rentrop-Verfahrens in die Anwesenheit nichtlinearer Steifheit (Stiffness) analysiert. Dazu werden mittels eines einfachen Modells zwei Größen introduziert. Die Werte dieser Größen reflektieren gewissermaßen das Verhalten eines Kaps-Rentrop-Verfahrens in die Anwesenheit einer bestimmten Kopplung zwischen die beiden Komponenten in das steife System gewöhnlicher Differentialgleichungen. Einige numerische Beispiele veranschaulichen die Analyse.	eine and zwei;iterative method;numerical method;rosenbrock methods;stiffness	Marinus van Veldhuizen	1984	Computing	10.1007/BF02243574	calculus;mathematics	Robotics	-97.38946205436262	33.90115455535724	102140
8787c45aa70f92c22aa6be327af8b8a8187dacdb	informelle e-partizipation in parteien		Politische Partizipation im Internet hat zunehmenden Einfluss auf reale politische Willensbildungsprozesse. Parteien, die ein Kernelement des politischen Systems in Deutschland bilden, stehen vor einer wichtigen Gestaltungsaufgabe, wenn sie den Strukturwandel der politischen Kommunikation erfolgreich bewältigen möchten. Ziel unseres Beitrags ist es, Erkenntnisse für diese Gestaltungsaufgabe zu liefern. Dafür wurden 91 Vorschläge von CDU-Mitgliedern ausgewertet und ergänzende Interviews geführt, um Praktiken der (E-)Partizipation sowie ihre Defizite und Bedingungen zu identifizieren. Aus den Ergebnissen leiten wir die Notwendigkeit von insbesondere informellen E-Partizipationsund Vernetzungs-Technologien für den Einsatz in der CDU, potentiell aber auch anderen Parteien, ab.	control display unit;gesellschaft für informatik;sie (file format);unified model;vhf omnidirectional range	Christian Reuter;Oliver Heger	2016		10.18420/muc2016-mci-0215		OS	-104.1227015765727	34.18179498921922	102436
aa1ef3e0b7b2774623e7d8f6a34e2fb629941725	on finite element methods for elliptic equations on domains with corners	adjoint problem;kernel function;finite element method;elliptic equation;numerical computation	A finite element method for approximating elliptic equations on domains with corners is proposed. The method makes use of the singular functions of the problem in the trial space and the kernel functions of the adjoint problem in the test space. This leads to good approximates of the coefficients of the singular functions. In the numerical computations, the method is compared with the well known Singular Function Method. Es wird eine Finite Elemente Methode zur Approximation elliptischer Differentialgleichungen auf Eckengebieten vorgeschlagen. Das Verfahren benutzt die Singulärfunktionen des Problems im Raum der Ansatzfunktionen und die Kernfunktionen des adjungierten Operators im Testraum. Dadurch erhält man gute Näherungen der Koeffizienten, der Singulärfunktionen. In einem numerischen Beispiel wird das Verfahren mit der bekannten Methode der Singulärfunktionen verglichen.	approximation;coefficient;computation;eine and zwei;finite element method;numerical analysis;singular function;whole earth 'lectronic link	Heribert Blum;Manfred Dobrowolski	1982	Computing	10.1007/BF02237995	kernel;mathematical optimization;mathematical analysis;discrete mathematics;extended finite element method;quarter period;elliptic rational functions;boundary knot method;nome;finite element method;singular solution;mathematics;geometry;elliptic curve;jacobi elliptic functions;mixed finite element method;algebra	HPC	-96.53138019148982	35.80649752993743	102500
77e523387879e95fa7f10f23dbdfdc89b98f9e52	on the fill-in when sparse vectors are orthonormalized		If the RevisedGram-Schmidt method is used for orthonormalizing a given set of sparse vectors, then it is shown that the local fill-in of non-zero elements at each stage can be easily determined. This makes it possible to rearrange the remaining vectors at each stage such that the local fill-in is minimized. It is also shown that a similar method can also be used in the case of theHouseholder triangularization method. Wenn die revidierteGram-Schmidt-Methode in der Orthonormalisierung einer gegebenen Menge magerer Vektoren angewendet wird, so kann die lokale Füllung von Nicht-Null-Elementen bei jedem Schrift leicht bestimmt werden. Dies ermöglicht eine Neuordnung der verbleibenden Vektoren bei jedem Schrift, die dann eine möglichst kleine lokale Füllung ergibt. Es wird hier ferner gezeigt, daß eine ähnliche Methode auch im Fall derHouseholder-Triangulisierungsmethode verwendet werden kann.	eine and zwei;schmidt decomposition;sparse matrix	Yang-an Chen;Reginald P. Tewarson	1972	Computing	10.1007/BF02236376	theoretical computer science;machine learning;algorithm	Vision	-106.52447882714316	32.495062782271596	103101
8045bead09916cac90b66de269631fc304d9149c	peer-to-peer-systeme und -anwendungen	peer to peer system	Unter dem Begriff ,,Peer-to-Peer” etabliert sich derzeit ein neues und höchst interessantes Paradigma für die Kommunikation im Internet. Obwohl ursprünglich nur für die sehr pragmatischen und rechtlich umstrittenen Dateitauschbörsen entworfen, können die Peerto-Peer-Mechanismen zur verteilten Nutzung unterschiedlichster Betriebsmittel genutzt werden und neue Möglichkeiten für internetbasierte Anwendungen eröffnen.	internet;peer-to-peer	Ralf Steinmetz;Klaus Wehrle;Oliver Heckmann	2005			computer science	ECom	-104.8120919202707	36.71020098311047	103471
12141e6d32e5ea373b045b1f72ac2b5e6f73ab96	das future internet - public private partnership programm - entwicklungen und möglichkeiten für die agrar- und ernährungsindustrie		Im Rahmen des Future Internet – Public Private Part nership Programmes werden webbasierende Technologien und Plattform en entwickelt, welche neue Möglichkeiten für den Datenaustausch in Wertschöpfu ngsketten durch intelligente Vernetzung von Informationssystemen in Betrieben der Agrarund Ernährungsindustrie eröffnen. Dieser Beitrag gibt einen kurzen Ü berblick über das Programm und zwei ausgewählte Projekte (Smart Agri-Food und FIspace) welche sich mit Technologien für den Agrarund Ernährungssektor be schäftigen. 1 Das Future Internet Public Private Partnership Programm Das Future Internet Public Private Partnership (FIPPP) Programm der EU wurde 2011 ins Leben gerufen, um Forschungsergebnisse aus dem 7.Rahmenforschungsprogramm einer breiten Öffentlichkeit zugänglich zu machen u nd die kommerzielle Umsetzung voranzutreiben. Das Internet wie es heute bekannt i st und verwendet wird, ist dominiert durch amerikanische Firmen, wie beispielsweise Goog le, Napster, YouTube, Twitter, Facebook oder Amazon, die durch ihre Produkte und K onzepte zu globalen Akteuren aufgestiegen sind und viele Bereiche des alltäglich en Lebens revolutionierten. Im gleichen Zeitraum gibt es nur wenige Beispiele in Europ a, die ähnliches mit dieser Nachhaltigkeit geschafft haben. Die EU fördert Projekte im IKT Bereich im 7. Rahmenprogramm (2007-2013) mit einem Betrag von 9,1 Milliard en Euro und verfolgt das Ziel Forschung und Innovation voranzutreiben, um die Sch lüsselrolle der IKT in Europa weiter auszubauen. Die Rolle des FI-PPP ist es dabe i Forschungsergebnisse im Bereich 1 CORDIS, 2011 FP7 Factsheet der Internettechnologien zur Marktreife zu bringen und deren Anwendung stärker zu forcieren. Das FI-PPP 2 hat ein Gesamtbudget von ca. 600 Mio. Euro, welche s zu 50% aus Fördergeldern und zu 50% aus Investitionen der Industriepartner getragen wird. Das Programm ist deshalb in drei Phasen aufgeteilt: Eine Konsolidierungsund Konzeptphase (2011-2013) in der 8 Projekte die Anforderungen in unterschiedlichen Industriezweigen identi fizieren und Anwendungsszenarien zur Nutzung der Grundbausteine entwickeln. Eine experimentelle Phase (2013-2015) in der die besten Projekte aus Phase 1 di erarbeiteten Konzepte zu industriespezifischen Technolo gieplattformen weiterentwickeln, um die Nutzung der Grundbausteine und Industriespez ifischer Bausteine zu ermöglichen. Eine Umsetzungsphase (2014-2016) in der eine größere Anzahl kleinerer P rojekte mit einem definierten Ausschreibungsbudget die Entwickl ung von Anwendungen auf der Basis der erarbeiteten Technologien in ca. 800 Klei nstprojekten (50.000 – 150.000 Euro pro Projekt) fördert. Der Gesamtumfang für diese Ph ase beträgt 100 Millionen Euro, wovon 80% in Ausschreibungen für Anwendungen überfü hrt werden müssen. Abbildung 1: Übersicht über den zeitlichen Ablauf u nd die Projekte des FI-PPP 3 Neben diesen anwendungsorientierten Projekten werde n im Programm separate Projekte betrieben, die mit der Entwicklung der Grundbaustei ne (FI-WARE), dem Marketing (Concord) und der Bereitstellung von technischen Re ssourcen (Infinity, XIFI) beauftragt sind. FI-PPP, 2011, FI-PPP Factsheet 3 Quelle: FI-PPP, www.fi-ppp.eu/about 2 Das Smart Agri-Food Projekt Das Smart Agri-Food Projekt (Phase 1; 2011-2013) be schäftigte sich mit der Vernetzung der Ursprungsproduktion, den Wertschöpfungsketten u nd der Logistik in der Lebensmittelindustrie, sowie der Kommunikation mit Konsument en. Abbildung 2: Kernthemen des Smart Agri-Food Projekt es Aufbauend auf einer umfassenden Analyse der Unterne hmensanforderungen [LE12; RE12] wurden mehrere Piloten [SAF13a] im Projekt et abliert und themenspezifische internationale Netzwerke aus IKT-, Agrar-, Ernährun gsi dustrie und Forschung aufgebaut, welche gemeinsam Konzepte für die Verwendung der Grundbausteine entwickelten: Smart Farming, mit den Schwerpunkten in der Erfassung und Verwen dung von landwirtschaftlichen Daten, bspw. von Sensornetzwerken in Gewächshäusern oder Landmaschinen, mit dem Ziel die Vernetzung von Dienstleis ern, Beratern, Landmaschinenherstellern, Technologieanbietern und den landwirtscha ftlichen Betrieben zu verbessern [SAF13b]. Smart Agri-Logistics, mit den Schwerpunkten in der Vernetzung von Unter nehmen in Wertschöpfungsketten, um die Effizienz der Logistik e nerseits und der notwendigen Durchgängigkeit von produktund prozessbezogenen D aten andererseits zu verbessern[SAF13c]. Smart Food Awareness , mit dem Schwerpunkt Konsumenten produktbezogene I nformationen leichter zugänglich zu machen, um die Tran sp renz in Bezug auf Lebensmittel zu verbessern [SAF13d]. In diesem Bereich wurden Ko zepte zur Kommunikation von Produktinformationen erarbeitet. 4 Quelle: Smart Agri-Food 2013, www.smartagrifood.eu . 3 Das FIspace Projekt Das FIspace Projekt (Phase 2; 2013-2015) ist das Fo lgeprojekt, welches aus Smart AgriFood und FInest, dem Logistikprojekt in Phase 1, he rvorgegangen ist. In FIspace wird derzeit eine innovative Business-to-Business Kollab r tionsplattform [FI13a] entwickelt, die IT Unternehmen den Zugang wiederverwendb aren zu Entwicklungsressourcen und den Grundbausteinen (Generic Enablern des FI-WA RE Projektes) ermöglichen soll. Abbildung 1: Übersicht über das FIspace Projekt 5 Das Ziel des FIspace Projektes ist neben der Entwic klung der Plattform, die Entwicklung von Anwendungen mit diesen Werkzeugen [FI13b] für 8 unterschiedliche Anwendungsfälle zu zeigen. Diese Anwendungsfälle basieren auf den in Phase 1 erarbeiteten Pilotkonzepten. Im Rahmen des Projektes wird derzeit ein e rste Ausschreibung für externe Entwickler durchgeführt, die mit einem kleinen Budg et in kürzester Zeit weitere Anwendungen für den FIspace produzieren sollen [FI13c ]. 4 Möglichkeiten und Schlussfolgerungen FIspace ermöglicht neue Wege in der Anwendungsentwi cklung für Unternehmen durch die Bereitstellung von Werkzeugen für die Integrati on von bestehenden Systemen, verschlüsselte Datenkommunikation, Erweiterung des FIs pace durch kleine fokussierte Anwendungen, die Vernetzung zwischen Unternehmen ve rschiedener Stufen der Wertschöpfungskette durch einen Social Media-basierten Ansatz, Dienstleistern und Maschinen und Vermarktungsmöglichkeiten von Anwendungen i n einem App Store. Dadurch werden eine Vielzahl neuer innovativer Anwendungen möglich, die heute nur mit einem erhöhten Aufwand, bspw. in der wiederholten Entwick lung eines User Managements, Kommunikationsund Verschlüsselungskomponenten und Integrationskomponenten, realisiert werden können. Durch die Wiederverwendba rkeit von FIspace Komponenten und Future Internet Bausteinen wird es möglich Anwe dungen in einem Bruchteil der Entwicklungszeit zu realisieren. In den beiden ange sprochenen Projekten wurde bereits eine breite User Community etabliert, welche sich v on namhaften großen Unternehmen, Dienstleister bis hin zu einzelnen Landwirten erstr ckt. 5 Quelle: www.fispace.eu Durch die Finanzierungsmöglichkeiten in Phase 3 des FI-PPP wird einer großen Gruppe von kleinen und mittelständigen Softwareentwicklern , die die Mehrheit der Entwickler für die Landwirtschaft bilden, ein Zugang zu den ne uen Technologien eröffnet, um innovative Anwendungen zu entwickeln. Literaturverzeichnis und Referenzen [FI13a] FIspace: Technical Architecture and Specifi cation. http://www.fispace.eu/ Documentations/Deliverables/FIspace-D200.2%20Technical%20Arc hite ture%20and%20 Specification.pdf [FI13b] FIspace: Online Tools to support Developers and Users http://www.fispace.eu/ Documentations/Deliverables/FIspace-D500.1.3%20Onli ne%20tools%20to%20Support %20Developers%20and%20Users.pdf [FI13c] FIspace: Technical Definition of the Open Ca ll http://www.fispace.eu/ Documentations/Deliverables/FIspaceD400.14%20Technical%20definition%20of%20the%20Open% 20Call.pdf [LE12] Lehmann, R.J.; Reiche, R.; Schiefer, G.: Future Int rnet and the Agri-Food Sector – State of the Art of Future Internet Research. In: Cla sen, M., Fröhlich, H., Bernhardt, H., Hildebrandt, K., Theuvsen, B. (Hrsg.): Referate der 3 2. GIL-Jahrestagung in Freising 2012 Informationstechnologie für eine nachhaltige Landbewirtschaftung. Seite 183ff. [RE12] Reiche, R; Lehmann, R.J.; Schiefer, G.: Visions for creating food awareness with future internet technologies. In: Clasen, M.; Fröhlich, H.; Bernhardt, H.; Hildebrandt, K.; Theuvsen, B. (Hrsg.): Referate der 32. GIL-Jahrestagu ng in Freising 2012 Informationstechnologie für eine nachhaltige Landbewirts chaftung. Seite 243ff. [SAF13a]Smart Agri-Food: Übersicht über die Piloten des Smart Agri-Food Projektes. http://www.smartagrifood.eu/pilots [SAF13b]Smart Agri-Food: Smart Farming: Final Asses sment Report. http://www.smart agrifood.eu/sites/default/files/content-files/downl oads/SAF-D200.4-SmartFarmingFinal Assessment-V1.1-Final.pdf [SAF13c]Smart Agri-Food: Smart Food Logistics: Stan d rdisation Needs and Roadmap. http://www.smartagrifood.eu/sites/default/files/con te t-files/downloads/SAF-D300.4SmartLogisticsStandardisation-V1.0-Final.pdf [SAF13d]Smart Agri-Food: Smart Food Awareness: Fina l Assessment Report. http://www.smartagrifood.eu/sites/default/files/con te t-files/downloads/SAF-D400.4SmartFoodAwarenessFinalAssessment-V1.0-Final.pdf	app store;bielefeld conspiracy;blitzkrieg;circa;documentation;eine and zwei;europa;future internet;gesellschaft für informatik;internet explorer;internet protocol suite;internet research;logistics;napster;phile;social media;stan;store and forward;tps report;unified model	Robert Reiche;Harald Sundmaeker;Gerhard Schiefer	2014			architecture;art;performance art	OS	-102.6601177379655	35.55427118463049	103612
74d0c2b7d6a082179df2218a4c01c4d252d7da34	compliance-anforderungen an integrations- und migrationsprojekte		Migrations- und Integrationsprojekte werden häufig unter einem technischen Fokus angegangen. Die Vorschriften von Gesetzgebern, Behörden oder internen Compliance-Abteilungen stehen dann nur selten im Projektfokus. Dabei führen auch diese Projekte häufig zu Konflikten mit verbindlichen Anforderungen — oder erlauben die Möglichkeit, diese endlich einzuhalten. Der Artikel gibt einen knappen Überblick über wesentliche Compliance-Anforderungen und Kontrollen. Davon ausgehend werden fünf Fallstricke identifiziert, die in der Praxis regelmäβig zu nicht konformen IT-Anwendungen und Prozessen führen.	altran praxis	Dieter Greipl	2007	HMD Praxis der Wirtschaftsinformatik	10.1007/BF03341124	library science;knowledge management;engineering	OS	-102.7925041374593	33.1493444369901	103984
573ef4865e653da027a915bcf284e1b63b7ccc60	a search routine for a sperner simplex	fixed point;fortran	A systematic search program is given for an approximate fixed point of a continuous mapping of either the unitn-cube into itself or a “preferred”n-simplex (on the unitn-cube) into itself. The coding is in FORTRAN IV. Es wird ein systematisches Suchprogramm angegeben für einen Fixpunkt einer stetigen Abbildung, die entweder denn-dimensionalen Einheitswürfel oder einen speziell gewähltenn-simplex in sich überführt. Das Programm ist in FORTRAN IV geschrieben.	approximation algorithm;fixed point (mathematics);fortran;gesellschaft für informatik;simplex algorithm	Eugene L. Allgower;C. L. Keller	1971	Computing	10.1007/BF02234051	mathematical optimization;combinatorics;discrete mathematics;mathematics;fixed point	HPC	-97.10011562874993	35.41184229852336	104245
06e0eef90dc00973a32901cc88eaae2945520c51	konzepte zur suche geometrisch ähnlicher bauteile	hnlicher bauteile	Der verstarkte Einsatz von CAD- Systemen erfordert heute auch im ingenieur- wissenschaftlichen Bereich den Einsatz von DB- Systemen. Eine wesentliche Form der Anfrage ist die Suche nach ahnlichen Teilen - im Maschinenbau auch als Wiederholteilsuche bezeichnet-, um den Aufwand fur die Konstruktion und die Produktionsplanung wesentlich zu verringern. In allen bereits verfugbaren Systemen werden Objekte durch einmalig festzulegende Attribute beschrieben. In diesem Artikel wird nun ein System zur geometrischen Wiederholteilsuche vorgeschlagen, welches auf ein DB-System zugreift, in dem die Objekte durch die von einem CAD- System bereitgestellte Geometrieinformation beschrieben sind. Vorteil dieser Vorgehensweise sind die Erhaltung der vollstandigen Information uber die Objekte, die automatische Generierung der zu speichernden Informationen, sowie eine in bisherigen Systemen nicht erreichbare Flexibilitat und Effizienz bei DB- Anfragen.		Stephan Heep;Hans-Peter Kriegel;Ralf F Schneider;Bernhard Seeger	1988		10.1007/978-3-642-73608-7_10	performance art;art	Crypto	-105.7562753069754	32.40096237570471	104356
72fe53ea760855f159aea27e698edf45fc39c9d0	text reuse detection using a composition of text similarity measures		Detecting text reuse is a fundamental requirement for a variety of tasks and applications, ranging from journalistic text reuse to plagiarism detection. Text reuse is traditionally detected by computing similarity between a source text and a possibly reused text. However, existing text similarity measures exhibit a major limitation: They compute similarity only on features which can be derived from the content of the given texts, thereby inherently implying that any other text characteristics are negligible. In this paper, we overcome this traditional limitation and compute similarity along three characteristic dimensions inherent to texts: content, structure, and style. We explore and discuss possible combinations of measures along these dimensions, and our results demonstrate that the composition consistently outperforms previous approaches on three standard evaluation datasets, and that text reuse detection greatly benefits from incorporating a diverse feature set that reflects a wide variety of text characteristics. TITLE AND ABSTRACT IN GERMAN Erkennung von Textwiederverwendung durch Komposition von Textähnlichkeitsmaßen Die Frage, ob und in welcher Weise Texte in abgewandelter Form wiederverwendet werden, ist ein zentraler Aspekt bei einer Reihe von Problemstellungen, etwa im Rahmen journalistischer Tätigkeit oder als Mittel zur Plagiatserkennung. Textwiederverwendung wird traditionell ermittelt durch Berechnen von Textähnlichkeit zwischen einem Ursprungstext und einem potentiell wiederverwendeten Text. Bestehende Textähnlichkeitsmaße haben jedoch die starke Einschränkung, dass sie Ähnlichkeit nur anhand von Eigenschaften berechnen, die vom Inhalt der gegebenen Texte abgeleitet werden können, und somit implizieren, dass jegliche andere Textcharacteristika vernächlässigbar sind. In dieser Arbeit berechnen wir Textähnlichkeit anhand von drei Dimensionen: Inhalt, Struktur und Stil. Wir untersuchen mögliche Kombinationen von Maßen entlang dieser Dimensionen, und zeigen deutlich anhand der Ergebnisse auf drei etablierten Evaluationsdatensätzen, dass die Komposition generell bessere Ergebnisse liefert als bestehende Ansätze, und dass die Bestimmung von Textwiederverwendung stark von einem breiten Spektrum an Textcharacteristika profitiert.	computation;machine learning;rewrite (programming);sie (file format);semantic similarity;supervised learning;wikipedia	Daniel Bär;Torsten Zesch;Iryna Gurevych	2012			pattern recognition;data mining;information retrieval	Web+IR	-107.33542465550623	35.54087518677928	104423
0417e4586f2ab19827e7da144d5122f206a03429	it-governance und strategisches informationsmanagement (itg-sim)		Die verlässliche sowie effektive und effiziente Gestaltung und Steuerung der IT ist für viele Unternehmen und Organisationen sowohl aus regulatorischen Gründen als auch zur Steigerung der Wettbewerbsfähigkeit und zur Sicherung eines Beitrags der IT zum Unternehmenserfolg heute wichtiger als in der Vergangenheit. Hinzu kommt die Notwendigkeit, die IT an den aktuellen Trends der Gestaltung und Entwicklung komplexer IT-Systeme auszurichten und dabei auch neu aufkommende Technologien und Anwendungen im Sinne der Unternehmensziele zu nutzen. Verbunden mit diesen Aspekten – aber über sie hinausgehend – ist eine informationszentrische Sichtweise, die nicht die IT als Organisation oder Anwendungen und Technologien in den Mittelpunkt stellt, sondern den Vermögensgegenstand Information. Die unterschiedlichen Sichten und die mit ihnen zusammenhängenden Fragestellungen sollen Gegenstand des Workshops sein.	eine and zwei;sie (file format)	Daniel F. Abawi;Matthias Goeken;André Miede	2016		10.18420/in2017_160	business administration;business;corporate governance	OS	-101.37034363794186	34.49324951913591	104466
4b06e65e9229dc4232f7b277784b1249bb41b6ff	ein vertraulichkeit gewährendes erreichbarkeitsverfahren: schutz des aufenthaltsortes in künftigen mobilkommunikationssystemen		Es wird ein Verfahren zur Verwaltung von Aufenthaltsinformationen in Mobilkommunikationssystemen vorgestellt. Dabei wird von dem in existierenden Netzen verwendeten Konzept der mehrstufigen Speicherung von Aufenthaltsinformationen ausgegangen. Das Verfahren erfüllt die Datenschutzforderung nach Vertraulichkeit des Aufenthaltsorts von Mobilkommunikationsteilnehmern. Es ermöglicht die Speicherung unterschiedlich granularer, geographischer Aufenthaltsinformationen unter Pseudonymen (statt der wahren Identität der Teilnehmer). Die Pseudonyme werden über Register unterschiedlicher Netzbetreiber miteinander verkettet. Somit ist die Erstellung von Bewegungsprofilen von mobilen Teilnehmern nicht möglich.		Hannes Federrath;Elke Franz;Anja Jerichow;Jan Müller;Andreas Pfitzmann	1997		10.1007/978-3-642-60729-5_6		OS	-104.16826787076701	32.6735007345073	106052
e53412d4e02f87d926a4ea1f013244d1bff87f27	rechner und menschliche gemeinschaft: drei capriccios	drei capriccios	MARXSCHE THEMEN IM COMPUTERZEITALTER. — Durch die radikalen begrifflichen und gesellschaftlichen Veranderungen, die treffend unter der Bezeichnung Computerrevolution zusammengefast wurden, sind gewisse Grundanliegen von Marx wieder einmal interessant geworden; gleichzeitig sind sie aber in eine Perspektive geruckt, an die Marx selbst kaum gedacht hatte.		Kristóf Nyíri	1989		10.1007/978-3-642-74688-8_52		NLP	-104.71963399039643	34.04840334688349	106183
1d26b077fb635215c7fc2795a541a3e611d972c8	und was bedeutet das jetzt für mich?		Im November 2012 fand in Boston die 11. International Semantic Web Conference (ISWC 2012) statt. Zwei eigene papers dort (in zwei verschiedenen workshops) und, naja, eine gute Gelegenheit, Sir Tim Berners-Lee von Angesicht zu Angesicht kennenzulernen – kurz: mindestens drei gute Gründe, die Konferenz zu besuchen. Trotz dieser Einleitung soll dieser Beitrag kein Konferenzbericht sein. Ich werde vielmehr versuchen, einen Blick in die Zukunft des Semantic Web zu wagen, wie sie sich mir vor allem durch eine ISCW panel session, an der u. a. Tim Berners-Lee teilgenommen hat, darstellt. Vielleicht ist ja die PIK nicht nur ein Ort für wissenschaftliche Berichte aus der Arbeit der diversen Arbeitsgruppen im Umfeld von „Kommunikation und Verteilten Systemen“, sondern auch ein Organ, in dem man sich gegenseitig auf gewisse Großwetterlagen aufmerksam macht. Es gilt hier allerdings wie bei allen anderen Wetterberichten auch: Das gefühlte Wetter ist möglicherweise nicht das wahre Wetter... In meiner naiven Sicht auf die Dinge stelle ich mir das Semantic Web als eine Substruktur „unter“ dem heute üblichen „Web“ (wie ich es ab hier nennen werde) vor, eine Substruktur, die geeignet ist, inhaltliche Bezüge zwischen den Dokumenten des Web einerseits und den darin dargestellten realweltlichen Objekten andererseits herzustellen. (Manchmal kommt etwas Verwirrung in die Sache, wenn man nämlich auch eine Webseite als ein „realweltliches Ding“ begreift.) Diese Substruktur soll helfen, den Inhalt von Webseiten nicht nur mittels Volltextsuche, sondern mit Hilfe von Metadaten („Schlagworten“) zu erschließen. Wobei es nicht – wie beim HTML-Tag „meta“ – um Schlagworte für jeweils eine komplette Webseite geht, sondern um Schlagworte für einzelne HTMLElemente oder sogar nur einzelne Worte in einem HTMLcodierten Text. Und darüber hinaus sollen auch die Bezüge zwischen all diesen Elementen und allerlei weiteren inhaltlich „verwandten“ Seiten erkennbar gemacht werden. Was diese Art von Text-Auszeichnung von der im Web üblichen „Verlinkung“ mit HTML-Links unterscheidet? Nun, HTML-Links stellen Verknüpfungen zwischen den digitalen Objekten der virtuellen Welt her, Schlagworte binden diese digitalen Objekte an realweltliche Objekte an. In dem einen Artikel kann zum Stichwort „Bach“ das Schlagwort „Komponist“ geschrieben und ein Verweis auf „Händel“ untergebracht werden, in einem anderen Artikel trifft beim gleichen Stichwort das Schlagwort „Wasser“ besser das gemeinte. Und so bekommen die „körperlosen“ digitalen Objekte auf einmal semantisches „Fleisch“ ... Ich schreibe eine zweite Einleitung: Vor einigen Jahren hat Daniel Kehlmann einen mittlerweile vielgelesenen Roman mit dem Titel „Die Vermessung der Welt“ vorgelegt. Dem staunenden Publikum wurden zwei Helden und Abenteurer vorgestellt: A. von Humboldt und C.F. Gauß, der eine bei seinen Reisen um die Welt, der andere bei seiner Reise durch die Welt der Mathematik. So verpackt konnte auch das eher klassisch-bildungsbürgerliche Publikum sogar der Mathematik neue Reize abgewinnen. Ich finde diesen Roman mittlerweile ziemlich hausbacken, ich würde gerne einen neuen Roman schreiben: „Die Verschlagwortung der Welt“. Die Top-Ingredienz des erfolgreichen Romans würde allerdings fehlen: der bürgerliche Held. Denn wenn es nach den Betreibern erfolgreicher Suchmaschinen geht, dann haben wir alle („the crowd“) die gewünschte Verschlagwortung höchst selbst vorzunehmen – und ob die crowd als Held eines bürgerlichen Romans dienen kann, das wage ich doch sehr zu bezweifeln. Im folgenden werden wir nun zunächst einen kleinen Einstieg in die Begriffswelt des Semantic Web unternehmen (den die Leserin, die sich mit semantischen Technologien auskennt, getrost überspringen kann), um dann zwei verschiedene Sichten auf das Semantic Web zu präsentieren („Hintergrundwissen“ vs. „Semantische Auszeichnung“). Es schließt sich an eine Diskussion eines speziellen Schlagwort-Vokabulars (schema.org), das im Kontext der semantischen Auszeichnung derzeit viel Aufmerksamkeit beansprucht. Der Aufsatz schließt mit einem skeptischen Ausblick auf die Perspektiven des Semantic Web. DOI 10.1515/pik-2013-0003 PIK 2013; 36(2): 91–97	eine and zwei;html;i/o controller hub;iswc;intentionally blank page;internet explorer;open road tolling;sie (file format);schema.org;semantic web;unified model;vhf omnidirectional range;world wide web	Norbert Luttenberger	2013	Praxis der Informationsverarbeitung und Kommunikation	10.1515/pik-2013-0003		Web+IR	-105.19837352640529	35.70205255926921	106417
eb0d1f35fbb505ead299bf0968ecccc5d30918d9	tutorieller und trainingsorientierter unterricht in informatik und mathematik		Seit Oktober 1972 steht im Christian-Ernst-Gymnasium in Erlangen ein Fernschreiber als Datenendstation einer CD 3300 des Rechenzentrums der Universität Erlangen-Nürnberg. Damit erlernten Teilnehmer der Informatikkurse der Schule die Programmiersprache ALGOL mit einem tutoriellen Lehrprogramm, das am Rechenzentrum für Studenten entwickelt worden ist. Im Mathematikunterricht einer 11. Klasse wurde ein weiteres Lehrprogramm für die Kurvendiskussion ganzer rationaler Funktionen sowohl im Klassenunterricht als auch im nachfolgenden Trainingseinsatz erprobt.		Klaus Kreisel	1974		10.1007/3-540-06907-0_67		NLP	-104.42293785299002	33.097552984158675	106553
40701dd9c4bba079de3a32117630a7ff74d7b90c	der zerlegungs-ansatz - ein alternativer vorschlag zur messung von armut	equivalence scales;decomposition approach;armutsmessung;welfare;zerlegungs ansatz;equivalence scale;poverty measurement;wohlfahrt;aquivalenzskalen	In diesem Beitrag wird ein alternativer Ansatz zur Armutsmessung diskutiert, der so genannte Zerlegungs-Ansatz. Diese Methode differenziert zwischen verschiedenen sozialen Gruppen in dem Sinne, dass fur jede Gruppe eine separate Armutsgrenze bestimmt wird. Beispielsweise konnte die Haushaltsgrose ein Kriterium fur eine solche soziale Unterscheidung sein. Hierdurch wird das Problem der traditionellen Armutsmessung vermieden, einkommensunabhangige Aquivalenzskalen zu verwenden. Auch das Problem der traditionellen Vorgehensweise, zur Bestimmung einer (allgemeinen) Armutsgrenze einen mehr oder weniger willkurlichen Prozentsatz des mittleren gesellschaftlichen Wohlstandsniveaus festzulegen, existiert beim Zerlegungs-Ansatz nicht.		Jürgen Faik	2011	AStA Wirtschafts- und Sozialstatistisches Archiv	10.1007/s11943-010-0089-4	economics;welfare	NLP	-105.45437224251411	32.92938768950162	107088
46d6f0dd0dda275a35b1da757c190af191ce69d9	partizipation contra kriteriengeleitete aufgabenbewertung - eine scheinalternative?	eine scheinalternative	Die Kontrastive Aufgabenanalyse (KABA), ein Leitfaden zur Analyse und Gestaltung von Buroarbeitsplatzen unter dem besonderen Blickwinkel des Einsatzes von Informations- und Kommunikationstechniken (vgl. Dunckel, Volpert, Zolch, Kreutner, Pleiss u0026 Hennes, 1992, i. V.) gehort zu einer Familie von Arbeitsanalyseverfahren, die sich durch folgende Charakteristika kennzeichen lassen: rnrnrndie Analyse und Bewertung von Arbeitsaufgaben sowie die Entwicklung von Gestaltungshinweisen erfolgt anhand theoretisch begrundeter Kriterien, die als zentral fur eine menschengerechte Arbeit angesehen werden;rnrnrndie Analyse erfolgt bedingungsbezogen, d. h. beurteilt werden nicht die arbeitenden Personen, sondern die Arbeitsaufgaben und -bedingungen als Handlungsbedingungen fur die Arbeitenden (vgl. Oesterreich u0026 Volpert, 1987) undrnrnrndie Arbeitsaufgaben werden in der Regel von geschulten Untersucherinnen in Form eines Beobachtungsinterviews am Arbeitsplatz analysiert.	eine and zwei	Martina Zölch	1992		10.1007/978-3-642-77808-7_46		Robotics	-104.9782446905159	32.632486317736046	107243
46685e53220038f0a3dc0f4d84810cc8a6fd9ddd	persönlichkeitsrechtsverletzungen durch äußerungen im internet		Bei Persönlichkeitsrechtsverletzungen im Internet stellt sich oftmals die Frage nach der übertragbarkeit der für den analogen Bereich geltenden Grundsätze und den sich hieraus ergebenden Folgen. Der Beitrag skizziert die Grundzüge der von der Rechtsprechung entwickelten Maßstäbe sowie noch offene Problemfelder.	internet	Matthias Dittmayer	2013	Datenschutz und Datensicherheit - DuD	10.1007/s11623-013-0326-4	computer science;the internet;internet privacy	OS	-103.90996910213401	36.47488709352029	107479
d397418c84ea98c01d2c1ec233a541fd3168d29c	vergleich von distanzen und kernel für klassifikatoren zur optimierung der annotation von bildern		Die stetig steigende Anzahl von Bildern erfordert Verfahren zur maschinellen Annotation. Um automatisch semantische Informationen aus den Bildern zu extrahieren, repräsentieren wir die Bilder durch numerische Vektoren, sogenannte BoWHistogramme und klassifizieren diese auf vorgegebene Klassen. Als Klassifikatoren werden Nearest-Centroid (NC) und Support Vector Machine (SVM) eingesetzt. Auf der Caltech 101 Bilder-Datenbank liefert der SVM-Klassifikator mit dem empfohlenen RBF-Kernel bessere Ergebnisse als der NC-Klassifikator mit der Euklidischen Distanz. Wir vergleichen verschiedene Distanzfunktionen wie z.B. die Bhattacharyyaund Hellinger-Distanz und zeigen, wie sich die Mahalanobis-Distanz für eine Modifikation des NC-Klassifikators nutzen lässt. Nach einer Evaluation folgern wir, dass der NC-Klassifikator mit anderen Distanzfunktionen die SVM-Ergebnisse erreichen kann und eine Normierung der BoW-Histogramme sich ebenfalls positiv auswirkt. Außerdem zeigen wir, dass sich die Ergebnisse des SVM-Klassifikators signifikant durch den Einsatz des Chi-Quadratund Histogrammschnitt-Kernels verbessern können.	chi;caltech 101;eine and zwei;internet explorer;kernel (operating system);nc (complexity);radial basis function kernel;support vector machine;unified model	Alexander Askinadze	2015			kernel (linear algebra);annotation;computer science;bioinformatics	ML	-106.92930109686674	35.55026057440642	107537
e14dfab9de627a0cf075838e2294bc88a3293728	dijkstras fruchtbarer, folgenreicher irrtum		Teil 2 des vorliegenden Artikels liefert eine an der ALGOL60-Kopierregel orientierte Definition der ,,most recent“-Eigenschaft oder -Korrektheit eines Programms. Anschließend werden Programmbeispiele aus der Fachlitaratur diskutiert, welche die von E.W. Dijkstra behauptete ,,most recent“-Korrektheit aller Programme widerlegen. Anhand weiterer Beispiele möchten deren Autoren zwar die besonderen Komplikationen beim Ausführen formaler Prozeduraufrufe in block- und prozedurgeschachtelten Programmen demonstrieren, treffen aber dennoch nicht die ,,most recent“-Problematik.	eine and zwei;triple des	Hans Langmaack	2010	Informatik-Spektrum	10.1007/s00287-010-0446-2	software engineering;humanities;computer science	Crypto	-103.80642311231486	34.061150405011745	107553
2b866c00b1f161b9a5da0b287668374cec6addfc	digitalisierung in lehre und lernen: des kaisers neue kleider?!		In den vergangenen Jahren konnten zahlreiche Initiativen und Konzepte für die Erprobung digital unterstützten Lehren und Lernens wahrgenommen werden und Begriffe wie E-Learning oder Blended Learning waren in aller Munde. Gegenwärtig redet man an vielen Punkten von Digitalisierung, weshalb man folgende Fragen stellen kann: Ist Digitalisierung das neue Kleid des E-Learnings? Ist E-Learning „tot“? Was versteht man unter Digitalisierung? Wird über die Digitalisierung in Lehre und Lernen geredet, dann können zum einen der Diskurs der technischen und didaktischmethodischen Umsetzung digitaler Lehr-Lern-Angebote („Das neue Kleid des ELearnings?“) und zum anderen die Digitalisierung als Bildungsgegenstand an sich identifiziert werden. Gerade in deren Verbindung ergeben sich für Forschung und Praxis verschiedene Herausforderungen, die fokussiert werden sollten: Digitale Lehr-LernAngebote sind nicht nur ein Thema der Informatik, sondern auch Forschungsgegenstand in anderen Fachdisziplinen, wie politische Bildung. Darüber hinaus öffnen sich die Angebote immer mehr verschiedenen Zielgruppen, unterschiedlichen Lernbiografien und Bildungswegen. Durch diese Interdisziplinarität und Öffnung der Angebote muss über eine veränderte Auseinandersetzung mit Bildungsprozessen nachgedacht werden und zugleich müssen auch bestehende Planungsprozesse (Top-Downoder Bottom-UpEntwicklung digitaler Lehr-Lern-Angebote) evaluiert werden.	altran praxis;die (integrated circuit);eine and zwei;institut für dokumentologie und editorik;intentionally blank page;internet explorer;parity (physics);triple des	Sarah Sahl;Alke Martens	2016					-105.97900150352164	34.43828857589801	107921
279bcdc12f76308809fbf06ec6b59b68d0bfe827	awareness creation mit tele-lab it-security: praktisches sicherheitstraining im virtuellen labor am beispiel trojanischer pferde	it security	Die Schaffung von Sicherheitsbewusstsein (Awareness Creation) wird nicht nur für Unternehmen zu einem Thema von großer Wichtigkeit. Initiativen zur Sensibilisierung sollen bereits Schüler mit dem Thema Sicherheit vertraut machen. Dabei kommen – wie in Informatik-Studiengängen an Universitäten – nach wie vor in erster Linie Literatur, Seminare, Frontalschulungen oder verschiedene mehr oder weniger interaktive E-Learning-Angebote zum Einsatz. Die vorhandenen Angebote vermitteln in aller Regel jedoch lediglich theoretisches Wissen. Es fehlt an Möglichkeiten, praktische Erfahrungen mit Sicherheitsund Hackertools in einem realitätsgetreuen Übungsumfeld zu sammeln. Ausnahmen bilden hier lediglich teure und wartungsintensive dedizierte Sicherheitslabore, die nur an wenigen Institutionen zur Verfügung stehen. Die vorliegende Arbeit stellt die Möglichkeiten des Tele-Lab Servers – einer internetbasierten Lernplattform mit integrierter Übungsumgebung – anhand einer Lerneinheit zur Gefährdung durch Trojanische Pferde vor. Dabei wird eine Übung angeboten, die es dem Lernenden ermöglicht, selbst einen Angriff mit einem existierenden Trojaner auf ein virtuelles Opfer durchzuführen – und so nach einer Erfahrung aus der Sicht des Hackers das Gefährdungspotential neu einzuschätzen.	die (integrated circuit);eine and zwei;internet explorer;television;vhf omnidirectional range	Christian Willems;Christoph Meinel	2008			art;performance art		-105.98012103423989	33.829496561348435	108015
0d6d4582dc149ece2b0198a30c2dc8af365d842f	gis 2d, 3d, 4d, nd		Einleitung Die Begriffe Geodaten, Geoinformationen und Geoinformatik scheinen allgegenwärtig, sie sind Gegenstand von Erörterungen in Landtag [2] und Bundestag [3, 4], führende Unternehmen der Branche, die National Geographic Society und die American Association of Geographers haben den alljährlichen Internationalen GIS Day initiiert [5], Kongresse beschäftigen sich damit, wie es um die Potenziale von Geoinformationen in Wirtschaft, Politik und Verwaltung bestellt ist [6]. Dementsprechend lebendig sind die Begriffe selbst und ihre Definitionen sind einer raschen Entwicklung ausgesetzt.	data privacy day (data protection day internationally);gis day;geographic information system;internet explorer;sie (file format);unified model	Helmut Schaeben;Marcus Apel;K. Gerald van den Boogaart;Uwe Kroner	2003	Informatik-Spektrum	10.1007/s00287-003-0303-7	software engineering;computer science	Vision	-103.05955611074545	36.080587291628134	108069
1f49f64b436f62c5fb385b4d3b2f739cb519857d	ein algorithmus zur berechnung aller reellen nullstellen in einem intervall		1. Das Verfahren In dieser Arbeit wird eine rekursive Prozedur ffir einen in [1] beschriebenen Algorithmus angegeben, der dazu dient, alle Nullstellen einer reellwertigen Funktion f (x) in einem reellen Intervall X omit Fehlerschranken zu berechnen. Als Ergebnisse werden Intervalle bestimmt, deren Vereinigung alle Nullstellen enth~ilt. Vorausgesetzt wird ffir die Funktion f(x), dab sie einer Lipschitzbedingung geniigt, das heigt ffir j edes Intervall X_~ X 01/iBt sich ein Intervall F~ (J0 berechnen, so dab gilt f(x)-f(y) F1 (X) fi~r alle x, y E X. (1) x y	algorithm;dab ensemble;eine and zwei;emoticon;sie (file format)	Wilhelm Barth	1972	Computing	10.1007/BF02241606	mathematics;mathematical analysis;calculus	PL	-97.01525465254507	35.44478211670463	108471
82ef876676ecc9594fb352fb832eae9f83544ba6	die bedeutung der organisationstheorie für die entwicklung der wirtschaftsinformatik	guidage;validacion;pertinencia;guiado;impact environnement;information and communication systems;organizational design;engineering information systems;pertinence;guidance;organization theory;validation;relevance;organizational behavior;system design and implementation;impacto medio ambiente;systeme information ingenierie;environment impact	Da Informationsund Kommunikationssysteme ihre organisatorische Umgebung in signifikanter Weise beeinflussen, müssen technische und organisationsbezogene Fragestellungen gemeinsam betrachtet werden, um effektive Lösungen zu entwickeln und zu implementieren. In diesem Beitrag argumentieren wir, dass die Disziplin Wirtschaftsinformatik davon profitieren würde, der Organisationstheorie mehr Aufmerksamkeit zu widmen.	unified model	Arnold Picot;Oliver Baumann	2009	Wirtschaftsinformatik	10.1007/s11576-008-0135-9	relevance;management;organizational architecture;organizational behavior		-100.30185135116488	33.19313176813885	108979
fbed9cab3214aa4c92dedb1833e9673c3e2b60c1	ausgewählte problemfelder und lösungsansatz des requirements engineering in der telekommunikationsbranche		In diesem Erfahrungsbericht aus der Telekommunikationsbranche werden aktuelle Problemfelder der Unternehmensberatung zum Requirements Engineering vorgestellt. Ursachen der Problemfelder werden analysiert (vorhandene Prozesse in Unternehmen, mangelnde Toolunterstützung, Enterprise Mobility als zentraler Faktor für das RE). Die unzureichende Verbindung des Vorgehensmodells Requirements Engineering zur operativen Umsetzung wird dabei als maßgeblich identifiziert. Ein Lösungsansatz wird vorgestellt.	requirements engineering	Alexander Rachmann;Sven Eselgrimm;Frank Engel	2013			software engineering;engineering;requirements engineering	SE	-101.23709607170039	32.9020981321904	109938
bca5e41bb4d68eb9f4a0971131241e8e2c5dcf3d	der einsatz einer telemetrischen gewichtsmessung im rahmen eines gesundheitsprogramms zur betreuung von patienten mit chronischer herzinsuffizienz		Am Beispiel eines Herzinsuffizienz-Gesundheitsprogrammes wird das telemetrieunterstützte Gewichtsmonitoring dargestellt. Zum Einsatz kommt eine Waage, deren Messungen per SMS an eine Datenbank weitergeleitet und dort zeitnah ausgewertet werden. Dadurch lassen sich Zeichen einer Dekompensation frühzeitig erkennen und damit Krankenhauseinweisungen und Kosten verringern.	am broadcasting;eine and zwei	Thomas Brettreich;Thomas Hudler;Stephanie Klinger;Stefan Kottmair	2005				ML	-104.00927557503461	33.51744058805031	110826
86f3ee55e0df310c4362918e101a50dffb3b994a	architekturzentriertes vorgehen für integrationsprojekte		In diesem Paper kondensieren wir das in zahlreichen Integrationsprojekten gesammelte Vorgehenswissen. Dabei spannen wir den Bogen von kleinen Integrationsprojekten bis zu großen Programmen und zeigen, dass ein auf die Architektur ausgerichtetes Vorgehen entscheidend für den Projekterfolg ist.	gesellschaft für informatik	Bernhard Humm;Boris Zech	2004			performance art;history	NLP	-104.02068663485362	34.32167760390411	110918
d90697f0087bc0441bb2fe80aebfe7a00f67b80d	wie zuverlässig ist der empfang von netzwerkpaketen bei der verwendung des transportprotokolls udp?		Einführung Am Max-Planck-Institut für Plasmaphysik ist ein Großexperiment im Aufbau. Dessen Experimentablauf soll über ein verteiltes Monitoring-System dargestellt werden. Die hierzu notwendigen, physikalisch relevanten Informationen stammen aus verteilten Messquellen und sollen einer Gruppe von Beobachtern zeitnah zur visuellen Inspektion an verschiedenen Orten über das lokale Netzwerk zur Verfügung stehen. Hierfür wird ein Gruppenkommunikationssystem eingesetzt, wie es ähnlich auch bei Videokonferenzen zwischen mehreren Partnern, VoIP (engl. Voice over IP) oder ereignisgesteuerten Architekturen [2] verwendet wird. Solchen Systemen ist gemeinsam, dass die Übertragungen keine spürbaren Verzögerungen haben dürfen. Ebenso wenig lassen sich Verluste tolerieren, die eine Verzerrung oder Sinnentstellung der Inhalte zur Folge haben, wie beispielsweise verschluckte Silben oder das Fehlen bzw. die Verfälschung relevanter Bildinformationen. Bei einer Punkt-zu-Punkt-basierten Kommunikation wird allgemein TCP/IP angewandt. Das Transportprotokoll TCP (engl. Transmission Control Protocol) mit seinen Kontrollflussmechanismen sorgt u.a. dafür, dass alle Datenpakete den Empfänger erreichen. Jedoch ist TCP/IP in speziellen Anwendungsfällen nicht das Mittel der Wahl, d.h. TCP genügt insbesondere nicht einer Echtzeitanforderung. Eine alternative und einfache Realisierung besteht darin, dass die Quelle die Datenpakete an	citeseerx;eine and zwei;internet explorer;internet protocol suite	Steffen Tambach;Christine Hennig	2007	Informatik-Spektrum	10.1007/s00287-007-0138-8		OS	-104.5286397888295	36.238299782302846	110977
8724dc413d0a78136fb4888ce225f375f76d60a8	the range of values of a circular complex polynomial over a circular complex interval	mean value property;bernstein polynomial	Two Methods to find a small circular interval that encloses the range of values of a circular interval polynomial over a circular interval are developed. The first method uses Bernstein polynomials over the sides of a regular polygon enclosing the domain, the other method uses a mean value property of curves in the complex plane. They are then compared to each other as well as to the result obtained from the Hornerscheme and the true range. Es werden zwei Methoden entwickelt, einen möglichst kleinen Kreisbereich zu finden, der den Wertebereich eines Kreisintervallpolynoms auf einem gegebenen Kreisbereich einschließt. Die erste Methode benützt Bernsteinpolynome auf den Seiten eines umschriebenen regulären Polygons, die andere eine Mittelwerteigenschaft von Kurven in der komplexen Ebene. Die beiden werden untereinander und auch mit dem Hornerschema und dem wirklichen Wertebereich verglichen.	bernstein polynomial;die (integrated circuit);eine and zwei	E. Grassmann;Jon G. Rokne	1979	Computing	10.1007/BF02252094	mathematical optimization;mathematical analysis;discrete mathematics;mathematics;bernstein polynomial	Theory	-96.58075527557727	35.860977154134645	111149
59d7fa5781a4fc1eb71281cc41318a96ad066df6	a framework for proactive caching in business process-driven environments		"""| C h a p t e r 3 | P a g e Abstract System response times influence the satisfaction of users interacting with a system. Research shows that increasing response times lead to increasing dissatisfaction or complete refusal of using the system. System analyses show that enforcing access control requirements significantly influence the system's performance experienced by end users. With increasing regulatory demands such as Basel II, Sarbanes Oxley, or data protection laws, modern complex and multi-layered enterprise systems require fine-grained and context sensitive enforcement of access control policies. Consequently, an efficient policy evaluation is getting more and more important to ensure a satisfactory system performance for interactive tasks. Research in the area of performance optimizations of access control evaluations is well known, comprising replication of respective system components, structural optimizations of the security policy, as well as different caching strategies. All these approaches have in common that the presented optimization techniques try to optimize access control evaluations independently from the system context. Modern enterprise systems are inherently based on models for process execution. These models provide a detailed view on the system context and, thus, enable new caching approaches. The dynamic nature of today’s process management systems and increasing demand for context sensitive security enforcement, however, challenge caching access control decisions as changing context strongly impacts on the continuous validity of stored access control decisions. In this thesis, we propose ProActive Caching, a caching strategy specifically tailored to the dynamic properties of business process-driven environments. ProActive Caching aims at providing a significantly low response time for access control decisions, as well as allowing to cache access control decisions which are based on context sensitive security policies. Moreover, we provide an accompanying caching architecture and a detailed performance analysis of different caching strategies for static and dynamic aspects of access control policies, showing that our strategy significantly improves the performance compared to other approaches for caching access control decisions. Extended Abstract (German) | C h a p t e r 5 | P a g e Extended Abstract (German) Für prozessorientierte Industrielösungen bestehen die gegenläufigen Herausforderungen, die Reaktionszeiten des Systems für Benutzer optimal zu minimieren und gleichzeitig mittels Zugriffskontrollauswertungen, welche die Reaktionszeit signifikant erhöhen, unbefugte Interaktionen zu verhindern. Verzögerte Antwortzeiten führen zu Unzufriedenheit beim Benutzer und können zu vollständiger Ablehnung des Systems führen. Für die Autorisierung von Interaktionen eines Benutzers mit in Unternehmen häufig eingesetzten prozessorientierten Industrielösungen, wie beispielsweise für Ressourcenplanung (ERP), müssen eine Vielzahl von Zugriffskontrollanfragen ausgewertet und die intendierte Aktion des Benutzers auf ihre Legitimität hinsichtlich der im System festgelegten """"Security Policy"""" überprüft werden. Als Konsequenz werden die Reaktionszeiten auf Benutzereingaben durch die durchgeführten Autorisierungsabfragen signifikant beeinflusst. Verzögerungen im Bereich von 100 ms werden bereits als kleine Störung wahrgenommen, Wartezeiten von mehr als einer Sekunde unterbrechen bereits den Gedankenfluss. Gerade zusätzliche, rechtliche Anforderungen durch beispielsweise Basel II, Sarbanes Oxley oder Datenschutzgesetze erfordern in modernen, mehrschichtigen Industrielösungen eine feingranulare als auch kontextabhängige Auswertung und Durchsetzung von Security Policies. Konsequenterweise ist es für die Zufriedenheit der Benutzer wichtig, eine auf Geschwindigkeit optimierte Evaluierung von Sicherheitsanfragen einzusetzen. Zur Optimierung von Zugriffskontrollanfragen gibt es bereits verschiedene Ansätze. Hierzu gehört die Replikation von denjenigen Systemen, welche für die Auswertung von Zugriffskontrollanfragen genutzt werden oder die strukturelle Optimierung von Security Policies. Eine weitere Möglichkeit ist die Nutzung verschiedener Caching Strategien. Die Literatur bietet eine Fülle von generischen als auch für Zugriffskontrollauswertungen optimierten Caching Verfahren. Die genannten Ansätze haben gemeinsam, dass die jeweilig dargestellten Strategien zwar eine Optimierung der Performance darstellen, diese jedoch den Einbezug des Anwendungskontextes innerhalb dessen die jeweilige Strategie eingesetzt werden soll nicht berücksichtigen. Gerade der Einsatz von dynamischen Kontextinformationen erhöht die Komplexität von Zugriffskontrollauswertungen. Während bei der Auswertung von statischen Security Policies keine weiteren Informationen über das Anwendungssystem benötigt werden, müssen bei dynamischen Zugriffskontrollauswertungen Systeminformationen hinzugezogen werden. Diese werden benötigt, um beispielsweise Entscheidungen zur Einhaltung des Vier-AugenPrinzips durchzusetzen; dies ist jedoch nur möglich, wenn bei der Auswertung bekannt ist, ProActive Caching in Business Process-driven Environments 6 | P a g e ob der jeweilige Benutzer zuvor bereits sich ausschließende Interaktionen am System oder einem Geschäftsobjekt durchgeführt hat. Diese Einbeziehung von sich dynamisch veränderbaren Kontextinformationen erschwert den Einsatz von Caching Lösungen. Die Veränderung einer zur Zugriffkontrollauswertung genutzten Information führt unweigerlich dazu, dass zuvor ermittelte Zugriffskontrollentscheidungen ungültig werden können. In der Konsequenz können Zugriffskontrollentscheidungen nur in einem Cache gespeichert werden, wenn sichergestellt wird, dass ausschließlich gültige Einträge aus dem Cache abgerufen werden können. Diese Doktorarbeit stellt eine Caching Strategie vor, welche speziell für den Einsatz in prozessorientierten Industrielösungen entwickelt wurde. Dabei werden zwei wesentliche Ziele verfolgt: • Das erste Ziel ist eine signifikante Reduktion für die Bereitstellung von Zugriffskontrollentscheidungen, welche durch ein prozessorientiertes System verarbeitet und durchgesetzt werden können. • Das zweite Ziel ist eine Cache-Management Strategie, welches auch die Speicherung von solchen Zugriffskontrollentscheidungen erlaubt, welche neben der Berücksichtigung der Security Policy mittels dynamisch veränderbaren Kontextinformationen ausgewertet wurden. Diese Ziele erreichen wir mittels der folgenden fünf technischen Beiträge: Erstens durch """"ProActive Caching"""" (PAC). PAC ist eine Caching-Strategie, die speziell für den Einsatz in Geschäftsprozess unterstützen Unternehmen entwickelt wurde. Sie ist speziell darauf ausgelegt die Bereitstellungen von Zugriffskontrollentscheidungen signifikant zu beschleunigen. PAC ermöglicht es hierfür, Zugriffskontrollanfragen anhand vorhandener Prozessmodelle vorauszuberechnen und zwischenzuspeichern, sodass Zugriffskontrollantworten direkt aus einem Cache beantwortet werden können. Dies gilt selbst für """"Erstzugriffe"""", welche bei regulären Caching Strategien üblicherweise nicht aus dem Cache beantwortet werden können. Darüber hinaus ermöglicht PAC die Vorhaltung solcher Zugriffskontrollentscheidungen, welche von bestehenden Caching Strategien nicht gespeichert werden können, da die Entscheidung über die Zugriffserlaubnis auf dynamisch verändernden Kontextinformationen beruht. Zweitens wird in der vorliegenden Arbeit eine hybride """"2-Level Caching Strategie"""" definiert, welche es ermöglicht, PAC mit weiteren Caching Strategien zusammen zu verwenden. Die Vorausberechnungen von Zugriffskontrollentscheidungen bedeuten für PAC einen größeren Overhead für das Cache Management, wie dies bei alternativen Caching Strategien der Fall ist. Alternative Strategien können jedoch keine auf dynamischen Kontextinformationen beruhenden Zugriffskontrollentscheidungen speichern. Durch die gemeinsame Nutzung von Extended Abstract (German) | C h a p t e r 7 | P a g e PAC mit alternativen Caching Methoden können Vorund Nachteile jeweiliger Strategien kompensiert werden. Drittens werden Lösungen zur automatischen Generierung einer Caching Heuristic präsentiert, welche eine Voraussetzung sind, um Zugriffskontrollentscheidungen vorauszuberechnen. Mittels der Caching Heuristic wird definiert, zu welchem Zeitpunkt während der Ausführung eines Geschäftsprozesses Zugriffskontrollentscheidungen vorausberechnet werden. Insbesondere auch, auf welcher Basis für Zugriffskontrollanfragen dies geschieht und zu welchem Zeitpunkt bereits gespeicherte Zugriffskontrollentscheidungen nicht mehr benötigt werden und somit aus dem Cache entfernt werden können. Viertens wird empirisch die Performance von PAC in Geschäftsprozessumgebungen analysiert und mit den Ergebnissen der Analyse alternativer Caching Strategien verglichen. Dies beinhaltet auch die Performanceanalyse des zuvor genannten hybriden Ansatzes. Fünftens wird eine allgemein einsetzbare Caching Architektur für die Anwendung von PAC in Geschäftsprozess-unterstützten Unternehmen beschrieben. Die Architektur ist jedoch nicht auf PAC beschränkt, vielmehr erlaubt sie allgemein die Integration von alternativen Caching Strategien. Insgesamt stellt diese Arbeit eine Lösung zur zeitoptimierten Bereitstellung von Zugriffskontrollentscheidungen vor. Die empirischen Ergebnisse zeigen, dass PAC die Antwortzeiten für Zugriffskontrollanfragen gegenüber einer Nicht-Optimierung als auch im Vergleich zu alternativen Caching Strategien signifikant reduziert. Gerade im Umfeld von Geschäftsprozessen mit häufiger Interaktion der Anwender in IT-Systemen sind schnelle Reaktionen auf Benutzereingaben elementar. Mit PAC können Zugriffskontrollanfragen nahezu direkt beantwortet werden. Acknowledgement | C h a p t e r 9 | P a g e Acknowledgements I am particularly thankful to my supervisor, Prof. Dr. Claudia Eckert, for her continuous support throughout this project and for her insigh"""	am broadcasting;access control;business process;cpu cache;cache (computing);die (integrated circuit);eine and zwei;erp;es evm;eckert–mauchly award;enterprise system;entscheidungsproblem;heuristic;information privacy;intentionally blank page;interaction;internet explorer;mathematical optimization;parity (physics);requirement;response time (technology);sie (file format);unified model;vhf omnidirectional range	Mathias Kohler	2011			real-time computing;false sharing;engineering;database;computer security	DB	-101.27634920239237	34.55307116741638	111256
25a5393e9a78bb3f321b326143118a682c4c1fde	automatisiertes headhunting im web 2.0: zum einsatz intelligenter softwareagenten als headhunting-robots		Der Beitrag skizziert aus Entwurfsperspektive ein automatisiertes agentenbasiertes Headhunting-System für Online Social Networks (OSN). Dabei werden neben der grundsätzlichen Projektidee makround mikroökonomische Modellierungsaspekte des Headhunting-Systems beleuchtet. Im Ergebnis zeigt sich, dass deliberative intelligente Softwareagenten prinzipiell geeignet sind, Headhunting-Aktivitäten im Bereich der Kandidatensuche zu automatisieren. Die Einführung von Entgelten für die jeweilige Nutzung der sozialen (Sub-)Netze der entsprechenden Akteure führt zur Evolution der OSN und zur Verbesserung der Netzqualität (Optimierung der Vernetzungsund Prestigemaße). Wertschöpfungsbezogen können die Akteure im OSN (potentielle Kandidaten, Vermittler, etc.) und die OSN-Betreiber von den Nutzungsentgelten und die Personalsuchenden von qualitativ hochwertigeren und schnell zur Verfügung stehenden Kandidatenlisten profitieren.	web 2.0	Ricardo Buettner	2011			world wide web;robot;headhunting;web 2.0;engineering	DB	-104.2521831606483	37.43498231562887	111494
f662080bacbccca25154baa04baffd500d495649	automatische medienanalyse im digitalen archiv durch einsatz von mpeg-7 und mxf		Die Rolle des Archivs in den Arbeitsabläufen der Rundfunkanstalten wird mit der Konvergenz von IT-, Kommunikationsund A/V-Technik immer bedeutender. Die Wiederverwertbarkeit von Beiträgen ist zu einem wichtigen Ziel der Medienindustrie geworden. Digitale Archive erlauben den direkten und gleichzeitigen Zugriff auf gespeicherten Content. Damit Inhalte schnell und zielgenau gefunden werden können, werden qualitativ hochwerige Metadaten benötigt. Im vorliegenden Beitrag wird das Medienanalysesystem iFinderSDK zur automatischen Erzeugung von MPEG-7-Metadaten vorgestellt. MPEG-7 bietet ein sehr detailliertes XML-basiertes Metadatenmodell zur effektiven Suche in großen multimedialen Archiven. Zur Integration der Medienanalyse in den digitalen Produktionsund Archivierungsworkflow der Rundfunkunternehmen ist jedoch auch ein Standardformat zum Austausch von A/V-Material nötig. MXF bietet sich für diesen Zweck als eine gute Lösung an. Ein Konzept zur Integration einer MXF-Schnittstelle in das bestehende Medienanalysesystem iFinderSDK wird im folgenden genauer beschrieben.	archive;eine and zwei;mpeg-7;material exchange format;xml	Felix Zielke;Jobst Löffler	2005				OS	-107.02424785831458	35.58294926713437	111568
11350a63d744a760dad3a97fc95f919ee566e9db	schwachstellen mit floss finden und verwalten		IT-Systeme werden schon vor der Auslieferung mit vielfältiger Software vorbereitet. Vielleicht ist dabei sogar daran gedacht worden, in diesen Systemen alle bekannten Sicherheitsaktualisierungen einzuspielen und gefährliche Konfigurationen anzupassen. Aber schon nach wenigen Wochen und manchmal nur Tagen sind diese Systeme schon wieder durch Schwachstellen gefährdet. Einmal beim Endanwender in Betrieb genommen, werden sie nur noch selten geprüft oder aktualisiert. Für den sicheren Betrieb der Systeme sind daher regelmäßige Prüfungen auf Schwachstellen erforderlich. OpenVAS ermöglicht dies automatisiert und unterstützt bei der Behebung der Schwachstellen.	citeseerx;openvas;sie (file format);vhf omnidirectional range	Wilhelm Merx	2014	Datenschutz und Datensicherheit - DuD	10.1007/s11623-014-0099-4	internet privacy;operating system;computer science	OS	-102.74591345374203	32.820537547865634	112045
9c9c9a5bb96b0583e5704e25b1f9eb80ddbda253	die problematik einer management information base (mib) für ein integriertes netzmanagement	management information base		management information system;mebibyte	Heinz-Gerd Hegering	1991	Inform., Forsch. Entwickl.		software engineering;database;management information base;osi model;computer science	AI	-100.27044779585009	32.37518994626033	112093
2c961de5f8f55645e4c09ccf9588c697e00536d8	organisationaler wandel durch die emergenz cyber-physikalischer systeme: die fallstudie avl list gmbh		Entwicklungen wie Web 2.0, Web 3.0 und Semantic Web haben nicht nur die Art und Weise verändert, wie Menschen miteinander interagieren. Durch den Einzug von Informations- und Kommunikationstechnologie in physische Produkte sowie in ihre Produktionsstätten werden auch Maschinen intelligenter und vernetzter. Aus mechatronischen Systemen entstehen zunehmend vernetzte cyber-physikalische Systeme (CPS). Doch deren erfolgreiche Entwicklung zwingt Industrieorganisationen zu einem Wandel. Die AVL List GmbH ist das weltweit größte unabhängige Unternehmen für Entwicklung, Simulation und Prüftechnik von Antriebssystemen für PKW, LKW und Großmotoren. Sie steht heute mehr denn je vor der Herausforderung, aktuelle und künftige Trends rund um CPS erfolgreich in eigene Produkte und Services zu integrieren. Der Beitrag erläutert nach einer Beschreibung der wesentlichen sozio-technischen Konzepte rund um CPS und Industrie 4.0, warum es in Organisationen wie der AVL zu Veränderungen kommen muss. Er diskutiert in der AVL durchgeführte Maßnahmen, wie etwa die Befähigung von technischem Personal zum Denken in Systemen durch die Einführung von modellbasiertem Systems Engineering, um dem durch CPS ausgelösten Paradigmenwechsel erfolgreich zu begegnen.	avl tree;industry 4.0;internet explorer;sie (file format);semantic web;simulation;systems engineering;unified model;vhf omnidirectional range;web 2.0	Andrea Denger;Johannes Fritz;Dirk Denger;Peter Priller;Christian Kaiser;Alexander Stocker	2014	HMD Praxis der Wirtschaftsinformatik	10.1365/s40702-014-0090-4	knowledge management;library science;engineering	DB	-102.449815834127	33.53059768204447	112170
713fcbea7c361a0b121ab7bba249e82181628106	wiederverwendung durch ablaufmodellierung bei der migration eines vertragsverwaltungssystems		In diesem Dokument wird dargestellt wie in einem Migrationsprojekt bei einem Lebensversicherer die Wiederverwendung vorhandener Komponenten durch den Einsatz von Ablaufmodellierung unterstützt wurde. 1 Projektaufgabe Die Migration eines Lebensversicherungsbestandes stellt aufgrund der fachlichen Komplexität der Daten und der Anwendungen ein sehr aufwändiges Geschäft dar, welches sich über Monate und oft über Jahre hinzieht. Die Projektaufgabe bestand darin, den Vertragsbestand aus einem Lebensversicherungs-Verwaltungssystem auf einem Großrechner (im folgenden als ‚Host’ bezeichnet) zu migrieren in ein neues Verwaltungssystem mit einer neuen Datenbank. Im Zuge dieser Migration mussten die Verträge, die am Host mit alten versicherungsmathematischen Modulen berechnet wurden (hier kurz mit ‚alter VM‘ und ‚sehr alter VM‘ bezeichnet) an eine neue Versicherungsmathematik (‚neue VM‘) angepasst werden. Abbildung 1: Beschreibung der Projektaufgabe Im folgenden wird nicht auf die Erstellung des neuen Vertragsverwaltungssystems eingegangen, sondern auf die Aufgabe der Migration, d.h. der Überführung des alten Vertragsbestands in die neue Umgebung. Dabei handelt es sich um eine stark vereinfachende Darstellung welche auf den Aspekt der Wiederverwendung von Software-Komponenten in verschiedenen Projektstufen fokussiert. 2 Projektstufen Die Überführung des Vertragsbestands fand in mehreren Stufen statt: altes Verwaltungssystem sehr alte VM alte VM alte Vertrags-DB neues Verwaltungssystem neue VM neue Vertrags-DB 2.1 Integration der neuen VM in die alten Anwendungen und Bestandsinitialisierung In einer ersten Stufe (Stufe 1) wurde die neue VM in die alten Anwendungen integriert: Dabei wurden die Berechnungen der alten VM durch die neue VM simuliert. Diese Simulation beinhaltet eine Konvertierung der Verträge in die Schnittstelle der neuen VM (Neue VM-SNT). Die Verträge, die mit der ‚alten VM‘ gerechnet wurden, wurden an die neue VM angepasst (der mit der alten VM gerechnete Vertragsbestand wurde ‚initialisiert‘). Die Verträge mit sehr alter VM wurden nicht verändert. Die Datenhaltung erfolgte weiterhin auf dem Host. Diese erste Stufe wurde in den Jahren 1998 – 2003 produktiv eingesetzt. In derselben Zeit wurde das neue Verwaltungssystem entwickelt. Abbildung 2: Stufe 1: Integration der neuen VM in die alten Anwendungen 2.2 Migration der in Stufe 1 initialisierten Verträge In der nächsten Stufe (produktiv seit 2002) erfolgt nun die Migration der in Stufe 1 initialisierten Verträge in das neue Verwaltungssystem. Im folgenden bezeichnen wir mit Migrationsweg 1 den gesamten Migrationsweg dieser Verträge bestehend aus der Bestandsinitialisierung (d.h. Anpassung an neue VM in Stufe 1) und anschließender Migration. 2.3 Migration der in Stufe 1 nicht initialisierten Verträge (Verträge mit sehr alter VM) In einer letzten Stufe (produktiv seit 2003) werden die in Stufe 1 noch nicht initialisierten Verträge, d.h. die Verträge mit sehr alter VM migriert. Ziel bei der Konzipierung dieses Migrationsweges (im folgenden mit Migrationsweg 2 bezeichnet) war es, möglichst viele der für den Migrationsweg 1 erstellten Software-Komponenten (eventuell mit leichten Änderungen) zu übernehmen. Zu berücksichtigen waren dabei die folgenden Vorgaben: Im Migrationsweg 2 soll die Anpassung an die neue VM und Überführung in die neue Vertrags-DB in einem Zug erfolgen. Zur Anpassung an die neue VM wird ein versicherungstechnisches Modul (VTM) eingesetzt. Host -DB Aufrufschicht Alte Anwendungen Verträge mit sehr alter VM Verträge angepasst an neue VM (initialisiert) sehr alte VM Konvertierung in Neue VM-SNT Neue VM Simulation alte VM durch neue VM 3 Vorgehen zur Erzielung von Wiederverwendung im Migrationsweg 2 Zur Identifikation von Wiederverwendungsmöglichkeiten der schon verfügbaren Software-Komponenten aus dem Migrationsweg 1 im Migrationsweg 2 wurde der bisherige Einsatz dieser Komponenten anhand einer groben Modellierung des IstAblaufs des Migrationswegs 1 (bestehend aus der Bestandsinitialisierung in Stufe 1 und der Migration der initialisierten Verträge) dargestellt. 3.1 Modellierung des Ist-Ablaufs im Migrationsweg 1 Abbildung 3: Vereinfachte Darstellung des Migrationswegs 1 durch ein Aktivitätendiagramm Vertrag mit alter VM in Host-DB INI1: Initialisierung der Records für neue VM teilinitialisierter Host-Vertrag Hinkonvertierung Vertrag--> VM-SNT Rückkonvertierung VM-SNT --> Vertrag initialisierter Vertrag in Host-DB Struktur Hinkonvertierung Vertrag--> VM-SNT Bestandsinitialisierung (1998/1999)	die (integrated circuit);eine and zwei;institut für dokumentologie und editorik;intentionally blank page;internet explorer;simulation;triple des;unified model;z/vm	Friederike Nickl;Christine Dobis	2004				OS	-105.46624642744592	33.43219130269261	112447
d9c222e81758e25e62057718b2c834fdc0a49d38	datenschutz in den vereinigten staaten von amerika	ciencias juridicas;dcho procesal y penal;dcho civil y mercantil	̧ Rechtsanwalt Dr. Mathias Lejeune, München. Der Beitrag ist Herrn Rechtsanwalt Prof. Dr. Jochen Schneider zum 70. Geburtstag im November 2013 gewidmet und drückt aufrichtige Dankbarkeit für eine langjährige Unterstützung und stets gute Zusammenarbeit aus. Der vorliegende Beitrag beschäftigt sich mit dem Datenschutz in den USA. Anlass zu prüfen, inwieweit überhaupt von einem effektiven Datenschutz im US Recht gesprochen werden kann, geben zunächst die Enthüllungen von Edward Snowden zu den Praktiken des amerikanischen Geheimmdienstes NSA. Desweiteren ist in diesem Zusammenhang die Entscheidung des U.S. Foreign Intelligence Surveillance Courts (FISC) vom 29.8.2013 zu erwähnen. Nach dieser Entscheidung unterliegen Telefon-Metadaten im US-Recht nicht dem verfassungsrechtlichen Schutz der Privatsphäre.		Mathias Lejeune	2013	Computer und Recht	10.9785/ovs-cr-2013-755		NLP	-103.44298664029269	35.3011275772658	112896
673a2a461ce47ee0ead5dc55ff9ca07b691c9ab5	dud recht		Zum Sachverhalt: Der Kläger nimmt die Beklagten auf Unterlassung angeblich persönlichkeitsrechtsverletzender Veröffentlichungen in Anspruch. Der Kläger, der als Friseur von zahlreichen Prominenten bekannt geworden ist, betreibt mehrere Friseurgeschäfte. Im März 2012 veröffentlichten die Beklagte zu 1 in der von ihr verlegten BILD-Zeitung und die Beklagte zu 2 in dem von ihr betriebenen Internetportal www.bild.de unter der Überschrift „Filialleiter von U. W. [voller Name des Klägers] mit ‚Hells Angels‘ verhaftet“ einen Artikel, in dem im Wesentlichen darüber berichtet wird, dass Benjamin S., ein Mitarbeiter des Klägers, zusammen mit einem Freund und zwei Mitgliedern der Gruppierung „Hells Angels“ wegen des Vorwurfs der versuchten schweren räuberischen Erpressung verhaftet worden sei. Wörtlich heißt es dazu unter anderem: „Als Filialleiter bei Promi-Friseur U. W. [voller Name des Klägers] (67) frisiert Benjamin S. (26) die Reichen und Schönen. Jetzt verhaftete das SEK den Kudamm-Geschäftsführer, einen Freund (29) und zwei „Hells Angels“-Rocker (25, 29)! Der Vorwurf: versuchte schwere räuberische Erpressung. Was hat der Figaro bloß mit den Rockern zu tun? [...] Dem Filialleiter tut jetzt alles leid. Über seinen Chef sagt er: ‚Ich bin im Kreuzberger Kiez groß geworden. U. [Vorname des Klägers] weiß, dass ich eine schwierige Vergangenheit habe. Er hat mir trotzdem eine Chance gegeben.‘“ Der Kläger ist insbesondere der Auffassung, er müsse es nicht dulden, für die Beklagten als Aufmacher für ein Ermittlungsverfahren gegen eine dritte Person herzuhalten. Er nimmt die Beklagten darauf in Anspruch, es zu unterlassen, ihn namentlich im Zusammenhang mit einer Festnahme eines Herrn Benjamin S. zu erwähnen, insbesondere wenn dies wie geschehen passiere. Das Landgericht hat der Klage stattgegeben. Das Berufungsgericht hat die dagegen gerichtete Berufung der Beklagten gemäß § 522 Abs. 2 ZPO zurückgewiesen. Mit der vom erkennenden Senat zugelassenen Revision verfolgen die Beklagten das Ziel der Klageabweisung weiter.	eine and zwei;equidistributed sequence;i/o controller hub;internet explorer;link rot;queen of angels;tun (product standard)	Zum Anspruch;Abs;I V M Art;Es Er	2015	Datenschutz und Datensicherheit - DuD	10.1007/s11623-015-0439-z		OS	-104.37935036320317	34.804319990482526	113417
c8508a7371ad552da6c4d17e1e46b8c3d2e5376b	it-integration und migration —konzepte und vorgehensweisen		Die Applikationslandschaft in den Unternehmen ist durch Heterogenität geprägt. Dies ist nicht nur eine Unzulänglichkeit in der gegenwärtigen Situation, sondern ein charakteristisches Merkmal, für das es diverse Gründe gibt. Da andererseits eine unternehmensübergreifend barrierefreie IT-Landschaft gefordert wird, werden verschiedene Lösungsansätze für die IT-Integration vorgestellt. Zukunftsweisend ist die serviceorientierte Architektur (SOA), da hier insbesondere in Verbindung mit der Web-Service-Technologie die wesentlichen Voraussetzungen für eine Integration auf der Basis von Standardadaptern sichtbar werden. Mit diesem Architekturmodell lässt sich eine unternehmensweite oder sogar unternehmensübergreifende Steuerung der Geschäftsprozesse mithilfe einer Prozess-Engine umsetzen. Die zugehörigen Migrationsprojekte weisen einige Besonderheiten auf, da unabhängig konzipierte Applikationen mit zum Teil recht unterschiedlichen Organisationsmodellen zu einem durchgängig funktionierenden System zusammengefügt werden müssen.	citeseerx;die (integrated circuit);eine and zwei;web service	Herbert Glöckle	2007	HMD Praxis der Wirtschaftsinformatik	10.1007/BF03341120	knowledge management;engineering;performance art	OS	-101.75734557364153	34.13231979112708	113911
94dcdb7c4eb898e3961f736974c874e2091d321f	algorithmische effizienzanalyse von ernteprozessketten		Insbesondere die zunehmende Nutzung von Biomasse a l Energierohstoff führt zu einem deutlichen Anstieg des Transpo rtaufkommens im Agrarsektor. Die Effizienz der Logistikketten ist dabei oftmals gering. Die vorgestellte Systemanalyse, basierend auf der Aufzeichnung von Positio n daten, welche mit speziellen Algorithmen ausgewertet werden, ermittelt Schwachst ellen in der LogistikPlanung und bildet die Basis für eine systematische Optimierung.	eine and zwei	Valentin Heizinger;Heinz Bernhardt	2012				DB	-104.71688578024093	32.4837569829819	114236
05043e2e1aa1d2e4e249e7b4947aaedf0f4656e5	erfahrungsbericht zur lehrevaluation der informatik in paderborn	erfahrungsbericht zur lehrevaluation der	Das Fach Informatik an der Universitat-GH Paderborn hat von Mitte 1996 bis Mitte 1997 eine Evaluation von Studium und Lehre durchgefuhrt. Wir haben damit sehr positive Erfahrungen gemacht, die wir in diesem Artikel weitergeben mochten. Ein solcher Bericht aus der Sicht des Faches mag die eher methodischen Beschreibungen von Evaluationsinstitutionen nutzlich erganzen. Zusammen mit dem Material aus Evaluationen anderer Informatik-Bereiche soll er die Basis ubertragbarer Erfahrungen verbreitern.		Uwe Kastens	1998				Vision	-103.89278435252929	34.14812409313103	114597
9554141aee822a9a906f018f0cb91fd8926d72bd	die partizipative erstellung und nutzung eines multimedialen lernmoduls		Virtuelle Organisationen erobern eine wachsende Bedeutung im Alltag. Wir haben ein sozio-technisches Konzept entwickelt, das komplexe und flexible Lernprozesse in diesem Rahmen ermöglicht. Das Konzept umfasst den gesamten Zyklus der Entwicklung und Produktion bis zur Bereitstellung und Nutzung eines begleiteten Lernmoduls und die Evaluation. Die Nutzer sind in den gesamten Prozess aktiv eingebunden. Die Erfahrungen aus einer ersten Umsetzung berichten wir hier.	die (integrated circuit);eine and zwei	Dian Tan;Torsten Engelskirchen	2003				AI	-104.12533225560053	32.73136225733721	115147
411aede26ebeb626d97dd73d286c7c6fb7c16555	das meta-elgamal signaturverfahren und seine anwendungen		Ausgehend vom ElGamal Signaturverfahren werden das Meta-ElGamal Signaturverfahren und einige Anwendungen vorgestellt. Diese sind im einzelnen Meta-Authentifikationsschemata, selbstzertifizierende offentliche Schlussel und Meta-Schlusselaustauschprotokolle. Einige der dabei abgeleiteten Varianten sind effizienter als die bisher bekannten Protokolle.		Patrick Horster;Markus Michels;Holger Petersen	1995			algorithm;elgamal encryption;computer science	Robotics	-104.6754496534324	32.35433102239951	115155
d0d3221e296395f4329397ab573ea41f9063364b	computing simple bifurcation points using a minimally extended system of nonlinear equations	extended system;bifurcation points;nonlinear parameterdependent equations;minimally extended system;local convergence.;branch points;computing simple bifurcation point;nonlinear equation;newton-like method	The present paper deals with the computation of simple bifurcation points of nonlinear parameter dependent equations. At first, a minimally extended system of nonlinear equations is constructed by addition of one parameter and two equations. This augmented system has an isolated solution which yields to the simple bifurcation point directly. Using the structural properties of this auxiliary system an adapted Newton-like method is developed not requiring evaluations of second derivatives. Finally, the results of some computer experiments show the efficiency of theR-quadratically convergent method. Es wird eine Vorgehensweise zur Berechnung einfacher Bifurkationspunkte nichtlinearer, von einem Parameter abhängender Gleichungssysteme vorgestellt. Zunächst wird das ursprüngliche Gleichungssystem um einen Parameter und zwei Gleichungen erweitert. Das so erhaltene System besitzt eine reguläre Lösung, aus der unmittelbar der gesuchte Bifurkationspunkt abgelesen werden kann. Aufgrund der speziellen Struktur dieses Systems wird ein Newton-ähnliches Verfahren abgeleitet, das ohne die Berechnung zweiter Ableitungen auskommt. Abschließend wird die Wirksamkeit des vorgeschlagenenR-quadratisch konvergenten Verfahrens an einfachen Beispielen demonstriert.	bifurcation theory;computation;eine and zwei;experiment;newton;nonlinear system;rate of convergence;unified model	Gerd Pönisch	1985	Computing	10.1007/BF02240195	mathematical optimization;discrete mathematics;nonlinear system;control theory;mathematics;bifurcation theory	Robotics	-96.3347431148771	35.94935919753016	115427
c1fe19a942e426fca3b5724d4b10fb395cb7fe3d	balance der schmerzen		in den Jahren nach dem Kriege half uns Amerika mit Marshall-Plan und privaten Zuwendungen wieder auf die Beine; das machte uns die Amerikaner sympathisch. Darüber, wie zu helfen ist, hatten sie meist vorgefasste Meinungen. Dass etwa ein niederbayerischer Bauer anders geartet ist als ein Farmer in Idaho, ließ damals mein amerikanischer Gesprächspartner als Argument nicht gelten: „Bullshit, people are the same all over the world.“ Eben das bestritt ich. Nun allerdings, da der American Way of Life, die amerikanische Lebensart, weltweit angenommen wird, würde ich darüber nicht mehr so pauschal streiten. Die Völker mögen ungleich sein; wenn sie aber miteinander verkehren und leben wollen, geht das nur über einen Mindestsatz gemeinsamer Normen. Sie werden sich zum Schmerz der Traditionalisten mit der Zeit immer gleicher. Deutschland hat sich im 19. Jahrhundert stark verändert. Vorher wurde es fleckenweise von unabhängigen absoluten Monarchen regiert. Dann kam Napoleon, unterwarf und re or ganisierte das Land. Seine Herrschaft hatte den Deutschen ihre Gemeinsamkeiten bewusst gemacht. Die Unterschiede aber waren noch da; etwa in Preußen zwischen dem agrarischen Ostelbien und der anbrechenden Industriegesellschaft in den rheinischen Provinzen. Die feudale Struktur Deutschlands wurde restauriert, doch das Miteinander musste neu organisiert werden. Un ter anderem wurde ein Erneuerungsund Angleichungsprozess im Rechts we sen unternommen. Die Hegel’sche Philosophenschule war für eine ganzheitliche Sicht des Menschen und für ein aus dem natürlichen Rechtsgefühl abgeleitetes, neues Recht. Die Politik aber hielt sich unbeirrt an die altdeutschen Weisheiten und an den im Rheinbund praktizierten Code Napoleon. Am Ende des Jahrhunderts standen die positivistischen Gesetzbücher fest. Die Rechtspraxis war vereinheitlicht; die Deutschen waren sich gleicher geworden; das Naturrecht war noch leer ausgegangen. Erst ein halbes Jahrhundert danach war es als Ergebnis globaler Anstrengungen wieder da: in Form der Allgemeinen Erklärung der Menschenrechte. Zwanzig Jahre später war diese Erklärung die Grundlage für den Datenschutz. Nun haben wir eine Europäische Union, die ähnlich wie seinerzeit Deutschland zu ihren gesellschaftlichen Normen finden muss. Die EU-Kommission hat vor 6 Jah ren für die öffentliche Sicherheit und die Sicherheit der Person die „Richtlinie 2006/24/EG über die Vorratsspeicherung von Daten“ erlassen. Diese muss von den Staaten in nationales Recht umgesetzt werden. Deutschland zögert damit, denn nach Spruch des Bundesverfassungsgerichts verstößt Vorratsdatenspeicherung gegen den Datenschutz. Die Umsetzungsfrist ist verstrichen. Die EU-Kommission verklagt Deutschland beim Europäischen Gerichtshof wegen Verletzung der EU-Verträge. Sie will aber auch die Richtlinie überarbeiten, um Datenschutzempfindlichkeiten nach Möglichkeit zu berücksichtigen. Die Zeiten sind bewegt. Datenschutz, Menschenrechte, Naturrecht stiften derzeit Unruhe in Europa. Die Menschen wollen Schutz vor Missbrauch ihrer Daten, aber auch Schutz ihres Menschenrechts auf „Leben, Freiheit und Sicherheit der Person“. Die Polizei muss diesen Schutz gewährleisten. Sie will dazu Daten auf Vorrat speichern. Soll sie das dürfen? Darüber gibt es Streit. Eine gelungene technische Lösung könnte den Streit überflüssig machen. Wenn sie nicht gelingt, müssen die Betroffenen bereit sein, für die Gewährleistung des einen Rechtsgutes eine begrenzte Verletzung des anderen zu akzeptieren. Man könnte wohl, liebe Leserinnen und Leser, die Verluste gegeneinander abwägen und unter Partnern auf einem demokratischen Wege die Entscheidung finden. Diese kann aber nur in dem Sinne gerecht sein, dass jedem Partner sein Stückchen Verlust gleich weh tut. Balance der Schmerzen. So lange es aber weh tut, bleiben die Partner Gegner. Man kann hoffen, dass sie bezüglich eines ausgewogenen Bedarfs an Menschenrechten zusammenfinden, dass die Unterschiede sich verlieren, dass die Schmerzen nachlassen, und dass sich damit die Gegner als Europäer ein Stückchen gleicher werden.	die (integrated circuit);eine and zwei;entscheidungsproblem;europa;gesellschaft für informatik;i/o controller hub;institut für dokumentologie und editorik;intentionally blank page;internet explorer;nakajima–zwanzig equation;sie (file format);unified model;vhf omnidirectional range;zentralblatt math	Karl Rihaczek	2012	Datenschutz und Datensicherheit - DuD	10.1007/s11623-012-0123-5	internet privacy;computer science;computer security	AI	-104.85608399794465	35.85015210733458	115596
91a9872711f1ee84e6b605a4669c230c73096a8f	knowledge communities - virtuelle lerngemeinschaften als binderglied zwischen elearning und wissenmanagement	und wissenmanagement;knowledge communities;virtuelle lerngemeinschaften al	Knowledge Communities sind elektronisch gestützte Gemeinschaften, die den kollaborativen Aufbau und Austausch von Wissen fördern. Sie kombinieren Ansätze aus den Bereichen eLearning, Groupware und Wissensmanagement und reichern sie um Konzepte der relativ jungen Disziplin Community Management an. Als universelle Kommunikationsund Kollaborationslösung eignen sie sich für eLearning und Wissensmanagement gleichermaßen und schlagen eine Brücke zwischen beiden Welten. Der vorliegende Beitrag motiviert den Einsatz einer virtuellen Wissensgemeinschaft und erläutert den Aufbau und die Funktionsweise einer Knowledge Community am Beispiel von wissensplanet.de, einer Community zum Thema eLearning.	collaborative software;eine and zwei;sie (file format);unified model	Thomas Brückner	2002			alkoxy group;alkyl;medicinal chemistry;oxygen;thiol;phos;halogen;hydrogen;sulfur;chemistry	DB	-107.30033902576008	34.229593222358936	115734
b9b24a5a8b921405174cb773c8dcdb09dd0cb4de	ein umweltwissenssystem zur semantischen vernetzung forstwirtschaftlicher datenquellen		Der Beitrag fokussiert den Einsatz von „Intelligenten Systemen“ zur Zusammenführung von Umweltinformationen durch die Verwendung von semantischen Technologien wie etwa Linked (Open) Data hin zu Umweltwissen. Dieses Umweltwissen kann in der Konsequenz z.B. zur Entscheidungsunterstützung der forstwirtschaftlichen Nachhaltigkeit durch die betroffenen Stakeholder verwendet werden. Die zugrunde liegende Forschungsfrage liegt darin, dass Umweltinformationen heute noch autark bzgl. Themen oder von Institutionen erfasst werden, aber eine Vernetzung und Anwendbarkeit im Sinne des Wissensmanagements noch wenig stattfindet. Dieses Wissen fehlt dementsprechend für die Erkennung von Umwelttrends oder in Entscheidungssituationen. Der Beitrag betrachtet die Frage, wie eine Zusammenführung und Vernetzung von unterschiedlichen Datenquellen mittels semantischer Technologien bzw. mittels Wissensmanagementverfahren stattfinden kann. Zur Abbildung des Anwendungsszenarios wird ein Vernetzungsszenario dargestellt. Es wird erläutert, welche Möglichkeiten bestehen, aus einem reinen Informationssystem ein Umweltwissenssystem zu etablieren, um letztendlich einen Aspekt eines Grünen Wissensmanagements umzusetzen. Das vorliegende Papier fokussiert aufgrund der begrenzten Seitenzahl die logische Schicht des Umweltwissenssystems.	eine and zwei;information system;internet explorer;linked data;unified model	Mareike Dornhöfer;Alexander Holland;Madjid Fathi	2016					-103.03733012768689	34.16598029987139	115864
2c9e21c37fd5680e15841f9e711b2b878df68b40	graph-basierte facettierte erstellung von semantischen suchanfragen	facettierte suche;semantic web;graph basierte visualisierung;talk;hierarchische facetten	In diesem Beitrag stellen wir einen neuen Ansatz zur Graph-basierten Visualisierung hierarchischer Facetten vor. Die Repräsentation der Facetten durch Knoten, sowie deren Beziehungen durch gerichtete Kanten zwischen den Knoten, erlauben eine zusammenhängende, erweiterbare und leicht verständliche Darstellung und damit die einfache Erstellung auch komplexer semantischer Suchanfragen.	eine and zwei;vhf omnidirectional range	Philipp Heim;Jürgen Ziegler	2009			natural language processing;world wide web;information retrieval	OS	-106.49379249387754	35.56564550073575	115971
3c5a97b0512341c862184d3b54287d7e76650194	halteprobleme von fang-systemen (tag systems)		"""Im Jahr 1943 berichtete E. L. Post 1-6] fiber ein ihm ,,intractable"""" erscheinendes, von B. P. Gilt ,,tag system"""" genanntes normales System. Daraufhin besch~iftigten sich M. L. Minsky, H. Wang, S. Aanderaa u.a. mit diesen tag systems, hier Fang-Systeme. Minsky [4] land als erster ein Fang-System, dessen Halteproblem unentscheidbar ist. Wang 1-7] gab eine Klassifizierung nach der Abschlagzahl (deletion number) an : (i) alle Fang-Systeme mit Abschlagzahl 1 haben ein entscheidbares Halteproblem, (ii) zu jeder Zahl p > 1 gibt es ein Fang-System mit Abschlagzahl p und unentscheidbarem Halteproblem. Aanderaa und Belsnes [1], deren Terminologie wir weitgehend fibernehmen, zeigten; dab in jedem rekursiv aufz~ihlbaren m-Grad (many-one degree) das Halteproblem eines Fang-Systems liegt. Es blieb hierbei often, ob ihr Ergebnis auch fiir Fang-Systeme gilt, deren Abschlagzahlen durch eine feste obere Grenze beschr~inkt sind. Wir werden beweisen:"""	aanderaa–karp–rosenberg conjecture;eine and zwei;gab;gradient;many-one reduction;rekursiv;tag system	Bernhard Falkenberg	1980	Arch. Math. Log.	10.1007/BF02011140	algorithm;mathematics;halting problem;fang	DB	-99.52400053432319	36.65584694989664	116122
42435c2b3a5034fc9ec4706a59382eada674c088	auswirkungen der digitalisierung im handel am beispiel des retourenprozesses		Durch die Digitalisierung haben sich die Arbeitswelten im Handel grundlegend verändert. So verlagert sich der deutsche Einzelhandel immer mehr in den E-Commerce. Ein Kernprozess im E-Commerce ist der Retourenprozess. Diesem wird aufgrund seiner meist kostenintensiven Durchführung ein großes Optimierungspotenzial zugeschrieben. Um die Kosten zu minimieren, arbeiten die E-Commerce-Händler an Strategien zur Retourenvermeidung und zur Optimierung der Retourenbearbeitung. Im Rahmen dieser Strategien finden vermehrt innovative Technologien und weitere Elemente der voranschreitenden Digitalisierung Anwendung. Wie der Einsatz von Technologien die Arbeitswelt im Umfeld des Retourenprozesses verändern kann, wird in diesem Beitrag näher beleuchtet. Auf Basis des Retourenbearbeitungsprozesses werden Digitalisierungselemente vorgestellt, die in Zukunft die Arbeitswelt bei der Durchführung dieses Prozesses zum Teil deutlich verändern können. Diese Elemente reichen von Softwaresystemen zur Nachverfolgung der Retoure und Prognosesystemen durch Big Data für das tägliche Retourenaufkommen, die einen besseren Personaleinsatz versprechen, über unterstützende Systeme bei der Erfassung von Retouren (RFID, Smartglasses, Spracheingabe) bis hin zu Robotersystemen, die manuelle Arbeitsschritte vollständig automatisieren können. Welchen Einfluss die unterschiedlichen Digitalisierungselemente auf die Retourenbearbeitung haben können, wird im Rahmen einer Expertenbefragung eruiert. The Working environment in trade has fundamentally changed due to growing digitization. Thus, the German retail sector is moving straight towards electronic commerce. A key process in e-commerce is the returns process, mostly due to its costly implementation. To minimize costs, e-commerce merchants are working on strategies to avoid returns and to optimize the processing of returns. Part of these strategies are innovative technologies and other elements of progressive digitization. This paper examines how the use of technology can change the working environment with regard to the returns process. Primarily, digitization elements that can change the working environment of the returns handling process in future are introduced. These include software systems which track returns, forecasting systems which predict daily return traffic, support systems which help to register returns (RFID, smartglasses, voice input) and robotic systems. An expert survey shows the influence the methods of digitization can have on the returns process.	am ag:prthr:pt:rbc^donor:ord;androsace septentrionalis;big data;die (integrated circuit);diethylstilbestrol;e-commerce;endometrial intraepithelial neoplasia;fear of having a social problem;handel;handel-c;handling (psychology);internet explorer;projections and predictions;radio frequency identification device;robot;smartglasses;software system;support system;unified model	Stefan H. M uller Weinfurtner;Gregor Zellner;Stefan Münch	2015	HMD Praxis der Wirtschaftsinformatik	10.1365/s40702-015-0195-4	engineering;marketing;performance art	DB	-99.77963062804346	33.837559821313285	116261
dabd0f0552f3243afd72f376a62d17942c5f55b4	realisierung eines clients zur visualisierung von verteilten xml-dokumenten für ein informationssystem in der landwirtschaft		XML hat sich als wichtige Technologie für den elektronischen Datenaustausch im Web etabliert. Auch in der Landwirtschaft hat XML durch die Entwicklung von agroXML ihren Einzug erhalten. Gegenstand der Masterarbeit ist die Entwicklung eines Clients, der eine integrierte einheitliche Sicht auf vernetzte und verknüpfte XML-Dokumente bietet. Wichtiges Ziel ist die Erweiterbarkeit und die Flexibilität der Anwendung, die durch den entwickelten Ansatzes zur Laufzeit ein XML Data Binding herstellt. Aufbauend auf diesem Ansatz werden eine dynamische Formulargenerierung, sowie weitere Ansichten zur Visualisierung von verteilten XML-Dokumenten umgesetzt.	eine and zwei;information system;xml data binding	Ronnie Kullick;Daniel Martini;Hans-Peter Wiedling	2010			world wide web;xml;computer science	Web+IR	-105.69848984877251	35.639683809089064	116459
9205b6f8a6eda1022290f2f0ad039448f726c69b	randbedingungen für protokolle zur transaktionsorientierten datenverarbeitung in verteilten realzeitsystemen		Die transaktionsorientierte Datenverarbeitung ist bisher eine Domane der (verteilten) Datenbankmanagementsysteme, wohingegen der Begriff zeitgerecht in angestammten Gebieten der Realzeitdatenverarbeitung zu Hause ist, die die Automatisierung technischer Prozesse zum Ziel hat. In diesem Beitrag wird untersucht, inwieweit die Konjunktion zwischen den beiden Attributen transaktionsorientiert und zeitgerecht gerechtfertigt ist. Nach einer Begriffsklarung werden die Randbedingungen fur eine transaktionsorientierte Verarbeitung unter Realzeitbedingungen naher untersucht und am Beispiel des 2-Phasen-Commit-Protokolls auf notwendige Modifikationen eines Protokolls zur Gewahrleistung der Atomizitat eingegangen.		K. Stieger	1991		10.1007/978-3-642-77060-9_58		Crypto	-104.3027651032341	32.44741022309873	116510
1a83f3b997b1ee727a7b4c308381197c977e7425	themenschwerpunkt „logistik“		Logistik umfasst verschiedene Aufgaben, welche die Planung und Steuerung von Prozessen zum Transport von Entitäten bspw. Güter und Daten betreffen. Hierbei sind Problemstellungen auf unterschiedlichen Ebenen vom Management bis hin zum Materialfluss zu lösen. Durch die hohe Komplexität der logistischen Szenarien und Entscheidungsprozesse sowie eine mögliche Verteilung auf verschiedene Organisationen ist die Unterstützung durch KITechnologien notwendig oder zumindest für die Optimierung von Abläufen zur Einsparung von Zeit und Kosten hilfreich. Wie die Beiträge in diesem Schwerpunktheft zeigen, bestehen hierbei viele Möglichkeiten, Methoden aus der Künstlichen Intelligenz einzusetzen. Der Fachbeitrag von Günther und Nissen betrachtet die untertägige Personaleinsatzplanung für einen Logistikdienstleister. Die Problemstellung wird in dem Beitrag durch Particle Swarm Optimization und Evolutionsstrategien angegangen. Die Behandlung dynamischer Ereignisse wird in dem Fachbeitrag von Sauer sowie dem Projektbeitrag von Pulter, Nimis und Lockemann adressiert. Im ersten Fall wird die vertikale Datenintegration für ein reaktives Scheduling in Supply Chains diskutiert. Pulter et al. präsentieren das Projekt LogoTakt, in dem ein Störungsmanagement für offene, getaktete Logistiknetze entwickelt wird. Hellingrath und Böhle diskutieren in ihrem Fachbeitrag den Einsatz von Multiagentensystemen für die Produktions-und Logistikplanung in der Supply Chain, wobei insbesondere diskutiert wird, wie die Entwicklung von Agentensystemen erfolgen könnte, um die Anfor-	die (integrated circuit);eine and zwei;gesellschaft für informatik;internet explorer;particle swarm optimization;schedule (project management);unified model	Andreas D. Lattner;Ingo J. Timm	2010	KI - Künstliche Intelligenz	10.1007/s13218-010-0042-2		AI	-102.64553358476395	32.703433049354146	117112
d07717cc4bdccb496f58b0d0355aa15afe32d66f	computergestützte hochschullehre - das chl-konzept		Zusammenfassung: cHL stellt ein an der Universität Münster entwickeltes E-Learning-Konzept dar, mit dem das Ziel verfolgt wird, die Qualität der Lehre und des Lernens zu verbessern. cHL ist ein wirtschaftsinformatorischer Ansatz, dessen Architektur Subsysteme umfasst, die primär die Rollen des Studierenden und des Lehrenden unterstützen. Im Rahmen dieses Beitrags werden die Komponenten der cHLRahmenarchitektur skizziert. Von grundlegender Bedeutung für die informationstechnologische Unterstützung universitärer Lehrund Lernprozesse ist die Verfügbarkeit einer geeigneten Softwareplattform, die administrative Funktionen bereitstellt. Am Institut für Wirtschaftsinformatik wurde zu diesem Zweck das Open Source-Softwareprodukt OpenUSS (Open University Support System) entwickelt, das in diesem Beitrag schwerpunktmäßig dargestellt wird, zumal diese Komponente auch zunehmend international eingesetzt wird.	am broadcasting;aldert van der ziel	Heinz Lothar Grob;Frank Bensberg	2003				OS	-103.3127383167047	33.298820921764964	117271
067aea117f4cff99bf967a46148703028445a51e	elektronische archivierung — aufbewahrungspflichten nach handels- und steuerrecht		Der Trend zur vollständigen elektronischen Archivierung von Dokumenten erfasst alle Lebensbereiche. Es stellt sich daher auch die Frage, welche rechtlichen Vorgaben bei der elektronischen Archivierung von handels- und steuerrechtlich relevanten Unterlagen zu beachten sind. Der nachfolgende Beitrag befasst sich mit den rechtlichen Vorgaben für die Aufbewahrung dieser Unterlagen. Der Schwerpunkt liegt dabei auf den geltenden Regelungen für die elektronische Archivierung.	blitzkrieg;perm (computer)	Rainer Spatscheck;Sebastian Engler	2009	Datenschutz und Datensicherheit - DuD	10.1007/s11623-009-0179-z	computer science;internet privacy	ML	-103.77644829992269	36.23136737772126	117423
ee163a7cc8d008a4ab30a32e81e95568e4e9d597	"""interview mit jörg lübcke zum thema """"digitalisierung der geschäftsmodelle in der medienindustrie"""""""		Dr. Jörg Lübcke ist seit 2010 Geschäftsführer der Burda Digital GmbH. Der Bereich Digital von Hubert Burda Media bündelt die strategischen Internetaktivitäten des Konzerns. Zu den Unternehmen zählen E-Commerceund Vermarktungsplattformen, Direktmarketing, Kundenmanagement, Empfehlungsund Vermittlungsportale ebenso wie Social-Media-Beteiligungen und ein Corporate-Venture-Beteiligungsgeschäft. Der Anteil der Digital-Sparte am Konzernumsatz belief sich im Jahr 2012 auf über 1 Mrd. EUR und lieferte damit knapp die Hälfte des Gesamtumsatzes. Zuvor arbeitete Dr. Jörg Lübcke als u. a. als Mitglied der Geschäftsleitung bei der internationalen Unternehmensberatung Booz & Company sowie als Bereichsleiter bei Giesecke & Devrient GmbH. Dr. Lübcke studierte Wirtschaftswissenschaften mit den Schwerpunkten Finanzwissenschaft und Management an der Freien Universität Berlin, wo er auch promovierte.		Martin Spann	2013	Wirtschaftsinformatik	10.1007/s11576-013-0364-4		OS	-102.93048671953184	35.01850474717762	117951
4056383b2ddb8ebdee1b8939a049a0bf91fd6571	curve interpolation with constrained length	spline;interpolation;esplin;fonction reguliere;interpolacion;maillage;polynomial;algorithme;algorithm;celdarada;polinomio;spline function;grid pattern;funcion regular;esplin cubico;spline cubique;polynome;smooth function;cubic spline;algoritmo	We consider the problem of finding a curve which interpolates at given points such that (approximately) the length of the curve between each two subsequent interpolation points is equal to some given number. We only consider the functional case. We give an algorithm which yields an interpolating cubic polynomial spline. In case the data is taken from a (smooth enough) function this spline function converges at least quadratically in the mesh size to the original one. If the mesh is ‘regular enough’ it is even third order accurate. We also given an extension to the bivariate case. For the univariate case it will be shown that the length on each interval of this constructed spline at most differs quadratically in the mesh size from the actual lengths. Assuming regularity on the partition this estimate can also be improved by one order. Wird befassen uns mit dem Problem, eine Kurve zu bestimmen, die in gegebenen Punkten interpoliert und deren Länge zwischen zwei aufeinanderfolgenden Punkten (näherungsweise) gleich einer vorgegebenen Zahl ist. Wir betrachten dabei den Fall, daß die Kurve durch eine Funktion gegeben ist. Es wird ein Algorithmus zur Berechnung eines interpolierenden kubischen Splines vorgestellt. Für Interpolationsdaten von einer (genügend) glatten Funktion ist die Konvergenz der Spline-Funktion mindestens quadratisch in der Maschenweite. Bei (genügend) regulärem Gitter tritt sogar eine Konvergenz der Ordnung drei auf. Wir betrachten ferner den zweidimensionalen Fall. Für den eindimensionalen Fall zeigen wir, daß auch der Fehler des berechneten Splines in der vorgeschriebenen Länge zwischen den Gitterpunkten quadratisch mit der Maschenweite abnimmt. Auch hier erreicht man bei regulärem Gitter eine Erhöhung der Konvergenzordnung um eins.	algorithm;bivariate data;cubic function;eine and zwei;gitter;interpolation;polynomial;regular expression;spline (mathematics);unified model	Ruud van Damme;R.-H. Wang	1995	Computing	10.1007/BF02238080	spline interpolation;spline;mathematical optimization;mathematical analysis;mathematics;geometry;flat spline;algorithm	Theory	-96.6250002641671	36.19685519167691	118193
63cf36f6a7c0de40623f78e20870153438bbe504	selbstorganisierende smart-kamera-systeme		Zukünftige Systeme zur Überwachung von großen Flächen werden auf der Basis von verteilten intelligenten Kamerasystemen entwickelt werden. Aufgaben solcher Systeme sind beispielsweise das Verfolgen und Zählen von bewegten Objekten und die Analyse ihres Bewegungsverhaltens. Jede dieser Smart-Kameras ist ein autonomer Knoten, ausgestattet mit einem Schwenk-/Neige-/Zoom-Aktuator (PTZ für pan/tilt/zoom), Verarbeitungsressourcen und einer Kommunikationsschnittstelle. Dieser Beitrag gibt einen Überblick über das Forschungsgebiet der Smart-Kamera-Systeme und Beispiele für verteilte Steuerungsalgorithmen, welche die systemweite Selbstorganisation ermöglichen. Der Begriff Selbstorganisation beinhaltet einen integrierten Ansatz zur Selbstkonfiguration, Selbstoptimierung (Smart-Kameras konfigurieren und optimieren ihre Sichtbereiche) und Selbstheilung (Smart-Kameras übernehmen Aufgaben ausgefallener Knoten). Smart-Kamera-Systeme werden dabei als verteilte Systeme auf der Basis von Ad-hoc-Netzen modelliert. Diese Architektur erlaubt es, die Nachteile bisheriger zentraler Ansätze in den Bereichen Skalierbarkeit und Fehlertoleranz zu vermeiden.	bielefeld conspiracy;hoc (programming language);pan–tilt–zoom camera;smart tv;système universitaire de documentation	Jörg Hähner;Uwe Jänen;Carsten Grenz;Martin Hoffmann	2012	Informatik-Spektrum	10.1007/s00287-012-0594-7	world wide web;operating system;computer science	OS	-105.18363343381223	36.838768026344255	118284
49ffef14a021fcea28391e76c9b98db0ed2f2f40	vorgehensmodelle für die rollenbasierte autorisierung in heterogenen systemlandschaften	modelizacion;controle acces;licence procedure;paysage;securite informatique;autorizacion;paisaje;autorisation;integration;computer security;modelisation;seguridad informatica;authorization;access control;information system;landscape;modeling;architecture;systeme information;roles;sistema informacion	Der State-of-the-Art in Forschung und Praxis zur Autorisierung in heterogenen Systemlandschaften wird dargestellt. Folgende Ergebnisse konnen aus der Analyse abgeleitet werden:#R##N##R##N##R##N#Die existierenden Forschungsbeitrage enthalten nur wenig detaillierte Vorgehensmodelle zur Integration der rollenbasierten Autorisierung.#R##N##R##N##R##N#Die Praxis halt konkretere Ansatze bereit, die als Ausgangspunkt fur verbesserte Vorgehensmodelle dienen konnen.#R##N##R##N##R##N#Durch eine Kombination von Erkenntnissen aus Theorie und Praxis kann die Grundlage fur ein verbessertes Vorgehensmodell geschaffen werden.		Felix Wortmann;Robert Winter	2007	Wirtschaftsinformatik	10.1007/s11576-007-0096-4	telecommunications;computer science;access control;architecture;landscape;authorization;information system	Logic	-103.16080972301062	37.654764689118984	118587
f35eb87e141b6c55e432f223247c367c33045744	die gestaltungsfähigkeit öffentlicher verwaltungen und die legitimationsfähigkeit von automationszielen	higkeit von automationszielen	Die bisherigen Anwendungen der Informationstechnologie in den Einheiten der offentlichen Verwaltung sind durch wenige oder nicht operationable, haufig auch widerspruchliche Grundsatzentscheidungen der politischen Ebene gekennzeichnet — fur mehr Burgernahe, mehr Wirtschaftlichkeit, mehr Integration -, aus denen dann die „Macher“ in Ministerien, Rechenzentren, DV-Abteilungen im Rahmen der finanziellen, organisatorisch-technischen und personellen Moglichkeiten fast jede „machbare“ Losung legitimieren konnten und konnen. So werden immer wieder als Ziele der Automation genannt:2)rnrnrnVerbesserung der Arbeitssituation der Mitarbeiter durch Entlastung von minderwertigen Arbeiten und Routinetatigkeiten sowie einfachen Kontrolltatigkeiten,rnrnrnVerbesserung der Beziehungen zum Burger durch Verdichtung des Informationsaustausches, Gewahrleistung einheitlicher Rechtsanwendung, Verringerung der Fehleranfalligkeit und Verbesserung der Arbeitsqualitat und des Arbeitsproduktes,rnrnrnVerbesserung der Effizienz und Steuerungsfahigkeit des Verwaltungsapparates durch rasche Anpassungsfahigkeit an gesetzgeberische Masnahmen, Erhohung der internen Flexibilitat und Mobilitat, grosere Kontrolldichte, Produktion von Informationen fur soziale und wirtschaftspolitische Masnahmen,rnrnrnVerbesserung des Kosten-Nutzen-Verhaltnisses durch Verzicht auf Personalvermehrung bei Steigerung der Verwaltungsaufgaben nach der Fallzahl und/oder ihrer Komplexitat, durch Erhohung der Arbeitsdichte in bisher eher vernachlassigten Aufgabenbereichen, durch Ertragssteigerung aufgrund automatisch uberwachter Zahlungstermine und automatischer Festsetzung von Saumniszuschlagen sowie durch Zinsgewinn,rnrnrnStabilisierung der Organisationsstrukturen durch aufgabenspezifische Nutzung der Informationstechnologie, Verbesserung des Informationsaustausches zwischen den verschiedenen Verwaltungsebenen und zwischen verschiedenen Verwaltungen.		Klaus Grimmer	1980		10.1007/978-3-642-68084-7_43	performance art;history	NLP	-104.590619782837	33.52961659365999	118640
99f397b6c0f05428efe7ae1f1eeed1f08fa179b7	governance von globalen it-projekten — eine dynamische kontrollperspektive		IT-Projekte verfügen über eine hohe strategische Bedeutung. Zur systematischen Umsetzung von IT-Projekten wurde eine Vielzahl von Projektmanagementstandards entwickelt. Diese Standards führen aber oftmals zu einer überbetonung von traditionellen, formalen Managementmechanismen und fokussieren auf die Rolle des Projektmanagers. Anhand von zwei globalen IT-Großprojekten eines Sportartikelherstellers zeigt der Beitrag, wie agile und informale Projekt-Gover-nance-Mechanismen über den Projektverlauf zunehmend an Bedeutung gewinnen. Zudem liefert der Beitrag erste Hinweise auf die unzureichende Integration zwischen Governance-Mechanismen auf Unternehmens- und Projektebene.	agile software development;eine and zwei;internet explorer	Martin Wiener;Reinhard Denk	2012	HMD Praxis der Wirtschaftsinformatik	10.1007/BF03340681	management;knowledge management;engineering	Robotics	-101.30704988337774	33.81033881254673	119185
b9847ea5d7e22767b8fd62adb357920d2a3fc2ce	ebundesrat: referenzprozess für die elektronische vorgangsbearbeitung in bundesratsangelegenheiten		Mit der Anwendung eBundesrat wird ein Referenzprozess für eine verwaltungsübergreifende elektronische Vorgangsbearbeitung zwischen Bundesrat und den Bundesländern mit folgenden Eckpunkten bereitgestellt: automatisierte Übernahme sämtlicher relevanter Bundesratsdokumente in das Standard-DMS Hessens, sichere Kommunikationsinfrastuktur, einheitliche zentrale elektronische Aktenführung aller Bundesratsund Normsetzungsvorgänge innerhalb Hessens, hohe Nutzenpotentiale durch einfache Handhabung der Anwendung, Synergien durch die Zusammenführung heterogener technischer Systeme und fachlicher Prozesse.	eine and zwei	Torsten Guthier;Holger Hünemohr	2010			engineering	Crypto	-104.35999706101887	32.9629172454077	119833
949812048b3c734fbcd3ba1b05b68d55efb8800c	routen- und überblickswissen - konzeptuelle überlegungen / route- and configurational knowledge - conceptual considerations	cognitive map;spatial cognition;conceptual analysis;theoretical analysis	Summary. For an interdisciplinary approach to spatial cognition the research concerning route- and configurational knowledge is of central importance. (See also Bloom et al. 1996; Chown et al. 1995; Habel 1989; Herrmann et al. 1995; Landau & Jackendoff 1993; Schweizer et al. 1998; Taylor & Tversky 1992; Wender & Wagener 1990; Werner et al. 1997). The documented position in the relevant literature for theoretical analysis and definitions of route- and configurational knowledge and its development is unsatisfying. There is no consent determination of what landmarks, routes, cognitive maps, configurational or survey knowledge are and what kinds of discriminating attributes they have. (See Buhl 1996; Cohen 1989; Downs & Stea 1982; Engelkamp 1990; Evans 1980; Freksa & Habel 1990; Moore & Golledge 1976; Siegel & White 1975; Wagener-Wender 1993). With the following conceptual analysis we try to make some proposals for definitions and theoretical considerations. On the one hand we refer to generally accepted fields of application, on the other hand we make novel proposals. Some suppositions still need to be examined and refer to the conditions under which route- and configurational knowledge are developing and especially to the change from route to configurational knowledge. We want to discuss our suggestions to contribute to an improvement of definitions and the terminological situation. Zusammenfassung. Für die interdisziplinäre Erforschung der Raumkognition ist der Problemkomplex des Routen- und Überblickswissens von zentraler Bedeutung. (Man vergleiche dazu Bloom et al. 1996; Chown et al. 1995; Habel 1989; Herrmann et al. 1995; Landau & Jackendoff 1993; Schweizer et al. 1998; Taylor & Tversky 1992; Wender & Wagener 1990; Werner et al. 1997.) Der in der einschlägigen Literatur dokumentierte Stand der begrifflich-theoretischen Analyse des Routen- und des Überblickswissens und ihrer Entstehung läßt jedoch zu wünschen übrig. So gibt es so gut wie keine theoretisch zufriedenstellende und bei den beteiligten Forscherinnen und Forschern konsensuelle Bestimmung dessen, was Landmarken, was eine Route, was eine kognitive Karte, was Überblickswissen u. dgl. sind bzw. welche diskriminativen Merkmale sie besitzen könnten. (Dazu Buhl 1996; Cohen 1989; Downs & Stea 1982; Engelkamp 1990; Evans 1980; Freksa & Habel 1990; Moore & Golledge 1976; Siegel & White 1975; Wagener-Wender 1993.) Aus der im folgenden versuchten konzeptuellen Analyse ergeben sich einige begrifflich-terminologische Vorschläge und provisorische theoretische Abgrenzungen, mit denen wir zu einem Teil auf eine weithin einvernehmlich akzeptierte Verwendungspraxis zurückgreifen, zum anderen Teil sind unsere Vorschläge aber auch neuartig. Einige Vorschläge betreffen prüfungsbedürftige Annahmen zur bedingungsabhängigen Entstehung von Routen- und Überblickswissen und speziell zum Übergang vom Routen- zum Überblickswissen. Wir möchten unsere Vorschläge zur Diskussion stellen, um dazu beizutragen, die begrifflich-terminologische Situation in diesem Problembereich gemeinsam mit anderen zu verbessern.		Theo Herrmann;Karin Schweizer;Gabriele Janzen;Steffi Katz	1998	Kognitionswissenschaft	10.1007/s001970050067	psychology;cognitive psychology;neuroscience;developmental psychology;cognitive map;management science;cognitive science	NLP	-98.81697008860704	33.64162876530362	120057
a4700b45427a7150125d7eb67f88a865909a5f2f	doktorandensymposium der se 2010		Ziel des Doktorandensymposiums war es, jungen Wissenschaftlerinnen und Wissenschaftlern konstruktive Rückkopplung zu ihren Dissertationsvorhaben durch erfahrene Forscher und anderen Doktoranden außerhalb ihrer Forschungsgruppe zu geben. Durch sorgfältig angefertigte Gutachten wurde sichergestellt, dass die Doktoranden unabhängig davon, ob ihre Einreichungen akzeptiert wurden, von ihrer Einreichung zum Symposium profitieren konnten.	triple des	Alexander Pretschner	2010				Logic	-104.08281280287798	34.52590115129556	120222
895e6acc799d1849b2bcc29c9e8a6fcb5fbf07c3	verbesserung der datensicherheit und kostenverminderung bei der erfassung betrieblicher nummern	der erfassung betrieblicher nummern;verbesserung der	Die Datenerfassungsphase ist im Vergleich zu den ubrigen Phasen eines maschinellen DV-Prozesses durch eine hohe Fehlerquote gekennzeichnet. Zur Senkung dieser Fehlerrate sind spezielle Erkennungsverfahren entwickelt worden. Diese bekannten Verfahren sowie weitere Erkennungsverfahren werden im Hinblick auf ihre Eignung uberpruft. Neben der ubli-cherweise zugrunde gelegten Fehlererkennungswahrscheinlichkeit und an-deren verfahrensabhangigen Grosen werden hier die Kosten als umfassen-des Entscheidungskriterium herangezogen.		B. Jahnke	1979		10.1007/978-3-642-67444-0_49		NLP	-104.75491044293258	32.520699394414684	120290
8d429bce856c34e38013e9a85252e25ee7f51cdb	der weg zum medienbruchfreien kreditantrag		Die digitale Transformation im Bankensektor spielt eine entscheidende Rolle. Viele Banken haben erkannt, dass jahrzehntelang etablierte Modelle den Zenit ihrer Zeit überschritten haben. Innovationsmanagement wurde somit fortan großgeschrieben, was insbesondere an der Berufung zahlreicher „Chief Innovation Officer“ in der Branche erkennbar wurde, deren Aufgabe es ist, ihr Unternehmen den neuen, sich immer verändernden Marktgegebenheiten anzupassen.	eine and zwei;intentionally blank page	Dirk Rudolf	2016	Wirtschaftsinformatik & Management	10.1007/s35764-016-0043-5		DB	-102.9135753850736	34.189298835736096	120538
f98e1c4998e5e1d3b56596824227d0dd06362eb4	perspektiven des einsatzes und der entwicklung integrierter bürosysteme	der entwicklung integrierter b	Integrierte Burosysteme bieten das Nutzungspotential, einen Anwen-dungs- und Rationalisierungsschub im Burobereich unserer Unternehmen auszulosen. Uber reine kostenorientierte Rationalisierungsstrategien hinaus sollen diese Systeme unsere Unternehmen leistungsfahiger und innovativer machen. Entsprechend sollte ihr Einsatz verstarkt auch fur Fachspezialisten und mittleres Management geplant werden. Bei der Weiterentwicklung der entsprechenden Techniksysteme kann konstatiert werden, das der Bereich der Bearbeitung von Buroinformation sowie der Bereich der Kommunikation soweit fortgeschritten ist, das der verstarkte Praxiseinsatz moglich ist. Ein Engpas ist bei der elektronischen Ablage zu sehen. Integrierte Burosysteme benotigen besonders sorgfaltig gestaltete Benutzerschnittstellen. Hier wurden in den letzten Jahren etliche Fortschritte erzielt. Der Trend geht zu Benutzerschnittstellen, die eine eigene Schicht in den entsprechenden Softwarearchitekturen bilden. Wesentlich beeinflust werden konnen zukunftige Burosysteme von Softwarearchitekturen aus dem Bereich der kunstlichen Intelligenzforschung. Der breite Einsatz entsprechender Systeme wird jedoch erst fur die 90er Jahre prognostiziert.		Hans-Jörg Bullinger;Klaus-Peter Fähnrich	1985		10.1007/978-3-642-70285-3_40	software engineering;distributed computing;computer science	Crypto	-103.28910177445049	33.39807013748753	120578
abaff66d8c65bc1921e316b250540610b60f90ef	,,raus aus dem sessel“ – computerspiele für mehr gesundheit		Computerspiele ziehen inzwischen jung und alt gleichermaßen in ihren Bann. Betrachtet man die oftmals sehr komplexen Aufgaben, die in vielen Spielen unter Zeitdruck gelöst werden müssen und die äußerst realistische Simulation und Darstellung der virtuellen Welten in heutigen Spielen, so stellt sich die Frage, ob dieses Potenzial auch für andere Zwecke, abseits der reinen Unterhaltung, genutzt werden kann. Mit dieser Frage beschäftigt sich eine wachsende Anzahl Wissenschaftler und Computerspielehersteller schon seit einiger Zeit und über die letzten Jahre konnte sich die Bezeichnung Serious Games als Oberbegriff für diesen Bereich etablieren. Gleichzeitig eröffnet die Entwicklung von massenmarkttauglichen Eingabegeräten für die körperliche Interaktion insbesondere für die spezielle Gruppe der sog. Exergames (Exercise + Game) neue Möglichkeiten und Anwendungsgebiete. Dieser Artikel gibt einen kurzen Überblick zur Geschichte der Serious Games und insbesondere der Exergames und stellt zwei spezielle Ansätze und Anwendungsgebiete für die Entwicklung von Exergames aus der aktuellen Forschung vor: Exergames für den Einsatz in der Physiotherapie und die Nutzbarmachung herkömmlicher Vollpreisspiele als Exergames.	7 days to die;eine and zwei;gesellschaft für informatik;simulation;vhf omnidirectional range	Marc Herrlich;Dirk Wenig;Benjamin Walther-Franks;Jan D. Smeddinck;Rainer Malaka	2014	Informatik-Spektrum	10.1007/s00287-014-0825-1	world wide web;computer science;performance art	AI	-106.96456943016251	33.3685163069002	120595
db98e34e52e1d65ce723ae5e3afa9ad44cc659df	implementierung von kryptographischen sicherheitsverfahren für apache cassandra und apache hbase		Spaltenfamiliendatenbanken (engl.: „column family databases“ oder „wide column stores“) sind wegen ihres flexiblen Datenmodells beliebt, das eine weitgehend schemalose Datenverwaltung ermöglicht. Diese Datenbanken (insbesondere HBase und Cassandra als quelloffene Produkte) werden auch von einigen großen Cloud-Dienstanbietern als Database-as-a-Service bereitgestellt. Eine Verschlüsselung der Transportschicht (also eine Sicherung der Verbindung zwischen Kundenrechner und der Cloud-Datenbank) ist in der Regel vorgesehen. Jedoch wird eine darüberhinausgehende Verschlüsselung der Daten innerhalb der Datenbank entweder gar nicht oder zu spät (d. h. erst auf Datenbankseite) unterstützt. Die Daten sind daher im Klartext zugreifbar für den Dienstanbieter. Im Falle eines Einbruchs in das Datenbanksystem kann darüber hinaus auch ein externer Angreifer vollen Zugriff auf die Daten erhalten. Verschlüsselung ist daher notwendig, um Daten vor unbefugtem Zugriff zu schützen. Insbesondere sollte die gesamte Schlüsselverwaltung sowie die Ver- und Entschlüsselungsoperationen auf Kundenseite erfolgen, damit die Vertraulichkeit der Daten gewahrt bleibt. Traditionelle starke Verschlüsselungsverfahren führen jedoch dazu, dass die Daten nicht mehr effizient verwaltet werden können: eine Suche nach übereinstimmenden Werten, eine Sortierung oder eine Aggregation (zum Beispiel Summierung) der Daten ist nicht möglich. Zur Lösung dieser Probleme wurden in der Theorie zahlreiche Verschlüsselungsverfahren vorgeschlagen, die gewisse Eigenschaften des Klartextes erhalten (sogenannte durchsuchbare und ordnungserhaltende Verschlüsselung). In diesem Artikel behandeln wir zum einen die derzeit vorhandenen Angebote, HBase und Cassandra als Database-as-a-Service zu nutzen und zum Anderen stellen wir unsere Implementierungen von Verschlüsselungsverfahren vor, die es ermöglichen, Cloud-Datenbanken (und zwar speziell HBase und Cassandra) mit verschlüsselten Daten zu nutzen. Column family databases (sometimes also called wide column stores) are popular due to their flexible data model, which allows schemaless data storage. These databases (in particular the open source platforms Apache Cassandra and Apache HBase) are offered as database-as-a-service by several cloud storage providers. While encryption of the transport layer (and thus, a secure connection between a customer’s computer and the cloud database) is usually provided, there is no further encryption within in database. The cloud storage provider can access the data in plaintext format. In case external attackers break into the database, they can get access as well. Thus encryption is necessary to protect sensitive data from illegitimate access. In particular the key management as well as encryption and decryption should be done on customer side in order to preserve data confidentiality. However traditional encryption methods like AES do not preserve the plaintexts characteristics, which make data processing very inefficient. Certain operations, for example sorting, searching and aggregations, are no longer possible at all after encryption. However, various theoretical encryption methods were proposed recently, that preserve the plaintext properties the databases are relying on, e.g. order-preserving encryption and searchable encryption. This article describes the currently available options for using Apache Cassandra and HBase in the database-as-a-service scenario and introduces our implementations of property-preserving encryption schemes, that enables cloud databases to operate on encrypted data.	3-methyl-2-oxobutanoate dehydrogenase (ferredoxin) activity;antilymphocyte serum;apache cassandra;apache hbase;balbiani body;cloud database;cloud storage;coagulum lysis:prthr:pt:ppp:ord:coag;computer data storage;confidentiality;cryptographic protocol;cryptography;data model;die (integrated circuit);diethylstilbestrol;eine and zwei;exog gene;format-preserving encryption;hl7publishingsubsection <operations>;key management;open-source software;phosphoribosylglycinamide formyltransferase;plaintext;platelet aggregation inhibitors;published database;sorting;tricyclic antidepressants tested for:prid:pt:ur:nar:screen;unified model;united states indian health service;vhf omnidirectional range;van der woude syndrome;verloes bourguignon syndrome;swallowing problems	Tim Waage;Lena Wiese	2016	HMD Praxis der Wirtschaftsinformatik	10.1365/s40702-016-0227-8	knowledge management;engineering;operating system	DB	-102.0758402279017	37.035061904197306	120703
5bf266f094b26e4cc78ab8364c2f4db57fc11aa2	der gegenwärtige stand der stochastischen programmierung		Wenn in einem linearen Programm einige oder alle Koeffizienten Zufallsvariable sind, verliert die Zielsetzung dieses linearen Programmes offenbar ihren Sinn. Die dann auftretenden neuen Problemstellungen, die bisher in der Literatur behandelt wurden, sollen in dieser Arbeit diskutiert werden: Das Verteilungsproblem, das Programm mit Wahrscheinlichkeitsrestriktionen und das zweistufige Problem.		Peter Kall	1968	Unternehmensforschung	10.1007/BF01918316	mathematical economics;discrete mathematics;mathematics	Crypto	-97.19721368948808	35.04064984922296	120816
6ccfea300a8f44359554f882e140f724a85c727b	das entwickeln und testen von prozeßnetzen mit dem netzwerkprogrammierungs-arbeitsplatz	von proze	Die Netzwerkprogrammierung (NWP) stellt als Methodik die konzeptionellen Grundlagen zur Entwicklung verteilter Systeme bereit. Dies umfast die auf dem Prozesparadigma aufbauende Idee autonomer, nur uber Kommunikation miteinander agierender Prozesse, die Einbindung von Kommunikationsanweisungen und somit die Bereitstellung beliebiger Kommunikationsschemata auf programmiersprachlichem Niveau und Konzepte zur Entwicklung, Konfigurierung und Optimierung sowie zum Testen von Prozes(teil-)netzen sowohl in funktionaler Hinsicht, als auch unter Aspekten der Auslastung und des Datendurchsatzes.		Jens Kutscher	1989		10.1007/978-3-642-74872-1_10	history;performance art	Theory	-103.57301628660407	33.33336105031645	121357
46ae27023f90c72ece5bf09c221ef6c4996fa1a6	untersuchungen zur typenäquivalenz von negationsnormierten termen				Klaus Apitzsch	1967	Elektronische Informationsverarbeitung und Kybernetik		combinatorics;pure mathematics;mathematics	NLP	-95.4990788394378	34.33814025892152	121502
c21ac02e42b4d9f9b92ce9654ec4c89cc545f162	it-servicemanagement in deutschen hochschulen		Die Rolle der IT hat sich in den letzten Jahrenstark verändert. Dabei ist die IT-Unterstützung von Geschäftsprozessen vielfach zu einem wettbewerbskritischen Faktor geworden. Dieser Wandel der IT vollzieht sich nicht nur in Unternehmen der Privatwirtschaft, sondern gilt gleichermaßen für öffentliche Einrichtungen, zu denen auch die Hochschulen zählen. Bedingt durch Reformen im europäischen Hochschulraum und eine zunehmende leistungsorientierte Mittelvergabe seitens der öffentlichen Haushalte sind die zielgerichtete ganzheitliche Entwicklung und Steuerung der IT-Infrastruktur dringend erforderlich. Nur so können Hochschulen im Wettbewerb um Studierende und Forscher langfristig konkurrenzfähig bleiben. Durch die Implementierung entsprechender Konzepte des IT-Servicemanagements (ITSM) wird der Wandel von einem technikorientierten Funktionsbereich zu einem kundenorientierten Dienstleistungsanbieter vollzogen. Der vorliegende Beitrag gibt einen ersten Überblick über die Umsetzung von ITSM in deutschen Hochschulen. Hierzu wurde eine empirische Untersuchung durchgeführt, in der den Fragen nach dem Bekanntheitsgrad von ITSM, der Verbreitung von Referenzmodellen sowie den bevorzugt umgesetzten Bereichen des ITSM nachgegangen wurde.	die (integrated circuit);eine and zwei;unified model	Markus Bick;Kathrin Börgmann	2008	HMD Praxis der Wirtschaftsinformatik	10.1007/BF03341217	library science;knowledge management;engineering	OS	-101.5114038030081	33.850872899440034	121721
c49a0726a51854bdae2e72f1a98a0c4220132636	evaluierung eines entscheidungstheoretischen modells zur datenbankselektion		A central problem in networked information retrieval is database selection. Which databases have to be considered to meet the information need of a user? Originating from a decision theoretic model for database selection one finds out that estimating the number of relevant documents in a database is fundamental for database selection. Approaches to estimate this parameter are presented as well as an evaluation of these approaches. It is exposed that such an estimation with simple methods is not possible. 1 Einleitung Bislang hat sich die Forschung auf dem Gebiet des Information Retrieval hauptsächlich darauf konzentriert, geeignete Methoden zur Suche in einer abgeschlossenen Dokumentkollektion zu untersuchen. Insbesondere eine explosionsartig wachsende Zahl von Informationsressourcen und Datenbanken im Internet ließ jedoch weitergehende Fragestellungen im IR entstehen bzw. aktuell werden. Eine der zentralen Fragestellungen bei der Untersuchung vernetzter Information-Retrieval-Systeme ist das Resource-Discovery-Problem: Dem Informationsnachfrager stehen eine Vielzahl von weltweit verteilten Datenbanken zur Verfügung. Bevor der Benutzer sein Informationsbedürfnis überhaupt spezifizieren kann, muß er erst einmal die Datenbanken suchen (und finden), die eventuell sein Informationsbedürfnis befriedigen können. 1Email: goevert@ls6.cs.uni-dortmund.de Evaluierung eines entscheidungstheoretischen Modells zur Datenbankselektion Ziel der Datenbankselektion in vernetzten Information-Retrieval-Systemen ist es, die Verteiltheit der Retrievalsysteme bezüglich der Retrievalqualität soweit möglich vor dem Benutzer zu verbergen. Im besten Fall erhält der Benutzer den Eindruck, daß er nicht in mehreren miteinander vernetzten Systemen sucht, sondern in einer großen, aus den Dokumenten der Einzelsysteme zusammengemischten Gesamtkollektion. Ein entscheidungstheoretischer Ansatz zur Datenbankselektion wird in [Fuhr 97] vorgestellt. Das ihm zugrundeliegende Szenario zeigt Abbildung 1. Der Benutzer erhält über einen Broker Zugriff auf verschiedene Datenbanken. Aufgabe des Brokers ist es, mittels der Anfrage des Benutzers aus den Datenbanken diejenigen auszuwählen, die relevante Dokumente enthalten. Diese werden dann vom Broker befragt. Die Datenbanken ermitteln ihr lokales Suchergebnis und leiten es an den Broker weiter. Dieser muß nun die einzelnen Suchergebnisse zu einem Gesamtergebnis zusammenmischen, welches er dem Informationsnachfrager präsentiert. Client Client Client	database;eine and zwei;information needs;information retrieval;theory;vhf omnidirectional range	Norbert Gövert	1997			data mining;information needs;computer science	DB	-106.6164146102812	35.93212916694523	122083
27bdbae1ba19934e4102e3eeebcfb13222d8dc65	ein stadion voller geld - oder: wie viel sind zwei billionen euro?		Es geht nicht darum, diese Zahl aufzuschreiben – das gelingt vermutlich Schulkindern sogar eher als Politikern –, sondern es geht darum, sich diese Zahl, ich meine in dem Fall wirklich, sich diese Anzahl vorzustellen. Die bundesdeutsche Staatsverschuldung beträgt derzeit ungefähr zwei Billionen oder 2.000 Milliarden oder zwei Millionen Millionen Euro! Wie viel ist das überhaupt? Machen wir uns diese Geldmenge an einem ersten einfachen Beispiel klar. Die Bundesrepublik hat derzeit 82 Millionen Einwohner. Würden wir die Staatsverschuldung darauf verteilen, sind das für jeden Bundesbürger – ob groß oder klein – 24.390 Euro. Also für eine vierköpfige Familie sind das schon mal fast 100.000 Euro. Ups! Da kann dann aber gleich mal der Schuldenberater kommen. Versuchen wir mal, uns das Geld in Scheinen vorzustellen. Der häufigste Schein ist der 50-Euro-Schein. Das wären dann 40 Milliarden Scheine. Legt man diese 40 Milliarden Scheinen alle schön hintereinander, kann man das entstandene Band 140-mal um die Erde wickeln. Oder eventuell vorstellbarer ausgedrückt: Wir können mit diesem Band siebenmal zum Mond und zurück. Wer solch astronomische Längenvergleiche nicht mag – hier ein Flächenbeispiel. Legen wir alle 50-EuroScheine nebeneinander zu einem großen Teppich, so ist dieser ungefähr so groß wie das Bundesland Bremen. Ganz Bremen ist also unter einer Decke von 50-Euro-Scheinen versteckt. Da wir gerade Bremen als Beispiel nehmen: Stellen Sie sich vor, Sie sind auf einem Schiff auf hoher See und befinden sich im einem Ausguck von zehn Metern Höhe über dem Meeresspiegel. Dann können Sie rundherum genauso weit sehen, wie der Teppich aus 50-Euro-Scheine reichen würde. Oder für Frankfurter: Nehmen wir mal den 100-Euro-Schein – so ein Teppich aus zwei Billionen Euro würde den ganzen Stadtbezirk Frankfurt zudecken. Eine surreale Vorstellung. Um diese Menge an 100-Euro-Geldscheinen zu transportieren, braucht man 820 Sattelzüge. Parkt man diese hintereinander, erhält man eine Strecke von über 16 Kilometern. Aber eine solche Staulänge ist man ja durchaus gewohnt. Packen wir das Geld wieder aus und bringen wir die Geldscheine in die Commerzbankarena. Und jetzt fangen wir an zu stapeln. Wir bedecken die Spielfläche von 105 x 68 Metern mit Schein um Schein. Würden wir das mit 100-Euro-Scheinen tun, so hätten wir eine Stapelhöhe von 4,72 Metern erreicht. Rechnen wir mit einer Sekunde, um ein Bündel aus 100 Scheinen (das sind 10.000 Euro) zu legen, und gehen wir davon aus, dass 150 Personen bei dieser Aktion helfen, benötigte man genau ein Jahr, um diese Geldmenge zu stapeln (es wird aber natürlich rund um die Uhr und jeden Tag gearbeitet). Eindrucksvoller wird es, wenn man die 100-Euro-Scheine in Zehn-Euro-Scheine umtauscht. Dann dauert es zehn Jahre, und man erhält eine Stapelhöhe von mehr als 33 Metern. Der höchste Sitzplatz in der Commerzbankarena liegt übrigens bei 32 Metern. Das heißt, das Stadion ist komplett voll mit Zehn-Euro-Scheinen. Das hat selbst Dagobert Duck nicht erreicht, aber es wäre eine schöne Vorstellung für Eintrachtfans.	die (integrated circuit);eine and zwei;gesellschaft für informatik;i/o controller hub;internet explorer;mag (cryptography);parity (physics);sie (file format);tun (product standard);unified model;vhf omnidirectional range;word error rate;zentralblatt math	Matthias Ludwig	2011	Wirtschaftsinformatik & Management	10.1365/s35764-011-0099-1		OS	-105.31434123365798	35.233281670814975	122470
b30cb143cf6a2f6f78aaa2b091e486ebe7ef928d	efficient matchmaking of business processes in web service infrastructures	business processes;efficient matchmaking;web service infrastructures	In dieser Rubrik wird über die im deutschsprachigen Raum abgeschlossenen Dissertationen berichtet. Dissertationen sind ein typischer Ausdruck für die auf einem Fachgebiet aktuellen Forschungsund Entwicklungsthemen. Um eine einheitliche Darstellung zu erreichen, wird jeweils folgende Information angegeben: Thema, Autor, Universität, Jahr, Gutachter und Kurzfassung. Die Angaben basieren auf Daten, die von den Universitätsinstituten oder den Autoren zur Verfügung gestellt werden. Die Rubrik erhebt keinen Anspruch auf Vollständigkeit. Sind mehrere Gutachter angegeben, so steht der Name des Hauptreferenten an erster Stelle.	business process;eine and zwei;unified model;web service	Bendick Mahleko	2006			business logic;semantics of business vocabulary and business rules;business process execution language;business domain;computer science;artifact-centric business process model;business process management;business case;data mining;database;business process model and notation;business process;business process discovery;business rule;world wide web;business process modeling	Web+IR	-102.24456269887467	34.684929681565116	123846
7566cb3f06fb5bdd37aa47dd9d16ce3b6444f43b	repräsentation therapeutischen wissens in der pädiatrischen onkologie		"""Einleitung Charakteristisch für die Pädiatrische Onkologie ist die protokollgesteuerte Therapie im Rahmen von multizentrischen Therapiestudien. In den zugehörigen Studienprotokollen (z. B. [1], [2]) werden detaillierte Behandlungspläne vorge-schlagen, die an die lokalen Verhältnisse anzupassen sind und dann als Grundlage für patientenindividuelle Therapie-Entscheidungen dienen. Insbesondere enthalten diese Pläne umfangreiche Empfehlungen zur Therapiemodifikation (ereignisgesteuerte Therapieplanung). Ferner ist in den Studienprotokollen umfangreiches Fachwissen in Textform niedergelegt, das den aktuellen Stand der Wissenschaft in diesem Gebiet widerspiegelt und jederzeit bei der Planung der Behandlung zur Verfügung stehen soll. Zur Erfassung, Repräsentation und Verarbeitung dieses Wissens wird am IMSD das Projekt TheMPO durchge-führt (Therapieplanung und Management in der Pädiatrischen Onkologie), in Zusammenarbeit mit der Arbeitsgruppe """" Angewandte Informatik in der Pädiatrischen Onkologie """" der Gesellschaft für Pädiatrische Onkologie und Hämato-logie (GPOH). Ziel des Projekts ist also speziell die Computerunterstützung der protokollgesteuerten Therapie, allge-mein die Erstellung von Werkzeugen zur Therapieplanung."""	gesellschaft für informatik;triple des	E. Burger;C. Musinszki;Ralph Müller;U. Nauerth;K. Pommerenig;Marita Muscholl;O. Thews	1994				OS	-103.79846204130195	33.30273530188096	123961
2c45fa0cd2d8a0d1f7c96f71ee1e9ede3f87cfb6	outsourcing - bedrohung oder chance?		"""Die Lage wird immer undeutlicher: Im Posteingang finden wir die Ankündigung einer internationalen Konferenz „Abkehr von zentralen Konzepten"""", gleich dahinter wird in einem Newsletter der wirtschaftliche Vorteil einer Konzentration von Rechenzentren dargelegt. Auf unserem Schreibtisch liegt der Vorschlag eines Fachbereichsleiters, die Informationsverarbeitung endlich vollständig zu dezentralisieren, der Vorstand wartet noch auf die Beantwortung der Frage, ob wir nicht auch wie das Unternehmen X die gesamte Informationsverarbeitung „outsourcen"""" können. Nur gut, daß bei der überbordenden Tagesarbeit für all diese Veränderungswünsche zu wenig Platz bleibt. Dabei wäre es eigentlich nützlich, diesen scheinbar divergierenden Überlegungen ein wenig nachzugehen. Lassen Sie mich das zunächst mit einem Bild tun, das ausnahmsweise mal den Benutzer von Informationssystemen in den Mittelpunkt stellt. Die konzentrischen Kreise symbolisieren die support levels für Aufgaben der Informationsverarbeitung, Entwicklung, Betrieb und Betreuung von Informationssystemen. Da gibt es zunächst die benutzernahe Ebene, den first level support: Vom Information Center innerhalb der Fachabteilung unterstützen wir die Benutzer bei der Entwicklung von Programmen (und zwar soweit benutzerseitige Programmentwicklung gewollt ist, z. B. bei der Auswertung von Datenbeständen), wir betreuen sie in der Handhabung von BENUTZER BERATUNG"""	internet explorer;outsourcing;sie (file format);tun (product standard);technical support	Joachim Griese	1991	Praxis der Informationsverarbeitung und Kommunikation	10.1515/piko.1991.14.2.68	computer science;outsourcing;distributed computing	OS	-102.68747154797177	34.67166410677117	124031
423f9e7c5531d20217ec365ad080f0cdc40a1a29	entschließung der konferenz der datenschutzbeauftragten des bundes und der länder vom 25. januar 2013		serungen bei der Konzeption von ASV erreicht werden konnten. Gegen das Gesetz zur Errichtung einer standardisierten zentralen Antiterrordatei von Polizeibehörden und Nachrichtendiensten von Bund und Ländern (Antiterrordateigesetz-ATDG) sind erhebliche verfassungsrechtliche Bedenken erhoben worden, über die bereits im 22. Tätigkeitsbericht 2006 berichtet wurde. Nun ist gegen das ATDG eine Verfassungsbeschwerde eingelegt worden, über die beim Bundesverfassungsgericht im November 2012 mündlich verhandelt worden ist. Möglicherweise wird das Verfahren auch die umstrittene Frage klären, ob und inwieweit das sogenannte Trennungsgebot einer Zusammenarbeit von Polizei und Nachrichtendiensten entgegensteht. Der Verfahrensausgang wird sich überdies auf die Beurteilung der neu errichteten Rechtsextremismusdatei auswirken. Einen zentralen Prüfungsschwerpunkt im Berichtszeitraum bildete der Einsatz des „Staatstrojaners“ durch bayerische Strafverfolgungsbehörden im Zusammenhang mit der Durchführung von Maßnahmen zur Quellen-Telekommunikationsüberwachung. Die Ergebnisse dieser Prüfung werden nochmals zusammenfassend dargestellt. Sollte an der Quellen-Telekommunikationsüberwachung weiter festgehalten werden, empfehle ich dringend, gesetzliche Bestimmungen zu schaffen, die der erhöhten Eingriffsintensität und den technischen Besonderheiten dieser Maßnahme gerecht werden. Die Einhaltung des Personaldatenschutzrechts hat der BayLfD in mehreren Kommunen verstärkt überprüft. Regelmäßig bemühten sich die geprüften Stellen ernsthaft um die Einhaltung der datenschutzrechtlichen Bestimmungen. Im Rahmen der Kontrollen waren gleichwohl eine nicht unerhebliche Anzahl von Mängeln festzustellen. Zudem hat der BayLfD beim Personaldatenschutz zahlreiche grundlegende Verbesserungen bewirken können: Bei der beamtenrechtlichen Beihilfe wurde endlich die – im Übrigen auch von der betroffenen Ärzteschaft seit langem geforderte – Pseudonymisierung im Psychotherapie-Begutachtungsverfahren in der Bayerischen Beihilfeverordnung fest verankert. Dies ist ein wesentlicher Fortschritt zur Wahrung der Datenschutzrechte der betroffenen Beihilfeberechtigten, aber auch ihrer Angehörigen. In den vom Bayerischen Finanzministerium erarbeiteten Leitfaden Betriebliches Eingliederungsmanagement haben die von mir aufgestellten datenschutzrechtlichen Anforderungen Eingang gefunden. Die datenschutzkonforme Ausgestaltung wird sicherlich dazu beitragen, die Akzeptanz dieses Verfahrens bei den Betroffenen zu fördern. Im staatlichen Bereich ist nun auch das Regressverfahren nach Dienstund sonstigen Unfällen datenschutzkonform geregelt. Die Übermittlung personenbezogener (Gesundheits-)Daten an die Schadensersatzpflichtigen wird damit auf das notwendige Maß beschränkt. Der Trend zur Zusammenfassung der IT-Ressourcen des Freistaats in wenigen Standorten hat sich ansonsten weiter fortgesetzt. In diesem Zusammenhang hat der CIO-Rat eine vom Staatsministerium des Innern und der CIO-Stabsstelle erarbeitete Musterrahmenvereinbarung zur Auftragsdatenverarbeitung gebilligt und der Staatskanzlei und den Ressorts deren Verwendung empfohlen. Sie reduziert das Risiko von widersprüchlichen Anforderungen an die Rechenzentren und den hohen Aufwand an Einzelvereinbarungen zwischen den Auftrag gebenden öffentlichen Stellen und den Rechenzentren. Der BayLfD hat die Erstellung der Musterrahmenvereinbarung begleitet und wird das Vorliegen solcher Regelungen zur Auftragsdatenverarbeitung prüfen. Der 25. TB ist auf der Website des BayLfD verfügbar: http://www.datenschutz-bayern.de/	chief information officer;eine and zwei;i/o controller hub;intentionally blank page;sie (file format);terabyte;unified model	Dem Kultusministerium	2013	Datenschutz und Datensicherheit - DuD	10.1007/s11623-013-0094-1		OS	-103.0249187910319	36.181801191506075	124043
9ed359784f5c172ea9a71dd49fa5293106d134cc	ein xml-basiertes datenbanksystem für digitale wörterbücher - ein werkstattbericht aus dem institut für deutsche sprache (an xml-based database system for online dictionaries - a report on lexicographic work at the institute for german language)	database system	Zusammenfassung Das Online-Wortschatz-Informationssystem Deutsch (OWID) ist ein digitales Wörterbuchportal des Instituts für Deutsche Sprache. Alle darin zusammengeführten lexikografischen Daten sind auf XML-Basis feingranular strukturiert. Speicherung, Verwaltung und Retrieval dieser Daten übernimmt das Oracle-basierte Electronic Dictionary Administration System (EDAS). Der vorliegende Beitrag erläutert die XML-basierte Modellierung der Daten, XML-spezifische Fragen der Speicherung, sowie das Retrieval mit XPath und SQL/XML. Summary The Institute for German Language (IDS) hosts the lexicographic portal OWID for online dictionary access. All lexicographic data share a fine-grained XML structure. Storing, administration, and retrieval are done using the ORACLE-based Electronic Dictionary Administration System (EDAS). This article copes with questions of XML modelling for dictionary data, storing of XML fragments within.	dictionary;information system;lexicographical order;lexicography;oracle database;sql;sql/xml;xml;xpath	Carolin Müller-Spitzer;Roman Schneider	2009	it - Information Technology	10.1524/itit.2009.0542	computer science	Web+IR	-106.2906824228717	36.417140827595325	124236
c6c250fe7fe39ee54da8762eea08ab1f3e8e2121	klartext: auf dem weg zu standard-navigationswordings im deutschsprachigen internet	poster	"""Welche Begriffe beim Entwurf von Webangeboten ausgewählt werden, ist in der Regel eine auf Erfahrungswerten beruhende """"Bauchentscheidung"""" der Verantwortlichen. Der Grund: Die Wünsche und das Verständnis der Nutzer beim Navigationswording sind bislang noch nicht systematisch untersucht worden. Die Studie """"Klartext"""" untersucht die wichtigsten Navigationsbegriffe aus Sicht der Nutzer und trägt dazu bei, allgemeine Standards für die Verwendung von Navigationsbezeichnungen zu bestimmen."""	eine and zwei;internet	Christian Bopp;Michael Wörmann	2002			the internet;world wide web;computer science	OS	-103.83189264657567	36.28215989717636	124395
e25d0959669c5e1d9122bf0972cd966a8ace6d0f	errorbounds for simple zeros of λ-matrices	eigenvalues;fast algorithm;eigenvectors	We describe a method for finding errorbounds for eigenvalues und eigenvectors of λ-matrices. Results from an earlier paper by the author (see [11]) are used to find a fast algorithm that produces good errorbounds. The algorithm is tested on several examples. Wir beschreiben hier eine Methode, mit der man Fehlerabschätzungen für Eigenwerte und Eigenvektoren von λ-Matrizen erhalten kann. Mit den Ergebnissen aus einer früheren Arbeit des Autors (siehe [11]) wird ein Algorithmus gefunden, der mit wenig Rechenaufwand gute Abschätzungen liefert. Der Algorithmus wird an mehreren Beispielen getestet.	algorithm;eine and zwei	Jon G. Rokne	1976	Computing	10.1007/BF02241976	mathematical optimization;combinatorics;discrete mathematics;eigenvalues and eigenvectors;eigenvalues and eigenvectors of the second derivative;mathematics;quantum mechanics;eigenvalue perturbation;algebra	ML	-96.31784876114355	35.28434749766403	124592
615b8c4163530583ce9da129b76e3b3560ac9013	ein untersuchungsdesign zum vergleich von offener und script-basierter kollaboration beim lernen mit videos	research article	Der Einsatz von CSCL-Scripts stellt noch immer eine technische und didaktische Herausforderung dar. Dies gilt insbesondere für videobasierte Lernumgebungen. Das hier vorgestellte Forschungsdesign zielt deshalb auf e ine vergleichende Untersuchung der Interaktionen beim Script-gesteuerten und offenen kollaborativen Lernen mit Videos. In einem 2x2-faktoriellen Untersuchungsdesign we rden ein fünf-phasiges Script in der Versuchsbedingung und ein offenes, kollaboratives Lernszenario in der Kontrollbedingu ng untersucht. Dabei werden Studierende von zwei Lehrveranstaltungen an zwei Hoc hschulen auf beide Bedingungen aufgeteilt. Die Auswertung basiert auf Logdaten , nhand derer sich effektive, kollaborative Interaktionen sowie Nutzeraktivitäten feststell en lassen. 1 Fragestellung und Hypothesen Der Einsatz von CSCL-Scripts ist u.a. mit der Erwartung verbunden, kollaborative Lernszenarien effizient zu organisieren, so dass Lernende in gleicher Weise am Lernprozess partizipieren können [WF12]. Es gibt Anzeichen dafür, dass das auch für videobasierte Scripts zutrifft und die Gruppenmitglieder dabei auf effektive Art und Weise miteinander interagieren [Sei13]. Bislang existieren jedoch nur wenige Untersuchungen zu videobasierten CSCL-Scripts [Tra06, LT05], so dass sic h positive Effekte auf den Lernprozess noch nicht hinreichend belegen lassen. Das hier vorgestellte Forschungsdesign zielt auf eine vergleichende Untersuchung d er Interaktionen beim Script-gesteuerten und offenen kollaborativen Lernen mit Vid eos. Verglichen wird dabei der Einfluss des Script-Einsatzes auf die Effektivität der Interaktion und die Kollaboration zwischen den Teilnehmenden sowie die Auswirkungen des Scripts auf die Nutzungsintensität der Videolernumgebun und die Arbeitsverteilung innerhalb der Gruppen. Den methodischen Rahmen für diese Studie liefert ein Modell zur Bestimmung und Beobachtung effektiver, kollaborativer Interaktionen von Gruppen [CF+10]. Das für die Untersuchung der Videonutzu ng adaptierte Modell basiert auf Indikatoren für die Partizipation und den sozialen Zusammenhalt (siehe Tab. 1). Die Zusammenarbeit innerhalb einer Gruppe wir d demnach als effektiv angesehen, wenn alle Kennzahlen größer oder gleich de m	die (integrated circuit);eine and zwei;eos;eddie (text editor);v-model;voltage regulator module	Niels Seidel	2014				OS	-105.69116559157285	33.042787851655476	124702
821f8d253a3b74e74d81b5fa655271a395c9fbfb	optoakustisches audiointerfacedesign und psychoakustische audiovision für pc- und videogames		Es bestehen keine optoakustischen Standards des Audiointerfacedesigns bei PCund Video-Games. Diese Subjektpositionierung wäre jedoch notwendig, da es dabei um die produktspezifische Implementierung diskursiv auditiver Enund Decoding-Settings ginge, mit denen ein Game über eine intermediale Relevanz verfügen würde. Dieses ist mit einem umfassenden und ganzheitlichen Audiointerfacedesignkonzept möglich, wobei der von Raymond Schafer determinierte Faktor der Corporate Sound Scapes, d. h. sogenannter inszenierter Klanglandschaften als System-Aura, diesbezüglich an Bedeutung gewinnt. Behavioristische Klangraumaspekte, besonders aber Sprachdialoge in Games, sollten im Stereobild bei 60-72% Links im Panning gesetzt werden, da medienpsychologisch bezüglich des Dialogdesigns nachweislich effizienter. Die Tiefenstaffelung, besonders aber die einzelnen ‚post-processed‘ Sound-Layers, wären im Hinblick ihres Einsatzes und ihrer Formation zu überdenken, denn in vielen Fällen erzeugen diese nicht nur ein Chunking beim Konsumenten, sondern verzeichnen eher eine antidialogische Metrik, die es zu korrigieren gilt; homo audiens et homo ludens. 1 Transformation der Musik – Gamemusic und Game-Audiodesign als optoakustische Audiovision innerhalb der Emerging Culture Die Computerspiele-Industrie erzielt seit einigen Jahren international höhere Umsätze als die Plattenund Filmindustrie gemeinsam [BIU10]. Eine der zunehmenden betriebswirtschaftlich relevanten Einzelgamesparten stellt u. a. der mediendidaktisch relevante Serious Games-Markt dar, mit Umsatzsteigerung, im Vergleich zum Vorjahr in Europa, USA und Asien, von jeweils ca. 8-15% p.a. [Ec08]. Dieses didaktisch fokussierte Softwareprodukt-Genre, welches wiederum unterteilt ist in Educational Games, Corporate Games, Health Games, Persuasive Games und andere softwarebasierende Werteschöpfungen mit edukativer Präferenz, nutzt dabei Technologien aus dem Unterhaltungssoftwarebereich, ohne dass der ludologische Unterhaltungsfaktor dabei eine primäre Priorität besitzen soll. Gleichwohl diese Definition des Genre Serious Games zunächst einmal oberflächlich erscheint, wird dieses Marktsegment zunehmend von großen internationalen Developern, Publishern und Audioproduzenten als lukrativ wahrgenommen; die Entwicklungskosten steigen, Gamedesign, Klangraumdesign und Gameplay wirken zunehmend professioneller, fakultative Forschungsergebnisse werden zunehmend gerade aufgrund dieses Genres berücksichtigt und im Rahmen des Gameinterfacedesigns, auch im Hinblick anderer bereits etablierter Games-Genres, ebenfalls berücksichtigt und eingebettet. Einzig der auditive Aspekt verzeichnet in sämtlichen Games-Genres, damit auch in jenen o. g. edukativen Produkten, verschiedene Defizite, da es bis dato wenig Forschungsinteresse an dem Thema ‚psychoakustische Audiovision und optoakustisches Audiointerfacedesign in Games‘ gab, neben einem defizitären internationalen Forschungsstand im Hinblick der ‚Inkulturationsprozesse und der auditiven Aufmerksamkeitskompetenz im Kontext unterschiedlicher kultureller Gewissensund Wissenssettings‘ [Mü10]. Zwar sagte Friedrich Schiller „... und er [sic. der Mensch] ist nur da ganz Mensch, wo er spielt“ [Sc87] (S. 358) und zahlreiche gegenwärtige medienfakultative Einrichtungen rückbeziehen sich auf dieses didaktische Leitmotiv des ‚homo ludens‘, vergessen jedoch dabei, dass Schiller dieses hinsichtlich eines gesunden und idealen Gesellschaftssettings in Kontext setzte, indem er die ästhetische Erziehung des Menschen zwar für essentiell erachtete, diese aber wiederum konzeptionell mit einer negativen Konnotation substituierte, indem er den wachsenden wissenschaftlich-technischen Fortschritt der Gesellschaft nämlich als sentenzielle Bedrohung verzeichnete, der den Menschen in sich selbst konsekutiv entfremde, indem die Seele zwischen zwei parallelen Lebenswirklichkeiten gespalten werde, zwischen einer rationalen Lebenswirklichkeit und einer sinnlichemotionalen. Auf der anderen Seite wird unterschätzt, dass man in der Regel rezeptionsästhetisch das sieht, was man hört, diesbezüglich die Lebenspräferenz des Menschen als homo audiens determiniert werden kann, denn gerade Musik und Audition stehen im Antagonismus zwischen erlebter gegenwärtiger Lebenswirklichkeit und vermeintlich physikalischer Interpretation, denn Audition und Musik sind nicht nur eine eigene Sprache für sich genommen, sondern die wahrgenommene Sequenzierung und Konstitution von Klangfarben, Tönen, Intonation und Rhythmus, die sich des Weiteren auch sonographisch aufzeigen ließe. Somit ist alles (Er)Leben Hören, da wir als Wesen existieren, um in auditive Kommunikation mit dem Leben überhaupt zu treten. Verzeichnet man jedoch die optoakustischen Settings in Games oder aber z. B. die Evaluationsrichtlinien von edukativen Games-Produkten, z. B. von GBTs (Game-Based Training Produkten) und PGTs (Play-Based Training Produkten), so wird schnell erkennbar, dass sämtliche Evaluationskriterien und -kataloge interessanterweise den Inhalt und die visuelle Umsetzung unter didaktischen und medienpsychologischen Subjekt-Objekt-Aspekten berücksichtigen, jedoch nicht den so wichtigen Bereich des Audiointerfacedesigns dabei berücksichtigen, u. a. die damit umgesetzte synästhetisch optoakustische Audiovision im Kontext der Enund Decodierungsaspekten. 1 U. a. PAS-1032, MEDA, AKAB, SODIS D. h. eine diskursive Bewertung des auditiven Bereichs, im Sinne eines medienvermittelnden und diskursiven Konstitutionsprozesses, demnach im Hinblick des intermedialen Games-Produktes defizitär stattfindet. Dieser so wichtige Faktor, der medienpsychologisch und je nach Game-Sparte bis zu 50% im Hinblick der Aufmerksamkeitssteigerung der Rezipienten ausmachen kann, steht thematisch hiermit im Fokus: Optoakustisches Game-Audiointerfacedesign und psychoakustische Audiovision in Games als didaktische und audioproduktionstechnische Herausforderung. Die Implementierung von optoakustischer Audiovision in multimodalen GamesUmgebungen erfolgte bis dato häufig eher utilitaristisch, d. h. beliebig, mit einem Nutzenkalkül und ohne Emotional Value Added, leider dadurch häufig unreflektiert, medien-, kommunikationspsychologisch und mediendidaktisch betrachtet defizitär, musikund audioproduktionstechnisch nicht nach etablierten Normen. 2 Warum das Thema optoakustisches Audiointerfacedesign für elektronische Medien, wie den PCund Video-Games, so wichtig ist Wenn es um die Erörterung des Game-Audiointerfacedesigns, der synästhetischen Wichtigkeit und Kontextualisierung von optoakustischer Psychoakustik und Audiovision bei Games geht, dann sollte stets die Fragestellung berücksichtigt werden, wie Aspekte der bildenden Künste, zu denen eben die Bereiche (Game-)Musik und (Game-) Audiodesign de facto zählen, überhaupt als elektronische Medien in intermedial softwarebasierenden Prozessen sich einbinden lassen und warum dies möglicherweise sinnvoll erscheint. Es versteht sich von selbst, dass hier nur eine kleine Facette dargestellt werden kann. Zunächst hilft es sich zu vergegenwärtigen, dass es beim optoakustischen Audiointerfacedesign immer um rezeptiv-diskursive Aneignungsformationsprozesse zwischen Audiointerfacedesigner und dem Konsumenten geht, jedoch hier im Sinne des humboldtschen Bildungsideals, nämlich indem Prozesse auf Medien, wie den Games, transformiert werden, d. h. Audiointerfacedesign in der Systematik somit immer auch ein aktiver Vermittlungsprozess zwischen intermedialen und lokalen Diskursen ist. Der Verfasser mag an dieser Stelle bewusst den Begriff ‚abbilden‘ nicht verwenden, da es bei der Transformation immer um ein Umformen unter Beibehaltung der Bedeutung bzw. Zielsetzung im Kontext der gegenwärtigen Lebensund Arbeitswirklichkeit geht, d. h. Kontextualisierung schließt somit immer die Rücksicht der mediensoziologisch relevanten Inkulturationsprozesse ein, erzeugt so eine gewisse kulturelle Authentizität und Identität bzgl. gegenwartsrelevanter Enund Decodingsprozesse, die wiederum wichtig sind im Hinblick des gesellschaftlichen Wirklichkeitsund Repräsentationsverständnis. Games als Softwares mit auditivem, d. h. optoakustischem Content, schließen somit immer normativ diskursive Prozesse mit Mehrwert mit ein. Dabei geht es nicht nur um eine gewisse kulturelle Identität, vielmehr um eingebettete soziokulturelle Orientierungsmuster, gerade bzgl. des gegenwärtigen Wirklichkeitsund Repräsentationsverständnisses, mit deren Auswirkungen auf die Hörund Lesart der Konsumenten, darum diese wiederum gekoppelt sein sollten an den gegenwärtigen gesellschaftlich semiotischen Ressourcen, die nämlich über die eigentliche Rezeption hinaus gehen, weshalb optoakustische Settings, d. h. durch optische und akustische Systeme substituierte Interfaces, innerhalb von Games-Settings, im Sinne einer ingamebased Diskursivität zwischen Mensch und Computer, Computer und Mensch als sehr wichtig erscheinen. Um dieses wiederum effizient umsetzen zu können, sollten Standards konstituiert werden. Standardisierungen fokussieren eine Vereinfachung der normativen, damit notwendigen Prozesse, gleichzeitig sollte der Entwickler eines Games-Produktes ebenfalls eine Vorstellung darüber besitzen, was er mit seinem Games-Content überhaupt auslöst. Die Stimulus-Response-Kodierung, die Analyse der Bedingungsund Entscheidungsfelder im Hinblick jener softwarebasierenden Umsetzungen, um nur einige wenige Punkte zu nennen, werden nämlich in den meisten Fällen leider defizitär berücksichtigt, genauso wenig, wie dem Gamedeveloper immanent bewusst ist, dass es beim Spielen selbst immer auch um ein behavioristisch begründetes Aneignungsformationssetting geht. Betrachtet man die o. e. etablierten Standards als mögliche Inspirationsquelle für das Produkt-Genre Games im Allgemeinen, so verzeichnet man, dass der optoakustische Bereich des Audiointerfacedesigns unbedingt eine essentielle und sentenzielle Beachtung verdienen sollte. Wie kann dies vergessen worden sein, wenn doch Alltagskompetenz ste	circa;die (integrated circuit);eine and zwei;europa;gab;intentionally blank page;internet explorer;mag (cryptography);parity (physics);persuasive games;recueil des historiens des croisades;shallow parsing;triple des;unified model	Giovanni Vindigni	2011				Security	-105.6280806005696	34.63039978617915	124879
35a428ba502773427e9f798f19402b0bfe517730	forschungen zur automatischen multisensor-gestützten forstinventur		Automatisierungsroutinen sowie semi-automatische echtzeitbasierte Erfassungsmethoden wichtiger forstlicher Bestandsparameter haben heute eine hohe Relevanz, insbesondere in Bezug auf die Verwendung der räumlich erhobenen Atributdaten innerhalb von modernen 3D und 4D Waldwachstumsmodellen, wie z. B. „B-Win-Pro“ oder dem „Waldplaner“. Ein Großteil forstlich relevanter Objektparameter können mittels der Verknüpfung verschiedener, autonomer Sensorplattformen IPS (Integrated Positioning System) und anderer opto-elektronischer Scanner in nahezu Echtzeit erfasst werden. Die Lageund Objektdaten werden in internetfähigen Geodatenbanken als individuelle Geo-Objekte und Sachdatenbestände (Attribute) nutzerfreundlich verwaltet.	eine and zwei;internet explorer;positioning system;semiconductor industry	Jan-Peter Mund;Anko Börner;Adrian Schischmanow	2013				Robotics	-104.31930327487451	32.67556340364048	125534
96ebf7cc5c9516b1f45d48914eb84473d80e49a3	gauss-turán quadratures of chebyshev type and error formulae	error bound;error estimate	This paper begins with an investigation of two special forms of the Gauss-Turán quadrature of Chebyshev-type of precision 6n−1. Then the remainder formulas of these quadratures are developed and sharp error bounds for the functions inC q [−1, 1] are shown, whereq is a positive integer. Most importantly this study proves that these reslts can be extended in order to yield sharp error estimates for all such quadratures of higher precision. Dieser Aufsatz fängt mit einer Untersuchung zweier besonderer Gestalten der Gauß-Turán-Quadratur des Chebyshev-Typs der Präzision 6n−1 an. Dann werden die Restformeln dieser Quadraturen entwickelt und scharfe Irrtumgrenzen für die Funktionen inC q [−1, 1] gezeigt, woq eine positive ganze Zahl ist. Am wichtigsten beweist diese Studie, daß diese Ergebnisse verlängert werden können, um die Resformeln und scharfe Irrtumsabschätzungen für alle solchen Quadraturen höherer Präzision zu erhalten.	am broadcasting;chebyshev polynomials;eine and zwei;gesellschaft für informatik;unified model	R. D. Riess	1975	Computing	10.1007/BF02242365	mathematical optimization;mathematical analysis;calculus;mathematics	DB	-96.36112388129256	35.7397287616675	125724
5d6d1a62d2e2b7b1e49da8cb2807fd4641e45745	erwerb motorischer geschicklichkeit bei wissensgestützt beobachtenden robotern		Es werden einige Aspekte zum Wesen der Programmierung von Industrierobotern zusammengetragen und daraus der Vorschlag fur ein hybrides System fur die Roboterprogrammierung abgeleitet; dieses soll die Vorteile des Offline-Programmierens per Texteingabe und des Online-Programmierens per Vorfuhrung (Teach-In) durch den geschickten Einsatz wissensbasierter Techniken verbinden und damit dem Roboter ein „Verstandnis“auch auserst komplexer, kaum noch verbalisierbarer motorischer Aktivitaten ermoglichen. (Man denke an das Annahen eines Knopfes, das Binden einer Krawatte oder das Drehen eines Stiftes zwischen drei Fingern einer Hand.) Die Arbeit gilt einer Programmierumgebung, welche einerseits dem Instrukteur (Online-Programmierer) eine Interaktion mit dem Roboter ermoglicht, die seinen eher motorisch orientierten Ausdrucksfahigkeiten entspricht, und welche andererseits auch alle Mittel zur Abstraktion bereitstellt, um auf prazise Weise generische, d.h. allgemeingultige Programme zum Losen von Roboteraufgaben an die Maschine zu vermitteln - und dies beides in einer Weise, die ein maschinelles Schlusfolgern uber solchen Losungsvorschlagen gestattet. Dem Vorschlag liegt die Modellierung des Roboters nach dem Bild eines menschlichen Lehrlings zu Grunde, der im Verlauf seiner Ausbildung sowohl praktisch als auch theoretisch unterwiesen wird und dadurch sein Auffassungsvermogen und seine Selbstandigkeit zunehmend verbessert. Das typische Wechselspiel von Theorie und Praxis soll - auf die Maschine ubertragen - in einer Art Bootstrap-Prozes aus einem vom Hersteller gelieferten „dummen“Roboter einen effizient lernenden „intelligenten“Roboter machen. Die Idee, derart akquiriertes anwendungs- und fachspezifisches Wissen in (austauschbaren) Softwaremoduln zu isolieren, fuhrt zum Konzept des „Fachroboters“, der sich dadurch auszeichnet, fur Anwendungen seines Gebiets besonders einfach programmierbar zu sein. Der Beitrag versucht eine Systemskizze.		R. Heyers	1986		10.1007/978-3-642-71388-0_50	art;performance art	NLP	-105.5940803497354	32.3452613629223	125876
dec04bb9e1e23d24d12b7e39c93ac8ccb14a5332	aufruf-hierarchie und klassen-definition		Klassen auf Windows-Plattformen entwickeln Auf Windows-Plattformen stellt Natural den Class Builder als Werkzeug zur Entwicklung von Natural-Klassen zur Verfügung. Der Class Builder präsentiert eine Natural-Klasse in einer strukturierten hierarchischen Reihenfolge und ermöglicht es dem Benutzer, die Klassen und ihre Komponenten effizient zu verwalten. Wenn Sie den Class Builder benutzen, sind überhaupt keine Vorkenntnisse oder auch nur Grundkenntnisse der unten beschriebenen Syntax-Elemente erforderlich.	eine and zwei;microsoft windows;sie (file format)	Reinhard Budde	1983				ML	-106.07219269107135	33.47038954870875	126064
f8284d8f73ae38fa2dce2d9b24fd0ffba02e54c1	einsatz von geoweb-technologien im tourismus		Wie in kaum einer anderen Branche werden technologische Entwicklungen des Geoweb im Tourismus bereits heute intensiv genutzt. Interaktive Karten und Google Earth haben sich als wichtige Informationsquellen etabliert und sind heute ebenso gefragt wie traditionelle Reiseführer. Geoweb-Technologien finden sich in Buchungsplattformen, Routenplanern, Online-Reiseführern und den Webseiten von Destinationen und Tourismusunternehmen. Eine wesentliche Grundlage der Angebote bilden die APIs der Earth-Viewer-Plattformen von Google, Microsoft & Co., bei denen neben Geofunktionalitäten auch Geodaten bereits integriert sind. Der Beitrag gibt einen Überblick zur Entwicklung, zu Anforderungen und zum Einsatz von Geoweb-Technologien im Tourismus. Es werden aktuelle Beispiele, Geschäftsmodelle und zukünftige Geoweb-Anwendungen im Bereich Tourismus vorgestellt.	eine and zwei;geoweb;google earth;internet explorer	Martin Soutschek	2010	HMD Praxis der Wirtschaftsinformatik	10.1007/BF03340534	marketing;geoweb;engineering;performance art	DB	-105.29216063819123	36.698326784970504	126093
6621a95f4d76e1703b62ef84225201add30f7224	biometrische authentisierung — möglichkeiten und grenzen		Die Authentisierung von Personen anhand bestimmter körperlicher Charakteristika wie Fingerabdrücken, Gesichtsgeometrie oder Irismuster wird gelegentlich als Alternative zu den Authentisierungsverfahren durch Besitz und/oder Wissen angesehen. Der Beitrag1 untersucht die Möglichkeiten und Grenzen dieser Verfahren bei der Authentisierung.	internet explorer	Hanns-Wilhelm Heibey;Gisela Quiring-Kock	2010	Datenschutz und Datensicherheit - DuD	10.1007/s11623-010-0099-y	internet privacy;computer science	NLP	-103.82782028837873	36.274035927502766	126273
8cdcee214b5baead49fd623966b84130f9ef375c	genrespezifische kultivierung durch krimirezeption		Zusammenfassung. Die Studie geht von zwei kontraintuitiven Befunden zur Kultivierung aus: Die Nutzung von Krimis hat einen geringeren Einfluss auf Kultivierung als das Gesamtfernsehen; aktive Rezeption schwacht Kultivierungseffekte ab. Shrum (1995) nimmt an, dass Fernsehinformationen nur dann in Ansichten uber die reale Welt einfliesen, wenn die Quelle der Information vergessen wird. Es wird daher postuliert, dass eine haufige Rezeption verbrechensbezogener Kultivierungsindikatoren in Krimis, Aktivitat sowie die Lebhaftigkeit der Darstellung ein besseres Behalten der Quelle bewirken und damit niedrigere Kultivierungseffekte. In einer Befragung von 319 Personen stellt sich heraus, dass Kriminutzung mit fast allen Kultivierungsmasen entweder schwacher als das Fernsehen korreliert oder aber negativ. Lebhafte Kultivierungsmase hangen negativ mit Kriminutzung zusammen. Ein Inhibitionseffekt von Aktivitat kann jedoch nicht festgestellt werden. Die Befunde werden in Hinblick auf Kausalitat diskutiert.		Helena Bilandzic	2002	Zeitschrift für Medienpsychologie	10.1026/%2F1617-6383.14.2.60	psychology;media studies;psychoanalysis	NLP	-105.72705357119611	34.455969809578455	126550
a6a1946d85b075a0a5ab9cfdf83d1eee74155143	entropy, function and evolution: naturalizing peircian semiosis	aworking paper;jaynes approach to entropy;peirce s concept of semiosis;evolution of functions;thermodynamics;semiosphere;evolutionary process;working paper;maximum entropy production;functions;observer relativity;information	Nutzungsbedingungen: Die ZBW räumt Ihnen als Nutzerin/Nutzer das unentgeltliche, räumlich unbeschränkte und zeitlich auf die Dauer des Schutzrechts beschränkte einfache Recht ein, das ausgewählte Werk im Rahmen der unter → http://www.econstor.eu/dspace/Nutzungsbedingungen nachzulesenden vollständigen Nutzungsbedingungen zu vervielfältigen, mit denen die Nutzerin/der Nutzer sich durch die erste Nutzung einverstanden erklärt. Terms of use: The ZBW grants you, the user, the non-exclusive right to use the selected work free of charge, territorially unrestricted and within the time limit of the term of the property rights according to the terms specified at → http://www.econstor.eu/dspace/Nutzungsbedingungen By the first use of the selected work the user agrees and declares to comply with these terms of use.	die (integrated circuit);terms of service	Carsten Herrmann-Pillath	2010	Entropy	10.3390/e12020197	information;artificial intelligence;theoretical physics;mathematics;semiosphere;thermodynamics;function;physics;quantum mechanics;statistics	NLP	-97.95467597260452	33.61809870907977	126674
fc210bc40783909412d6fac837b44fa68ea07b66	über tschebyscheffsche approximationen durch asymptotisch konvexe funktionenfamilien		In dieser Arbeit untersuchen wirTschebyscheffsche Approximationen an reellwertige stetige Funktionen durch asymptotisch konvexe FunktionenfamilienV, die von endlich vielen reellen Parametern abhängen. Zur Charakterisierung der besten Approximation werden Extremalsignaturen definiert. Wir leiten notwendige und hinreichende Bedingungen dafür her, daß eine Teilmenge vonV eine Menge von besten Approximationen für eine gegebene stetige Funktionf ist und daß die Dimension der Menge aller Minimallösungen fürf unter einer vonf unabhängigen Schranke bleibt. Schließlich betrachten wir Approximationen durch Funktionenfamilien, die nach den Parametern differenzierbar sind. In this paper we investigateTschebyscheff-Approximations for realvalued continuous functions by asymptotic convex familiesV of functions, which depend on a finite-dimensional set of real parameters. To obtain a characterization of best approximation extremal signatures are defined. We derive necessary and sufficient conditions for a subset ofV to be a set of best approximations for a given continuous functionf and for the dimension of the set of all best approximations forf to be bounded by a constant independent off. Finally we consider approximations by familiesV, which are differentiable in the parameters.	antivirus software;approximation;eine and zwei;gesellschaft für informatik	Bruno Brosowski	1966	Computing	10.1007/BF02234364	mathematics;calculus;mathematical analysis	Theory	-96.62447984961057	35.73113739851821	126943
3be5a9f24d57e0ce2000f3d01ef4a27482ad5d1d	schichtübergreifende früherkennung von verbindungsausfällen in drahtlosen mesh-netzwerken		Drahtlose Mesh-Netzwerke (WMNs) bilden aufgrund ihrer Selbstorganisation ein flexibles Kommunikationssystem. Bei der Erkennung einzelner Verbindungsausfalle, die bei der Integration mobiler Teilnehmer unvermeidbar sind, ist bei aktuellen Routingprotokollen die Kommunikation jedoch fur mehrere Sekunden unterbrochen. In dieser Arbeit wird gezeigt, wie durch Nutzung von Informationen aus der MAC-Schicht ein Ausfall fruhzeitig erkannt und dadurch die Anzahl der Paketverluste von mehreren Hundert auf maximal vier reduziert werden kann. Hierdurch wird die Zuverlassigkeit und Verfugbarkeit von WMNs erhoht und ihr Einsatz fur Echtzeit-Anwendungen ermoglicht.	mesh networking	Timo Lindhorst	2009		10.1007/978-3-642-04783-1_8		NLP	-105.21936595497935	32.48702219211024	127341
5f0cf051b8e34e576023437835c7b4a300e18b26	"""""""did i say something wrong?"""" a word-level analysis of wikipedia articles for deletion discussions"""	wikipedia;articles for deletion;function words;i messages;you messages	This thesis focuses on gaining linguistic insights into textual discussions on a word level. It was of special interest to distinguish messages that constructively contribute to a discussion from those that are detrimental to them. Thereby, we wanted to determine whether “I”and “You”-messages are indicators for either of the two discussion styles. These messages are nowadays often used in guidelines for successful communication. Although their effects have been successfully evaluated multiple times, a large-scale analysis has never been conducted. Thus, we used Wikipedia Articles for Deletion (short: AfD) discussions together with the records of blocked users and developed a fully automated creation of an annotated data set. In this data set, messages were labelled either constructive or disruptive. We applied binary classifiers to the data to determine characteristic words for both discussion styles. Thereby, we also investigated whether function words like pronouns and conjunctions play an important role in distinguishing the two. We found that “You”-messages were a strong indicator for disruptive messages which matches their attributed effects on communication. However, we found “I”-messages to be indicative for disruptive messages as well which is contrary to their attributed effects. The importance of function words could neither be confirmed nor refuted. Other characteristic words for either communication style were not found. Yet, the results suggest that a different model might represent disruptive and constructive messages in textual discussions better. Zusammenfassung Diese Arbeit beschäftigt sich damit, linguistische Erkenntnisse auf Wortebene über schriftlichen Diskussionen zu gewinnen. Die Unterscheidung zwischen Botschaften, welche sich förderlich auf Diskussionen auswirken und jene, welche diese unterbrechen, spielte dabei eine besondere Rolle. Hierbei lag ein Schwerpunkt darauf, zu ermitteln, ob Ichund Du-Botschaften charakteristisch für die beiden Kommunikationsarten sind. Diese Botschaften sind über Jahre hinweg zu Empfehlungen für erfolgreiche Kommunikation avanciert. Ihre zugeschriebene Wirkung wurde zwar mehrfach bestätigt, jedoch geschah dies stets in kleineren Studien. Deshalb wurde in dieser Arbeit mithilfe der Löschdiskussionen der englischen Wikipedia und der Liste gesperrter Nutzer eine vollautomatische Erstellung eines annotierten Datensatzes entwickelt. Dabei wurden Diskussionsbotschaften entweder als förderlich oder schädlich für einen konstruktiven Diskussionsverlauf markiert. Dieser Datensatz wurde anschließend im Rahmen einer binären Klassifikation verwendet, um charakteristische Worte für die beiden Kommunikationsarten zu bestimmen. Es wurde zudem untersucht, ob anhand von Synsemantika (auch bekannt als Funktionswörter) wie Pronomen oder Konjunktionen eine Entscheidung über die Kommunikationsart einer Botschaft getroffen werden kann. Du-Botschaften wurden, übereinstimmend mit ihrer zugeschriebenen negativen Auswirkung auf Kommunikation, als schädlich in den durchgeführten Untersuchungen identifiziert. Entgegen der zugeschriebenen positiven Auswirkung von Ich-Botschaften, wurde bei diesen ebenfalls eine schädlich Wirkung festgestellt. Eine klare Aussage über die Relevanz von Synsemantika konnte anhand der Ergebnisse nicht getroffen werden. Weitere charakteristische Worte konnten nicht festgestellt werden. Die Ergebnisse deuten darauf hin, dass ein anderes Modell textliche Diskussionen potentiell besser abbilden könnte.	binary classification;blitzkrieg;eine and zwei;es evm;entscheidungsproblem;http 404;i/o controller hub;intentionally blank page;internet explorer;unified model;v-model;wikipedia;zentralblatt math	Michael Ruster	2016	CoRR		natural language processing;computer science;artificial intelligence;brand;world wide web	HCI	-107.6718827902207	35.583261590027696	127871
ad0846e6d5858429b57515cb182709a8ee9a1fed	architekturen und prozesse für die entwicklung von elearning-content.	talk	Die Entwicklung von interaktivem eLearning Content ist im Wandel von einem handwerklichen Produktionsverfahren zu industrialisierten Prozessen. Dies ermöglichen neueste technische Standards, systematisch weiterentwickelte arbeitsteilige Prozesse und der Einsatz neuer Werkzeuge wie Self-AuthoringTools. Der Beitrag stellt dar, welche Anforderungen heute an die Produktion von Content gestellt werden. 1 Content: Vom Flaschenhals zur Massenware? Bei Anwendern von Learning Management Lösungen in der Industrie wie auch in der Hochschule wird eine sehr divergierende Diskussion über den Nutzen sowie die Wirtschaftlichkeit des Einsatzes von Web-based-Trainings (WBTs) im Sinne von interaktiven Content geführt. Einerseits ist man sich bewusst, dass der Erfolg von Learning Management Anwendungen in hohem Maße von der Bereitstellung und Akzeptanz geeigneter und guter Lerninhalte abhängt. Es reicht nicht aus, wenn Learning Management Lösungen sich auf die administrative Abwicklung von Lernund Lehrprozessen wie beispielsweise die Anmeldung zu einem Kurs oder einer universitären Veranstaltung konzentrieren, oder die Nutzung von Communities zur Vorund Nachbereitung von Präsenzveranstaltungen oder Vorlesungen ermöglichen. Dies kann allenfalls eine erste Stufe in Richtung der systematischen Nutzung von Learning Management sein. Auf der anderen Seite wird trotz des Bewusstseins über die Bedeutung multimedialer Lerninhalte in vielen Organisationen Content nicht systematisch beschafft oder entwickelt. In vielen Organisationen, sei es an den Lehrstühlen von Universitäten oder in Weiterbildungsorganisationen von Unternehmen, fehlt eine Content-Strategie. Es fehlt eine systematische Analyse des Bedarfs und eine definierte Zuständigkeit für die Beschaffung und Produktion von Inhalten, es fehlen Rollout-Strategien für Content und Integrationsszenarien mit den bestehenden Bildungsmedien bzw. Präsenzveranstaltungen. Aus Sicht der Inhalte müssen demnach drei Probleme gezielt angegangen und gelöst werden, um den Einsatz neuer Medien in der Ausund Weiterbildung erfolgreich zu machen:	eine and zwei;internet explorer;unified model;zentralblatt math	Volker Zimmermann;Tilman Küchler	2003			computer science	ML	-103.0809577575079	33.38367275820897	128727
3d1ad38aff125cb4da511371e804d2e8e28e2fbd	kinderleicht wie ein computerspiel? versuch einer analyse		Technisch ist in der Welt der virtuellen Realitäten (VR) alles in Butter. Einund Ausgabegeräte für VR-Systeme existieren, Algorithmen gibt es in Hülle und Fülle, und die nötige Rechenleistung zur Erzeugung von 3D-Grafik in Echtzeit liefert jeder PC vom Discounter. Durchgesetzt haben sich virtuelle Umgebungen (virtual environments, VE) als allgemeine Benutzungsschnittstellen jedoch nicht. In einigen Nischen werden VRTechniken erfolgreich eingesetzt, etwa in Simulatoren zur Pilotenausbildung oder zur anschaulichen Visualisierung von Konstruktionen vor ihrer tatsächlichen Herstellung. Ansonsten existieren sie jedoch hauptsächlich als Forschungsprototypen, beeindruckend bei Vorführungen, aber im Alltag bedeutungslos. Die Suche nach Gründen muß von den Motivationen und Hoffnungen ausgehen, mit denen VE-Ansätze für die verschiedensten Anwendungen vorgeschlagen wurden. Ein gern angeführtes Argument ist die Ähnlichkeit zu Computerspielen, welche zum einen erfolgreich 3DTechniken einsetzen und zum anderen als einfach und intuitiv bedienbar, also benutzerfreundlich gelten. Der vorliegende Beitrag sammelt vorhandenes Wissen und versucht, anhand einer kurzen Analyse gängiger Spieltypen den Geltungsbereich dieser Aussage einzugrenzen. Abschnitt 2 gibt einen Überblick über Computerspiele und erinnert an die Voraussetzungen für die Benutzerfreundlichkeit von Anwendungssoftware. In Abschnitt 3 werden exemplarisch einige Klassen von Computerspielen vorgestellt und analysiert. Der letzte Abschnitt zieht Schlußfolgerungen aus den gemachten Beobachtungen.	bielefeld conspiracy;graphics;institut für dokumentologie und editorik;internet explorer;sie (file format);vhf omnidirectional range;virtual reality	Sven Türpe	2001			dielectric;loading coil;wire gauge;telephone line;electronics;repeater;carrier signal;electrical engineering;physics;voice frequency	DB	-106.2300258689802	33.760480594589616	128805
3e6dda94af09bd057b831f0cbb5485686bd565e7	annotiertes lecture recording	lecture recording;talk	Zur Durchführung virtueller Vorlesungen ist es nützlich, neben Ton und Bild auch jeweils den gesamten Desktop aufzuzeichnen und zu übertragen. Dies wird durch die Benutzung von anwendungsunabhängigem Screen-Recording unterstützt. Ebenfalls für Präsentationen bewährt haben sich Annotationsmöglichkeiten, die es gestatten, die Aufmerksamkeit zu fokussieren und Vermerke auf einer ansonsten überwiegend statischen Projektionfläche anzubringen. Wir berichten über eine erfolgreiche Kombination von allgemeinem Screen-Recording mit einem einfachen aber flexiblen Annotierungssystem für den gesamten Desktop und zeigen, dass dies die Dynamik der Vorlesungen erhöht.	eine and zwei;gesellschaft für informatik;lecture recording;screencast	Peter Ziewer;Helmut Seidl	2004			performance art;art	OS	-106.63912223195886	33.13562114696075	129172
7e0e9cc34ac941045ebb14e3ad9bb454b17e9c41	stand der normung im ccitt, ebenen 2-6	der normung im ccitt	Bei der „Kommunikation in verteilten Systemen“ kommt dem CCITT (Comite Consultatif International Telegraphique et Telephonique) eine besondere und zentrale Bedeutung zu. Denn, so wie wir die schnellen, wirksamen und zuverlassigen Dienste wie Telefon und Telex als welt-weit einheitliche Kommunikationsmittel schon selbstverstandlich in unseren Alltag miteinbeziehen, so wunschen sich die Fernmeldeverwal-tungen einen adaquat geregelten Dienst fur die Daten- und Textuber-tragung sowie die Datenfernverarbeitung.		Michael Hegenbarth	1981		10.1007/978-3-642-67978-0_8	telecommunications;telex;computer network;computer science	DB	-104.35476345746751	34.28063316732544	129195
44382f71d13932cc01b8bbabb1b30673d40a13d3	eignung von routing-protokollen für multimediale kommunikationssysteme		Der Entwurf zukunftiger Kommunikationsprotokolle mus sich an den neuartigen Anforderungen multimedialer Dienste orientieren. Die Ausbreitung dieser Dienste uber den Bereich lokaler Netze hinaus setzt insbesondere geeignete Konzepte fur die Netzwerkebene voraus. Dieser Beitrag wird Anforderungen an multimedia-fahige Routing-Protokolle darstellen und erstmals die Routing-Protokolle RIP, IGRP, IS-IS, OSPF, BGP, IDPR und ST-II in Bezug auf ihre Verwendbarkeit fur multimediale Kommunikationssysteme vergleichen. Im Anschlus an ein neues Konzept zur Koordination von verbindungsorientiertem und verbindungslosem Dienst wird eine flexiblere Wegewahl unter Berucksichtigung von Netztopologie, Service- und Verkehrsparametern auf der Basis neuronaler Netze vorgeschlagen.		Sabine Neuhauser	1993		10.1007/978-3-642-78091-2_30	computer network;computer science	Crypto	-104.33662036917796	36.42899508353564	129261
40353732ba02b1d94936c409a9f20246fbcbd749	methodik der oose für fachinformatiker nach dem lernfeldansatz unter einbeziehung der lehrerfortbildung		Der Rahmenlehrplan für Fachinformatiker stellt die Handlungsorientierung im Berufsschulunterricht in den Vordergrund. Diese Schwerpunktsetzung wird durch den Lernfeldansatz curricular abgesichert. Die Arbeit stellt die didaktische Transformation des Handlungsfeldes der objektorientierten Softwareentwicklung (OOSE) aus der Praxis in das Lernfeld „Entwickeln und Bereitstellen von Anwendungssystemen“ für Fachinformatiker an der Berufsschule vor. Es wird ein auf die Bedürfnisse der Berufsschule angepasstes Vorgehensmodell entwickelt, das die klassische fachsystematische Strukturierung ersetzt. Erste Ergebnisse einer Pilotunterrichtsreihe werden vorgestellt. Die Arbeit verdeutlicht die besondere Bedeutung der Metasprache UML (Unified Modeling Language) für die Übersichtlichkeit der OOSE und diskutiert den Einsatz von Entwicklungswerkzeugen. Da dieser Ansatz eine grundlegend neue Didaktik und Methodik verlangt, beinhaltet die vorgestellte Konzeption auch die Lehrerfortbildung. Konkret werden die Kursmodule zur OOSE der IT Akademie Hessen vorgestellt.	altran praxis;didaktik;die (integrated circuit);eine and zwei;unified modeling language;vhf omnidirectional range	Dietmar Johlen	2002			psychoanalysis;philosophy	AI	-101.15443335027352	32.510944872863675	129836
cc559b654e5faafa83e78cf06afdbc96718bab71	10 jahre informationsfreiheit in brandenburg		Zehn Jahre Informationsfreiheit in Brandenburg. Das ist ein Grund zum Feiern, aber auch zurückzublicken und nach vorne zu schauen. Am 20. März 1998 ist das Brandenburgische Akteneinsichtsund Informationszugangsgesetz (AIG) als erstes Informationsfreiheitsgesetz der Bundesrepublik Deutschland in Kraft getreten. Obwohl das Recht auf Akteneinsicht 1992 in Artikel 21 Abs. 4 der brandenburgischen Landesverfassung verankert worden ist, dauerte es bis zur Verabschiedung des Gesetzes noch sechs Jahre. Trotz Verfassungsrangs gab es genügend Skeptiker, die vieles befürchteten: einen hohen zusätzlichen Verwaltungsaufwand, eine Behinderung der Verwaltungsabläufe oder sogar ein Standortnachteil für die Ansiedlung von Unternehmen durch die befürchtete Möglichkeit, Konkurrenten dann ausspionieren zu können. Vor diesem Hintergrund war auch der Regierungsentwurf eines AIG aus dem Jahre 1996 eher zaghaft ausgefallen. Die Verfassung sollte zwar ausgeführt, aber Neuland so vorsichtig wie möglich betreten werden. Die Akten öffneten sich 1998, aber nicht alle Akten, nicht alle Inhalte und nicht in jeder nutzbaren Form. Die Bürgerinnen und Bürger Brandenburgs strömten nicht gerade in die Behörden, keine Behörde brach zusammen und die Behörden lernten und lernen noch heute den Umgang mit dem neuen Gesetz. Es war und sind die alltäglichen Fragen, die die Nutzer dieses neuen Rechts klären wollen. Bauvorhaben einer Straße, die Konzeption einer Schulsporthalle, die Frage der Kosten für Wasserund Abwasser, die Nutzung einer Schwimm-halle oder die Verkehrsüberwachung, um nur einige Dinge beispielhaft zu nennen. Gott sei Dank hat das erste Informationsfreiheitsgesetz auch einen Beauftragten für das neue Recht vorgesehen. In den zehn zurückliegenden Jahren hat die LDA als Landesbeauftragte für das Recht auf Akteneinsicht sich bemüht, Beschwerden bereits im Vorfeld abzufangen, durch Beratung der Behörden und der Antragsteller. Es hat sich gezeigt, dass Beratung, Fortbildungsangebote für Behörden und Öffentlichkeitsarbeit die wichtigsten Bausteine für die Förderung der Informationsfreiheit sind. Fortbildungen schaffen Kompetenz in den Behörden und öffentlichen Stellen, die sich auszahlt, Beratungen helfen bei Einzelfallproblemen und Öffentlichkeitsarbeit weist auf das bestehende Recht hin. Diese Basisarbeit hat sicher dazu beigetragen, dass sich die Anzahl der Beschwerdefälle auf einem relativ geringen Niveau eingependelt hat. Allerdings ist auch nicht bekannt, wie oft die Brandenburgerinnen und Brandenburger im Jahr von ihrem Recht tatsächlich Gebrauch machen, denn eine statistische Erfassung der Akteneinsichtsanträge gibt es nicht. Ein Vorreitergesetz, das den Spagat zwischen Befürwortern und Skeptikern meistern muss, ist leider oft ein zaghaftes Gesetz. Es macht oft Fehler, die andere dann vermeiden können. Welche Schwierigkeiten hatte und hat das AIG noch? Bei dem 1998 verabschiedeten AIG fehlte zunächst eine Bearbeitungsfrist für die auskunftspflichtigen Stellen. Die damit einhergehende zögerliche Bearbeitung kann sich jeder leicht vorstellen. Außerdem gab es keine Pflicht, auf die Möglichkeit der Anrufung der LDA im Falle einer Ablehnung des Antrages hinzuweisen. Diese Schwierigkeiten konnten durch eine Änderung der entsprechenden Vorschriften im Jahre 2004 behoben werden. Geblieben sind zahlreiche andere Probleme. So ist das AIG in laufenden Verwaltungsverfahren stets nicht anwendbar, Unternehmensdaten sind so geschützt wie in keinem anderen Informationsfreiheitsgesetz. Aufsichtsakten können generell nicht eingesehen werden und ein Anspruch auf Fotokopien ist im Gesetz nicht vorgesehen. Hinzukommen Probleme durch die Weiterentwicklung des Informationszugangsrechts. Gehörten in Brandenburg das Umweltinformationsgesetz, das den Zugang zu Umweltinformationen auf der Grundlage der europäischen Umweltinformationsrichtlinie von 1990 regelte und das AIG zu den ersten informationsfreiheitsrechtlichen Gesetzen, gibt es inzwischen immer mehr Gesetze, die Informationszugang für bestimmte Bereiche, wie beispielsweise das 2007 verabschiedete Verbraucherinformationsgesetz, regeln. Vor dem Hintergrund von immer mehr Zugangsgesetzen wird auch die Anwendung der Gesetze immer schwieriger. Welche Regelungen haben Vorrang? Sind auf einen Sachverhalt mehrere Gesetze anwendbar? 2007 hat der brandenburgische Gesetzgeber bei der Verabschiedung eines Umweltinformationsgesetzes die Zusammenführung von UIG und AIG bis zum 31. Dezember 2008 beschlossen. Dies eröffnet nach zehn Jahren die Chance, wieder eine Vorreiterrolle einzunehmen. Es können Vorschriften nachgebessert werden und ein Schritt in Richtung besserer Anwendbarkeit und damit auch Entbürokratisierung gemacht werden. Wie viel Mut die jetzige Landesregierung hat, wird sich zeigen. Auch heute gibt es noch genügend Skeptiker, was das Recht auf Transparenz und die weitere Verabschiedung vom alten Amtsgeheimnis angeht. Die Landesbeauftragte für den Datenschutz und für das Recht auf Akteneinsicht hat zur Feier des ersten runden Geburtstages eine Festschrift „Zehn Jahre Akteneinsichtsund Informationszugangsgesetz in Brandenburg“ herausgegeben. Darin kommen Wegbereiter des AIG, der Ministerpräsident des Landes Brandenburg, der Präsident des heutigen Landtages sowie Vertreter aus Politik, Regierung, Wissenschaftlicher, Journalisten und Bürger mit einem persönlichen Blick auf die zehn Jahre AIG zu Wort (http:// www.lda.brandenburg.de).	die (integrated circuit);eine and zwei;gab;institut für dokumentologie und editorik;internet explorer;parity (physics);unified model;vhf omnidirectional range	Dagmar Hartge	2008	Datenschutz und Datensicherheit - DuD	10.1007/s11623-008-0057-0	internet privacy;computer security;computer science		-104.96366313626345	35.63779731994565	130006
ceaf57b6c50d1afa9db50c07fdc067ab74a5ba47	the computation of elementary functions in radix 2 p	arithmetique ordinateur;methode calcul;algorithme;metodo calculo;algorithm;computer arithmetic;funcion matematica;elementary functions;aritmetica ordenador;mathematical function;fonction mathematique;digital number;computing method;algoritmo	Many hardware-oriented algorithms computing the usual elementary functions (sine, cosine, exponential, logarithm, ...) only use shifts and additions. In this paper, we present new algorithms using shifts, adds and “small multiplications” (i. e. multiplications by few-digit-numbers). These CORDIC-like algorithms compute the elementary functions in radix 2 p (instead of the standard radix 2) and use table look-ups. The number of the required steps to compute functions with a given accuracy is reduced and since we use a quick “small multiplier”, the computation time is reduced. Viele hardware-orientierte Algorithmen zur Berechnung der üblichen Elementarfunktionen (Sinus, Cosinus, Exponentialfunktion, Logarithmus, ...) benützen nur Shifts und Additionen. In dieser Arbeit stellen wir neue Algorithmen vor, die zusätzlich noch “kleine Multiplikationen” (mit Zahlen von wenigen Stellen) benützen. Diese CORDIC-artigen Algorithmen berechnen die Elementarfunktionen in der Basis 2 p (statt der standardbasis 2) und benützen Wertetabellen. Da-durch wird die Anzahl der für eine bestimmte Genauigkeit notwendigen Schritte reduziert und bei der Verwendung einer schnellen “kleinen Multiplikation” auch die Rechenzeit.	algorithm;cordic;computation;eine and zwei;elementary function;time complexity;vhf omnidirectional range	Xavier Merrheim	1994	Computing	10.1007/BF02307375	arithmetic;elementary function;mathematics;function;algorithm	Theory	-96.77708877418902	36.363947543110754	130090
413cbe09856d7e6a115086bfa16ef8ed2e6c8597	computer-integriertes private banking: (cipb) ; theoretische und empirische untersuchung zum wettbewerbsbeitrag neuer informationstechnologien im schweizerischen private banking				Daniel Signer	1992				DB	-102.53892468371362	37.16002965292424	130267
e58dbdcc7301a08ce43467ab115074b03ef38214	it-compliance als triebkraft von leistungssteigerung und wertbeitrag der it		Informationstechnologie (IT) muss die Position des Unternehmens gegenüber dem Wettbewerb verbessern sowie den Geschäftsbetrieb sicher, fehlerfrei, effizient und kostengünstig unterstützen. Hinzu kommt die Einhaltung gesetzlicher und regulatorischer Vorgaben (IT-Compliance). Dies führt zu erheblichem Aufwand, etwa für die Einführung von Überwachungsmaβnahmen, die Änderung von IT-Prozessen, für Dokumentation sowie durch die verschiedenartigen Compliance-Nachweise. Der Beitrag zeigt, wie Gesetzes- und Vorgabenkonformität hergestellt und damit gleichzeitig Wertbeitrag und Performance der IT gesteigert werden, wenn die Herstellung der IT-Compliance besondere Gestaltungsgrundsätze beachtet und einer wirksamen IT-Governance unterliegt.	internet explorer	Markus Böhm	2008	HMD Praxis der Wirtschaftsinformatik	10.1007/BF03341246	knowledge management;engineering;performance art	NLP	-103.57622248429055	33.070199680805764	130367
8d7fdd5f24f971b8a23511ea1b9a0ccd9774b7ce	reifegradmodell industrie 4.0 - ein vorgehensmodell zur identifikation von industrie 4.0 potentialen		Zahlreiche Kongresse, Tagungen und Symposien werden unter dem Begriff „Industrie 4.0“ abgehalten. Für eine breite Anwendung in Unternehmen fehlt es oft an Umsetzungsideen mit entsprechender Bewertungsmöglichkeit. Das Reifegradmodell Industrie 4.0 ist ein strategiegeleitetes Vorgehensmodell für Unternehmen, das in den Dimensionen Daten, Intelligenz und Digitale Transformation den Industrie 4.0 Reifegrad bestimmt. Nach Feststellung des ISTReifegrades lässt sich strategiegeleitet der angestrebte SOLL-Reifegrad bestimmen. Konkrete Projektvorschläge zur Erreichung dieses Sollzustandes lassen sich ebenfalls aus dem Reifegradmodell für die teilnehmenden Unternehmen ableiten.	eine and zwei;gesellschaft für informatik;industry 4.0;triple des;zur farbenlehre	Herbert Jodlbauer;Michael Schagerl	2016				NLP	-102.18921362015702	33.67902318995388	130583
2fa72d128b0a21108603e60035f4208651b9048c	computer - mega-maschine oder werkzeuge - zur verantwortung im umgang mit dem computer	mega-maschine oder werkzeuge	Die Diskussion urn Fluch und Segen der Technik ist sicher schon so alt wie die Geschichte der Technik selbst (siehe die Jagdszenen in den Eiszeithohlen von Lascaux), wobei in fruhen Zeiten der Technik­ Besitzende wohl mehr den Machtvorteil sah und der Noch-Nicht-Technik­ Besitzer ohnmachtig aufbegehrte. Auch in der Neuzeit verI ief das Aufkomnen neuer Technologien oft parallel mit komplexen gesellschaftlichen Strukturveranderungen (z.B. beim Buchdruck*), bei den mechanischen Webstuhlen). Kleine gesellschaftliche Gruppen, die die neuen Technologien einfuhrten, standen ihnen naturlich positiv gegenuber, andere Teile der Gesell­ schaft, wenn sie durch diese Technologien Nachteile befurchteten oder erfuhren, lehnten sie abo Die Geschwindigkeit der technisch­ wirtschaftlichen Veranderung spielte dabei unter Unstanden auch ei­ ne Rolle fur die gesellschaftlichen Auseinandersetzungen. Vor genau 100 Jahren hat Werner Siemens sich offentlich an der Auseinanderset­ zung urn die rapide Entwicklung der Elektrotechnik beteiligt und dem eindeutigen Nutzen auch die truben pessimistischen Anschauungen ge­ bi Ideter Kreise als auch breiter Volksschichten gegenubergestellt /1/ .	maschine	Rolf Günther	1986		10.1007/978-3-642-71380-4_9	performance art;history	Theory	-104.95588248301326	33.426777302056166	131163
ea6d35b6ebed7765269b46a0294f79c59f78fac7	in memoriam hans sartorius		at – Automatisierungstechnik 53 (2005) 8 © Oldenbourg Verlag Der Nestor der deutschen Regelungstechnik ist tot, der letzte jener Pioniergeneration, die in den 40er-Jahren die Grundsteine für unser Fachgebiet legte. Er starb drei Tage vor seinem 92. Geburtstag und wurde im engen Freundeskreis in Hersbruck, seinem Geburtsort, beerdigt. Hans Sartorius, geboren am 25. Mai 1913, machte an der Oberrealschule Nürnberg 1933 Abitur und begann – nach einem Praktikum bei mehreren Firmen – das Studium der Elektrotechnik an der Technischen Hochschule München. Dort legte er 1937 das Diplom ab und trat in die Firma Siemens & Halske in Berlin ein, und zwar in das Entwicklungslaboratorium für wärmetechnische Regelgeräte, das unter der Leitung von Rudolf C. Oldenbourg stand. Daraus entwickelte sich eine fruchtbare, lebenslange Freundschaft zweier Männer, beide noch sehr jung und fast gleichaltrig, verbunden durch die gemeinsame Begeisterung für das neue Gebiet der Regelungstechnik. Ihrer engen Zusammenarbeit entsprang das Buch „Dynamik selbsttätiger Regelungen“, das 1944 erschien, dessen Manuskript aber im Wesentlichen schon 1942 vorlag, also nur fünf Jahre nach Beginn der Zusammenarbeit! Es ist das erste deutsche Buch, nein, das erste überhaupt, in dem die Regelungstechnik allgemein und fachübergreifend so klar und konsequent von einem systemtheoretischen Standpunkt aus behandelt wird. Dieses Buch war dem damaligen Stand der Technik weit voraus und nahm die Grundgedanken vieler späterer theoretischer Entwicklungen vorweg. Ich habe es 1985 hier in dieser Zeitschrift ausführlich beleuchtet und kann es auch heute, 20 Jahre später, nur als Geniestreich bezeichnen. Bemerkenswert, dass Sartorius erst zwei Jahre nach Erscheinen des Buches promovierte, nämlich 1946 an der TH Stuttgart bei A. Leonhard mit einer Dissertation über „Die zweckmäßige Festlegung der frei wählbaren Regelungskonstanten“; In memoriam Hans Sartorius	eine and zwei;eddie (text editor);hans moravec;i/o controller hub;institut für dokumentologie und editorik;nestor (encryption);the daily telegraph;vhf omnidirectional range	Franz Mesch	2005	Automatisierungstechnik	10.1524/auto.2005.53.8.411	control engineering;engineering physics;engineering	OS	-103.96178399511801	35.15160414515461	131237
0f59695aaddc4e9f6126fb67e912ba7110b4ec1d	protokollkomposition und komplexität		Um dem Bedarf der modernen Kryptographie an rigorosen und mächtigen Sicherheitsdefinitionen zu genügen, sind in den letzten Jahren sogenannte simulationsbasierte Sicherheitsmodelle mit Umgebung populär geworden. Diese kommen jedoch in vielen Varianten, und es ist nicht offensichtlich, in welcher Relation diese Varianten stehen, das heißt welche Definitionen welche implizieren und welche Begriffe äquivalent sind. Wir untersuchen die verschiedenen Varianten und geben eine vollständige Klassifikation, indem wir alle Implikationen und Trennungen zwischen den Begriffen aufzeigen. Die Resultate werden hier nur kurz skizziert, eine vollständige Darstellung findet sich in der Dissertation [Unr07].	eine and zwei;unified model	Dominique Unruh	2006				OS	-104.98974232795317	32.9739619873822	131315
fa09de55dc4ff63549fc92e5025da83402df0e8e	eine bemerkung zur theorie der symmetrischen zeitspiele			eine and zwei	Lothar von Wolfersdorf	1967	Elektronische Informationsverarbeitung und Kybernetik		pure mathematics;combinatorics;mathematics	NLP	-95.56302293800069	34.37199556006914	131439
a5c405f7173085734ff1dbd3a993f3c881ae4ba9	a novel approach to detection of closely spaced sinusoids	projection matrices;notch periodogram;frequency estimation;fft;detection;hypothesis testing;hypothesis test	A novel method for the detection of closely spaced sinusoids is proposed. It is based on the notch periodogram and a simple detection criterion. Compared with other well-known approaches, this method is not as sensitive to the accuracy of the estimated signal parameters, and it can be implemented with a low computational load. Simulation results of the approach are included, and they show excellent performance. Zusammenfassung Eine neue Methode zur Detektion dicht benachbarter Sinussignale wird vorgeschlagen. Sie basiert auf dem NotchPeriodogramm und einem einfachen Detektions-Kriterium. Verglichen mit anderen bekannten Andtzen ist diese Methode unempfindlich beziiglich der Genauigkeit der geschgtzten Signal-parameter und sie kann mit nur geringer Rechenleistung implementiert werden. Simulationsergebnisse zu dem gewlhlten Ansatz werden vorgestellt; sie zeigen ein hervorragendes Verhalten. Une mkthode innovatrice est proposte pour la dktection de sinuso’ides rapprochCes. Elle est basCe sur le pkriodogramme ii bande Ctroite coupCe et un crithe de dktection simple. Cornparke avec d’autres approches bien connues, cette mkthode n’est pas aussi sensible g la prCcision des parametres e&m&s du signal, et elle peut &tre implant&e avec une charge de calcul minimale. Des rCsultats de simulation de l’approche sont inclus, et ils montrent d’excellentes performances.	computation;eine and zwei;estdomains;linear algebra;performance;secam;sie (file format);simulation;spectral density estimation	Hsiang-Tsun Li;Petar M. Djuric	1996	Signal Processing	10.1016/0165-1684(96)00034-5	econometrics;statistical hypothesis testing;electronic engineering;mathematics;statistics	ML	-98.18421277128672	35.89578651562352	131496
c5b20ab1c353ea52590bdcfca52717c7f6dc0a3f	die algol-verschwörung		Den Ausdruck Die ALGOL-Verschwörung hat meines Wissens erstmals 1993 der Züricher Peter Läuchli, einst Mitarbeiter Rutishausers, geprägt [1]. In der Tat treffen die typischen Merkmale einer Verschwörung zu: eine Gruppe von Personen, ein durchzusetzendes Ziel, ein Ziel, das zunächst nicht offen propagiert wurde. Die Verschwörung begann vor knapp 60 Jahren. Die Gruppe umfasste anfänglich Heinz Rutishauser, Friedrich Ludwig Bauer und Klaus Samelson, und die ersten Ansätze zur Verschwörung ergaben sich auf der von Alwin Walther ausgerichteten Darmstädter Rechenmaschinentagung im Oktober 1955. Die dort vorgetragenen Berichte betrafen hauptsächlich den Bau von Rechnern in Deutschland; aber auch die Fachleute der, wie man es nannte, ,Programmierungstechnik‘ trafen sich nach der Göttinger Tagung von 1953 erstmals wieder in größerem Rahmen. Emphatisch wurde die Vereinheitlichung des Programmierens gefordert, die der ,,Verständigung zwischen den verschiedenen um je eine Maschine gruppierten Rechenzentren“ dienen sollte (Samelson). Rutishauser aus Zürich proklamierte: ,,Es werden jetzt an verschiedenen Orten verschiedene Methoden zum automatischen Programmieren entwickelt und dabei verschiedene Schreibweisen benützt. Es wäre aber zu wünschen, dass in ferner Zukunft einmal alle diese verschiedenen Wege in eine einzige Methode ausmünden ... sollten sie nach Möglichkeit schließlich zu einer einheitlichen algorithmischen Schreibweise kommen, doch muss dies nicht schon heute geschehen.“ Samelson sagte	algol;eine and zwei;heinz rutishauser;intentionally blank page;internet explorer;klaus samelson;maschine;sie (file format);unified model;vhf omnidirectional range	Friedrich L. Bauer	2011	Informatik-Spektrum	10.1007/s00287-011-0585-0	software engineering;computer science	OS	-104.1401505526807	34.13796669405785	131592
876027ab957e6e60e24b4871e0ba7c5bbd65aed7	mitteilungen der gesellschaft für informatik 153. folge (fortsetzung)		Ihre Wahl: Die GI hat einen neuen Vorstand und sechs neue Präsidiumsmitglieder Nicht nur die Kandidatinnen und Kandidaten für die Vorstandsund Präsidiumsämter, auch die Mitglieder des Wahlausschusses und die Mitarbeiter der GI-Geschäftsstelle fieberten dem 14. Dezember entgegen: Wahlauszählung. Bereits vorher hatte man grob gezählt und auf eine hohe Wahlbeteiligung gehofft. 20% hatten wir uns vorgenommen, ein ehrgeiziges Ziel ... Am Nachmittag des 14. Dezember ging es dann los, Teilnahmebögen wurden überprüft, Wahlbriefe gezählt und geöffnet, Berge von Stimmzetteln geordnet und Strichlisten geführt. Um für diese verantwortungsvolle Aufgabe auch angemessen gestärkt zu sein, wurden die Wahlhelferinnen und -helfer reichlich mit Schokolade und Kuchen, Brötchen und Keksen versorgt. Nur den Sekt, den gab es erst (GI-Präsident Heinrich C. Mayr)	eine and zwei;gnu variants;gab;gesellschaft für informatik;unified model	FOLGE FORTSETZUNG	2002	Informatik-Spektrum	10.1007/s002870100207			-104.90699135846461	33.74853480167387	131867
a30c6cdea7fc9cc77353c3aef7822f91bee662f8	fractals, chaos, power laws - minutes from an infinite paradise		Concrete 224 Fractal Interfaces Enforce Fractional Frequency Exponents 225 The Fractal Dimensions of Fracture Surfaces 230 The Fractd Shapes of Clouds and Rain Areas 231 Cluster Agglomeration 232 Diffraction from Fractals 233 11 ITERATION, STRANGE MAPPINGS, AND A BILLION DIGITS FOR PI 23 7 Looking for Zeros and Encountering Chaos 239 The Strange Sets of Julia 243 A Multifractd Julia Set 245 The Beauty of Broken Linear Relationships 249 The Baker's Transformation and Digital Musical Chairs 251 Arnol'd's Cat Map 253 A Billion Digits for 71. 257 Bushes and Flowers from Iterations 259 12 A SELF-SIMILAR SEQUENCE, THE LOGISTIC PARABOLA, AND SYMBOLIC DYNAMICS 263 Self-Similarity from the Integers 264 The Logistic Parabola and Period Doubling 268 Self-Similarity in the Logistic Parabola 272 The Scaling of the Growth Parameter 274 Self-Similar Symbolic Dynamics 2 77 Periodic Windows Embedded in Chaos 279 The Parenting of New Orbits 282 The Calculation of the Growth Parameters for Different Orbits 286 Tangent Bifurcations, Intermittency, and Ilf Noise 289 A Case of Complete Chaos 291 The Mandelbrot Set 295 The Julia Sets of the Complex Quadratic Map 297 13 A FORBIDDEN SYMMETRY, FIBONACCI'S RABBITS, AND A NEW STATE OF MATTER 301 The Forbidden Fivefold Symmetry 301 Long-Range Order from Neighborly Interactions 304 Generation of the Rabbit Sequence from the Fibonacci Number System 307 The Self-Similar Spectrum of the Rabbit Sequence 308 Self-Similarity in the Rabbit Sequence 310 A One-Dimensional Quasiperiodic Lattice 3 10 Self-Similarity from Projections 311 More Forbidden Symmetries 315	chaos theory;complex quadratic polynomial;fractal;interaction;iteration;julia set;mandelbrot set;microsoft windows;period-doubling bifurcation;quasiperiodicity;scalability;self-similarity	Manfred R. Schroeder	1991				Visualization	-96.20402071493503	33.75695866702838	131911
3479e3f7a702288e69e40fc7e365b0ce50a075d2	heuristische erlösprognosen für die bewertung von geschäftsmodellen im application service providing	prix vente;modelizacion;entreprise;modele entreprise;fournisseur;heuristic method;empresa;metodo heuristico;supplier;modelo empresa;devis estimatif;modelisation;business model;presupuesto estimativo;firm;methode heuristique;estimate;modeling;selling price;precio venta;proveedor	Bedingt durch die Fortschritte in der Informationsund Kommunikationstechnik sowie die zunehmende Spezialisierung vieler Unternehmen wurden in den letzten Jahren viele traditionelle Leistungsangebote aufgespalten und zu neuen Leistungsbündeln zusammengefasst. Parallel dazu entstanden neue Wertschöpfungsketten und Kooperationsformen von Unternehmen [BiRü02; PiRe03]. Dies gilt zum Beispiel auch für das Application Service Providing (ASP), bei dem Kunden die entgeltliche Nutzung von Softwareanwendungen mit Hilfe von Telekommunikationsdienstleistungen ermöglicht wird. Leistungsbündel [Cors01, 20] sind Kombinationen aus verschiedenen, untereinander komplementären und kompatiblen Gütern. Die einzelnen Komponenten eines solchen Leistungsbündels können ihren Anwendern einen Originärnutzen stiften. In der Regel ergibt sich der Nutzen aber in erster Linie daraus, dass die Güter eines Leistungsbündels gemeinsam genutzt werden. Sie stehen oft in einem so starken Verwendungszusammenhang, dass die Kunden die verschiedenen Güter eines solchen Leistungsbündels als ein Produkt oder eine Dienstleistung wahrnehmen. Die einzelnen Güter eines solchen Leistungsbündels werden in der Regel von verschiedenen, miteinander kooperierenden Unternehmen entwickelt. Dem Kunden gegenüber tritt aber häufig nur eines dieser Unternehmen als Anbieter des gesamten Systems auf. Wie wir später noch detaillierter darlegen werden, können die im Rahmen von ASP angebotenen Dienstleistungen als solche komplexe Leistungsbündel verstanden werden [GüTa01, 562]. Die Erstellung von Leistungsbündeln durch eine Zusammenarbeit verschiedener Unternehmen eröffnet für die einzelnen beteiligten Partnern a priori verschiedene Kooperationsmöglichkeiten. Die Gestaltung solcher Kooperationsformen wird – sowohl in der Forschung als auch in der Unternehmenspraxis – im Kontext von Geschäftsmodellen diskutiert [BiRü02, 48ff.]. Bislang liegt kein umfassendes Modell zur ökonomischen Bewertung von Geschäftsmodellen vor, bei denen verschiedene Kooperationspartner gemeinsam kom-	die (integrated circuit);eine and zwei;internet explorer;sie (file format);v-model;vhf omnidirectional range	Hubert Dechant;Dirk Stelzer;Ralf Trost	2004	Wirtschaftsinformatik	10.1007/BF03250962	business model;systems modeling;management	OS	-101.235228034216	34.31563053753765	131985
18fada16af6636db2b56c52c5959bb21b608dd37	multihop connectivity in wireless ad hoc networks		Multihop-Konnektivitaet ist die Faehigkeit der Knoten, die nicht direkt angebunden sind, miteinander zu kommunizieren. Da drahtlosen Ad-hoc-Netzwerke keine Infrastruktur haben, die beteiligten Knoten sind selbst angeblich um den Dienst der Multihop-Konnektivitaet, indem die Weiterleitung der Nachrichten im Namen der jeweils anderen. Routing und Relaying sind die zwei Ansaetze, um Multihop-Konnektivitaet in solche Netzwerke zu realisieren. In Relaying ist MAC-Schicht der Punkt im Protokollstapel, beim der wechsel- oder die weiterleitung-Entscheidung getroffen wird. Die Routing-Systeme treffen diese Entscheidung zu einem spaeteren Zeitpunkt, beim Vermittelungsschicht. Routing ist ein weit erforscht und praktiziert Loesung fuer die Problem der Multihop-Konnektivitaet als Relaying. Diese Doktorarbeit argumentiert, dass aufgrund der besonderen Natur der drahtlosen Ad-hoc-Netzwerken und die MAC-Protokolle fuer diese Netze, Relaying ist technisch eine geeignete Option in dieser Netzwerke und hat hoehere Aussichten. Dieses Argument wird durch der Gestaltung eines Multihop-Version des IEEE 802.11 MAC-Protokoll und den Vergleich ihrer Leistung mit den AODV Routing-Protokoll unterstuetzt. Die Analyse zeigt, dass es viel einfach ist, ein Multihop 802.11 MAC umzusetzten, und es kann die Leistung vergleichbar mit dem AODV erreichen. Fuer reaktiven oder On-Demand-Klasse von Routing-Protokolle wird ein Accessibility-Prediction-Schema in dieser Arbeit eingefuhrt. Dies reduziert die Routing-Aufwand durch die Vermeidung von Routing-Aktionen, die moeglich zu scheitern sind. Darueber hinaus bewertet diese Arbeit die Auswirkungen der Nutzung von veralteten Routing-Informations, ein gemeinsames Konzept zur Optimierung der reaktiven Routing-Protokolle. Auf der Grundlage der Analyse, so wird argumentiert, dass diese Methode nicht mit der Art der reaktiven Routing konsistent ist, und hat nur beschraenkt aber unberechenbar Vorteile, hauptsaechlich wenn keine zusaetzliche Aufwand entsteht.	hoc (programming language)	Habib-ur Rehman	2009			vehicular ad hoc network;wireless ad hoc network;optimized link state routing protocol;mobile ad hoc network;ad hoc wireless distribution service;ad hoc on-demand distance vector routing	Mobile	-108.01176029382121	34.99733870346294	132547
0d9f4ab7032ca9c15cfb0e7162f2326782cd6f42	detektion von leukozyten mit hilfe neuronaler strukturen		Die Bestimmung der Anzahl und Geschwindigkeit von Leukozyten in Venolen ermoglicht Ruckschlusse auf den Aktivierungszustand des Immunsystems. In diesem Beitrag werden neuronale Netze zur Detektion von Leukozyten in Sequenzen von Mikrozirkulationsaufnahmen eingesetzt. Das Training der Netze erfolgt mit synthetischen Leukozytenbildern, die uber ein stochastisches Modell gewonnen werden. Kunstliche Zellenmuster bieten eine wesentlich bessere Anpassungsfahigkeit an neues Bildmaterial, als dies reales Bildmaterial ermoglicht. Um die Leistungsfahigkeit des Zellenmodells zu uberprufen, werden Netze mit echten und synthetischen Datensatzen trainiert. Dabei erzielen Netze auf Basis synthetischer Zellenmuster in fast allen Netzkonfigurationen bessere Ergebnisse als solche, die mit echten Zellenbildern trainiert wurden.		U. Schreiner;Michael Egmont-Petersen;Thomas Martin Deserno;S. C. Tromp;D. W. Slaaf;Theo Arts	1998			history;performance art	Crypto	-105.81091378033226	32.63535270845653	132607
360f35c0fa20bf1685f872d81f5574237fd35b74	qualitative anforderungen an informationsobjekte bei der datenintegration		Zusammenfassung. Für die Datenintegration sind inzwischen viele Architekturkonzepte und Technologien verfügbar, und es stellt sich die Frage, auf welcher Basis eine Architekturund Technologieauswahl erfolgen sollte. Der Beitrag stellt aus fachlicher Perspektive (Sicht der Aufgabenträger) eine Reihe von nicht-funktionalen und funktionalen Anforderungen im Zusammenhang mit Informationsobjekttypen vor, aus denen sich potenziell technische Anforderungen an Datenintegrationsarchitekturen ableiten lassen.	eine and zwei;vhf omnidirectional range	Reinhard Jung	2005				DB	-105.0264116752818	32.45415509827842	132734
ef9b4ac8966ab347ca60e8757ad0e369eb5729ce	,,print ist heute nach wie vor ein wesentlicher und wichtiger bestandteil im alltag der jungen menschen“		Ja, genau. Wenn es darum geht, Neues zu erfassen, weisen haptisch vorliegende Lernunterlagen einen Vorteil auf. Auf gedruckten Seiten ist es leichter, sich eine Übersicht zu verschaffen, komplexe Zusammenhänge einzuordnen und sich Inhalte einzuprägen. Papier kann angemarkert, bekritzelt und an besonders wissenswerten Stellen geknickt werden – das macht das Lernen doch noch leichter und anschaulicher, als Inhalte auf digitalen Bildschirmen zu lesen. Auch Befragungen zeigen das: Bei Statista zum Beispiel gaben 61 % der Befragten an, längere Texte lieber auf Papier zu lesen [6]. Lediglich 6 % bevorzugen den Bildschirm. Eine ähnliche Erfahrung machen wir im Kontakt mit Unternehmenskunden: Die Visitenkarte ist beim Geschäftstreffen so allgegenwärtig wie das Firmenlogo auf dem Shirt oder die Folie auf dem Fahrzeug. Wenn wir den Gedanken hier weiterspinnen und an Werbemöglichkeiten denken, die über das persönliche Inventar hinausgehen, landen wir schnell bei den Zeitungen, Magazinen und Beilagen, ohne die eine riesige Werbefläche verloren gehen würde. Und nicht nur das. Auch das Kernprodukt Print überlebt zum einen durch die Werbekunden, die ihre Produkte zu Themenspecials und sonstigen Anlässen in den Medien platzieren wollen, und zum anderen, weil die Menschen es lieben, sich beim Frisör, im Zug, beim Frühstück oder in der Mittagspause mit etwas Papier in der Hand zu belesen und sich unterhaltsam die Zeit zu vertreiben. Das Wochenmagazin Werben & Verkaufen stellt hier in einer Studie vom 9. Juli 2018 heraus, dass die Bindung der Leser an ihre regionale Tageszeitung sehr stark ist [7]. Demnach würden 89 % der Printleser die Printauflage vermissen. Dem entgegen stehen 88 % der Digitalleser, die das Angebot ebenfalls vermissen würden. Auch die alljährliche Studie des Reuters Institute zum Thema Mediennutzung zeigt in seinem Report für 2018, dass der Printkonsum im Vergleich zu den Vorjahren wieder zunimmt [1]: 30 % der Deutschen verfolgen Nachrichten in gedruckten Zeitungen – 4 % mehr als im Vorjahr. 65 % bevorzugen	eine and zwei;internet explorer;vhf omnidirectional range	Cecil von Croÿ;Peter Pagel	2018	Informatik-Spektrum	10.1007/s00287-018-1119-9	software engineering;computer science	OS	-104.46175158487176	33.97421439762457	132780
0edb6bcb1a864891486e0071e56a9418f342e7ac	das neue v-modell® xt		Bei der Entwicklung softwareintensiver Systeme ist die Zahl gescheiterter oder wirtschaftlich nicht erfolgreicher Projekte erschreckend hoch. Ein Grund dafür sind unzureichende Planung und unsystematische Vorgehensweisen.	v-model	Manfred Broy;Andreas Rausch	2005	Informatik-Spektrum	10.1007/s00287-005-0488-z		NLP	-104.1051316601348	32.80106678137568	133538
5ff41f7c0073a02d7c047733e7f63b1fe2fade6b	usability gesichtserkennungsbasierter authentifizierung		Die Authentifizierung von Nutzern an IT-Systemen erfolgt — trotz zahlreicher praktischer Schwächen — bis heute meist mit Passwort-Verfahren. Sie sind oft das schwächste Glied in einer Kette von Sicherheitsmechanismen und damit maßgeblich für die Gesamtsicherheit. Eine Alternative zu herkömmlichen alphanumerischen Passwörtern ist die Verwendung „graphischer Passwörter“, mit denen einigen Schwachstellen begegnet werden kann. Die Autoren stellen die Ergebnisse der praktischen Erprobung eines gesichtserkennungsbasierten Authentifizierungssystems vor, das die besondere menschliche Merkfähigkeit von Gesichtern nutzt.	eine and zwei;sie (file format);usability;vhf omnidirectional range	Thomas Fenzl;Christian Kollmitzer	2012	Datenschutz und Datensicherheit - DuD	10.1007/s11623-012-0167-6	internet privacy;usability;computer science	OS	-103.60584518534174	36.95279239978519	134884
10aeaf718cd8822e8200ebe2985b5548e44938fa	ist die zipf'sche regel noch gültig?		"""Dr. Wilfried Grieger, Studium der Physik an der Universität Göttingen 1971-1977, Promotion in Theoretischer Physik 1981 über ein Gittermodell, Hochschulassistent am Institut für Theoretische Physik der Universität Göttingen 1982-1987, seit 1987 wissenschaftlicher Mitarbeiter der Gesellschaft für wissenschaftliche Datenverarbeitung mbH Göttingen in der Arbeitsgruppe „Organisation und Planung""""."""	wilfried brauer	Wilfried Grieger	1992	Praxis der Informationsverarbeitung und Kommunikation	10.1515/piko.1992.15.2.103	algorithm;computer science;sche;zipf's law;distributed computing	DB	-103.44875157395971	34.986166453992766	134912
897253cdb94984edf3d16639a13a16a7472b0049	anforderungen an lehrunterstützende kooperationssysteme aus kommunikationstheoretischer sicht		Mit der beschleunigten Entwicklung hin zur Informationsgesellschaft gewinnt auch der Computereinsatz in der Ausbildung an Bedeutung, wobei nicht nur Anwendungen sondern auch zugrundeliegende Paradigmen wechseln. Wahrend in den 60er Jahren mit dem Aufkommen des Computer-Assisted Instruction (CAI) der Behaviourismus seine Sternstunde hatte, wurde in Anwendungen der 80er Jahre kognitiver Konstruktivismus umgesetzt. Neueste Entwicklungen stutzen sich auf das Paradigma des Computer Supported Collaborative Learnings (CSCL), das Konzepte des sozial orientierten Lernens propagiert. Dabei steht vor allem auch das kooperative Lernen in Gruppen im Vordergrund, das auch den Lernenden eine aktive Rolle zuordnen soll. Koschmann [Koschmann (1996)] oder Wiburg [Wiburg (1995)] sehen in dieser Entwicklung einen Paradigmenwechsel hin zum selbsverantwortlichen Lernenden. Die Umsetzung in neuartigen Konzepten geht jedoch nach Meinung einiger Skeptiker bislang nicht weit genug. So verweist Papert auf die Probleme, das bestehende Ansatze haufig dem Lehrenden eine aktive und dem Lernenden eine passive Rolle zuordnen: „Diese Asymmetrie ist so stark verwurzelt, das sogar die Befurworter einer aktiven oder „konstruktivistischen“ Padagogik Schwierigkeiten haben, ihr zu entgehen“ [Papert (1994), S. 104].		Thomas Herrmann;Andrea Kienle	1999				Logic	-107.12899416353511	33.92242515899258	134960
bae09c06b700a0886d0e46b4bc10f8ce748858fe	ein integrativer ansatz für unternehmensweite wissensportale	330 wirtschaft;ddc 330	Wissensportale leisten einen wichtigen Beitrag zum Wissensmanagement eines Unternehmens, indem sie es Benutzern ermoglichen, direkt mit Geschaftsprozessen und Wissen zu arbeiten. Dabei bieten Wissensportale durch eine konsolidierte, personalisierte Benutzeroberflache einen effizienten Zugriff auf die immer unuberschaubarer werdende Flut an Informationen, die die Wissensbasis des Unternehmens bilden. Heutige Portalsysteme beschranken sich jedoch auf die gemeinsame Darstellung unterschiedlicher Wissensressourcen (Data Warehouse, Dokumentenmanagementsystem, Internet, etc.) in Form von sog. Portlets auf einer Portalseite. Eine Interaktion der Portlets untereinander erfolgt nicht. Navigiert ein Benutzer innerhalb eines Portlets, so bleiben die anderen statisch, was bedeutet, dass jede Wissensressource getrennt nach relevanten Informationen durchsucht werden muss. Dieser Beitrag stellt einen Integrationsansatz vor, der im Sinne einer effizienten Wissensnutzung den durch Navigation in einem Portlet offenbarten Informationsbedarf eines Benutzers auch in anderen Portlets zum Auffinden passender Informationen heranzieht. Zur Evaluation des Ansatzes ist ein prototypisches Portalsystem in Entwicklung, welches sich auf die Integration von OLAP und Information Retrieval konzentriert.		Torsten Priebe;Günther Pernul;Peter Krause	2003		10.1007/978-3-642-57445-0_14	computer science	Crypto	-106.27375336906549	35.46611269137154	135357
2c8fc1a1ca9c476eed9ac00cd77011bcf64f4ad7	ein referenzmodell für anforderungsspezifikationen		Zusammenfassung: Viele verschiedene Ansätze zur Modellierung von Anforderungen wurden im Verlauf der Zeit entwickelt. Doch der prinzipielle Zusammenhang zwischen diesen Notationen ist weitestgehend unklar. Im Rahmen der beschriebenen Arbeit wurde ein Referenzmodell abgeleitet, dass mehrere sehr verschiedene Notationen integriert. Das mittelfristige Ziel der beschriebenen Arbeiten ist eine Basis für die semi-automatische Transformation von Anforderungsmodellen zu bieten. 1 Motivation	eine and zwei;gesellschaft für informatik;semiconductor industry	Thomas Olsson;Christian Denger;Tom Koenig;Michael Eisenbarth;Klaus Schmid	2004	Softwaretechnik-Trends		computer science;software engineering;performance art	OS	-102.64310037543326	32.31789204010767	135581
70d230603cc0dc949a8ff477565c169002a06c32	open-source-erp-systeme für das controlling — eine vergleichende systemevaluation		Die Systemevaluation vier ausgewählter Open-Source-ERP-Systeme (OS-ERP-Systeme) hat gezeigt, dass Controlling-Aspekte oftmals nur minimal oder unzureichend umgesetzt sind. Damit konnte eine wesentliche Lücke im Funktionsumfang der betrachteten Systeme identifiziert werden.Darüber, inwiefern diese funktionale Lücke in Zukunft geschlossen werden wird, kann jedoch nur schwer eine Aussage getroffen werden. Der Markt für OS-ERP-Systeme und die Systeme selbst unterliegen einer hohen Dynamik, sodass innerhalb kurzer Zeit neue Systeme hinzukommen oder sich der Funktionsumfang einzelner Systeme wesentlich umgestalten kann.	die (integrated circuit);eine and zwei;erp;firefox os;operating system;système universitaire de documentation	Christian Leyh;Mark Neumann	2012	HMD Praxis der Wirtschaftsinformatik	10.1007/BF03340662	knowledge management;engineering;performance art	OS	-102.57526464296325	32.74595147516023	135742
1b36f54a2ca6cdd7d634da424f6930dd90731aa4	auswirkungen kulturspezifischer verhaltensmuster auf das sozialkapital in multinationalen it-projektteams - ein fallstudienansatz		Die vorliegende Forschungsarbeit hilft, negative Auswirkungen kultureller Unterschiede in multikulturellen IT-Projektteams besser verstehen und mittels geeigneter Managementmasnahmen adressieren zu konnen. Es wird untersucht, wie sich kulturspezifische Verhaltensweisen auf das Sozialkapital multikultureller Teams auswirken und wie ein Unternehmen dadurch entstehende Spannungen besser bewaltigen kann. Die bestehende Literatur, die sich mit den kulturellen Auswirkungen im Kontext von Informationssystemen beschaftigt, fuhrt kulturspezifische Verhaltensweisen – wenn uberhaupt – nur auf einzelne Kulturdimensionen zuruck. Der in dieser Arbeit vorgeschlagene Ansatz geht dagegen einen Schritt weiter. Wir argumentieren, dass eine Kombination und Aggregation mehrerer Kulturdimensionen zu sogenannten kulturellen Verhaltensmustern notwendig ist, um ein bestimmtes kulturspezifisches Verhalten besser verstehen und die sich daraus ergebenden Beziehungsprobleme in multikulturellen Szenarien in der Folge besser nachvollziehen und bewaltigen zu konnen. Auf Basis von Fallstudien in sechs landerubergreifenden IT-Projekten werden zwei beispielhafte kulturspezifische Verhaltensmuster betrachtet (Gesichtswahrung in Indien und Post-Kommunismus in Tschechien). Zudem werden geeignete Managementmasnahmen abgeleitet, die zur Vermeidung der sich in den Projekten ergebenden Probleme beitragen. Die gewonnenen Erkenntnisse fordern ein besseres Verstandnis sowie das Management negativer Auswirkungen kulturspezifischen Verhaltens in IT-Projektteams und bestatigen, dass Forschung auf Basis bewahrter Kulturdimensionen hierfur einen wichtigen Beitrag liefern kann.		Alexander von Stetten;Daniel Beimborn;Tim Weitzel	2012	Wirtschaftsinformatik	10.1007/s11576-012-0322-6	knowledge management;data science;computer science	Logic	-101.1386785162471	35.24332831473312	135878
efa4bd8d5d57f422ab5abeac69d6f93a2832044c	optimierte umsetzung eines telekommunikation protokolls aus dem bereich internet-telefonie auf mikrocontrollern		Gegenstand der hier vorgestellten Bachelorarbeit ist die Erstellung eines Realisierungskonzepts und der Implementation des Kommunikation-GatewayProtokolls MEGACO auf einer spezialisierten (embedded) TelekommunikationHardware-Plattform. Die angestrebte Anwendung ist die Verbindung von klassischen Telefonnetzen mit der Internet-Telefonie.	embedded system;internet	Sebastian Blumenthal	2008			world wide web;the internet;business	Embedded	-103.41142487241758	36.203636488551965	135948
3d110ee914b1480d9b94b2c0a38afdad81dd5bda	anonymisierungsverfahren für paneldaten	panel data;anonymisation;micro data;mikroaggregation;mikrodaten;anonymisierung;zufallsuberlagerung;microaggregation;paneldaten;random noise methods	Der folgende Artikel gibt einen Uberblick uber die im Projekt „Wirtschaftsstatistische Paneldaten und faktische Anonymisierung“ untersuchten Anonymisierungsverfahren. Ziel des Projektes ist die Untersuchung der Anwendbarkeit von Verfahren zur Einzeldatenanonymisierung bei der Erstellung von Scientific-Use-Files. Die Bereitstellung von faktisch anonymisierten Scientific-Use-Files soll es der Wissenschaft ermoglichen, mit Paneldaten auch auserhalb von Forschungsdatenzentren zu arbeiten. Dabei bedeutet faktische Anonymitat, dass der Nutzen aus dem Informationsgewinn fur einen Datenangreifer den Aufwand fur die Zuordnung und Offenlegung von Informationen nicht ubersteigt. Die Ergebnisse analoger Untersuchungen fur Querschnittsdaten sind in Ronning et al. (2005) dokumentiert. Deshalb wird hier im Besonderen auf die Erweiterungen eingegangen, die durch die Anwendung der Verfahren auf Paneldaten erforderlich werden.	gesellschaft für informatik	Jörg Höhne	2008	AStA Wirtschafts- und Sozialstatistisches Archiv	10.1007/s11943-008-0047-6	microdata;economics;panel data;mathematics	NLP	-102.50379414602087	35.77503905199503	136292
b387ab7a414221f28ea61c0ba5506cdf9c3d2243	the one-sided remez algorithm	one-sided;minimax;alternation;remez algorithm.	Best one-sided minimax approximations from above on an interval by alternating families have an alternating characterization and may be computed by a simple modification of the classical Remez algorithm for ordinary Chebyshev approximation. Beste einseitige Minimax-Approximationen von oben auf einem Intervall mit Hilfe von alternierenden Familien besitzen eine Charakterisierung als Alternanten. Die Approximationen können durch eine einfache Abänderung des klassischen Remez Algorithmus für gewöhnliche Tschebyscheff-Approximationen berechnet werden.	approximation theory;eine and zwei;minimax;remez algorithm	Charles B. Dunham	1983	Computing	10.1007/BF02253898	mathematical optimization;combinatorics;mathematical analysis;equioscillation theorem;mathematics;remez algorithm;minimax approximation algorithm	Theory	-96.5103950738168	35.36488566394774	136447
e10f2d73b5d87ccb5bd7f7380b8eacf0779b17bc	dr. dean jacobs		Die deutsche Datenbank-Community trauert um Dr. Dean Jacobs, der am 14. Januar nach kurzer schwerer Krankheit verstarb. Dean Jacobs wurde 1958 in New Jersey geboren und studierte Informatik an der UC San Diego. Er wechselte nach dem Bachelor an die Cornell University, wo er bei Prof. David Gries promovierte. 1984 wurde er mit 25 Jahren Professor an der University of Southern California (USC), Los Angeles. Mitte der 90’er Jahre verließ er zunächst die akademische Welt, um federführend den (später marktführenden und dann durch BEA akquirierten) Applikationsserver WebLogic zu realisieren. Ab 2004 war er zwei Jahre lang leitender Softwarearchitekt bei salesforce.com, bevor er 2006 eine DFG-geförderte Mercator Gastprofessur an der TU München annahm und dadurch auch innerhalb der deutschen Datenbank-Community aktiv und geschätzt wurde. Während der Gastprofessur beschäftigte sich Dean mit den Herausforderungen an die technischen Grundlagen von Datenbanksystemen im Kontext von Softwareas-a-Service. Im Speziellen initiierte er die Datenbankforschung im Umfeld von Multi-Tenancy, also der effizienten Unterstützung mandantenfähiger Anwendungen auf großen Datenbankinstallationen. Mit diesem Thema besetzte Dean Jacobs ein für die Datenbankforschung nicht nur extrem herausforderndes, sondern insbesondere auch praktisch relevantes Themengebiet. Sein Forschungsbeitrag (D. Jacobs & S. Aulbach: Ruminations on Multi-Tenant Databases) auf der BTW 2007 in Aachen läutete dieses derzeit sehr aktive Forschungsgebiet nicht nur in Deutschland sondern	david gries;eine and zwei;institut für dokumentologie und editorik;multitenancy;oracle weblogic server;uc browser;unified model	Alfons Kemper;Wolfgang Lehner	2013	Datenbank-Spektrum	10.1007/s13222-013-0117-y	computer science;library science;data mining	DB	-103.86438089930589	35.171708778208064	136606
86f1d1a1d1d36003c56acd5796c75034150dfae3	zur rolle von parametrisierung bei der fachlichen anpassung betrieblicher softwarekomponenten		Komponentenbasierte betriebliche Anwendungssysteme bieten den Vorteil, dass ein Teil der notwendigen Flexibilität durch Auswahl und Austausch von Komponenten erreicht werden kann. Allerdings ist es weder möglich noch effizient, die gesamte notwendige Variabilität allein durch Komponentenaustausch zu realisieren. Eine Alternative dazu besteht vor allem bei kleineren, fachlichen Anpassungen im Einsatz von Parametrisierung. Diese Arbeit beschäftigt sich mit der Rolle, die Parametrisierung zur fachlichen Anpassung in komponentenbasierten betrieblichen Anwendungssystemen spielen kann, und untersucht insbesondere, in welchen Anpassungssituationen ihr Einsatz geeignet ist.	eine and zwei;vhf omnidirectional range	Jörg Ackermann;Klaus Turowski	2006			collar;ratchet;limiting;integrally closed;materials science;thermoforming;composite material	OS	-105.31633652225521	33.32929763429815	137017
aac26a8f3aa662f5d95d78effd1adb082413da2f	dud recht		"""1. Beim Scannen zur Erstellung einer elektronischen Akte ist sicherzustellen, dass mangelhafte Scanvorgänge erkannt werden. Insoweit bedarf es beim Scannen einer entsprechen-den Qualitätskontrolle, welche auch sicherstellt, dass die Do-kumente in der Originalgröße, in den Originalfarben sowie richtig lesbar und vollständig eingescannt werden. 2. Unterlagen in Behördenakten haben eine Bedeutung und Ur-kundseigenschaft. 3. Im Falle eines ersetzenden Scannens ist jedes eingescannte Dokument zwingend auf seine Qualität zu prüfen und von der einscannenden Person entsprechend mit einem Überein-stimmungsvermerk qualifiziert zu signieren. 4. Ist dies nicht der Fall, so führt die Ausländerbehörde nur ir-gendwelche Kopien, über deren Richtigkeit und ihren Nach-weisgehalt in einem Freibeweis entschieden werden muss. Erstellung einer elektronischen Akte sicherzustellen ist, dass mangelhafte Scanvorgänge (z.B. fehlende Seiten, mangelnde Lesbarkeit – wie vorliegend gegeben, z.B. durch Verkleine-rung und Abschneiden der Dokumente – fehlender Doku-mentenzusammenhang, beschädigte Dateien) erkannt wer-den. Dazu muss eine geeignete Qualitätskontrolle und ggf. eine erneute Erfassung stattfinden. Insoweit bedarf es beim Scannen einer entsprechenden Qualitätskontrolle, welche auch sicherstellt, dass die Dokumente in der Originalgröße, in den Originalfarben sowie richtig lesbar und vollständig eingescannt werden. Dies ist bei den vorgelegten Ausdrucken in der """" Ausländerak-te """" nicht der Fall. Dies ist vorliegend alles bei der """" Ausländerakte """" nicht gegeben."""	eine and zwei;institut für dokumentologie und editorik;internet explorer;link rot;word error rate;zur farbenlehre	Zum Sachverhalt;Soweit	2015	Datenschutz und Datensicherheit - DuD	10.1007/s11623-015-0362-3		NLP	-105.3510948987094	33.92583153028074	137145
b05a67c04a7b39b45e39be56e56653baf7915392	optimale meßstrategie zur frequenzganganalyse stochastisch gestörter regelstrecken				Hans-Helmut Wilfert	1972	Elektronische Informationsverarbeitung und Kybernetik		combinatorics;mathematics	NLP	-95.49921062296775	34.317271496848655	137158
578eb08d9d09bbef9f14666a1b5d57983f72c8ba	ansatz zur automatischen erzeugung von ausgabetreibern für die ansteuerung von zeichendruckern durch textformatierer				Klaus Guntermann	1984			mathematical physics;mathematics;ansatz	Theory	-97.00888114771735	34.20877501413677	137528
5ce3e670495b7407c59c9ac7c6c79b4311bced7e	iterative analyse von markov-modellen mit alternierender aggregation und disaggregation	iterative analyse von	Wir schlagen eine iterative approximative Analysemethode fur Markov-Ketten mit grosem Zustandsraum vor, die mit Aggregation und Disaggregation durch Entropiemaximierung die Speicherund Rechenzeitkomplexitat reduziert. Sie ist universell; es werden exemplarisch Fork-Join-Netze und Pollingsysteme damit modelliert und analysiert. Dazu wird eine passende Modelliersprache und ein Programmierwerkzeug verwendet. Im diskreten Fall beruht die Iteration auf der ublichen Vektoriteration, ist also bei fast vollstandig zerlegbaren Systemen zu langsam konvergent. Wir schlagen zur Abhilfe ein auf Aggregationen zugeschnittenes Verfahren fur simultane Iteration vor.	markov chain	Johann Christoph Strelen	1991		10.1007/978-3-642-76934-4_22	mathematical optimization;mathematics;markov chain	AI	-97.54274937033385	35.18664915872545	138194
5dab405629d0321efd3cf24bda13151f9b4590e2	die extensible business reporting language-standard, taxonomien und entwicklungsperspektiven	langage xbrl;extensible business reporting language;information system;systeme information;sistema informacion	Seit ca. drei Jahren wird durch die Entwicklung der Extensible Business Reporting Language (XBRL) versucht, die Erstellung und bermittlung von Geschäftsdaten (business reporting), insbesondere unter Nutzung des World Wide Web, zu verbessern. Mögliche Empfänger sind z. B. staatliche Stellen, Wirtschaftsprüfer, Investoren und Analysten. Während in vielen Ländern die Veröffentlichung von Geschäftsdaten in elektronischer Form ein freiwilliges Angebot darstellt, sind Aktiengesellschaften in den USA und Kanada ab einer bestimmten Größe verpflichtet, Geschäftsdaten an eine zentrale Datenbank zu übermitteln.	circa;eine and zwei;world wide web	Pascal Kranich;Hans Schmitz	2003	Wirtschaftsinformatik	10.1007/BF03250885	computer science;database;world wide web;information system	DB	-102.6413873046591	34.6341965144186	138218
ef928faeac24f22ccf2ec04c0376c2a03003b799	systemorientiertes automotive engineering		Die Zunahme der durch Informations- und Kommunikationstechnologien erbrachten Funktionalitäten in Automobilen stellt die Industrie vor neue Herausforderungen. Weitergehende Anforderungen zur Individualisierung, und damit zur Modell- und Variantenvielfalt, sowie der Zwang zu schnellen Modellwechseln bedingen eine steigende Komplexität, spezifische Kostenstrukturen und eine weitergehende Arbeitsteilung bei optimierter Produktivität in Entwicklung und Produktion. Dies und der wachsende Kostendruck sind der Hintergrund, vor dem das essenzielle Wechselspiel zwischen der Vielzahl der Funktionen und Systeme im Rahmen immer kürzerer Innovationszyklen beherrscht werden muss. Die dazu notwendige Zusammenarbeit unterschiedlicher Disziplinen wie Informatik und Informationstechnik mit traditionellen Ingenieurdisziplinen wie Maschinenbau und Elektrotechnik, erfordert zwingend die Herausbildung eines ganzheitlichen systemorientierten Automotive Engineerings.	automotive software;eine and zwei;internet explorer;vhf omnidirectional range	Herbert Weber;Manfred Broy	2009	Informatik-Spektrum	10.1007/s00287-009-0337-6	software engineering;computer science	OS	-101.86284252482871	32.39912677273459	138354
79a4b97c25e725050f26216678524a14dbfa64b0	prognosen und thesen . . . nicht nur zum schmunzeln		sentiere ich in dieser Arbeit 60 (Gruppen von) Aussagen, die zu dem Zeitpunkt, zu dem sie gemacht wurden, Prognosen über zukünftige technische Entwicklungen waren. Einige von diesen haben sich inzwischen als eklatant falsch, andere als verblüffend richtig erwiesen, und wieder andere beziehen sich auf Zeiten jenseits 2000 und sind also noch 1offena. Die Sammlung von Aussagen zeigt v. a., wie schwer Prognosen über die Zukunft sind, wie schwer sich oft auch die besten Wissenschafter von liebgewonnenen Ideen trennen, selbst wenn schon alles gegen sie spricht. Sie zeigt aber auch ± dort, wo sie die Zukunft betrifft ± ein wie starker Wandel unserer Gesellschaft noch bevorsteht.	gesellschaft für informatik;i/o controller hub;internet explorer;sie (file format)	Hermann A. Maurer	2000	Informatik-Spektrum	10.1007/s002870050008	world wide web;software engineering;computer science	NLP	-104.8759816775977	34.42176860311677	138451
4c26c77d5ad8399b7daf8976fd8187c8ca37fd71	mitteilungen der schweizer informatiker gesellschaft · 4/2003		Abstrakt In der Softwareentwicklung greift man oft auf ausgereifte, freie, im Internet erhältliche Softwareprodukte zurück, um die eigene Entwicklungsarbeit zu beschleunigen und die Entwicklungskosten zu senken. Dies führt dazu, dass z.B. die Durchdringung der Internetinfrastruktur mit freier Software enorm hoch ist. Gemäss einer kürzlich veröffentlichten Statistik [1], wurden im April 2003 von 40 Millionen geprüften Webservern über 60 Prozent mit dem Open Source Produkt „Apache“ realisiert. Auf dem zweiten Platz, mit unter 30 Prozent Anteil, folgt das kommerzielle Produkt „IIS“ (Internet Information Server) von Microsoft. Da die Nutzung solch „freier“ Software aber immer auch an entsprechende Lizenzen gekoppelt ist, muss man sich bewusst sein, welchen Einfluss ein solcher Softwareeinsatz auf das eigene kommerzielle Produkt haben kann. In der Zwischenzeit gibt es eine große Anzahl verschiedener Lizenzmodelle für „freie“ Software und es ist nicht immer einfach, sich in diesem Lizenz-Dschungel zurechtzufinden. Deshalb wollen wir in diesem Artikel die wichtigsten Lizenzen zur freien, offenen Software vorstellen und anhand konkreter Beispiele zeigen, welche Bedingungen diese Lizenzen bei der Nutzung an das eigene Produkt stellen.	eine and zwei;internet information services;unified model;zentralblatt math	M. Schweizer;Markus Degen;Marcel Lanz;Jürg Luthiger	2003	Informatik-Spektrum	10.1007/s00287-003-0323-3		OS	-104.85710462959638	35.68097066828326	138699
7684d40098b6a9b3a9e6bd1d356023d145e61298	„datenschutz geht zur schule“ — was hänschen nicht lernt…		Seit 2010 sind engagierte Datenschutzexperten aus dem Berufsverband der Datenschutzbeauftragten Deutschlands (BvD) e.V. mit speziellen Veranstaltungskonzepten bundesweit ehrenamtlich an Schulen aktiv, um Schülern und Schülerinnen ab der fünften Klasse klare und einfache Verhaltensregeln für den sensiblen Umgang mit ihren persönlichen Daten im Netz näher zu bringen. Der vorliegende Beitrag soll die Hintergründe, die zur Entstehung der Initiative führten, beleuchten, die bisherigen Leistungen und Erfolge darstellen und einen Abriss darüber geben, wo Kinder und Jugendliche im Umgang mit den neuen Medien heute stehen. Weiterhin soll er darstellen, wie Sensibilisierungsveranstaltungen ablaufen und welche Vorteile das Mitarbeiten als Datenschutzbeauftragter bei der Initiative bieten kann, er soll die Initiative im Umfeld der anderen Aktiven — die Kinder und Jugendlichen sensibilisieren — positionieren und einen Ausblick auf die Zukunft geben.	entity–relationship model;internet explorer;unified model	Rudi Kramer;Frank Spaeing	2014	Datenschutz und Datensicherheit - DuD	10.1007/s11623-014-0143-4	computer science;internet privacy;performance art	DB	-103.93251047792492	35.91428671926523	139442
62c0edd2056594e088354af44212eebe04a80afa	verteiltes problemlösen in der finanzberatung - ein portfoliotheoretscher ansatz				Bernd Mack;Christof Weinhardt	1995	KI		quantum electrodynamics;ansatz;mathematics	Crypto	-97.10477990053533	33.89782194840082	139746
fe2f216bbd7bc378c7dfcd2a74b87413528800c9	32. dafta datenschutzfachtagung der gdd am 20./21.11.2008 im maternushaus, köln		DuD Datenschutz und Datensicherheit 12 | 2008 833 tung von Regelungen des Arbeitnehmerdatenschutzes zukommen, so Rahe. Prof. Dr. Gregor Thüsing, Direktor des Instituts für Arbeitsrecht und Recht der Sozialen Sicherheit der Universität Bonn, warnte die politisch Verantwortlichen davor, dass Thema Arbeitnehmerdatenschutzgesetz lediglich vor dem Interesse zu sehen, ein „Zeichen“ gegen LIDL & Co. setzen zu wollen. Ein gutes Gesetz sei nicht bereits ein solches, das keinen Schaden anrichte, so Thüsing. Gesetze müssten vielmehr einem materiellen Handlungsbedarf folgen. Für den Bereich der Videoüberwachung etwa habe das Bundesarbeitsgericht klare rechtliche Rahmenbedingungen aufgezeigt. Natürlich müssten diese Leitlinien auf den jeweiligen konkreten Einzelfall heruntergebrochen werden. Daran würde aber auch die Schaffung neuer gesetzlicher Regelungen nichts ändern, da diese stets abstrakt-generell blieben. Handlungsbedarf bestehe dagegen etwa z.B. im Hinblick auf die Datenschutzkontrolle beim Betriebsrat, so Thüsing. Nachdem die Thesen der Referenten zum Teil kontrovers diskutiert worden waren, endete der Vormittag mit einer Plenumsabstimmung. Dabei sprach sich der weit überwiegende Teil der anwesenden Datenschutzbeauftragten und -praktiker gegen ein selbstständiges Gesetz zum Arbeitnehmerdatenschutz aus. Als sinnvoll wurde es vielmehr angesehen, regelungsbedürftige Aspekte des Beschäftigtendatenschutzes im Bundesdatenschutzgesetz als dem „Basisgesetz“ zum Datenschutz bzw. in bestehenden Spezialgesetzen aufzugreifen. Dies könne über ein entsprechendes Artikelgesetz geschehen. Inhaltlicher Regelungsbedarf wurde insbesondere im Hinblick auf den Umgang mit Mitarbeiterdaten im Konzernverbund gesehen. Hier bewegten sich die Unternehmen vielfach in einer rechtlichen Grauzone. Gesetzliche Regelungen zur Videoüberwachung, Kontrolle der E-Mailund Internetnutzung im Unternehmen und dem Umgang mit Gendiagnostikdaten im Arbeitsverhältnis wurden von den Teilnehmern ebenfalls als notwendig angesehen.	game design document;vhf omnidirectional range	Karl Rihaczek	2008	Datenschutz und Datensicherheit - DuD	10.1007/s11623-008-0201-x	computer security;internet privacy;computer science	OS	-103.7610570820814	35.48877577410951	139954
4de6639ede2548b244098f8b921270e619a22e3b	ein vergleich ausgewählter methoden zur analyse von kommunikationsdaten aus der netzbasierten kleingrupenforschung		Zusammenfassung. Die Analyse der Kommunikation in der Kleingruppenforschung wird haufig mit Hilfe von Verfahren durchgefuhrt, die auf der IPA bzw. dem SYMLOG-Verfahren (Bales, 1976; Bales u0026 Cohen, 1982) beruhen. Diese Verfahren fokussieren die Betrachtung der Aktionen und Reaktionen der Kommunikationsteilnehmer in Bezug auf aufgabenorientierte oder sozio-emotionale Auserungen. Eine Anwendung dieser Verfahren auf die Analyse von Kommunikationsdaten zur netzbasierten Wissenskommunikation bestatigt einmal mehr, dass in netzbasierten Settings aufgabenbezogener, aber weniger vertauensvoll und offen kommuniziert wird. Durch das Hinzunehmen weiterer Variablen wie der Betrachtung der Sprecherwechsel selbst, der Anzahl von Redebeitragen oder des non-verbalen Verhaltens werden diese Ergebnisse jedoch in Frage gestellt.		Karin Schweizer	2003	Zeitschrift für Medienpsychologie	10.1026/%2F1617-6383.15.1.34	humanities;media studies;psychology	NLP	-107.52936044835141	33.33662062813219	140314
4db09db864d2389676268861a2d130f91648cea1	optimale betriebsmatrizen		"""Z u s a m m e n f a s s u n g: Bei vielen betriebswirtschaftlichen Problemen des """"Linear Programming"""" sind die Schranken in den Nebenbedingungen haufigen Ver/~nderungen unterwoffen. Die optimalen LSsungen sind dann lineare Funktionen dieser Schranken und k6nnen unter Benutzung der Matrizenschreibweise in iibersiehtlieher Weise ermittelt und dargestellt werden. Grundsatzliche Fragen werden an einem einfachen Beispiel erlautert, anschlieBend wird ein praktisches Problem numerisch gel6st."""	linear programming	Peter Stahlknecht	1959	Unternehmensforschung	10.1007/BF01922377		Crypto	-98.3045021833134	35.34591195704583	140433
9cc731790168eafb2b3bcc7b6315edc492fe4c0e	it-gestütztes training sozio-emotionaler kognition für menschen mit autismus		Das Erkennen und Teilen fremder Emotionen sowie das Ausdrücken eigener Emotionen sind eine wesentliche Grundlage des sozialen Miteinanders. Diese Fähigkeiten sind bei Menschen mit Autismus beeinträchtigt. Erste IT-gestützte Trainingssysteme zur Emotionserkennung konnten bereits eine leicht verbesserte sozio-emotionale Kognition bewirken, jedoch bislang noch keinen breiten Transfer des Gelernten auf das Sozialverhalten im Alltag nachweisen. Der Beitrag stellt anhand der in existierenden Lösungen erkannten Defizite neue Trainingsansätze vor. Diese adressieren v. a. die Spezifika der Wahrnehmung der Zielgruppe durch eine Reduktion von Darstellung und Interaktion auf das Wesentliche, die Wahrung der Motivation der Lernenden durch Einbettung des Trainings in eine spielerische Handlung und durch eine adaptive Steuerung des Schwierigkeitsgrads sowie die Erweiterung auf besondere Zielgruppen wie Kinder. Abschließend wird auf weiterhin offene Handlungsfelder verwiesen.	eine and zwei;internet explorer;vhf omnidirectional range	Dietmar Zoerner;Tobias Moebert;Ulrike Lucke	2017	Informatik-Spektrum	10.1007/s00287-017-1074-x	world wide web;computer science;performance art	Crypto	-106.00351839059016	32.98593464321238	140872
016cf58c04bb965fcf9511d232b53dccdb356291	eine anfragesprache für das retrieval von listen, bäumen und dags in datenbanken	computation tree logic	"""Aber trotz ihrer Bedeutung als Modellierungswerkzeug fanden Listen, B¨ aume und Graphen bisher kaum Verwendung als Datentypen in Datenbanksystemen. Relationale Datenbanksysteme bieten nur Mengen bzw. Relationen zur Modellierung von Entit¨ atsmengen an, sowie einfache atomare Datentypen wie Integer und String f¨ ur die Repr¨ asentation von Entit¨ atseigenschaften. Nichttraditionelle Datentypen wie Listen, B¨ aume und Graphen m¨ ussen mit diesen M¨ oglichkeiten m ¨ uhevoll nachgebildet werden. Auch in objekt-orientierte Datenbanksysteme wurden bis jetzt nur einfache Kollektionstypen wie Tupel, Mengen, Listen oder Multimengen eingebracht (siehe [Cat94]). Dar ¨ uberhinaus sind die Abfragem¨ oglichkeiten solcher Datenbanksysteme ziemlich eingeschr¨ ankt in Bezug auf die oben angef¨ uhrten Kollektionstypen. Insbesondere Pr¨ adikate, die verschiedene Elemente einer Liste betreffen, wie z. B. """"Selektiere aus einer gegebenen Menge von Listen ganzer Zahlen die Listen, die monoton steigend sind"""", werden kaum unterst¨ utzt. F ¨ ur solch eine Anfrage m¨ u?te eine spezielle Methode in einer assoziierten Datenbankprogrammiersprache geschrieben werden. In diesem Artikel werden Konzepte zur Gestaltung einer Anfragesprache f¨ ur Objektbank-systeme skizziert, die Listen, B¨ aume und gerichtete azyklische Graphen als Datentyp bzw. Objekttyp anbieten. Der verwendete Ansatz basiert auf einer Arbeit von J. Richardson [Ric92]. Dort wurde ein auf temporaler Logik basierender Ansatz f¨ ur die Definition von Pr¨ adikaten auf Listen pr¨ asentiert. Solch ein Ansatz erscheint nat¨ urlich, denn """"temporale Formeln (f¨ ur linea-re diskrete Zeit), die ¨ ublicherweise zur Beschreibung von zeitlich geordneten Sequenzen von Zust¨ anden dienen, k¨ onnen genauso gut geordnete Sequenzen von Objekten beschreiben"""", vgl. [Ric92]. Hier wird der in [Ric92] gegebene Ansatz auf B¨ aume und gerichtete azyklische Graphen (DAGs) erweitert. Hierf¨ ur werden Konzepte aus der Verzweigungslogik (branching-time logic) in den schon existierenden Ansatz eingebracht. Insbesondere werden dabei Konzepte aus der sogenannten Computational Tree Logic (CTL* resp. CTL) [CES86] benutzt. Diese erweitern die Konzepte der linearen temporalen Logik, die die Basis von [Ric92] darstellt, um Quantoren auf Pfade. """	eine and zwei	Peter Becker	1995				Vision	-105.99065594690884	32.74228562431209	140944
1a74c2290ba575431883f45a3e67e18a50059c45	prospektive registrierung in der magnetresonanztomografie		Die Bildgebung mithilfe des Magnetresonanztomographen wird heute innerhalb verschiedenster medizinischer Fachrichtungen zur Darstellung pathologischer Veränderungen verwendet und ist als integrierter Bestandteil der Diagnostik nicht mehr wegzudenken. Wird eine pathologische Veränderung diagnostiziert, so ist dies üblicherweise erst der Beginn einer ganzen Reihe von weiteren Untersuchungen. In diesem Zeitraum entsteht bei der Therapie und Operationsplanung oder bei einer Verlaufskontrolle eine Vielzahl von medizinischen Bilddaten.	eine and zwei	Sebastian Baecke	2009				OS	-104.61954097166544	32.693960683055685	141431
d543526852fe96e7ed419dfc974d6e7856df17b0	die erweiterung von lernräumen durch augmented reality am beispiel des social augmented learning		Im Projekt Social Augmented Learning (www.social-augmented-learning.de) wird untersucht, wie mobile Endgeräte, Augmented Reality und die Kommunikation über soziale Netzwerke in der beruflichen Ausund Weiterbildung eingesetzt werden können. Der Projektansatz wird im Rahmen des Berufsfeldes „Medientechnologe Druck“ erprobt, evaluiert und zu einer in neue Branchen und Settings übertragbaren Lösung ausgebaut. Der vorliegende Beitrag gibt einen Einblick in das Design und die Implementation der im Projekt entwickelten Lehrund Lernanwendung, fasst erste gesammelte Erfahrungen zusammen und zeigt das Potenzial digital erweiterter Lernräume auf.	augmented learning;augmented reality;internet explorer	Christian Dominic Fehling;Thomas Hagenhofer	2015			augmented learning;multimedia;augmented reality;computer science	HCI	-107.79730260782217	34.19066448756827	141617
ef00929cf6a7e5e18182f9388ad6652c98910436	flache und semantische verarbeitung von namen biochemischer verbindungen		Termverarbeitung in der Domäne der Biowissenschaften beinhaltet für Information Retrieval, Data Mining, Information Extraction und für die Pflege wissenschaftlicher Datenbanken eine Reihe von Herausforderungen. Wir beschreiben diese Problematik und stellen unsere beiden Lösungsansätze vor. Dabei handelt es sich zum einen um ein normalisiertes Namensmatching und zum anderen um eine semantische Namensverarbeitung.	data mining;eine and zwei;information extraction;information retrieval;institut für dokumentologie und editorik;unified model;vhf omnidirectional range	Henriette Slogsnat;Martin Golebiewski;Meik Bittkowski;Fritz Hamm;Jasmin Saric;Ulrike Wittig;Wolfgang Müller;Uwe Reyle;Isabel Rojas	2009			world wide web;computer science	NLP	-106.68809806963381	35.80794455668504	141655
0cc1b92e7ff10b7eac2c8ce4106207f3e229b4d3	zur struktur und dynamik der kollaborativen plagiatsdokumentation am beispiel des guttenplag wikis: eine vorstudie		Dieser Beitrag thematisiert die zeitliche Entwicklung der wikibasierten Zusammenarbeit am Beispiel des GuttenPlag Wikis. Es geht dabei um die Weiterentwicklung und Exemplifizierung netzwerkanalytischer Methoden im Bereich der Kollaborationsforschung, um die Analyse der Netzwerkstruktur von so genannten Kollaborationsnetzwerken also. Dies geschieht am Beispiel eines Wikis, das in besonderer Weise die Dynamik des World Wide Web zum Ausdruck bringt, in dem – besser als in jedem anderen der bislang bekannten Medien – das Aufkommen, die Entwicklung, die Erstarrung oder das Absterben von Instanzen neuer Dokumenttypen beobachtbar sind	eine and zwei;wiki	Alexander Mehler;Christian Stegbauer;Rüdiger Gleim	2013		10.1007/978-3-531-93336-8_17	performance art;history	Crypto	-105.71002587863376	35.14762224104289	143262
ec1248a8ddab0c1ec8e4569cccb7b61db3868e62	eine infrastruktur für das internet der dienste		Der Dienstleistungssektor ist der größte Arbeitgeber in Deutschland und hat überdurchschnittliche Wachstumsraten. Ein Ziel des Texo-Projekts ist es, Dienstleistungen (ähnlich zu Produkten) über Business Webs handelbar und damit auch exportierbar zu machen. Business Webs sind Dienstleistungsnetzwerke, in denen unabhängige Unternehmen zusammenarbeiten, um gemeinsam Dienstleistungen zu erbringen. Hierfür wird mit Texo eine Infrastruktur entwickelt, um diese Dienstleistungen im Internet bereitzustellen. Die Komponierbarkeit von Dienstleistungen ist dabei eine zentrale Eigenschaft, um aufbauend auf existierenden Dienstleistungen neue, innovative Dienstleistungen zu realisieren. Dabei werden diese Dienstleistungen von unterschiedlichen Anbietern bereitgestellt und integriert. Der Fokus liegt auf webbasierten Dienstleistungen, die zugreifbar über das Internet sind (eServices). Es werden sowohl Business-Dienste (Dienstleistungen) als auch deren Realisierung durch technische Dienste (z. B. Webservices) betrachtet. Der Texo-Marktplatz eröffnet damit kleinen und mittelständischen Dienstleistern neue Märkte und ermöglicht es Texo-Nutzern, ihre Software dynamisch an Veränderungen anzupassen. Auf Basis differenzierter Geschäftsmodelle entstehen individuelle Geschäftsbeziehungen. Der vorliegende Artikel erläutert den konzeptionellen Rahmen dieses Projekts an einem konkreten Beispiel.	eine and zwei;internet;unified model;web service	Christian Janiesch;Rainer Ruggaber;York Sure-Vetter	2008	HMD Praxis der Wirtschaftsinformatik	10.1007/BF03341214	the internet;world wide web;marketing;engineering	OS	-102.8067700701461	35.56881362902579	143412
bf2c9bd1ae8b977bb3943bf6f94cdd94322eba67	zur glättung empirischer häufigkeitsverteilungen		Es werden Verfahren zur Glattung von Histogrammen mit Hilfe von Spline-Funktionen dargestellt.	smoothing;spline (mathematics)	Helmuth Späth	1972	Computing	10.1007/BF02242246	mathematical analysis;mathematics;applied mathematics	Vision	-97.00111880159014	35.456722805876865	143555
4daa71ba414152a56b3cad2e292cab60ec65da46	approximability of optimization problems through adiabatic quantum computation	quantum information;quantum algorithms;monadic second order logic;adiabatic quantum computing;treewidth;computer science;combinatorial optimization;quantum computing	More related with approximability of optimization problems through adiabatic quantum computation synthesis lectures on quantum computing : Kelley Blue Book Vs Edmunds Manuals Lagna Lord In 3rd House Manuals Kelley Blue Book Boat Motor Values Manuals Kelly Blue Book Nissan Pathfinder Manuals Land Cruiser For User Guide Manuals Land Cruiser Mileage Manuals Kirsten Directory Manuals Kia Carens Manuals Manuals Manuals Kelley Blue Book 2005 Toyota Prius Manuals Kelley Blue Book User Manuals Book Cars User Guide Manuals Kelley Blue Book Value Calculator Manuals King Ranch Trucks For User Guide Manuals Kristen Archives Mf Manuals Kelly Blue Book Toyota Corolla Manuals Kelly Blue Book Rv Prices Manuals King Pin Extension For Fifth Wheel Manuals Kia Online Repair Manuals Manuals Kia Soul Maintenance Schedule Manuals Kia Rio 2008 Manuals Kelly Blue Book Trucks Manuals Kenwood Car Stereo Wiring Manuals Kicker L7 Wiring Diagram 1 Ohm Manuals Kelley Blue Book User Manuals Book Pickup Trucks Manuals Kenwood Dnx8120 Screen Manuals Land Cruiser Manualss Free Manuals Kia Rough Idle Manuals Kellybluebook User Manuals Book Trucks Manuals Kelley Blue Book 2012 Ford Fusion Manuals Lancer Ralliart Manuals Kelley Blue Book Toyota Prius Manuals Land Cruiser Repair Manuals Free Manuals Kenwood Electronics Ltd Manuals Kia Spectra Warning Lights Manuals Kia Cars Problems Manuals Kelly Blue Book Value Truck Manuals Kelly Blue Rv Manuals Kia Brake Repair Manuals Kelly Blue Book Auto Trader Manuals Kit Cars Kitcars Manuals Kelley Blue Book Rv Value Manuals Knitted Lace Tablecloth Patterns Manuals Kelley Blue Book 2005 Ford Focus Manuals Kelley Blue Book Ford Fusion 2010 Manuals Land Cruiser Fj60 Manuals Kicker Speakers Prices Manuals Kelley Blue Book Jet Skis Manuals Kristen Stewart Pregnant Manuals Keyless Motorcycle Ignition Manuals Kicker Cvr 10 Wiring Diagram Manuals Kelley Blue Book Value For Rv Manuals Kia Rio Shop Manuals Manuals Kelly Blue Book 2005 Honda Civic Manuals Kenwood Car Audio Wiring Diagram Manuals Kone Monospace Dwg Manuals Kia Car Stereo Manuals Kelley Blue Book Private Party Value Manuals Kicker Games Manuals Kelly Blue Book Ford Escape Manuals Kicker Wiring Diagram Sub Manuals Kenn Nesbitt Biography Manuals Land Cruiser Jeep Manuals Kristen Stewart Manuals Kelley Blue Book Boats Online Manuals Kelley Blue Book Motorcycles Manuals Kicker Fussball Bundesliga Startseite Html Manuals Kenmore Washer Schematic Manuals Kia Sportage Remote Manuals Kenwood Car Stereo Package Manuals Manuals Kelly Rv Blue Book Value Manuals Kia Service Bulletins Manuals Kgc 9044 Wiring Diagram Manuals Kellybluebookcom Rv Manuals Kia Rio Air Filter Manuals Labor Cost On A Timing Change On A Honda Civic Manuals Kenwood Mp3 Manuals	adiabatic quantum computation;approximation algorithm;autonomous car;blue book (cd standard);html;kelly criterion;mp3;mathematical optimization;quantum computing;rca spectra 70;sync;schematic;trader media east;uvo;winsock;wiring diagram	William Cruz-Santos;Guillermo Morales-Luna	2014		10.2200/S00596ED1V01Y201409QMC009	mathematical optimization;combinatorics;discrete mathematics;quantum information;combinatorial optimization;mathematics;treewidth;quantum computer;quantum algorithm;physics;quantum mechanics;adiabatic quantum computation	HCI	-100.98383658374426	37.52623028933663	143613
3e0f03997872be8d81b219ceb38399471ba6cf67	prozeßschritte zur testfallauswahl bei der testfallgenerierung aus uml-modellen		Mit Hilfe des vorgestellten Ansatzes soll eine Testfallauswahl im Rahmen einer automatisierten und modellbasierten Testfallgenerierung ermöglicht werden. Dazu wird das UML-Systemmodell entsprechend erweitert und ein mögliches Verfahren zur weiteren Informationsverarbeitung vorgestellt. Diese Testfallauswahl ist ein Teilprozeß eines Verfahrens zur Testfallgenerierung, welches aus UML-Modellen passende Testfälle in der gewählten Zielsprache mit Unterstützung einer Tool-Chain ableitet. In diesem Papier wird beschrieben, wie auf Basis von UML-Systemmodellen eine risikobasierte Testfallauswahl ermöglicht wird. 1 Ausgangssituation und Motivation Die gezielte Auswahl von Testfällen spielt insbesondere bei Regressionstests speziell bei einer automatisierten maschinellen Generierung einer Vielzahl von Testfällen eine große Rolle. Dabei sollte eine Auswahl anhand von verschiedensten Kriterien geeignete Testfälle identifizieren bzw. priorisieren und gleichzeitig die Fehleraufdeckungsrate im Vergleich zur Durchführung aller Testfälle möglichst konstant halten. Da man bei den hier betrachteten Black-Box-Tests keinen Einblick in den Aufbau der Programme hat, ist man bei der Auswahl auf bestimmte ergänzende Angaben angewiesen. Dabei soll die Testfallauswahl als Teilablauf in einen Gesamtprozeß einer Testfallgenerierung mit Hilfe von UML-Modellen eingebettet sein und diesen entsprechend ergänzen. Als problematisch kristallisiert sich hier die Fragestellung heraus, wie und vor allem welche Informationen, die die Datenbasis in Form von Kennzahlen für eine, mögliche risikobasierte (e.g. Risiko = Schadensausmaß x Eintrittswahrscheinlichkeit), Auswahl am Ende des Prozesses darstellen, in das UML-Modell bzw. in die einzelnen Diagramme eingebracht werden können. Weiters ist zu klären, wie die Informationen geeignet interpretiert werden können und der Zugriff auf diese in dem Generierungsprozeß erfolgt. Schließlich ist noch der Zeitpunkt der Auswahl zu diskutieren, bevor die durchzuführenden Testfälle automatisch mit Hilfe eines risikobasierten Verfahrens identifiziert werden. [vgl. beispielsweise Am05, CPS02, Ot99, Re04]. Hier stellen wir einen Ansatz zur Lösung der oben besprochenen Fragestellungen vor. Dabei stützen sich	eine and zwei;internet explorer;unified modeling language;v-model;vhf omnidirectional range	Matthias Hudler;Michael Krüger	2007			art;performance art	OS	-103.58718328661202	32.474387843972714	143631
e28dad889935f8e00790b0b3fc341a29a379e43c	zur discourse awareness mit dem diskursmeter		Im Gegensatz zu Präsenzdiskursen fehlt den Teilnehmern eines stark frequentierten E-Diskurses der Überblick über Verlauf und Stand der Diskussion (discourse awareness). Das Diskursmeter versucht, diese Schwäche zu beseitigen. Es zeichnet auf, aggregiert und visualisiert Zustände, Ereignisse und Tendenzen eines laufenden E-Diskurses. 1 Motivation Mit der Modernisierung der Staatsverwaltung, wie es die E-Government-Initiative BundOnline2005 der Bundesregierung signalisiert, rechnen wir damit, dass neben dem administrativen Charakter des E-Government auch die partizipativen Elemente der EDemocracy an Bedeutung gewinnen werden. Insbesondere das Instrument der Bürgerbeteiligungen wird, so unsere Vermutung, verstärkt über E-Diskurse abgehalten werden. Mit der Akzeptanz solcher E-Diskurse werden diese schnell eine Komplexität erreichen, die von den Teilnehmern nicht mehr zu bewältigen ist. Die Komplexität ergibt sich aus der großen Anzahl der Teilnehmer und Beiträgen und der damit verbundenen Meinungsvielfalt, die es für alle zu überschauen gilt. Den bisherigen E-Diskursen fehlt ein Instrumentarium zur Unterstützung dieses Diskursverständnisses (discourse awareness), um die gelebte Partizipation transparenter zu gestalten, Beiträge einzuordnen und zu gewichten. Hier setzt das vom Team Wissen und Kommunikation der AIS entwickelte Diskursmeter zur Erlangung von discourse awareness an. 2 Discourse Awareness [DB92] definiert awareness aus dem Bereich des kooperativen Arbeitens als „an understanding of the activities of others, which provides a context for your own activity“. 1 Discourse awareness wird im Folgenden kontextabhängig sowohl als Diskursverständnis als auch im Sinne eines Konzepts zur Erlangung von Diskursverständnis verwendet.	die (integrated circuit);e-government;eine and zwei;internet explorer;unified model	Viviane Wolff	2003			sociology;performance art	NLP	-107.45784608387942	33.60366970467055	143837
723f744455914bf1ead6ad267976a1500b7dee4a	an analysis of annotated corpora for emotion classification in text		Several datasets have been annotated and published for classification of emotions. They differ in several ways: (1) the use of different annotation schemata (e. g., discrete label sets, including joy, anger, fear, or sadness or continuous values including valence, or arousal), (2) the domain, and, (3) the file formats. This leads to several research gaps: supervised models often only use a limited set of available resources. Additionally, no previous work has compared emotion corpora in a systematic manner. We aim at contributing to this situation with a survey of the datasets, and aggregate them in a common file format with a common annotation schema. Based on this aggregation, we perform the first cross-corpus classification experiments in the spirit of future research enabled by this paper, in order to gain insight and a better understanding of differences of models inferred from the data. This work also simplifies the choice of the most appropriate resources for developing a model for a novel domain. One result from our analysis is that a subset of corpora is better classified with models trained on a different corpus. For none of the corpora, training on all data altogether is better than using a subselection of the resources. Our unified corpus is available at http://www.ims.uni-stuttgart.de/data/unifyemotion. Title and Abstract in German Eine Analyse von annotierten Korpora zur Emotionsklassifizierung in Text Es existieren bereits verschiedene Textkorpora, welche zur Erstellung von Modellen für die automatische Emotionsklassifikation erstellt wurden. Sie unterscheiden sich (1) in den unterschiedlichen Annotationsschemata (z.B. diskrete Klassen wie Freude, Wut, Angst, Trauer oder kontinuierliche Werte wie Valenz und Aktivierung), (2) in der Domäne, und, auf einer technischen Ebene, (3) in den Dateiformaten. Dies führt dazu, dass überwacht erstellte Modelle typischerweise nur einen Teil der verfügbaren Ressourcen nutzen sowie kein systematischer Vergleich der Korpora existiert. Hier setzt unsere Arbeit mit einem Überblick der verfügbaren Datensätze an, welche wir in ein gemeinsames Format mit einem einheitlichen Annotationsschema konvertieren. Darauf aufbauend führen wir erste Experimente durch, in dem wir auf Teilmengen der Korpora trainieren und auf anderen testen. Dies steht im Sinne zukünftiger, durch unsere Arbeit ermöglichten Analysen, die Unterschiede zwischen den Annotationen besser zu verstehen. Des Weiteren vereinfacht dies die Wahl einer angemessenen Ressource für die Erstellung von Modellen für eine neue Domäne. Wir zeigen unter anderem, dass die Vorhersagen für einige Korpora besser funktioniert, wenn ein Modell auf einer anderen Ressource trainiert wird. Weiterhin ist für kein Korpus die Vorhersage am besten, wenn alle Daten vereint werden. Unser aggregiertes Korpus ist verfügbar unter http://www.ims.uni-stuttgart.de/data/unifyemotion. This work is licenced under a Creative Commons Attribution 4.0 International Licence. Licence details: http:// creativecommons.org/licenses/by/4.0/	aggregate data;benchmark (computing);die (integrated circuit);domain adaptation;downstream (software development);eine and zwei;emotion markup language;emotion recognition;experiment;internet explorer;java annotation;media resource locator;preprocessor;sie (file format);sadness;statistical classification;text corpus;triple des;v-model	Laura Ana Maria Bostan;Roman Klinger	2018			computer science;artificial intelligence;natural language processing;pattern recognition;emotion classification	NLP	-107.26864854159966	35.727686779245815	144978
40ae11f29a74f319c468985b2c6d271191aa7963	mediengewalt, lebenswelt und persönlichkeit - eine problemgruppenanalyse bei jugendlichen	gewalt;emotions;social context;media violence;peacefulness;lebenswelt;mediengewalt;emotionen;friedfertigkeit;aggression;violence;aggressivitat	Zusammenfassung. Eine Querschnittsstudie untersucht zentrale Einflusse auf Aggressivitat, Gewaltbereitschaft/Friedfertigkeit in der Problemgruppe der Schuler/innen der Klassen 5 bis 10 in Hauptschulen. Erfasst wurden Variablen aus den Bereichen Mediengewaltkonsum, sozialer Kontext, Personlichkeit sowie emotionale Reaktionen bei realer und fiktionaler Gewalt. Als zusatzlicher Aspekt wurde der Einfluss eines niedrigen Familieneinkommens (Armut) berucksichtigt. Die Analyse der Daten basierte auf dem General Aggression Model von Anderson und Bushman. Einflusse, die Aggression erhohen, konnten in 7 Hauptfaktoren zusammengefasst werden: (1) Haufigkeit des Mediengewaltkonsums, (2) aggressive Emotionen beim Mediengewaltkonsum, (3) gewaltorientierte Uberzeugungen, (4) Hass, Wut und Rache bei Gruppengewalt, (5) hoher TV-Konsum der Eltern, (6) Hass, Wut und Rache bei elterlicher Gewalt, (7) materialistische Wertorientierungen. Extremgruppenvergleiche und Pfadanalysen bestatigten die Bedeutung des Mediengewaltkonsums...	eine and zwei	Werner H. Hopf	2004	Zeitschrift für Medienpsychologie	10.1026/1617-6383.16.3.99	humanities;psychology	ML	-107.90586553371753	33.41886297842646	145345
c91535622f478ef50499e9e5d4d9830ac6557f65	softwarebasierte anlagenabsicherung in chemieanlagen - erfahrungen bei der erstellung von ssps-spplikationssoftware	softwarebasierte anlagenabsicherung;erfahrungen bei der erstellung;von ssps-spplikationssoftware	Es gibt viele Wege, die Risiken eines kritischen Prozesses zu minimieren. Der beste Weg ist sicherlich einen in sich sicheren Prozess zu entwerfen. Wo dies nicht möglich ist, übernehmen PLT-Schutzeinrichtungen die Aufgabe dieses Risiko zu minimieren. In den letzten 10 Jahren entwickelten sich sicherheitsgerichtete speicherprogrammierbare Steuerungen (SSPS) zunehmend zum Mittel der Wahl bei der Absicherung von kritischen Prozessen in der chemischen Industrie. Das Spektrum von softwareintensiven PLTSchutzsystemen reicht von einfachen Systemen, welche lediglich bei einer großen Anzahl von E/A-Punkten die traditionellen VPS-Systeme aus ökonomischen Gründen substituieren, über Systeme zur Absicherung von Batch-Anlagen bis hin zu komplexen Schutzsystemen. Während triviale Standard-Sicherheits-Schaltungen wie „Druck-zu-Hoch–Überwachung“ einfach zu beherrschen sind, erfordern komplexe PLT-Schutzsysteme weitergehende Entwurfs-, Entwicklungs-, Dokumentationssowie Verifizierungsund Validierungsmethoden. In diesem Beitrag wird insbesondere auf Erfahrungen in der Spezifikationsphase komplexer sicherheitsrelevanter Applikationssoftware im Umfeld der Prozessindustrie eingegangen. 1. Software in SSPS-Systemen Die Software von SSPS-Systemen setzt sich aus einer Vielzahl von Programmen mit sicherheitsrelevantem Aspekt zusammen: • dem Betriebssystem, • der Firmware, • der Kommunikationssoftware, • dem Benutzerinterface und diverse Hilfsprogramme, • der Software-Engineeringtools, • und nicht zuletzt die Applikationssoftware, die anlagenspezifischen Funktionen enthaltende, Software. Während a priori bis auf die Applikationssoftware alle anderen Programme im Rahmen der Systemzertifizierung (Nachweis der Eignung bzw. Zulassung für Sicherheitsaufgaben) als „sicher“ gelten, wird die Qualität und Zuverlässigkeit des Applikationsprogramms scheinbar maßgeblich von der „Qualität“ des Programmierers und seinem Umfeldes bestimmt. Der Grundstein für ein qualitativ hochwertiges und damit sicheres Applikationsprogramm wird jedoch schon in der Spezifikationsphase gelegt.	firmware;gesellschaft für informatik;internet explorer;racket;virtual private server	Dirk Hablawetz	2002				OS	-104.73397352892674	34.99339932899755	145567
2917977beb1c6fac99be0a9eb645966e3761b452	neue institutionen für den daten- und persönlichkeitsschutz im internet: „cyber-courts“ für die blogosphere		Die Digitalisierung der elektronischen Kommunikation und die Herausbildung von Netzwerken jenseits der Individualkommunikation und diesseits der Massenmedien verlangen die Entwicklung neuer rechtlicher Institutionen, die auf deren hybriden Charakter eingestellt sind. Netzwerke erzeugen neue Risiken und stellen eine Herausforderung für das öffentliche Sicherheitsrecht dar. Sie ermöglichen aber auch die Herausbildung von Intermediären, die insbesondere dem Datenschutz dienen können, und neue Formen der Streitschlichtung. Dies gilt auch für „soziale Medien“ wie Facebook.	blogosphere;eine and zwei;internet explorer;sie (file format)	Karl Heinz Ladeur	2012	Datenschutz und Datensicherheit - DuD	10.1007/s11623-012-0237-9	the internet;internet privacy;computer science;blogosphere	OS	-104.20113713805476	37.07465375777592	145671
5ede196b7fc31c4ee53b953cfcbbea21085d49c5	tiefe charakterisierung		Zusammenfassung Mehrstufige Beschreibungshierarchien kommen in zunehmendem Maße in den verschiedensten Gebieten zum Einsatz. Ob in der Definition von Modellierungssprachenstandards, der Prozeßmodellierung oder in der Beschreibung von (Domänen-)Referenzmodellen mit dynamischer Typebene, immer werden Beschreibungshierarchien mit mindestens drei Ebenen genutzt. Die Beziehung der Beschreibungsebenen untereinander beruht typischerweise auf der Instanziierung, welche aber traditionell nur für zwei Ebenen ausgelegt ist. Dieser Beitrag thematisiert das Bedürfnis, Eigenschaften dennoch über mehr als eine Ebenengrenze hinweg festzulegen, und schlägt, nach der Erläuterung einiger konventioneller Lösungsmöglichkeiten, die Anwendung von “tiefer Instanziierung” vor, die als konservative Erweiterung der zweistufigen Instanziierung eine natürliche und prägnante Charakterisierung von Modellelementeigenschaften über mehrere Ebenengrenzen hinweg erlaubt.	eine and zwei;vhf omnidirectional range	Thomas Kühne;Friedrich Steimann	2004				OS	-104.61620530371903	32.46469142566141	146208
da3dd5aa465f97fe2a8289eced11209ce35cbcd7	generische einschränkung der modellierungsfreiheit in fachkonzeptuellen modellen		Die zunehmende Verwendung von Informationsmodellen über technische Softwareaspekte hinaus, die ansteigende Anzahl an Modellerstellern sowie die Forderung nach Modellvergleichbarkeit bzw. Modellbewertbarkeit machen eine an Konventionen orientierte konstruktive Einschränkung der Freiheitsgrade bei der fachkonzeptuellen Modellierung notwendig. In diesem Artikel wird eine generische Methode vorgestellt, welche durch die Einführung von „Beschreibungsrahmen“ (Description Kits) sowohl eine Einschränkung der Modellierungsfreiheit in Bezug auf natürlichsprachliche Aspekte in fachkonzeptuellen Modellen erlaubt, als auch eine restriktive Benutzung bestehender Modellierungssprachen ermöglicht. Als Anwendungsfall wird die Konfiguration service-orientierter Architekturen diskutiert und die Nützlichkeit des Ansatzes in einer Pilotstudie illustriert, durchgeführt im Projekt MIRO an der Universität Münster.	eine and zwei	Martin Juhrisch;Gunnar Dietz;Werner Esswein	2008				NLP	-104.29638455736273	32.655925433682	146252
9ced9e45745e5151433b2fd51bb102997eda40db	transputereinsatz in der kardiologischen grundlagenforschung: untersuchungen an isolierten herzmuskelzellen	isolierten herzmuskelzellen;der kardiologischen	Wir stellen ein Messystem vor, mit welchem das Kontraktionsverhalten isolierter Herzmuskelzellen analysiert wird. Dabei ubernimmt ein Parallelrechnersystem die Steuerung der Versuchsaparatur sowie die Aufzeichnung und Auswertung von visuellen Daten, die mit einer an ein Mikroskop gekoppelten Standard-CCD-Kamera mit Restlichtverstarkung aufgenommen werden. Auf diese Weise kann der zeitliche Verlauf wichtiger Kenngrosen (intrazellulare Ca2+ -Konzentration und mechanische Verkurzung) untersucht werden. Zusatzliche Daten zum Energieumsatz der Zellen werden uber einen IEC-Bus aufgenommen. Anwendungen ergeben sich im Bereich der kardiologisch-pharmakologischen Forschung.		D. Kulsch;S. Pöpping;A. Ladwig;H. Rose;H. Kammermeier	1992				NLP	-104.48470544765573	32.76674019640858	146837
002cb42c25740ad8564a8a2d94065e2bb1d45d79	das automobil als anwendungsgebiet der informatik - ein auto ohne informatik, geht das?		Informationstechnologien sind treibende Kräfte von Innovation in vielen Branchen – auch im Automobil. Software im Fahrzeug ist keine Vision – in Premium-Fahrzeugen der neuesten Generation ist auf Basis der Elektronik bereits ein erheblicher Softwareanteil vorzufinden. Die Informatik mit ihren Theorien, Konzepten und Methoden ist die Ausgangsdisziplin, um das Fahrzeug auch als ITSystem zu begreifen. Die Informatik wird ihr Potenzial in künftigen Fahrzeuggenerationen entfalten.	gesellschaft für informatik;unified model	Alexandre Saad	2003			computer science;performance art	AI	-103.65953886136278	34.31417216351101	147020
09edb9a7e520a52d08a6f1c726c6a82bf9b76d0d	beiträge zur integrationsproblematik im kontext von electronic business und elektronischen marktplätzen	business to business;electronic business	Zusammenfassung: Relevanz und Komplexitat der Aufgabenstellung zwischenbetrieblicher Integration haben sich mit dem Electronic Business weiter erhoht. Dies gilt insbesondere fur eine spezifische Erscheinungsform des Electronic Business, die Elektronischen Marktplatze. Speziell im Business-to-Business-Bereich (B2B) haben diese internetbasierten Handelsplattformen, auf denen Verkaufer und Kaufer in virtueller Weise aufeinander treffen, in den letzten Jahren stark an Bedeutung gewonnen und fur die Zukunft wird weiteres Wachstum prognostiziert, trotz derzeit beobachtbarer Konsolidierungsbewegung. Der Beitrag beschreibt Merkmale und Vorgehensweisen der Integration im Electronic Business, insbesondere fur Elektronische Marktplatze. Es werden ein Referenzmodellierungsansatz fur Marktplatze sowie Kriterien der Leistungsfahigkeit fur Elektronische Marktplatze betrachtet, um darauf aufbauend eine Zielformulierung fur Integrationslosungen abzuleiten. Im Rahmen des Betrags wird ein Ansatz eines Referenzmodells fur Integrationslosungen vorgestellt.	electronic business	Peter Voigtmann;Thomas Zeller	2003		10.1007/978-3-642-57444-3_13	computer science	DB	-102.05354293008676	34.322590774058746	147200
9d78917ec8d33d958bb98c9d99d9dc451a9cb85e	datenschutzrecht - basis und bremse des cloud computing	340 recht;330 wirtschaft;ddc 340;ddc 330;ciencias juridicas;dcho procesal y penal;dcho civil y mercantil	Die Nutzung von Cloud-Technologien birgt aus unternehmerischer Sicht erhebliche Kosten-einsparungs- und Effizienzsteigerungs- sowie aus volkswirtschaftlicher Sicht nicht unbedeutende Wachstumspotentiale. Dennoch schrecken gegenwartig noch viele Unternehmen vor einem Ruckgriff auf externe Cloud-Dienstleister zuruck. Zuruckzufuhren ist dies insbesondere auf Unsicherheiten mit Blick auf die datenschutzrechtliche Konformitat des Einsatzes derartiger Technologien. In der Tat stellen sich bei der (grenzuberschreitenden) Nutzung externer Cloud-Dienstleister eine Vielzahl von datenschutzrechtlichen Fragen, die weder legislativ, noch in der Verwaltungspraxis oder gar hochstrichterlich in ausreichendem Umfang geklart sind. Im vorliegenden Beitrag beleuchten die Autoren diese datenschutzrechtlichen Hemmnisse und bieten Losungsvorschlage, insbesondere mit Blick auf die geplante EU-Datenschutz-Grundverordnung.	cloud computing	Jürgen Kühling;Michael Biendl	2014	Computer und Recht	10.9785/ovs.cr.2014.0304	history;performance art	Theory	-102.12546198753975	35.452261573159696	147277
0eb8775d152aebdff77362c6a713a59c2c51ccdd	maschinelle lernmethoden zur analyse von tiling-array-daten		Im Rahmen meiner Dissertation [Zel10] entwickelte ich auf Maschinellen Lerntechniken basierende, bioinformatische Methoden, um zur Beantwortung zentraler molekularbiologischer Fragestellungen beizutragen: • In welchen Bereichen des Genoms unterscheiden sich einzelne Individuen derselben Spezies? • Welche Bereiche des Genoms beinhalten Gene, und in welchen Zellen, Organen und Entwicklungsstadien werden diese in mRNA-Moleküle transkribiert? Diese beiden Probleme weisen einige – vielleicht unerwartete – Gemeinsamkeiten auf: Erstens lassen sich beide als Segmentierungsprobleme formalisieren. Zweitens hat die Molekularbiologie eine sehr flexible Hochdurchsatz-Experimentiertechnik entwickelt, sogenannte Tiling-Arrays (bzw. deren Weiterentwicklung zu Resequencing-Arrays), die es ermöglich, diese beiden (und weitere) Fragestellungen experimentell zu bearbeiten. Im wesentlichen liefert diese Technik eine Sequenz von Messwerten, die in einem regelmäßigen Raster das gesamte Genom abdecken. Das Segmentierungsproblem bei der Analyse dieser Sequenzdaten besteht nun darin, die Teilbereiche zu erkennen, welche dem gesuchten biologischen Phänomen entsprechen, nämlich einerseits variable Genomregionen (im Unterschied zu solchen, wo sich Individuen nicht unterscheiden) und andererseits Segmente, aus denen mRNA-Moleküle generiert werden. Zur Lösung dieser Probleme entwickelte ich Segmentierungsmethoden, die auf der sogenannten Hidden Markov Support Vector Machine (HMSVM) basieren und sich durch folgende Eigenschaften auszeichnen: • Genauigkeit der Vorhersagen war von entscheidender Bedeutung, da meine Resultate die Grundlage für weitergehende experimentelle Forschung bildeten. Wo vergleichbare Methoden verfügbar waren, konnte ich die stark verbesserte Genauigkeit der neu entwickelten Lernmethoden belegen. • Ich untersuchte empirisch, dass die hohe Genauigkeit teils einem ausgefeilten Modellierungsansatz und teils einem neuen diskriminativen Lernalgorithmus mit großer Robustheit gegen Rauschen zugeschrieben werden kann. Angesichts des starken Rauschens in Tiling-Array-Daten erwies sich Robustheit als Schlüsseleigenschaft. • Ein weiterer Schwerpunkt lag auf der Effizienz der Methoden. Analysen ganzer Genome erfordern schnelle Vorhersagealgorithmen, und angesichts langer Trainingssequenzen sind Lernmethoden im Vorteil, die bereits anhand weniger Trainingsbeispiele in der Lage sind, genaue Vorhersagen zu machen. • Die Verwandschaft zu Hidden Markov Modellen (HMMs) mit einem breiten Anwendungsspektrum in der Bioinformatik eröffnet für die Anwendung der HMSVM viele Möglichkeiten über die hier beschriebenen hinaus. 1 Maschinelles Lernen in den Lebenswissenschaften Hochdurchsatzverfahren in der Molekularbiologie, wie z.B. die DNA-Sequenzierung, haben in den letzten Jahren entscheidend unsere Sicht auf uns selbst und die Funktionsweise unseres Körpers verändert [LLB+01]. Die automatisierte Datengenerierung im großen Stil, die heute fast alle molekularbiolgischen Forschungsfelder prägt, sorgt für einen stetig wachsenden Bedarf an ”intelligenten“ Analysetechniken, um aus riesigen, oft komplexen und heterogenen Datenmengen biologische Einsichten zu gewinnen. Die Entwicklung solcher bioinformatischer Methoden, die Konzepte aus den Bereichen des Maschinellen Lernens und des verwandten Data Minings entlehnen und dabei besonders dem biologischen Kontext Rechnung tragen, bildet ein faszinierendes, interdisziplinäres Forschungsgebiet. Maschinelle Lernverfahren ”lernen“ eine bestimmte Eigenschaft von Beispieldaten (d.h. sie erkennen verallgemeinerbare Gesetzmäßigkeiten), um diese dann auf neuen, unbekannten Daten vorherzusagen. Handelt es sich um die Vorhersage einer Klassenzugehörigkeit, spricht man von Klassifikation. Wenn jedoch jedes Lernbeispiel selbst aus einer Sequenz von Messpunkten (oder allgemein aus einer Merkmalssequenz) besteht, ist man oft an einer Segmentierung dieser Sequenz in bestimmte Teilbereiche interessiert. In der Bioinformatik sind wir häufig mit Segmentierungsproblemen konfrontiert. Genvorhersage beispielsweise, d.h. die Segmentierung des Genoms in Gene, in welchen sich wiederum exonische Bereiche mit intronischen Bereichen abwechseln, sowie in umgebende intergenische Bereiche, ist ein bioinformatisches Kernproblem (Abb. 1) [SZZ+09]. Dieses und andere Segmentierungsprobleme lassen sich darauf reduzieren, jeder Position in einer langen Sequenz ein atomares Label zuzuweisen (z.B. exonisch, intronisch oder intergenisch). Oft existieren hier Abhängigkeiten (z.B. sind Introns im Genom stets von Exons umgeben), die es nicht erlauben, einfach Klassifikationsverfahren positionsweise unabhängig anzuwenden. Derartige Labelabhängigkeiten lassen sich jedoch mithilfe eines Zustandsübergangsmodells formal beschreiben (Abb. 1).	bibliothèque de l'école des chartes;blitzkrieg;dna computing;eine and zwei;eddie (text editor);hidden markov model;i/o controller hub;internet explorer;markov chain;sie (file format);support vector machine;tiling array;tiling window manager;unified model;zur farbenlehre	Georg Zeller	2010			lag;performance art;art		-106.7231983235894	32.68178101361405	147314
9a9e4a4292ef27a34972a75edc172ce529e3e13a	zulässigkeit der spam-filterung im unternehmen		Spam-E-Mails sind nicht nur lästig, sie kosten auch Arbeitszeit. Die Bekämpfung von Spam in Wirtschaft und Verwaltung ist damit ein Gebot der Wirtschaftlichkeit. Das Filtern von Nachrichten den Zugang von Nachrichten beeinträchtigt, sind vor dem Einsatz von Spam-Filtern eine Reihe von Rechtsfragen zu klären, denen die Autoren in ihrem Beitrag nachgehen.	eine and zwei;sie (file format);spamming;vhf omnidirectional range	Thomas Sassenberg;Katharina-Patricia Lammer	2008	Datenschutz und Datensicherheit - DuD	10.1007/s11623-008-0109-5		OS	-104.02272678440242	36.281771568789615	147460
d228b6d85cd23952fd19777b4201b70333099ade	informatik lehren - zeitgemäße ansätze zur nachhaltigen qualifikation aller schülerinnen		Ziel des Beitrags ist die Darstellung von Ergebnissen grundlegender Überlegungen zur Konstruktion und Umsetzung von Informatikcurricula. Die Gestaltungsmöglichkeiten werden auf dem Hintergrund durchgeführter und geplanter Studien untersucht und einer ersten Bewertung unterzogen.	triple des	Ludger Humbert	2001				NLP	-104.65653898827058	32.484109354999134	147524
a920cd6fc7af55cf257e1a305a4c88b9f297049e	informationstechnologien und transparenz von wertschöpfungsketten des agribusiness: eine untersuchung am beispiel der milch- und fleischwirtschaft		Der Transparenz von Wertschöpfungsketten des Agribusiness und dem dazu erforderlichen Ausbau der Informationsinfrastrukturen wird eine zunehmend größere Bedeutung beigemessen. Das Ziel dieses Beitrags ist es vor diesem Hintergrund, den Beitrag leistungsfähiger Informationstechnologien (IT) zum Aufbau tragfähiger Informationsnetzwerke aus einer theoretischen Perspektive zu beschreiben und das Potential von stufenübergreifenden Informationsinfrastrukturen zur Verbesserung der Transparenz in den Wertschöpfungsketten des Agribusiness anhand empirischer Daten aus der Milchund Fleischwirtschaft aufzuzeigen. 1 Theorie und Methode Transparenz ist definiert als das Ausmaß, in dem alle Beteiligten eines Wertschöpfungsnetzwerks ohne Verlust, Störung oder Verzögerung Zugang zu den Informationen haben, die sie wünschen [Ho03]. Transparenz ist nicht nur durch einen im Zeitablauf dynamischen Charakter gekennzeichnet, sondern variiert in seiner Ausprägung auch zwischen einzelnen Wertschöpfungsstufen und verschiedenen Wertschöpfungsketten. Die Erfassung und Analyse unterschiedlicher Transparenzgrade sieht sich mit dem Problem konfrontiert, dass Transparenz ein latentes Konstrukt ist, das keiner direkten Messung zugänglich ist, sondern die Definition von beobachtbaren Indikatoren erfordert, die seine indirekte Messung ermöglichen. Bei der Operationalisierung gilt es, dem Facettenreichtum des Transparenzkonstrukts Rechnung zu tragen. Dabei zeigt sich, dass Transparenz nur unter Berücksichtigung sowohl organisatorisch-technischer Einflussfaktoren (u.a. Struktur der Wertschöpfungskette einschließlich der eingesetzten IT) als auch sozial-relationaler Determinanten (z.B. Bereitschaft der Transaktionspartner zu Kooperation und Kommunikation sowie Zufriedenheit, Vertrauen und Commitment in der Transaktionsbeziehung) angemessen erfasst werden kann [DFT08; Fr08]. Abbildung 1 präsentiert ein theoretisches Modell zur Messung der Transparenz von Wertschöpfungsketten des Agribusiness, das die formative Spezifizierung latenter Konstrukte über ihre Bestimmungsfaktoren und die reflektive Spezifizierung über ihre Wirkungen – in diesem Fall auf die Leistungsfähigkeit der Wertschöpfungskette – vereint. Darüber hinaus wird das Konzept um die Perspektive der erlebten, subjektiv wahrge-	aldert van der ziel;eine and zwei;institut für dokumentologie und editorik;sie (file format);unified model;v-model;vhf omnidirectional range	Mechthild Frentrup;Ludwig Theuvsen	2009			sociology;performance art	OS	-102.93869410246583	33.07136856290092	147681
7ce2d0b2d384f73a1f547f970d9cd76a5ef5b709	datenvisualisierung und data mining	incollection;inproceedings	Die rasante technologische Entwicklung der letzten zwei Jahrzehnte ermöglicht heute die persistente Speicherung riesiger Datenmengen durch den Computer. Forscher an der Universität Berkeley haben berechnet, dass jedes Jahr ca. 1 Exabyte (= 1 Million Terabyte) Daten generiert werden ein großer Teil davon in digitaler Form. Das bedeutet aber, dass in den nächsten 3 Jahren mehr Daten generiert werden als in der gesamten menschlichen Entwicklung zuvor. Die Daten werden oft automatisch mit Hilfe von Sensoren und Überwachungssytemen aufgezeichnet. So werden beispielsweise alltägliche Vorgänge des menschlichen Lebens, wie das Bezahlen mit Kreditkarte oder die Benutzung des Telefons, durch Computer aufgezeichnet. Dabei werden gewöhnlich alle verfügbaren Parameter abgespeichert, wodurch hochdimensionale Datensätze entstehen. Die Daten werden gesammelt, da sie wertvolle Informationen enthalten, die einen Wettbewerbs-Vorteil bieten können. Das Finden der wertvollen Informationen in den großen Datenmengen ist aber keine leichte Aufgabe. Heutige Datenbankmanagementsysteme können nur kleine Teilmengen dieser riesigen Datenmengen darstellen. Werden die Daten zum Beispiel in textueller Form ausgegeben, können höchstens ein paar hundert Zeilen auf dem Bildschirm dargestellt werden. Bei Millionen von Datensätzen ist dies aber nur ein Tropfen auf den heißen Stein.	bibliothèque de l'école des chartes;circa;data mining;die (integrated circuit);eine and zwei;exabyte;internet explorer;sie (file format);terabyte	Daniel A. Keim	2002	Datenbank-Spektrum		exabyte;performance art;history		-106.2421944512146	34.8714775708771	147701
128be8d80635e61145e0decc75f16ca19bcdead3	grundlagen eines kalkulationsmodells für blended learning kurse	blended learning;talk	Neue technologieunterstützte Lehrformen mit Internet als Transportmedium und neue Arten der didaktischen Wissensbereitstellung stecken noch am Anfang, wenn es darum geht deren Geschäftsmodelle kostenoptimierte aufzubauen. Dieses Paper unternimmt eine Gliederung der an den Kosten beteiligten Faktoren eines Kurses, stellt einfache Formeln zu Berechnung auf und zeigt ausgehend davon Faktoren auf, die zu einem kosteneffektiven Einsatz von E-Learning optimiert werden können. Die gewonnenen Ergebnisse sind sowohl für traditionelles Präsenzlernen, als auch für E-Learning Kurse anwendbar.	eine and zwei;gesellschaft für informatik	Martin Gutbrod;Helmut W. Jung;Stefan Fischer	2003			art;performance art	ML	-107.18339322061267	34.366145540580575	148436
6c2754ac559c588c11869aa09e97bef669282974	g&d bietet abhörsicheres smartphone für regierungen und behörden an		"""Die Angreifer infizierten ihre Opfer, indem sie ausgeklügelte Spear -Pishing-Mails 3 versandten. Die E-Mails enthielten schädliche Mi-crosoft-Office-Dokumente, die mit zwei sehr komplexen Schwach-stellen-Exploits (CVE-2012-0158 und CVE-2010-3333) 4 ausgestattet waren. Auch wenn Microsoft bereits Patches für diese Schwachstel-len veröffentlicht hat, werden diese nach wie vor für zielgerichtete Attacken missbraucht und haben sich als sehr wirksam erwiesen. Die Dateibezeichnungen der schädlichen Anhänge, die bei der Spear-Phishing-Attacke benutzt wurden, veranschaulichen, dass die NetTraveler-Gruppe keine Mühen gescheut hat, um hochran-gige Zielobjekte zu infizieren. Die bemerkenswertesten Dateibeze-ichnungen waren: """" Army Cyber Security Policy 2013.doc """" , """" Report-Asia Defense Spending Boom.doc """" , """" Activity Details.doc """" , """" His Holiness the Dalai Lama's visit to Switzerland day 4 """" und """" Freedom of Speech.doc """". Kaspersky Lab hat auf Grundlage der C&C-Server-Daten auch das Kaspersky Security Network (KSN) zu Rate gezogen 6 , um zu-sätzliche lokale Infizierungsstatistiken zu erhalten. Dabei taucht Deutschland in der Top-Ten der vom KSN entdeckten Opfer auf. Datenkanal (verschlüsselte Voice-over-IP-Verbindung) über das"""	eine and zwei;internet explorer;phishing;sie (file format);smartphone;switzerland;unified model;vhf omnidirectional range	Welche Daten Wurden Gestohlen;Weitere Erkenntnisse	2013	Datenschutz und Datensicherheit - DuD	10.1007/s11623-013-0231-x		Security	-104.17356813990239	36.96013479318992	148516
914e45172265703335f0c60bdee7c6227cf5b72a	optimal computation of the bernstein algorithm for the bound of an interval polynomial	bernstein polynomial;upper and lower bounds	If a polynomial is expanded in terms of Bernstein polynomial over an interval then the coefficients of the expansion may be used to provide upper and lower bounds for the value of the polynomial over the interval. When applying this method to interval polynomials straightforwardly, the coefficients of the expansion are computed with an increase in width due to dependency intervals. In this paper we show that if the computations are rearranged suitably then the Bernstein coefficients can be computed with no increase in width due to dependency intervals. Die Koeffizienten einer Bernstein-Polynomentwicklung geben obere und untere Schranken für den Wertebereich eines Polynoms über einen Intervall. Wenn diese Methode direkt auf Intervall-Polynome angewendet wird, dann sind die Ergebnisse mit einer Aufblähung behaftet. Diese Arbeit zeigt, daß diese Aufblähung der Bernstein-Koeffizienten vermeidbar ist, wenn die Formeln passend verändert werden.	algorithm;bernstein polynomial;coefficient;computation;die (integrated circuit);interval arithmetic;phil bernstein;zentralblatt math	Jon G. Rokne	1982	Computing	10.1007/BF02241751	kharitonov's theorem;mathematical optimization;mathematical analysis;discrete mathematics;alternating polynomial;stable polynomial;wilkinson's polynomial;degree of a polynomial;bernstein inequalities;mathematics;monic polynomial;bernstein polynomial;matrix polynomial;upper and lower bounds;reciprocal polynomial;square-free polynomial	AI	-96.40023220197583	35.6734261039574	148666
a67173aa4fc66a18bb84d49efbc0f181d5b826d9	agile business intelligence als beispiel für ein domänenspezifisch angepasstes vorgehensmodell		Business-Intelligence-Systeme stellen durch ihre Unterstützung bei der Entscheidungsfindung für Unternehmen eine wichtige Rolle dar. Mit einer stetig dynamischeren Unternehmensumwelt geht daher die Anforderung nach der agilen Entwicklung dieser Systeme einher, so dass in der BI-Domäne zunehmend erfolgreich agile Methoden und Vorgehensmodelle eingesetzt werden. Die Weiterentwicklung und Anpassung von BI-Systemen ist dahingehend besonders, dass diese in der Regel langjährig gewachsenen Systemen und Strukturen betreffen, die strengen regulatorischen Rahmenbedingungen unterliegen, was eine Herausforderung für agile Vorgehensweisen darstellt. Wurden die Werte und Prinzipien des agilen Manifests [AM01] und die daraus abgeleiteten Methoden zu Beginn meist eins zu eins auf den Bereich BI übertragen, so hat sich das Verständnis von BIAgilität als ganzheitliche Eigenschaft der BI im deutschsprachigen Raum etabliert, und agile Methoden wurden auf die Besonderheiten der BI-Domäne adaptiert. In diesem Beitrag werden BI-Agilität und Agile BI erläutert, ein Ordnungsrahmen für Maßnahmen zur Steigerung der BI-Agilität eingeführt sowie Herausforderungen bei Agile BI erläutert.	agile software development;die (integrated circuit);eine and zwei	Stephan Trahasch;Michael Zimmer;Robert Krawatzeck	2016			process management;business intelligence;agile software development;engineering	OS	-101.44727944121335	33.69206942034694	149406
2eb1d063b00178005bdf78838699785ebbcc746d	konfigurative prozessmodellierung der hybriden leistungserstellung in unternehmensnetzwerken des maschinen- und anlagenbaus		Die im Maschinenund Anlagenbau zunehmend verbreitete Erstellung hybrider Leistungsbündel aus Sachgütern und Dienstleistungen wird häufig in Netzwerken aus Kunden und Lieferanten entlang der Wertschöpfungskette ausgeführt. Je nach Ausrichtung des Geschäftsmodells und der Rollenverteilung innerhalb des Netzwerks ändern sich die Prozesse der beteiligten Wertschöpfungspartner. Der vorliegende Beitrag analysiert die sich hieraus ergebenden Anforderungen an Prozessmodelle für die hybride Wertschöpfung aus der Perspektive zweier Wertschöpfungsnetzwerke im Maschinenund Anlagenbau. Als ein Lösungsansatz werden konfigurierbare Prozessmodelle identifiziert. Für den unternehmensübergreifenden Prozess der Störfallbeseitigung wurde ein Prozessmodell konstruiert, das als Ausgangslösung toolgestützt an die Erfordernisse speziell ausgeprägter Netzwerke angepasst werden kann. 1 Hybride Wertschöpfung in Unternehmensnetzwerken des Maschinenund Anlagenbaus Im Maschinenund Anlagenbau ist die Bedeutung hybrider Leistungsbündel aus Sachund Dienstleistungen in den letzten Jahren immer mehr gestiegen [SB03; Ra06; La06; St07]. Verantwortlich hierfür sind insbesondere sinkende Margen im Produktgeschäft. Während im deutschen Maschinenbau das Maschinengeschäft durchschnittlich eine Umsatzrendite von 2,3% erzielt, werden im Bereich der Dienstleistungen mehr als 10% Umsatzrendite erreicht, wobei der Anteil bei einzelnen Dienstleistungen durchaus noch höher sein kann. Die durch Dienstleistungen zu erzielenden Margen bewegen sich dabei durchschnittlich im Umfeld von 8-18% [Me03]. Hybride Leistungsbündel stellen Kopplungen von Sachund Dienstleistungsanteilen dar. Im Gegensatz zur verbreiteten klassischen Betrachtung als getrennte Leistungsbestandteile zeichnet sich ein hybrides Leistungsbündel durch eine integrierende und sich gegenseitig determinierende Planung, Entwicklung, Erbringung und Nutzung beider Leistungsbestandteile aus. Um neue, kombinierte Leistungsergebnisse erzielen zu können, wird dabei häufig die Möglichkeit zur partiellen Substitution der jeweiligen Sachbzw. Dienstleistungsbestandteile vermutet [MK06]. Der Umfang der industriellen Dienstleistungen [Ga98], die in einem hybriden Leistungsbündel zusammen mit der Sachleistung erbracht werden, ist von der Ausgestaltung der Beziehung zwischen Anbieternetzwerk und Kunde in einem Geschäftsmodell abhängig. Grundsätzlich unterscheidet man funktions(klassische), verfügbarkeits(Performance Contracting) und ergebnisorientierte (Betreibermodelle) Geschäftsmodelle [MKK06], wobei die Art und Anzahl der Dienstleistungsbestandteile in allen Phasen des Sachleistungslebenszyklus variiert. In der weiteren Betrachtung wird hier beispielhaft die Sachleistung als ein Investitionsgut zur Produktion dargestellt, die im Folgenden als „Anlage“ bezeichnet wird. Beispielhafte Dienstleistungen der Anlaufphase, die dem Betrieb der Anlage vorgelagert ist, sind z.B. Beratungssowie Planungsoder Simulationsleistungen und dienen der Herstellung eines betriebsfähigen Zustandes. In der Betriebsphase des Produktes zielen die Dienstleistungsbestandteile des Leistungsbündels auf den Betrieb der Anlage (Bedienung durch ausgebildetes Personal, Anpassung von CNC Programmen, Entsorgung verbrauchter Materialien, etc.) sowie die Erhaltung der Betriebsfähigkeit der Anlage (Wartung, Instandhaltung) ab. Die Demontage sowie der Wiederverkauf bzw. die Entsorgung von Komponenten sind typische Dienstleistungen der Nachnutzungsphase einer Anlage. Die durch Dienstleistung zu realisierenden Nutzenpotenziale sind vielfältig [Qu88]. So tragen Dienstleistungen zu einer längeren und intensiveren Kundenbindung [SG05], einer höheren Leistungsfähigkeit des Produktes und einer flexibleren Anpassung des Produktes an Kundenbedürfnisse [Ho03] bei. Die Erbringung des hybriden Leistungsbündels findet in der Regel nicht alleine beim Anlagenhersteller statt, sondern beschreibt zumeist einen Netzwerkprozess, der die komplette Wertschöpfungskette vom Lieferanten des Anlagenherstellers bis zum Betreiber der Anlage umfasst. Ergänzt wird dieses Netzwerk durch externe Dritte, die sich auf die Erbringung besonderer Dienstleistungen spezialisiert haben. Dabei können sich die Leistungsbestandteile, die ein Unternehmen in zwei Netzwerken mit gleichem Geschäftsmodell und ähnlicher Charakteristik bezüglich Sachleistung und Zusammensetzung der Wertschöpfungskette zu erbringen hat, vollständig unterscheiden. Um die Zusammenarbeit im Netzwerk dennoch effizient gestalten zu können, ist die geschäftsmodellspezifische Integration der Geschäftsprozesse der beteiligten Unternehmen notwendig. Die Zusammenstellung von materiellen und immateriellen Komponenten in Leistungsbündeln erfordert eine genaue Kenntnis der zur hybriden Wertschöpfung erforderlichen Geschäftsprozesse, auch und vor allem über Unternehmensgrenzen hinweg. Zur Förderung einer gemeinsamen Leistungserstellung können Prozessmodelle dienen, in denen die Geschäftsprozesse formalisiert und eindeutig beschrieben sind. Ein Überblick über bestehende Referenzmodelle zeigt, dass bisher kaum Ausgangslösungen für die geschäftsmodellspezifische Konzeption hybrider Wertschöpfungsprozesse vorliegen (Abschnitt 2). Ziel dieses Beitrags ist es daher, speziell für den Bereich des Maschinenund Anlagenbaus einen Ansatz zur Entwicklung geeigneter Prozessmodelle zu aufzuzeigen. Hierfür werden zunächst auf der Basis von zwei Netzwerken spezielle Anforderungen an die Prozessmodellierung erhoben (Abschnitt 3). Im Anschluss wird ein konfigurierbares Prozessmodell für den Wertschöpfungsprozess „Störfallbeseitigung“ einer Anlage vorgestellt, das den identifizierten Anforderungen gerecht wird (Abschnitt 4). Die Schlussbemerkungen ziehen ein Fazit und geben einen Ausblick auf weiterführende Forschungsarbeiten (Abschnitt 5). 2 Bestehende Referenzmodelle für die hybride Wertschöpfung Um den derzeitigen Stand der Referenzmodellierung im Umfeld industrieller Dienstleistungen erfassen zu können, wurden Referenzmodelle zur Beschreibung von Produktion und Dienstleistungen zusammengestellt und analysiert [BBK08]. Für den Bereich der Produktion konnten 13 Referenzmodelle identifiziert werden. Diese sind dabei teilweise domänenunspezifisch (z.B. SCOR, Y-CIM Model), teilweise decken sie sehr spezielle Bereiche der Produktion ab (z.B. die Herstellung von Transportbandsystemen). Da Produktionsprozesse untereinander viele Gemeinsamkeiten aufweisen, ist die Wiederverwendbarkeit der Referenzmodelle im Produktionsbereich vergleichsweise hoch. Im Dienstleistungsbereich konnten 15 Referenzmodelle identifiziert werden. Als Folge der Heterogenität des Dienstleistungssektors und der kundenindividuellen Dienstleistungserstellung decken diese sehr unterschiedliche Fachbereiche (z. B. Bankdienstleistungen und IT-Infrastrukturdienstleistungen) ab und unterscheiden sich entsprechend sehr stark voneinander und beinhalten die Mitwirkung verschiedener Stakeholder. Lediglich drei der identifizierten Referenzmodelle beziehen sich sowohl auf Aspekte der Produktion als auch des Dienstleistungsbereiches, wobei auffällt, dass diese Modelle auf sehr spezielle Teilgebiete (Qualitätsmanagement, Facility Management) ausgerichtet sind. Der Erklärungsbeitrag zum Fachgebiet hybrider Leistungsbündel, die eine integrierte Sicht auf die Verknüpfung von Produkt und Dienstleistung entlang des Produktlebenszyklus (z. B. durch die Einbeziehung von Beratungsdienstleistungen, Recyclingdienstleistungen, Training, usw.) bereitstellen, bleibt somit sehr begrenzt. Entsprechend lässt sich feststellen, dass bisher keine hinreichende Referenzmodellunterstützung in diesem Bereich vorhanden ist. Somit bleiben Produzenten und Dienstleister – besonders im interorganisationalen Kontext in Wertschöpfungsnetzwerken – ohne ausreichende methodische Unterstützung. So wird Abstimmungsproblemen und Ineffizienzen bei Verständnis, Design und Durchführung entsprechender Kooperationen nicht systematisch begegnet. 3 Anforderungen an Prozessmodelle für die hybride Wertschöpfung im Anlagenbau Um die Anforderungen an Prozess(referenz)modelle für die hybride Wertschöpfung zu identifizieren, werden zwei Unternehmensnetzwerke des Maschinenund Anlagenbaus untersucht, die sich jeweils aus einem Systemlieferanten (supplier), einem Anlagenhersteller (Original Equipment Manufacturer, OEM) und dem Nutzer der Anlage (user) zusammensetzen. Beiden Netzwerken gemeinsam ist das Bestreben, die hybride Wertschöpfung zu forcieren, um die jeweiligen Erfolgsziele zu erreichen. Das erste Netzwerk behandelt ein hochverkettetes Presswerk, bei dem der Ausfall einer Presse den kompletten Stillstand der Anlage bedeutet. Bei Anlagen dieser Größe ist der Informationsaustausch zwischen user und OEM sehr ausgeprägt, die Kooperation wird als langfristige Partnerschaft gesehen und auftretende Probleme werden kooperativ gelöst. Auch im zweiten Netzwerk besteht eine enge Zusammenarbeit zwischen user und OEM. Durch persönliche Bekanntschaften werden Informationen stellenweise unpräzise ausgetauscht, jedoch durch den persönlichen Kontakt dennoch verstanden. Ist der entsprechende Ansprechpartner jedoch verhindert, hat seine Vertretung häufig Probleme, die teilweise unvollständigen Informationen lösungsorientiert zu deuten. Dieses Problem tritt nicht nur unternehmensübergreifend, sondern genauso innerhalb eines Unternehmens auf. Die supplier werden in beiden vorliegenden Geschäftsmodellen hauptsächlich bei der Ersatzteilversorgung einbezogen. Ein auch außerhalb der dargestellten Netzwerke häufig festzustellendes Problem ist die Trägheit der Informationskette, so dass vom letzten Glied der Nachschubkette die Lieferung des benötigten Ersatzteils innerhalb weniger Stunden gefordert wird, nachdem in den fordernden Unternehmen der Prozess durch mangelhafte Informationsgewinnung und -weitergabe sowie durch Schnittstellenverluste bereits Tage vergangen sind. In beiden Netzwerken sollen daher Referenzprozesse zur schnelleren Abwicklung von unternehmensüb	aldert van der ziel;computer-integrated manufacturing;die (integrated circuit);eine and zwei;institut für dokumentologie und editorik;sie (file format);triple des;unified model;vhf omnidirectional range;zentralblatt math	Daniel Beverungen;Uwe Kaiser;Ralf Knackstedt;Robin Krings;Armin Stein	2008			tile;systems engineering;computer science;composite material	OS	-103.59999789308957	33.307114570407045	149619
f320f4d0ef5b6051bb7cc813d81d6f33acfca6f9	anordnung gegen massendatenabgleich zwischen whatsapp und facebook		tionsfreiheit hat am 27. September 2016 eine Verwaltungsanordnung erlassen, die es Facebook ab sofort untersagt, Daten von deutschen WhatsApp-Nutzern zu erheben und zu speichern. Facebook wird ferner aufgegeben, bereits durch WhatsApp an das Unternehmen übermittelte Daten zu löschen. Facebook und WhatsApp sind selbstständige Unternehmen, die die Daten ihrer jeweiligen Nutzer auf Grundlage ihrer eigenen Nutzungsund Datenschutzbedingungen verarbeiten. Nach dem Erwerb von WhatsApp durch Facebook vor zwei Jahren haben sie öffentlich zugesichert, dass die Daten der Nutzer nicht miteinander ausgetauscht werden. Dass dies nun doch geschieht, ist nicht nur eine Irreführung der Nutzer und der Öffentlichkeit, sondern stellt auch einen Verstoß gegen das nationale Datenschutzrecht dar. Denn ein solcher Austausch ist nur dann zulässig, wenn sowohl auf Seiten des Unternehmens, das Daten liefert (WhatsApp) als auch bei dem empfangenden Unternehmen (Facebook) eine Rechtsgrundlage dafür vorliegt. Facebook hat allerdings weder eine wirksame Einwilligung von den Nutzern von WhatsApp eingeholt, noch ist eine gesetzliche Grundlage für den Datenempfang vorhanden. Dass Facebook die Regelungen des deutschen Datenschutzrechts respektieren muss, ist klar, nachdem im Juli der EuGH in einem Urteil bestätigt hat, dass nationales Datenschutzrecht anwendbar ist, wenn ein Unternehmen im Zusammenhang mit einer nationalen Niederlassung Daten verarbeitet. Dies tut Facebook in Deutschland durch seine Niederlassung in Hamburg, die das deutschsprachige Werbegeschäft betreibt.	die (integrated circuit);eine and zwei;national cyberdefence centre;sie (file format);vhf omnidirectional range;whatsapp messenger	Johannes Caspar	2016	Datenschutz und Datensicherheit - DuD	10.1007/s11623-016-0701-z		OS	-103.80736002250818	35.959612952202995	150092
b48544fb3b49139deb5c3f02fdbb4c2809b7ac4d	redefining the scientific record		Die Konferenz „Academic Publishing in Europe“ (APE),1 ins Leben gerufen von Arnoud de Kemp, verfolgt das Ziel, aktuelle Entwicklungen und Trends im wissenschaftlichen Verlagswesen aufzunehmen, widerspiegelt ein Panoptikum des aktuellen Diskurses. 2014 bereits zum neunten Mal durchgeführt,2 bot die Konferenz auch in diesmal ein ausgesuchtes Programm mit namhaften Rednern und widmete sich der Thematik „Redefining the scientific record“. Redefining the scientific record – eine Branche befindet sich im Aufund Umbruch. Vor dem Hintergrund sozialer Medien und der Flüchtigkeit der Informationen, in einem Umfeld, in dem jeder selbst zum Autor werden kann, stellt sich die Frage, welche Rolle der wissenschaftliche Verlag heute und in Zukunft einnehmen muss, welchen (Mehr-)Wert dieser bieten kann, um die Qualität in der wissenschaftlichen Kommunikation zu garantieren. Die APE-Konferenz nahm diese Aspekte auf, bot Raum zur Vorstellung innovativer Projekte und Initiativen, setzte inhaltliche Akzente auf Themen zu Open Access, Altmetrics und Big Data. Organisatorisch ist die APE aufgeteilt in die sogenannte „Pre-Conference“,3 die stets am Vortag der offiziellen Konferenz stattfindet, und die Hauptkonferenz. Zum ersten Mal durchgeführt wurde die Session „Dotcoms-to-Watch!“, in welcher fünf Startup-Firmen ihre Ideen und Ziele präsentieren konnten. Aus der Fülle des Tagungsprogramms4 werden einige Punkte herausgegriffen, Einund Aussichten, Erkenntnisse oder auch Erstaunliches daraus wiedergegeben. Zu einem essentiellen Faktor im wissenschaftlichen Publikationswesen gehört die Qualitätsmessung der Forschung. Neben etablierten und zugleich kontrovers diskutierten Methoden wie Impact Factor beginnen sich seit einigen Jahren alternative Messverfahren durchzusetzen, welche zusätzlich die Reichweite einer wissenschaftlichen Veröffentlichung in den Social Media nachzuzeichnen und anzugeben versuchen, subsumiert unter dem Begriff „Altmetrics“.5 In der Session „All about Metrics“ wurden die unterschiedlichen Facetten und Feinheiten von „Altmetrics“ beleuchtet. Euan Adie (Gründer der Firma „Altmetric“) stellte die Ziele und Visionen seines Unternehmens vor, sprach über dessen Produkte und Dienstleistungen.6 Mike Taylor (Technology Research Specialist, Elsevier Labs) gab einen Überblick über die verschiedenen Anwendungsgebiete von „Altmetrics“ (Aufspüren von Trends, Nachzeichnen des „versteckten“ Impacts, Nachweis der Information in Echtzeit). Eine überraschende Sicht auf das Thema zeigte sich im Vortrag von Stefanie Haustein (Université de Montréal), die in ihrem Beitrag7 verdeutlichte, dass Twitter sich nicht unbedingt eigne, um den Impact einer Publikation zu verbessern. In einer Studie8 untersuchte sie mit anderen Forschern zusammen anhand von 1,4 Millionen Artikeln (Peer Review), wie oft diese via Twitter weitergeleitet wurden, dies über einen Zeitraum von 2010 bis 2012; sie kam zum Schluss, dass Twitter den Impact nicht erhöhen kann. So lässt sich abschließend zu „Altmetrics“ wohl anmerken, was Taylor (2013) bemerkte: „... it may	7 days to die;altmetrics;big data;definition;die (integrated circuit);dot-com company;eine and zwei;gab;internet explorer;sie (file format);social media;unified model;vhf omnidirectional range	Anne-Katharina Weilenmann	2014	Inf. Wiss. & Praxis	10.1515/iwp-2014-0028		DB	-101.71764849186467	36.109042873629875	150518
8221913fb1cc75b82cfa44b241a19a8bdd0dfa11	vorgehensmodelle für die entwicklung hybrider produkte - eine vergleichsanalyse		Der Markterfolg eines Unternehmens steht in einem engen Zusammenhang mit dem Aspekt, ob angebotene Sach-oder Dienstleistungen die Anforderungen der Kunden treffen (Leimeister und Glauner 2008; Lindemann 2009). Ein weiterer Aspekt ist die Differenzierung von angebotenen Sachoder Dienstleitungen zu Wettbewerbern, die den Kunden einen Zusatznutzen verschaffen und welche die Position eines Unternehmens auf dem Markt stärken kann. Jedoch reichen Differenzierungsmöglichkeiten im Zusammenhang mit Sachleistungen nicht mehr aus, um die Kunden durch Alleinstellungsmerkmale zufriedenzustellen (Böhmann und Krcmar 2007). Deswegen orientieren sich viele Unternehmen neu und bieten integrierte Bündel von Sachund Dienstleistungen an – sog. hybride Produkte die die Probleme der Kunden lösen sollen (Lönngren et al. 2008; Böhmann et al. 2008; Leimeister und Glauner 2008). Im Bereich des Maschinenund Anlagebaus, beispielweise, erhöhen die Ausweitung und Optimierung der Vernetzung von Anlagen und Anlagenumgebung im Bereich des Großanlagenbaus die Komplexität im Betrieb für Unternehmen. Die hieraus resultierenden neuen Herausforderungen, wie z. B. Planungsund Abwicklungssysteme direkt einzubinden oder auf neue Anforderungen zeitnah zu reagieren, erfordern an die Umwelt anpassbare Prozesse. Hersteller von industriellen Großanlagen sehen sich infolge dessen, neben den Entwicklungsfragen im Maschinenund Anlagenbau, zudem mit Fragestellungen	eine and zwei;institut für dokumentologie und editorik;internet explorer;the daily telegraph;unified model	Philipp Langer;Felix Köbler;Marina Berkovich;Felix Weyde;Jan Marco Leimeister;Helmut Krcmar	2010			knowledge management;computer science;performance art	AI	-103.31125307412093	33.53115916101997	150662
a070a6262360e7b812c37032c0977047b0c70206	aussprache zum referat von herbert fiedler		Ein erster Schwerpunkt der von Lucian Koloseus geleiteten Diskussion widmete sich der von Fiedler festgestellten Diskrepanz zwischen IT-Entwicklung und verwaltungsspezifischer Gestaltung von Arbeitsmethoden. Koloseus stellte hierzu einleitend die Frage nach dem Adressatenkreis, der fur die Entwicklung von Strategien zum Abbau dieser Diskrepanz in Frage komme.		Wilfried Frankenbach	1984		10.1007/978-3-642-95469-6_5		Vision	-104.18416473347888	33.123248743043625	150915
44fcc40dc296b5bf3585dc9570cec554a823032a	vorwort: junge informatik		Paul E. Ceruzzi ist als Kurator am Nationale Air and Space Museum in Washington D.C., einem der Museen mit der weltweit höchsten Besucherzahl, für die ausstellungsmäßige Präsentation der Verwendung von Computern in der Luft-und Raumfahrt zuständig. Seit mehr als zwei Jahrzehnten erforscht er aber auch die Geschichte der Computer in ihrer ganzen Breite und hat sich als Autor mehrerer Bücher einen Namen gemacht. Als er in seinem ersten Buch die frühen Rechenautomaten von Konrad Zuse jenen von Howard Eicken und George R. Stibitz gegenüberstellte, wurde das auch in Deutschland zur Kenntnis genommen. Er hat Zuses frühe Leistungen, mit denen der deutsche Anteil an der Geschichte des Computers besonders eng verbunden bleiben wird, immer wieder im internationalen Vergleich kompetent gewürdigt, so auch 1991 in einem Kolloquium des Deutschen Museums in München zur 50. Wiederkehr des Jahrestags der ersten Vorführung von Zuses Z3. Selbstverständlich hatte der Autor die amerikanischen Leser vor Augen. So widmete er dieses Buch den an der Technik und ihrer Geschichte interessierten Besuchern des Air and Space Museums, deren Fragen er täglich beantworten muss. Mit zahlreichen angeführten Details und geschilderten Zusammenhängen bestätigt er, was man schon immer ahnte, dass nämlich jene Kapitel der Geschichte des Computers, in denen es um seine Verbreitung geht, in den USA geschrieben wurden. Ceruzzis roter Faden durch die zweite Hälfte des 20. Jahrhunderts zieht sich auf der Suche nach der weiteren Verbreitung der immer wieder in neuer Gestalt erscheinenden Rechenautomaten durch sehr verschiedene Situationen. Er beginnt bei den Vätern des ENIAC, John Presper Eckert und John William Mauchly, nicht nur weil ihnen der Bau dieser Maschine gelang, sondern auch, weil sie es waren, die zur industriellen Serienfertigung des elektroni-	eine and zwei;eniac;eckert–mauchly award;gestalt psychology;maschine;sie (file format);triple des;unified model;vhf omnidirectional range	Friedemann Mattern;Friedhelm Meyer auf der Heide	1999				Crypto	-103.87923123232207	34.655543210735274	150918
ae699096f499deb86c9cfb274588335174851aac	risiken der nichterkennung von malware in komprimierter form	malware	Maliziöse Software (Malware) gefährdet die Vertraulichkeit, Integrität und die Verfügbarkeit von Informatiksystemen auf verschiedene Art und Weise. In diesem Beitrag wird der Frage nachgegangen, inwiefern durch Malware in komprimierter Form Risiken entstehen. Ausgewählte Risiken werden anhand eines Szenarios veranschaulicht und analysiert. Ein Standard-Schutzmechanismus vor Malware ist Anti-Malware-Software. Es wird eine Testmethodik vorgestellt, mit der systematisch die Güte der Erkennung von Malware in komprimierter Form durch Anti-Malware Software getestet werden kann. Abschließend werden mit dieser Methodik erlangte Testergebnisse vorgestellt. 1 Risiken durch Malware in komprimierter Form	antivirus software;archive;citeseerx;computer mouse;eine and zwei;gesellschaft für informatik;institut für dokumentologie und editorik;intentionally blank page;internet explorer;laptop;malware;sie (file format);triple des;unified model;vhf omnidirectional range	Heiko Fangmeier;Michel Messerschmidt;Fabian Müller;Jan Seedorf	2004			operating system;malware;computer science	ML	-104.2349585706673	37.748276177588124	151041
ffd91050667e63433880c9103a37820dba74516f	deutscher wortschatz im internet		Die mittlerweile vorliegende Datensammlung, die momentan sicher eine der umfangreichsten frei zugänglichen Datensammlungen zur deutschen Sprache ist, entstand Anfang der 90er Jahre mit einer Wortliste mit sporadisch vorhandenen Angaben zu Grammatik und Sachgebiet. Diese war angelegt worden, da damals ein allgemeiner Mangel an frei verfügbaren maschinenlesbaren Daten zum deutschen Wortschatz bestand. Anliegen der damals begonnenen Sammlung war und ist, verfügbare Daten zunächst zu sammeln und sie (sobald wie möglich) zu nutzen, um fehlende Angaben zu ergänzen und eventuelle Fehler zu beseitigen. Dazu bietet sich speziell die Redundanz an, die in einer so großen Sammlung zu finden ist. Hier erweist sich auch die Sammlung von Vollformen als günstig, da bei einer späteren Reduktion auf Grundformen die Menge der flektierten Formen zu einer Grundform die korrekte Erkennung dieser Grundform erleichtert. Ebenso läßt sich dann das korrekte Flexionsschema leichter erkennen bzw. überprüfen. Nachdem lange mit verschiedenen Wortlisten gearbeitet worden war, wurde 1994 auf ein relationales Datenbanksystem umgestellt, um eine einfachere Datenverwaltung und einheitliche Zugriffsmöglichkeiten zu bekommen. Schnell stellte sich heraus, daß bei einigen so gesammelten Wörtern für den Betrachter im nachhinein nicht festgestellt werden kann, ob es sich um ein fehlerhaft geschriebenes Wort, einen Eigennamen oder vielleicht einen ihm unbekannten Fachbegriff handelt. Um solche Fragen wenigstens in der überwiegenden Mehrzahl der Fälle klären zu können, wurde ab ca. 1996 zusätzlich für jede neue Wortform ein Belegsatz gesammelt. Dazu wurde ein eigener Satzsegmentierer entwickelt (s. u.). Das Vorhandensein der Beispielsätze wiederum ermöglicht Untersuchungen von Kollokationen. Erste Versuche sahen sehr erfolgversprechend aus, allerdings war das verwendete Material an Beispielsätzen nicht repräsentativ, da immer nur Sätze mit neuen Wörtern gesammelt wurden. Deshalb wurde 1998 dazu übergeFachbeiträge	circa;die (integrated circuit);eine and zwei;gesellschaft für informatik;grammatik;intentionally blank page;internet explorer;sie (file format);unified model	Uwe Quasthoff	1998	LDV Forum		computer science;information retrieval;world wide web;the internet	OS	-105.7428671574463	35.396935167056284	151084
2070a381554c7dbf06458872a947b647ac4ae602	detektion von fahrspuren und kreuzungen auf nichtmarkierten stra\en zum autonomen führen von fahrzeugen		  Das Wissen über Position und Verlauf der Straße ist eine der wichtigsten Informationen, die zum Führen autonomer Straßenfahrzeuge  benötigt wird. Die meisten Arbeiten gehen davon aus, dass Markierungen auf der Straße vorhanden sind, die die Erkennung enorm  erleichtern. Üblicherweise werden die Fahrbahnränder detektiert und die Fahrspur mit Hilfe eines Kaiman-Filters geschätzt  [1]. Andere Arbeiten verwenden zusätzlich die Straßenfarbe und kombinieren die verschiedenen Hinweise in einem Partikel-Filter  [2]. Ein allgemeiner Überblick über Verfahren zur Fahrspurdetektion findet sich in [3].    		Stefan Vacek;Cornelius Bürkle;Joachim Schröder;Rüdiger Dillmann	2007		10.1007/978-3-540-74764-2_30	performance art;history	ML	-105.32401733500343	32.640193654783374	151304
fcd4c78706380f8ab62526276e475fc82892b495	interaction with mobile systems as part of smart ecosystems		Ein Beispiel für Smart Ecosystems sind Smart Rural Areas. Um dem demografischen Wandel vieler Städte und Dörfer entgegenzuwirken, bedarf es vor allem der Vernetzung und Stärkung der ländlichen Regionen unter Zuhilfenahme moderner Kommunikationstechnologien. Dies geschieht indem ländliche Regionen mithilfe neuer Dienste, so genannter Smart Services, attraktiver gemacht werden und somit der Landflucht entgegenwirken. Es entfaltet sich ein neues Potenzial für ländliche Regionen, wenn beispielsweise der Nahverkehr mit dem Warentransport verknüpft wird oder eine bessere medizinische Versorgung durch mobile Telemedizin-Portale garantiert werden kann. Die benötigte Infrastruktur im ländlichen Raum wird durch die Chancen der Digitalisierung smart – komfortabel für den Nutzer und lukrativ für neue Geschäftsmodelle.	calculating space;die (integrated circuit);eine and zwei;ecosystem;unified model;vhf omnidirectional range	Konstantin Holl;Christian Müller;Peter Liggesmeyer;Achim Ebert	2016		10.18420/muc2016-ws09-0000		Mobile	-102.4483074724533	37.04881120577703	151716
9783808239e1e803d32bc8e74057b418ce987cc8	zur einschätzung von programmierfähigkeiten - jedem programmieranfänger über die schultern schauen		Am besten kann man den Kenntnisstand und die Fähigkeiten eines Studierenden in einer Programmierveranstaltung einschätzen, wenn man ihm während des Programmierens über die Schulter schaut. Man erkennt, ob systematisch vorgegangen wird, welche Sprachkonstrukte sicher sitzen oder nicht, wieviel Trial & Error im Spiel ist, etc. Da die Anzahl der Teilnehmer die der Betreuer aber um ein Vielfaches übersteigt, ist eine solche direkte Beobachtung schwer möglich. Wir beschreiben vorbereitende Arbeiten und erste Teilergebnisse für die Erprobung eines Werkzeugs, das eine nachträgliche Analyse der Entstehung einer Lösung erlaubt, um über (manuelle oder semiautomatische) Auswertungen Rückschlüsse auf Wissenslücken und damit hilfreiche Aufgaben oder sinnvolle Stoff-Wiederholungen zu erlangen.	am broadcasting;eine and zwei;unified model	Bastian Schulten;Frank Höppner	2015			clinical psychology;psychology	AI	-107.26818823553548	33.02790235878693	152562
01b4378f0712831f6d7177ea11e51055c00cb8c7	efficacité et robustesse aux distracteurs d'un retour tactile pour faciliter le pointage	touchpad;coefficient of friction;squeeze film effect;distractor;performance improvement;friction;pointing facilitation	Surfpad is a pointing facilitation technique that operates in the tactile domain by taking advantage of the ability to alter a touchpad's coefficient of friction. We report on two experiments comparing it to the semantic pointing technique and constant control-display gain with and without distractor targets. Our results clearly show the limits of traditional target-aware gain adaptation in the latter case, and the benefits of our tactile approach in both cases. Surfpad can lead to a performance improvement of up to 21% compared to unassisted pointing at small targets with no distractor. It is also robust to high distractor densities, keeping an average performance improvement of nearly 10% while semantic pointing can degrade up to 100%.	amiga walker;best, worst and average case;bitmap;brewster's angle;chi;coefficient;computer performance;cursor (databases);experiment;fitts's law;haptic technology;hudson;human factors and ergonomics;human–computer interaction;icra;killer instinct;linear algebra;look and feel;multimodal interaction;nouvelle ai;oakley protocol;p (complexity);photographic plate;pointing device;pointing stick;robbins v. lower merion school district;sans institute;sticky bit;stylus (computing);t pad;tactile imaging;touchpad;yang	Géry Casiez;Nicolas Roussel;Romuald Vanbelleghem;Frédéric Giraud	2010		10.1145/1941007.1941012	simulation;engineering;communication;engineering drawing	HCI	-109.5407583480801	32.489691009699534	152588
a0de2e3adf1a01fc87d6207baf6b17d79478858b	hochschulübergreifendes e-learning: technische realisierung und datenschutz		A state machine space for concurrent state machines is provided for use in a telecommunications system. Processing of the state machines (and their functions/actions) utilizes specialized data structures and processes to normalize and control data and events dynamically in the telecommunications system. A Universal Data Structure (UDS) provides data uniformity and represents an event in the telecommunications system. A typical UDS includes four fields which are defined by the UDS definition. Three of these fields include event, component types, and data, while an embedded fourth field includes enums. Each UDS represents an event occurring in the telecommunications system and activates one or more state machines contained within a sub-space.		Stephan Graf;Wolfgang Hommel;Sabine Rathmayer	2009			data mining;finite-state machine;distributed computing;computer science;data structure	NLP	-98.27267750612165	32.46877325588417	152640
4783d11a4b8a71e600c2c233c52d038ce629eb61	kommunikation und kooperation im wissensaustausch in virtuellen verbünden		In diesem Workshop sollen sich Forscherinnen und Praktikerinnen zusammenfinden, die sich mit Entstehung, Motivation und Unterstutzung von Wissensaustauschprozessen in Virtuellen Verbunden (Virtuelle Organisationen, Virtuelle Communities, Communities of Practice, Community Networks, Burgernetze, etc.) beschaftigen. Gegenuber Organisationen mit stabilen Strukturen und Prozessen ist der Wissensaustausch in Verbunden durch die Volatilitat von Beziehungen und die gering ausgepragten Strukturen wesentlich schwerer sozio-technisch zu unterstutzen. Es handelt sich beim Wissensaustausch in virtuellen Verbunden um Kommunikation, aber auch um Kooperation in und uber dynamische, verteilte, noch zu erschliesende Wissenslandschaften und nicht um fest umrissene Aufgaben und Strukturen.		Peter Mambrey;Volkmar Pipek;Gregor Schrott	2001				Logic	-102.52662107594976	33.755377170623085	152802
bd9bd52ec31b623f552e69d013eba299c9c83d60	einsatz von magnetfeldsensoren in der zerstörungsfreien materialprüfung und qualitätssicherung		Die zerstörungsfreie Materialprüfung spielt in der Industrie eine wichtige Rolle, insbesondere im Bereich der Qualitätskontrolle. Dabei haben sich in den letzten Jahren vermehrt Verfahren durchgesetzt, die auf magnetischer Bildgebung basieren. Im vorliegenden Beitrag werden Sensoren basierend auf zwei unterschiedlichen Effekten, dem Riesenmagnetowiderstand (engl. giant magnetoresistance, GMR) und dem Faraday-Effekt beschrieben und ihre Einsatzmöglichkeiten in der Qualitätssicherung demonstriert. Die Einsatzgebiete kommerzieller Sensoren, die auf diesen beiden Effekten basieren, reichen von der Qualitätssicherung in der Stahlindustrie bis zur Endkontrolle von integrierten Schaltungen in der Halbleiterindustrie. Es wird gezeigt, dass GMR-Sensoren in der Lage sind, selbst kleinste Einschlüsse in Stahlbändern bereits während der Produktion sicher zu erkennen. Mittels eines GMRZeilensensors können stromdurchflossene Leiter innerhalb eines Halbleiter-Chips kontrolliert werden. Damit eröffnen sich parallel zu den sonst üblichen potentiometrischen auch magnetfeldbasierte Charakterisierungsverfahren in der Endkontrolle der ICs. Der Prüfung mittels GMR-Zeilensensoren wird auch die Messdatenaufnahme über flächig messende, auf dem Faraday-Effekt beruhende Sensoren gegenübergestellt.	eine and zwei;faraday cage;giant magnetoresistance	Patrick Hölzl;Florian W. Dietachmayr;Johannes Atzlesberger;Bernhard G. Zagar	2015	Elektrotechnik und Informationstechnik	10.1007/s00502-015-0307-4	engineering;polymer science;electronic engineering	OS	-104.97330686922615	33.222401795101135	152967
dbca7c70a5ef7960638c179a5133a8a8f560ef29	verwundbarkeitsprüfungen mit shodan		Immer mehr Dienste werden über das Internet angeboten — und damit auch zum Ziel von Angreifern [1]. Erfolgreiche Angriffe auf Online-Dienste können nicht nur direkte Umsatzeinbußen, sondern auch Reputationsschäden verursachen. Daher ist eine regelmäßige Untersuchung der Systeme auf bekannte Schwachstellen angeraten. Wie das auch ohne klassische Penetrationstests gelingen kann, zeigt der vorliegende Beitrag.	eine and zwei;internet explorer;shodan	Kai Simon;Cornelius Moucha	2016	Datenschutz und Datensicherheit - DuD	10.1007/s11623-016-0691-x	internet privacy;the internet;computer science	OS	-103.90648687130613	36.36655275091997	153167
0468913a0198152f95e03aeb63c1373b555d8a53	author index		Ba, Zhongjie...................................................... 373 Gao, Jing........................................................... 328 Bai, Yong........................................................... 271 Gao, Yongchang................................................. 38 Bao, Jinling........................................................ 429 Ge, Jidong......................................................... 425 Bao, Wenyan..................................................... 435 Ge, Yu............................................................... 237 Bei, Jia.............................................................. 479 Gong, Bin............................................................ 38 Bin, Liu.............................................................. 128 Gong, Xueqing.................................................. 265 Cao, Keyan......................................................... 76 Guangyu, Bao............................................. 80, 415 Che, Nan........................................................... 361 Guo, Jian........................................................... 294 Chen, Dapeng................................................... 471 Guo, Junxia....................................................... 107 Chen, Guolong.................................................. 361 Guo, Wei........................................................... 369 Chen, Ke........................................................... 221 Ha, Yue............................................................. 265 Chen, Lei........................................................... 456 Haichao, Zuo..................................................... 138 Chen, Lin........................................................... 176 Haiyan, Huang.................................................... 80 Chen, Ling........................................... 97, 249, 281 Han, Hao........................................................... 107 Chen, Qi.................................................... 281, 373 Han, Weihong........................................... 355, 365 Chen, Zheyi....................................................... 361 Han, Yanbo....................................... 143, 314, 324 Chenyu, Wang.................................................. 351 He, Li................................................................. 355 Chou, Jian......................................................... 176 He, Ping............................................................ 281 Cui, Peng.......................................................... 347 He, Wei............................................................. 465 Dai, Yuehua...................................................... 400 He, Wenjie......................................................... 211 Dawei, Jin............................................................ 84 Hongmei, Li....................................................... 275 Dengchao, He..................................................... 84 Hu, Hao..................................................... 409, 425 Ding, Feng........................................................... 71 Hu, Jianbin.......................................................... 71 Ding, Guohui....................................................... 76 Hu, Kongfa.......................................................... 97 Ding, Hui........................................................... 176 Huang, Dajun.................................................... 243 Ding, Weilong.................................................... 328 Huang, Mengxing........................................ 90, 377 Ding, Zhaoyun................................................... 355 Huang, Yihua................................................ 55, 65 Dong, Guoqing.................................................. 119 Jia, Wei............................................................... 11 Dou, Hui............................................................ 394 Jia, Yan............................................................. 355 Du, Zi-jun............................................. 33, 229, 255 Jiang, Lu............................................................ 180 Duan, Xi............................................................ 377 Jiang, Zhen......................................................... 19 Fang, Jun.................................................. 314, 324 Jin, Yang............................................. 33, 229, 255 Feng, Shi........................................................... 243 Jing, Qi................................................................ 71 Fu, Lizhen........................................................... 42 Jing, Wang........................................................ 318 Gan, Zaobin.............................................. 133, 199 Ju, Yingnan......................................................... 71 Gang, Chen................................................. 84, 275 Jun, Qi............................................................... 289 Gang, He........................................................... 167 Kong, Lanju....................................................... 471 Gao, Cheng....................................................... 107 Kou, Yue........................................... 184, 333, 383 Gao, Fuxiang..................................................... 217 Lan, Chao.................................................... 15, 339 Gao, Hongyu..................................................... 113 Lan, Yao............................................................ 237	binary prefix;chao (sonic);corylopsis hypoglauca;eighty;entity–relationship model;execution unit;han unification;holographic principle;jing;lu decomposition;lithium;lobular neoplasia;local area networks;local interconnect network;meridians;nan;photinia glabra;schisandra chinensis;yang;yao graph	Mohamad Hammam;Vijaya Prakash	1986		10.1007/BF00319547			-99.62589398290666	37.37418163390356	153564
2e0e0d89c4fcf489112eb1c9aed2fd4393a203b5	verfahren für eine schnelle konturanalyse		Fur die automatische Objektvermessung und Objekterkennung in der industriellen Anwendung werden bevorzugt die Objektkonturen analysiert, und es werden in der Regel hohe Geschwindigkeitsanforderungen an die Konturanalyse gestellt. Um diesen hohen Geschwindigkeitsanforderungen gerecht zu werden, ist es erforderlich, die Gewinnung der gewunschten Konturinformation so in einfache Teilschritte zu gliedern, das diese mit elektronischen Spezialschaltungen ausfuhrbar sind.	eine and zwei;gesellschaft für informatik	W. Hättich	1987		10.1007/978-3-662-22205-8_35		Vision	-104.61241841663755	32.41790426945819	153825
2e86484460bc59b3e3d1af5379ca0ce4ebef2c00	nutzeridentifikation mit mobilen endgeräten		Mit einer raumgenauen Nutzeridentifikation und vernetzter Gebäudeautomation ist eine Verbesserung des Energiemanagements im Gebäudebetrieb denkbar. Die technische Umsetzung erfordert dafür eine genaue Erfassung von Nutzungsverhalten und Energieverbrauchsdaten, wodurch eine Vielzahl an personenbezogenen Daten verarbeitet wird. Daraus ergeben sich Risiken für die informationelle Selbstbestimmung der Nutzer. Die erforderliche Nutzerakzeptanz kann durch die Gewährleistung von Datenschutz und Datensicherheit erreicht werden.	diethylstilbestrol;eine and zwei;mit/gnu scheme	S. Braun;Tobias Henzler;Anders Berg	2018	Datenschutz und Datensicherheit - DuD	10.1007/s11623-018-1023-0	computer security;internet privacy;computer science	NLP	-103.73378915895834	36.567618749829556	154206
3fb0ba0f0eab9c9379f0bb4a0121184ae2ed77cd	equivalência entre a área sob a curva kolmogorov-smirnov e o índice de gini na avaliação de desempenho de decisões binárias		This paper proposes and proves the important equivalence between the Gini index and the area under the Kolmogorov-Smirnov (KS) distribution curve. The proof’s rationale is similar to that used in the proof of equivalence between AUC_ROC and AUC_KS. But different from that, this one uses a transformation that preserves the 1-to-1 correspondence between the ideal classifier on the KS and Lorenz curve domains. As metrics, this paper proves that the Gini index ratio to that of the ideal classifier is equivalent to the area under the KS curve ratio to that of its ideal classifier. That is Gini_Index_Ratio = AUC_KS_Ratio. This complements the proven equivalence between KS and ROC area metrics extending it to the Gini index. Resumo. Este artigo propõe e prova a importante equivalência entre o índice de Gini e a área sob a curva da distribuição Kolmogorov-Smirnov (KS). A lógica da prova é semelhante à utilizada na prova de equivalência entre a AUC_ROC e a AUC_KS. Mas, diferente daquela, esta usa uma transformação que preserva a relação 1-para-1 entre o classificador ideal nos domínios das curvas KS e de Lorenz. Como métricas, este artigo prova que a razão do índice de Gini pelo do classificador ideal é equivalente à razão da área sob a KS pela área do classificador ideal. Isso é Gini_Index_Ratio = AUC_KS_Ratio. Isso complementa a equivalência entre as métricas de área KS e ROC, estendendo-a para o índice de Gini.	design rationale;kolmogorov complexity;multi-agent system;nos;numerical aperture;prova;turing completeness;windows legacy audio components	Paulo J. L. Adeodato;Sílvio B. Melo	2016			statistics;data mining;computer science;kolmogorov–smirnov test	Vision	-94.85065644584729	34.75984824519734	154356
9d0848e5519a0f0b205c7c1e31dae24fce5cfd94	informationswissenschaft an deutschsprachigen universitäten - eine komparative informetrische analyse		Untersucht wurden die Institute für Informationswissenschaft folgender Universitäten: Humboldt-Universität zu Berlin, Heinrich-Heine-Universität Düsseldorf, Karl-Franzens-Universität Graz, Universität Hildesheim und Universität Regensburg. Für die Erhebung der Messdaten dienten die Publikationslisten aller Mitarbeiter, die an den Instituten tätig waren. Für den Zeitraum von 2003 bis einschließlich 2012 wurden über 1.000 Publikationen ermittelt. Indikatoren der szientometrischen Analyse sind die Anzahl der Publikationen, der Dokumenttyp, der Abdeckungsgrad in Fachdatenbanken, die Zitationen und der h-Index. Ausgewählte Fachdatenbanken sind Web of Science, Scopus, Google Scholar, Mendeley, CiteULike und BibSonomy. Auftretende Fehler in den Datenbanken sind genau dokumentiert und Gegenstand der Auswertung. Anhand der erhobenen Werte werden die betrachteten Institute in Relation zueinander gesetzt. Der Vergleich bezieht sich auf den Abdeckungsgrad in den zur Recherche verwendeten Datenbanken, die Produktivität sowie den wissenschaftlichen Einfluss der jeweiligen Institute.	eine and zwei;google scholar;mendeley;scopus;web of science	Mathilde B. Friedländer	2014	Inf. Wiss. & Praxis	10.1515/iwp-2014-0018		AI	-103.65447357139733	34.388134840635225	155235
dd1bbef5f017e95f4baab2c7d2b965b223d06139	internetwahlendemokratische wahlen über das internet?	online elections · internet voting · techniques · risks internetwahl · online-briefwahl · verfahren · risiken	Nach einer Zusammenstellung und kritischen Diskussion derjenigen Argumente, die Befürworter und Gegner der Durchführung demokratischer Wahlen über das Internet oft vorbringen, bespricht der Artikel die technischen Grundlagen einiger praktikabler Typen von Internetwahlverfahren, die bereits in realen Wahlexperimenten erprobt werden. Dabei werden die Stärken, Schwächen und verbleibenden Risiken deutlich gemacht und bewertet. After a critical discussion of those arguments that are frequently given by both the proponents and the opponents of democratic elections over the Internet, the article presents the technical basics of some Internet voting schemes that are practical and that have already been used in voting experiments. The presentation identifies strength and weaknesses of the schemes and focusses on the remaining risks.	experiment;internet;zentralblatt math	Michael Philippsen	2002	Informatik-Spektrum	10.1007/s002870200216		Security	-103.14198963456617	36.930638916595676	155327
d0e42c822a3747d10bc57876949e54a8d593c4f2	benchmarking e-government - formale aspekte der anwendbarkeit unter berücksichtigung differenzierter zielsetzungen		Nach Beobachtungen der Vereinten Nationen [UnNa03, 128] werden sich weltweit Regierungen (und deren Verwaltungen) zunehmend der Notwendigkeit bewusst, basierend auf dem Einsatz moderner Informationsund Kommunikationstechnologien [kurz: IKT] Verbesserungen in der öffentlichen Dienstleistungserstellung zu erzielen. Als Gründe hierfür werden zwei zusammenhängende Phänomene erachtet: So führte einerseits die schnelle Globalisierung durch den verstärkten zwischenstaatlichen Handel mit Gütern und Finanztiteln zu einer zunehmenden Verdichtung der transnationalen Netzwerke, innerhalb welcher sich Staaten nun gezwungen sehen, konkurrenzfähige Dienstleistungen und Produkte zur Verfügung zu stellen. Andererseits zogen die Fortschritte in der IKT neue Ansätze zur Integration dieser Netzwerke und zu Effizienzsteigerungen in der Güterund Dienstleistungserstellung mit sich. ffentliche Verwaltungen setzen deshalb weltweit vermehrt IKT als Grundlage ihrer Dienstleistungserstellung ein, um den veränderten Umweltbedingungen und Kundenerwartungen gerecht zu werden und somit letztlich dem „Imperativ zu E-Government“ [UnNa03, 128] Folge zu leisten. In diesem Kontext können internationale Benchmarking-Studien – abhängig von Zielsetzung und Design – essenzielle Stimuli für die Weiterentwicklung von E-Government repräsentieren, da sie einerseits eine Bewertung des nationalen Entwicklungsstands gegenüber internationalem Best Practice vollziehen und andererseits Anleitungen zur erfolgreichen Durchsetzung von E-Government in der Praxis bieten. Um den Beitrag von internationalen Benchmarking-Untersuchungen zur Umsetzung von E-Government Modellen abwägen zu können, werden im Folgenden die Erhebungsmethoden und Ergebnisse von vier ausgewählten Studienreihen präsentiert. Aufbauend darauf soll in einem ersten Schritt geklärt werden, inwiefern die Untersuchungsreihen aufgrund ihrer jeweiligen Ausgestaltungen geeignet sind, dem Benchmarking innewohnende, funktionale Ausgestaltungen unterschiedlicher Nutzenaspekte zu realisieren. In einem zweiten Schritt wird dann der Frage nachgegangen, inwiefern die Studien und deren Bewertungsmodelle eine zweckdienliche Grundlage für Regierungen darstellen, welche die Implementierung einer nachhaltigen und umfassenden Konzeption von E-Government anstreben.	altran praxis;best practice;e-government;eine and zwei;handel;sie (file format);unified model	Herwig Ostermann;Roland Staudinger	2005	Wirtschaftsinformatik	10.1007/BF03251477	knowledge management;data mining;management science;management;benchmarking	OS	-101.3910158037869	33.7825667944284	155752
52ac5c74b5e90ff6a98f3439a63d7dfb297d9281	wireless systems and mobility in next generation internet, 4th international workshop of the eurongi/eurofgi network of excellence, barcelona, spain, january 16-18, 2008, revised selected papers	cooperative systems;part of book or chapter of book;disruptive tolerant networks	Die Online-Fachbuchhandlung beck-shop.de ist spezialisiert auf Fachbücher, insbesondere Recht, Steuern und Wirtschaft. Im Sortiment finden Sie alle Medien (Bücher, Zeitschriften, CDs, eBooks, etc.) aller Verlage. Ergänzt wird das Programm durch Services wie Neuerscheinungsdienst oder Zusammenstellungen von Büchern zu Sonderpreisen. Der Shop führt mehr als 8 Millionen Produkte.	internet explorer;next-generation network;sie (file format)	Gabriele Kotsis;Otto Spaniol	2008		10.1007/978-3-540-89183-3	simulation;telecommunications;engineering;computer security	OS	-103.65452527685878	37.52049351192599	156087
f7d15cf388f4e0c4848ebd8032f9438a45b47e2b	sicherheitsprobleme für it-outsourcing durch cloud computing		Sowohl fehlende Standards aufseiten der Cloud-Provider als auch unklare Sicherheitsbestimmungen machen eine Risikoanalyse von Services, die in der Cloud angeboten werden, schwierig. Eine Lösung hierfür ist die Analyse Cloud-spezifischer Sicherheitsprobleme und der Vergleich mit Problemen des klassischen IT-Outsourcings. Die identifizierten Probleme werden hinsichtlich der bedrohten Schutzziele nach BSI IT-Grundschutz eingeordnet und es werden Maßnahmen zur Linderung der Probleme vorgeschlagen. Cloud-Einsteiger profitieren von den vorgestellten Leitfäden zum Thema Cloud-Sicherheit, Cloud-Anwender können durch die aufgeführten Sicherheitsvorfälle bei Cloud-Providern ihre Cloud-Ressourcen besser evaluieren.	broadcast signal intrusion;cloud computing;die (integrated circuit);eine and zwei;outsourcing	Mathias Ardelt;Frank Dölitzscher;Martin Knahl;Christoph Reich	2011	HMD Praxis der Wirtschaftsinformatik	10.1007/BF03340625	knowledge management;software engineering;cloud computing;engineering;outsourcing	OS	-101.93214253216196	35.53596813124267	156230
0bd7522094b433bf840b516cb8468fe7dbbf4382	zum bedarf an methodenvielfalt im bereich der entscheidungsunterstützenden simulation	zum bedarf;tzenden simulation;methodenvielfalt im bereich der	Bereits Anfang der 70er Jahre legten M. Mesarovic et al (1970) den sogenannten Mehrebenensystemansatz vor, eine Konzeption, die insbesondere von E. Jantsch (1974) fur die Planungsmethodik bzw. allgemeine Erklarungsversuche aufgegriffen wurde. In dieser Konzeption wird davon ausgegangen, das gerade im Umfeld sozio-okonomischer Systeme - aber nicht nur dort - die Methodik sich auf einen heterogenen Gegenstandsbereich einlassen mus, und das es hierbei nicht angebracht ist, nur physikalis- tische Erklarungs- und Darstellungsmuster zu berucksichtigen. Die Konzeption sieht vor, das Systeme durch unterschiedliche Ebenen mit unterschiedlichen Charakteristika modelliert werden, Ebenen, die untereinander in Kommunikations- und Austauschbeziehungen stehen, die ansonsten aber als weitgehend autark angesehen werden konnen. Neben einer „physikalischen“ werden z. B. eine „Entscheidungsebene“ und eine „Normenebene“ berucksichtigt. Wahrend auf der Ebene physikalischer Vorgange Masse- und Energietransfers eine Rolle spielen sind die Vorgange auf den anderen Ebenen symbolgesteuerte bzw. informationsverarbeitende.	simulation	Karl-Heinz Simon	1984		10.1007/978-3-642-69706-7_103		EDA	-104.66466393994617	33.04619202096822	156396
813b0faf31f40f68306b55c6f3b46487626d9918	aspekte der bildverarbeitungsgestützten lokomotion humanoider laufmaschinen	aspekte der bildverarbeitungsgest	Eines der bisher wenig behandelten zentralen Forschungsziele beim technischen humanoiden Laufen ist die Realisierung zielorientierter, perzeptionsbasierter Laufbewegungen. In diesem Beitrag wird eine an das menschliche Vorbild angelehnte Regelungsarchitektur vorgestellt. Zur experimentellen Validierung von Sensorverarbeitungsalgorithmen und Verfahren zur zielorientierten Planung von Laufbewegungen wird eine Emulationsumgebung entwickelt, die die Bewegung einer virtuellen Laufmaschine simuliert. Der Beitrag stellt Bildverarbeitungsalgorithmen zur Perzeption eines Experimental-Szenarios, ein Schrittplanungsverfahren und experimentelle Ergebnisse zur Bestatigung dieser Verfahren vor.		Oliver Lorch;Martin Buss;Franz Freyberger;Günther Schmidt	1999		10.1007/978-3-642-59708-4_3		Crypto	-104.64341164835808	32.38370509931343	156532
5e5ba683ee2abef8eb1ed1fd2d2df161f918f1e8	governance des it-sourcing bei einem finanzdienstleister	information management	Das Outsourcing von IT-Dienstleistungen wird seit einigen Jahren zumeist selektiv betrieben. Je umfassender IT-Leistungen an Sourcing-Partner vergeben werden, desto grosser sind die Anforderungen an das verbliebene IT-Management. Insbesondere wenn Entwicklung und Betrieb von (voneinander unabhangigen) Dritten durchgefuhrt werden, ist eine transparente und wirksame Steuerung durch das IT-Management zwingend notwendig, um die Leistungen der von einander unabhangigen Sourcing-Partner zu koordinieren. Die fundamentalen Koordinationsprozesse werden dabei erst durch eine systematische und ganzheitliche Ableitung einer Sourcing Governance aus der IT-Governance ermoglicht. Somit stellt eine idealtypische IT-Governance die grundlegenden Organisations- und Managementvoraussetzungen fur eine langfristige und wirtschaftliche Partnerschaft mit externen IT-Dienstleistern zur Verfugung.		Joachim Schelp;Otto Schmitz;Jörg Schulz;Matthias Stutz	2006	HMD - Praxis Wirtschaftsinform.		computer science;knowledge management;electrical engineering;information management	Crypto	-101.19106189097592	34.53451463169691	156823
307ffd53502d32cd17fc3d59e8360fa9332f5d1f	verfahren zur sicherung und wiederherstellung von datenbeständen		Die zunehmende Komplexitat und der enorme Umfang von Datenbestanden, wie sie bei modernen Datensystemen anfallen, werden zukunfig an die Integritat der Daten Anforderungen stellen, die heute noch weitgehend unbekannt sind. Zwar konnte die Zuverlassigkeit der Maschinen, der „Hardware“, gesteigert werden so das sie wesentlich unanfalliger sind als fruher, dafur treten aber neue Fehlerquellen auf, die vornehmlich im Bereich der Maschinenbedienung liegen.		D. F. Jung	1972		10.1007/978-3-642-80732-9_48	art;performance art	Vision	-105.34533738262706	33.49943665517887	156892
37d6cde8be756b70d22262f1acc3442a0c6aa7ea	kernel learning approaches for image classification	kernel;bildklassikation;algorithmus;online katalog;objekterkennung;automatische klassifikation;annotation;kernmethode;recherche;algorithm;kernel learning;ambiguitat;deutsche nationalbibliothek;object classification;maschinelles lernen;bild;mehrdeutige annotation;image classication;kernkombination;label ambiguity	This thesis extends the use of kernel learning techniques to specific problems of image classification. Kernel learning is a paradigm in the eld of machine learning that generalizes the use of inner products to compute similarities between arbitrary objects. In image classification one aims to separate images based on their visual content. We address two important problems that arise in this context: learning with weak label information and combination of heterogeneous data sources. The contributions we report on are not unique to image classification, and apply to a more general class of problems. We study the problem of learning with label ambiguity in the multiple instance learning framework. We discuss several di erent image classification scenarios that arise in this context and argue that the standard multiple instance learning requires a more detailed disambiguation. Finally we review kernel learning approaches proposed for this problem and derive a more efficcient algorithm to solve them. The multiple kernel learning framework is an approach to automatically select kernel parameters. We extend it to its infinite limit and present an algorithm to solve the resulting problem. This result is then applied in two directions. We show how to learn kernels that adapt to the special structure of images. Finally we compare di erent ways of combining image features for object classification and present significant improvements compared to previous methods. #N#In dieser Dissertation verwenden wir Kernmethoden fur spezielle Probleme der Bildklassifikation. Kernmethoden generalisieren die Verwendung von inneren Produkten zu Distanzen zwischen allgemeinen Objekten. Das Problem der Bildklassifikation ist es, Bilder anhand des visuellen Inhaltes zu unterscheiden. Wir beschaftigen uns mit zwei wichtigen Aspekten, die in diesem Problem auftreten: lernen mit mehrdeutiger Annotation und die Kombination von verschiedenartigen Datenquellen. Unsere Ansatze sind nicht auf die Bildklassififikation beschrankt und fur einen grosseren Problemkreis verwendbar. Mehrdeutige Annotationen sind ein inharentes Problem der Bildklassifikation. Wir diskutieren verschiedene Instanzen und schlagen eine neue Unterteilung in mehrere Szenarien vor. Danach stellen wir Kernmethoden fur dieses Problem vor und entwickeln einen Algorithmus, der diese effizient lost. Mit der Methode der Kernkombination werden Kernfunktionen anhand von Daten automatisch bestimmt. Wir generalisieren diesen Ansatz indem wir den Suchraum auf kontinuierlich parametrisierte Kernklassen ausgedehnen. Diese Methode wird in zwei verschiedenen Anwendungen eingesetzt. Wir betrachten spezifische Kerne fur Bilddaten und lernen diese anhand von Beispielen. Schlieslich vergleichen wir verschiedene Verfahren der Merkmalskombination und zeigen signifikante Verbesserungen im Bereich der Objekterkennung gegenuber bestehenden Methoden.	computer vision;kernel (operating system)	Peter V. Gehler	2009			computer science;artificial intelligence;algorithm	Vision	-107.38172515893581	35.496547380514585	157147
195c6118720fdba5e9471e35c06168fe527279c7	erfolgsfaktoren bei der einführung von social software in unternehmen		Evidenzbasierte Praktiken haben ih ren Ursprung in der Medizin. Hier berücksichtigen sie wissenschaftlich fundi erte Ergebnisse und in tegrieren sie in den praktischen Arbeitsalltag. Bei Evidenzbasierten Praktiken im Wissensmanagement lassen sich zwei Theorie-Praxis Lücken feststellen: zwischen Wissensmanager und Mita rbeiter und zwischen Wissensmanager und Wissenschaft. Diese beiden Lücken gilt es zu schließen, soll die Implementierung von Wissensmanagement erfolgre ich sein. Social Software wird dabei gleichzeitig als Gegenstand und als Werkzeug von Eviden zbasierten Praktiken betrachtet.	altran praxis;eine and zwei;i/o controller hub;sie (file format)	Sonja Gust von Loh;Isabella Peters	2011			social software;software engineering;computer science	OS	-102.33386752482136	32.68557180796302	157505
d215bfabe8407665e5fc6e4bf7079f03a0e4352c	"""entwicklung eines berufsbegleitenden, interdisziplinären masterstudiengangs """"ambient assisted living"""" (maal)"""		In diesem Beitrag wird das BMBF-Projekt „Entwicklung eines berufsbegleitenden, interdisziplinären Masterstudiengangs im Bereich Ambient Assisted Living – MAAL“ vorgestellt. Der Studiengang wird gemeinsam von der Alice Salomon Hochschule Berlin und der Hochschule für Technik und Wirtschaft Berlin sowie weiteren, außeruniversitären Partnern entwickelt. Es werden fachbezogene Kompetenzen vermittelt, die die Absolventinnen und Absolventen für die Entwicklung von AAL-Produkten und -Dienstleistungen sowie für die Beratung zu diesen Angeboten qualifizieren. 1 Herausforderungen für marktfähige und sinnvolle AAL-Lösungen zur Unterstützung selbstbestimmten Lebens Technik, die auch von älteren Menschen oder Menschen mit Behinderungen mühelos genutzt werden und sie im alltäglichen Leben unterstützen kann, steht in besonderer Weise in einem Spannungsfeld zwischen individuellen Bedürfnissen und Anforderungen an Standardisierung [Kl09, S. 30]. An diesem Spannungsfeld wird die Notwendigkeit von neuen Strategien, von Fachkräften und Geschäftsmodellen deutlich, die es ermöglichen, Technologien zur Alltagsunterstützung für ganz spezifische Nutzergruppen zu entwickeln. Insbesondere ältere Menschen werden eine wichtige Nutzergruppe, denn die Generation der über Fünfzigjährigen wird mit einem Anteil von 78 % im Jahr 2050 zur beherrschenden Konsumentengruppe [VD08]. Leider ist das bisherige Angebot an Produkten und Dienstleistungen oft nur bei oberflächlicher Betrachtung für ältere Menschen oder Menschen mit Behinderungen geeignet [De10, S. 125]. Dies mag auch daran liegen,	atm adaptation layer;eine and zwei;gesellschaft für informatik;mag (cryptography);mag technology co.;sie (file format)	Maxine Saborowski;Ingrid Kollak;Andrea Schuster;Gerhard Hörber	2012				OS	-103.72873446508476	37.1032707076508	157836
798b389312dfad2fef0bb76499f8cbd24370c943	gasteditorial ki und kognition		auch wenn in der KI immer wieder Einzelbeiträge aus der kognitiven KI und Themenhefte mit Bezug zu kognitionswissenschaftlichen Fragen erscheinen, ist der Abstand zwischen dem letzten Themenheft “KI und Kognition” und dem nun vorliegenden zwölf Jahre. Das Themenheft 6/1995 wurde von Christian Freksa als Gastherausgeber betreut. Im aktuellen Heft finden sich einige Beiträge aus dem SFB/TR Raumkognition dessen Sprecher Christian Freksa ist. Es ist schön zu sehen, wie sich Themen und Arbeitsgruppen in den vergangenen zwölf Jahren weiterentwickelt haben und erfreulich, dass neue Themenbereiche (zum Beispiel Analoges Schließen und humanoide Agenten) hinzugekommen sind. Über die große Resonanz auf den Aufruf zu Beiträgen aus allen Rubriken war ich sehr erfreut. Die Qualität der Beiträge und die Bandbreite der Themen zeigt, dass das Thema Kognition in der deutschen KI sehr gut abgedeckt ist. Einige Beiträge fanden leider keinen Platz mehr in diesem Heft. In folgenden Heften werden Ihnen also weiter Arbeiten aus dem Bereich der kognitiven KI begegnen: der Fachbeitrag Augmenting Cognition with a Digital Episodic Memory (Kröner et al., DFKI Saarbrücken), die Projektberichte Alignement in Communication (Rickheit und Wachsmuth, Universität Bielefeld), Virtuelle Nautiker (Strohschneider et al., Universität Jena), Multi-Modal Scene Interpretation ( Wünstel und Röfer, DFKI Bremen), Using Qualitative Semantic Representations of Spatial Knowledge in Dialogue Systems (Shi und Krieg-Brückner, DFKI Bremen), i2home – Towards an Universal Home Environment for Elderly and Disabled (Alexandersson, DFKI Saarbrücken), sowie eine Dissertation aus dem Bereich Räumliches Schließen (Gips, TU Berlin). Bereits im letzten Heft konnten Sie Tagungsberichte über das Interdisziplinäre Kolleg, die Annual Conference of the Cognitive Science Society sowie die International Conference on Cognitive Modeling lesen. Herzlich bedanken möchte ich mich bei Peter Geibel, Kerstin Schill, Christoph Schlieder und Klaus Stein für die fachliche Begutachtung der Beiträge und bei allen Autoren für die fristgerechte Lieferung ihrer spannenden Beiträge.	binary prefix;blue (queue management algorithm);borderlands 2;cognition;cognitive model;cognitive science;eine and zwei;german research centre for artificial intelligence;heterogeneous earliest finish time;i/o controller hub;institut für dokumentologie und editorik;internet explorer;ipke wachsmuth;sie (file format)	Ute Schmid	2008	KI		conductor;acoustics;materials science	Robotics	-107.83138615094104	33.661514347239255	157987
2fa544f75b5ec1db97facd6b8e21068d265167bb	algorithmische probleme bei einrelatorgruppen und ihre komplexität	word problem;complexity;algorithm;one relator groups;decidability	Das Wortproblem f'tir endlich dargestellte (e.d.) Gruppen ist eines der klassischen Entscheidungsprobleme der Mathematik. Nachdem Boone und Novikov die Unl6sbarkeit dieses Problems nachgewiesen haben, wurden unentscheidbare Gruppen mit vorgeschriebenem Grad der Unentscheidbarkeit und entscheidbare Gruppen mit vorgeschriebener Komplexit~it konstruiert [1]. Innerhalb der entscheidbaren Gruppen ist es nun interessant, bekannte e.d. Gruppen nach ihrer Komplexit~it zu klassifizieren. So sieht man leicht, dab endliche, freie, abelsche und allgemeiner alle die Gruppen, ftir die Dehns Algorithmus zur LOsung des Wortproblems anwendbar ist, linear entscheidbar sind. Weiter sind die e.d. polyzyklischen (speziell also die nilpotenten) Gruppen elementar entscheidbar [2]. Wir untersuchen in dieser Arbeit die Einrelatorgruppen. Ist G = (S;r) eine Einrelatorgruppe mit zyklisch reduziertem Relator r, in dem jeder Buchstabe mindestens zweimal auftritt, so liil3t sich G in eine HNNErweiterung einer Einrelatorgruppe G O = (S o ; ro) mit kiirzerem Relator einbetten. Diese Tatsache wird in [4] benutzt, um die LiSsbarkeit des Wortproblems bei Einrelatorgruppen zu beweisen. In der vorliegenden Arbeit soil mit verfeinerten Methoden gezeigt werden, dab dies von Magnus [3] erstmals erzielte Ergebnis stark versch~irft werden kann. Ist 8 n die n-te Grzegorczyk-Klasse von Wortfunktionen, so gilt: Ist Irl <2n, so sind das Wort-, das Potenz-, das Ordnungs- und das verallgemeinerte Wortproblem t'tir G = (S; r) ~:entscheidbar. Ist r in der freien Gruppe (S; 0) eine echte Potenz, so sind die Probleme sogar 81-entscheidbar. Die auftretenden Algorithmen werden konsequent durch Wortfunktionen beschrieben, da eine (sonst iibliche) Kodierung in den natiirlichen Zahlen unnattirlich und auch unn5tig ist.		Jürgen Avenhaus;Klaus Madlener	1978	Arch. Math. Log.	10.1007/BF02011863	decidability;word problem;discrete mathematics;complexity;mathematics;algorithm	Theory	-99.3324074904496	36.557452355982456	158879
5642739cbf98e401849558d9f6fa5c2d60a4384f	preisfindung von it-produkten durch retrograde kalkulation		Mit dem Übergang von der Individualsoftwareentwicklung auf die Entwicklung von Software-Produkten ändern sich auch die Anforderungen an die Abrechnung der betreffenden Dienstleistungen. Während die Abrechnung von Softwareentwicklungsleistungen zumindest früher zumeist „nach Aufwand“ erfolgte – Preis gleich Aufwand plus Gewinnaufschlag (s. u.) wird für Standardsoftware wie für andere Produkte ein bestimmter Preis definiert. Die Bestimmung eines (Fest-)Preises ist aufgrund unzuverlässiger Aufwandschätzung in der Praxis auch bei Individualsoftwareentwicklungen eine wichtige Option. Darüber hinaus gibt es immer mehr industriell gefertigte Produkte, deren Wertschöpfung durch Software bestimmt wird und andererseits spezifische Softwaresysteme, die in eine bestimmte Hardwareplattform eingebettet sind. Die Verfahren für die Kalkulation und Preisfindung1 industrieller Produkte lassen sich jedoch nicht ohne weiteres auf Software-Produkte übertragen. Eine klare Abgrenzung und Zuordnung funktionaler Elemente aufgrund der unterschiedlichen Technologien ist schwieriger und die Funktionen werden aufgrund der Immaterialität von Software anders bewertet. Dies gilt prinzipiell für alle IT-Produkte, d. h. für softwareintensive Produkte mit oder ohne Hardwareanteile. Bei der Bestimmung des Preises von IT-Produkten	altran praxis;eine and zwei;internet explorer	Georg Herzwurm;Benedikt Krams;Wolfram Pietsch	2010			performance art;art	OS	-104.89053610422022	33.744511859266375	158920
1ffe5ce89f7c2de3e68fa7ea5bc6d824ab85875b	ein integrierender ansatz zur computergestützten arzneimittelentwicklung				Elke Lang;Claus-Wilhelm von der Lieth	1994			quantum electrodynamics;ansatz;mathematics	ML	-97.11881710436874	33.853520236048745	158959
ea4f4cdf1d9243bf1d08346c2ae3e7733ef90d8f	arbeiten zum datenschutz im it-grundschutz vorläufig abgeschlossen		Nach mehreren Ansätzen in den vergangenen Jahren ist es jetzt gelungen, die Arbeiten zur Integration des Datenschutzes in den IT-Grundschutz zu einem Abschluss zu bringen. Nach den Datenschutzbeauftragten des Bundes und der Länder haben jetzt auch die Aufsichtsbehörden für den nichtöffentlichen Bereich untereinander die Arbeitsentwürfe abgestimmt. Die gemeinsam erarbeiteten Endfassungen liegen jetzt vor.	vhf omnidirectional range	Claus Simon	2007	Datenschutz und Datensicherheit - DuD	10.1007/s11623-007-0170-5	computer security;computer science;internet privacy	Crypto	-103.73843197768014	36.275251159110354	159487
2a3c1ffa904c1f6daa72ef35f29f2ac46f0e9450	bedürfnislandschaft älterer menschen in österreich		Im Rahmen eines Forschungsprojekts mit dem ÖIAT und B-NK wurden in einer Cultural Probe Studie die Bedürfnisse älterer, zuhause lebender Menschen (60+) in Österreich erforscht. Die Testpersonen dokumentierten ihre Wünsche, Bedürfnisse und Ärgernisse und lieferten zahlreiche Anknüpfungspunkte für die Entwicklung von mobilen Apps für SeniorInnen. Die dominierenden Themen waren hierbei Unterstützung im Haushalt, Medizinisches, Gartenarbeit, sowie soziale Kontakte und Familie.	mit computer science and artificial intelligence laboratory	Dorothea Erharter;Elka Xharo	2015				Robotics	-106.52437079373365	33.72924852494539	159489
7feac26aa70aaa954f82a72b158413a25fdd9fe0	vorgehensmodelle und reifegradmodelle - ergänzung oder konkurrenz?		Für Unternehmen, die ihre Entwicklungsprozesse systematisieren und verbessern wollen, gibt es zwei verbreitete Werkzeuge, die gelegentlich als Konkurrenz verstanden werden, nämlich Vorgehensmodelle und Reifegradmodelle. Bei genauer Betrachtung zeigt sich aber, dass diese beiden Ansätze sich hervorragend ergänzen: Vorgehensmodelle liefern die Details der Umsetzung, die in Reifegradmodellen fehlen, während umgekehrt Reifegradmodelle eine Vorgehensweise zur Einführung und Umsetzung von Vorgehensmodellen enthalten.	eine and zwei;gesellschaft für informatik	Ralf Kneuper	2007			history;performance art	NLP	-104.33316367745233	33.84237543924817	160000
11c32f642cee7e5510056a789cd3655f3c992eba	ganzheitliche ingenieurausbildung		1. Einleitung Es hat etwas von einer verkehrten Welt: Auf die Frage, was der technischen Ausbildung in besonderer Weise helfen kann, „zukunftstauglich“ zu sein, kommt in letzter Zeit oft die Antwort, weniger in die technischen, sondern in die kommunikativen sowie sozialund persönlichkeitsbildenden Bereiche zu investieren. Die technische Ausbildung wird als gut bis zufriedenstellend anerkannt, aber die Zukunft der ausgebildeten Ingenieure ist oft ungewiss und verlangt von den zukünftigen Absolvent/innen ein hohes Maß an beruflicher Flexibilität. Es reicht offensichtlich nicht mehr, nur im technischwirtschaftlichen Bereich gut zu sein, sondern die entwickelten Kompetenzmodelle drängen darauf, neben der Fachund Methodenkompetenz auch soziale und personale Kompetenzen als weiteres, möglicherweise am Beginn etwas unsicheres Standbein auf den Berufsund Lebensweg mitzugeben. So könnte man sagen, dass zu den wichtigsten Entdeckungen der letzten HTL-Lehrplangeneration die ganzheitliche Ingenieurausbildung und die Wiederentdeckung des Erfolgsfaktors Persönlichkeit zählen. Arnold und Müller (1992) definieren in einer Arbeit aus den 1990er Jahren die Ganzheitlichkeit als Aufhebung von Gegensatzpaaren in der Bildungsdiskussion:	arnold;high threshold logic	Christian Dorninger	2015	Elektrotechnik und Informationstechnik	10.1007/s00502-015-0332-3		DB	-105.57622179171086	33.9080870919898	160033
a85cba087d9f790f8ac821693bf31274baab9cad	mitteilungen der schweizer informatik gesellschaft / 3_2011		Neue Fachgruppe: The SEE Group Die sich neu konstituierende Fachgruppe ,,The SEE Group“ hat zum Ziel, die quantifizierbaren und ökonomischen Aspekte von ITProjekten, Wartung und Betrieb von IT Systemen zu beleuchten. SEE steht für Software Estimation and Economics. Dabei steht die empirische Datensammlung (d. h. Projekt-Nachkalkulationen) und die Datenpublikation für die Community im Vordergrund der geplanten Aktivitäten. Die Hauptanwendung der empirischen Datensammlung ist die Aufwandund Termin-Schätzung bzw. -Überprüfung für anstehende Projekte. Die entsprechenden Methoden (v. a. parametrische Verfahren wie die Function Point Methode oder die System Meter Methode) sind auch im Fokus von ,,The SEE Group“. Diese Fachgruppe ist ein re-launch einer bereits seit 1997 existierenden Vereinigung gleichen Namens. Diese hat unter anderem bereits eine Erfahrungsdatenbank mit über 600 Projekten (Abschlussdaten 1996–2010) aufgebaut, welche übernommen werden kann. The SEE Group präsentierte sich am 11.5.2011 anlässlich der Generalversammlung der SI in Bern. Weitere Informationen unter www.theseegroup.org.	citeseerx;cost estimation in software engineering;eine and zwei;function point;gesellschaft für informatik;internet explorer	Bernhard M. Hämmerli;programmieren Schildkröten;Irena Kulka	2011	Informatik-Spektrum	10.1007/s00287-011-0544-9	software engineering;world wide web;computer science	AI	-101.22625741320785	32.65177853163253	160112
7985c31928c9db3fef5a057a6eb9977f67bdb4a4	wer macht eigentlich requirements engineering & management?		Rollen als Teile eines Vorgehensmodells dienen dazu, Aufgaben und Verantwortlichkeiten eindeutig und optimal Personen zuzuweisen. Da das Requirements Engineering und Management (RE&M) wichtig ist, gibt es bei vielen jedoch nicht allen Vorgehensmodellen eine oder mehrere Rollen, die das RE&M durchführen. Tatsächlich ergeben sich in der Praxis einige Schwierigkeiten bei der Arbeit im RE&M aufgrund von suboptimalen Rollendefinitionen oder dem Fehlen von solchen. Dieser Artikel diskutiert solche Schwierigkeiten anhand von zwei Studien.	altran praxis;eine and zwei;requirement;requirements engineering	Andrea Herrmann;Rüdiger Weißbach	2013			philosophy;requirements engineering;performance art	DB	-101.85535049965038	33.33866850217478	160341
2b3ea6217a345dafdcd6aa931e8e240329c30a9a	optimale portefeuilles für institutionelle anleger		Zusammenfassung Mit Hilfe der Standardmethode von Markowitz werden optimale Portefeuilles für Pensionskassen und Lebensversicherungen aufgrund von schweizerischem Datenmaterial beberechnet. Dem Umstand, daß es sich um institutionelle Anleger handelt, wird durch die Wahl der Daten Rechnung getragen. Es stellt sich heraus, daß die optimalen Portefeuilles sowohl bei einer nominellen als auch bei einer realen Zielsetzung stets einen geringen Aktienanteil aufweisen. Zudem fällt der Effizienzverlust, welcher aus einer nominellen Zielsetzung der institutionellen Anleger und einer realen Zielsetzung der Versicherten resultiert, extrem klein aus.		Heinz H. Müller;René Capitelli;Markus J. Granziol	1984	Zeitschr. für OR	10.1007/BF01920508	decision theory;modern portfolio theory;statistics;project portfolio management	NLP	-98.49554957475569	35.132030107474144	160663
98ee2a2c05ff8c55adc1418da531129341c4169f	erlernen logischer entscheidungsfunktionen bei gestörtem angebot				Ulrich Rösler;Wolfgang Uebel	1974	Elektronische Informationsverarbeitung und Kybernetik		pure mathematics;combinatorics;mathematics	NLP	-95.48257417177999	34.35619000394389	161163
b6aaac3f006884e405df9f6627132c2d27e96de2	benutzerzentrierte entwicklung für das internet der dinge		In diesem Artikel diskutieren wir Möglichkeiten für die Umsetzung datenschutzfreundlicher und sicherer Lösungen für das Internet der Dinge unter besonderer Berücksichtigung der Benutzbarkeit. Als entscheidendes Moment für die angestrebte Nutzerakzeptanz erweist sich dabei ihre frühzeitige Einbeziehung — bereits in der konzeptionellen Phase der Entwicklung von Systemlösungen.	internet	Marian Margraf;Stefan Pfeiffer	2015	Datenschutz und Datensicherheit - DuD	10.1007/s11623-015-0404-x	the internet;internet privacy;computer science	OS	-103.84837547003934	36.49234409340764	161411
918b882a6829c8b5004314b7de1f058806f1aaa3	nutzenpotenziale maßgetreuer 3d-avatare aus low-cost-bodyscannern		Der Einsatz realitätsnaher dreidimensionaler Modelle des menschlichen Körpers (sog. Avatare) wird seit Mitte der 90er-Jahre für unterschiedlichste Anwendungen diskutiert. Eine kommerzielle Umsetzung scheiterte in der Vergangenheit jedoch oft an den Kosten von 3D-Scannern. Neue technologische Innovationen, insbesondere die von der Unterhaltungsindustrie forcierte Entwicklung preiswerter Tiefensensoren, führen nun dazu, dass 3D-Scanner heute zu einem Bruchteil der Kosten entwickelt werden können. So entsteht die Möglichkeit für den breiten Einsatz von Avataren in aufgabenorientierten und nicht aufgabenorientierten Kontexten und damit ein enormes betriebswirtschaftliches Potenzial.	3d scanner;eine and zwei	Christian Zagel;Jochen Süßmuth	2013	HMD Praxis der Wirtschaftsinformatik	10.1007/BF03342068	marketing;engineering;performance art	OS	-102.67960501670878	33.99467136339339	161437
88c13b3fd4b9c19b460bacfb5cb40658d591016c	database and expert systems applications		Die Online-Fachbuchhandlung beck-shop.de ist spezialisiert auf Fachbücher, insbesondere Recht, Steuern und Wirtschaft. Im Sortiment finden Sie alle Medien (Bücher, Zeitschriften, CDs, eBooks, etc.) aller Verlage. Ergänzt wird das Programm durch Services wie Neuerscheinungsdienst oder Zusammenstellungen von Büchern zu Sonderpreisen. Der Shop führt mehr als 8 Millionen Produkte.	database;expert system;internet explorer;sie (file format)	Bearbeitet Von;Heinrich C. Mayr;Jirí Lazanský;Gerald Quirchmayr;Pavel Vogel	2004		10.1007/b99664		DB	-105.48759683145016	35.84782664885945	161562
3961f7f67792a36da9890c4da8b756c07b3f3cba	die berücksichtigung von festterminrestriktionen bei der projektplanung und -steuerung		In der einfachen Netzplantechnik werden Limitierungen durch Festtermine nicht berucksichtigt. Alle denkbaren Arten von Festterminrestriktionen werden in der vorliegenden Arbeit analysiert, ihre Bedingungskonstellationen erarbeitet sowie die Moglichkeiten und Auswirkungen der Berucksichtigung derartiger Festterminrestriktionen fur beliebige Ereignisse bei der Projektplanung und -steuerung dargestellt.		M. Ullrich	1978	Zeitschr. für OR	10.1007/BF01917671	mathematical physics;discrete mathematics;mathematics	Vision	-97.15966989002665	34.67720197054409	161568
15761fb10da926526cd3c50b84468c3c06a9f39a	erfolgsfaktoren für effektives e-lerning - ergebnisse einer empirischen studie		Web-basierte Trainings werfen viele Fragen auf bezüglich des zu erwartenden Nutzungsverhaltens von Kursteilnehmenden. Bisher liegen nur wenige Studien mit wenigen Aussagen darüber vor, wie Web-basierte Trainings im Rahmen berufsbegleitender Weiterbildungsmaßnahmen genutzt werden. Auf Basis einer Analyse des Nutzungsverhaltens von Studenten des Studienganges WINFOLine macht der vorliegende Beitrag Aussagen über Nutzungsprofile, bevorzugte Diskussionsfunktionen, die Rolle von Übungsaufgaben sowie die Intensität der Nutzung von Teilen des Kursangebotes. Diese Aussagen werden mit dem Lernerfolg der Teilnehmenden in Beziehung gesetzt um so Einflussfaktoren zu identifizieren, deren Berücksichtigung zur Verbesserung zukünftiger Lernangebote beitragen kann.	gesellschaft für informatik;internet explorer;unified model;vhf omnidirectional range	Ines Grützner;Claudia Hebestreit;Dietmar Pfahl;Carsten Vollmers	2004				Crypto	-103.9403074976015	33.05233882239341	161700
eb37c6cbc4734410327687d633f57fa10e3c8fdc	interaktive videos als neues medium für das elearning		Der Einsatz von Videos in eLearning-Applikationen wird zunehmendforciert. Es istdavon auszugehen, dass im Internet zukünftig die Bedeutung der Videotechnologie sogar noch zunehmen und der Interaktivität dabei eine besondere Rolle zukommen wird. Die Interaktivität in videogestützten eLearning-Anwendungen wird derzeit noch wenig genutzt, obwohl dadurch ein exploratives, situiertes und problemorientiertes Lernen gut unterstützt werden kann. Der Nutzer eines interaktiven Videos (auch als »Hypervideo«, »dynamisches Video« oder »clickable Video« bezeichnet) kann sich, ähnlich wie beim hypertextbasierten Lernen, die für ihn relevanten Informationen mithilfe der interaktiven Funktionen heraussuchen und je nach verwendeten Interaktionsele-menten auch aktiv mit dem Video arbeiten. Dieser Beitragführt kurz in die Technologien und die besonderen Herausforderungen ein, die mit der Erstellung interaktiver Videos verbunden sind, und bietet einen Überblick über die aktuelle Verbreitung und Nutzung interaktiver Videos im Bereich eLearning. Darauf aufbauend wird ein neu entwickeltes Tool zur Realisierung interaktiver Videos vorgestellt und es werden erste Erfahrungen in der Unterrichtsanwendung präsentiert.	clickable;die (integrated circuit);eine and zwei;hypervideo;internet explorer	Franz Lehner	2011	HMD Praxis der Wirtschaftsinformatik	10.1007/BF03340549	knowledge management;hypervideo;world wide web;clickable;engineering	OS	-107.41900241149771	34.45477185230905	161900
58bce09e8420b3e723dc9f85dff88910c3131630	polynomially solvable cases of the traveling salesman problem and a new exponential neighborhood	traveling salesman problem;rattachement tour;optimal solution;assignment problem;temps polynomial;subtour patching;travelling salesman problem;multichemin;temps lineaire;tiempo lineal;problema viajante comercio;permutation cyclique;minimum distance;probleme commis voyageur;linear time;polynomial time;voisinage exponentiel;distance matrix;asymmetric traveling salesman problem;matrice monge;tiempo polinomial	LetA=(a ij ) be the distance matrix of an arbitrary (asymmetric) traveling salesman problem and let τ=τ1τ2...τ m be the optimal solution of the corresponding assignment problem with the subtours τ=τ1τ2...τ m . By choosing (m−1) transpositions (k, l) withk ∈ τ i−1,l ∈ τ i (i=2, ...,m) and patching the subtours by using these transpositions in any order, we get a set of cyclic permutations. It will be shown that within this set of cyclic permutations a tour with minimum distance can be found by O(n 2|τ|* operations, where |τ|* is the maximum number of nodes in a subtour of τ. Moreover, applying this result to the case whenA=(a ij ) is a permuted distribution matrix (Monge-matrix) and thepatching graph G τ is a multipath, a result of Gaikov can be improved: By combining the above theory with a result of Park alinear algorithm for finding an optimal TSP solution can be derived, provided τ is already known. Es sieA=(a ij ) die Entfernungsmatrix eines (asymmetrischen) Rundreiseproblems und τ=τ1τ2...τ m die Optimallösung des zugehörigen Zuordnungsproblems mit den Teilzyklen τ=τ1τ2...τ m . Wählt man (m−1) Transpositionen (k, l) mitk ∈ τ i−1,l ∈ τ i (i=2, ...,m) und verknüpft man die Teilzyklen unter Zuhilfenahme dieser Transpositionen in beliebiger Ordnung, so erhält man eine Menge zyklischer Permutationen. Es wird gezeigt, daß man die kürzeste Tour in dieser Menge von Rundreisen mit einem Rechenaufwand von O(n 2|τ|* Operationen bestimmen kann, wobei |τ|* die maximale Anzahl von Städten in einem Teilzyklus von τ ist. Im Falle, daß die EntfernungsmatrixA=(a ij ) eine permutierte Verteilungsmatrix (Monge-Matrix) und der VerknüpfungsgraphG τ ein mehrfacher Weg ist, kann ein Resultat von Gaikov verbessert werden. In Verbindung mit einem Resultat von Park führt die oben entwickelte Theorie in diesem Fall zu einemlinearen Verfahren zur Bestimmung einer optimalen Rundreise.	algorithm;assignment problem;cyclic permutation;decision problem;distance matrix;eine and zwei;monge array;multipath propagation;time complexity;travelling salesman problem;triple des;zur farbenlehre	Rainer E. Burkard;Vladimir G. Deineko	1995	Computing	10.1007/BF02253612	time complexity;mathematical optimization;combinatorics;mathematics;travelling salesman problem;algorithm	Theory	-98.3140880661898	36.51233449723191	161944
f4c7a688dbd95cc0076f25471a6eff1c062a2f58	eine methode zur dreidimensionalen geometrischen modellierung von gebäden	von geb	Die Grundlage fur die Eingabe der geometrischen Gebaudeinformation in den Rechner ist ein Modell des Grundrisses. Dieses besteht aus einem planaren Graphen, dessen Kanten mit einem Gebaudeelementcode markiert sind. Knoten und Kanten besitzen Attribute, die bestimmte geometrische Eigenschaften der Gebaudeelemente beschreiben. Eine erste automatische Modellierungsfunktion uber der Linienstruktur des Graphen erzeugt eine zweidimensionale polygonale Grundrisstruktur. Die zweite Funktion uber den Polygonen erzeugt durch vertikale Verschiebeoperationen ein dreidimensionales Modell des Gebaudes.	eine and zwei	Ch. Riepl	1982		10.1007/978-3-642-69027-3_10	mathematical optimization;mathematical physics;mathematics	NLP	-97.46021837200072	35.15274116763667	162122
bfcbb7e35241ec2a34b7632a27d8cfda9204d1c8	professionelles übersetzen mit star transit.		Transit (Translate it) ist ein professionelles Translation-Memory (TM) System entwickelt auf der Basis der langjährigen praktischen Erfahrung von STAR, eines der größten und erfolgreichsten Übersetzungsunternehmens der Welt. Die Kunden von STAR kommen aus der Automobilindustrie, der Informationstechnologie und dem Bereich Maschinenbau. Transit, das seit 1994 kommerziell als Produkt vertrieben wird, kommt Ende 1999 als 32-Bit-Version mit Unicodeund XMLUnterstützung als Version 3.0 auf den Markt.1	32-bit;translation memory;xerox star	Judith Klein	1999	LDV Forum		information retrieval;computer science	OS	-103.63475951594666	34.41433480629589	162541
0ac891f181502ce0ae12e410b1cc01096094d304	sicherheitsverfahren für girokonten beim massenverkehr im internet-banking: sicherheit vs. bedienerfreundlichkeit, ein widerspruch?			online banking	Salim Güler	2012				NLP	-102.64612250264891	37.07196166646987	162749
07bdc4c4849a5daf67227daf03792676ac300378	thesen zur künftigen struktur der dv-versorgung an der humboldt-universität zu berlin (hub)		"""Der Verein „Zentren für Kommunikation und Informationsverarbeitung in Lehre und Forschung"""" (ZKI) existiert nun etwas mehr als ein Jahr. Wir haben uns u.a. als Ziel gestellt, den Informationsaustausch und die Diskussion bis hin zum Erarbeiten gemeinsamer Dokumente auf eine qualitativ höhere Stufe zu heben. Ob wir das auch erreichen, wird man viel später einzuschätzen haben. Betrachten Sie den vorliegenden Artikel als einen solchen Beitrag zum Informationsaustausch. Die aufgeführten Thesen sind nicht als beschlossene Linie des Handelns zu verstehen, sondern als Denkanstöße und Beginn der Fortschreibung der DV-Konzeption der Humboldt-Universität."""	eine and zwei;sie (file format);zur farbenlehre	Peter Schirmbacher	1995	Praxis der Informationsverarbeitung und Kommunikation	10.1515/piko.1995.18.1.47	computer science;engineering physics;distributed computing	OS	-104.35256724078425	34.69298921306562	162762
de1a151c8b854a5d7ff83ebb5d81ef1a954ca294	vorwort: isih'08: informationssysteme in industrie und handel - erp und collaborative business		Das Thema Collaborative Business beschäftigt sich in einer unternehmensübergreifenden Sicht mit der Verbindung von Anwendungssystemen innerhalb von Wertschöpfungsnetzwerken. Im Zentrum steht dabei das unternehmensinterne ERP-System, das zunehmenden Anforderungen an unternehmensübergreifende Integration ausgesetzt ist. Vor allem im Bereich von papierlosen Geschäftsdokumenten besteht noch ein großes Verbesserungspotenzial bei Prozessen zwischen Kunden und Lieferanten, sowohl in großen Unternehmen als auch zunehmend im Mittelstand.	erp;handel;vhf omnidirectional range	Peter Loos;Norbert Gronau;Petra Schubert	2008			strain gauge;nuclear power plant;wheatstone bridge;corrosion;software engineering;cantilever;systems engineering;engineering;mechanical engineering	DB	-100.69206987041207	32.646894183962914	162792
aea6396924f2dd64f6aa91e851b5ec2d80dcaa28	product placement, markengedächtnis, markenimage (2)		Zusammenfassung. Nach einer Untersuchung von Bock und Gomez Izquierdo (2006) ist die Wirksamkeit des Product Placement gering, weil Markenprodukte dabei kaum beachtet werden. In einer Folgeuntersuchung haben wir deshalb die Aufmerksamkeit variiert, indem unsere Teilnehmer/innen bei einem James-Bond-Film zwei unterschiedliche Aufgaben erhielten. Bei der ersten Aufgabe sollten sie auf James Bond achten, bei der zweiten auf Markenplatzierungen. Theoretischer Hintergrund war ein Modell, das zwei mogliche Wirkungswege des Product Placement beschreibt: einen expliziten Weg, der eine Beachtung der Markenplatzierungen erfordert, und einen impliziten Weg, der davon unabhangig ist. Tatsachlich wurden die Markenplatzierungen jedoch nur auf dem expliziten Weg wirksam, sichtbar an den expliziten Markenerinnerungen. Die impliziten Markenerinnerungen und die Markenimages wurden dagegen nicht verbessert. Abschliesend wird deshalb diskutiert, wie sich die Wirksamkeit des Product Placement auf dem impliziten Weg verbessern...		Michael Bock;Bettina Kirchgäßner;Viola Seeliger	2006	Zeitschrift für Medienpsychologie	10.1026/1617-6383.18.4.146	humanities;political science	EDA	-104.67135241575656	34.90845145315343	162957
01c4c39728c86ef99d3321aa5f176fc0eda0759b	nachhaltigkeit durch energiecontrolling		Nachhaltigkeit in ihrer ökonomischen, ökologischen und sozialen Dimension kann durch unterschiedliche Maßnahmen erreicht werden. Maßnahmen zur Energieeffizienz sind ein wesentlicher Bestandteil, dessen Potentiale von ausgewiesenen Experten als überdurchschnittlich eingestuft werden. Um Maßnahmen ergreifen zu können, bedarf es jedoch der Transparenz bei energierelevanten Größen. Auch wenn der Return on Investment für ein IT-System zum Energiecontrolling im Vorhinein schwer zu berechnen ist, zeigt das Fallbeispiel, wie sich mit geringem Aufwand signifikante Effizienzpotentiale heben lassen. 1 Nachhaltigkeit und Energiemanagement nur Trends? Der Begriff der Nachhaltigkeit (engl. Sustainability) ist seit geraumer Zeit in aller Munde. Nachhaltiges Handeln ist dabei immer durch das Gleichgewicht bzw. die Berücksichtigung der ökonomischen, ökologischen und sozialen Auswirkungen geprägt. Gesellschaftlich genießt nachhaltiges Wirtschaften den höchsten Stellenwert, da die Umwelt und Ressourcen geschont werden, Arbeitsplätze erhalten bleiben und gleichzeitig wirtschaftliches Wachstum erzielt wird. Eberhard Jochem vom FraunhoferInstitut für Systemund Innovationsforschung ist der Meinung, dass Klimaund Umweltschutz mit wirtschaftlichem Wachstum sich nicht widersprechen, sondern mit entsprechendem Einsatz und Know-How möglich ist. Der Informationsund Kommunikationstechnik kommt in diesem Zusammenhang eine bedeutende Rolle zu. Dem Begriff des Informationssystems folgend (vgl. [FS06], S. 1, [HN04], S. 84) stellt ein IT-System für das Thema „Energie“ Funktionen zur Erfassung, Übertragung, Transformation, Speicherung und Bereitstellung von kontextbezogenen Daten bereit. Da Energie in nahezu allen Unternehmensprozessen eine Rolle spielt, ist eine integrierende Funktion eines solchen Informationssystems für den zunehmend zum Wettbewerbsfaktor werdenden Themenbereichs „Energie“ notwendig. Die nachfolgende Abbildung enthält einen Überblick der energierelevanten Aspekte in Anlehnung an die grundlegenden Unternehmensprozesse nach Porters Definition der Wertschöpfungsbzw. Wertkette (vgl. [Po85]).	eine and zwei;internet explorer;unified model	Stephan Niggemann	2010			business	OS	-101.74128955425637	34.53848822818089	163081
9f2637be74375d9efe0c606e80aef698ddeb0a6f	an industry case study on semi-automated generation of component fault trees from simulink-models		Kurzfassung: Seit mehreren Jahren wird an einer stärkeren Integration von modellbasierter Systementwicklung und Sicherheitsanalyse geforscht. In diesem Paper werden ein Ansatz und ein Werkzeug zur besseren und frühzeitigen Verzahnung zwischen der Systementwicklung und der Sicherheitsanalyse präsentiert. Im Vordergrund des Ansatzes steht die Verknüpfung der in der Industrie etablierten Werkzeuge für die Systemmodellierung (Matlab Simulink) und die Sicherheitsanalyse (Enterprise Architect). Ziel war es, die hierarchische Struktur von Komponenten-Fehlerbäumen (engl. Component Fault Trees/ CFTs) aus existierenden Simulink-Modellen zu generieren. Ein Transformationsalgorithmus, welcher die hierarchische Struktur und Signalflussinformationen von Simulink-Modellen analysiert und anschließend CFT-Rahmen mit möglichen Fehlermodi in Abhängigkeit von den in Simulink vordefinierten Signaltypen bildet, wurde im Rahmen einer Masterarbeit entwickelt. Anhand eines Fallbeispiels an einem vereinfachten elektrischen Antriebs für E-Fahrzeuge werden in diesem Paper die Vorgehensweise des Ansatzes sowie Erfolge und angetroffene Probleme erläutert.	enterprise architect;fault tree analysis;matlab;semiconductor industry;simulink	Suryo Buono;Viktor Ramich;Bernhard Kaiser;Justyna Zander	2015			fault tree analysis;reliability engineering;computer science	NLP	-101.26966354871217	32.604312382907416	163097
c1997c7abb0b7ae18e1a67668e822d5ca784d7d1	unternehmensarchitektur und digitalisierung		Enterprise Architecture Management ist im Wandel begriffen: Die Auswirkungen einer immer schneller werdenden Welt sind deutlich erkennbar. Da Transformationsplanung – von der Strategie zur Umsetzung – seit jeher zu den Kernfähigkeiten eines Architekturmanagements gehört, kann diese Disziplin viel zum Thema digitale Transformation beitragen, wenn es ihr gelingt, sich zeitgemäß und zielgerichtet aufzustellen. Im Rahmen einer Studie wurden Architekturmanagementorganisationen zu ihrer aktuellen Selbsteinschätzung befragt. Dabei wurde besonderer Wert auf solche Einflussfaktoren gelegt, die für das Thema Digitalisierung von hoher Bedeutung sind. Die Einflussfaktoren wurden im „Enterprise Architecture Digital Readiness Framework“ strukturiert. Aus der Studie wurden Defizite aktueller Architekturmanagementorganisationen abgeleitet: Die befragten Architekturmanagementorganisationen leiden unter unzureichenden Kenntnissen über ihre Kunden, haben wenig Praxis im Hinblick auf Methoden zur Erhebung und Modellierung von Geschäftsmotivation und Geschäftsmodell, liefern wenig Unterstützung und Initialbeschleunigung für Digitalisierungsprojekte und sie haben keine ausreichende Feedbackkultur. Auf dieser Basis wurden Lösungsansätze in den Bereichen Kundenschnittstelle, Qualifizierung, Optimierung des operativen Architekturmanagements und Feedbackkultur entwickelt, die im Überblick dargestellt werden. Der Ausblick will aufzeigen, wohin sich das Architekturmanagement der Zukunft entwickelt. Enterprise Architecture Management is changing: The effects of a world becoming faster day by day are clearly visible. Since transformation planning – from strategy to implementation – has always been one of the core skills of architecture management, this discipline can contribute a lot to the topic of digital transformation if it succeeds in positioning itself in a contemporary and targeted manner. As part of a study, architecture management organizations were asked about their current self-assessment. Special emphasis was placed on such influencing factors that are of great importance for the topic of digitalization. The influencing factors were structured in the “Enterprise Architecture Digital Readiness Framework“. Deficits of current architecture management organizations were derived from the study: The architecture management organizations surveyed suffer from insufficient knowledge of their customers, have little practice in methods for collecting and modeling business motivation and business models, provide little support and initial acceleration for digitalization projects, and do not have an adequate feedback culture. On this basis, solutions were developed in the areas of customer interface, qualification, optimization of operative architecture management and feedback culture, which are presented in an overview. The outlook wants to show where the architecture management of the future is heading.	altran praxis;chlorpheniramine maleate 1.25 mg oral capsule [haben herb];cwts leiden ranking;coagulum lysis:prthr:pt:ppp:ord:coag;course (navigation);dopamine;enterprise architecture management;feeling/behaving old/senile;gavia immer;lymphocyte activation;mathematical optimization;microsoft outlook for mac;modified rano van den bent glioma 2011 oncology response criteria;osteoarthritis, spine;patient transportation request:find:pt:^patient:doc;sie (file format);self-assessment;tricyclic antidepressants tested for:prid:pt:ur:nar:screen;tricyclic antidepressants tested for:prid:pt:ur:nom:screen;zur protein, e coli	Klaus D. Niemann	2018	HMD Praxis der Wirtschaftsinformatik	10.1365/s40702-018-00441-1	knowledge management;library science;engineering	DB	-99.88067138292303	33.903572308600545	163326
c58dd079030848423427911937165c850672ca03	zum prinzip der objektdarstellung in sgml	markup language	SGML ist eine Metasprache die geeignet ist Texte in natürlicher Sprache mit zusätzlichen Strukturen zu versehen und somit die Voraussetzung zu schaffen Volltextindexierungen in einer Weise vorzunehmen, wie dies bislang nicht möglich war. Der rasant zunehmende Bekanntheitsgrad der SGML liegt zweifellos an der bekanntesten Document Type Definition (DTD) im Rahmen der SGML, der Hypertext Markup Language (HTML), wie wir sie im Internet finden. Darüber hinaus erfüllt SGML je nach DTD die Bedingungen, die Objektorientiertheit unserer natürliche Sprache mit ihren definierbaren Begriffen sinnvoll zu unterstützen und beispielsweise mit Hilfe der objektorientierten Programmiersprache JAVA zu verarbeiten. Besonders hervorzuheben ist die sich damit verändernde Publikationsform bei wissensbasierten Texten, in denen SGMLDokumente nicht mehr nur für sich zu betrachten sind, wie Zeitschriftenaufsätze oder Bücher, sondern die darüber hinaus in Form von Wissenselementen in einer Datenund Wissensbank organisiert und recherchierbar zu machen sind.	eine and zwei;html;internet explorer;java;sie (file format);standard generalized markup language	Iris Schwarz;Walther Umstätter	1997			document type definition;programming language;markup language;database;html;sgml;computer science	DB	-105.84342200017907	35.58339312012787	163361
0adc44d2a61b064bf99ff6b4d48506b2b7e61d76	on the optimality of (z, z)-order-policies in adaptive inventory control	inventory model;inventory control	Zusammenfassung: Es wird ein zu diskreten Zeitpunkten inspiziertes Ein-Produkt-Lagerhaltungsmodell betrachtet, bei dem die Nachfrageverteilung in jeder Periode gesch~itzt wird aufgrund des Sch/itzers der vorangehenden Periode und der dort beobachteten Nachfrage. Es werden hinreichende Bedingungen ftir die Optimalitiit einer (z (t), Z (t))-Bestellpolitik gegeben, die sich bei Vorgabe des Sch~itzers t wie eine von den Lagerhaltungsmodellen unter Risiko her bekannte (s, S)-Bestellpolitik verh~ilt.	eine and zwei;internet explorer;inventory control;triple des	Karl-Heinz Waldmann	1980	Zeitschr. für OR	10.1007/BF01920272	inventory control;simulation;mathematics	OS	-98.363965224507	35.193034473045984	163423
2689ae4cb3a35498850f7e1ffd76bc9dcc49c506	persönliche verantwortung und haftungsrisiken von it-verantwortlichen-strafrechtliche aspekte		Die Nutzung von Computern, Internet und E-Mail im Geschäftsleben hat in den letzten Jahren rasant zugenommen. Der Einsatz dieser Informationssysteme geht einher mit der Vernetzung der Datenverarbeitung in den Betrieben. Waren in der Vergangenheit nur einzelne betriebliche Funktionen, wie Buchführung oder Gehaltsabrechnung in ein EDV-System integriert, verfügen heute zahlreiche Arbeitnehmer eines Unternehmens über einen an ein Netzwerk angeschlossenen Computer am Arbeitsplatz. Zumeist besitzt dieser durch das Internet auch Kontaktmöglichkeiten über den unternehmensinternen Bereich hinaus. Die explosive Entwicklung wirft nicht nur eine Vielzahl technischer, sondern auch rechtlicher Fragen auf. In den vergangenen Jahren wurden zahlreiche Rechtsvorschriften erlassen, die unmittelbare Handlungspflichten und Haftungsvoraussetzungen für den Bereich des Datenschutzes, der Datenverarbeitung und Datenübertragung festlegen. Diese Normen finden sich über die verschiedensten Gesetze verstreut und sind untereinander zum Teil disharmonisch. Die Neuigkeit des Rechtsgebietes und der zu regelnde hochkomplexe technische Hintergrund, der zudem noch ständig in Bewegung ist, begründet und entschuldigt zugleich die inhomogene Regelung des neuen Bereiches. Auch deshalb ist nur den Wenigsten der Umfang der strafrechtlichen Verantwortung bekannt, die den Einzelnen im EDV-Wesen treffen kann. In Unternehmen liegen aufgrund Arbeitsteilung und Delegation unterschiedliche Verantwortlichkeiten vor, da das Strafrecht an Pflichtenstellungen ansetzt, ist es von besonderer Wichtigkeit, zu wissen, wer sich und weshalb einer Strafdrohung ausgesetzt sieht.	eine and zwei;internet explorer;vhf omnidirectional range;word error rate	Jürgen Wessing	2005			history;performance art	Security	-104.51326765193377	35.99366232498279	164095
034e59ae4d75e5aafe7773ab35a82901434e81c1	informationssysteme der produktion - ein objektorientierter ansatz				Birgid S. Kränzle	1995			quantum electrodynamics;ansatz;mathematics	Vision	-97.13159989552597	33.8592611063243	164205
3d1fa596bf4ff56ab57f3b7151ee428146118214	über die grenzen der einsicht im computerwesen	grenzen der einsicht im	Grenzen sind heute nur noch bedingt scharfe Linien; immer mehr sind sie Ubergange mit Grauzonen oder mit allmahlicher Transformation. Mitunter mus man Grenzen als Gebiete verstehen, in denen man einen Aspekt nur im Tausch gegen einen anderen verbessern kann. Das kommt von der Verfeinerung unserer Beobachtung und Einsicht, von der Klein-heit unserer Vorrichtungen in Raum und Zeit. Von den harten Grenzen hatte man sich noch jene abschliesende perfekte Erkenntnis und Ordnung versprochen, welche der Physik und der Technik eine gewisse Uberheb-lichkeit suggerierten. Die weichen Grenzen geben uns das Bewustsein von Unzulanglichkeit und Unterinformiertheit zuruck, welches im vortechnischen Zeitalter fur normal angesehen wurde und nun, am Ende des 20. Jahrhunderts, zu Bescheidenheit und Besinnung mahnt. Das hat nichts mit Kulturpessimismus zu tun oder mit einer Verteufelung der Technik, welche vorwiegend von Leuten betrieben wird, die wenig Einsicht haben und unreflektierten Gebrauch von der Technik machen. Noch vor zwanzig Jahren war es ein wirksamer Scherz, den technischen Direktor einer grosen Gluhlampenfirma nach den Planen fur eine allge-meine Alpenbeleuchtung zu fragen — heute klange es nach den ublichen Ubertreibungen eines grunen Parteiblatts. Die Alpen lassen sich so wenig ausleuchten wie ein technisch-wissenschaftliches Gelande. Selbst die Informatik, ein Fachgebiet auf solidester logischer Basis, hat ihre Dunkelbezirke, und es ist eine ebenso legale wie nutzliche Aufgabe, sich mit den Grenzen der Einsicht in ihren Bereichen aus-einanderzusetzen.		Heinz Zemanek	1984		10.1007/978-3-642-69394-6_1	computer science;parallel computing;performance art	Robotics	-105.9246363611901	33.81965205271103	164546
2fe11b68c38fde893c025c1a41ba69823697fd81	integration von wissenskomponenten in ein digitales archiv zur schreiberidentifikation von historischen musikhandschriften		Ein wichtiger Schritt für die Verbesserung der Nutzbarkeit von digitalen Bibliotheken ist das Anbieten spezialisierter Services. Beispiele für derartige Bedürfnisse finden sich in vielen Bereichen. In unserer Arbeit gehen wir auf die Bedürfnisse von Musikwissenschaftlern bzgl. der Verwaltung von historischen Notenhandschriften und der Erkennung der Notenschreiber ein. An der Universität Rostock lagern mehr als 5000 Notenhandschriften des 17. und 18. Jahrhunderts. Diese zu digitalisieren, zu analysieren und Mechanismen für die Schreibererkennung zu entwickeln, ist Aufgabe des eNoteHistory-Projektes [2]. Wir haben dazu das Wissen der Musikexperten genutzt, um die Handschriften mit 80 Features aus 13 Featuregruppen zu beschreiben. Die momentane Umsetzung beinhaltet eine manuelle Bestimmung der Schreibercharakteristiken. In diesem Artikel soll die Realisierung eines solchen digitalen Archivs für historische Musikschriften und die Integration spezieller domänenspezifischer Daten und Methoden für eine Schreiberidentifizierung beschrieben werden. Dabei werden insbesondere Formalismen für die Repräsentation einer Handschrift, Implementierungsaspekte und Tests vorgestellt.	eine and zwei;unified model	Ilvio Bruder;Temenushka Ignatova;Lars Milewski	2004			history;performance art	OS	-104.67163359426286	32.88703033612805	164758
b56b6640b3a622e7cac15a3b1c37e514c0c37a41	rechtsprechung zum datenschutz 2006 — teil 2		Nachdem sich der erste Teil der Rechtsprechungsübersicht insbesondere der Judikatur des BVerfG und des BGH gewidmet hat, befasst sich der zweite Teil vornehmlich mit Entscheidungen aus dem Zeitraum Januar bis Anfang November 2006, die im Arbeitsrecht und dem Internetrecht sowie auf den Gebieten der Werbung und des Marketing ergangen sind.		Noogie C. Kaufmann	2007	Datenschutz und Datensicherheit - DuD	10.1007/s11623-007-0047-7		Crypto	-103.45166470984809	35.13766204178425	164846
0aeb64e12d68f5df49f6c51b1d01239306365966	zur problematik von softwareentwicklung für den unterricht	zur problematik von softwareentwicklung;den unterricht	Mit Recht hat B. Andelfinger davor gewarnt, das sich Padagogen im Zusammenhang mit dem Thema „Computer und Schule“ dazu hergeben, eine bereits vollzogene Entwicklung durch eine nachgereichte padagogische Begrundung zu sanktionieren (Andelfinger 1985). Im Bewustsein dieser Warnung wird hier versucht, die Problematik der Softwareentwicklung in einen Rahmen zu stellen, der allein der Vernunft verpflichtet ist.		Annemarie Abshoff	1986		10.1007/978-3-642-71648-5_60		NLP	-103.72365719063441	34.66883175831657	164871
e2530e353fece1f3cf054622d7a9220472273076	der kanon der informationswissenschaft		Blaise Cronin hat 2013 die Frage formuliert, ob es so etwas wie einen Kanon der Informationswissenschaft gibt. Er schlägt vor, zur Ermittlung des Kanons auch Namensund Sachregister von einschlägigen Lehrbüchern informetrisch auszuwerten. Untersucht wurden englischsprachige Publikationen aus der Kategorie Information Science & Library Science der Fachdatenbank Web of Science sowie neun ausgewählte Lehrbücher der Informationswissenschaft. Im Web of Science wurden über 324.000 Publikationen ermittelt. Im Rahmen der szientometrischen Analyse wurden Zitationen, Publikationen und Themen ausgewertet. Zusätzlich zur klassischen Auswertung der Datenbankdokumente wurde erstmals eine Registeranalyse bei den Lehrbuchdokumenten durchgeführt. Die unterschiedlichen Ergebnisse wurden zusammengefasst, um einen gemeinsamen Kanon der Informationswissenschaft bilden zu können.	eine and zwei;information science;internet explorer;library science;unified model;vhf omnidirectional range;web of science	Mathilde B. Friedländer	2015	Inf. Wiss. & Praxis	10.1515/iwp-2015-0021	sociology;performance art	DB	-103.38149134566217	34.632984727371785	165033
7042a40018ecd7c782b01858b09f816605ab03ef	europäische und nationale regulierungen		Durch den NSA-Skandal wurde offensichtlich, dass die IT-Sicherheit von europäischen Unternehmen in viel höherem Maße bedroht ist als vorher gedacht und dass die derzeit gültigen EU-Rechtsvorschriften und nationale Gesetze offensichtlich nicht ausreichen, um die Unternehmen zu einer ausreichenden Gewährleistung von Datenschutz und Datensicherheit anzuhalten.	unified model	Ulrich Emmert	2015	Datenschutz und Datensicherheit - DuD	10.1007/s11623-016-0539-4	internet privacy;computer science	NLP	-103.71543991006733	36.395997145558596	165056
16d4704d65debdc916ead4580928da609d2dc0e5	kostenmodelle für softwareproduktlinien		Dieser Beitrag erläutert Kostenmodelle für die Entwicklung von Softwareproduktlinien und vergleicht diese auf Basis wichtiger Kriterien. Die Ergebnisse helfen, die verschiedenen Aspekte der Wirtschaftlichkeitsbetrachtung von Softwareproduktlinien besser zu verstehen und für konkrete Projekte anwenden zu können.	gesellschaft für informatik	Oliver Charles;Markus Schalk;Steffen Thiel	2010	Informatik-Spektrum	10.1007/s00287-010-0478-7	software engineering;computer science	NLP	-102.41091757434991	32.56589676195525	165942
6d03af8b1a158c01ef706348268b8a0f89006b44	ganzheitlicher umweltschutz - eine herausforderung für politik und informatik	ganzheitlicher umweltschutz;eine herausforderung	Ich habe mich besonders uber die Einladung zu dem Einfuhrungsvortrag fur Ihr Symposium gefreut. Ich mochte aber keinen Zweifel daran lassen, das ich fur Umweltinformatik alles andere als ein Experte bin. Ich verweise fur die Details, insbesondere die Mes- und Kontrollinformatik, auf den hier verfugbaren Sonderdruck „Was kann die Informations- technik fur den Umweltschutz tun?“ /1/.	eine and zwei	Ernst Ulrich von Weizsäcker	1987		10.1007/978-3-642-73563-9_1	performance art;history	Vision	-104.68775658468932	34.52868228986171	166038
856c648121e9c9979964a5d79359b8b738165f27	nutzeradäquate prozessbeschreibungen in der automotive e/e entwicklung		Mit steigender Produktkomplexität in der Automotive Elektrik / Elektronik (E/E) Entwicklung steigt auch die Komplexität der zugehörigen Entwicklungsprozesse und damit die Notwendigkeit, Prozessbeschreibungen für den Nutzer optimal zu gestalten. Die vorliegende Arbeit leistet hierzu einen Beitrag, indem sie einen Kriterienkatalog vorstellt, der es erlaubt, nutzeradäquate Prozessbeschreibungen zu erstellen und bestehende Prozessdarstellungen bezüglich ihrer Nutzeradäquatheit zu bewerten. Der theoretische Überbau wird durch eine umfassende Literaturrecherche geschaffen, die insbesondere den im Kontext Prozessbeschreibungen bisher vernachlässigten Bereich der Pädagogik miteinbezieht. Die resultierenden 430 Empfehlungen aus der Literatur wurden im Rahmen einer Befragung von Mitarbeitern der E/E Entwicklung bewertet und gleichzeitig durch weitere Nutzeranforderungen ergänzt. Der Kriterienkatalog und der zugehörige Styleguide wurden durch weitere Befragungen evaluiert und können in dieser ersten Untersuchung als empirisch bestätigt angesehen werden. 1 Prozessdarstellungen in der Elektrik / Elektronik Entwicklung Elektronik im Automobil spielt eine immer bedeutendere Rolle: Rund 90 % der Innovationen betreffen elektronische Systeme, davon entfallen 80 % auf den Bereich Software [Sc02]. Elektrische und elektronische Bauteile sowie Software machen bereits heute etwa 20 % des Autowertes aus, bis zum Jahr 2015 wird dieser Anteil auf 30 % ansteigen [Wy06] – der Bereich Elektronik stellt somit einen wettbewerbsentscheidenden Faktor dar. Steuergeräte, in deren Entwicklungsumfeld sich dieser Beitrag bewegt, sind elektronische Systeme, die im Automobil komplexe Regelungs-, Steuerungsund Überwachungsaufgaben übernehmen. Während Mitte der 1990er Jahre nur einige wenige Steuergeräte im Auto verbaut worden sind, verfügt ein Wagen der Oberklasse heute in der Regel über mehr als 80 Steuergeräte, die miteinander vernetzt sind [WR08].	die (integrated circuit);eine and zwei;sie (file format)	Franziska Rothermel;Carsten König	2008			hook;geology;structural engineering;trunk	OS	-102.86120074569901	33.18795384748389	166039
ae1a82d577484fb340a965ae734a27d06b8fdb92	über einige probleme bei der mathematisch exakten definition der semantik einer programmiersprache			list of concept- and mind-mapping software	Hans Rohleder	1975	Elektronische Informationsverarbeitung und Kybernetik		pure mathematics;combinatorics;mathematics	NLP	-95.60079228198994	34.43847859335595	166376
7a62484a04923b9339f5ab81b93377799cb09a68	auswertung von energiedaten - ein ansatz zur kombination einer soziologischen perspektive mit der methodik des data minings		Die Methoden des Data Minings liefern sinnvolle Ansätze zur Weiterverarbeitung und zielgruppengenauen Segmentierung von Kunden für innovative Marketingansätze. Dies wird bei Energieversorgern durch zunehmenden Wettbewerb und neuen Marktbegleitern ein immer wichtigeres Thema. Bestehende Forschungen beschäftigen sich mit der Segmentierung von Lastgängen nach maximaler Ähnlichkeit des Profils. Problematisch ist dabei bislang die Integration von kundenspezifischen Daten sowie deren Erhebung im Rahmen einer Lernstichprobe. Die vorliegende Publikation widmet sich dieser Thematik und adressiert die Kombination von soziodemografischen und lebensstilspezifischen Daten mit der aktuell verbreiteten Anwendung des Data Minings. Die Untersuchung nimmt dabei die Integration einer konsumsoziologischen Perspektive vor, mit dem Ziel die wichtigsten Faktoren auf Grundlage relevanter Literatur theoretisch herzuleiten. Diese Faktoren werden dann mit der Methodik des Data Minings verknüpft, um einen Ansatz zu generieren, welcher ein umfassenderes Bild des Konsumenten liefert und so dem Marketing eine breitere Basis für die zielgruppenspezifische und gleichzeitig datengetriebene Ansprache zur Verfügung stellt.	citeseerx;eine and zwei;unified model;vhf omnidirectional range	Tobias Weiß;Marco Krause	2015			mathematical physics;ansatz;mathematics	DB	-101.1777524272622	35.277695893457256	166741
b311886f3b6553797b42b3bed9299f9d580c3c93	multimodale bildauswertung zur rechnergestützten bestrahlungsplanung von augentumoren		Bei dem zugrundeliegenden Projekt wird eine Verbesserung der aktuellen Bestrahlungstherapie von intraokularen Tumoren durch den Einsatz von Protonenstrahlen angestrebt. Ausgehend von CT-Schnittbildern, MRT-Schnittbildern, Fundusphotographien und Ultraschallaufnahmen wird ein Bestrahlungmodell fur die Durchfuhrung der Bestrahlungstherapie ermittelt. Durch wissensbasierte Bildauswertung und Kombination aller zur Verfugung stehenden Informationen erreicht dieses Modell eine Prazision, die eine Ausnutzung der Dosierungsgenauigkeit von Protonenstrahlen erst moglich macht.		Sebastian Nöh;Klaus Haarbeck;Norbert Bornfeld;Thomas Tolxdorff	1998				Vision	-104.98778640385358	32.455624007478974	167010
f3d18b19a975de40280823471bb1dc4273c4c050	cloud computing und datenschutz	cloud computing	Cloud Computing wird datenschutzrechtlich meist als Auftragsdatenverarbeitung durchgeführt. Die dabei erforderliche Kontrolle des Cloud-Anbieters durch den Cloud-Nutzer ist am besten mittels einer datenschutzrechtlichen Zertifizierung des Cloud-Anbieters durchzuführen. Der Beitrag erläutert die Grundlagen und Ziele der datenschutzrechtlichen Zertifizierung von Cloud-Diensten im Konzept der AG „Rechtsrahmen des Cloud Computing“ und im Pilotprojekt „Datenschutz-Zertifizierung von Cloud-Diensten“ des BMWi. Der Verfasser ist Leiter der AG „Rechtsrahmen des Cloud-Computing“ und des Pilotprojekts.	cloud computing;die (integrated circuit);triple des	Georg Borges	2014	Datenschutz und Datensicherheit - DuD	10.1007/s11623-014-0069-x	cloud computing;computer science;operating system	Crypto	-102.06305698574052	35.94375705528731	167063
9a1eb1cf37f77068dea8a9ee58c2eee62b7d41b5	eine content-management-architektur für die umsetzung verteilter redaktionsprozesse bei der erstellung wieder verwendbarer inhalte für das elearning	content management	Inhalte fur eLearning-Anwendungen werden haufig noch spezifisch fur eine Zielgruppe und zur Prasentation uber eine bestimmte Plattform erstellt. Aufgrund der hohen Entwicklungskosten fur multimedial aufbereitete Lerninhalte wird jedoch eine Wiederverwendung einmal erstellter Inhalte gefordert. Verschiedene Standardisierungsbemuhungen konnen dieses Problem jedoch nicht zufrieden stellend losen. In diesem Beitrag wird der Ansatz eines XML-basierten Content Managements beschrieben, der die Autoren bei der verteilten Erstellung didaktisch aufbereiteter Lerninhalte unterstutzt und gleichzeitig eine flexible Mehrfachverwendung fur verschiedene Einsatzszenarien, Zielgruppen und Learning Management Systemen ermoglicht.	eine and zwei	Ruben Gersdorf	2003			content management;computer science;world wide web	NLP	-107.17011322338884	34.78616189060077	167096
730e8292f17313acbabeae020ba3cc3e61e9e6d9	mobilität im ,,future internet“	future internet	Eine der Herausforderungen im ,,Future Internet“ ist durch die Mobilität der Benutzer aber auch durch die der Ressourcen gegeben. Während Benutzer zunehmend mit tragbaren Geräten auf Internetdienste zugreifen, wurden Internetprotokolle unter der Annahme stationärer Knoten entworfen. Im Artikel wird ein Überblick über Mechanismen zur Unterstützung von Gerätemobilität gegeben, die für eine mobilitätsfreundliche Architektur des Future Internet von Relevanz sind. Darunter fallen Mechanismen zur Verbesserung der Konnektivität und Tolerierung von Verbindungsunterbrechungen sowie Mechanismen zur effizienten Adressierung und für übergangsloses Handoff-Management. Zusätzlich wird das Konzept der Mobility-Awareness vorgestellt, das auf Basis aktueller Bewegung reaktive und proaktive Adaptierungen von Netzwerkprotokollen ermöglicht. Die Mobilität von Netzwerkressourcen wird als zweite Form der Mobilität im Überblick diskutiert. Zusammen mit der Netzwerkvirtualisierung kann die Ressourcenmigration zur Flexibilisierung des Future Internet beitragen. Ressourcen wie virtuelle Links und virtuelle Router können zur Erreichung unterschiedlicher Ziele, wie zum Beispiel zur Verbesserung der Netzwerkqualität, Robustheit oder Energieeffizienz, migriert werden.	eine and zwei;future internet;internet explorer;router (computing)	Karin Anna Hummel;Andrea Hess;Harald Meyer	2010	Informatik-Spektrum	10.1007/s00287-010-0425-7	computer science	OS	-104.42004564072762	36.43344660611909	167405
0e967c12df83a1b74abeb372f00e031bf93fde4b	über die gestaltung schulischer netzwerke unter besonderer berücksichtigung von datenschutz und datensicherheit auf basis einer quantitativen befragung an schulen		Die landes-, bundes- und europaweiten Initiativen zur Vernetzung der Schulen und damit zurrnBefahigung der Schuler und Schulerinnen, sich in der Welt der Information und Kommunikation sicherrnzu bewegen, zeigen Erfolge. Allerdings ist das Land NRW in diesem Zusammenhang trotz allerrninvestierter Mittel und trotz allen Engagements immer noch eher ein Entwicklungsland. Dies aberrnhangt nicht nur zusammen mit den fehlenden Mitteln, sondern auch mit den Erfordernissen, vorhandenesrnLehrpersonal entsprechend fortzubilden und diese Fortbildungsmasnahmen zu finanzieren,rnzielgerichtet aufzubauen und zu realisieren. Schulen fuhlen sich mit den Aufgaben, die mit derrnNutzung moderner Technologie verbunden sind, allein gelassen. Damit ist eine fruhe Chance zurrnBegeisterung der Betroffenen in den Schulen vertan. Es gilt, dieses Manko im Nachhineinrnaufzufangen. rn      Dies aber kann nur durch Nutzung mehrfacher, parallel laufenderrnWege geschehen:rn 1. Es mussen finanzielle Unterstutzungen unterschiedlichster Art geleistet werden. Das gingernnur, kame es zu einem Umdenkungsprozess, der den bisherigen Schwachen in der Umsetzungrnentgegentritt, die Weiterentwicklung okonomischer und effizienter gestaltet. Die Losung kann nur einrnauf hochster Ebene initiiertes Projekt eines Gesamt-Verwaltungsnetzes sein, in dem sich letztrnendlich auch die Schulen wieder finden werden, und zwar so, dass sie sowohl im Rahmen vonrnProjektbeteiligungen mitbestimmen konnen als auch so, dass sie Gestaltungsfreiraume fur ihre ganzrnspeziellen Aufgabenzuschnitte haben werden. rn2. Das bisherige Problem der Schulen, sich nur ansatzweise mit den Anforderungen desrnDatenschutzes und der Datensicherheit auseinandergesetzt zu haben, kann auf diese Weise ebensornaufgefangen werden. Allerdings werden auch die Schulen sich als Teil einer Gesamtnetzes anrnvorgegebene Regularien halten. Durch ein Netz, das die gesamte Landesverwaltung umfasst, sindrnwesentliche Teile der Administration auf eine landesweite Ebene verlagert. Die verbleibendenrnAufgaben innerhalb der schulischen Subnetze konnen durch Lehrer der einzelnen Schulen erfullt werden.rnDas aber setzt voraus, dass es zu einer zentralen Aus- und Fortbildung kommt, die sich an denrnErfordernissen orientiert: Lehrer mit Administrationsaufgaben erhalten spezielle Schulungen, anderernlernen das Netz zu nutzen und im Sinne ihrer Schuler und ihres Unterrichts dessen Chancen zurnerkennen. Zielgerichtete und zielgruppenorientierte Fortbildung kann nicht in der Organisationsmachtrnund Entscheidungskompetenz der Schulen selbst liegen, sie muss zentral als Planungsaufgabernverstanden und angenommen werden. rn      Der technische Fortschritt ist ebenso wenig aufzuhalten wie dierngesellschaftliche Entwicklung, beide bedingen einander, beide wirken aufeinander. Damit ist es furrnalle Lebensbereiche, somit auch fur alle zum Bereich der Bildung gehorenden Institutionen undrnPersonen, wesentlich, sich in diese Entwicklungsschritte einzureihen, nicht etwa unkritisch mit demrnStrom zu schwimmen, aber fordernd, nicht bremsend, und offen, nicht gehemmt an der GesamtentwicklungrnTeil zu haben und mitzuwirken.		Monika Pientka	2005			history;performance art	ML	-104.73418927467702	34.43882695408376	168211
f4d901cbac9307edcf9dbf6fa8de0e25c32e512e	bwlehrpool: durchführung von elektronischen prüfungen in virtualisierten umgebungen		Aufgrund der zunehmenden Bedeutung von E-Prüfungen an Hochschulen und Universitäten werden Lösungen benötigt, die eine einfache, schnelle und sichere Nutzung von bestehenden Poolräumen für verschiedene Prüfungsszenarien ermöglichen. Das Projekt bwLehrpool hat in der Vergangenheit gezeigt, dass mit Hilfe von Virtualisierung eine große Anzahl an unterschiedlichen, individualisierten Lehrumgebungen flexibel und räumlich unabhängig verteilt werden kann. Im nächsten Schritt sollen nun Erweiterungen entwickelt werden, die diese Flexibilität auch für elektronische Prüfungen nutzbar macht. Dabei gilt es vor allem, die Vorteile, wie z.B. die Nutzung von Softwareunterstützung für realitätsnahe Aufgabenstellungen, mit der Notwendigkeit nach größtmöglicher Sicherheit und schneller Umrüstzeit der Infrastruktur in Einklang zu bringen. Um den aktuellen Entwicklungsstand zu testen, wurde im Wintersemester 2015/2016 an der Hochschule Offenburg eine E-Prüfung unter bwLehrpool durch über 140 Studierende durchgeführt. Die Ergebnisse zeigen, dass die Anforderungen bisher erfolgreich umgesetzt werden konnten, allerdings noch mehr manueller Aufwand nötig ist, als gewünscht. Der Ablauf soll in Zukunft weiter vereinfacht und verstetigt werden.	eine and zwei;internet explorer;unified model;vhf omnidirectional range	Steffen Ritter;Stephan Trahasch;Sven Slotosch;Dirk von Suchodoletz;Jan Münchenberg	2016				AI	-104.61286160103131	33.222166097596194	168570
7dbcfc78818bb2ae80d20892a6b0fb6d949c56fe	mitteilungen der schweizer informatiker gesellschaft · 5/2003		Der Einbruch der ‚New Economy‘ und die Trendwende auf dem IT-Arbeitsmarkt, noch vor zwei Jahren kaum denkbar, bietet erneut Anlass, sich mit Fragen des ‚mismatch‘ zwischen Angebot und Nachfrage an Qualifikationen in der Informatik zu befassen, freilich mit umgekehrten Vorzeichen: Nur zu rasch stellte sich nach dem weltweit prognostizierten Mangel ein Überschuss an Fachkräften ein, die – angesichts der Geschwindigkeit der Wissensentwicklungen und raschen beruflichen Ausdifferenzierung des Feldes – kaum darauf hoffen können, ihre heute erworbenen Qualifikationen morgen noch zu verwerten. Dieses Problem existiert in ganz Europa: So sitzen beispielsweise auch in Deutschland einige ehemals stolze Inhaber/innen einer Greencard für IT-Spezialisten schon wieder auf gepackten Koffern. Anschauungsmaterial für eine Auseinandersetzung mit dem Problem der ‚Qualifikations-Prognose‘ bietet ein kürzlich veröffentlicher Forschungsbericht (Dupuis/Liebig/ Morandi 2003), der sich mit der Informatik in der Schweiz seit Beginn der 1980er Jahre befasst. Der auf umfassenden sekundärstatistischen Analysen basierende Bericht verfolgt Angebot und Nachfrage nach informatikbezogenen Qualifikationen sowie den Markt der IuK-Technologien in der Schweiz, wobei neben der Darstellung regionaler Besonderheiten auch die Frage gestellt wird, inwieweit Frauen an der ‚Informatikrevolution‘ beteiligt sind. Wie wichtig der Informationsund KommunikationstechnologieMarkt Sektor für die Schweiz ist, lässt sich anhand einiger Kennziffern illustrieren: So kommt ihm hier mit rund 8% des Bruttoinlandprodukts eine herausragende ökonomische Bedeutung zu, bezüglich deren er nur noch von den USA und Schweden übertroffen wird. Gemessen an den Pro-Kopf Ausgaben wurde im Jahr 2002 in keinem anderen Land der Welt so viel Geld für neue Technologien ausgegeben. Das über viele Jahre ungebremste und von der Gesamtentwicklung der Schweizer Wirtschaft weitestgehend losgelöste Wachstum des Technologiemarktes, allen voran von Schlüsseltechnologien wie Internet und Mobiltelefonie sowie damit zusammenhängenden Carrier-Services hatte in der Schweiz – begleitet von verschiedenen eidgenössischen Bildungsoffensiven – seit den 1980er Jahren enorme Umstellungen und Investitionen im Bereich informatikbezogener Ausbildungsangebote zur Folge. Während sich an den Universitäten und Eidgenössischen Technischen Hochschulen (ETHZ/EPFL) die Zahl der Informatik-Studierenden in zwei grossen Wellen vervielfachte, zu Anfang und gegen Ende der 1990er Jahre, erfuhren die ausseruniversitären Berufslehren in Informatik, Geräteinformatik, Mediamatik, Multimedia-Gestaltung und Telematik erst in den letzten Jahren ein immenses Wachstum, sodass heute bereits die Hälfte aller angehenden Fachleute für Informationsund Kommunikationstechnologien in der Schweiz über eine Berufslehre zu ihren Kenntnissen gelangt. In naher Zukunft, so lässt der Bericht erwarten, wird vom ausseruniversitären Ausbildungsbereich die Mehrzahl der Nachwuchskräfte hervorgebracht. Ähnlich expansiv verhielt sich der Informatik-Arbeitsmarkt: Rezession und konjunkturellen Abschwung des Dienstleistungssektors konterkarierend, zeichnete eine bis Anfang des Jahres 2001 ungebremste Zunahme von Beschäftigten die Informatikbranche als wirtschaftlichen Leitsektor der 1990er Jahre aus, wobei die Dynamik informationstechnologischer Entwicklungen stetige Veränderungen und Weiterungen des Beschäftigungsbereichs mit sich brachte. Erinnert sei etwa an die Umwandlung der ehemaligen ‚Monopol‘Berufe im Postund Fernmeldebereich in ‚normale‘ Ausbildungsberufe. Und während Bereiche wie HardSchweizer Informatiker Gesellschaft (SI)	eine and zwei;europa;gesellschaft für informatik;internet explorer;new economy;rasch model;triple des;vhf omnidirectional range	M. Schweizer;INFORMATIKER GESELLSCHAFT;Monique Dupuis	2003	Informatik-Spektrum	10.1007/s00287-003-0338-9		OS	-104.37970727644465	34.776837521506664	168721
447919d9453bc6e46c47824edd940c62060bc454	die zukunft der kryptographie		Wenn über die Zukunft der Kryptographie gesprochen wird, dann geht es häufig um ein Thema: Quantencomputer. Dabei liest oder hört man oft Aussagen wie: „Mit einem Quantencomputer kann jedes Verschlüsselungsverfahren geknackt werden!“. Aber stimmt das so überhaupt? Welche Bedrohung stellt ein Quantencomputer genau dar? Zum einen ist nach wie vor völlig unklar, ob überhaupt jemals ein Quantencomputer gebaut werden kann, der eine Bedrohung für kryptographische Algorithmen darstellt. Andererseits gibt es auch kryptographische Verfahren, die nach dem aktuellen Stand der Forschung resistent gegen Angriffe mittels Quantencomputern sind. Sind damit also alle Probleme der Zukunft der Kryptographie gelöst? Leider nein, denn der fehlerhafte Einsatz von Kryptographie in der Praxis stellt bereits heute ein Problem dar.	altran praxis;eine and zwei;internet explorer;unified model;vhf omnidirectional range	Tibor Jager	2014	Datenschutz und Datensicherheit - DuD	10.1007/s11623-014-0204-8	internet privacy;computer science;performance art	OS	-104.20950361893739	35.78035490771732	169049
6b3b6e0832eeacb67a9b0a11980eff7e6e8df88b	big data im informatikunterricht: motivation und umsetzung		Das Sammeln und Auswerten von Daten ist heute allgegenwärtig: In vielen Bereichen des täglichen Lebens nimmt die Bedeutung von Daten und datenbezogenen Anwendungen immer mehr zu, z. B. bei der Nutzung sozialer Medien oder bei der Verwaltung großer Mengen an eigenen Daten. Während Daten früher hauptsächlich konsumiert wurden, wird heute auch jeder zum Produzenten immer umfangreicherer Datenmengen. Dabei werden immer größere und vielfältigere Datenmengen verwaltet und verarbeitet. Im Informatikunterricht wird Big Data jedoch bisher kaum thematisiert: Die fachlichen Grundlagen dafür scheinen auf den ersten Blick zu komplex und kaum auf schulischem Niveau verständlich zu sein. In diesem Beitrag werden daher zuerst die wesentlichen Entwicklungen vorgestellt, die sich derzeit im Datenmanagement ereignen, sowie die sich dadurch ergebenden fachlichen Herausforderungen. Um zu demonstrieren, dass solche fachliche Innovationen oft grundlegende Konzepte enthalten, die im Informatikunterricht thematisiert werden können, wird anhand von zwei Unterrichtsszenarien aus diesem Themenbereich exemplarisch vorgestellt, wie Informatik es mittels moderner Ansätze zur Datenverarbeitung ermöglicht, Big Data beherrschbar zu machen.	big data;die (integrated circuit);eine and zwei;internet explorer;mathematical foundations of quantum mechanics;unified model	Andreas Grillenberger;Ralf Romeike	2015			history;performance art	DB	-100.8017298629147	35.63656972030558	169068
9119860a88341ea01a6e45beabb4108906369dcc	iterative gewinnung von existenzaussagen für randwertprobleme mit gewöhnlichen differentialgleichungen 2. ordnung		Eine ganze Reihe von Arbeiten beschäftigt sich mit der Frage der Existenz von Lösungen für Randwertprobleme der Art (1.1). Von besonderem Interesse sind dabei die konstruktiven Aussagen. Das Ziel der folgenden Arbeit ist, einmal alle unten zitierten iterativen Existenzaussageneinheitlich zu gewinnen und zum anderen die Grenze des Konvergenzbereiches solcher Iterationsverfahren aufzuzeigen durch die Betrachtung von Eigenwertaufgaben, die für die Probleme kennzeichnend sind. Many notes deal with the existence problem of solutions for boundary value problems of the kind (1.1). Constructive statements are of a special interest. The first purpose of the following note is to show that it is possible to obtain all the iterative statements about the existence quoted below in a uniform manner. Secondly we will limit the range of convergence of those iteration processes by discussion of some characteristic eigenvalue problem.	eine and zwei;iteration;triple des	Harald W Ade	1968	Computing	10.1007/BF02277219	mathematical analysis;calculus;mathematics	Theory	-96.55889158866825	35.30148397970765	169071
e454231296625087ff55386987d5aeb3807ec06e	smart experience sampling in android	public records;websearch;rwth publications	Experience Sampling beschreibt die Aufzeichnung und Auswertung von manuell in Fragebögen eingetragenen Daten. Diese Methode ermöglicht die Betrachtung und Auswertung von subjektiven und schlecht automatisch messbaren Lernerinformationen, die über einen längeren Zeitraum aufgenommen wurden. Mit Hilfe von Smartphones und ihren eingebauten Sensoren kann diese Methode weiter verfeinert werden. In diesem Projekt wird gezeigt, wie mittels Sensoren und zusätzlichen Informationen über einen Lernenden genaue Zeitpunkte für die Präsentation von Fragebögen gewählt werden können und wie die Auswahl der Fragen möglichst so gewählt wird, dass die Lernenden auch über einen längeren Zeitraum hinweg nicht die Motivation an der Beantwortung der Fragebögen verlieren.	android;internet explorer;smartphone	Hendrik Thüs;Markus Soworka;Philipp Brauner;Ulrik Schroeder	2015			performance art;art	OS	-105.8495257304576	37.13341210622432	169560
08187f703c25a56b8f13003cf482bf583d869768	blended museum - vielfältige besuchererfahrungen durch hybride vermittlungsstrategien	workshop;inproceedings	Innerhalb der Bildungsinstitution Museum entstehen durch den Einsatz von Informationsund Kommunikationstechnologien (IuK) neue Möglichkeiten der Informationsvermittlung. Im Blended Museum wird versucht, virtuelle und reale Präsentationsformen miteinander zu vermischen. Dies ermöglicht hybride Vermittlungsstrategien, die neue und vor allem vielfältigere Besuchererfahrungen erlauben, als dies mit konventionellen Hilfsmitteln möglich ist. 1 Hybride Vermittlungsstrategien 1.1 Der Ansatz des Blended Museum Lernen und der Erwerb von Wissen in modernen Wissensgesellschaften findet nicht nur in formalen Bildungseinrichtungen, sondern auch innerhalb Institutionen statt, die einen informalen Bildungsanspruch erheben. Eine dieser Institutionen ist das Museum, in der das Sammeln, Bewahren, Erforschen und Ausstellen auf die Vermittlung von Bildung abzielt [IC06]. Ausgehend von den ausgestellten authentischen Objekten rückt die Information und Kommunikation von Wissen in den Mittelpunkt des Museums. Damit ein Objekt verstanden werden kann, muss es in einen dem Besucher nachvollziehbaren Zusammenhang gebracht werden. Zur Bildung eines solchen Ausstellungskontextes werden meist klassische Hilfsmittel wie Texttafeln, Schaubilder, etc. herangezogen, die den Besucher jedoch auf eine passive Empfängerrolle beschränken. Diese Techniken bzw. Hilfsmittel zur Bildung eines Ausstellungskontextes können als Vermittlungsstrategien bezeichnet werden [Wo05]. Der Einsatz von Informationsund Kommunikationstechnologien (IuK) bietet durch das Charakteristikum der Interaktivität neue Möglichkeiten, den Besucher in den Vermittlungsprozess einzubinden und ihm eine aktive Produktion subjektiver Bedeutung zu ermöglichen. Neben der internen Nutzung von IuK innerhalb des realen Museums ermöglicht der Einsatz von IuK jedoch auch einen externen und somit ortsunabhängigen Zugriff auf Museumsinhalte z.B. über das Internet. Diese neue Form der Zugänglichkeit wird meist als virtuelles Museum bezeichnet. Erschienen in: Workshop Proceedings der Tagungen Mensch & Computer, DeLFI 2008 und Cognitive Design 2008, Logos Verlag, Berlin, 2008, S. 424-428	eine and zwei;intentionally blank page;internet explorer;mensch computer;vhf omnidirectional range	Daniel Klinkhammer;Harald Reiterer	2008			art;performance art	OS	-106.47280076489808	34.884554858007824	170070
f2f060853e9f837a0e0defcc490de04dcbc0ed2b	bürgerrechtskonforme bekämpfung der computerkriminalität		Das Internet und die damit vernetzten Computer sind nicht das „Reich des Bösen“, sondern müssen ein „Raum der Freiheit“ in unserer Informationsgesellschaft bleiben. Dies hindert nicht eine wirksame Strafverfolgung. Der Überblicksbeitrag thematisiert die aktuellen Versuchungen bei der strafverfolgenden digitalen Spurenanalyse und die datenschutzrechtlichen Grenzen hierbei.	eine and zwei	Thilo Weichert	2007	Datenschutz und Datensicherheit - DuD	10.1007/s11623-007-0197-7	internet privacy;the internet;computer security;computer science	OS	-103.79805731750946	36.64973740948233	170469
5daeb076e5f1d5cb888538f9bce9c19b043fa445	"""interview mit hans-christian boos zum thema """"unternehmertum in der it-branche"""""""		Hans-Christian Boos gewann im Jahr 1988 den Jugend-Forscht-Preis. Damals entwickelte er ein ergonomisches Benutzer-Interface für klimatologische Daten. Nach dem Abitur studierte er in Zürich und Darmstadt Informatik. Anfang der 90er Jahre vernetzte er als Praktikant für eine deutsche Großbank die weltweite Kapitalmarktforschung über das Internet. Dies realisierte er mit einer selbst entwickelten Software – eines der ersten Content-Management-Systeme. 1995 gründete er die arago GmbH, ein Institut für komplexes Datenmanagement. Im Jahr 2002 wurde arago zur AG, deren Vorstand er heute ist. Neben Content-Management stehen IT-Sicherheit und Server-Administration im Vordergrund. Hans-Christian Boos ist zudem Autor zahlreicher Fachpublikationen zu den Themen Information Modelling und IT-Strategien.	eine and zwei;information model	Armin Heinzl;Birte Autzen	2006	Wirtschaftsinformatik	10.1007/s11576-006-0097-8		DB	-102.51345168860615	33.47636722439349	170578
53847a4e9ee9a72ba61cf15f7fe6b4517625924c	zur automatischen ermittlung von testszenarien aus epk-schemata		Für funktionale Systemtests großer, komponentenund serviceorientierter betrieblicher Anwendungssoftware sind durchgängige Testszenarien sinnvoll, die für die wichtigsten, geschäftskritischen betrieblichen Abläufe des Anwenders vorzubereiten und durchzuführen sind. Zur Unterstützung der Ermittlung solcher „higher order“ Testfälle wird eine systematische Methode der Extraktion verzweigungsfreier Wege durch EPK-Schemata vorgeschlagen. Um die vorgestellte Methode praktikabel zu machen werden optionale Annahmen zur kombinatorischen Relaxation getroffen. Die Methode ist als Erweiterung der Open-Source Initiative „EPC-Tools“ implementiert. 1 Einleitung und Motivation Im komponentenund serviceorientierten Entwicklungsparadigma betrieblicher Anwendungssysteme [SGM02; Tu03] kann man fragen, wie fremdbezogene Komponenten bzw. Dienste möglichst früh und effizient überprüft werden [Bo81; We98]. Man geht dabei für die Seite der Komponentenhersteller bzw. Dienstelieferanten davon aus, dass sie die Außensicht auf ihre Komponenten und Dienste spezifizieren, um sie am Markt anzubieten [Tu03]. Man kann weiter annehmen, dass ein Anwender solche Spezifikationen auf ihre Eignung für seine zu automatisierenden betrieblichen Abläufe überprüft, bevor er die entsprechenden Komponenten und Dienste einsetzt bzw. bevor er sie auch nur bezieht. Jedoch können im allgemeinen nicht alle möglichen Abläufe einer zu automatisierenden Domäne gegen alle Eigenschaften der sie unterstützenden Software getestet werden. Das dürfte auch, zumindest bei nicht sicherheitskritischen Systemen, in den allerwenigsten Fällen wirtschaftlich sinnvoll sein. Damit geht es für den nachfragenden Anwender zunächst darum, die für ihn wichtigsten, geschäftskritischen Abläufe unabhängig von den angebotenen Komponenten bzw. Diensten systematisch zu identifizieren. Sind diese kritischen Abläufe gefunden, dann eignen sie sich gut als Grundlage zur weiteren Ausarbeitung der tatsächlichen Prüfschritte, dabei v.a. zur Definition verzweigungsfreier Szenarien für Positivtests mit unabhängigen Orakeln („sunshine paths“ [Sk07, ST07]). Die Frage, die dieser Beitrag zu beantworten versucht ist damit, ob und wie aus einem betrieblichen Ablaufschema	eine and zwei;electronic product code;internet explorer;sie (file format);unified model	Oliver Skroch	2008			philosophy;performance art	OS	-104.8415486711908	33.03035673200388	170872
952edd3c4ca568d22681298ee549885926a96944	datenschutzrechtliche anforderungen an innereuropäische personaldatenübermittlungen in matrixorganisationen		Für die innereuropäische Übermittlung von Personaldaten zwischen Konzerngesellschaften hat der Düsseldorfer Kreis strenge Vorgaben entwickelt. Dieser Beitrag zeigt, wie diese Vorgaben mit einem Datenschutzvertrag erfüllt werden können.	internet explorer	Michael Schmidl	2009	Datenschutz und Datensicherheit - DuD	10.1007/s11623-009-0074-7	internet privacy;computer security;computer science	NLP	-103.53739332244481	36.65344114555177	171251
bed1039f8b3a9a8405798917b73bc61e9ea479c8	mitteilungen der gesellschaft für informatik 233. folge (fortsetzung)		Grand Challenges der Informatik: Systemische Risiken in weltweiten Netzen Die dritte Grand Challenge unserer Initiative, die Sie als Poster in diesem Informatik Spektrum finden, beschäftigt sich mit ,,Systemischen Risiken in weltweiten Netzen“. Wirtschaftssysteme, Unternehmen, Maschinen und Haushalte sind enger vernetzt als je zuvor. Die Methoden, eine Übertragung von Schocks durch das gesamte System zu identifizieren und einzuschränken, haben mit dieser Entwicklung jedoch nicht Schritt gehalten: Systemische Risiken werden auch in komplexen und dynamischen Netzwerken durch starre Trennlinien, fixe Puffer und personelle Überprüfung gemanagt. Die Herausforderungen an die Informatik: Entwicklung differenzierter Interventionssysteme. Details zu dieser und den vier anderen Grand Challenges finden Sie unter http://www.gi.de/ themen/grand-challenges-derinformatik.html.	die (integrated circuit);eine and zwei;gesellschaft für informatik;grand challenges;institut für dokumentologie und editorik;puffer train;sie (file format)	Petra Hofstedt;Oliver Günther;Dieter Fellner	2015	Informatik-Spektrum	10.1007/s00287-015-0889-6			-103.56149720907612	34.54293842073713	171569
2ec021d8b0e638f2ec0a5f650fee58b433d4d7c5	offene innovationen und die sie begünstigenden systeme		Was ist ein Innovationssystem, was ein Ökosystem? Bei Innovationen von einem System zu sprechen, ist zumindest ungewohnt. In der Technik, insbesondere in der Informatik, kann ein Einzelner zwar immer noch großartige Ideen generieren oder artikulieren. Bei ihrer Umsetzung in die Form wirtschaftlich relevanter Innovationen ist er aber schnell überfordert. Aber auch für Unternehmen kann es ein Umdenken erfordern, wenn sie Innovationsprozesse nicht aus sich allein heraus gestalten wollen oder können. Sie vollziehen dann den Übergang von der geschlossenen zur offenen Innovation.Offene Innovationen sind gleichsam zur Leitidee der globalisierten Wirtschaft geworden. Zu einem Innovationssystem gehört alles, was den Prozess des Anstoßens und der Umsetzung von offenen Innovationen zielgerichtet unterstützt, ausgehend von der ersten Idee eines Produkts bis zum Milliardengeschäft. Als das wohl bekannteste Beispiel eines regionalen Innovationssystems in unserer Branche gilt das Silicon Valley in Kalifornien. Obwohl man seine Erfolgsprinzipien nicht im Detail versteht, wird immer wieder versucht, es nachzuahmen. Im Falle Japans wird (oder wurde) von einem nationalen Innovationssystem gesprochen. Oft spricht man auch von Innovationsclustern oder Innovationsnetzen, je nachdem, ob die geografische Ausrichtung im Vordergrund steht oder die Art der Kommunikationsbeziehungen. Primäres Ziel dieses Beitrags ist es, Innovationsprozesse auf unserem Fachgebiet aus Sicht der industriellen Praxis zu beleuchten. Dabei soll zunächst auf die Rolle innovativer Produkte, der Unternehmensgröße und offener Architekturen eingegangen werden. Der Blick lässt sich ausweiten auf das, was man neuerdings häufig als Ökosystem (engl. ecosystem) bezeichnet. Dieser Ausdruck stammt ursprünglich aus der Biologie und galt als Abkürzung für ein ökologisches System. Im übertragenen Sinne kann auch ein ökonomisches System gemeint sein, also das Zusammenwirken privater und staatlicher Initiativen zur Entstehung und Pflege eines Marktsegments. Das Charakteristische eines Ökosystems ist, dass die Mitglieder sich gegenseitig Vorteile verschaffen. Es ist sinnvoll, nicht von dem Innovationssystem oder dem Ökosystem der Informatik zu sprechen, sondern von einer Mehrzahl von Systemen.	altran praxis;ecosystem;sie (file format)	Albert Endres	2010	Informatik-Spektrum	10.1007/s00287-010-0479-6	software engineering;computer science	DB	-103.20544560437752	33.01033654436432	172261
da18a03fdc6c72c5ea9a9ab5a9a9451052fe4c8d	service-orientierte unterstützung des nationalen früherkennungsprogramms für kinder		Wir stellen ein Konzept zur Service-Orientierten Unterstützung eines nationalen Vorsorgen-Monitorings für Kinder-Vorsorgeuntersuchungen vor. Nach einem Überblick der medizinischen Thematik und einer rudimentären Modellierung des Arbeitsablaufes, stellen wir das SECTET-Rahmenwerk zur modellgetriebenen Entwicklung sicherheitskritischer Service-Orientierter Architekturen (SOA) vor. Unserer Meinung nach eignet sich dieses Rahmenwerk ideal, um den Anforderungen an Datenschutz und Privatsphäre an eine solche SOA gerecht zu werden.	eine and zwei;unified model;vhf omnidirectional range	Nadim Sarrouh;Oliver Blankenstein;Uwe Nestmann	2010				Crypto	-103.76422070350215	32.964191410810834	172498
393f168e237d824385d4979c551898e5cb41f75b	chancen des einsatzes öffentlicher datennetze bei der umweltverträglichen steuerung des personennahverkehrs	der umweltvertr	Angesichts einer Entwicklung uberproportionalen Verkehrsaufkommens und einer Verkehrsstruktur, die sich zunehmend zulasten offentlicher Verkehrsmittel verschiebt, kommt es zu einer drastischen Steigerung der negativen Umwelteffekte. Masnahmen zur Attraktivitatssteigerung des Offentlichen Personennahverkehrs (OPNV), die eine veranderte Verkehrsmittelwahl bewirken, haben somit einen hohen Stellenwert bei der Verbesserung der Umweltsituation. In diesem Zusammenhang leisten Informations- und Kommunikationstechniken einen zentralen Beitrag. Am Beispiel eines neuen Fernwirkdienstes (TEMEX) werden Erfahrungen aus Pilotprojekten in einigen deutschen Stadten aufgegriffen, aus denen die Wirksamkeit und Wirtschaftlichkeit schnell greifender Moglichkeiten zur Verbesserung der Umweltsituation im Verkehrssektor hervorgehen.		Peter Zoche;Rainer König	1990		10.1007/978-3-642-76081-5_83	history;performance art	Crypto	-104.0753589426266	32.871030101001054	172679
699d6f77624042bd5d6182478f48aec4b074faae	ausbildung und zertifizierung in der industriellen software-wartung		Dieser Artikel beschreibt die aktuelle Lage der Ausbildung und Zertifizierung in der Software-Branche im Allgemeinen und in der industriellen Software-Wartung im Speziellen. Dabei zeigt sich, dass eine Ausbildung für die Tätigkeiten der Software-Wartung fehlt. Um diesen Missstand zu beheben, wird im Artikel das Modell eines idealen Software-Warters entworfen und werden dessen Fähigkeiten beschrieben. Aus diesen Fähigkeiten wird unter den gegebenen industriellen Rahmenbedingungen ein Ausbildungsund Zertifizierungskonzept für die Software-Wartung in der Industrie abgeleitet.	eine and zwei;unified model;v-model	Stefan Opferkuch;Jochen Ludewig	2008			history;performance art	OS	-103.51315684028678	32.507085987835424	173025
683f2e2c3299e7bc49cd1235370c2777f4a3639f	zielkonflikte um datenschutz, sicherheit und leben		Primäre Organisationsziele vertragen sich mit Vorgaben aus den Bereichen Informationssicherheit und Datenschutz nicht immer. Die Konflikte treten im medizinischen Umfeld in extremer Ausprägung auf - und lassen sich nur lösen, wenn der einzelne Mitarbeiter zu den richtigen Entscheidungen im Einzelfall befähigt wird. Genau diesen Weg werden im „Bring-your-own-Device“-Zeitalter auch andere Branchen einschlagen müssen.	unified model	Daniel Kaboth;Bettina Weßelmann;Johannes Wiele	2012	Datenschutz und Datensicherheit - DuD	10.1007/s11623-012-0226-z	internet privacy;computer science	DB	-103.72725876889058	36.3234739551255	173155
a1c14c89890b73c779e724eef82d8b7281b42e6c	qualitätssicherung für software durch vertragsgestaltung und vertragsmanagement		1.1 Verträge sind Verträge über Software-Projekte sind juristische Abbildungen des Projektgeschehens und haben deshalb grundsätzlich eine ähnliche Komplexität. Lieferund LeistungsverEinfache werkvertragliträge sind Pläne, und zwar che Modelle werden in zweierlei Sinn: dem nicht gerecht. Das Regelungsgefüge ist in Ein gemeinsamer Plan ist die die Bereiche LeistungsFestlegung eines zukünftibeschreibung, Vergügen, abgestimmten Verhaltung, Organisation und tens. Der Plan weist in die Rechtsregeln aufzuteiZukunft und soll diese Zulen; zwischen diesen kunft organisieren, im ErfasBereichen sind Steusungsbereich des Planes zu ernde Verbindungen einer gemeinsamen Zukunft herzustellen. Damit ermachen, weist sich der ProjektAls Plan bezeichnet man vertrag als Hilfe in der aber auch eine technische Projektarbeit. Der AuZeichnung (z. B. Stadtplan, tor schlägt einen neuGrundrißplan) also die fachen Blick und neue lieh korrekte Umsetzung und Strukturierungen vor. Abbildung. Auch in diesem	eine and zwei;tor messenger;vhf omnidirectional range;zentralblatt math	Michael Bartsch	2000	Informatik-Spektrum	10.1007/s002870050003	software;software engineering;computer science	OS	-104.61388395122887	34.24894553339656	173473
29d90130a77533df948e23722a678222e69ee519	rechtliche betrachtungen zur automatisierten erzeugung qualifizierter elektronischer signaturen gemäß §14 ustg und §36srvwv		Diese Arbeit beleuchtet einige rechtliche Aspekte der automatisierten Erzeugung qualifizierter elektronischer Signaturen – der sogenannten „Massensignatur“. Neben den generellen Rahmenbedingungen aus der Signaturgesetzgebung wird der Einsatz der „Massensignatur“ zur elektronischen Rechungsstellung gemäß §14 Abs. 4. Satz 2 UStG und zur elektronischen Archivierung schriftlicher Unterlagen gemäß §36 Abs. 1 SRVwV näher beleuchtet.		Detlef Hühnlein;Yvonne Knosowski;Ragna Tern	2003			computer security;computer science;library science;satz	OS	-103.59565349799794	35.590735062208246	173795
619da730b59d811caed5cd993a911d6433e259f1	zerlegung der knotenmengen von graphen zum nachweis der isomorphie		Bestehende Verfahren zum Nachweis der Isomorphie von zwei Graphen beginnen mit der Konstruktion von zwei Partitionen der gemeinsamen Knotenmenge, deren Mengen bei jedem Isomorphismus bijektiv aufeinander abgebildet werden. Die vorliegende Arbeit beschreibt eine Systematisierung dieser Vorgangsweise, als deren Folge sich eine direkte Methode zur simultanen Zerlegung der Knotenmenge ergibt. Known methods for checking graph isomorphism start with the construction of two partitions of the node sets. The partitioning is made in such a way that each set of the first partition corresponds uniquely to a set of the second partition under each possibly existing graph isomorphism. The paper deals with a generalization of this idea and describes a direct method for finding finest partitions.	direct method in the calculus of variations;eine and zwei;graph isomorphism	Josef Hinteregger;Gottfried Tinhofer	1977	Computing	10.1007/BF02244021	algebra;mathematical analysis;mathematics	DB	-95.8922439276532	34.915982608682754	174054
ef6519f38ea06a95bb02012904b787d15706f42d	individualisierte, auf ein benutzermodell gestüzte präsentation von lerninhalten	sentation von lerninhalten;zte pr	Die Zeiten, in denen der Benutzer zwischen ein oder zwei Anwendungsprogrammen eines 64K Rechners zu wahlen hatte, sind voruber. Heutige Systeme sind „integriert“. Fur beinahe alle vorstellbaren Probleme liegen Losungen bereit, eine verwirrende Vielfalt unterschiedlichster Werkzeuge wartet darauf, benutzt zu werden. Diese Feststellung gilt fur viele Bereiche der Computernutzung, fur die Bereiche Programmiersprachen und -Umgebungen ist sie offensichtlich. Die Zahl der primitiven Funktionen, Objekte, Variablen, usw. in Sprachen wie Commonlisp oder SmallTalk geht in die Hunderte oder Tausende; alles elementare Wissenseinheiten (Chunks), die der Programmierer lernen und schlieslich beherrschen mus.		Heinz-Dieter Böcker;Hubertus Hohl;Thomas Schwab	1990		10.1007/978-3-642-76119-5_35	art;performance art	Crypto	-105.22036139982863	33.82380834871662	174115
cfdb4c1c0f074ba365820217ed6e94f3c575e901	algol sub-committee report - extensions			algol	Edsger W. Dijkstra;W. Heise;Alan J. Perlis;Klaus Samelson	1959	Commun. ACM			Graphics	-94.36671162383979	33.06855947528973	174228
5b1fc839d2d96b05b2db2abe8a18c87e505a9aec	die einführung der datenhehlerei		Bereits seit einigen Jahren wurde der Diskurs auf Landesebene geführt, bevor sich der Gesetzgeber auf Bundesebene zur Einführung der Norm entschieden hat. Das Land Hessen hat einen Gesetzentwurf vorgelegt, mit dem die Einführung der Vorschrift des § 202d StGB vorgeschlagen wurde. Die endgültige Fassung des § 202d StGB ist mit einigen Änderungen vom Bundestag verabschiedet worden. Der Gesetzgeber lehnte sich grundsätzlich an den Gesetzentwurf des Landes Hessen an; der Wortlaut der Norm wurde indes präzisiert. Der Beitrag wirft die Frage auf, ob es in der Praxis überhaupt einer eigenen strafrechtlichen Vorschrift hierzu bedarf.		Smaro Tassi	2017	Datenschutz und Datensicherheit - DuD	10.1007/s11623-017-0871-3	internet privacy;computer science;law and economics	Security	-103.50548462069995	36.10462227703855	174236
2b937e42ff3e742c2f1986218f60b4a7a63edf6b	aspekte des qualitätsmanagements bei der implementierung einer suchmaschine.	information retrieval system;informa tion retrieval	In diesem Aufsatz soll die geplante Implementierung von Suchmaschinentechnologien im Fachportal Pädagogik zum Anlass genommen werden, um sich mit den damit verbundenen neuen Anforderungen an ein Qualitätsmanagement auseinanderzusetzen. Im Zentrum stehen die Fragen, welche Zusammenhänge die RechercheSituationen formen und welche Schlussfolgerungen sich daraus für ein Evaluationsdesign ergeben. Als analytisches Instrumentarium soll dabei eine soziotechnische Sichtweise auf das Information-Retrieval-System (IR) dienen.	eine and zwei;unified model	Christoph Schindler;Dirk Burmeister	2006			database;computer science	NLP	-106.69008858098356	35.61839318578372	174566
f64edef3fcd88b1d2db547ff0927009c6eb1411b	digitaler showdown - der wettbewerb um kontrolle in der autoelektronik		Software und Elektronik sind schon längst integraler Baustein jeder Autoplattform. Von aktiven Sicherheitsfunktionen über Infotainment-Lösungen bis zu Informationsund Kommunikationsmöglichkeiten – bis auf wenige Materialund Konstruktionsneuheiten werden Fahrzeuginnovationen durch Software und Elektronik überhaupt erst möglich. Ein Ende dieser Entwicklung ist nicht in Sicht: Mehr und mehr Unterhaltungselektronik bevölkert das Automobil, darunter gleichberechtigt integrierte Funktionen und Nachrüstlösungen, die im Vergleich zu werkseitig eingebauten Systemen leichter und schneller aktualisiert werden können, aber auch mittlerweile erheblich preisgünstiger sind als vorinstallierte Systeme. Auch als Bestandteil von Produktdifferenzierungsstrategien wird Software zunehmend wichtiger: Software und deren Funktionen sowie Benutzerschnittstellen sind direkt vom Fahrer wahrnehmbar und damit sehr markenprägend! Viele Automobilhersteller haben daher Software als zentrale Kompetenz erkannt – die meisten jedoch konnten diese Lücke in den letzten Jahren noch nicht vollständig schließen. Es ist absehbar, dass die Hersteller ihre Fahrzeuge schon bald mit einer erweiterbaren und konfigurierbaren Software-Ausstattung Digitaler Showdown – Der Wettbewerb um Kontrolle in der Autoelektronik	unified model	Jürgen Reiner;Axel Krieger	2011	Wirtschaftsinformatik & Management	10.1365/s35764-011-0072-z		SE	-103.10078727541718	32.42553349892458	174749
d0bd5f10de91f68b29ab5e41cea64fef7059ad26	schatten-it: implikationen und handlungsempfehlungen für mobile security		Die Gefahren, die von Schatten-IT ausgehen, ändern sich durch die größer werdende Akzeptanz der Anwender von Cloud Computing Services, die ortsunabhängig, jederzeit und von jedem (mobilen) Endgerät genutzt werden können. Auf der Basis von Experteninterviews und einer Vignetten-Studie zeigt der vorliegende Beitrag auf, dass es nicht an der technischen Umsetzung mangelt, Schatten-IT zu unterbinden, sondern eine geeignete unternehmensinterne Strategie, die auch das Mobile Device Management umfasst, vermisst wird. Hierzu werden entsprechende Handlungsempfehlungen aus den Ergebnissen abgeleitet.	cloud computing;eine and zwei;mobile device;mobile security	Marc Walterbusch;Adrian Fietz;Frank Teuteberg	2014	HMD Praxis der Wirtschaftsinformatik	10.1365/s40702-014-0006-3	marketing;operating system;mobile device management;engineering	OS	-102.515490004302	36.88196880609178	174855
30ef0e22992c70a98f6d90b15413dcc62c4c8258	objektorientierte systemarchitektur - ein ansatz zur unterstützung von fehlertoleranz				Jörg Kaiser;Edgar Nett	1983			quantum electrodynamics;ansatz;mathematics	Vision	-97.10311164636714	33.92610650506945	175206
922c4fb342c5ae68ad068f2e097cb68bb1dc8ca9	ein vollständiger ableitungsbegriff für die äquivalenz in einem funktionell unvollständigen dreiwertigen aussagenkalkül				Hans Rohleder	1977	Math. Log. Q.	10.1002/malq.19770232506	combinatorics;algebra;mathematics	Theory	-95.69299495059859	34.428648992971354	175317
e2110eee8ab7d77beff451055ad8570831f24e34	datenschutz und datensicherheit im service-rechenzentrum (i)		"""Das am 1. Januar 1978 mit seinen Hauptteilen in Kraft getretene Bundesdatenschutzgesetz (BDSG) hat eine Vielzahl von Zweifelsfragen aufgeworfen, die nicht nur auf die Neuartigkeit dieser komplizierten Materie, sondern auch auf die Verwendung unbestimmter Rechtsbegriffe und daraus resultierende Interpretationsschwierigkeiten und Fehlauslegungen zurückzuführen sind. Viele dieser Zweifelsfragen betreffen auch die Tätigkeit der Service-Rechenzentren. Zwar beinhalten die von der obersten Landesaufsichtsbehörde jüngst beschlossenen „vorläufigen Verwaltungsvorschriften zum Bundesdatenschutzgesetz"""" eine Reihe von Hinweisen zur Anwendung dieses Gesetzes, doch verbleiben immer noch — zum Teil wegen mehrdeutiger Formulierungen — viele klärungsbedürftige Problemkreise. Darüber hinaus haben diese Verwaltungs-"""	eine and zwei	Jürgen Hund	1978	Praxis der Informationsverarbeitung und Kommunikation	10.1515/piko.1.1978.1.2.61	computer science;distributed computing	OS	-104.17430892553105	34.14950616273724	175417
69b1aa0c9d0b41e72c9881113e99cfd80323c090	yazılım efor tahmininde farklı bir yaklaşım: sınır değerlerine göre tahmin		Özet. Yazılım efor tahmini, yazılım proje yönetiminde çok önemli bir aşamadır. Tahmin değerinin doğruluğu proje başarı ya da başarısızlığına doğrudan etki eder. Yöneticiler uygun kaynakları tahmin etmeye çalışırlar ve bu yönetim için zorlayıcı bir durumdur. Araç ve tekniklerin yardımıyla tahmin süreci daha iyi gerçekleştirilebilir. COCOMO en çok kullanılan, parametrik modellerden biri olarak ifade edilen yöntemlerdendir. Aynı zamanda, COCOMO tabanlı Yapay sinir ağlarının (YSA) kullanıldığı çalışmalar da mevcuttur. Bu çalışmalarda toplam performansın arttığı gösterilmiştir. Fakat efor tahmini süreci, genelde, tek çıktı üretir: tahmin edilen efor değeri. Bir proje yöneticisinin tahminlerinde bazı üst ve alt limitleri, sınırları dikkate alması gerektiği bilinen bir gerçektir. Bu çalışmada yeni bir metot önerilmiş, COCOMO tabanlı YSA ile K-Means kullanılarak efor tahmini ve olası sınırlar belirlenmiştir. YSA çıktısı K-Means kümelerine girdi olarak sunulmuş, olası küme belirlenmiş ve buna göre olası üst ve alt limit efor tahmin değerleri üretilmiştir. Deneysel çalışma sonuçları sayısal olarak kabul edilebilir düzeyde çıkmış ve kullanılabilir birden çok tahmin değeri üretilerek daha pratik bir efor tahmin sürecinin olabileceğini göstermiştir.	cocomo;k-means clustering	Ömer Faruk Saraç;Nevcihan Duru	2013			art;performance art	ML	-101.11371111156689	32.45252287702537	175624
4d31c6c4bc787b3af2bbcded8391c8aef365edca	uml4all: gemeinsam in diversity teams software modellieren		Das gemeinsame Entwerfen von UML-Modellen durch Personen mit und ohne Seheinschränkung ist durch die aktuell vorhandenen Werkzeuge und Modellierungssprachen nur eingeschränkt möglich. Grund hierfür sind unter anderem Werkzeuge wie Eclipse, die nur bedingt barrierefrei bedienbar sind und Modellierungssprachen wie z. B. PlantUML, die die Anforderungen für eine barrierefreie Nutzung nur teilweise erfüllen. So können blinde Software-Entwickler zwar mit Eclipse und den existierenden UML-Plugins grafische Modelle erzeugen, diese jedoch nicht mit einem Screenreader lesen. Im Rahmen des Cooperate-Projektes wurde ein Kooperationswerkzeug entwickelt, das je nach Arbeitsweise eine textuelle oder grafische Modellierung erlaubt. Änderungen werden synchron gehalten. Für die textuelle Modellierung von UML-Diagrammen wurde mit UML4ALL eine textuelle Syntax entworfen, die ohne die Nachahmung von visuellen Elementen durch ASCII-Zeichen auskommt und der Arbeitsweise von Menschen mit Blindheit beispielsweise durch die Verwendung einer Präfixnotation entgegenkommt. Diese neue Sprache hilft nicht nur Menschen mit Seheinschränkung, sondern allen, die Modelle textuell entwerfen möchten. Das beschriebene Vorgehen lässt sich auch auf andere grafische Notationen übertragen. Um den Einstieg in die UML, in UML4ALL, in PlantUML und in die Entwicklungsumgebung Eclipse zu erleichtern, wurden Schulungsmaterialien erstellt, die mithilfe von taktilen Grafiken, textuellen Beschreibungen und Einführungstexten die unterschiedlichen Themen näher erläutern. Alle bisher entwickelten Inhalte inklusive einer ersten Version des Kooperationswerkzeugs wurden von Personen mit Seheinschränkung getestet und zur Verbesserung der Materialien verwendet.	eine and zwei;eclipse;internet explorer;plantuml;plug-in (computing);unified model;unified modeling language	Karin Müller;Vanessa Petrausch;Gerhard Jaworek;Jörg Henß;Stephan Seifermann;Claudia Loitsch;Rainer Stiefelhagen	2017	Informatik-Spektrum	10.1007/s00287-017-1073-y	world wide web;computer science;performance art	Logic	-102.3010698700573	32.340024917096635	175693
09851d5d833a53e66c0d8b0553ea14c5e8c0750e	on roundoff error distributions in floating point and logarithmic arithmetic	distribution;arithmetique ordinateur;probabilistic model;computers arithmetic;floating point;ams subject classification;calculateur logarithmique;floating point arithmetic;distribucion;rounding error;virgule flottante;erreur arrondi	Probabilistic models of floating point and logarithmic arithmetic are constructed using assumptions with both theoretical and empirical justification. The justification of these assumptions resolves open questions in Hamming (1970) and Bustoz et al. (1979). These models are applied to errors from sums and inner products. A comparison is made between the error analysis properties of floating point and logarithmic computers. We conclude that the logarithmic computer has smaller error confidence intervals for roundoff errors than a floating point computer with the same computer word size and approximately the same number range. Unter Zugrundelegung von sowohl theoretisch als auch empirisch gerechtfertigter Annahmen wird ein stochastisches Modell der Gleitkomma- und der logarithmischen Arithmetik konstruiert. Die Rechtfertigung dieser Annahmen löst offene Fragen bei Hamming (1970) und Bustoz et al. (1979). Diese Modelle werden auf die Fehler von Summen und inneren Produkten angewendet. Es wird ein Vergleich zwischen den Eigenschaften von Gleitkomma- und logarithmischen Rechnern hinsichtlich ihrer Fehleranalyse angestellt. Wir kommen zu dem Schluß, daß der logarithmische Rechner kleinere Fehlerkonfidenzintervalle für die Rundungsfehler aufweist als ein Gleitkommarechner mit der gleichen Wortlänge und dem annähernd gleichen Zahlenbereich.	computer;error analysis (mathematics);logarithmic number system;round-off error;v-model	Jesse L. Barlow;Erwin H. Bareiss	1985	Computing	10.1007/BF02251833	arithmetic;discrete mathematics;binary scaling;floating point;mathematics;machine epsilon;algorithm	Theory	-96.02764082393287	36.30251427456285	175921
be49782220cc05af58a912887f955a2af0bfdb59	kompetenzorientierte lehre im software engineering		Software Engineering ist eine komplexe Aufgabe, die von den Beteiligten ausgeprägte Kompetenzen in vielen verschiedenen Bereichen fordert. Die Vermittlung dieser Kompetenzen über das reine Fachwissen hinweg ist eine zentrale Aufgabe, die eine SoftwareEngineering-Ausbildung leisten muss, um Absolventen für den Einsatz in der Praxis zu qualifizieren. Ausgehend von den zu vermittelnden Kompetenzen zeigen wir, wie wir in unserer Lehrpraxis mit Hilfe eines möglichst einfach gehaltenen, aber so komplex wie nötig gestalteten durchgängigen Beispiels sowie durch innovative Lehrmethoden praxisnah eine fundierte Einführung in die komplexen Tätigkeiten des Software Engineerings vermitteln.	altran praxis;eine and zwei;internet explorer;software engineering;unified model	Axel Böttcher;Veronika Thurner;Gerhard Müller	2011			software engineering;computer science	SE	-101.56911015450646	32.36794415686786	175929
b76c3fb430010200d0c854b1ca41f0b40dbc31c5	zur theorie der syntaktischen analysealgorithmen für kontextfreie grammatiken ii				Dieter Bär	1969	Elektronische Informationsverarbeitung und Kybernetik		pure mathematics;combinatorics;mathematics	NLP	-95.47480585477179	34.35275178236514	176139
b5c2c31d4e50ccde5c45bcadf2458d7ce3c1f357	kompositionsbildung bei symbolfolgen und bediensequenzen: empirische befunde und die theorie des „competitive chunking”	artificial grammar learning	Im Paradigma des Grammatiklernens mussen zunachst regelhaft strukturierte Symbolfolgen memoriert werden. In einer unerwartet folgenden Testphasemussen weitere Symbolfolgen danach beurteilt werden, ob sie den vorangegangenen ahnlich sind. Die Diskriminierbarkeit grammatikkonformer und agrammatischer Symbolfolgen ohne Kenntnis der grammatischen Struktur wird als Indiz fur unbewustes Lernen angesehen. Eine Erklarung dieses Effektes besteht darin, das die Memorierung der Folgen zur Bildung von Kompositionen (Chunks) fuhrt, die — hierarchisch organisiert — der kompakten Reprasentation der Symbolfolgen dienen. Mit zunehmender Kompaktheit der Wahrnehmung erscheinen die Folgen vertrauter und werden bei Unsicherheit uber das richtige Urteil eher als ahnlich beurteilt. Fur den inzidentellen Erwerb von Bedienwissen konnte ebenfalls die Bildung von Kompositionen nachgewiesen werden. Dabei zeigten sich allerdings zwei Besonderheiten: (a) die Sensitivitat gegenuber Verletzungen der grammatischen Struktur ist generell geringer und (b) Verletzungen am Ende zu diskriminierender Sequenzen sind wichtiger als solche am Anfang. Beide Besonderheiten verschwanden, wenn — analog zu Buchstabenfolgen — die Einzelinformationen einer Sequenz permanent verfugbar waren. In der vorliegenden Simulationsstudie wurde untersucht, ob diese Befunde mit den theoretischen Vorstellungen zur Kompositionsbildung zu vereinbaren sind. Zum einen wurde untersucht, ob der Einflus der Verf ugbarkeit der Sequenzinformation dadurch reproduzierbar ist, das die Differenzierung der Retentionsintervalle variiert wird. Zum anderen wurde untersucht, ob die Kompositionsbildung fur die Wahrnehmung obligatorisch ist. Die Differenzierung der Retentionsintervalle bewirkte nur marginale Veranderungen. Die empirischen Effekte konnten nur dann reproduziert werden, wenn in der Diskriminationsphase die Bildung grammatikkonformer Kompositionen angenommen wurde. Die Implikationen dieser Befunde werden abschliesend diskutiert.		Burkhard Müller	1998	Kognitionswissenschaft	10.1007/BF03354927	psychology;computer science	Crypto	-106.35674931087716	33.41176093712052	176207
eb554968a7500091395596db63472718f0a0814d	geschäftsprozessmodellierung: die ,,killer-applikation“ für petrinetze	сети петри;управление бизнес процессами;моделирование процессов	Seit ihrem Entwurf im Jahr 1962 sind Petrinetze in ganz unterschiedlichen Bereichen eingesetzt worden. Obwohl sie graphisch dargestellt werden und intuitiv einfach verständlich sind, haben Petrinetze eine formal eindeutige Semantik mit einer Vielzahl mathematischer Analysetechniken. Sie reichen vom Model Checking und der Strukturellen Analyse über das Process Mining bis zur Performanz-Analyse. Im Lauf der Zeit haben Petrinetze solide Grundlagen für die Forschung zum Geschäftsprozess-Management (BPM) beigetragen. Sie umfassen Methoden, Techniken und Werkzeuge um Geschäftsprozesse zu entwerfen, implementieren, verwalten und zu analysieren. Die etablierten Modellierungsmethoden und Workflow-Managementsysteme verwenden Token-basierte, von Petrinetzen entlehnte Beschreibungen. Nutzer moderner BPM-Analysetechniken wissen oft gar nicht, dass ihre Geschäfts- prozesse intern als Petrinetze repräsentiert werden. Dieser Beitrag zeigt die grundlegende Rolle von Petrinetzen im BPM.	beam propagation method;eine and zwei;model checking;sie (file format);unified model	Wil M. P. van der Aalst	2013	Informatik-Spektrum	10.1007/s00287-013-0756-2	world wide web;computer science	Logic	-103.07538729507951	32.88295532782356	176378
148848f6b490772eb131546971b2a69d89cb66e5	calculus for interval functions of a real variable		Some properties of the algebraical system <I(R),+,o,−>, where <I(R),+,o> is the well known quasinear interval space and “−” is a nonstandard operation such thata−a=o, are given in this paper. The an elementary calculus for interval functions using this nonstandard arithmetic is discussed. In dieser Arbeit betrachten wir die Menge <I(R),+,o,−> aller Intenvale hinsichtlich der zwei bekannten Verknüpfungen +und o und einer Nicht-Standard-Verknüpfung “−” mit der Eigenschafta−a=o. Eine elementare Differential- und Integralrechnung für intervallwertige Funktionen kann man auf dieser Basis entwickeln.	eine and zwei;emoticon;whole earth 'lectronic link	Svetoslav Markov	1979	Computing	10.1007/BF02265313	mathematical analysis;discrete mathematics;calculus;mathematics	Theory	-96.27534029842249	35.07564192137121	176550
df9895e57ac4e52d8773306d0533ef16c66b5e6f	autorenwerkzeuge für digitale, multimediale und interaktive lernbausteine im web 2.0		eleed, Iss. 10 - Die vorliegende Forschungsarbeit siedelt sich im Dreieck der Erziehungswissenschaften, der Informatik und der Schulpraxis an und besitzt somit einen starken interdisziplinaren Charakter. nnAus Sicht der Erziehungswissenschaften handelt es sich um ein Forschungsprojekt aus den Bereichen E-Learning und Multimedia Learning und der Fragestellung nach geeigneten Informatiksystemen fur die Herstellung und den Austausch von digitalen, multimedialen und interaktiven Lernbausteinen. Dazu wurden zunachst methodisch-didaktische Vorteile digitaler Lerninhalte gegenuber klassischen Medien wie Buch und Papier zusammengetragen und mogliche Potentiale im Zusammenhang mit neuen Web 2.0-Technologien aufgezeigt. Darauf aufbauend wurde fur existierende Autorenwerkzeuge zur Herstellung digitaler Lernbausteine und bestehende Austauschplattformen analysiert, inwieweit diese bereits Web 2.0-Technologien unterstutzen und nutzen. nnAus Sicht der Informatik ergab sich aus der Analyse bestehender Systeme ein Anforderungsprofil fur ein neues Autorenwerkzeug und eine neue Austauschplattform fur digitale Lernbausteine. Das neue System wurde nach dem Ansatz des Design Science Research in einem iterativen Entwicklungsprozess in Form der Webapplikation LearningApps.org realisiert und stetig mit Lehrpersonen aus der Schulpraxis evaluiert. Bei der Entwicklung kamen aktuelle Web-Technologien zur Anwendung. Das Ergebnis der Forschungsarbeit ist ein produktives Informatiksystem, welches bereits von tausenden Nutzern in verschiedenen Landern sowohl in Schulen als auch in der Wirtschaft eingesetzt wird. In einer empirischen Studie konnte das mit der Systementwicklung angestrebte Ziel, die Herstellung und den Austausch von digitalen Lernbausteinen zu vereinfachen, bestatigt werden. nnAus Sicht der Schulpraxis liefert LearningApps.org einen Beitrag zur Methodenvielfalt und zur Nutzung von ICT im Unterricht. Die Ausrichtung des Werkzeugs auf mobile Endgerate und 1:1-Computing entspricht dem allgemeinen Trend im Bildungswesen. Durch die Verknupfung des Werkzeugs mit aktuellen Software-Entwicklungen zur Herstellung von digitalen Schulbuchern werden auch Lehrmittelverlage als Zielgruppe angesprochen.	web 2.0	Michael Hielscher	2012			art;performance art	HCI	-107.46931761244682	34.33588079729656	176982
120a898aa653c7fa487ef3a0a975e7b1cd639b00	ein partitionierungsdienst für geographische daten in räumlichen datenbanken		Da in der computergestützten Geographie mit zum Teil sehr großen Mengen von räumlichen Daten gearbeitet werden muss, hat sich mittlerweile die Überzeugung durchgesetzt, solche Datensätze in räumlichen Datenbanken zu speichern. Allerdings wird bei der Entwicklung von geographischen Programmen dem Aspekt der Skalierbarkeit oftmals wenig Beachtung geschenkt. So enthalten verbreitete Programme für Geoinformationssysteme wenig bis keine sogenannten externen Algorithmen, die den Geschwindigkeitsunterschied zwischen internem (RAM) und externem Speicher (Festplatte) berücksichtigen und versuchen, die Anzahl der I/O-Zugriffe auf letzteren zu minimieren. Diese Programme arbeiten daher nur dann effizient, wenn genug interner Speicher für die zu bearbeitenden Geodaten zur Verfügung steht. Wir stellen in diesem Beitrag einen auf Partitionierung basierenden Ansatz vor, der den Aufwand für die Entwicklung von auf großen Geodatenmengen skalierenden Programmen stark reduziert. Dazu werden Zugriffe auf externe Speicher in eine vorgelagerte Partitionierungsund eine nachgelagerte Rekompositionsphase verschoben und für diese Phasen flexible Operationen, die ein breites Spektrum an geographischen Problemstellungen unterstützen, als Partitionierungsdienst für räumliche Datenbanksysteme angeboten.	eine and zwei;random-access memory;vhf omnidirectional range	Hendrik Warneke;Udo W. Lipeck	2012			computer science	OS	-104.13896141689798	32.845146930404226	177523
2a156bcba7c3fb9195f25e5c94c709dd7f138183	die didaktische rekonstruktion für den informatikunterricht		Wichtige Grundfragen der Didaktik der Informatik sind, in welcher Weise Informatikunterricht zu fassen ist, wie er geplant, durchgeführt oder erforscht werden sollte. Etliche fachdidaktische Ansätze versuchten bereits hierfür einen Rahmen zu schaffen und auch die fundamentalen Ideen von Schwill, die Bildungsstandards für Informatik der GI und unzählige Materialien und einige Bücher geben entsprechende Hinweise. Die Konstruktion von Informatikunterricht verläuft aber immer sehr individuell und bisher größtenteils unerforscht. Wir möchten hier einen Rahmen zur Entwicklung und Erforschung von Informatikunterricht vorstellen, welcher die Didaktische Rekonstruktion nutzt, um sich dem Informatikunterricht sowohl in der Forschung als auch in der Unterrichtsplanung strukturierter zu nähern.	didaktik;gesellschaft für informatik;internet explorer;unified model	Ira Diethelm;Christina Dörge;Ana-Maria Mesaros;Malte Dünnebier	2011			computer science	OS	-104.42638418683214	33.1005120231581	178157
b99680b44ce5868c57dee3b1184b536e34047450	efficient evaluation of splines	spline;series expansion;approximation;developpement taylor;developpement serie	An algorithm is presented to compute the Taylor expansion of a polynomial B-spline function from its de Boor points. It is shown to be more efficient than existing methods and has the additional advantage of being reversible. Es wird ein Algorithmus für die Berechnung der Taylorkoeffizienten eines Polynomsplines aus dessen de Boor-Punkten angegeben. Er ist schneller als die üblichen Methoden und dazu umkehrbar.	b-spline;de boor's algorithm;polynomial;reversible computing;spline (mathematics)	Wolfgang Böhm	1984	Computing	10.1007/BF02240188	spline;mathematical optimization;mathematical analysis;series expansion;de boor's algorithm;approximation;calculus;mathematics;geometry	HPC	-96.70056667337178	35.92057163588164	178269
2dd942cb569a86710c58bd92d03339ed3f19b01e	referenz-architektur und nichtfunktionale anforderungen adaptiver dialogkerne		Die Service-oriented Architecture (SOA) ermöglicht die Flexibilisierung von Anwendungen durch Einbindung von Diensten zur Laufzeit und durch Verwendung einer Vielzahl von Technologien zur Kommunikation mit den eingebundenen Diensten. Spätestens in Benutzungsschnittstellen (BSS) müssen EntwicklerInnen die fachliche und technologische Vielfalt von Diensten adressieren, da sich die BSS an die verwendeten Dienste anpassen muss. Die Komponente der BSS, die für die Anpassung an die verwendeten Dienste zuständig ist, wird im folgenden „adaptiver Dialogkern“ genannt. In unserem Beitrag formulieren wir funktionale und nichtfunktionale Anforderungen an einen adaptiven Dialogkern und stellen darauf basierend ein mögliches Architektur-Modell vor, welches die Konfiguration und Einbindung von Diensten zur Laufzeit ermöglicht. Für die Realisierung beurteilen wir den Einsatz einer Bibliothek mit technischen Adaptern und den Einsatz von Rahmenwerken zur „Dependency Injection“ (DI).	dependency injection;service-oriented architecture;service-oriented device architecture;v-model;vhf omnidirectional range	Jürgen Rückert;Barbara Paech	2007			food science;caramel color;food color;chemistry	AI	-103.42946922399165	33.18598410325534	178476
5163573914b5e691c4edf3bf8fcf35a7d5b4e42e	sicherheitsmechanismen für kontaktlose chips im deutschen reisepass	chip	Dieser Artikel gibt einen Überblick Über die Ziele und die Funktionsweise der Sicherheitsmechanismen, die im deutschen elektronischen Reisepass (ePass) zur Anwendung kommen. Dieses beinhaltet auch die erweiterten Sicherheitsmechanismen, welche in der zweiten Stufe elektronischer Reisepässe hinzukommen.	gesellschaft für informatik	Dennis Kügler;Ingo Naumann	2007	Datenschutz und Datensicherheit - DuD	10.1007/s11623-007-0066-4	chip;computer science	EDA	-103.82811425206812	32.51452741725507	179022
a90e2e90bb92a50cd42f3d823cd53e75219fb38a	zeitliche verläufe emotionaler aktivierung in der mensch-technik-interaktion / temporal dynamics of emotional activation in man-machine interaction	emotionen;emotionale dynamiken;research article	Im alltäglichen Leben helfen uns Emotionen, Situationen zu bewerten um auf diese Bewertungen adäquat zu reagieren. Ebenso beeinflussen sie die Art von Situationen, die wir bewusst aufsuchen (Frijda 2007). Im Nutzungskontext von modernen, interaktiven Technologien sind diese Bewertungsund Verhaltensaspekte von besonderer Relevanz. Sie sind u. a. verantwortlich dafür, dass wir bestimmte Nutzungsszenarien gezielt meiden oder aufsuchen bzw. mit mehr oder weniger Erfolg (d. h. effizienter) durchlaufen (Hassenzahl & Tractinsky 2006). Für die Untersuchung scheint es sinnvoll, den emotionalen Zustand von Personen vor der Interaktion mit technischen Geräten und die Auswirkungen von Emotionen während der Mensch-Technik-Interaktion in Studien zu betrachten. Diesen Versuch unternimmt die vorliegende Arbeit. Die Analyse von Emotionen in dieser Studie ist zweigeteilt: Zum einen soll eine differenzierte Induktion von Emotionen durch eine Mensch-Technik-Interaktion erfolgen. Zum anderen wird der Einfluss dieser Emotionsinduktion auf die anschließende Interaktion mit einem Tablet untersucht. Dabei ist es von Bedeutung, ob und wie sich die Dynamik der Aufgabenbearbeitung unter dem Einfluss der jeweiligen Emotion verändert. 1.1 Emotionsinduktion durch Mensch-TechnikInteraktion	eine and zwei;emotion markup language;internet explorer;sie (file format);tablet computer;unified model;vhf omnidirectional range	Nils Backhaus;Stefan Brandenburg	2014	i-com	10.1515/icom-2014-0009	psychology;developmental psychology;cognitive science	AI	-108.30712377500782	32.727052710820864	179037
5810f46a637c7ae64ec9c87d92387929ead97c71	modulare einführung für eine bedarfsorientierte unterstützung der vorgangsbearbeitung		In der kommunalen Vorgangsbearbeitung steigt der Bedarf nach ITUnterstützung spürbar an. Das resultiert sowohl aus einer zunehmend fragmentierten Ablage von Informationen in Kommunalbehörden als auch aus einer steigenden Vernetzung mit anderen Behörden, wie sie sich bspw. aus der EUDienstleistungsrichtlinie ergibt. Um hier dem fachlichen Bedarf einerseits und den finanziellen Restriktionen andererseits angemessen Rechnung tragen zu können, wurde die Methode der modularen Einführung entwickelt. Die Methode wird beschrieben und einer kritischen Diskussion unterzogen.	eine and zwei;internet explorer;sie (file format);unified model	Jeff Licker;Andreas Mayer;Siegfried Kaiser	2010			engineering	OS	-103.86600798165188	32.81671747714226	179103
8a796517d3d3ea03ec4b20232a9fab6eaab1cf09	voraussetzungen für eine sensorgesteuerte teilflächen-spezifische n-düngung		In mehrjährigen Untersuchungen wurden Reflexionsme s ungen an verschiedenen landwirtschaftlichen Kulturpflanzen mit dem Ziel der Erarbeitung der Voraussetzungen eines Systems für eine teilflächens pezifische Stickstoffdüngung druchgeführt. Der Beitrag behandelt die Punkte: a) Eignung verschiedener Vegetationsindices zur Abbildung der Stickstoffaufnahme u nd deren Stabilität gegenüber Umwelteffekten, b) Anforderungen und Ableitung von Messund Applikationsalgorithmen, c) Entwicklung von Düngealgorithmen für die Bemessung der teilflächenspezifischen N-Düngung, dargestellt am Beispiel von Winterweizen. 1. Einleitung und Problemstellung Aufgrund von natürlichen Bodenheterogenitäten inner halb der Schläge kommt es zu mehr oder weniger großen Ertragsunterschieden einze lner Teilflächen mit entsprechenden Abweichungen im Nährstoffentzug. Eine flächenei nh tliche Düngung führt auf derartigen Flächen zu entsprechenden Nährstoffüberb zw. –unterbilanzen. Sowohl hohe Nährstoffüberwie auch Nährstoffunterbilanzen sind ökonomisch und ökologisch als nachteilig zu bewerten. Nur durch eine entsprechend e teilflächenspezifische N-Düngung lassen sich diese Probleme vermeiden. Prinzipiell lassen sich drei verschiedene Verfahren d r Teilschlagdüngung unterscheiden, der mapping-Ansatz, der online-Ansatz und der Ansatz online mit mapoverlay. In der Literatur wie auch in der Praxis werden vor all em sensorgestützte Ansätze (online, online mit mapoverlay) diskutiert bzw. eingesetzt. Gegenüber den Sensorsystemen wird jedoch in jüngster Zeit vermehrt Kritik geübt, da d er große Mehrwert häufig ausbleibe, so einige Aussagen (Ru11, Ga11).	altran praxis;eine and zwei;emoticon;gesellschaft für informatik;internet explorer;vhf omnidirectional range	Franz-Xaver Maidl	2012				OS	-104.68989586030735	32.76583719435116	179262
5f9435c88b6090261f3edb65f0c0de62065b7fed	"""eine bemerkung zum aufsatz """"der fundamentalsatz der algebra und der intuitionismus"""" von h. kneser"""		Es gibt heute mehrere konstruktive Beweise des Fundamentalsatzes der Algebra. Die meisten handeln von dem Spezialfall eines Polynoms mit ganzzahligen Beiwerten oder eines normierten Potynoms. Brouwer und sp/iter H. Kneser haben auch die erweiterte Fassung des Fundamentalsatzes betrachtet, in dem zum mindesten ein Beiwert as (k>0) positiv von Nutl verschieden ist, [I], [3]. Die Methode von Kneser ist ganz elegant und v611ig algebraisch. Kneser ffihrte den Allgemeinfall zuriick auf den Fall eines normierten Polynoms und fand eine	brouwer fixed-point theorem;die (integrated circuit);eine and zwei	Dirk van Dalen	1985	Arch. Math. Log.	10.1007/BF02007555		DB	-96.45941941566838	34.82832116044735	179579
9b652daba7341b8bf52487f602ebf395e50c4229	gesamtkonzept eines ergebnisorientierten integrierten planungssystems in der versicherungswirtschaft				Peter Gessner	1987	Zeitschr. für OR	10.1007/BF01272656	discrete mathematics;applied mathematics;mathematics	Vision	-95.89457695819249	34.41901080632939	180895
f4e99fb3cf56d61d64af201ecd6cb8cc04f2f117	die veränderung der planungs- und denkanforderungen durch den einsatz von cad im konstruktionsbüro	den einsatz von cad;nderung der planungs;im konstruktionsb	Die neuen Informations- und Kommunikationstechniken kommen auch in den Bereichen der Produktion zum Einsatz, in denen sich die Arbeitsmittel in den letzten 100 Jahren nicht sehr wesentlich verandert haben. Es sind dies vor allem die der Fertigung vorgelagerten Bereiche Konstruktion und Arbeitsplanung sowie Verwaltung und Vertrieb. Gerade der - bisher zahlenmasig eher geringe Einsatz von Computersystemen in Konstruktion und Arbeitsplanung hat eine breite Diskussion uber die sozialen und psychischen Folgen hervorgerufen. Ausschlaggebend dafur sind zwei Grunde: zum einen ist der Einsatz von Computersystemen in der Konstruktion ein Baustein fur die geplante Integration von Planung und Fertigung durch Computernetze, eine Zielstellung, die sich in dem Schlagwort “CIM” (computer integrated manufacturing = Computergestutzte integrierte Fertigung) ausdruckt. Zum anderen aber stellt gerade der Einsatz des Computers in einem Bereich, der wie die Konstruktion als “kreative Insel” in der sonst weitgehend standardisierten und formalisierten Produktion gilt, eine deutliche Herausforderung dar.	computer-aided design	Martin Resch	1986		10.1007/978-3-642-71380-4_20	performance art;art	EDA	-104.01484313145629	32.95419577236386	181133
a82b7f8d4cedc6521c3fe32f0285530330a77a02	"""einleitung zum themenheft """"ressourcenadaptive kognitive prozesse"""""""		In der Kognitionswissenschaft tritt der Begriff einer beschr̈ankten Ressource in vielen Zusammenḧ angen auf. Insbesondere wird der TermRessourceauf sehr unterschiedliche Entiẗ aten angewandt, unter anderem auf Zeit, (menschliches und maschinelles) Ged ächtnis, Wissen und Information. Durch die breite Anwendung dieses Begriffs lassen sich einige weitere gemeinsame Begriffe – sowie damit zusammenḧangende Fragestellungen – erkennen. Aus diesen Gemeinsamkeiten ergeben sich M öglichkeiten f̈ ur eine fruchtbare interdisziplin̈are Zusammenarbeit. Anfang 1996 nahm in Saarbr ücken der von der Deutschen Forschungsgemeinschaft unterst ützte Sonderforschungsbereich ,,Ressourcenadaptive kognitive Prozesse“ seine Arbeit auf. Dieses Forschungsprogramm umfaßt 11 Projekte, deren Leiter in den Disziplinen Computerlinguistik, Informatik, Philosophie und Psychologie t ätig sind; mehrere der Projekte werden von Vertretern verschiedener Disziplinen gemeinsam geleitet. Das vorliegende Themenheft soll den Lesern eine repr äsentative Stichprobe der Forschung in diesem SFB bieten. Während die Autoren und der Gastherausgeber aus dem SFB 378 stammen, wurden alle Gutachten (mindestens zwei für jede Einreichung) von Fachkollegen außerhalb Saarbr̈ uckens erstellt. Mit ihren fachkundigen und ausf ührlichen Kritiken haben die Gutachter das Themenheft entscheidend mitgestaltet. Aufgrund der Gutachten traf der Herausgeber der Zeitschrift Kognitionswissenschaft , Prof. Dr. Gerhard Weber, die Entscheidungen in bezug auf Annahme und Ablehnung von Manuskripten. In dieser Einleitung wird zuerst der weitgefaßte Begriff einerRessource , der im SFB 378 verwendet wird, kurz motiviert und skizziert. Dann werden die einzelnen Artikel im Themenheft in diesen Rahmen eingeordnet. Insbesondere wird am Schluß er̈ ortert, welche Formen vonRessourcenadaptiviẗat in den Projekten des SFB unterschieden werden. 1	blue (queue management algorithm);eine and zwei;graph edit distance	Anthony Jameson;Kai Buchholz	1998	Kognitionswissenschaft	10.1007/s001970050059		OS	-104.72597147518461	33.811420760636686	181143
34280436f24a0df9f00c673398e1b753d9dc8157	rezension „fit für die prüfung: wirtschaftsinformatik“		Prüfungsvorbereitung ist eine besondere „Disziplin“, jede(r) Studierende(r) geht – entsprechend seinen Vorlieben – anders vor. Eine Möglichkeit, auf eine Prüfung zu lernen, ist die Nutzung eines Lernbuches, wie es das vorliegende Büchlein ist. In insgesamt 10 Etappen werden die Grundlagen der Wirtschaftsinformatik angesprochen. Gelungen ist die didaktische Struktur, die in jeder Etappe mit einer „Motivation“ beginnt. In ihr werden der Inhalt, wichtige Schlagworte, der „Einsatzbereich“ des erworbenen Wissens und Prüfungstipps zusammengefasst. Damit hat der Leser bereits eine erste Orientierung und kann entscheiden, ob er diese Etappe durchgehen, oder lieber an anderer Stelle fortsetzen möchte. Jede Etappe schließt dann mit einem „Zwischenstand“, in dem ein kleiner Multiple-Choice-Test das erworbene Wissen prüft. Die richtigen Antworten können – ganz im Sinne des Zeitalters der Digitalisierung – über einen QR-Code abgefragt werden. Eine Lernkontrolle ist damit leicht möglich. Allerdings muss eine Internetverbindung bestehen. Die Lösungen hätten alternativ sicherlich auch am Ende des Buches eingefügt werden können, dann wäre es ohne jede Technik möglich, sein Wissen abzugleichen, aber eben nicht so modern. Am Ende des Buches finden sich stattdessen hilfreiche Quellen und eine Tabelle, in der aus allen 10 Etappen die jeweils erworbenen, sog. „Fitness-Punkte“ eingetragen und addiert werden können. Ein kleines Stichwortverzeichnis, das auch etwas mehr Einträge hätte aufnehmen können, rundet das Lernbuch ab. Die Auswahl der Themen und ihre Detailtiefe können als gelungen bezeichnet werden.	am broadcasting;anhidrosis, isolated, with normal sweat glands;antilymphocyte serum;coagulum lysis:prthr:pt:ppp:ord:coag;codes of ethics;concern sexual preference;diethylstilbestrol;eine and zwei;endometrial intraepithelial neoplasia;fitness centers;ist-fs 29;internet explorer;penicillium eben-bitarianum;qr code;reflex, vestibulo-ocular;salvia aristata;tricyclic antidepressants tested for:prid:pt:ur:nar:screen;vhf omnidirectional range;van der woude syndrome	Matthias Knoll	2016	HMD Praxis der Wirtschaftsinformatik	10.1365/s40702-016-0276-z	engineering management;business informatics;knowledge management;engineering	OS	-105.3095947543405	35.54642589546	181252
604981e96450a4163f4517250a2cc1405ff84d11	verallgemeinerungen im zusammenhang mit dem stufenbegriff und ihre bedeutung für die theorie der compiler			compiler	Hans Rohleder	1975	Elektronische Informationsverarbeitung und Kybernetik		combinatorics;compiler;algorithm;mathematics	PL	-95.80573300596261	34.217599668276925	181259
145ba161004938bb21944c730ef0edd1077c9e5c	zuverlässigkeitsbewertung einer getriebesteuerungs-software durch auswertung der betriebserfahrung		Für den Einsatz komplexer Softwaresysteme in sicherheitskritischen Anwendungsbereichen ist angesichts der schwerwiegenden Folgen von Versagen ein rigoroser Nachweis hoher Zuverlässigkeit angebracht und oft auch vorgeschrieben. Die während einer vorangegangenen Testoder Betriebsphase beobachtete fehlerfreie Funktionsweise deutet zwar auf ein zuverlässiges Produkt hin, jedoch fehlen bisher Methoden um einen quantitativen Nachweis auf Basis der gewonnen Betriebserfahrung zu erbringen.	unified model	Sven Söhnlein;Francesca Saglietti;Franz Bitzer;Siegfried Baryschew	2009	Softwaretechnik-Trends		computer science;software;software engineering	OS	-102.54640692189508	32.66863557342547	181508
344bfe3e952099c9ee42a09681ebb4ce67661afc	big data mit datenschutz - mission impossible?		Big Data stellt wesentliche Datenschutzprinzipien auf den Kopf: Die massenhafte, ergebnisoffene und auf Dauer angelegte Sammlung und Auswertung von Daten scheint in einem unlösbaren Widerspruch zu den Anforderungen der Erforderlichkeit, Zweckbindung und der Datensparsamkeit zu stehen. Dabei gibt es durchaus Ansätze, wie sich der Konflikt entschärfen lässt: Die frühzeitige Berücksichtigung datenschutzrechtlicher Fragestellungen, Vorkehrungen zur Anonymisierung und Pseudonymisierung und ein Höchstmaß an Transparenz können verhindern, dass sinnvolle Big Data-Ansätze am Datenschutz scheitern.	big data;internet explorer	Peter Schaar	2014			history;performance art	ML	-100.99483257146845	35.69388667666426	181596
ea476cb44f1ff3acc5197b0d8d6d93ff7a66f1ce	verbesserung von social navigation durch identitätsmanagement	social navigation;talk	Die Benutzer des World Wide Webs werden regelmäßig mit seinen vielfältigen Benutzbarkeitsproblemen konfrontiert. Ein gravierender Mangel liegt dabei darin, dass es bis heute kaum brauchbare Konzepte zur Individualisierung der im Web angebotenen Informationen und Dienste gibt, die auch siteübergreifend einsetzbar wären: Suchmaschinen bieten keine personalisierten Ausgaben, Links sind nur durch die Autoren eines Dokuments zu erstellen und Annotationstechniken konnten sich bis heute nicht durchsetzen. Dieses Paper stellt ein neues Konzept von Social Navigation vor, das eine Identitätsinfrastruktur verwendet, um auch global einsetzbar zu sein und typischer Probleme wie des Kaltstartproblems oder des Sparsity-Problems Herr zu werden. Durch eine Identitätsinfrastruktur werden die sozialen Aspekte der Internetnutzung betont und die Voraussetzungen für soziales Navigieren verbessert. Es wird ein Prototyp vorgestellt, der diese Konzepte in Teilen realisiert. Abschließend werden die Ergebnisse einer damit durchgeführten Benutzbarkeitsevaluation diskutiert.	eine and zwei;internet explorer;sparse matrix;unified model;vhf omnidirectional range;world wide web	Tobias Baier;Harald Weinreich;Frank Wollenweber	2004			history;performance art	NLP	-106.020917833337	35.51809596726848	181600
b94511c09fd3b29829dfdb41afc2a8dfdab54fd3	kellerautomaten mit mehreren kellern				Peter Münterfering	1979	Elektronische Informationsverarbeitung und Kybernetik		pure mathematics;combinatorics;mathematics	ML	-95.45741503755818	34.33465675409968	181889
359c3adde258848e4b38db534a632448c6588b56	e-partizipation: welchen unterschied macht das ,,e“?		Einführung Immer wenn neue technische Medien eingeführt wurden, waren nicht nur die Erwartungen an ein daraus resultierendes Wirtschaftswachstum hoch. Es wurde auch eine Stärkung der Demokratie durch besseren Informationszugang und aktive Teilhabe an Planungen und Entscheidungen vorhergesagt. Dies galt schon für das Radio und die sogenannte Mikrocomputerrevolution und nun für das Internet. Unter verschiedenen Bezeichnungen wie Tele-, Cyberoder E-Democracy bzw. Eoder OnlinePartizipation ist die Argumentation immer dieselbe: Beteiligung erfordert Zeit für die Beschaffung von Informationen sowie für den Weg zu und die Teilnahme an Versammlungen, und dies hält viele Menschen davon ab, Beteiligungsangebote zu nutzen. Dies gilt für Angebote von Verwaltungen und Politik ebenso wie für die von Unternehmen, etwa bei der Planung von Industrieanlagen oder aktuell dem Ausbau der Stromnetze. Informationsund Kommunikationsangebote über das Internet sollen demgegenüber sehr viel leichter und vor allem zeitlich flexibler nutzbar sein und daher zumindest einige der Hürden traditioneller Beteiligungsformen überwinden. Dies klingt auf den ersten Blick plausibel, ist aber bisher kaum wissenschaftlich überprüft und nicht belegt worden. Ein von der European Science Foundation gefördertes Projekt hat dies mit einem Vergleich ähnlicher Beteiligungsformate, die online und offline angeboten wurden, in Deutschland, Österreich und Spanien versucht. Die Ergebnisse sind vor Kurzem in dem Buch ,,Evaluating e-Participation – Frameworks, Practice, Evidence“ [1] ausführlich dargestellt worden. Zwei interessante Teilergebnisse zu einer Konsultation zu einem Wahlprogramm und einem Kooperationsprojekt zur CO2-Einsparung sollen hier kurz wiedergegeben und praktische Konsequenzen daraus aufgezeigt werden.	argumentation framework;eine and zwei;internet explorer;online and offline;vhf omnidirectional range	Herbert Kubicek	2016	Informatik-Spektrum	10.1007/s00287-016-0986-1		OS	-104.0416224297315	34.70503920137978	182305
3f9e498cc30e500fa9640753ccc2f8c087ccc03c	eine diskussion zum einsatz der computertechnologie in nicaragua	eine diskussion zum einsatz;der computertechnologie	Der folgende Text dokumentiert eine Diskussion zum Einsatz der Computertechnologie in Nicaragua, die von Juni 1985 bis August 1985 in der Schweizer Zeitung „die Wochenzeitung“ („die Wochenzeitung“ wird im folgenden mit WOZ abgekurzt) gefuhrt wurde.	eine and zwei	Thomas Dey-Menzl	1988		10.1007/978-3-642-52518-6_21		Vision	-103.35905731246841	34.95319926040771	182480
23cb88422ce4f4a3800e3a3e4965e986226b2551	ein objektorientierter ansatz für die realisierung komplexer kontrollstrukturen				Thomas Christaller	1983			quantum electrodynamics;mathematics;ansatz	Logic	-97.13209613107831	33.90117856296164	182577
de2c2c65225434792f377eb988fb1da6d815868d	line-matching technik für verbesserte bewegungsschätzung in fernsehbildern	line-matching technik	Fur eine verbesserte Umsetzung von Bewegtbildern zwischen unterschiedlichen Fernsehnormen und zur Erhohung der Bildfolgefrequenz ist eine Zwischenbildinterpolation notwendig. Hierbei ist die bewegungskompensative Technik von entscheidender Bedeutung im Hinblick auf eine fur den menschlichen Gesichtssinn fehlerfreie Bewegungsdarstellung unter Beibehaltung der gegebenen ortlichen Auflosung.		Peihong Hou	1990		10.1007/978-3-642-76062-4_25		Vision	-104.73700208763314	32.69778588260089	182979
30e704afc28b6750588c00b2f7e9f229fa43779d	räumliche abschätzung der folgen von klimaänderungen auf ertrag und zusatzwasserbedarf landwirtschaftlicher fruchtarten, dargestellt am beispiel des freistaates thüringen		Bei der regionalen Abschätzung von Produktivität und Wasserbedarf in der Landwirtschaft spielen die Anforderungen an Modelle, Daten und Simulationstools eine besondere Rolle. Am Beispiel der Agrarflächen des Freistaates Thüringen werden bei einer Gebietsauflösung von 1 ha mit Hilfe der statistisch basierten Modelle YIELDSTAT und ZUWABE Abschätzungen zu Ertrag und Zusatzwasserbedarf der Hauptkulturen vorgenommen. Die Modellvalidierung erfolgt anhand realer Wetterund Ertragsdaten aus 1995-2010 auf Landesversuchsstations-, Kreisund Landesebene. Simulationsszenarien mit dem WETTREG-2010 A1B-Szenario sind die Grundlage für die Abschätzung der Veränderungen bei Ertrag und Zusatzwasserbedarf im Vergleich der Zeiträume 1981-2010 und 2021-2050. Die rein klimaänderungsbedingten Ertragseinbußen sind im Landesdurchschnitt bei Winterungen geringer (< 5 %) als bei Sommerungen (bis 14 %). Die Ergebnisse der Simulation werden vorgestellt, diskutiert und daraus Schlussfolgerungen gezogen. 1 Einleitung / Aufgabenstellung Für eine regionale Folgenabschätzung von Klimaänderungen auf Erträge und Zusatzwasserbedarf landwirtschaftlicher Fruchtarten über viele Zeitdekaden besteht die Herausforderung darin, die unterschiedlichen Einflussgrößen und teils komplex wirkenden Prozesse skalenbezogen zu berücksichtigen und die enormen Datenmengen verfügbar zu machen und zu handeln. Dabei stellt die regionale Skala besondere Anforderungen an	am broadcasting;eine and zwei;gesellschaft für informatik;simulation	Wilfried Mirschel;Ralf Wieland;Karl-Otto Wenkel;Christian Guddat;Herbert Michel	2013			history;performance art	OS	-104.86598565024441	32.790234597319866	183096
ed5eeeb9f955545885151303dc161543f25ba8e0	in die e-lernkarten geschaut - eine studie zur akzeptanz und nutzung		Mit e-Lernkarten steht ein Ansatz zur Verfügung, der Studierenden eine aktive Auseinandersetzung mit Lerninhalten bietet und durch individuelles Feedback eine gezielte Förderung ermöglicht. In diesem Beitrag werden Ergebnisse aus dem Piloteinsatz der e-Lernkarten in zwei Lehrveranstaltungen präsentiert. Diese zeigen eine verbreitete Akzeptanz und Nutzung der eLernkarten, machen allerdings auch organisatorische Bedarfe und technische Optimierungspotenziale deutlich. 1 Die Unterstützung aktiven Lernens Der hier präsentierte und evaluierte Ansatz geht von der Annahme aus, dass sich im Sinne konstruktivistischer Lerntheorien eine aktive Verarbeitung von Lerninhalten durch eigene Produktion von Inhalten und eine Diskussion dieser Inhalte mit anderen Lernenden positiv auf den Lernerfolg auswirkt [Ko96]. Zahlreiche Studien der Forschungsrichtung Computer Supported Collaborative Work (CSCL) belegen den positiven Effekt der aktiven Verarbeitung durch eigene Inhaltsproduktion (z.B. [SH12]). Eng damit verbunden ist die Erkenntnis, dass solche Lerninhalte für Studierende besonders gut nachvollziehbar sind, die von Studierenden selbst entwickelt wurden. Der Ansatz der e-Lernkarten [SK12] greift die Idee der Entwicklung von Lerninhalten durch Studierende in der Form von elektronischen (e-)Lernkarten auf. Der vorliegende Beitrag beschäftigt sich mit dem Piloteinsatz der e-Lernkarten in zwei Lehrveranstaltungen. Dazu wird zunächst der Ansatz grob skizziert und in Relation zu Studienergebnissen vergleichbarer Ansätze gesetzt (Kapitel 2), bevor auf Forschungsfragen und Design der hier vorgestellten Studie eingegangen wird (Kapitel 3). Anschließend werden die zentralen Ergebnisse des Piloteinsatzes dargestellt (Kapitel 4) und diskutiert (Kapitel 5). Der Beitrag endet mit Zusammenfassung und Ausblick (Kapitel 6).	eine and zwei;institut für dokumentologie und editorik	Andrea Kienle;Inga Saatz	2013				OS	-106.86858557055652	33.686172339055034	183189
f45e23c8192b6ea765d0e2032366b904282bb1d6	die macht eines frontendstandards über einen backendstandard am beispiel der microsoft office software als funktionsorientierte standardapplikation		Die vorliegende Dissertation beschaftig sich mit der Fragestellung, warum es nur bestimmten Softwareprogrammen vorbehalten ist sich zu einer Standardsoftware zu entwickeln, bzw. diesen Status zu erhalten. Die Diskussion, die Definition und die Anwendung von Standards in den unterschiedlichsten Bereichen stellt zunehmend ein zentrales Arguments des Erfolges oder Misserfolges einer Technologie dar. Der Schwerpunkt dieser Dissertation liegt im informationstechnologischen Bereich, der die Basis des Instrumentariums technologischer, okonomischer, soziologischer und psychologischer Handlungsweisen wesentlich beeinflusst. Nahe liegend ist hier eine direkte Betrachtung der Mensch-Maschine Schnittstelle. In diesem Zusammenhang wird oft von Standards gesprochen, oder gar darauf hingewiesen das vieles standardisiert sei. Fast jeder kennt den Begriff der „Standardsoftware“, der einen sehr guten Ansatzpunkt bietet, diesen genauer zu untersuchen, denn darf man eine Software Standardsoftware nennen, oder ist es vielmehr ein Softwarestandard? Diese vermeintliche rein formale Betrachtung impliziert viel mehr, als nur eine reine fokussierte Betrachtung von Software. Eine entsprechende Untersuchung, bedingt die Auswahl einer entsprechenden Software als Beispiel, so stellt die „Standardsoftware“ Microsoft Office, historisch wie gegenwartig, einen interessanten Untersuchungsgegenstand dar.	die (integrated circuit)	Rainer Lehmann	2004			microsoft office;software;philosophy;performance art	SE	-103.88288314426038	33.24893067830783	183308
7031261bd3ad465489ac7d90fedf001a3faa4859	on the complexity of conjugacy in amalgamated products and hnn extensions		This thesis deals with the conjugacy problem in classes of groups which can be written as HNN extension or amalgamated product. The conjugacy problem is one of the fundamental problems in algorithmic group theory which were introduced by Max Dehn in 1911. It poses the question whether two group elements given as words over a fixed set of generators are conjugate. Thus, it is a generalization of the word problem, which asks whether some input word represents the identity. Both, word and conjugacy problem, are undecidable in general. rnIn this thesis, we consider not only decidability, but also complexity of conjugacy. We consider fundamental groups of finite graphs of groups as defined by Serre - a generalization of both HNN extensions and amalgamated products. Another crucial concept for us are strongly generic algorithms - a formalization of algorithms which work for most inputs. rnThe following are our main results:rnrnThe elements of an HNN extension which cannot be conjugated into the base group form a strongly generic set if and only if both inclusions of the associated subgroup into the base group are not surjective. For amalgamated products we prove an analogous result.rnrnFollowing a construction by Stillwell, we derive some undecidability results for the conjugacy problem in HNN extensions with free (abelian) base groups. rnNext, we show that conjugacy is decidable if all associated subgroups are cyclic or if the base group is abelian and there is only one letter. Moreover, in a fundamental group of a graph of groups with free abelian vertex groups, conjugacy is strongly generically in P.rnrnMoreover, we consider the case where all edge groups are finite: If conjugacy can be decided in time T(N) in the vertex groups, then it can be decided in time O(log N * T(N)) in the fundamental group under some reasonable assumptions on T (here, N is the length of the input). We also derive some basic transfer results for circuit complexity in the same class of groups.rnrnFurthermore, we examine the conjugacy problem of generalized Baumslag-Solitar groups. Our main results are: the conjugacy problem in solvable Baumslag-Solitar groups is TC0-complete, and in arbitrary generalized Baumslag-Solitar groups it can be decided in LOGDCFL. The uniform conjugacy problem for generalized Baumslag-Solitar groups is hard for EXPSPACE. rnrnFinally, we deal with the conjugacy problem in the Baumslag group, an HNN extension of the Baumslag-Solitar group BS12. The Baumslag group has a non-elementary Dehn function, and thus, for a long time, it was considered to have a very hard word problem, until Miaskikov, Ushakov, and Won showed that the word problem, indeed, is in P by introducing a new data structure, the so-called power circuits. We follow their approach and show that the conjugacy problem is strongly generically in P. We conjecture that there is no polynomial time algorithm which works for all inputs, because the divisibility problem in power circuits can be reduced to this conjugacy problem. Also, we prove that the comparison problem in power circuits is complete for P under logspace reductions. nDiese Arbeit beschaftigt sich mit dem Konjugationsproblem in Gruppen, die sich als HNN-Erweiterung oder amalgamiertes Produkt schreiben lassen. Das Konjugationsproblem ist eines der fundamentalen Probleme der algorithmischen Gruppentheorie, die 1911 von Max Dehn eingefuhrt wurden. Es ist die Frage, ob zwei Worter uber den Erzeugern der Gruppe in der Gruppe zueinander konjugiert sind. Damit ist es eine Verallgemeinerung des Wortproblems, bei dem fur ein Eingabewort festgestellt werden soll, ob es die Identitat darstellt. Sowohl das Wort- als auch das Konjugationsproblem sind im Allgemeinen unentscheidbar.rnrnIn dieser Arbeit werden verschiedene Komplexitatsmase verwendet, um die Komplexitat von Wort- und Konjugationsproblem in HNN-Erweiterung und amalgamierten Produkten - und allgemeiner in Fundamentalgruppen von Graphen von Gruppen - zu analysieren. Die Arbeit ist wie folgt aufgebaut: Zuerst wird eine kurze Einfuhrung in die Bass-Serre-Theorie gegeben. Danach wird der Begriff der Mittelbarkeit (Amenability) sowie dessen Zusammenhang zu generischen Algorithmen untersucht. Es wird gezeigt, dass unter gewissen Voraussetzungen die Elemente einer Fundamentalgruppe, die nicht in eine der Knotengruppen hinein konjugiert werden konnen, eine stark generische Menge bilden (stark generisch bedeutet, dass der Anteil der Worter, die nicht in der Menge sind, exponentiell mit der Lange abnimmt). Da in vielen Fallen effiziente Algorithmen zur Losung des Konjugationsproblems eben fur jene Elemente existieren, ist in diesen Fallen das Konjugationsproblem stark generisch effizient losbar.rnrnDie folgenden Kapitel beschaftigen sich mit Algorithmen fur das Konjugationsproblem: Zunachst werden Fundamentalgruppen von Graphen von Gruppen mit freien bzw. frei abelschen Knotengruppen untersucht. Zunachst werden Unentscheidbarkeitsresultate von Miller verallgemeinert und dabei auch HNN-Erweiterungen frei abelscher Gruppen betrachtet. Andererseits stellt es sich heraus, dass mit nur einem stable letter das Konjugationsproblem in einer HNN-Erweiterung einer frei abelschen Gruppe in jedem Fall entscheidbar ist. Ferner ist das Konjugationsproblem in beliebigen Fundamentalgruppen von Graphen von Gruppen mit frei abelschen Knotengruppen stark generisch in P; wenn alle Kantengruppen zyklisch sind, ist es stets entscheidbar.rnrnWie die Unentscheidbarkeitsresultate zeigen, kann im Allgemeinen von der Entscheidbarkeit des Konjugationsproblems in den Knotengruppen nicht auf die Entscheidbarkeit in der Fundamentalgruppe geschlossen werden. Wie einfach zu sehen ist, andert sich diese Situation, wenn man sich auf endliche Kantengruppen beschrankt. Um diese Beobachtung zu verfeinern, wird gezeigt, dass der Mehraufwand fur das Wort- und Konjugationsproblem in der Fundamentalgruppe gegenuber den Knotengruppen maximal logarithmisch ist. Ferner ist das Konjugationsproblem der Fundamentalgruppe in NC^(i+1), falls die Konjugationsprobleme der Knotengruppen in NC^i sind.rnrnDanach werden verallgemeinerte Baumslag-Solitar-Gruppen behandelt. Diese sind Fundamentalgruppen endlicher Graphen von Gruppen mit unendlichen zyklischen Knoten- und Kantengruppen. Zuerst werden die auflosbaren Baumslag-Solitar-Gruppen betrachtet, deren Konjugationsproblem TC0-vollstandig ist. Sowohl das Wort- als auch das Konjugationsproblem verallgemeinerter Baumslag-Solitar-Gruppen ist in LOGDCFL. Betrachtet man den Graph von Gruppen allerdings als Teil der Eingabe, wandelt sich das Bild: In diesem Fall ist das Konjugationsproblem EXPSPACE-hart.rnrnSchlussendlich geht um die Baumslag-(Gersten-)Gruppe, eine HNN-Erweiterung der Baumslag-Solitar-Gruppe BS12. Die Baumslag-Gruppe galt lange Zeit als ein mogliches Beispiel einer Gruppe mit nicht in Elementarzeit losbarem Wortproblem, bis Miaskikov, Ushakov und Won zeigten, dass das Wortproblem tatsachlich in Polynomialzeit losbar ist. Der Beweis beruht auf einer neuen Datenstruktur, den sogenannten Power Circuits, die in der Lage sind, extrem grose Zahlen in komprimierter Form zu speichern. Mithilfe von Power Circuits kann auch gezeigt werden, dass das Konjugationsproblem der Baumslag-Gruppe stark generisch in P ist. Allerdings gibt es Eingaben, fur die kein Polynomialzeitalgorithmus bekannt ist. Um das Konjugationsproblem fur diese Eingaben effizient zu losen, musste man das Teilbarkeitsproblem fur Power Circuits effizient losen konnen. Allerdings kann dies nich durch Modulo-Rechnen geschehen, da dies zu einem nicht-elementaren Wachstum der Power Circuits fuhrt. Es ein offenes Problem, ob es einen Polynomialzeitalgorithmus gibt, der das Konjugationsproblem der Baumslag-Gruppe fur alle Eingaben lost.		Armin Weiss	2015			calculus;mathematics;performance art	NLP	-98.91135174739763	36.58922699761379	183443
cc32472339ce81aefe14469d63a16cf1b6b5bbcb	erfahrungen in der umsetzung von unternehmensarchitekturen		Die Entwicklung unternehmensweiter Architekturen stellt die Praxis vor einige Herausforderungen. Zum einen bedarf es geeigneter Architekturmodelle und Techniken zur Beschreibung von Architekturen im Großen und zum anderen ist ein effizientes Architekturmanagement erforderlich, das die Interessengruppen aus Management, Fachabteilungen und IT zielorientiert zusammenbringt. Vor diesem Hintergrund wird ein Ansatz zur Beschreibung von Unternehmensarchitekturen vorgestellt und einige Erfahrungen in seiner Umsetzung werden exemplarisch aufgezeigt. Der Ansatz konsolidiert die Vielfalt an Architekturmodellen. Drei Kategorien von Sichten (Komponenten-, Kommunikations- und Verteilungssicht) ermöglichen die Beschreibung von Struktur und Zusammenhängen der Architekturbausteine. Zentrales Element für die Architekturplanung sind Bebauungspläne. Diese zeigen in einer Übersicht die Verwendung eines Architekturbausteins im Kontext der Gesamtarchitektur sowie das Zusammenspiel mit anderen Bausteinen. Damit ist es möglich, die Auswirkungen im Architekturdesign und die Integration zwischen der Geschäftsarchitektur und der Anwendungs- und Infrastrukturarchitektur aufzuzeigen.	altran praxis;intentionally blank page;vhf omnidirectional range	Michael Rohloff	2008	HMD Praxis der Wirtschaftsinformatik	10.1007/BF03341234	knowledge management;engineering;performance art	DB	-102.51137048320861	33.477880131446646	183572
68e8c7673d1bcc269a4a1099e2e64d9f46848402	kompendium philosophischer begriffe und fragestellungen in der informatik: ein vorschlag		Zusammenfassung: Dies ist ein Vorschlag, ein Kompendium (nach dem Duden: Abriss, kurz gefasstes Lehrbuch) für Begriffe und Fragestellungen zu schaffen, die in der Schnittmenge zwischen Informatik und Philosophie liegen. Es soll dem Informatiker zu einem tieferen Verständnis seines Faches verhelfen, und dem Philosophen praktische Züge seiner Analysen zeigen. Es wird skizziert, wie ein solches Kompendium durch örtlich und nach Kompetenzen verteilte Zusammenarbeit entstehen könnte.	es evm;internet explorer	Ralf Hauber	2001				OS	-104.31329297273476	33.08403953841322	183575
0df001a9abf8dc1dcc047e73d613708ccf511043	mobile klienten: ortsübergreifender zugang zu diensten in offenen verteilten informationssystemen	informatik;ddc 004;netze;theoretische informatik	"""Die zunehmende Verbreitung und Leistungsfähigkeit globaler Kommunikationsinfrastrukturen führt zu einer entsprechend unübersichtlichen Anzahl von Diensten in offenen verteilten Informationssystemen. Der Mechanismus """"Markt"""" erscheint hierbei zunehmend bedeutend, wenn die Zielsetzung in der effizienten Koordinierung von Nachfragern und Anbietern dieser Dienste liegt. Ziel der Projekte COSM und TRADE ist daher insbesondere die Schaffung einer verteilten Kommunikationsinfrastruktur, welche die flexible Koordination bei der Dienstnutzung unterstützt."""	cosm	Michael Merz;Kai Müller-Jones;Winfried Lamersdorf	1995		10.1007/978-3-642-79958-7_56		NLP	-103.93935371263773	33.189420761865215	183610
a943205f4cda042fab80a087eb417f1feb9e0ebb	die ermittlung der komplexität paralleler prozesse auf mikro-computern				Guido Walz	1989	Elektronische Informationsverarbeitung und Kybernetik		pure mathematics;combinatorics;mathematics	NLP	-95.4871157882168	34.33193742648333	183638
78c933f99db23b6284a254e55cb9a0e114748f70	motivation for free - zum motivationsfaktor von internationalen robocupjunior-wettbewerben		Motivation ist eine notwendige Voraussetzung für Lernen. Sind die Lernenden gut motiviert, können wir auf Lernerfolg hoffen. Andernfalls können wir eigentlich gleich aufhören. Die Verwendung von Robotern in der Ausbildung hat sich als hervorragendes Werkzeug zur Motivation von Studierenden aller Altersstufen von 8 bis 80 erwiesen. Dieser Aufsatz beschreibt die Nutzung von Wettbewerben, um die Motivation der Studierenden über einen längeren Zeitraum zu erhalten, was wiederum die Chance erhöht, dass die Studierenden Wissen über eine Thematik vertiefen und ein dauerhaftes Interesse am Fach entwickeln. Im speziellen beschreiben wir die zugrundeliegenden Ideen der verschiedenen Wettbewerbe im RoboCupJunior, die genau zu diesem Zweck entwickelt wurden und weltweit genutzt werden. Weltweit schätzungsweise mehr als 2000 Teams von Schülerinnen und Schüler haben im Jahr 2004 an solchen Wettbewerben teilgenommen, und die Teilnehmerzahlen steigen weiter. 1 Einleitung und Motivation Ende der neunziger Jahre wurde die deutsche Bildungsszene durch die bescheidene Performanz deutscher Schülerinnen und Schüler bei internationalen Studien wie TIMMS und PISA aufgeschreckt. Seither finden Ansätze zur Verbesserung der Bildung und ihrer Ergebnisse wieder eine gewisse Aufmerksamkeit. Besonders in den letzten fünf Jahren entfaltete nahezu jede relevante gesellschaftliche Gruppe mehr oder minder hektische Aktivitäten, angefangen von den staatlichen Stellen der Bildung auf Gemeinde-, Landesund Bundesebene, über wirtschaftliche Vereinigungen und Lobbygruppen wie den VDMA, den VDI, und Gesamtmetall, bis hin zu gemeinnützigen Organisationen, Vereinen und Stiftungen wie etwa der Robert-Bosch-Stiftung. Die Bewertung der einzelnen Aktivitäten und die Identifikation kritischer Erfolgsfaktoren ist schwierig, da eine systematische Evaluation und Analyse meist nicht erfolgt und die Ziele und Methoden sehr stark variieren. Dennoch lässt sich ein Schlüsselelement für erfolgreiche Projekte identifizieren: Motivation! Dieses Schlüsselelement ist eigentlich nicht neu und zumindest in der Pädagogik altbekannt. Nur wenn die Lernenden motiviert sind, also ihr Interesse an der behandelten Thematik geweckt worden ist, können wir einen Lernerfolg erhoffen. Fehlt die Motivation, dann scheitern auch die innovativsten Lerntheorien und -praktiken. Zeitverschwendung! In unseren Schulen scheint – zumindest Betrachtern außerhalb des Bildungsestablishments –,	desktop virtualization;eine and zwei;fach;gesellschaft für informatik;internet explorer;triple des;unified model;zentralblatt math	Gerhard K. Kraetzschmar	2005			history;performance art	Comp.	-104.88651109470881	34.68290977480765	184015
f51e315688801beec0e7762146c3829e58e03857	mehrschrittverfahren mit exponentialanpassung für differentialgleichungssysteme 1. ordnung		In der vorliegenden Arbeit wird ein neues Prädiktor-Korrektor-Verfahren mit exponentiell angepaßter Version zur numerischen Berechnung des Anfangswertproblems eines Differentialgleichungssystems 1. Ordnung hergeleitet. Das Verfahren liefert für eine Klasse von Differentialgleichungen die exakte Lösung. Einige Beispiele zeigen die Anwendung des neuen Mehrschrittverfahrens. In the present paper a new predictor-corrector-method with an exponentially fitted version is given for the numerical treatment of the initial value problems for systems of first oder differential equations. For a class of linear differential equations the exact solution is obtained. Some numerical examples show the application of the new multistep algorithms.	algorithm;eine and zwei;gesellschaft für informatik;kerrison predictor;numerical analysis;predictor–corrector method	Karl Strehmel	1976	Computing	10.1007/BF02259649	mathematics;calculus;mathematical analysis	Theory	-96.57801110937017	35.79966042446049	184406
4b0058e5330609cd608b3c9483cd5171b0121e4e	binary decision diagrams for random boolean functions	branching program;boolean function;computer science;binary decision diagram;data structure	Binary Decision Diagrams (BDDs) are a data structure for Boolean functions which are also known as branching programs. In ordered binary decision diagrams (OBDDs), the tests have to obey a fixed variable ordering. In free binary decision diagrams (FBDDs), each variable can be tested at most once. The efficiency of new variants of the BDD concept is usually demonstrated with spectacular (worst-case) examples. We pursue another approach and compare the representation sizes of almost all Boolean functions. Whereas I. Wegener proved that for ‘most’ values of the expected OBDD size of a random Boolean function of variables is equal to the worst-case size up to terms of lower order, we show that this is not the case for within intervals of constant length around the values . Furthermore, ranges of exist for which minimal FBDDs are almost always at least a constant factor smaller than minimal OBDDs. Our main theorems have doubly exponentially small probability bounds (in ). We also investigate the evolution of random OBDDs and their worst-case size, revealing an oscillating behaviour that explains why certain results cannot be improved in general. Zusammenfassung Binary Decision Diagrams (BDDs) sind eine Datenstruktur für Boolesche Funktionen, die auch unter dem Namen branching program bekannt ist. In ordered binary decision diagrams (OBDDs) müssen die Tests einer festen Variablenordnung genügen. In free binary decision diagrams (FBDDs) darf jede Variable höchstens einmal getestet werden. Die Effizienz neuer Varianten des BDD-Konzepts wird gewöhnlich anhand spektakulärer (worst-case) Beispiele aufgezeigt. Wir verfolgen einen anderen Ansatz und vergleichen die Darstellungsgrößen für fast alle Booleschen Funktionen. Während I. Wegener bewiesen hat, daß für die ‘meisten’ die erwartete OBDD-Größe einer zufälligen Booleschen Funktion von Variablen gleich der worst-case Größe bis auf Terme kleinerer Ordnung ist, zeigen wir daß dies nicht der Fall ist für innerhalb von Intervallen konstanter Länge um die Werte . Ferner gibt es Bereiche von , in denen minimale FBDDs fast immer um mindestens einen konstanten Faktor kleiner sind als minimale OBDDs. Unsere Hauptsätze haben doppelt exponentielle Wahrscheinlichkeitsschranken (in ). Außerdem untersuchen wir die Entwicklung zufälliger OBDDs und ihrer worst-case Größe und decken dabei ein oszillierendes Verhalten auf, das erklärt, warum gewisse Aussagen im allgemeinen nicht verstärkt werden können. Acknowledgements I am grateful to everybody who supported and contributed to this work: Hans Jürgen Prömel (my supervisor), Anand Srivastav, Mathias Block, Harry Preuß, Martin Skutella – as my coauthors; also to all the many other people with whom I discussed these things: Stefan Hougardy, Bernd Kreuter, Christoph Meinel, Paul Molitor, Till Nierhoff, Ralf Oelschlägel, Martin Sauerhoff, Detlef Sieling, Anusch Taraz, Thorsten Theobald, ; and my wife Antje . The graduate program ‘Algorithmische Diskrete Mathematik’ provided financial allowance and a high quality scientific framework. The graduate school ‘Algorithmische Diskrete Mathematik’ is supported by the Deutsche Forschungsgemeinschaft, grant GRK 219/2-97.	best, worst and average case;binary decision diagram;boolean algebra;citeseerx;data structure;display resolution;eine and zwei;ingo wegener;unified model	Clemens Gröpl	1999			calculus;mathematics;algorithm	AI	-96.90787757420597	36.985608479674575	184899
bd4c31df5719f12610a8f2e6cc74312d3d69daa2	ein zwei-kartne-verfahren zur gleichzeitigen kartographierung und lokalisierung		Bei der Kartographierung eines unbekannten Gebietes durch einen mit Sensorik ausgestatteten mobilen Roboter ergibt sich die Problematik, das dieser die Lage unbekannter Merkmale, sogenannter Landmarken, in seiner Umgebung bestimmen will, wobei er gleichzeitig mit Hilfe dieser Landmarken seine eigene Lage schatzt.	eine and zwei	Kai Briechle;Uwe D. Hanebeck	2000		10.1007/978-3-642-59576-9_20		NLP	-104.96861294288789	32.39921258806314	184971
b0da633a21bcb64f77d901dbaf33fa13cfb0facf	wirtschaftsinformatik und marketing		Elektronische Medien haben die Chancen und Herausforderungen für das Marketing grundlegend verändert. Die Interaktivität des Internets hat dazu geführt, dass die Einflussmöglichkeiten von Konsumenten stark zugenommen haben, beispielsweise auf den zu zahlenden Preis im Rahmen von interaktiven Preismechanismen (Bichler et al. 2010; Hinz et al. 2011; Skiera et al. 2005). Darüber hinaus können Konsumenten nun einfach Produktund Preisinformationen innerhalb ihres sozialen Netzwerks austauschen. Das ermöglicht Konsumenten, bessere (Kauf-)Entscheidungen zu treffen, und erfordert von Unternehmen, diese soziale Interaktion zwischen Konsumenten in ihren Geschäftsmodellen zu berücksichtigen (Hinz und Spann 2008). Demgegenüber bietet das Internet auch neue Möglichkeiten für Vermarkter: Empfehlungssysteme ermöglichen Händlern, Kunden zusätzliche und höherwertige Produkte zu verkaufen sowie die Art des Verkaufsprozesses zu ändern (Hinz und Eckert 2010; Mertens 1997). Werbetreibende können in elektronischen Medien wesentlich besser als in traditionellen Medien die Effektivität und Effizienz ihrer Werbeaufwendungen messen (Animesh et al. 2010; Ghose und Yang 2009). Umfangreiche Daten und die Interaktion mit Nutzern ermöglichen die Gestaltung personalisierter Produkte, Werbung und ein individualisiertes Kundenmanagement (Ray et al. 2005; Tam und Ho 2006). Darüber hinaus haben sich neue Vermarktungskanäle wie beispielsweise Suchmaschinen, soziale Netzwerke und Location-based Services über mobile Endgeräte etabliert (z. B. Kumar und Benbasat 2006). Konsumenten hinterlassen über Transaktionsdaten und User-generated Content eine umfangreiche Datenspur, die ein großes Potenzial für Unternehmen darstellt. Allerdings geht mit diesen Informationen die Herausforderung einher, dass Unternehmen daraus unternehmensrelevantes Wissen erzeugen müssen. Auf Basis dieser Informationen können neue Produkte entwickelt, Betriebskosten gesenkt oder Konsumentenbedürfnisse besser verstanden werden. Da solche Daten viel Rauschen enthalten und aufgrund ihres Umfangs (Stichwort Big Data) aufwändig zu verarbeiten sind, benötigt das Marketing das entsprechende Wissen und die entsprechenden Fähigkeiten aus den IT-Abteilungen von Unternehmen bzw. von Wirtschaftsinformatikern, um diese Daten sinnvoll nutzen zu können. Andererseits erfordern die Chancen dieser großen Datenmengen auch eine kritische Reflexion im Bezug auf den Schutz personenbezogener Daten. Daher sollten Wissenschaftler in diesem Bereich sich auch aktiv an der Diskussion zum Datenschutz beteiligen, damit ein sinnvoller Ausgleich zwischen dem Innovationspotenzial, das solche Daten bieten, und dem individuellen Datenschutzbedürfnis gefunden werden kann. In diesem Zusammenhang sei auf die aktuelle Diskussion zum Datenschutz in Europa verwiesen, z. B. siehe http://www.dataprotectioneu.eu. Diese oben beschriebenen Chancen und Herausforderungen wurden durch die Entwicklungen im Bereich Informationstechnologie in den letzten Jahren ermöglicht. Folglich haben diese technologischen Entwicklungen nicht nur neue Möglichkeiten für das digitale Marketing geschaffen, sondern bieten auch ein vielversprechendes Forschungsfeld an der Schnittstelle zwischen Marketing und Wirtschaftsinformatik. Mit diesem Schwerpunktheft soll dieses Forschungspotenzial beleuchtet werden und Forschung im Bereich Wirtschaftsinformatik und Marketing vorangetrieben werden. Das Ziel dieses Schwerpunkthefts ist es, das Verständnis der Möglichkeiten und Herausforderungen für Wirtschaftsinformatikforschung an der Schnittstelle zum Marketing zu vertiefen. Die Ausschreibung führte zu insgesamt 18 Einreichungen, die einem doppeltblinden Begutachtungsverfahren unterzogen wurden. Aus diesen Einreichungen wurden fünf Beiträge zur Veröffentlichung in diesem Schwerpunktheft akzeptiert. Die Breite der Themen und Methoden der fünf Beiträge in diesem Schwerpunktheft verdeutlicht das Potenzial dieses Forschungsfelds an der Schnittstelle zwischen Wirtschaftsinformatik und Marketing. Die Themen reichen von Kundenbewertungen und elektronischem Word-of-Mouth, sozialen Netzwerken bis zu sogenannten „Deal-ofthe-Day-Plattformen“ und Ertragssteuerung bei Fluglinien. Die Beiträge wenden ein	big data;chen–ho encoding;die (integrated circuit);eine and zwei;eckert–mauchly award;europa;gesellschaft für informatik;institut für dokumentologie und editorik;internet explorer;internets;ising model;unified model;user-generated content;word lists by frequency;yang;zentralblatt math	Martin Spann;Oliver Hinz;Vandana Ramachandran	2013	Wirtschaftsinformatik	10.1007/s11576-013-0363-5	business informatics;knowledge management;data science;computer science	AI	-104.30954947280051	37.31948421291667	185329
cd570586d162b15304b9e74db1a8af6feedba97d	herausforderungen bei der integration von benutzern in datenorientierten prozess-management-systemen		Im Projekt PHILharmonic Flows entwickeln wir ein datenorientierten Prozess-ManagementSystem der nächsten Generation. In Vorarbeiten haben wir fünf Herausforderungen diskutiert, die eine generische Komponente zur Unterstützung datengetriebener Prozesse mit einer integrierten Sicht auf Daten und Prozesse erfüllen sollte. In diesem Aufsatz betrachten wir zusätzlich die Integration von Benutzern. Dazu stellen wir vier weitere Herausforderungen für die Zugriffskontrolle in datenorientierten Prozess-Management-Systemen vor. Letztgenannte stellen obligatorische und optionale Aktivitäten zur Verfügung. Obligatorische Aktivitäten müssen für den Fortschritt einer Prozessinstanz zwingend ausgeführt werden, optionale Aktivitäten ermöglichen dagegen die Pflege und Verwaltung von Daten unabhängig von der Ausführung eines bestimmten Prozesses. Die Bearbeiterzuordnung für obligatorische Aktivitäten ist dabei nicht nur von der Aktivität an sich abhängig, sondern auch von den Berechtigungen eines Benutzers zur Durchführung der innerhalb der Aktivität erforderlichen Datenänderungen. Berechtigungen für Datenänderungen müssen dazu für verschiedene Objektinstanzen eines Objekttyps jeweils unterschiedlich vergeben werden können. Gleichzeitig darf bei der Ausführung optionaler Aktivitäten die Durchführung von Prozessinstanzen nicht fehlerhaft beeinflusst werden. Weiter erweist sich eine getrennte Verwaltung von Anwendungsdaten und Organisationsmodell als zu unflexibel für eine feingranulare Vergabe von Rechten mit möglichst geringem Administrationsaufwand. Insgesamt bieten datenorientierte Prozess-ManagementSysteme eine integrierte Sicht auf Prozesse, Daten und Benutzer, und eröffnen daher völlig neue Anwendungsfelder für Prozess-Management-Technologie.	eine and zwei;gesellschaft für informatik;vhf omnidirectional range	Vera Künzle;Manfred Reichert	2010	EMISA Forum		process management;performance art;computer science	OS	-102.20902442536533	33.34684024169195	185754
4d4512b14f2ce2e561ce6cb387a45d5959efe211	redundanzmatrizen und reduktion von modulautomaten				Hans Kohlhase	1982	Elektronische Informationsverarbeitung und Kybernetik		pure mathematics;combinatorics;mathematics	NLP	-95.40234091941359	34.266695163513866	185912
703c5b7930699edd6351c4538a39ba154ea6d633	datenstandards in der lebensmittelkette: stand der technik und künftige entwicklungsrichtung im rahmen der future internet-initiative der eu		Im Rahmen des Projektes SmartAgriFood, eines EU-Projektes im „Future Internet Public Private Partnership“-Programm, wurde eine Übersicht zu Standards für den Datenaustausch in der Landwirtschaft und der Lebensmittelkette zusammengestellt. Es wurden 35 Standards oder Gruppen von Standards hinsichtlich Anwendungsbereichen und Technologien untersucht und abschließend Empfehlungen zu Nutzung, Entwicklungsund Abstimmungsbedarf abgeleitet.	eine and zwei;future internet	Esther Mietzsch;Daniel Martini	2014			the internet;library science;business	OS	-103.28973711106389	36.39534358220789	185952
d7dd9aa0810e49091addc874e3bf35a87df6527e	bedarf nach mobile business in einer landwirtschaftlichen produktion unter dynamischen rahmenbedingungen		Die Arbeiten auf den landwirtschaftlichen Betrieben sind geprägt durch dynamische Rahmenbedingungen, die mit wachsenden Herausforderungen f ür das Betriebsmanagement verbunden sind. Obwohl Mobile Business, mi t seinen speziellen Vorteilen (z.B. Ortsungebundenheit), Möglichkeit en bietet auch betriebsfern bestimmte Tätigkeiten auszuführen, sind Apps für di e speziellen Bedürfnisse auf landwirtschaftlichen Betrieben bisher verhäl tnismäßig wenig vorhanden. Diese Studie überprüft mit Hilfe eines web-survey s den Bedarf an Mobile Business Anwendungen in landwirtschaftlichen Betrieben in De utschland. Die Ergebnisse zeigen, dass im Zusammenhang mit dem sic h wandelnden Umfeld die mobile Technologie geschätzt wird und ein Bedarf nach mehr Apps zur mobilen Unterstützung der alten und neuen Herausforderungen im landwirtschaftlichen Produktionsprozess besteht.	die (integrated circuit);institut für dokumentologie und editorik	Christa Hoffmann;Dominic Grethler	2013			business	ML	-102.79023685216305	37.01429014958301	186030
bf774228c47ff02c0665e3b0ea299391c43c2b9d	die forschungsstelle recht im dfn-verein - geschichte, status und perspektiven		Prof. Dr. Thomas Hoeren. Geboren am 22. August 1961 in Dinslaken. 1980–1987 Studium der Theologie und Rechtswissenschaften in Münster, Tübingen und London. 1986 Erwerb des Grades eins kirchlichen Lizentiaten der Theologie. 1987 Erstes Juristisches Staatsexamen, 1991 Zweites Juristisches Staatsexamen. 1989 Promotion an der Universität Münster (Thema der Dissertation: „Softwareüberlassung als Sachkauf“). 1994 Habilitation an der Universität Münster (Thema der Habilitation: „Selbstregulierung im Bankenund Versicherungsrecht“). 1995–1997 Universitätsprofessor an der Juristischen Fakultät der Heinrich-Heine Universität Düsseldorf (Professur für Bürgerliches Recht und internationales Wirtschaftsrecht). Seit April 1996 Richter am OLG Düsseldorf. Seit April 1997 Universitätsprofessor an der Juristischen Fakultät der Westfälischen Wilhelms-Universität Münster (Professor für Informationsrecht und Rechtsinformatik) sowie geschäftsführender Direktor des Instituts für Informations-, Telekommunikationsund Medienrechts (ITM).	irish transverse mercator;quad flat no-leads package	Thomas Hoeren	2010	Praxis der Informationsverarbeitung und Kommunikation	10.1515/piko.2010.034		ML	-99.32946317484166	32.53883148761987	186036
6b0de1cde5c86feae265fd20f4138991773ea4e3	flexibilität in betrieblichen informationssystemen		Flexibilität, d.h. die Fähigkeit zur Anpassung an geänderte Umstände, gehört zu den wichtigsten Anforderungen, die an betriebliche Informationssysteme gestellt werden. Trotzdem verfügen Informationssysteme in der Praxis vielfach nur über unzureichende Möglichkeiten zur Anpassung bzw. erforderliche Änderungen sind oftmals nur mit unvertretbar hohem Aufwand möglich. Dieser Beitrag beleuchtet das Problem der Flexibilität, beschreibt Möglichkeiten zur Lösung und schlägt workflowbasierte Informationssysteme vor, um ein größtmögliches Maß an Flexibilität zu ermöglichen.	altran praxis;unified model;vhf omnidirectional range	Andreas Oberweis;Wolffried Stucky	2003			library science;sociology	NLP	-102.89543596316476	33.50828745823149	186076
b1d42d294536aa54ae797b18eeebe90021539e42	400 jahre logarithmen		Mathematik und Informatik beteiligen sich an diesem ,,Festival der Jubiläen“ mit ,,400 Jahre Logarithmen“. Im Gegensatz zu den anderen genannten Jubiläumsdaten konnte ich keinen exakten Tag für dieses Ereignis ausmachen. Es steht aber fest, dass John Napier (1550–1617) im Jahr 1614 eine erste Logarithmentafel herausbrachte, deren Berechnungsgrundlagen allerdings von den später gebräuchlichen Briggs’schen Logarithmen abwichen. Briggs übertrieb es übrigens etwas mit seinen Lobhudeleien auf die Napier-Logarithmen. Er schrieb z. B. an Erzbischof Ussher: ,,Napier hat sowohl meinen Geist als auch meine Hände in Arbeit versetzt durch seine neuen und bewundernswerten Logarithmen. Ich hoffe, ihn im Laufe dieses Sommers zu treffen, so es Gott gefällt. Denn nie habe ich ein Buch gesehen, das mir besser gefiel oder mich mehr in Staunen versetzte.“ Schon die Inder sollen so etwas wie Logarithmen im zweiten Jahrhundert vor Christus genutzt haben. Aber Napier war halt der erste, der die Sache in der sogenannten neueren Zeit bekannt gemacht Abb. 1 John Napier (1550–1617)	eine and zwei;geist;halting problem;i/o controller hub;internet explorer;mir:ror;napier88;vhf omnidirectional range	Otto Spaniol	2014	Informatik-Spektrum	10.1007/s00287-014-0775-7	software engineering;computer science	DB	-104.58518027685903	34.33313913619882	186215
06a1a0d98cdda0088578e38601b0b91b2bc60cda	beschreibungsmodell für ikt-geschäftsmodelle in der elektromobilität		Mit der zunehmenden Bedeutung des Elektromobilitätsmarkts entstehen neue Geschäftsmodelle unterschiedlichster Anbieter. Diese unterscheiden sich von bisherigen unternehmerischen Ansätzen im Mobilitätssektor und nutzen unter anderem auch die neuartigen IKT-Voraussetzung en von Elektrofahrzeugen um innovative Produkte und Dienstleistungen zu entwickeln. In diesem Beitra g wi d ein Beschreibungsmodell vorgestellt, das zur Strukturierung ebensolcher Geschäftsmodelle mit IKT-Ausrichtung und Elektromobilitätsbezug dient. Ziel ist die Transparenz über bestehende Angebote zu erhöhen und die Ableitun g ne er Geschäftsmodelle zu unterstützen. 1 Motivation und Einleitung Auch wenn es keine kurzfristige Umstellung auf den Elektroantrieb geben wird [Kr11] und auch in Zukunft mehrere Antriebskonzepte nebeneinander existieren werden [Hu10], so ist der Übergang zur Elektromobilität (EM) langfristig wah rsc einlich [Ze09]. Unter allen Marktteilnehmern herrscht Einigkeit darüber, dass die EM ein möglicher Kandidat für die Mobilität der Zukunft ist [RRL12], [KZ11], [ Ko10]. 1.1 Ausgangssituation Laut dem New Policy Scenario der Internationalen Energieagentur wird der glob ale Energiebedarf bis zum Jahr 2035 aufgrund des Bevölkerungswachstums und der steigenden Personenund Frachtverkehrsnachfrage um 15% gegenüber dem Jahr 2010 steigen [IE11] . Verschiedene Studien wie die der Energy Watch Group [SZ08] oder der World Energy Outlook [IE11] kommen zu dem Schluss, dass mit ein em mittelbis langfristigen Preisanstieg des Öls zu rechnen ist. Durch EM ist es möglich, auf sämtliche der Stromerzeugung zur Verfügung stehenden Energieträger auszuweichen [Bu09], [PHM07], um so die Abhängigkeit vom Öl zu mindern.	es evm;gesellschaft für informatik;glob (programming);internet explorer;microsoft outlook for mac;unified model;zentralblatt math	Julian Krenge;Marco Roscher;Thorsten Kox	2013			engineering	OS	-106.85639415653	34.00829599092401	186617
0b9836e93c2477b263610e46bffcf4084954eecc	berücksichtigung von softwareperformanz im entwicklungsprozess		Software-Performance-Engineering (SPE) bezeichnet verschiedene Ansätze zur Performanzverbesserung von Software. Diese wurden bisher nicht vergleichend untersucht. Der vorliegende Beitrag beschreibt ein Vorgehen, um zu überprüfen, inwiefern die SPE-Ansätze die Entstehung performanter Software sicherstellen. Trotz des Vorhandenseins der SPE-Ansätze lassen sich bspw. beim Applikationsserver Apache Tomcat temporär im Entwicklungsversionen auftretende Performanzprobleme nachweisen. Dies deutet darauf hin, dass SPE-Techniken nicht bzw. nicht erfolgreich eingesetzt werden. Die semiautomatische Generierung von Performanztests könnte dieses Problem lösen, da mit dieser Performanzprobleme mit geringem Zusatzaufwand erkennbar wären. Dieser Beitrag schildert deshalb ein Vorgehen zur semiautomatischen Performanztestgenerierung.	apache tomcat;die (integrated circuit);intentionally blank page;performance engineering;unified model	David Georg Reichelt	2014			philosophy;performance art	SE	-102.2250787680576	32.527628960455964	186701
56cc492f9de61746960f21330e8728d90a9b941c	untersuchungen über die banach-logik		Die Arbeit gliedert sich in vier Abschnitte. Im ersten Abschnitt behandeln wir die Ausdrucksbestimmungen der Ranach-Logik. Der zweite Abschnitt beschiiftigt sirh niit den semantischen Grundbegriffen. Gegenstand des dritten Abschnittes ist die Einfuhrung der syntaktisch widerspruchsfreien Mengen von Ausdrucken. Im abschlieBenden vierten Abschnitt wird eine syntaktische Charakterisierung der semantisch widerspruchsfreien Mengen von Ausdriicken hergeleitet.	eine and zwei;zentralblatt math	Dietrich Schwartz	1979	Math. Log. Q.	10.1002/malq.19790250705	pure mathematics;combinatorics;mathematics	DB	-95.99977667574842	34.56818665218294	186717
7c2619522a8bf0b10337c520362b215e68752a7d	best practices für den umgang mit macht und politik im requirements engineering		Motivation Software-Projekte und damit auch deren Requirements Engineering (RE) sind eingebettet in das Projektund Firmenumfeld von Auftraggeber und Auftragnehmer. Hierzu gehören in nicht unerheblichem Maße auch die Machtverhältnisse und politischen Strategien der beteiligten Stakeholder. Diese Machtverhältnisse wirken sich auf den gesamten Prozess des REs und dessen Ergebnisse aus, z.B. auf Entscheidungen in Bezug auf Anforderungen oder deren Priorisierung. Teilweise werden Konflikte zwischen Stakeholdern auch über das RE ausgetragen. Angeregt durch den Artikel „Power and politics in requirements engineering: embracing the dark side?” [1] von Milne und Maiden beschäftigten wir uns im Arbeitskreis „Softskills Required!“ mit diesem Thema und fanden, dass der gegebene Rat, Machtverhältnisse zu modellieren, uns für die Praxis nicht genügt. Darum wollen wir selbst anhand realer Fallstudien eine Sammlung praxisorientierter Best Practices entwickeln.	altran praxis;best practice;dark side;eine and zwei;requirements engineering	Andrea Herrmann;Alexander-Marc Merten	2013	Softwaretechnik-Trends		software engineering;computer science;library science;requirements engineering	SE	-101.47274805392605	33.39432555716918	186835
0161d6bf7eb71ac4324f37236de68c8d2a45e188	der reale wert einer ip-adresse		Die Hauptargumentation seitens der Regierung und der Strafverfolgungsbehörden für die Vorratsdatenspeicherung ist der Kampf gegen den internationalen Terrorismus und die Schwerstkriminalität. Ich zeige am Beispiel von IP-Adressen im Umfeld von Kabel Netzwerken, wie einfach man eine fremde Identität annimmt oder anonym agieren kann, weshalb der Nutzen einer IP-Adresse für Strafverfolgungsbehörden gering ist.	eine and zwei;i/o controller hub;internet explorer	Amir Alsbih	2011	Datenschutz und Datensicherheit - DuD	10.1007/s11623-011-0119-6	computer science;internet privacy	NLP	-104.56350997173148	35.399160650787856	187325
736ee2361597fba2416620c3f240ebfc565b611a	eckpunktepapier der bundesregierung zu „trusted computing“ und „secure boot“		Der Bundesbeauftragte für den Datenschutz und die Informationsfreiheit Peter Schaar hat am 21.11.2012 einen Leitfaden zur Gesetzesevaluation vorgestellt. Der Leitfaden wurde im Auftrag des Bundesbeauftragten vom Deutschen Forschungsinstitut für öffentliche Verwaltung, unter der Leitung von Professor Dr. Jan Ziekow, erarbeitet. Peter Schaar: „Die Eignung gesetzlicher Maßnahmen und ihre Folgen für die Grundrechte der Bürgerinnen und Bürger müssen nach wissenschaftlichen Kriterien beurteilt werden. Die Deutungshoheit hierfür darf nicht weiter bei den Stellen liegen, die mit zusätzlichen Befugnissen ausgestattet wurden. Vielmehr muss der Deutsche Bundestag auf Basis unabhängiger und nach wissenschaftlichen Kriterien durchgeführter Evaluation darüber entscheiden, ob einmal beschlossene Befugnisse weiterhin gerechtfertigt sind.“ Die Erfahrung zeige, dass insbesondere die aufgrund konkreter Bedrohungen eingeführten Befugnisse der Sicherheitsbehörden selbst nach einer Entspannung der Sicherheitslage nicht zurückgenommen wurden. Noch im vergangenen Jahr wurden die nach dem 11. September 2001 unter Zeitdruck erlassenen Anti-TerrorGesetze erneut ohne gründliche, unabhängige Überprüfung verlängert. Der gesetzlich geforderte Evaluierungsbericht wurde vor der Verabschiedung des Gesetzentwurfs nicht vorgelegt. Der „Leitfaden zur Durchführung von ex-post-Gesetzesevaluationen unter besonderer Berücksichtigung der datenschutzrechtlichen Folgen“ richtet sich an Abgeordnete und Beamte, die mit einer Gesetzesevaluation betraut sind. Der Leitfaden setzt sich umfassend mit den Standards, Evaluationsinstrumenten und Methoden auseinander, die für die Evaluation gelten und stellt die verfassungsrechtlichen Rahmenbedingungen dar. Er gibt zudem einen praktischen Überblick über die notwendigen Abläufe bei den evaluierenden Stellen. Schon bevor eine Evaluierung in Auftrag gegeben wird, hilft der Leitfaden den Entscheidungsträgern, dafür die richtigen Bedingungen festzulegen. Der Leitfaden ist über die Website des BfDI verfügbar: http:// www.bfdi.bund.de/SharedDocs/Publikationen/Allgemein/Evaluation _Leitfaden.html?nn=408908	die (integrated circuit);eine and zwei;hardware restriction;trusted computing;vhf omnidirectional range	Der Bundesbeauftragte	2013	Datenschutz und Datensicherheit - DuD	10.1007/s11623-013-0032-2		Security	-103.65229034602271	35.84952679251544	187460
d87c428f3a71b78e65d1f31202e115fb11802e3f	id number policies in europe	public domain;point of view	The objective of this article is to present a view on the sensible use of the identification numbers, especially in the public domain. The question of whether proper use can be achieved by a single global identifier or multiple identifiers will be answered. In the report on which this article is based, several FIDIS partners investigated different aspects of ID numbers, such as the history of the use of identification documents, the legal framework, the sociological theoretical aspects and the possible use of ID numbers in the technique of profiling. Thus the investigations presented in the report provided a sound basis for determining the risks and opportunities in using ID numbers, especially in the area of e-government. From a European point of view the choices made of using either a single global identifier or multiple identities, are illustrated. The report shows how the ID number can be put to good use while at the same time not unduly harming the privacy interests of the individual. Der Beitrag liefert einen Überblick über die konzeptionellen, historischen, soziologischen und technischen Implikationen einer Politik der Identifizierungsnummern zwischen funktionalen Verwendungsinteressen einerseits und dem Datenschutz andererseits. Der Beitrag prognostiziert unterschiedliche Identifikatoren für verschiedene Verwendungszwecke, die interoperabel sein können, aber auch gleichzeitig eine Steuerung durch den Nutzer ermöglichen.	e-government;eine and zwei;identification (information);identifier;point of view (computer hardware company);privacy;profiling (computer programming)	J. C. Buitelaar	2008	Datenschutz und Datensicherheit - DuD	10.1007/s11623-008-0063-2	public domain;computer science;data mining;world wide web	Web+IR	-101.9353111569274	37.026019715496105	187843
1362a04e98061b9bec249399f1d27a02eaeb065c	komplexitätsmetriken für geschäftsprozessmodelle		"""Häufig werden grafische Modelle zum Software-Entwurf verwendet. In späten Phasen der Softwareerstellung sind solche Modelle oft schon recht """"codenahe"""". Gerade in den früheren Phasen gibt es aber häufig Modelle, deren Hauptzweck darin besteht, die Kommunikation zwischen Auftraggebern und Entwicklern zu unterstützen. Um diese Kommunikation zu erleichtern, sollten die Modelle möglichst leicht verständlich sein. Hierfür ist zunächst zu klären, was man unter „leicht verständlich“ versteht. Unser Beitrag untersucht, inwiefern sich Ideen bekannter SoftwareKomplexitätsmetriken auf grafische Geschäftsprozessmodelle übertragen lassen."""	gesellschaft für informatik;parity (physics);unified model	Volker Gruhn;Ralf Laue	2006			computer science	NLP	-105.29309562446227	33.92350983455912	188072
5f89ef71fa9bba03f3bb120f357cddd7ba22e07f	business continuity management für kmu		Bei kleinen und mittelständischen Unternehmen (KMU) besteht erheblicher Nachholbedarf beim Business Continuity Management (BCM). Die existierenden Standards und Prüfvorschriften werden häufig als zu komplex und ihre Umsetzung als zu aufwändig und teuer empfunden. Der Beitrag stellt einen Leitfaden für KMU zur Implementierung eines BCM vor, der auf den Ergebnissen einer von der FHS St. Gallen durchgeführten Studie zur Erfassung von Good Practices basiert.	bcm theory;business continuity planning;die (integrated circuit);institut für dokumentologie und editorik;scott continuity;vhf omnidirectional range	Christoph Thiel	2010	Datenschutz und Datensicherheit - DuD	10.1007/s11623-010-0114-3	management;internet privacy;computer science;business continuity	ML	-101.0464475232662	34.63533363662863	188164
b406105dc14c4a66812db27c0f08252c6e1977a8	die zulässigkeit it-gestützter compliance- und risikomanagementsysteme nach der bdsg-novelle		EDV durchdringt in zunehmendem Maße die Unternehmen. Sie ist das Werkzeug des Managements für die Steuerung und überwachung sämtlicher Prozesse. Sie kann unter anderem zur Unterstützung bei der Erfüllung von Risikomanagement- und Compliance-Pflichten eingesetzt werden und muss es abhängig von der Durchdringung des Unternehmens mit IT gesteuerten Prozessen auch. Mit dem IT-Einsatz verbinden sich neben einem möglichen Nutzen aber auch Risiken, die es zu beachten gilt. Es ist sicherzustellen, dass rechtliche, insbesondere datenschutzrechtliche, Anforderungen an den IT-Einsatz beachtet werden. So gilt es das Interesse der Unternehmen an einer möglichst umfassenden und effizienten Kontrolle von Unternehmensprozessen mit dem Interesse der Beschäftigten an ihrer informationellen Selbstbestimmung in Einklang zu bringen. IT-gestützte Compliance- und Risikomanagementsysteme bewegen sich daher in einem Spannungsfeld zwischen Nutzen, Risiken und rechtlichen Anforderungen. Die geplante Novelle des BDSG nimmt sich dieses Spannungsfeldes an und soll bisher fehlende klare gesetzliche Regelungen schaffen, um Beschäftigte zu schützen und Arbeitgebern eine verlässliche Grundlage für die Datenverarbeitung an die Hand zu geben.	die (integrated circuit);eine and zwei;opengl es;sie (file format);unified model	Bernd Schmidt;Christian Jakob	2011	Datenschutz und Datensicherheit - DuD	10.1007/s11623-011-0026-x	internet privacy;computer science;performance art	Crypto	-104.26710830436055	33.900495831756814	188802
8e3133f825c9101441128434de20f5f395fb36b2	wahlverhalten zum schulfach informatik in der si - eine studie im regierungsbezirk münster		Seit mehr als 40 Jahren etabliert sich das Fach Informatik in Nordrhein-Westfalen, doch die strukturellen Rahmenbedingungen machen Informatik für viele Schülerinnen und Schüler wenig attraktiv. Die Erwartungen und Erfahrungen im Hinblick auf Informatikunterricht schrecken scheinbar vor einer Wahl von Informatik ab. Den schon länger vermuteten Zusammenhängen möchte die Studie nachgehen, denn empirische Daten zu Anforderungen für Informatikunterricht von Schülerinnen und Schülern existieren kaum. Im Herbst/Winter 2013 und 2014 wurde eine Umfrage unter ca. 2400 Schülerinnen und Schülern der Sekundarstufe I in Informatikund NichtInformatik-Kursen durchgeführt.	circa;eine and zwei;fach;vhf omnidirectional range	Irina Janzen;Marco Thomas;Angélica Yomayuza	2015				DB	-104.92177558896395	33.83605673048924	188842
4ed1ea6d85e36085943ba25498fca8cf03eb20ec	prozessidentifikation mit der methode der adjusted least squares			least squares	Olaf N. Jepsen	1993				Theory	-97.9220929836102	35.78430865386309	189303
427c7eb8f9de878d8fffa48405dcf42d7dd347f5	der taylorismus - kein modell für die büroautomation	der taylorismus;kein modell	Wenn in den vergangenen 20 Jahren uber die Entwicklung der Buroarbeit diskutiert und auch spekuliert wurde, so stand vielen, vor allem kritischen Betrachtern die tayloristische Form der Arbeitsteilung als Zukunftsmodell vor Augen. Die im Produktionsbereich erfolgten Veranderungen stellten sozusagen das Muster dar, nach dem auch die Perspektiven der Buroarbeit beurteilt wurden und z.T. noch werden. Die gerade in den letzten Jahren erfolgte empirische Uberprufung dieser Vorstellung durch eine ganze Reihe von Forschungsprojekten (Baethge/Oberbeck 1986, Berger 1984, Engfer 1984, Gottschall u.a. 1985, Hartmann 1984, Jacobi/Lullies/Weltz 1980, Weltz/Lullies 1983) hat nun aber gezeigt, das von einer Taylorisierung der Buroarbeit, was deren Kern betrifft, nicht gesprochen werden kann. Der Trend scheint nicht in Richtung einer verstarkten Arbeitszerlegung, sondern in Richtung einer Beibehaltung bzw. Neuschaffung komplexer Sachbearbeitung zu gehen. Damit aber durfte das Verhaltnis von Produktions- und Verwaltungsautomation eher in entgegengesetzter Richtung verlaufen als fruher angenommen. Die (im folgenden naher analysierten) Strategien und Resultate von Verwaltungsrationalisierung scheinen das vorwegzunehmen, was in jungster Zeit unter der Bezeichnung “Neue Produktionskonzepte” eine Wende in der Produktionsumstrukturierung markiert. Warum dieser Typ von Rationalisierung die Buroautomation pragt, soll im weiteren anhand der Industrieverwaltung beleuchtet werden.1)	v-model	Michael Hartmann	1986		10.1007/978-3-642-71380-4_14	history;performance art	Logic	-105.2713321088939	34.03561607346919	189870
df734e28af45a69ee8379d3bd8b10f8774638994	vertrauen ist gut … zertifizierung ist besser!		Der grundsätzliche Wert einer Zertifizierung der IT-Sicherheit von Produkten und Lösungen ist aufgrund langjähriger Praxis unbestritten – schließlich sind viele unserer täglichen Begleiter, ob Personalausweis, Reisepass oder Gesundheitskarte, nach speziellen Sicherheitsvorgaben zertifiziert und mit ISO/IEC 15408 hat sich ein einschlägiges, international abgestimmtes Normenwerk (auch bekannt als „Common Criteria“) fest etabliert. Andererseits erreicht die Methodik der Common Criteria aus nachvollziehbaren Gründen nur einen kleinen Teil der uns umgebenden IT Infrastruktur. Ein wenig ist das – bitte verzeihen Sie das plumpe Bild – als würden nur wenige ausgewählte Fahrzeuge auf unseren Straßen TÜV-geprüft. Unter anderem mit dem Ziel, diese unbefriedigende Situation zu verbessern, hat die Europäische Kommission im September 2017 im Rahmen ihres Cybersecurity Packages einen Vorschlag für einen sogenannten „Cybersecurity Act“ veröffentlicht. Dieser stellt zum einen eine gute Chance für die Verbesserung der Cybersicherheit in Europa dar, zugleich soll er der europäischen IT-Sicherheits-Industrie neue Möglichkeiten eröffnen. Den inhaltlichen Schwerpunkt des vorliegenden Heftes bildet eine Reihe von Beiträgen zu dem oben angesprochenen Komplex. Miguel Bañón führt in die ISO/IEC 15408 Normenfamilie ein, diskutiert das Erreichte und das Wünschenswerte und gibt einen Ausblick auf die derzeit intensiv vorangetriebene Weiterentwicklung der Common Criteria. Andreas Mitrakas beleuchtet im Anschluss den „Cybersecurity Act“ aus Sicht der ENISA und diskutiert die angestrebte neue Rolle der ENISA im Zusammenspiel mit den bereits existierenden Aktivitäten und Spielern auf dem Feld der Zertifizierung von IT-Sicherheit in Europa. Der Beitrag von Bernd Kowalski und Matthias Intemann bildet hierzu einen Gegenpol und setzt sich entsprechend kritisch mit dem „Cybersecurity Act“ auseinander. Edward Humphreys gibt einen Einblick in seine Erwartungen hinsichtlich der Weiterentwicklung der überaus erfolgreichen ISO/IEC 27001 Normenfamilie. Er beleuchtet marktwie technologiegetriebene Herausforderungen und diskutiert möglicherweise notwendig werdende Anpassungen im Angebot der ISMS Standards. Neben der IT-Sicherheit sind Vertrauensdienste – wie sie durch die eIDAS-Verordnung definiert sind – ein bereits bewährtes Anwendungsfeld für Zertifizierungen. Mit Kim Nguyen und Herbert Leitold/Daniel Konrad erläutern ausgewiesene Experten die positiven sowie in Deutschland und Österreich auch unterschiedlichen Erfahrungen in diesem Bereich. Arno Fiedler und Christian Thiel runden den Schwerpunkt des Heftes mit einer kritischen Sicht auf nationale, regionale und gesellschaftliche Aspekte einer Zertifizierung von IT-Sicherheit ab. Zwei Aufsätze gehen darüberhinaus auf spezifische Themen ein, die sich aus der Datenschutzgrundverordnung ergeben. Olga Kieselmann und Arno Wacker behandeln mit einem neuen Lösungsansatz das nach wie vor spannende Thema „Löschen im Internet“ und Susan Gonscherowski, Marit Hansen und Martin Rost greifen Resilienz als eine neue Anforderung aus der Datenschutz-Grundverordnung auf. Wir hoffen, das Spektrum der Beiträge in diesem Heft findet auch diesmal Ihr Interesse.	altran praxis;blitzkrieg;citeseerx;common criteria;computer security;cyber security standards;eine and zwei;europa;heterogeneous earliest finish time;iso/iec 27001:2013;internet explorer;olga (technology);randi j. rost;sie (file format);vhf omnidirectional range	Walter Fumy;Helmut Reimer	2018	Datenschutz und Datensicherheit - DuD	10.1007/s11623-018-0966-5	computer science;internet privacy;computer security	OS	-103.43164870721289	35.57127603301883	189910
b8a8fa82b118a1d68dd275459879581f392a546f	cloud storage: wie viel cloud computing steckt dahinter?	cloud computing	Kurzfassung: Durch die hohe Dynamik im Bereich des Cloud Computings entstehen neues Potenzial, aber auch Risiken bezüglich existierender und neuer Anwendungen. Eine wichtige Ressource bei der Nutzung von Cloud Computing ist sicherlich Cloud Storage. Unter Cloud Storage werden Datenspeicher subsumiert, die in unterschiedlichen Varianten von Cloud Computing Betreibern angeboten werden. Die wichtige Frage für die Nutzung von Cloud Storage ist hierbei, inwiefern auf technischer Ebene die wesentlichen Eigenschaften des Cloud Computings wie Elastizität, Skalierbarkeit und Kostenreduktion umgesetzt werden. Anhand von Beispielen wird deutlich, dass viele dieser Eigenschaften nach derzeitigem Stand nicht vollständig erfüllt werden.	cloud computing;cloud storage;eine and zwei;internet explorer	Michael C. Jäger;Uwe Hohenstein	2011			cloud storage;cloud computing;distributed computing;computer science	HPC	-102.12654836871629	36.04250242636867	189994
eade4480e629848b0a50e2a635d983dbf7c4133c	studentische interaktion mit automatischen prüfungssystemen	talk	Idealerweise werden Studierende dazu angehalten, sich kontinuierlich mit dem Stoff einer Vorlesung zu befassen. Die beschränkte Verfügbarkeit von Ansprechpartnern zur Beantwortung allgemeiner Fragen oder zur Korrektur konkreter Abgaben für Übungsblätter führt jedoch eher zu einer schubweisen Beschäftigung mit einem Thema. Der vorliegende Artikel untersucht als Anwendungsbeitrag an einem konkreten Beispiel, ob und wie ein permanent verfügbares, automatisches Prüfungssystem für Übungsaufgaben eine Änderung der Situation herbeiführen kann und welche Nutzungsstrategien Studierende gegenüber einem solchen System entwickeln.	eine and zwei;internet explorer;mit/gnu scheme	Michael Striewe;Michael Goedicke	2011				OS	-105.23277012737711	34.20613814483388	190289
f7a849818e6914953ec302ea6da8b925eaf6f7d7	wohin mit den stasi-akten?		In der DDR gab es keine öffentlich zugänglichen Nachrichtendienste. Neuigkeiten zu sammeln war das Vorrecht der Geheimpolizei. Im Gegensatz zu den Verlautbarungen des sogenannten Allgemeinen Deutschen Nachrichtendienstes (ADN) der DDR spiegeln die Unterlagen des Ministeriums für Staatssicherheit (auch) Probleme und Misserfolge wider. Diese Niederschriften, gelagert in den Räumen des Bundesbeauftragten für die Stasi-Unterlagen, BStU, stehen im Spannungsverhältnis zwischen der Neugier des Historikers und dem Recht auf informationelle Selbstbestimmung. Am 12. April 2016 hat eine Kommission unter Vorsitz des ehemaligen Ministerpräsidenten Wolfgang Böhmer Vorschläge zum weiteren Aktenumgang vorgestellt. Diese sind Gegenstand der nachfolgenden Betrachtung.	application delivery network;eine and zwei;gab;stasi 2.0	Bodo Walther	2016	Datenschutz und Datensicherheit - DuD	10.1007/s11623-016-0665-z	internet privacy;computer science;performance art	Crypto	-103.30033425399984	35.351880966799236	190442
7934437ad7bd33ccd8f4cbe0583e968ed2e63eef	"""kivs und kuvs. ein spiegel der deutschen """"network community"""" seit 25 jahren"""		Heinz-Gerd Hegering, 1984-1988 Professor für Informatik an der Technischen Universität München. Seit 1989 Lehrstuhl für Informatik und Geschäftsführender Vorstand des Instituts für Informatik der Ludwig-Maximilians-Universität München sowie Vorsitzender des Direktoriums des Leibniz-Rechenzentrums. Mitglied der Kommission für Rechenanlagen der Deutschen Forschungsgemeinschaft (DFG) von 1995 bis 2000. Vorstand des Vereins Deutsches Forschungsnetz (DFN-Verein) seit 1996. Mitglied diverser ministerieller Experten-Kommissionen für IT-Infrastrukturplanung und InformatikEntwicklung an Hochschulen. Forschungsgebiete: Kommunikationssysteme, Netzund Systemmanagement, IT-Infrastrukturen.	gesellschaft für informatik;quad flat no-leads package	Heinz-Gerd Hegering	2005	Praxis der Informationsverarbeitung und Kommunikation	10.1515/PIKO.2005.2		OS	-99.31622568211307	32.40260941187205	190514
e5d11a7dcdc6fbb3dcf76daa7aada739db676517	extraktion und kartografische visualisierung von informationen aus weblogs		Beim Information Retrieval ist in Anbetracht der Informationsflut entscheidend, relevante Informationen zu finden. Ein vielversprechender Ansatz liegt im semantischen Web, wobei dem System die Bedeutung von Informationen ontologiebasiert beigebracht wird. Sucht der Benutzer nach Stichworten, werden ihm anhand der Ontologie verwandte Begriffe angezeigt, und er kann mittels Mensch-Maschine-Interaktion seine relevanten Informationen extrahieren. Um eine solche Interaktion zu fordern, werden die Ergebnisse visuell aufbereitet. Dabei liegt der Mehrwert darin, dass der Benutzer anstelle von Tausenden von Suchresultaten in einer fast endlosen Liste ein kartografisch visualisiertes Suchresultat geliefert bekommt. Dabei hilft die Visualisierung, unvorhergesehene Beziehungen zu entdecken und zu erforschen.		Edy Portmann;Adrian Kuhn	2010	HMD - Praxis Wirtschaftsinform.		computer science	NLP	-106.39646214876552	35.47056786768689	190971
82824e38e23d96d007f507756f3ff723165c70e0	regelgestützte generalisierung von gebäudegrundrissen in geographischen datenbanken		Die Bearbeitung raumbezogener Daten zwecks Darstellung in Landkarten wird zunehmend mit Computerunterstutzung durchgefuhrt. Fur den Prozes der kartographischen Generalisierung, in dem die darzustellenden Gegebenheiten aufgrund von Platzmangel in der Darstellung vereinfacht bzw. modifiziert werden, existieren noch keine Verfahren, die den vielfaltigen Anforderungen dieses Vorgangs gerecht werden. Es wird ein regelbasierter Ansatz vorgestellt, der sowohl der heuristischen Natur dieses Vorgangs entspricht als auch der geforderten Flexibilitat gerecht wird, die es erlaubt, ihn unterschiedlichen Anforderungen anzupassen.		Ralf Bill;Marko Krause;Andreas Reuter	1993			philosophy;performance art	Vision	-104.94501706609208	32.36194207610893	191525
1d8603b4bee23bbcf78c8b424ee8bd56e7ee3347	privatheit parzelliert		in Kolumne 04/13 „In der Parentel“ befasste ich mich mit der Privatheit im frühen Mittelalter. In dieser Zeitspanne – von der Völkerwanderung bis zum achten Jahrhundert – hatten sich auf dem Boden des untergegangenen römischen Reichs die uns geläufigen Ethnien geformt. Die Germanen waren zu gläubigen Beschützern der Kirche geworden. Ihre Gesellschaftsordnung folgte dem Prinzip von Macht und Unterordnung. Unter dem König stand hierarchisch gestaffelt der Adel, seine Vasallen. Sie wurden von ihm mit Ämtern, Titeln und Immobilien belehnt und waren ihm dafür zu Diensten verpflichtet. Die Unterordnung war demonstrativ. So hatte etwa der Hochadel gegenüber dem König leibdienende Funktionen, wie Küchenmeister (Truchsess) oder Stallmeister (Marschall). Dem entsprechend beherrschten die hochadeligen Herren ihre eigenen Vasallen. Die öffentliche Macht war insofern gestaffelt und parzelliert. Die sonstige germanische Bevölkerung war abhängig, zumeist hörig oder leibeigen. Das öffentliche Leben spielte sich nicht, wie in der Antike, in den Städten sondern nach germanischem Geschmack auf Herrensitzen im Lande ab. Das germanische Gefolgschaftswesen hatte das römische Klientelwesen abgelöst. Der Einzelne genoss Sicherheit in definierten Gemeinschaften, etwa im Gefolge eines Fürsten, im Kloster oder unter Waffenbrüdern, insbesondere aber in der Sippe. In sie wurde er hineingeboren. Sie gab ihm Schutz und forderte von ihm Loyalität und seinen Beitrag zur Sippenehre. Er stand für sie ein, befolgte ihre Riten, folgte ihren Entscheidungen, rächte Ehrverluste, heiratete den ihm zugedachten Partner etc. An Struktur und Riten der Sippe orientierten sich die anderen Gemeinschaften. Auch Gesellschaft und Privatheit waren also parzelliert. Zur weltlichen Macht war die geistliche Macht der Kirche hinzugekommen, die Gesellschaft entlang der beiden Machtlinien geordnet. Wie sie war, wurde diese Ordnung als göttlich und unveränderlich verstanden. Der persönliche Freiraum des Einzelnen war durch den Sippenkanon eingeengt. Nicht das Individuum sondern seine Gemeinschaft wäre im heutigen Sinne das gefühlte Schutzsubjekt für Menschenrechte gewesen. Der Glaube an die Vernunft rührte sich noch nicht, und auch nicht so recht die Besinnung des Menschen auf seine Individualität. Davor bewahrte ihn die Kirche; sie hatte die Gefährlichkeit des „falschen Herzen“ erkannt und wusste ihr zu begegnen. Die einschlägigen Historiker1 rätseln darüber, warum sie bei der Genehmigung von Heiraten besonders strikte Inzestregeln anwendete. Ein Paar durfte nicht getraut werden, wenn die beiden auch nur entfernt (manchmal bis zum siebten Grad) miteinander verwandt waren, nicht notwendigerweise blutsverwandt. Das hätte das Heiraten sehr erschweren müssen. Es wurde trotzdem geheiratet. Eine der von Historikern vorgebrachten, unbewiesenen Vermutungen ist: Je strikter die Inzestregeln, umso leichter lässt sich ein Grund gegen eine eheliche Verbindung finden, dem drängenden „falschen Herzen“ eines mächtigen Herren nachzugeben und eine Ehe als inzestuös aufzulösen oder sie zu verbieten. Das, bemerkte der Autor, könnte als ein Zeichen von Individualismus gedeutet werden. Diese Bemerkung fiel mir auf, denn „Individualismus“ war beim Suchen nach Privatheit im feudalen Zeitalter eines meiner Suchvokabeln. Die hier vorgefundene besondere Art Individualismus, liebe Leserinnen und Leser, hat in der Feudalzeit und später oft Bewegung in die geschichtliche Entwicklung gebracht; denken Sie etwa an Heinrich VIII von England. Und: Sollte die o.a. Vermutung der Historiker wahr sein, dann wäre die Kirche gegen ihre Moral einem „falschen Herzen“ gefolgt; sie hätte sich eine zweckdienliche Regel ausgedacht, den Individualismus eines Mächtigen bedienen und eine Ehe auflösen oder verbieten zu können. Heute hätte sie – bei aller modernen Liberalität – mit solcher Willfährigkeit ein Problem.	eine and zwei;gab;gesellschaft für informatik;i/o controller hub;internet explorer;könig's lemma;moral hazard;sie (file format);the grid analysis and display system (grads)	Karl Rihaczek	2013	Datenschutz und Datensicherheit - DuD	10.1007/s11623-013-0167-1		OS	-104.75008096907716	35.392285226349586	191720
178410f848b855f51563dd3e5acfc7d61aa5b971	meins oder deins – private endgeräte im unternehmenseinsatz		Mitte 2007 kam der Erste unserer Kunden mit Fragen zu dem Einsatz von Smartphones in seinem Unternehmen auf uns zu. Dabei ging es um die Nutzung von Windows-Mobile-basierten Geräten für Mitarbeiter im Außendienst. In diesem Projekt sollten Mitarbeiter mit gemanagten Endgeräten auf dedizierte Unternehmensdaten und ihre persönliche Kontakte, Kalender, Aufgaben und E-Mail zugreifen. Damals waren die Maßgaben aus Sicherheitsaspekten sehr rigide und die Diskussionen mit den Sicherheitsverantwortlichen hatten eher den Verlauf von Tribunalen. Hier wurde erstmals erkennbar, welche Probleme mobile Endgeräte in Unternehmensdiensten hervorrufen. Letztendlich konnte das Projekt zum Erfolg geführt werden. Zwei Erfahrungen wurden gemacht:	eine and zwei;gnu variants;intentionally blank page;microsoft windows;smartphone;unified model;windows mobile	Michael Wilk	2014	HMD Praxis der Wirtschaftsinformatik	10.1365/s40702-014-0013-4	knowledge management;engineering		-104.25807336900601	37.00922233727874	192255
55db0485488fce09656600d8c02532a15d7409b0	erschließung neuer dienstleistungspotenziale durch webbasierte zusammenarbeit und grid-computing	grid computing	Im industriellen Umfeld treten häufig stark arbeitsteilige Prozesse auf, bei denen mehrere Beteiligte zur Erreichung eines gemeinsamen Ziels kooperieren müssen. Die Zusammenarbeit kann dabei mit Hilfe einer Kollaborationsplattform effizienter gestaltet werden. In einem konkreten Szenario wurde in Zusammenarbeit mit einem mittelständischen Numerikdienstleister aus dem Bereich der Metallumformtechnik der Projektabwicklungsprozess zwischen mehreren Parteien durch eine portalbasierte Kollaborationsplattform unterstützt und zusätzlich Methoden des Grid-Computing in den typischen Ablauf eines Berechnungsprojekts integriert. Auf diese Weise konnte das Leistungsangebot des Dienstleisters um neue Dienste erweitert werden. 1 Einleitung Das Ziel des vom Bundesministerium für Bildung und Forschung (BMBF) geförderten Projekts PartnerGrid [PG10] ist die Erprobung von Gridund Cloud-Computing in konkreten Anwendungsfällen aus der industriellen Praxis. Als Testfeld dienten verschiedene rechenintensive Szenarien, die gemeinsam mit Industriepartnern aus den Bereichen Gießereiprozesssimulation und Umformtechnik realisiert wurden. Im Szenario „Umformsimulation“ lag der Schwerpunkt darin, Grid-Computing in die Abläufe des Berechnungsdienstleisters zu integrieren und den Projektabwicklungsprozess zwischen mehreren beteiligten Partnern einer Wertschöpfungskette durch eine portalbasierte Kollaborationsplattform zu unterstützen [We07]. Das betrachtete Szenario stellt sich wie folgt dar: Ein Großunternehmen (Auftraggeber) gibt bei einem mittelständischen Betrieb (Zulieferer) ein Bauteil in Auftrag, für das er als Qualitätsdokumentation Simulationen des Produktionsprozesses und der Bauteileigenschaften verlangt. Der Zulieferer kann diese Simulationen nicht selbst durchführen und beauftragt einen Dienstleister mit der Berechnung. 1 Förderkennzeichen 01G07009A-D	altran praxis;blitzkrieg;cloud computing;eine and zwei;gesellschaft für informatik;grid computing;internet explorer;unified model	Erik Hebisch;Oliver Strauß	2010			grid computing;distributed computing;computer science	Crypto	-102.01600081135061	35.49185458845397	192878
8e3789379ee07c2548704e8a88c49e3a598ce73e	procycle - integrierte unterstützung des prozesslebenszyklus	case base reasoning	Aufgrund häufiger Änderungen in ihrem Geschäftsumfeld müssen Unternehmen in der Lage sein, ihre Geschäftsprozesse und die sie unterstützenden Informationssysteme (IS) rasch und flexibel anzupassen. In jüngerer Vergangenheit ist eine neue Generation von IS entstanden, die eine umfassende IT-Unterstützung für Prozesse zum Ziel haben. Diese Systeme haben sich jedoch in der Praxis oftmals als zu starr erwiesen. Um wirklich breit einsetzbar zu sein, muss es auch möglich sein, in Ausnahmefällen flexibel vom definierten Prozess abzuweichen sowie Prozessimplementierungen rasch an sich ändernde Rahmenbedingungen, wie beispielsweise neue gesetzliche Anforderungen, anzupassen. Das prozessorientierte IS sollte den Benutzer im Änderungsfall durch die Wiederverwendung von Änderungen unterstützen sowie den Prozessverantwortlichen bei der Ableitung von verbesserten Prozessmodellen helfen. Dieser Beitrag stellt mit ProCycle einen implementierten Ansatz vor, der all diese Funktionalitäten bietet und der aus der Integration adaptiver Prozess-Management-Technologie mit Techniken des Case-Based Reasoning hervorgegangen ist. Ziel ist es, den kompletten Prozesslebenszyklus in integrierter Form zu unterstützen.	altran praxis;case-based reasoning;eine and zwei;internet explorer;rasch model;sie (file format);unified model;vhf omnidirectional range	Barbara Weber;Werner Wild;Manfred Reichert;Peter Dadam	2007	KI			OS	-102.86915113847238	32.966478876360384	192895
292fa99ced897d558b8da640655be484561152cc	ocr für alte drucke		Einleitung Unter allen kulturellen Artefakten nimmt die Schrift nach Menge und Bedeutung zweifellos den ersten Rang ein. Das schriftlich fixierte kulturelle Erbe ist in Manuskripten, der Menge nach aber vor allem in gedruckten Büchern gespeichert, die seit der Medienrevolution durch die Erfindung des Drucks mit beweglichen Metalllettern (1453: Gutenbergs Bibeldruck) vorliegen. Nach mehr als einem halben Jahrtausend steht nun die nächste Revolution an, die unser vorhandenes Wissen in ein neues Medium transformieren, gleichzeitig aber auch neuen Verwendungen zugänglich machen wird: Eine Reihe von Digitalisierungsprojekten, allen voran Google Books, ist seit Jahren damit beschäftigt, digitale Seitenbilder dieser Bücher durch Anwendung der Buchscantechnologie zu erzeugen. Es ist absehbar, dass der Großteil aller jemals hergestellten Buchtitel in einigen Jahren vollständig digitalisiert und für jedermann zugreifbar im Internet vorliegen wird. Damit scheint sich der Traum von der universalen Bibliothek, die Vision des freien Zugriffs auf das gesamte Menschheitswissen, demnächst zu verwirklichen. Es gibt jedoch eine Einschränkung: Bildseiten können nicht maschinell durchsucht werden und erfordern zu ihrer Interpretation ein Augenpaar mit dahinter geschaltetem Gehirn. Die echte universale Bibliothek liegt erst dann vor, wenn ihre Texte auch in maschinenverarbeitbarer Form zur Verfügung stehen, damit Fundstellen, Querverweise, Abhängigkeiten und die ganze Breite des intellektuellen Diskurses auf Knopfdruck zur Verfügung stehen.	eine and zwei;gesellschaft für informatik;internet explorer 7;vhf omnidirectional range	Uwe Springmann	2016	Informatik-Spektrum	10.1007/s00287-016-1004-3	computer science;software engineering;world wide web	OS	-105.47984384279212	35.38810848717237	192905
984f4e88c85506ee48ac21b1d9501c70df724a29	"""kontextgesteuertes e-learning in unternehmensumgebungen: der """"learning in process""""-ansatz"""		Im Gegensatz zu traditionellen Lernprozesstypen in Unternehmen ermöglicht das kontextgesteuerte E-Learning eine enge Verzahnung von Lernen und Arbeiten und damit eine Erhöhung der Effektivität des Lernens. Hierbei sammelt das E-Learning-System Informationen über den Kontext des Benutzers und schlägt auf der Basis der Wissensanforderungen dieses Kontextes und der Kenntnisse des Benutzers passende und auf den Lernenden abgestimmte Lernprogramme vor, die aus kleinen modularen Lernobjekten dynamisch bei Bedarf zusammengestellt werden. Es wird eine Methodik sowie eine konkrete technische Lösung auf der Basis von Ontologien vorgestellt, die im Rahmen des Projektes LIP entwickelt und evaluiert wurden.	eine and zwei;vhf omnidirectional range	Andreas B Schmidt	2004				Crypto	-107.50618686490499	34.23022011535664	193154
28c7ee30557a2661c63ff3434ff509ff95714b8f	satellitengestützte erfassung von schnittterminen im grünland und feldfutterbau		Grünlanderträge werden momentan im Gegensatz zu anderen landwirtschaftlichen Produkten nur grob an Hand weniger Versuchsergebnisse und Erhebungen abgeschätzt. Wichtige Hinweise zu Ertragshöhe liefern die Zahl der Schnitte der Grünlandaufwüchse in Verbindung mit Witterungsdaten und der Kenntnis der regionalen Bestandstypen. Ziel dieser Studie ist eine automatisierte Erfassung von Schnittterminen auf Basis von Radardaten zu entwickeln. Es wird gezeigt wie durch die deutliche Oberflächenänderung nach Schnitt auf Grünland und Feldfutterbauflächen die satellitengestützte Feststellung der Schnitte auf landwirtschaftlichen Flächen realisiert werden kann. Die Ergebnisse können in Kombination mit einem an regionale Verhältnisse angepassten Ertragsmodell als Grundlage für eine personaleffiziente, exakte und regionalisierte Ertragsschätzung von Grünland und Feldfutterbaubeständen dienen.	aldert van der ziel;eine and zwei;internet explorer	Kerstin Grant;Melanie Wagner;Robert Siegmund;Stephan Hartmann	2015				OS	-104.68864135900176	32.611243107331234	193251
34234736bfa57658ee85ccbc4c168020f0fc6a69	die fortschreibung der ethischen leitlinien der gi		Die derzeitige Fassung der Ethischen Leitlinien der GI wurde am 13.01.1994 vom Präsidium verabschiedet und am 16.12.1994 von den Mitgliedern bestätigt. Seitdem werden die Leitlinien sowie allgemeine Fragen der Verantwortung für das informatische Handeln sowohl innerhalb der GI als auch im Rahmen bspw. der angewandten und der Technikethik diskutiert – zuweilen recht kontrovers. Gleichzeitig enthalten die Ethischen Leitlinien die Forderung einer stetigen Fortschreibung, damit sie den sich ändernden Arbeitsbedingungen im Umfeld der Informationsund Kommunikationstechnologie ständig angepasst werden. Um diese Forderung zu erfüllen und die dabei in der Fachdiskussion aufgeworfenen Fragen und die bisher geäußerte Kritik aufzunehmen, trat am 24.11.2001 ein neuer Arbeitskreis „Informatik und Verantwortung“ im Auftrag des Präsidiums zusammen, um die Ethischen Leitlinien zu überarbeiten. Das Ergebnis dieser Überarbeitung wird anlässlich der Informatik 2003 präsentiert und diskutiert.	sie (file format);triple des;unified model	Karl-Heinz Rödiger;Karsten Weber	2003				AI	-104.4181548882294	33.368286939254354	193371
b237204fe8f8a588e90845da31369e7a87487e2a	die österreichischen beiträge bei der cired 2013		Die Versorgungszuverlässigkeit bezieht sich auf Unterbrechungen der Versorgung von elektrischer Energie und kann in unterschiedlichen Formen ausgedrückt/ermittelt werden. Die dafür meist genutzten Indikatoren sind die Anzahl von Unterbrechungen und die Nichtverfügbarkeit (unterbrochene Zeit) pro Jahr, welche auch häufig als Qualitätselement/-komponente in Anreizregulierungsmodellen Anwendung finden, um das Qualitätsniveau in den Netzen in angemessener Weise auszubauen bzw. zu erhalten. In den meisten Ländern (15 von 26) gibt es bereits Qualitätsregulierung – sechs weitere Länder stehen unmittelbar davor, diese einzuführen. Die Erhebung zeigt, dass in allen Ländern Unterbrechungen gemessen und überwacht werden und, dass in den meisten Ländern auch alle Spannungsebenen Berücksichtigung finden und sehr viele Länder auch alle Unterbrechungen (einschließlich kurzer Unterbrechungen) einbeziehen. Jedoch gibt es noch immer eine Vielzahl unterschiedlicher Kennzahlen und Gewichtungsmethoden. Die einheitliche Erfassung aller Unterbrechungen auf allen Spannungsebenen sowie eine Fortführung der Vereinheitlichung der Gewichtungsmethoden werden demnach auch als Empfehlung abgeleitet. Weiters wird gezeigt, dass in mehr als der Hälfte der Länder die Ausfallszeiten zurückgehen und speziell in jenen Ländern mit bereits sehr niedrigen Werten das Niveau ähnlich bleibt. Es werden auch mögliche Korrelationen von z. B. Bevölkerungsdichte und Anteil von Verkabelungen in Bezug auf die Versorgungszuverlässigkeit analysiert und aufgezeigt.	die (integrated circuit);eine and zwei;unified model	Martin J. Lin-dinger;Christian Raunig;Ernst Schmautzer;Lothar Fickert;G. F. Bartak;Hendrik Vennegeerts;Gerhard Feske	2013	Elektrotechnik und Informationstechnik	10.1007/s00502-013-0183-8		OS	-104.64081301045614	32.79798814107276	193703
0ead36b2bc03ecb9de2ddf5e5e46e8f80c1e8298	die bestimmung kürzester pfade in graphen und passende datenstrukturen		Indem wir geeignete Datenstrukturen verwenden, lösen wir ein Buchhaltungsproblem, das bei der Bestimmung kürzester Pfade auftritt. Dadurch werden auch die Unterschiede zwischen den klassischen Verfahren vonMoore und vonDijkstra abgebaut. Außerdem wird eine Möglichkeit betrachtet, wie der Rechenaufwand durch Informationen über den Zielpunkt reduziert werden kann. By using appropriate data structures we solve a bookkeeping problem that arises when determining the shortest path in a net. At the same time the difference between the classical algorithms byMoore andDijkstra is diminished. Besides that we present a way how the computing effort can be reduced when information about the end point is available.	algorithm;data structure;eine and zwei;internet explorer;shortest path problem	Dietrich Braess	1971	Computing	10.1007/BF02234053	mathematics;mathematical analysis;algorithm	Theory	-97.20074816653838	35.64337491391788	193741
ec07a1ff3ed19ad7de6ab4f9ab20417b184efb4e	ein neues bildaufnahmesystem für die konventionelle lichtmikroskopie	konventionelle lichtmikroskopie;ein neues bildaufnahmesystem	Seit der Einfuhrung der konfokalen Mikroskopie hat sich in der Entwicklung der optischen Mikropskopie wenig getan. Doch durch die Verbindung von konventioneller Lichtmikropskopie, Video- und Computertechnik konnen neue interessante Applikationsfelder eroffnet werden. So konnen zum Beispiel die physikalischen Grenzen der Scharfentiefe, die durch die Numerische Apertur gegeben sind, durchbrochen werden und Bilder konnen erzeugt werden, die so im Okular nicht sichtbar sind. Auch ist es moglich durch digitale Kontrastverstarkung Objekte mit schwachem Kontrast darzustellen. Durch Langzeitintegration konnen Farbfluoreszenz (fur z.B. fluorescence in situ hybridization, FISH) und Wachstumsprozesse durch Zeitsteuerungen sichtbar gemacht werden. Und letztlich konnen durch Bildbearbeitung sehr hochauflosende Bilder aus kleineren Einzelbildern erzeugt werden.		Volker Tympel	1996			art;molecular biology	NLP	-106.55076788149854	33.046430002008904	194086
8a00ff702d402d8b67d1ec6a25e3928d6dee7596	ein ansatz zur einführung von complex event processing zum workfloworientierten software-monitoring.		In vollautomatisierten Geschäftsworkflows sollte nicht nur die Ausführung, sondern auch die Überwachung der ausführenden Software automatisiert ablaufen. Bei dieser Überwachung bleiben meist diejenigen Ausfälle unberücksichtigt, bei denen die jeweilige Software zwar noch als aktiver Prozess läuft und Ressourcen beansprucht, aber nicht mehr dem eigentlichen Zweck nachgeht. Ein solcher Ausfall wird erst deutlich, wenn man den gesamten Workflow betrachtet. Im vorliegenden Beitrag wird anhand des Auftragseingangsprozesses eines Unternehmens aus der Fleischwarenindustrie eine Möglichkeit vorgestellt, diese Art von Ausfällen mittels Complex Event Processing (CEP) zu erkennen. Dabei wird die Zielsetzung verfolgt, ein ressourcensparendes Echtzeit-Verfügbarkeits-Monitoring für den Auftragseingangsworkflow zu schaffen.	complex event processing;eine and zwei	Sebastian Niehaus	2016			software;theoretical computer science;ansatz;complex event processing;computer science	OS	-102.50078425715462	32.510600297656374	194093
5d8f4cac609c3bc1c2145f1c5f509c039dabc2c3	vom name-server zum trader		Ein neuartiger Basisdienst in verteilten Systemen gewinnt in den letzten Jahren zunehmend an Bedeutung: der Trading-Dienst Er erweitert herkömmliche Client-ServerModelle dahingehend, daß eine zumeist zusätzliche Instanz, der Trader, die Verwaltung der im verteilten System verfügbaren Dienste übernimmt und als Vermittler bei Dienstanfragen von Clients geeignete Server auswählt. Der vorliegende Beitrag gibt eine Übersicht über aktuelle Entwicklungen im Bereich Trading in verteilten Systemen. Er stellt das Basismodell eines Traders vor und setzt sich mit der damit verbundenen Problematik sowie Lösungsansätze auseinander. Desweiteren wird im Beitrag auf die Querverbindungen zu dem verwandten Gebiet des Naming eingegangen. Schließlich werden einige Systeme, die den Trading-Dienst einsetzen, beschrieben und miteinander verglichen. Schlüsselwörter: Trading, Client-Server-Modell, Client-Service-Modell, Verteilte Systeme, Verteilte Anwendungen, Name-Server, Fehlertoleranz	eine and zwei;institut für dokumentologie und editorik;trader media east;traders;v-model;vhf omnidirectional range	Ludwig Keller	1993	Praxis der Informationsverarbeitung und Kommunikation	10.1515/piko.1993.16.3.122	computer science;world wide web;name server;distributed computing	OS	-104.04408870015536	36.01688627185031	194269
8295501a7a2a15d52e25cc192aeee68662170c66	fachkunde des datenschutzbeauftragten		Voraussetzung der Bestellung eines betrieblichen Datenschutzbeauftragten durch die verantwortliche Stelle ist, dass er die „zur Erfüllung seiner Aufgaben erforderliche Fachkunde“ besitzt (§ 4 f Abs. 2 Satz 1 BDSG). Ist der Beauftragte bestellt, dann ist er „in Ausübung seiner Fachkunde auf dem Gebiet des Datenschutzes“ weisungsfrei (§ 4 f Abs. 3 Satz 2 BDSG). Seine Qualifizierung muss ihn also befähigen, fachlich eigenverantwortliche Entscheidungen zu fällen. Die Bedeutung der Fachkunde des Beauftragten wird dadurch unterstrichen, dass er von der Aufsichtsbehörde abberufen werden kann, „wenn er die zur Erfüllung seiner Aufgaben erforderliche Fachkunde“ nicht besitzt (§ 38 Abs. 5 Satz 3 BDSG). Welche Fachkunde als Voraussetzung seiner Bestellung erforderlich ist, ist funktional aus seinen gesetzlichen Aufgaben zu bestimmen.		Johann Bizer	2006	Datenschutz und Datensicherheit - DuD	10.1007/s11623-006-0069-6	computer security;internet privacy;computer science	Crypto	-103.85497910008964	36.24533735836156	194569
efb1d5c1e0df340d4f221decf595a1518fa6a91c	das geo-informationssystem sicad - anwendungen im umweltbereich	das geo-informationssystem sicad;anwendungen im umweltbereich	Geo-Informationssysteme werden heute in vielen Bereichen eingesetzt; z. B. im Vermessungswesen, bei Energieversorgungsunternehmen, in der Stadtplanung und der Wissenschaft und Forschung. Im letzten Jahrzehnt hat sich ein neues Anwendungsfeld fur den Einsatz von Geo-Informationssystemen gebildet: der Umweltbereich. Es hat sich gezeigt, das gerade dieser Bereich nicht auf eine fachspezifische Anwendung ausgerichtet ist, sondern das vielmehr fachubergreifende Informationen erfast, analysiert und dokumentiert werden mussen. Die Fulle der verschiedenen Daten, seien es graphische und alphanummerische Daten oder auch Bilddaten, konnen heute nur mit modernen Rechenanlagen gespeichert und verarbeitet werden. Im folgenden soll das Geo-Informationssystem SICAD (R) vorgestellt werden. Seine verschiedenen Ausbaustufen in Hard- und Software ermoglichen einen breiten Einsatz bei umweltbezogenen Fragestellungen. Besondere Schwerpunkte bilden die hybride Graphik, also die Kombination von Vektor- und Rasterdaten, und der „Umweltarbeitsplatz“. Mit SICAD kann die wesentliche Komponente eines Umwelt-Informationssystems realisiert werden (Abb.1).	information system	Bernd Sonne;Johann Schellerer	1991			art;performance art	Robotics	-103.74089097179842	33.0356415630334	195229
a378e9be323166516d4e63ee56bae0f309edc006	einsatz einer interaktiven planungssprache beim aufbau eines marketing-informations-systems	information system	Marketing-Informations-Systeme sind durch den Informatiker in Abhangigkeit von Informationsbedurfnissen und -prioritaten der Unternehmen individuell zu gestalten. Prioritaten fur die Entwicklung des Systems, Aggregationsgrad und Aktualitat der Information sind abhangig von Produkt, Branche und Wettbewerbsverhaltnissen.		M. Heidötting	1980		10.1007/978-3-642-67953-7_8	information system;computer science;marketing	Robotics	-100.33421958076202	32.97152621105466	195243
8d4672ed075ca3ead0c4ede05e57626c32996cb3	einsatz eines sicherheitsmusters zur absicherung einer mobilen wissensmanagementlösung		Zusammenfassung: Der Einsatz mobiler IuK-Technologien führt zu Effektivitätsund Effizienzsteigerungen im Wissensmanagement. Die vorgestellte mobile Wissensmanagementlösung (U-Know) nutzt diese neuen Möglichkeiten. Jedoch vergrößert der Einsatz der innovativen Technologien auch die Gefahr, dass Unbefugte leichter an sensible Daten gelangen. Eine Bedrohungsanalyse identifizierte potenzielle Schwachstellen von U-Know. Das Auffinden von geeigneten Sicherheitsmaßnahmen wird anhand von Sicherheitsmustern gezeigt. Es wurden mehrere sinnvoll einzusetzende Sicherheitsmuster erkannt. Die Musterbeschreibung ermöglicht die Realisierung von Maßnahmen, die in ihrer Qualität dem Stand der Technik entsprechen, da sie auf erprobten Lösungsansätzen von Experten basieren. Abschließend wird die um Sicherheitsmaßnahmen erweiterte Systemarchitektur von U-Know vorgestellt.	eine and zwei;sie (file format);unified model;zur farbenlehre	Stefan Berger;Jens Ingo Mehlau	2003					-105.13426936187886	32.85427635582248	195945
02473682d634ec4055196dc7491c53a4e78b804a	"""der """"digital signature standard"""": aufwand, implementierung und sicherheit"""	digital signature standard	"""Mit der Veröffentlichung des Entwurfs für einen """"Digital Signature Standard"""" (DSS) durch NIST im Herbst 1991 wurde erstmalig für ein kryptographisches Verfahren zur Erzeugung elektronischer Unterschriften eine Standardisierung eingeleitet. Nach einer Erläuterung des DSSSignierund Testalgorithmus' werden effiziente Algorithmen für eine Software-Implementierung der im DSS-Verfahren benötigten modularen Langzahl-Exponentiation betrachtet. Es folgen Vorschläge für eine schnelle Version der DSS-Algorithmen it Vorausberechnungen. Aufwandsabschätzungen und Messungen einer Implementierung für 80x86-Mikroprozessoren des DSSund des RSA-Verfahrens werden verglichen. Die Darstellung schließt mit Betrachtungen zur Sicherheit des DSS-Verfahrens auf der Grundlage der aktuellen Diskussion."""	digital signature;eine and zwei;exponentiation by squaring;gesellschaft für informatik;institut für dokumentologie und editorik;rsa conference	Dirk Fox	1993				Crypto	-103.50528645696794	35.66673595493372	195954
36014953dc2c6fcfb68aba849580d18a1cac141f	studienfachübergreifende lehre im fach werkstofftechnik an der htw berlin - ein praxisbeispiel		Seit dem Wintersemester 2012/13 werden an der HTW Berlin die Lehrinhalte des Grundlagenfaches Werkstofftechnik des Studienganges Maschinenbau in eigenständige MikroLehr/-Lernmodule (also in Themenkomplexe, die nicht aufeinander aufbauen) „zerlegt“ und den Studierenden auf der Lernplattform moodle zur Verfügung gestellt. Basis des Präsenzunterrichts ist das moderne Lehrformat des sog. „Design-led-approaches“ [MAT13]. Gelehrt wird hierbei nicht in klassischer Weise vom „Atom bis zum Bauteil“ sondern im sog. Blended-Learning werden ausgewählte Bauteile vorgestellt, die Werkstoffe identifiziert, deren Eigenschaften erläutert und die wissenschaftlichen Hintergründe in projektbasierter Arbeit erforscht. Dieses Konzept und die Qualität der Arbeitsmaterialien beruht auf einer starken Einbeziehung der Studierenden bei der Entwicklung sowie Erstellung von Lehr-/Lernmaterialien, wie z.B. WBTs, moodle-Lektionen, Tests, auf den Unterrichtsinhalt zugeschnittene Lehrfilme uvm. Ziel des Projekts ist es, den Kurs „Werkstofftechnik“ HTW-weit zur Verfügung zu stellen, so dass die Inhalte von interessierten Lehrenden aller Studiengänge zentral abgerufen und individuell zugeschnitten und eingesetzt werden können.	atom (standard);citeseerx;die (integrated circuit);fach;internet explorer	Anja Pfennig;Astrid Böge	2015			performance art;art	Crypto	-105.10741464136079	33.39849645586066	195972
eab18f916993842846b7414a00774327456ef411	zur modellierung von prozessystemen	dar sich die prozesse bel ihrer arbeit unterst~tzen;bei koexistenzfragen wird dagegen das pro- blem der gegenseitigen behinderung behandelt;zur modellierung von prozessystemen;f~r kooperation ist es charakteristisch	Umweltfragen und -aufgaben begegnen uns im Alltag auf Schritt und Tritt. Damit gehen Aspekte einher, die naturoder technikwissenschaftliche Methoden, andere, die geistesund sozialwissenschaftliche Ansätze betreffen. Die Carolo-Wilhelmina bietet in jedem Semester eine Vielzahl von Veranstaltungen quer durch alle Fachbereiche, quer durch wissenschaftliche Traditionen, die manchmal unterschiedlicher nicht sein könnten. Wer sich den komplexen ökologischen Aufgaben wirklich stellen will, muss über die Grenzen der eigenen Disziplin hinausschauen und fächerübergreifend arbeiten. Gerade darin liegt die Chance zu wirklich innovativen Lösungswegen.	eine and zwei;parity (physics);word error rate	Alfons J. Jammel	1973		10.1007/3-540-06473-7_22		AI	-106.12886629892625	33.04423365186469	196112
5274cf5c0b69a8e7578a29c40a4cce06fe4e14e3	zukunft der web-pki?		Seit fast 20 Jahren wird PKI im öffentlichen Internet eingesetzt, oft in Kombination mit TLS. Schwachstellen und Angriffe haben gezeigt, dass die alten Konzepte mit ihrem Ursprung in den frühen neunziger Jahren nicht ausreichen. Es gibt einige Ansätze, die als Ergänzung zur klassischen PKI und TLS für mehr Sicherheit sorgen können.	institut für dokumentologie und editorik;internet explorer;public key infrastructure;transport layer security	Jürgen Brauckmann	2014	Datenschutz und Datensicherheit - DuD	10.1007/s11623-014-0205-7	internet privacy;computer science;the internet;public key infrastructure	Metrics	-103.74932296348835	36.70825094375033	196193
b19b9b8ad89718ce0680bb52ed995dfe8d1e1675	charakterisierung der farbeigenschaften melanozytärer hautveränderungen zur unterstützung der früherkennung des malignen melanoms		Beste Chancen zur Heilung des malignen Melanoms bestehen bei fruhzeitiger Erkennung. Die morphologische Vielfalt, auch gutartiger melanozytarer Hautveranderungen, erschwert die Diagnose. Hilfe verspricht die Dermatoskopie und die dazugehorige dermatoskopische ABCD-Regel, die die Merkmale Asymmetrie, Berandung, Farbvielfalt und Differentialstrukturen semiquantitativ bewertet. Durch Einsatz digitaler Bildverarbeitung sollen diese Kriterien quantitativ, objektiviert, reproduzierbar und nachvollziehbar zur Unterstutzung des Dermatologen bewertet werden. In diesem Beitrag wird die Quantifizierung der Farbeigenschaften detailliert beschrieben. Diese lassen sich durch die Farbvielfalt, die Farbhomogenitat innerhalb der Lasion und die farbliche Symmetrie bezuglich der Lasionsachsen beschreiben.		R. Pompl;Wolfram Bunk;Dominik R. Dersch;Alexander Horsch;Wilhelm Stolz;W. Abmayr;Wilfried Brauer;A. Gläßl;R. Schiffner;Gregor Morfill	1999				Crypto	-104.74914741104534	32.50275101990405	196798
2cf6044f6e2a999084012d016c36a9336a93cd37	datenschutz und identitätsmanagement für communities - communities für datenschutz und identitätsmanagement		Damit verbunden sind jedoch auch Datenschutzrisiken, bedingt durch den übergreifenden Austausch von Identitätsinformationen oder durch die zentralisierte Datenverarbeitung bei den Anbietern. Die Implementierung datenschutzgerechter Technologien hat nicht mit der schnellen Verbreitung der Community-Infrastrukturen Schritt gehalten. Andererseits können Communities aber auch Effekte für einen verbesserten Datenschutz mit sich bringen. So zeigt sich beispielsweise, dass viele erfolgreiche Datenschutztechnologien von Communities engagierter Nutzer getragen werden. Diese schließen sich oft aus ideellen Gründen zusammen, um gemeinsam zu einem besseren Datenschutz im Internet beizutragen.	internet explorer;unified model	Jan Zibuschka;Lexi Pimenidis;Marit Hansen;Heiko Rossnagel	2011				ML	-103.96711791545079	36.722375856494374	196875
af8958413e9bdbf93c56be55db16624b5c627aa7	formative evaluation einer situierten e-learning-umgebung in der betrieblichen bildung	situated instruction;training;trouble shooting;betriebliches lernen;e learning;situiertes lernen;technische storungsdiagnose;organizational e learning;formative evaluation	Zusammenfassung. Zum betrieblichen E-Learning gibt es wenige theoriegeleitet entwickelte und evaluierte Anwendungen. Die Lernumgebung Diagnose-KIT soll den Erwerb und den Transfer von Storungsdiagnosekompetenz an komplexen Produktionsanlagen bei technischem Personal fordern. Der Kern besteht in der Simulation einer teilautomatisierten Fertigungsanlage mit verschiedenen technischen Storungen als Ubungsaufgaben, erganzt durch weitere didaktische Module. Dazu wird uber die theoriegeleitete Entwicklung und Gestaltung der gesamten Lernumgebung auf der Grundlage situierter und problembasierter Instruktionsprinzipien berichtet, in Verbindung mit der formativen Evaluation der simulationsbasierten Aufgabenumgebung. Diagnose-KIT wurde mit dafur entwickelten Skalen hinsichtlich anwendungs- und ergonomiebezogener Kriterien in mehreren Entwicklungsschritten von Auszubildenden und Ausbildern technischer Berufe formativ evaluiert. Die Resultate lassen darauf schliesen, dass die Lernumgebung die Anforderungen an situiert...		Sabine Hochholdinger;Niclas Schaper;Karlheinz Sonntag	2007	Zeitschrift für Medienpsychologie	10.1026/1617-6383.19.3.105	computer science;operating system;troubleshooting;formative assessment	NLP	-107.83517421225267	34.13237379618233	197113
d4562f794e9de44cf329b3e4b83a1699d85b3d3a	xl: eine plattform für web services	web service	Web Services entwickeln sich zu einer beherrschenden Technologie fur betriebliche Informationssysteme. Trotzdem ist die Entwicklung und der Betrieb von Web Services teuer. Grunde sind die Vielzahl von verwendeten Standards und die mangelnde Abstraktion in den verwendeten Entwicklungsund Programmiermodellen. Dieser Vortrag stellt XL vor. XL baut auf den wichtigsten Standards auf, bundelt sie, bietet eine komfortable und intuitive Programmierschnittstelle und ermoglicht automatische Optimierungen fur den effizienten Betrieb. WebDB Web Databases	eine and zwei;web service	Donald Kossmann	2003			world wide web;business;web service	ML	-102.46256503827574	34.55056307043879	197370
c9c251c979a556f85d2e2f099eb9353c2a37f04f	datenschutz bei lernsoftware		Der Wandel in Kommunikation und Informationsbeschaffung hat auch vor Schulen nicht halt gemacht. Das Lernen mit modernen Medien ist inzwischen notwendiger Bestandteil jeder Schulausbildung geworden. Der folgende Beitrag gibt einen Überblick über die Möglichkeiten der Nutzung von Lernsoftware im Internet und zeigt die damit verbundenen datenschutzrechtlichen Probleme auf.	halting problem;vhf omnidirectional range	Britta Alexandra Mester;Sabine Seifert	2011	Datenschutz und Datensicherheit - DuD	10.1007/s11623-011-0207-7	computer science;internet privacy;the internet	ML	-104.00689340940674	36.52425315640064	197414
41b6bc2d442250256256c7da294506d5a7be457c	a combinatorial method for the generation of normally distributed random numbers	exponential distribution;normal distribution;random numbers	The proposed method generates standard normal variablesx. In 84.27% of all cases sampling from the centre $$(|x| \leqslant \sqrt 2 )$$ of the normal distribution is carried out using a variant ofJ. v. Neumann's algorithm for the generation of exponentially distributed random numbers. For sampling from the tails $$(|x| > \sqrt 2 )$$ the same method byJ. v. Neumann is combined with an acceptance-rejection approach ofG. Marsaglia. Die Methode erzeugt Zufallszahlen der standardisierten Normalverteilung. Für das Zentrum $$|x| \leqslant \sqrt 2 $$ (84,27% aller Fälle) wird eine Variante des v.Neumannschen Vergleichsverfahrens zur Erzeugung exponentialverteilter Zufallszahlen vorgeschlagen. Für die Werte $$|x| > \sqrt 2 $$ der Normalverteilung wird eine Verwerfungsmethode vonG. Marsaglia verwendet, bei der die majorisierende Funktion die Exponentialfunktion ist. Die dafür benötigten exponential-verteilten Zufallszahlen werden durch die ursprüngliche v.Neumann'sche Methode erzeugt.	algorithm;eine and zwei;rejection sampling;sampling (signal processing);tails;time complexity	Ulrich Dieter;Joachim H. Ahrens	1973	Computing	10.1007/BF02252903	normal distribution;exponential distribution;mathematical optimization;combinatorics;discrete mathematics;mathematics	AI	-97.26982721622258	37.081478569052564	197691
06be89d4ef49e0c0b0281dee51ce5ef3cd6b3b9d	effektives customer relationship management durch intermediation	customer relationship management;000 computer science knowledge systems;330 economics;650 management public relations;information management	Bestehende Modelle im Customer Relationship Management (CRM) weisen diverse Schwachstellen auf. Erstens sind viele Kunden durch die grose zu verarbeitende Informationsmenge uberfordert, zweitens gelingt es vielen Anbietern nicht, die Konsistenz und Relevanz der gesammelten Kundendaten zu gewahrleisten, und drittens bringen Kunden den Anbietern nicht das Vertrauen entgegen, das fur eine umfassendere Offenlegung von Kundendaten erforderlich ware. Durch die Einschaltung eines Intermediars konnen diese Schwachstellen gemildert werden. Zusatzlich bietet die Intermediation die Moglichkeit, Transaktionskosten zu senken, die Macht der Kunden zu bundeln und die Beziehungen zu Kunden zu intensivieren. Ermoglicht wird dies durch die engere Verknupfung der Kommunikations- und der Einkaufsfunktionalitaten des Internets. Als Erfolgsfaktoren gilt es, die kritische Masse und das erforderliche Vertrauen zu erreichen sowie einen wesentlichen Beitrag zur Wertschopfung zu leisten.	customer relationship management	Martin Böhlen;Reinhard Jung	2006	HMD - Praxis Wirtschaftsinform.		computer science;knowledge management;electrical engineering;marketing;information management	AI	-101.15101683099421	34.64974436262412	198483
13b96b9cc61d7c743db3ef9e9f7a9359149c2da1	merkmalsextraktion aus audiodaten evolutionäre aufzucht von methodenbäumen		Musikstucke konnen als Zeitreihen variabler Lange aufgefasst werden. Im Falle der Musikdaten ist die typische Lernaufgabe die Klassifikation bzw. die Suche nach ahnlichen Reihen.		Ingo Mierswa;Katharina Morik	2005	Informatik-Spektrum	10.1007/s00287-005-0015-2	world wide web;software engineering;computer science	DB	-102.64755237273582	32.66748231197128	198625
b4b6eaaf5f8928672d16e317bfdfc7edf4c5263d	das recht des forschers auf datenschutz		Die Praxis des forschenden Wissenschaftlers ist zunehmend digitalisiert. Seine Arbeit und deren Ergebnisse werden von elektronischen Laborbüchern und Laborinformationssystemen (automatisiert) elektronisch erfasst und dokumentiert. Wie ist das datenschutzrechtlich zu bewerten? Das Grundrecht auf Wissenschaftsfreiheit wird ohne Gesetzesvorbehalt gewährleistet. Bietet es dem Wissenschaftler für seine eigenen personenbezogenen Daten einen größeren Schutz als das Datenschutzrecht?	altran praxis;internet explorer	Paul C. Johannes	2012	Datenschutz und Datensicherheit - DuD	10.1007/s11623-012-0279-z	internet privacy;computer science;library science	Crypto	-103.6061807646998	36.044366484382756	199278
2aa9be85f05bb8350be1f4623cea74c2af14bcdf	ein adressierungskonzept zur unterstützung der objekt-orientierten verarbeitung in prima		PRIMA (Prototyp-Implementierung des Molekul-Atom-Datenmodells) bildet den Kern eines Non-Standard-Datenbanksystems (NDBS) /Mi84/, der an seiner Schnittstelle mit dem Molekul-Atom-Datenmodell (MAD-Modell /Mi87/) ein allgemeines, an die Anforderungen der neuen Anwendungen aus Buro, Technik und Wissenschaften angepastes Datenmodell zur Verfugung stellt. Kennzeichnend fur dieses Datenmodell ist die Moglichkeit, komplexe Objekte („Molekule“), die dynamisch aus Elementar-bausteinen („Atomen“) aufgebaut werden konnen, auf eine einfache Art und Weise zu verarbeiten. Eine der wesentlichen Anforderungen an PRIMA ist damit eine effiziente Unterstutzung dieser dynamischen Molekulbildung. Dieser Anforderung wird vor allem durch ein geeignetes Architekturkonzept Rechnung getragen, das fur das gesamte NDBS zu einem 7-Schichten-Modell fuhrt /HR85/. Fur die Betrachtung des Adressierungskonzepts genugt jedoch eine grobe Dreiteilung von PRIMA in das Datensystem, das Zugriffssystem und das Speichersystem (Bild 1).		Andrea Sikeler	1987		10.1007/978-3-642-72617-0_50		Crypto	-105.04645052276533	32.445470934533	199593
db77c2cbd66e25aaa9af7584d464abed53225200	sprachanalyse, metadaten, social navigation - semantik-konzepte im wandel		Die automatisierte Erschließung von Bedeutung stellt ein Grundproblem in der Geschichte der Informatik dar. Entwickelte die KI-Forschung hierzu eine Vorgehensweise, die sich auf die Inhaltsanalyse von Texten konzentrierte, so greifen die gegenwärtigen Projekte im Bereich des Semantic Web auf manuelle Kategorisierungsverfahren zurück. Als Alternative zu diesen beiden Ansätzen möchte der vorliegende Artikel eine weitere Sicht auf Semantik anbieten, die die tatsächlichen Aktivitäten des Benutzers mit einbezieht und davon ausgeht, dass Bedeutung vornehmlich als ein Kondensat aus Suchoder Navigationsprozessen hervorgeht. Konkrete Möglichkeiten zur Strukturbeobachtung bieten hier einerseits das Konzept der Social Navigation, andererseits die Suchmaschinen.	binary prefix;die (integrated circuit);eine and zwei;list of concept- and mind-mapping software;semantic web	Sabrina Geißler	2003	EMISA Forum		systems engineering;engineering drawing;social navigation;computer science	AI	-106.56578828750249	35.28623065320034	199952
