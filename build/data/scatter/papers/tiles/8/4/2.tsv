id	title	keywords	abstract	entities	authors	year	journal	doi	fos	area	x	y	ix
bb22458875ec36db43844feffe66ac8b25f84500	scut: multi-class imbalanced data classification using smote and cluster-based undersampling		Class imbalance is a crucial problem in machine learning and occurs in many domains. Specifically, the two-class problem has received interest from researchers in recent years, leading to solutions for oil spill detection, tumour discovery and fraudulent credit card detection, amongst others. However, handling class imbalance in datasets that contains multiple classes, with varying degree of imbalance, has received limited attention. In such a multi-class imbalanced dataset, the classification model tends to favour the majority classes and incorrectly classify instances from the minority classes as belonging to the majority classes, leading to poor predictive accuracies. Further, there is a need to handle both the imbalances between classes as well as address the selection of examples within a class (i.e. the so-called within class imbalance). In this paper, we propose the SCUT hybrid sampling method, which is used to balance the number of training examples in such a multi-class setting. Our SCUT approach oversamples minority class examples through the generation of synthetic examples and employs cluster analysis in order to undersample majority classes. In addition, it handles both within-class and between-class imbalance. Our experimental results against a number of multi-class problems show that, when the SCUT method is used for pre-processing the data before classification, we obtain highly accurate models that compare favourably to the state-of-the-art.	cluster analysis;complexity class;computer cluster;expectation–maximization algorithm;machine learning;mixture model;oversampling;preprocessor;sampling (signal processing);synthetic intelligence;type class;undersampling	Astha Agrawal;Herna L. Viktor;Eric Paquet	2015	2015 7th International Joint Conference on Knowledge Discovery, Knowledge Engineering and Knowledge Management (IC3K)		oversampling;biological classification;computer science;machine learning;pattern recognition;data mining;cluster analysis;undersampling;statistics	ML	14.214386881108382	-41.58228922838391	13081
0382fc76152e9b21ad66cb2fdfabeb5e2a449832	new dynamic clustering approaches within belief function framework	uncertainty;belief clustering;dynamic clustering;cluster separation;transferable belief model tbm;cluster cohesion	Recently, dynamic clustering has attracted significant attention and has been considered as a challenging task in unsupervised classification. However, most existing approaches assume that all classification parameters are certain. Unfortunately, the reality is connected to uncertainty by nature. To solve these problems, we propose in this paper new dynamic clustering approaches, based on the well known K-modes method, under uncertainty for handling both increasing and decreasing of the clusters’ number where uncertain categorical attribute values are represented and managed through the Transferable Belief Model (TBM) concepts. By using the cluster cohesion and separation concepts, our main objective is to update the clusters’ partition without performing the reclustering from scratch. The experiments on known benchmark data sets, show that our dynamic methods outperform the static version.	benchmark (computing);cluster analysis;experiment;unsupervised learning;whole earth 'lectronic link	Sarra Ben Hariz;Zied Elouedi	2014	Intell. Data Anal.	10.3233/IDA-140648	correlation clustering;uncertainty;fuzzy clustering;artificial intelligence;machine learning;data mining;mathematics;cluster analysis;statistics	AI	1.1357522493078234	-39.771697185205234	13137
5020ba7489d8453952c61f863af6dda91ad10bb9	supervised probabilistic principal component analysis	learning algorithm;probabilistic principal component analysis;information retrieval;projection method;data mining;semi supervised projection;dimensionality reduction;multi task learning;principal component analysis;supervised projection;pattern recognition;dimensional reduction	Principal component analysis (PCA) has been extensively applied in data mining, pattern recognition and information retrieval for unsupervised dimensionality reduction. When labels of data are available, e.g., in a classification or regression task, PCA is however not able to use this information. The problem is more interesting if only part of the input data are labeled, i.e., in a semi-supervised setting. In this paper we propose a supervised PCA model called SPPCA and a semi-supervised PCA model called S2PPCA, both of which are extensions of a probabilistic PCA model. The proposed models are able to incorporate the label information into the projection phase, and can naturally handle multiple outputs (i.e., in multi-task learning problems). We derive an efficient EM learning algorithm for both models, and also provide theoretical justifications of the model behaviors. SPPCA and S2PPCA are compared with other supervised projection methods on various learning tasks, and show not only promising performance but also good scalability.	algorithm;computer multitasking;data mining;dimensionality reduction;information retrieval;multi-task learning;pattern recognition;principal component analysis;scalability;semi-supervised learning;semiconductor industry	Shipeng Yu;Kai Yu;Volker Tresp;Hans-Peter Kriegel;Mingrui Wu	2006		10.1145/1150402.1150454	semi-supervised learning;multi-task learning;sparse pca;computer science;machine learning;pattern recognition;data mining;projection method;dimensionality reduction;principal component analysis	ML	22.843585566676808	-43.77265011225188	13139
96b93790d96570e6bc687af63962553d72e2694c	a review of some bayesian belief network structure learning algorithms	structure learning;belief networks;machine learning algorithms;urinary system diseases;bayesian methods;size measurement;inference mechanisms;hepatitis domain diseases;bayesian method;model complexity;learning artificial intelligence belief networks inference mechanisms;learning systems;learning system;machine learning;bayesian belief network;diseases;graphical model;diseases bayesian methods inference algorithms learning systems size measurement machine learning algorithms;inference algorithms;learning artificial intelligence;decision making bayesian belief network structure learning algorithms graphical models machine learning bbn structures;hepatitis domain diseases bayesian belief network structure learning urinary system diseases	Bayesian Belief Networks (BBNs) are useful in modeling complex situations. Such graphical models help in giving better insight and understanding of the situation. Many algorithms for machine learning of BBN structures have been developed. In this paper six different algorithms have been reviewed by constructing BBN structures for two different datasets using various algorithms. Some inferences have been drawn from the results obtained from the study which may help in decision making.	algorithm;bayesian information criterion;bayesian network;graphical model;machine learning;performance evaluation;subject-matter expert	Sangeeta Mittal;Shankar Lall Maskara	2011	2011 8th International Conference on Information, Communications & Signal Processing	10.1109/ICICS.2011.6173579	bayesian probability;computer science;artificial intelligence;machine learning;pattern recognition	Robotics	11.563977768396898	-36.20237424989697	13206
39b29e3e9b9f37905d07a51d137108cc351a412c	use correlation coefficients in gaussian process to train stable elm models	gaussian processes;learning machines;artificial neural networks	This paper proposes a new method to train stable extreme learning machines (ELM). The new method, called StaELM, uses correlation coefficients in Gaussian process to measure the similarities between different hidden layer outputs. Different from kernel operations such as linear or RBF kernels to handle hidden layer outputs, using correlation coefficients can quantify the similarity of hidden layer outputs with real numbers in (0, 1] and avoid covariance matrix in Gaussian process to become a singular matrix. Training through Gaussian process results in ELM models insensitive to random initialization and can avoid overfitting. We analyse the rationality of StaELM and show that existing kernel-based ELMs are special cases of StaELM. We used real world datasets to train both regression and classification StaELM models. The experiment results have shown that StaELM models achieved higher accuracies in both regression and classification in comparison with traditional kernel-based ELMs. The StaELM models are more stable with respect to different random initializations and less over-fitting. The training process of StaELM models is also faster.	coefficient;computational complexity theory;elm;gaussian process;kernel (operating system);kriging;overfitting;radial basis function network;rationality	Yu-Lin He;Joshua Zhexue Huang;Xizhao Wang;Rana Aamir Raza	2015		10.1007/978-3-319-18038-0_32	computer science;artificial intelligence;machine learning;pattern recognition;data mining;gaussian process;mathematics;artificial neural network;statistics	ML	13.92809804075321	-39.39742593175648	13231
4e71c82c6cd86511edc8fb3cba9fe53421bb1f60	semi-supervised multitask learning for scene recognition	image recognition;image resolution;manifolds;manifold regularized;manifold data structure semisupervised multitask learning mechanism scene image recognition visual information sparse feature selection based manifold regularization sfsmr;semantics;scene recognition;accuracy;visualization;sparse selection;feature extraction;期刊论文;learning artificial intelligence feature selection image recognition;image resolution semantics image recognition manifolds feature extraction visualization accuracy;sparse selection manifold regularized multitask learning scene recognition;multitask learning	Scene recognition has been widely studied to understand visual information from the level of objects and their relationships. Toward scene recognition, many methods have been proposed. They, however, encounter difficulty to improve the accuracy, mainly due to two limitations: 1) lack of analysis of intrinsic relationships across different scales, say, the initial input and its down-sampled versions and 2) existence of redundant features. This paper develops a semi-supervised learning mechanism to reduce the above two limitations. To address the first limitation, we propose a multitask model to integrate scene images of different resolutions. For the second limitation, we build a model of sparse feature selection-based manifold regularization (SFSMR) to select the optimal information and preserve the underlying manifold structure of data. SFSMR coordinates the advantages of sparse feature selection and manifold regulation. Finally, we link the multitask model and SFSMR, and propose the semi-supervised learning method to reduce the two limitations. Experimental results report the improvements of the accuracy in scene recognition.	computer multitasking;feature selection;manifold regularization;optical character recognition;physical object;redundancy (engineering);semi-supervised learning;semiconductor industry;sparse matrix;supervised learning;version	Xiaoqiang Lu;Xuelong Li;Lichao Mou	2015	IEEE Transactions on Cybernetics	10.1109/TCYB.2014.2362959	multi-task learning;computer vision;visualization;image resolution;manifold;feature extraction;computer science;machine learning;pattern recognition;semantics;accuracy and precision	Vision	24.359754204063258	-44.282530670870386	13233
139118b34a043c3b47d7682bb409de8663f068fa	experiments on the application of iohmms to model financial returns series	conditional hidden markov models;market indices;sequences;financial data processing;volatility;modeles de markov caches;neural nets;multilayer neural networks;transition probability;perforation;hidden markov model;economic forecasting;input variables;hidden markov models sequences biological system modeling multi layer neural network predictive models input variables economic forecasting speech recognition artificial neural networks logistics;biological system modeling;unconditional gaussian distribution;conditional return density;out of sample likelihood iohmm financial returns series input output hidden markov models i o hmm conditional hidden markov models emission probabilities transition probabilities multilayer neural networks financial time series prediction tasks unconditional gaussian distribution conditional linear gaussian distribution mixture conditional return density market indices sector indices;multi layer neural network;input output;series financieres;emission probabilities;artificial neural networks;transition probabilities;hidden markov models;logistics;financial series;financial time series prediction tasks;conditional linear gaussian distribution mixture;financial time series;i o hmm;gaussian distribution financial data processing hidden markov models neural nets generalisation artificial intelligence;speech recognition;financial returns series;volatilite;predictive models;mixture of gaussians;sector indices;generalisation artificial intelligence;input output hidden markov model iohmm;out of sample likelihood;multilayer neural network;gaussian distribution;conditional distribution;iohmm;input output hidden markov models;neural network	Input-output hidden Markov models (IOHMM) are conditional hidden Markov models in which the emission (and possibly the transition) probabilities can be conditioned on an input sequence. For example, these conditional distributions can be linear, logistic, or nonlinear (using for example multilayer neural networks). We compare the generalization performance of several models which are special cases of input-output hidden Markov models on financial time-series prediction tasks: an unconditional Gaussian, a conditional linear Gaussian, a mixture of Gaussians, a mixture of conditional linear Gaussians, a hidden Markov model, and various IOHMMs. The experiments compare these models on predicting the conditional density of returns of market and sector indices. Note that the unconditional Gaussian estimates the first moment with the historical average. The results show that, although for the first moment the historical average gives the best results, for the higher moments, the IOHMMs yielded significantly better performance, as estimated by the out-of-sample likelihood.	algorithm;artificial neural network;bootstrapping (statistics);estimated;experiment;generalization (psychology);generative model;hidden markov model;input/output;markov chain;mixture model;neural network simulation;nonlinear system;normal statistical distribution;p-value;probability;risk management;spatial variability;time series;value at risk;volatility	Yoshua Bengio;Vincent-Philippe Lauzon;Réjean Ducharme	2001	IEEE transactions on neural networks	10.1109/72.896800	normal distribution;conditional probability distribution;input/output;logistics;markov chain;maximum-entropy markov model;volatility;computer science;conditional variance;machine learning;hidden semi-markov model;pattern recognition;mixture model;sequence;mathematics;predictive modelling;markov model;artificial neural network;hidden markov model;statistics;variable-order markov model	ML	22.36082384857926	-25.52675477438132	13255
e2a881c71f79ff443104f319f8cdf2000d441849	relationship between phase and amplitude generalization errors in complex- and real-valued feedforward neural networks		We compare the generalization characteristics of complex-valued and real-valued feedforward neural networks. We assume a task of function approximation with phase shift and/or amplitude change in signals having various coherence. Experiments demonstrate that complex-valued neural networks show smaller generalization error than real-valued networks having doubled input and output neurons in particular when the signals have high coherence, that is, high degree of wave nature. We also investigate the relationship between amplitude and phase errors. It is found in real-valued networks that abrupt change in amplitude is often accompanied by steep change in phase, which is a consequence of local minima in real-valued supervised learning.	amplitude amplification;approximation;artificial neural network;experiment;feedforward neural network;generalization error;in-phase and quadrature components;information processing;input/output;maxima and minima;numerical analysis;supervised learning	Akira Hirose;Shotaro Yoshida	2012	Neural Computing and Applications	10.1007/s00521-012-0960-z	artificial intelligence;machine learning;control theory;mathematics	ML	19.370775175924845	-29.176930406048633	13288
0d2d269f275a7b9e7ac7b753e1672dbb95f5e8a8	reclassification of linearly classified data using constraint databases	database system;classification algorithm;decision tree;linear constraint	In many problems the raw data is already classified according to a variety of features using some linear classification algorithm but needs to be reclassified. We introduce a novel reclassification method that creates new classes by combining in a flexible way the existing classes without requiring access to the raw data. The flexibility is achieved by representing the results of the linear classifications in a linear constraint database and using the full query capabilities of a constraint database system. We implemented this method based on the MLPQ constraint database system. We also tested the method on a data that was already classified using a decision tree algorithm.	algorithm;database;decision tree;experiment;graph coloring;id3 algorithm;linear classifier;list of algorithms;oracle (software testing);support vector machine	Peter Z. Revesz;Thomas Triplet	2008		10.1007/978-3-540-85713-6_17	computer science;machine learning;decision tree;data mining;database	DB	8.736681625904678	-43.69774278130671	13317
5856a4f178d27656beaf03d1c293aab97b175e38	a hybrid model based on mutual information and support vector machine for automatic image annotation		Automatic image annotation (AIA) has been widely studied during recent years and a considerable number of approaches have been proposed. However, the performance of these approaches is still not satisfactory. The main purpose of this paper is to use the feature selection (FS) approach for improving the performance of AIA. The mutual information (MI) is used to measure contribution of each image feature. We introduce a nonlinear factor to evaluation function of the feature selection approach to measure its performance. The experiment results show that proposed AIA approach achieves higher performance than the existing most AIA approaches, its performance is satisfactory.	automatic image annotation;mutual information;support vector machine	Cong Jin;Jinan Liu;Jinglei Guo	2015		10.1007/978-3-319-18476-0_4	machine learning;pattern recognition;data mining;relevance vector machine;automatic image annotation;structured support vector machine	Vision	12.134568989219064	-44.153321794294214	13347
d424376d83b276e60fe57b6a6112084f3424c616	privacy preserving classification with emerging patterns	itemsets;decision tree;information loss;training;data privacy testing decision trees itemsets probability distribution training data classification tree analysis data mining databases conferences;testing;privacy preservation;data mining;randomization based technique;accuracy;data privacy;privacy preserving classification;emerging patterns;pattern classification;centralized database;data sets;decision trees;privacy;privacy preserving data mining;pattern classification data mining data privacy decision trees;data mining privacy preserving classification centralized database randomization based technique emerging patterns decision tree data sets	In privacy preserving classification, when data is stored in a centralized database and distorted using a randomization-based technique, we have information loss and reduced accuracy of classification. This paper presents a new approach to privacy preserving classification for centralized data based on Emerging Patterns. The presented solution gives higher accuracy of classification than a decision tree proposed in the literature, especially for high privacy. Effectiveness of this solution has been tested on real data sets and presented in this paper.	centralized computing;decision tree;lazy evaluation;mathematical optimization;maximal set;privacy;randomized algorithm;test set	Piotr Andruszkiewicz	2009	2009 IEEE International Conference on Data Mining Workshops	10.1109/ICDMW.2009.82	information privacy;computer science;machine learning;decision tree;data mining;database;internet privacy	DB	7.585483614135926	-39.56437119930359	13390
f32af6af9e014339dcfdf3f8ef036a70a8301619	averaging random projection: a fast online solution for large-scale constrained stochastic optimization	optimization problems averaging random projection large scale constrained stochastic optimization fast online solution signal processing online learning network problems incremental constraint averaging projection method icapm;support vector machines;training;training optimization noise support vector machines;incremental constraint projection method stochastic optimization large scale optimization random projection method;会议论文;stochastic processes optimisation signal processing;optimization;noise	Stochastic optimization finds wide application in signal processing, online learning, and network problems, especially problems processing large-scale data. We propose an Incremental Constraint Averaging Projection Method (ICAPM) that is tailored to optimization problems involving a large number of constraints. The ICAPM makes fast updates by taking sample gradients and averaging over random constraint projections. We provide a theoretical convergence and rate of convergence analysis for ICAPM. Our results suggests that averaging random projections significantly improves the stability of the solutions. For numerical tests, we apply the ICAPM to an online classification problem and a network consensus problem.	consensus (computer science);iteration;locality-sensitive hashing;mathematical optimization;numerical analysis;random projection;rate of convergence;sampling (signal processing);signal processing;stochastic gradient descent;stochastic optimization	Jialin Liu;Yuantao Gu;Mengdi Wang	2015	2015 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)	10.1109/ICASSP.2015.7178639	support vector machine;mathematical optimization;computer science;noise;stochastic optimization;machine learning;pattern recognition;mathematics	Vision	24.05776424139838	-34.28079332495153	13423
e2b7f37cd97a7907b1b8a41138721ed06a0b76cd	stacked denoising autoencoders: learning useful representations in a deep network with a local denoising criterion	stacked denoising autoencoders;learning useful representations;deep network;denoising autoencoders;denoising criterion;tractable unsupervised objective;higher level representations learnt;deep belief network;lower classification error;local denoising criterion;ordinary autoencoders;classification problem;performance gap	We explore an original strategy for building deep networks, based on stacking layers of denoising autoencoderswhich are trained locally to denoise corrupted versions of t heir inputs. The resulting algorithm is a straightforward variation on the stacking of ordinary autoencoders. It is however shown on a benchmark of classification problems to yield sign ificantly lower classification error, thus bridging the performance gap with deep belief networks (DBN), and in several cases surpassing it. Higher level representations learnt in this purely u ns pervised fashion also help boost the performance of subsequent SVM classifiers. Qualitative exp eriments show that, contrary to ordinary autoencoders, denoising autoencoders are able to lear n Gabor-like edge detectors from natural image patches and larger stroke detectors from digit images . Thi work clearly establishes the value of using a denoising criterion as a tractable unsupervised o bjective to guide the learning of useful higher level representations.	algorithm;autoencoder;bayesian network;benchmark (computing);bridging (networking);cobham's thesis;deep belief network;deep learning;exptime;edge detection;noise reduction;sensor;stacking;unsupervised learning	Pascal Vincent;Hugo Larochelle;Isabelle Lajoie;Yoshua Bengio;Pierre-Antoine Manzagol	2010	Journal of Machine Learning Research		artificial intelligence;machine learning;pattern recognition;mathematics;statistics	ML	22.43648206515001	-49.54493044924797	13430
0331f57f5a6b5031966a4caf67595bb89fe7de17	synaptic electronics and neuromorphic computing		In order to map the computing architecture and intelligent functions of the human brain on hardware, we need electronic devices that can emulate biological synapses and even neurons, preferably at the physical level. Beginning with the history of neuromorphic computation, in this article, we will briefly review the architecture of the brain and the learning mechanisms responsible for its plasticity. We will also introduce several memristive devices that have been used to implement electronic synapses, presenting some important milestones in this area of research and discussing their advantages, disadvantages, and future prospects.	computation;computer architecture;neuromorphic engineering;synapse	Navnidhi K. Upadhyay;Saumil Joshi;J. Joshua Yang	2016	Science China Information Sciences	10.1007/s11432-016-5565-1	synapse;computer science;artificial intelligence;neuromorphic engineering	ML	7.88903195231894	-24.881054465019886	13440
ef9ae1f58b6955101c0fdbf56fc169b9b69587a1	svm regularizer models on rkhs vs. on r m	kernel hilbert space;representer theorem;classification functions;会议论文;loss functions;newton type algorithms;regularizer;euclidean spaces	There are two types of regularizer for SVM. The most popular one is that the classification function is norm-regularized on a Reproduced Kernel Hilbert Space(RKHS), and another important model is generalized support vector machine(GSVM), in which the coefficients of the classification function is norm-regularized on a Euclidean space R m . In this paper, we analyze the difference between them on computing stability, computational complexity and the efficiency of the Newton-type algorithms. Many typical loss functions are considered. The results show that the model of GSVM has more advantages than the other model. Some experiments support our analysis. © 2012 Springer-Verlag.		Yinli Dong;Shuisheng Zhou	2012		10.1007/978-3-642-31588-6_14	mathematical optimization;mathematical analysis;topology;computer science;machine learning;reproducing kernel hilbert space;mathematics;representer theorem	Vision	24.371683848705132	-39.995865146532566	13446
3cdb02497f66aa57eb9a33ab407105eec78c8a33	a neighbor generation mechanism optimizing neural networks	arquitectura red;algoritmo busqueda;algorithme recherche;multilayer perceptrons;search algorithm;simulated annealing;architecture reseau;resolucion problema;perceptron multicouche;recuit simule;general methods;hybrid system;recocido simulado;tabu search;network architecture;reseau neuronal;random numbers;optimal algorithm;red neuronal;busqueda tabu;recherche tabou;problem solving;resolution probleme;neural network	This paper proposes the utilization of new neighbor generation method in conjunction with search techniques. The proposed mechanism works by adding a random number between -n and +n to the connection weights, where n is the weight value of each respective connection. This value may be multiplied by an adjustable ratio. The present paper shows the results of experiments with three optimization algorithms: simulated annealing, tabu search and hybrid system for the optimization of MLP network architectures and weights. In the context of solving the odor recognition problem in an artificial nose, the proposed mechanism has proven very efficient in finding minimal network architectures with a better generalization performance than the hybrid system mechanism used.	neural networks;optimizing compiler	Amanda Pimentel e Silva Lins;Teresa Bernarda Ludermir	2004		10.1007/978-3-540-30499-9_94	network architecture;simulated annealing;tabu search;computer science;artificial intelligence;machine learning;artificial neural network;algorithm;hybrid system;search algorithm	NLP	14.754698802643652	-25.749887539585234	13492
49afede089121849ca328ee944c0288669549e05	deconstructing binary classifiers in computer vision		This paper further develops the novel notion of deconstructive learning and proposes a practical model for deconstructing a broad class of binary classifiers commonly used in vision applications. Specifically, the problem studied in this paper is: Given an image-based binary classifier C as a black-box oracle, how much can we learn of its internal working by simply querying it? To formulate and answer this question computationally, we propose a novel framework that explicitly identifies and delineates the computer vision and machine learning components, and we propose an effective deconstruction algorithm for deconstructing binary classifiers with the typical two-component design that employ support vector machine or cascade of linear classifiers as their internal feature classifiers. The deconstruction algorithm simultaneously searches over a collection of candidate feature spaces by probing the spaces for the decision boundaries, using the labels provided by the given classifier. In particular, we demonstrate that it is possible to ascertain the type of kernel function used by the classifier and the number of support vectors (and the subspace spanned by the support vectors) using only image queries and ascertain the unknown feature space too. Furthermore, again using only simple image queries, we are able to completely deconstruct OpenCV’s pedestrian detector, ascertain the exact feature used, the type of classifier employed and recover the (almost) exact linear classifier.	algorithm;binary classification;black box;computer vision;feature vector;gadget (computer science);linear classifier;machine learning;opencv;statistical classification;support vector machine;wolfenstein: enemy territory	Mohsen Ali;Jeffrey Ho	2014		10.1007/978-3-319-16811-1_31	computer vision	ML	19.448245668714858	-51.36080349314864	13530
43e4c070200a0d8f1ba0a95dd310d761a1a3e332	efficient inference in phylogenetic indel trees	evolutionary trees;phylogenetic tree;multiple sequence alignment	Accurate and efficient inference in evolutionary trees is a central problem in computational biology. While classical treatments have made unrealistic site independence assumptions, ignoring insertions and deletions, realistic approaches require tracking insertions and deletions along the phylogenetic tree—a challenging and unsolved computational problem. We propose a new ancestry resampling procedure for inference in evolutionary trees. We evaluate our method in two problem domains—multiple sequence alignment and reconstruction of ancestral sequences—and show substantial improvement over the current state of the art.	algorithm;ar (unix);clustalw/clustalx;computational biology;computational problem;discretization;heuristic (computer science);multiple sequence alignment;phylogenetic tree;phylogenetics;problem domain;resampling (statistics)	Alexandre Bouchard-Côté;Michael I. Jordan;Dan Klein	2008			phylogenetic tree;computer science;bioinformatics;computational phylogenetics;phylogenetic network	ML	2.006961741442733	-51.8974858075654	13643
71ccc7555c808761e668406412057da1f8d97dc6	automatic classification of handsegmented image parts with differential evolution	centro gravitacional;differential evolution;base donnee;centre gravite;image processing;search space;center of mass;database;procesamiento imagen;base dato;image classification;average distance;classification;traitement image;classification image;multi class database;error rate;centroids;algorithme evolutionniste;recognition of image parts;algoritmo evolucionista;evolutionary algorithm;classification automatique;automatic classification;clasificacion automatica	Differential Evolution, a version of an Evolutionary Algorithm, is used to perform automatic classification of handsegmented image parts collected in a seven–class database. Our idea is to exploit it to find the positions of the class centroids in the search space such that for any class the average distance of instances belonging to that class from the relative class centroid is minimized. The performance of the resulting best individual is computed in terms of error rate on the testing set. Then, such a performance is compared against those of other ten classification techniques well known in literature. Results show the effectiveness of the approach in solving the classification task.	differential evolution	Ivanoe De Falco;Antonio Della Cioppa;Ernesto Tarantino	2006		10.1007/11732242_36	differential evolution;center of mass;contextual image classification;centroid;image processing;biological classification;word error rate;computer science;artificial intelligence;machine learning;evolutionary algorithm;pattern recognition;database;mathematics;algorithm	Vision	10.742680871747465	-34.40687951408559	13723
6f9bca212f9ec737e8393c389e8ee09e714e3d6f	streamgp: tracking evolving gp ensembles in distributed data streams using fractal dimension	distributed data;concept drift;change detection;genetic program;ensemble method;genetic programming;data mining;classification;fractal dimension;ensemble;distributed streaming data	The paper presents an adaptive GP boosting ensemble method forthe classification of distributed homogeneous streaming data that comes from multiple locations. The approach is able to handle concept drift via change detection by employing a change detection strategy, based on self-similarity of the ensemble behavior, and measured by its fractal dimension. It is efficient since each nodeof the network works with its local streaming data, and communicate only the local model computed with the otherpeer-nodes. Furthermore, once the ensemble has been built, it isused to predict the class membership of new streams of data until concept drift is detected. Only in such a case the algorithm is executed to generate a new set of classifiers to update the current ensemble. Experimental results on a synthetic and reallife data set showed the validity of the approach in maintaining an accurate and up-to-date GP ensemble.	algorithm;concept drift;ensemble kalman filter;fractal dimension;self-similarity;streaming media;synthetic intelligence	Gianluigi Folino;Clara Pizzuti;Giandomenico Spezzano	2007		10.1145/1276958.1277301	ensembl;genetic programming;biological classification;computer science;concept drift;machine learning;pattern recognition;data mining;ensemble learning;fractal dimension;change detection	AI	-0.6223520988104867	-37.340657982064414	13792
85d425e540867d052749e62129506f4e1bf27167	independently weighted value difference metric		Abstract The majority of the difference metrics used in categorical classification algorithms do not take the dependence structure among attributes into account. Some of these metrics even make strong assumptions on attribute independence which are not realistic for many real-world datasets. In addition, these metrics do not consider attribute importance on the class variable. In this paper, a new difference metric is proposed which is named as Independently Weighted Value Difference Metric (IWVDM). IWVDM includes an embedded Incremental Feature Selection (IFS) phase. The proposed metric does not require attribute independence and it introduces a weighting procedure for attributes depending on the information that they possess on the class variable. A series of experiments is conducted using 30 UCI benchmark datasets for comparing the efficiency of IWVDM with Overlap Metric (OM), Value Difference Metric (VDM) and Frequency Difference Metric (FDM). Experimental results show the superiority of IWVDM over these three metrics.		Ahmet Fatih Ortakaya	2017	Pattern Recognition Letters	10.1016/j.patrec.2017.07.009	a-weighting;pattern recognition;class variable;mathematics;artificial intelligence;feature selection;categorical variable;statistical classification;equivalence of metrics	Vision	8.05682627162565	-41.729594322871264	13809
8d8ca6094b149f6ebb9e151bc82e990c14466be3	selection of the optimal wavebands for the variety discrimination of chinese cabbage seed	semilla;multiple linear regression;modelizacion;analisis componente principal;haute performance;semence;partial least square regression;linear regression;pls regression;intelligence artificielle;chino;modelisation;variable selection;regression pls;espectrometria ir;analisis regresion;infrared spectrometry;regresion multiple;principal component analysis;spectrometrie ir;near infrared spectroscopy;regresion lineal;analyse composante principale;alto rendimiento;analyse regression;artificial intelligence;seed;regression analysis;principle component analysis;inteligencia artificial;chinois;discriminacion;chinese;modeling;high performance;regression multiple;regresion pls;regression lineaire;stepwise discriminant analysis;discrimination;multiple regression	This paper presents a method based on chemometrics analysis to select the optimal wavebands for variety discrimination of Chinese cabbage seed by using a Visible/Near-infrared spectroscopy (Vis/NIRS) system. A total of 120 seed samples were investigated using a field spectroradiometer. Chemometrics was used to build the relationship between the absorbance spectra and varieties. Principle component analysis (PCA) was not suitable for variety discrimination as the principle components (PCs) plot of three primary principle components could only intuitively distinguish the varieties well. Partial Least Squares Regression (PLS) was executed to select 6 optimal wavebands as 730nm, 420nm, 675nm, 620nm, 604nm and 609nm based on loading values. Two chemometrics, multiple linear regression (MLR) and stepwise discrimination analysis (SDA) were used to establish the recognition models. MLR model is not suitable in this study because of its unsatisfied predictive ability. The SDA model was proposed by the advantage of variable selection. The final results based on SDA model showed an excellent performance with high discrimination rate of 99.167%. It is also proved that optimal wavebands are suitable for variety discrimination.	chemometrics;feature selection;genetic algorithm;learning to rank;partial least squares regression;principal component analysis;seed;stepwise regression;visual instruction set;whole earth 'lectronic link	Di Wu;Lei Feng;Yong He	2006		10.1007/11925231_58	infrared spectroscopy;econometrics;computer science;linear regression;artificial intelligence;machine learning;feature selection;statistics	ML	11.493878249159229	-34.43707939955193	13849
0b8ee3c583fc61993fb663c4ed947e6f85a7bb25	goodman-kruskal measure associated clustering for categorical data	goodman kruskal measure;return on investment;dissimilarity measure;decisive rule;data mining;scenario association;marketing data;dissimilarity measures;decisive rules;clustering algorithms;supervised clustering;roi;categorical data;target variable	Motivated by business interest of return on investment (ROI) in marketing, we develop a conceptual clustering algorithm for categorical data with a response variable based on a variation to Goodman-Kruskal measure. The key to this algorithm is an implicitly cost-effective dissimilarity measure derived from a probabilistic association rule between the response and the explanatory scenarios. Applications to a real dataset FAMEX96 illustrate how useful information can be mined from marketing data using this dissimilarity measure.	categorical variable;cluster analysis;kruskal's algorithm	Wenxue Huang;Yuanyi Pan;Jianhong Wu	2012	IJDMMM	10.1504/IJDMMM.2012.049880	return on investment;computer science;machine learning;pattern recognition;data mining	ML	2.8180725097484816	-36.261837641198035	13850
21e6bf8d1e530a0d810eebdd079403d49a471b68	a study on effectiveness of extreme learning machine	feedforward neural network;feedforward neural networks;learning rate;learning algorithm;journal;function approximation;extreme learning machine;prediction accuracy;effective extreme learning machine	Extreme Learning Machine (ELM), proposed by Huang et al., has been shown a promising learning algorithm for single-hidden layer feedforward neural networks (SLFNs). Nevertheless, because of the random choice of input weights and biases, the ELM algorithm sometimes makes the hidden layer output matrix H of SLFN not full column rank, which lowers the effectiveness of ELM. This paper discusses the effectiveness of ELM and proposes an improved algorithm called EELM that makes a proper selection of the input weights and bias before calculating the output weights, which ensures the full column rank of H in theory. This improves to some extend the learning rate (testing accuracy, prediction accuracy, learning time) and the robustness property of the networks. The experimental results based on both the benchmark function approximation and real-world problems including classification and regression applications show the good performances of EELM.	algorithm;approximation;artificial neural network;benchmark (computing);elm;feedforward neural network;leo (computer);performance	Yuguang Wang;Feilong Cao;Yubo Yuan	2011	Neurocomputing	10.1016/j.neucom.2010.11.030	feedforward neural network;wake-sleep algorithm;computer science;artificial intelligence;online machine learning;machine learning;pattern recognition;stability;computational learning theory;active learning;generalization error	ML	15.723409827171807	-30.179195282216522	13904
4b008ce00767525372ad089680b921943fc05521	intelligent face recognition based on manifold learning and genetic-chaos algorithm optimized kernel extreme learning machine	face recognition;feature extraction;ga chaos;kelm	In order to extract sensitive features of face images from high dimensional image data and facilitate the recognition speed, this paper has proposed a novel method based on the manifold learning and genetic-chaos algorithm optimized kernel extreme learning machine (KELM) for the application of face recognition. The locally linear embedding (LLE) algorithm has been employed to extract distinct features by projecting the original high dimensionality of the face image into a low dimensionality space. Then the KELM is introduced to provide quick and accurate pattern recognition on the extracted features. The only parameter need to be determined in KELM is the neuron number of hidden layer. Literature review indicates that very limited work has addressed the optimization of this parameter. Hence, the genetic-chaos algorithm was used for the first time to optimize the KELM parameter in this paper. A robust KELM structure may be attained after the genetic-chaos optimization. In order to evaluate and verify the proposed method, experiment tests have been carried out using standard face expressions. The experimental analysis results indicate that the performance of the proposed LLEgenetic-chaos-KELM method outperforms its rivals in terms of both recognition accuracy and training speed.	algorithm;arc diagram;chaos theory;facial recognition system;kernel (operating system);mathematical optimization;neuron;nonlinear dimensionality reduction;pattern recognition;regular expression	Wei He;Enjun Wang;Ting Xiong	2013	JCM	10.12720/jcm.8.10.658-664	computer vision;computer science;artificial intelligence;machine learning;pattern recognition	AI	18.80742220863232	-48.504062384740834	13939
df0f725f159d56c57a349264ac6144510e5f4cd9	studies on assessment of structural reliability by response surface method and neural network	response surface method;structural reliability;neural network		artificial neural network;response surface methodology	Y. Murotsu;S. Shao;N. Chiku;Koki Fujita;Y. Shinohara	1993			artificial neural network;machine learning;computer science;artificial intelligence	Robotics	11.397612422711665	-25.071005369576763	13955
7c751665a3e47416ab37ff76c96947ac68f01682	support vector regression for software reliability growth modeling and prediction	modelizacion;support vector regression;intelligence artificielle;probabilistic approach;software engineering;modelisation;enfoque probabilista;approche probabiliste;machine exemple support;software reliability engineering;genie logiciel;artificial intelligence;inteligencia artificial;fiabilite logiciel;maquina ejemplo soporte;vector support machine;fiabilidad logicial;software reliability growth model;modeling;software reliability;ingenieria informatica	In this work, we propose to apply support vector regression (SVR) to build software reliability growth model (SRGM). SRGM is an important aspect in software reliability engineering. Software reliability is the probability that a given software will be functioning without failure during a specified period of time in a specified environment. In order to obtain the better performance of SRGM, practical selection of parameter C for SVR is discussed in the experiments. Experimental results with the classical Sys1 and Sys3 SRGM data set show that the performance of the proposed SVR-based SRGM is better than conventional SRGMs and relative good prediction and generalization ability are achieved.	experiment;population dynamics;reliability engineering;software quality;software reliability testing;support vector machine	Fei Xing;Ping Guo	2005		10.1007/11427391_148	support vector machine;simulation;systems modeling;computer science;artificial intelligence;machine learning;data mining;software quality	SE	7.522446762375123	-30.62884056836062	13965
66703ef80216d0d57efab2f343b7b32c14c9c7c1	partitioning fuzzy clustering algorithms for mixed feature-type symbolic data	clustering algorithms partitioning algorithms vectors prototypes algorithm design and analysis mathematical model equations;pattern clustering;prototypes;fuzzy set theory;iterative methods;fuzzy clustering;vectors;adaptive distances;mixed feature type symbolic data;iteration algorithm fuzzy clustering algorithms mixed feature type symbolic data histogram valued symbolic data fuzzy partition adequacy criterion adaptive euclidean distances;mathematical model;clustering algorithms;pattern clustering fuzzy set theory iterative methods;histogram valued data;algorithm design and analysis;partitioning algorithms;adaptive distances fuzzy clustering mixed feature type symbolic data histogram valued data	This paper presents partitioning fuzzy clustering algorithms for mixed feature-type symbolic data. The proposed algorithms need a previous pre-processing step in order to obtain a suitable homogenization of the mixed feature-type symbolic data into histogram-valued symbolic data. These fuzzy clustering algorithms give a fuzzy partition and a prototype for each fuzzy cluster by optimizing an adequacy criterion based on suitable adaptive and non-adaptive Euclidean distances between vectors of histogram-valued data. The adaptive Euclidean distances change at each algorithm iteration and are different from one fuzzy cluster to another. Experiments with real mixed feature-type symbolic data sets show the usefulness of these fuzzy clustering algorithms.	algorithm;cluster analysis;euclidean distance;fuzzy clustering;iteration;preprocessor;prototype;rand index;stationary process	Francisco de A. T. de Carvalho;Lucas F. S. Cambuim	2012	2012 IEEE International Conference on Systems, Man, and Cybernetics (SMC)	10.1109/ICSMC.2012.6377927	algorithm design;discrete mathematics;defuzzification;fuzzy clustering;flame clustering;fuzzy classification;computer science;fuzzy number;neuro-fuzzy;machine learning;pattern recognition;mathematical model;mathematics;prototype;iterative method;fuzzy set;cluster analysis;fuzzy set operations	DB	2.4877274185208726	-39.54231448306244	13984
681e984520ff98d7a98866e80993aa389993cba3	boosting trees for cost-sensitive classifications	decision tree learning;learning algorithm;decision tree;adquisicion del conocimiento;intelligence artificielle;algorithme apprentissage;acquisition connaissance;arbol decision;classification;boosting;machine learning;cost sensitive classification;knowledge acquisition;inductive learning;artificial intelligence;inteligencia artificial;computer science;algoritmo aprendizaje;working paper;arbre decision;clasificacion	This paper explores two boosting techniques for cost-sensitive tree classi cations in the situation where misclassi cation costs change very often. Ideally, one would like to have only one induction, and use the induced model for di erent misclassi cation costs. Thus, it demands robustness of the induced model against cost changes. Combining multiple trees gives robust predictions against this change. We demonstrate that the two boosting techniques are a good solution in di erent aspects under this situation.	mathematical induction	Kai Ming Ting;Zijian Zheng	1998		10.1007/BFb0026689	decision tree learning;biological classification;computer science;artificial intelligence;machine learning;decision tree;pattern recognition;boosting	ML	8.638354172900451	-32.57761553322061	13991
6d39b17f8034da7b35dd7d14116d6710ee9a90b4	discriminative multiview nonnegative matrix factorization with large margin for image classification		Image classification has attracted lots of attentions in recent years. To improve classification accuracy, multiple features are usually extracted to represent the context of images, which imposes a challenge for the combination of those features. To address this problem, we present a discriminative nonnegative multi-view learning approach for image classification based on the observation that those features are often nonnegative. For discrimination, we utilize class label as an auxiliary information to learn discriminative common representations through a set of nonnegative basis vectors with large margin. Meanwhile, view consistency constraint is imposed on the low-dimensional representations and correntropy-induced metric (CIM) is adopted for the measurement of reconstruction errors. We utilized half-quadratic optimization technique to solve the optimization problem and obtain an effective multiplicative update rule. Experimental results demonstrate the learned common latent representations by the proposed method are more efficient than other methods.	basis (linear algebra);computer vision;computer-integrated manufacturing;discriminative model;mathematical optimization;non-negative matrix factorization;optimization problem;performance	Fei Long;Weihua Ou;Kesheng Zhang;Yi Tan;Yunhao Xue;Gai Li	2017	2017 International Conference on Security, Pattern Analysis, and Cybernetics (SPAC)	10.1109/SPAC.2017.8304247	measurement uncertainty;discriminative model;multiplicative function;basis (linear algebra);linear programming;contextual image classification;non-negative matrix factorization;pattern recognition;mathematics;optimization problem;artificial intelligence	Vision	24.268593899821806	-42.78922349967759	13999
1487ff473d7ab260f85e88f1ed067466d5ae6735	evolutionary optimization ofwavelet feature sets for real-time pedestrian classification	software testing;test data generation;program testing;evolutionary algorithms;program testing genetic algorithms;genetic algorithm;genetic algorithms;genetic algorithms software testing immune system hybrid power systems system testing benchmark testing software quality instruments ant colony optimization cost function;evolutionary algorithm;evolutionary algorithms immune genetic algorithm software test data generation test data generation;software test data generation;immune genetic algorithm;hybrid algorithm	Computer vision for object detection often relies on complex classifiers and large feature sets to achieve high detection rates. But when real-time constraints have to be met, for example in driver assistance systems, fast classifiers are required. Here we consider the design of a computationally efficient system for pedestrian detection. We propose an evolutionary algorithm for the optimization of a small set of wavelet features, which can be computed very efficiently. These features serve as input to a linear classifier. The classification performance of the optimized system is on par with recently published results obtained with support vector machines on large feature sets, while the computational time is lower by orders of magnitude.	algorithmic efficiency;computation;computational complexity theory;computer vision;evolutionary algorithm;linear classifier;linear discriminant analysis;mathematical optimization;object detection;pedestrian detection;real-time clock;real-time transcription;run time (program lifecycle phase);support vector machine;time complexity;wavelet	Jan Salmen;Thorsten Suttorp;Johann Edelbrunner;Christian Igel	2007	7th International Conference on Hybrid Intelligent Systems (HIS 2007)	10.1109/HIS.2007.37	quality control and genetic algorithms;genetic programming;meta-optimization;computer science;theoretical computer science;machine learning;genetic representation;algorithm;population-based incremental learning	Vision	10.43190002827178	-41.42240952541032	14006
db7b8a92b2aa37ea00ffbed4a0b2d8bc20f1cd17	classifying 3d human motions by mixing fuzzy gaussian inference with genetic programming	time dependent;genetic program;fgi;context aware;fuzzy membership function;noisy data;human motion;probability distribution	This paper combines the novel concept of Fuzzy Gaussian Inference(FGI) with Genetic Programming (GP) in order to accurately classify real natural 3d human Motion Capture data. FGI builds Fuzzy Membership Functions that map to hidden Probability Distributions underlying human motions, providing a suitable modelling paradigm for such noisy data. Genetic Programming (GP) is used to make a time dependent and context aware filter that improves the qualitative output of the classifier. Results show that FGI outperforms a GMM-based classifier when recognizing seven different boxing stances simultaneously, and that the addition of the GP based filter improves the accuracy of the FGI classifier significantly.	boxing;fuzzy logic;genetic programming;google map maker;kinesiology;motion capture;preprocessor;programming paradigm;real life;signal-to-noise ratio	Mehdi Khoury;Honghai Liu	2009		10.1007/978-3-642-10817-4_6	probability distribution;computer science;artificial intelligence;machine learning;pattern recognition;data mining;statistics	ML	17.704401641893966	-45.018194451309746	14014
727038c422b8998a0dacbd46b2cc95a273cdab2d	learning sparse optimal rule fit by safe screening		In this paper, we consider linear prediction models in the form of a sparse linear combination of rules, where a rule is an indicator function defined over a hyperrectangle in the input space. Since the number of all possible rules generated from the training dataset becomes extremely large, it has been difficult to consider all of them when fitting a sparse model. In this paper, we propose Safe Optimal Rule Fit (SORF) as an approach to resolve this problem, which is formulated as a convex optimization problem with sparse regularization. The proposed SORF method utilizes the fact that the set of all possible rules can be represented as a tree. By extending a recently popularized convex optimization technique called safe screening, we develop a novel method for pruning the tree such that pruned nodes are guaranteed to be irrelevant to the prediction model. This approach allows us to efficiently learn a prediction model constructed from an exponentially large number of all possible rules. We demonstrate the usefulness of the proposed method by numerical experiments using several benchmark datasets.	benchmark (computing);convex optimization;experiment;mathematical optimization;numerical analysis;optimization problem;relevance;sparse matrix	Hiroki Kato;Hiroyuki Hanada;Ichiro Takeuchi	2018	CoRR		machine learning;mathematics;mathematical optimization;artificial intelligence;linear combination;linear prediction;hyperrectangle;indicator function;exponential growth;regularization (mathematics);convex optimization	ML	24.31102004206302	-35.18289385506005	14025
d864efaf9c4b7470f0ff373fc0cb1b7252d7a85e	hybrid neural modeling for groundwater level prediction	metodo regularizacion;bayes estimation;modelizacion;prediccion;correlacion;levenberg marquardt;calcul neuronal;optimisation;bayesian regularization;neural computation;haute performance;regularisation;optimizacion;fluctuations;neural model;62m20;62h20;regularization method;modelo hibrido;training algorithms;resource management;65kxx;algorithme hybride;water supply;methode regularisation;ann;optimization method;algoritmo genetico;65k10;modele hybride;metodo optimizacion;modele reseau neuronal;lead time;genetics;65j20;hybrid model;regularization;49xx;modelisation;gestion recursos;estimacion bayes;planificacion;nappe eau;prediction theory;propagacion;seasonality;water scarcity;capa agua;fluctuacion;analyse correlation;methode optimisation;algorithme genetique;alto rendimiento;gestion ressources;65f22;genetic algorithm;planning;groundwater;optimization;aquifers;model test;regularizacion;river basin;planification;correlation;winter;reseau neuronal;theorie prediction;fluctuation;modeling;high performance;prediction;back propagation;red neuronal;computacion neuronal;reseau neuronal artificiel;propagation;india;analisis correlacion;artificial neural network;estimation bayes;neural network;correlation analysis;groundwater management	The accurate prediction of groundwater level is important for the efficient use and management of groundwater resources, particularly in sub-humid regions where water surplus in monsoon season and water scarcity in non-monsoon season is a common phenomenon. In this paper, an attempt has been made to develop a hybrid neural model (ANN-GA) employing an artificial neural network (ANN) model in conjunction with famous optimization strategy called genetic algorithms (GA) for accurate prediction of groundwater levels in the lower Mahanadi river basin of Orissa State, India. Three types of functionally different algorithm-based ANN models (viz. back-propagation (GDX), Levenberg–Marquardt (LM) and Bayesian regularization (BR)) were used to compare the strength of proposed hybrid model in the efficient prediction of groundwater fluctuations. The ANN-GA hybrid modeling was carried out with lead-time of 1 week and study mainly aimed at November and January months of a year. Overall, simulation results suggest that the Bayesian regularization model is the most efficient of the ANN models tested for the study period. However, a strong correlation between the observed and predicted groundwater levels was observed for all the models. The results reveal that the hybrid GA-based ANN algorithm is able to produce better accuracy and performance in medium and high groundwater level predictions compared to conventional ANN techniques including Bayesian regularization model. Furthermore, the study shows that hybrid neural models can offer significant implications for improving groundwater management and water supply planning in semi-arid areas where aquifer information is not available.	artificial neural network;backpropagation;bayesian network;genetic algorithm;levenberg–marquardt algorithm;mathematical optimization;semiconductor industry;simulation;software propagation;viz: the computer game;libgdx	Nikunja B. Dash;Sudhindra N. Panda;Renji Remesan;Narayan Sahoo	2010	Neural Computing and Applications	10.1007/s00521-010-0360-1	planning;water scarcity;regularization;drainage basin;aquifer;systems modeling;genetic algorithm;bayesian interpretation of regularization;levenberg–marquardt algorithm;prediction;groundwater;computer science;artificial intelligence;backpropagation;machine learning;water supply;correlation;artificial neural network;seasonality;models of neural computation	AI	9.933463248358867	-24.058739658803127	14049
4c513c4a6714b6a41a44d44296b4463cfa73c675	what makes planners predictable?	search space	In recent work we showed that models constructed from planner performance data over a large suite of benchmark problems are surprisingly accurate; 91-99% accuracy for success and 3-496 seconds RMSE for runtime. In this paper, we examine the underlying causes of these accurate models. We deconstruct the learned models to assess how the features, the planners, the search space topology and the amount of training data facilitate predicting planner performance. We find that the models can be learned from relatively little training data (e.g., performance on 10% of the problems in some cases). Generally, having more features improves accuracy. However, the effect is often planner-dependent: in some cases, adding features degrades performance. We identify that the most prominent features in the models are domain features, though we find that the runtime models still have a need for better features. In the last part of the paper, we examine explanatory models to refine the planner dependencies and to identify linkages between problem structure and specific planners’ performance.	benchmark (computing)	Mark Roberts;Adele E. Howe;Brandon Wilson;Marie desJardins	2008				AI	14.101978027052022	-43.49538419571292	14122
d37afd76816b66079debe4d04390c7f8e17f0575	distinguishing causal and acausal temporal relations	analisis datos;time series;data analysis;vie artificielle;causalite;serie temporelle;serie temporal;analyse donnee;artificial life;causality;causalidad	In this paper we propose a solution to the problem of distinguishing between causal and acausal temporal sets of rules. The method, called the Temporal Investigation Method for Enregistered Record Sequences (TIMERS), is explained and introduced formally. The input to TIMERS consists of a sequence of records, where each record is observed at regular intervals. Sets of rules are generated from the input data using different window sizes and directions of time. The set of rules may describe an instantaneous relationship, where the decision attribute depends on condition attributes seen at the same time instant. We investigate the temporal characteristics of the system by changing the direction of time when generating temporal rules to see whether a set of rules is causal or acausal. The results are used to declare a verdict as to the nature of the system: instantaneous, causal, or acausal.	anticausal system;causal filter;causal system;entity–relationship model	Kamran Karimi;Howard J. Hamilton	2003		10.1007/3-540-36175-8_23	causality;computer science;artificial intelligence;time series;data mining;mathematics;data analysis;algorithm;artificial life;statistics	DB	-3.93826410334996	-32.26904834603819	14141
acc17ad0a460698e47e6c73436751b614373469f	a novel bat algorithm fuzzy classifier approach for classification problems		In this paper, the application of nature-inspired algorithms (NIA) along with fuzzy classifiers is studied. The four algorithms used for the analysis are genetic algorithm, particle swarm optimisation, artificial bee colony and bat algorithm. These algorithms are used on three standard benchmark datasets and one real-time multi-spectral satellite dataset. The results obtained using different fuzzy-NIAs are analysed. Finally, we observe that the fuzzy classifiers under a given set of parameters perform more accurately when applied with the bat algorithm.	bat algorithm	Shruti Parashar;J. Senthilnath;Xin-She Yang	2017	IJAISC	10.1504/IJAISC.2017.10005624	fuzzy logic;artificial intelligence;artificial bee colony algorithm;machine learning;genetic algorithm;bat algorithm;computer science;classifier (linguistics);particle swarm optimization	ML	9.36966071936717	-40.67151629823082	14238
1d398a9c6dff704183ea18e497ae45b840fbd472	why regularized auto-encoders learn sparse representation?		Although a number of auto-encoder models enforce sparsity explicitly in their learned representation while others don’t, there has been little formal analysis on what encourages sparsity in these models in general. Therefore, our objective here is to formally study this general problem for regularized auto-encoders. We show that both regularization and activation function play an important role in encouraging sparsity. We provide sufficient conditions on both these criteria and show that multiple popular models– like De-noising and Contractive auto-encoder– and activations– like Rectified Linear and Sigmoid– satisfy these conditions; thus explaining sparsity in their learned representation. Our theoretical and empirical analysis together, throws light on the properties of regularization/activation that are conducive to sparsity. As a by-product of the insights gained from our analysis, we also propose a new activation function that overcomes the individual drawbacks of multiple existing activations (in terms of sparsity) and hence produces performance at par (or better) with the best performing activation for all auto-encoder models discussed.	activation function;autoencoder;encoder;sparse approximation;sparse matrix	Devansh Arpit;Yingbo Zhou;Hung Q. Ngo;Venu Govindaraju	2016			econometrics;machine learning;normalization;mathematics;statistics	ML	22.72580915833425	-45.2005744924522	14312
bfabe2b8c9f3662dd5258205f08ae9948875b6bb	a fast c++ implementation of neural network backpropagation training algorithm: application to bayesian optimal image demosaicing	feedforward neural networks;image demosaicing;code optimisation	Recent years have seen a surge of interest in multilayer neural networks fueled by their successful applications in numerous image processing and computer vision tasks. In this article, we describe a C++ implementation of the stochastic gradient descent to train a multilayer neural network, where a fast and accurate acceleration of tanh(.) is achieved with linear interpolation. As an example of application, we present a neural network able to deliver state-of-the-art performance in image demosaicing. Source Code The source code and an online demo are accessible at the IPOL web page of this article1.	algorithm;artificial neural network;backpropagation;c++;computer vision;demosaicing;image processing;linear interpolation;stochastic gradient descent;web page	Yi-Qing Wang;Nicolas Limare	2015	IPOL Journal	10.5201/ipol.2015.137	computer vision;probabilistic neural network;computer science;artificial intelligence;machine learning;time delay neural network	ML	16.38771637722324	-32.91970697373785	14324
1f1122f01db3a48b2df32d2c929bcf5193b0e89c	effect of rule weights in fuzzy rule-based classification systems	fuzzy rule based system;control systems;inference mechanisms pattern classification knowledge based systems fuzzy systems fuzzy set theory;fuzzy if then rule;fuzzy reasoning;function approximation pattern classification fuzzy rule based systems fuzzy reasoning fuzzy if then rule membership functions fuzzy set theory rule extraction;application software;helium;fuzzy rule based systems;fuzzy control;rule extraction;inference mechanisms;indexing terms;fuzzy set theory;fuzzy sets;fuzzy rule base;function approximation;membership functions;classification system;membership function;pattern classification;fuzzy if then rules;computer simulation;fuzzy systems knowledge based systems fuzzy sets fuzzy reasoning pattern classification fuzzy control control systems computer simulation helium application software;fuzzy systems;knowledge based systems	This paper examines the effect of rule weights in fuzzy rule-based classification systems. Each fuzzy IF–THEN rule in our classification system has antecedent linguistic values and a single consequent class. We use a fuzzy reasoning method based on a single winner rule in the classification phase. The winner rule for a new pattern is the fuzzy IF–THEN rule that has the maximum compatibility grade with the new pattern. When we use fuzzy IF–THEN rules with certainty grades (i.e., rule weights), the winner is determined as the rule with the maximum product of the compatibility grade and the certainty grade. In this paper, the effect of rule weights is illustrated by drawing classification boundaries using fuzzy IF–THEN rules with/without certainty grades. It is also shown that certainty grades play an important role when a fuzzy rule-based classification system is a mixture of general rules and specific rules. Through computer simulations, we show that comprehensible fuzzy rule-based systems with high classification performance can be designed without modifying the membership functions of antecedent linguistic values when we use fuzzy IF–THEN rules with certainty grades.	computer simulation;fuzzy logic;fuzzy rule;logic programming;rule-based system	Hisao Ishibuchi;Tomoharu Nakashima	2001	IEEE Trans. Fuzzy Systems	10.1109/91.940964	defuzzification;type-2 fuzzy sets and systems;fuzzy mathematics;fuzzy classification;computer science;artificial intelligence;fuzzy number;neuro-fuzzy;machine learning;pattern recognition;data mining;mathematics;fuzzy set;fuzzy set operations;fuzzy control system	AI	5.122571171562546	-27.59231594740323	14360
44f35257a943082b9d23dbdfb0324e84640747b6	rainfall-runoff model usingan artificial neural network approach	calcul scientifique;mlp;water resource;matematicas aplicadas;modele mathematique;mathematiques appliquees;hydrologie;multilayer perceptrons;ressource eau;water resources;regression model;intelligence artificielle;modelo matematico;multilayer perceptron;perceptron multicouche;modelo regresion;hidrologia;computacion cientifica;mlp neural network;red multinivel;rainfall runoff models;modele regression;semiarid climate;recurso agua;comparative study;mathematical model;hydrology;artificial intelligence;rainfall runoff;morocco;inteligencia artificial;multilayer network;reseau multicouche;reseau neuronal;scientific computation;58a25;applied mathematics;red neuronal;artificial neural network;modele pluie debit;neural network;catchment;rainfall runoff model;multiple regression	The use of artificial neural networks (ANNs) is becoming increasingly common in the analysis of hydrology and water resources problems. In this research, an ANN was developed and used to model the rainfall-runoff relationship, in a catchment located in a semiarid climate in Morocco. The multilayer perceptron (MLP) neural network was chosen for use in the current study. The results and comparative study indicate that the artificial neural network method is more suitable to predict river runoff than classical regression model.	artificial neural network;typset and runoff	Souad Riad;Jacky Mania;L. Bouchaou;Y. Najjar	2004	Mathematical and Computer Modelling	10.1016/j.mcm.2004.10.012	water resources;probabilistic neural network;drainage basin;linear regression;artificial intelligence;comparative research;mathematical model;mathematics;multilayer perceptron;semi-arid climate;operations research;artificial neural network;regression analysis	ML	9.8636809052121	-24.349371466420003	14384
0c13e4008fa3a1a7a0aad6aa18d042166b3929c0	adaptive local fusion with fuzzy integrals	optimisation;linear aggregation adaptive local fusion classifiers outputs context extraction for local fusion with fuzzy integrals celf fi context identification multialgorithm fusion criteria sugeno measures alternating optimization fuzzy membership degree context dependent partial confidence values synthetic data ground penetrating radar landmine detection wideband electromagnetic induction global fuzzy integral fusion method;landmine detection;radar computing;sensor fusion electromagnetic induction fuzzy set theory ground penetrating radar landmine detection optimisation pattern classification radar computing;fuzzy set theory;ground penetrating radar;electromagnetic induction;pattern classification;sensor fusion;local fusion classification classifier fusion clustering fuzzy integrals;context feature extraction partitioning algorithms clustering algorithms training indexes testing	We propose a novel method for fusing different classifiers outputs. Our approach, called context extraction for local fusion with fuzzy integrals (CELF-FI), is a local approach that adapts a fuzzy integrals fusion method to different regions of the feature space. It is based on a novel objective function that combines context identification and multialgorithm fusion criteria into a joint objective function. This objective function consists of two terms: The first is designed to produce compact clusters, called contexts, and the second is designed to produce Sugeno measures for fuzzy integral fusion for each context. The terms are optimized simultaneously via alternating optimization. To test a new sample, first, its features (extracted by each algorithm) are used to assign it to each context with a fuzzy membership degree. Second, the sample confidence values (assigned by each algorithm) are fused within each context using the learned context fusion parameters. Then, the context-dependent partial confidence values are weighted by the membership degrees and averaged over all contexts to produce a final confidence value. We illustrate the performance of CELF using synthetic data, and we apply it to the problem of landmine detection using ground penetrating radar and wideband electromagnetic induction. Our extensive experiments have indicated that the proposed fusion approach outperforms all individual classifiers, the global fuzzy integral fusion method, and the basic local fusion with linear aggregation.	algorithm;computer cluster;context-sensitive language;experiment;feature vector;fuzzy logic;fuzzy measure theory;integral theory (ken wilber);loss function;mathematical optimization;nonlinear system;optimization problem;sugeno integral;synthetic data	Ahmed Chamseddine Ben Abdallah;Hichem Frigui;Paul D. Gader	2012	IEEE Transactions on Fuzzy Systems	10.1109/TFUZZ.2012.2187062	electromagnetic induction;ground-penetrating radar;fuzzy classification;computer science;artificial intelligence;machine learning;pattern recognition;data mining;sensor fusion;fuzzy set	Vision	20.311765156989352	-40.683844701646684	14429
fc7d5abcb95fe60b749a7fc1f7dfc2dcd447a3ba	matching attention network for domain adaptation optimized by joint gans and kl-mmd		Although deep neural networks have brought impressive advances in a variety of machine learning tasks, it is more difficult to train a top-performing model in the absence of the labeled data. To alleviate this issue, domain adaptation has been extensively researched, which aims to reduce the difference between the distributions of the source and target domain by imposing restrictions on features. Adversarial learning method is the most promising approach to generate data that obeys a complex distribution. However, generator model often sinks into partial or full collapse. In this paper, we transform the complex data into a simple distribution, then calculate KL divergence (KL-MMD). We combine the Matching Gate with Attention Mechanism and put forward Matching Attention to learn feature vectors. Extensive experiments and analysis are conducted on three different digits datasets: MNIST, USPS, SVHN. To our knowledge, our method achieves state-of-the-art digit recognition performance on three unsupervised adaptation results.	domain adaptation;kl-one;mikumikudance	Yuan-Zhu Gan;Hai-Qing Wang;Lu-Fei Liu;Yu-Bin Yang	2018		10.1007/978-3-319-97304-3_26	machine learning;labeled data;computer science;artificial neural network;pattern recognition;kullback–leibler divergence;artificial intelligence;domain adaptation;feature vector;complex data type;mnist database	Vision	23.957873709349315	-48.675316957973315	14470
39300319067be28867e9d62e44e359bb454e6fca	ecoc-based training of neural networks for face recognition	databases;feedforward neural networks;error correction codes;error back propagation;feed forward neural network;neural nets;training;biological system modeling;ecoc based training;output representation;classification tasks;error correcting output coding;artificial neural networks;face recognition;neural networks face recognition mimo error correction codes feeds feedforward neural networks backpropagation algorithms error correction multilayer perceptrons hamming distance;backpropagation algorithm;classification algorithms;classification system;back propagation algorithm;multi layer perceptron error correcting output coding error back propagation algorithm face recognition;multi layer perceptron;face;error back propagation algorithm;learning artificial intelligence;neural nets error correction codes face recognition learning artificial intelligence;backpropagation algorithm ecoc based training face recognition error correcting output codes output representation classification tasks feedforward neural networks classification systems;classification systems;error correcting output code;error correcting output codes;neural network	Error correcting output codes, ECOC, is an output representation method capable of discovering some of the errors produced in classification tasks. This paper describes the application of ECOC to the training of feed forward neural networks, FFNN, for improving the overall accuracy of classification systems. Indeed, to improve the generalization of FFNN classifiers, this paper proposes an ECOC-Based training method for neural networks that use ECOC as the output representation, and adopts the traditional back-propagation algorithm, BP, to adjust weights of the network. Experimental results for face recognition problem on Yale database demonstrate the effectiveness of our method. With a rejection scheme defined by a simple robustness rate, high reliability is achieved in this application.	algorithm;artificial neural network;backpropagation;code;code word;facial recognition system;loss function;rejection sampling;scheme;software propagation;teaching method	Nima Hatami;Reza Ebrahimpour;Reza Ghaderi	2008	2008 IEEE Conference on Cybernetics and Intelligent Systems	10.1109/ICCIS.2008.4670763	feedforward neural network;computer science;artificial intelligence;backpropagation;machine learning;pattern recognition;artificial neural network	Vision	14.546972023071413	-32.68114351863546	14473
540dd490958eeb2f155817c91881e2c6f6b0fe6b	nonlinear time-series prediction with missing and noisy data	data transmission;prediccion;logica temporal;stochastic process;maximum likelihood;noisy data;temporal logic;stochastic simulation;simulacion numerica;maximum vraisemblance;ruido;chaotic time series;nonlinear time series;transmission donnee;bruit;simulation numerique;processus stochastique;missing data;reseau neuronal;proceso estocastico;point of view;prediction;logique temporelle;red neuronal;maxima verosimilitud;transmision datos;noise;neural network;numerical simulation	We derive solutions for the problem of missing and noisy data in nonlinear time-series prediction from a probabilistic point of view. We discuss different approximations to the solutionsin particular, approximations that require either stochastic simulation or the substitution of a single estimate for the missing data. We show experimentally that commonly used heuristics can lead to suboptimal solutions. We show how error bars for the predictions can be derived and how our results can be applied to K-step prediction. We verify our solutions using two chaotic time series and the sunspot data set. In particular, we show that for K-step prediction, stochastic simulation is superior to simply iterating the predictor.	addendum;approximation;bayesian network;c date and time functions;experiment;heuristic (computer science);hénon map;kerrison predictor;logistic map;mean squared error;missing data;nonlinear system;sampling (signal processing);signal-to-noise ratio;simulation;state space;state-space representation;time series;unfolding (dsp implementation)	Volker Tresp;Reimar Hofmann	1998	Neural Computation	10.1162/089976698300017728	stochastic process;econometrics;prediction;temporal logic;missing data;computer science;noise;artificial intelligence;stochastic simulation;mathematics;maximum likelihood;artificial neural network;statistics;data transmission	ML	21.7308978292887	-26.15942760365555	14489
57abace00d385837e242071218676b562c23e499	a survey and perspective connected with rough non-deterministic information analysis	non deterministic information;privacy preserving;data mining;constraint satisfaction;incomplete information;estimation;rough sets	Rough non-deterministic information analysis (RNIA) is a rough sets-based framework for handling tables with exact and inexact data. Under this framework, we investigated possible equivalence relations, data dependencies, rule generation, rule stability, question-answering systems, as well as missing and interval values as special cases of non-deterministic values. In this paper, we briefly survey RNIA, and report the state of its underlying software implementation. Furthermore, we consider perspective on new two issues, i.e., the estimation and privacy-preserving, connected with RNIA		Hiroshi Sakai;Mao Wu;Naoto Yamaguchi	2014	IJCIStudies	10.1504/IJCISTUDIES.2014.062727	estimation;rough set;constraint satisfaction;computer science;data science;machine learning;data mining;complete information	AI	-3.8580262500100475	-27.809655526802096	14507
5562ca1a10e0993136c4d50d23b673b594579b14	som neural network design - a new simulink library based approach targeting fpga implementation	fpga;artificial neural networks;ann modelling;self organizing map;article;self organizing map artificial neural network;simulink library	The paper presents a method for FPGA implementation of SelfOrganizing Map (SOM) artificial neural networks with on-chip learning algorithm. The method aims to build up a specific neural network using generic blocks designed in the MathWorks Simulink environment. The main characteristics of this original solution are: on-chip learning algorithm implementation, high reconfiguration capability and operation under real time constraints. An extended analysis has been carried out on the hardware resources used to implement the whole SOM network, as well as each individual component block.	algorithm;artificial neural network;field-programmable gate array;network planning and design;simulink	Alin Tisan;Marcian N. Cirstea	2013	Mathematics and Computers in Simulation	10.1016/j.matcom.2012.05.006	self-organizing map;computer science;artificial intelligence;theoretical computer science;machine learning;time delay neural network;artificial neural network;field-programmable gate array	EDA	14.116135732260648	-26.19427256960687	14520
883dc960234b42f4c150f6bd4c7c3ec51a355866	a probabilistic mechanism based on clustering analysis and distance measure for subset gene selection	microarray data;gene microarray;distance measure;cluster analysis;computational complexity;clustering;clustering method;cancer diagnosis;gene selection	Many subset gene selection methods for microarray data employ classification tools to evaluate the discernability of a gene subset on a specific disease, and this evaluation process generally has a high computational complexity. In this study, we propose a probabilistic mechanism supported by a density-based clustering method and a distance measure to perform individual and group gene replacement for gene selection. Analysts can choose proper values for the parameters of the probabilistic mechanism to set the computational complexity for gene selection. The discernability of a gene subset on classification is evaluated by the distance measure to avoid the language bias that can be introduced by classification tools. Our experimental results on six microarray data sets show that the probabilistic mechanism can effectively and efficiently filter a gene subset with a high discernability on cancer diagnosis.		Tzu-Tsung Wong;Kuan-Liang Liu	2010	Expert Syst. Appl.	10.1016/j.eswa.2009.07.028	gene chip analysis;computer science;bioinformatics;machine learning;pattern recognition;data mining;mathematics;cluster analysis	Theory	6.913515470665964	-48.65311565205697	14562
e8acad2b7f17afd1af42545264fb5811db06ec5f	a novel probabilistic clustering model for heterogeneous networks	probabilistic graphical model;algorithm;clustering;heterogeneous networks	Heterogeneous networks, consisting of multi-type objects coupled with various relations, are ubiquitous in the real world. Most previous work on clustering heterogeneous networks either converts them into homogeneous networks or simplifies the modeling of the heterogeneity in terms of specific objects, structures or assumptions. However, few studies consider all relevant objects and relations, and trade-off between integrating relevant objects and reducing the noises caused by relations across objects. In this paper, we propose a general probabilistic graphical model for clustering heterogeneous networks. First, we present a novel graphical representation based on our basic assumptions: different relation types produce different weight distributions to specify intra-cluster probability between two objects, and clusters are formed around cluster cores. Then, we derive an efficient algorithm called PROCESS, standing for PRObabilistic Clustering modEl for heterogeneouS networkS. PROCESS employs a balance-controlled message passing algorithm and mathematical programming for inference and estimation. Experimental results show that our approach is effective and significantly outperforms the state-of-the-art algorithms on both synthetic and real data from heterogeneous networks.	cluster analysis;distributed algorithm;experiment;graphical model;mathematical optimization;message passing;semantic network;statistical model;synthetic intelligence	Zhi-Hong Deng;Xiaoran Xu	2016	Machine Learning	10.1007/s10994-016-5544-1	correlation clustering;heterogeneous network;flame clustering;computer science;theoretical computer science;machine learning;data mining;cluster analysis	ML	-1.5040993371496891	-44.05562446254298	14593
d292f56022a69594ce6e92fe1aa1031af8760b74	a new possibilistic biclustering algorithm for microarray gene expression data			algorithm;biclustering;microarray	Chandra Das;Pradipta Maji	2009			pattern recognition;gene expression;artificial intelligence;computer science;gene expression profiling;biclustering;microarray	Comp.	6.014159325454755	-48.31353669556395	14670
7d8030dcc4efc0734370bfc1b5df0dc2a4f28fdb	leading strategies in competitive on-line prediction	espace hilbert;prediccion;memoire;quadratic function;funcion cuadratica;fonction quadratique;espacio hilbert;46e22;divergence;46cxx;jeffreys s law;bregman divergence;estrategia;satisfiability;fonction perte;funcion perdida;regresion;strategy;hilbert space;regression;proper scoring rule;memoria;science learning;loss function;informatique theorique;reproducing kernel hilbert space;classe fonction;competitive on line prediction;strategie;prediction;divergencia;memory;computer theory;informatica teorica	We start from a simple asymptotic result for the problem of online regression with the quadratic loss function: the class of continuous limited-memory prediction strategies admits a “leading prediction strategy”, which not only asymptotically performs at least as well as any continuous limited-memory strategy but also satisfies the property that the excess loss of any continuous limited-memory strategy is determined by how closely it imitates the leading strategy. More specifically, for any class of prediction strategies constituting a reproducing kernel Hilbert space we construct a leading strategy, in the sense that the loss of any prediction strategy whose norm is not too large is determined by how closely it imitates the leading strategy. This result is extended to the loss functions given by Bregman divergences and by strictly proper scoring rules.	bregman divergence;hilbert space;loss function;offset binary;online and offline	Vladimir Vovk	2008	Theor. Comput. Sci.	10.1016/j.tcs.2008.06.040	scoring rule;regression;prediction;quadratic function;strategy;calculus;reproducing kernel hilbert space;mathematics;memory;divergence;algorithm;bregman divergence;algebra;satisfiability;loss function;hilbert space	ML	20.27667442787016	-30.54043127950502	14810
0688d605539faf53de818b7bb33a616a31643016	co-clusterd: a distributed framework for data co-clustering with sequential updates	pattern clustering;amazon ec2 cloud co clusterd distributed framework data coclustering algorithm sequential updates dyadic data coclustering parallelization approach distributed environment fast nonnegative matrix trifactorization fnmtf information theoretic coclustering itcc;distributed processing;data mining;pattern clustering data mining distributed processing information theory matrix decomposition;clustering algorithms algorithm design and analysis synchronization convergence linear programming distributed databases scalability;matrix decomposition;distributed framework co clustering concurrent updates sequential updates cloud computing;information theory	Co-clustering is a powerful data mining tool for co-occurrence and dyadic data. As data sets become increasingly large, the scalability of co-clustering becomes more and more important. In this paper, we propose two approaches to parallelize co-clustering with sequential updates in a distributed environment. Based on these two approaches, we present a new distributed framework, Co-ClusterD, that supports efficient implementations of co-clustering algorithms with sequential updates. We design and implement Co-ClusterD, and show its efficiency through two co-clustering algorithms: fast nonnegative matrix tri-factorization (FNMTF) and information theoretic co-clustering (ITCC). We evaluate our framework on both a local cluster of machines and the Amazon EC2 cloud. Our evaluation shows that co-clustering algorithms implemented in Co-ClusterD can achieve better results and run faster than their traditional concurrent counterparts.	biclustering	Sen Su;Xiang Cheng;Lixin Gao;Jiangtao Yin	2013		10.1109/ICDM.2013.76	information theory;computer science;theoretical computer science;data mining;mathematics;distributed computing;matrix decomposition;statistics	ML	-2.999534203114572	-39.398029542525435	14819
f4f52334ba5639f4c7e862e9610c902bab87cd6d	tadam: task dependent adaptive metric for improved few-shot learning		Few-shot learning has become essential for producing models that generalize from few examples. In this work, we identify that metric scaling and metric task conditioning are important to improve the performance of few-shot algorithms. Our analysis reveals that simple metric scaling completely changes the nature of few-shot algorithm parameter updates. Metric scaling provides improvements up to 14% in accuracy for certain metrics on the mini-Imagenet 5-way 5-shot classification task. We further propose a simple and effective way of conditioning a learner on the task sample set, resulting in learning a task-dependent metric space. Moreover, we propose and empirically test a practical end-to-end optimization procedure based on auxiliary task co-training to learn a task-dependent metric space. The resulting few-shot learning model based on the task-dependent scaled metric achieves state of the art on mini-Imagenet. We confirm these results on another few-shot dataset that we introduce in this paper based on CIFAR100.	algorithm;co-training;end-to-end principle;image scaling;mathematical optimization	Boris N. Oreshkin;Pau Rodríguez;Alexandre Lacoste	2018			artificial intelligence;computer science;machine learning;scaling;conditioning;metric space	ML	19.072991130474314	-32.16445101823331	14896
7d78fae159497b13443f36e62e71e0a84f26abd9	discovering solutions with low kolmogorov complexity and high generalization capability	machine learning;occam s razor	 Many machine learning algorithms aim atfinding &quot;simple&quot; rules to explain trainingdata. The expectation is: the &quot;simpler&quot;the rules, the better the generalization ontest data (! Occam's razor). Most practicalimplementations, however, use measuresfor &quot;simplicity&quot; that lack the power, universalityand elegance of those based on Kolmogorovcomplexity and Solomonoff's algorithmicprobability. Likewise, most previousapproaches (especially those of the&quot;Bayesian&quot; kind) suffer from the problem... 	kolmogorov complexity	Jürgen Schmidhuber	1995			kolmogorov structure function;algorithmic probability;solomonoff's theory of inductive inference;computer science;theoretical computer science;occam's razor;machine learning;algorithmically random sequence;mathematics;chain rule for kolmogorov complexity;algorithm;statistics	ML	8.963616696395937	-32.5662050000677	14913
8589b6e98ec9932966a895c57dffb767f3392269	applying cbr systems to micro array data classification	microarray data;case base reasoning;data mining;automatic classification;data classification	Microarray technology allows to measureing the expression levels of thousands of genes in an experiment. This technology required  requires computational solutions capable of dealing with great amounts of data and as well as techniques to explore the data  and extract knowledge which allow patients classification. This paper presents a systems based on Case-based reasoning (CBR)  for automatic classification of leukemia patients from microarray data. The system incorporates novel algorithms for data  mining that allow to filter and classify as well as extraction of knowledge. The system has been tested and the results obtained  are presented in this paper.  	case-based reasoning;microarray	Sara Rodríguez;Juan Francisco de Paz;Javier Bajo;Juan Manuel Corchado	2008		10.1007/978-3-540-85861-4_13	data science;pattern recognition;data mining	AI	7.74680341197451	-48.50068713701416	14943
a40cb295b6c1633c549d5846cd9fe59c381e6920	toward efficient multidimensional subspace skyline computation	skycube;skyline group;skyline queries;point based space partitioning;subspace skyline	Skyline queries have attracted considerable attention to assist multicriteria analysis of large-scale datasets. In this paper, we focus on multidimensional subspace skyline computation that has been actively studied for two approaches. First, to narrow down a full-space skyline, users may consider multiple subspace skylines reflecting their interest. For this purpose, we tackle the concept of a skycube, which consists of all possible non-empty subspace skylines in a given full space. Second, to understand diverse semantics of subspace skylines, we address skyline groups in which a skyline point (or a set of skyline points) is annotated with decisive subspaces. Our primary contributions are to identify common building blocks of the two approaches and to develop orthogonal optimization principles that benefit both approaches. Our experimental results show the efficiency of proposed algorithms by comparing them with state-of-the-art algorithms in both synthetic and real-life datasets.	algorithm;computation;mathematical optimization;real life;space partitioning;synthetic intelligence	Jongwuk Lee;Seung-won Hwang	2013	The VLDB Journal	10.1007/s00778-013-0317-y	pattern recognition;data mining;database	DB	-3.1037526114599014	-43.47449688619728	14959
9c0a69dd7e5f86e7c0596e8ae8194d591da22758	efficient maximum margin clustering via cutting plane algorithm	cutting plane;optimization problem	Maximum margin clustering (MMC) is a recently proposed clustering method, which extends the theory of support vector machine to the unsupervised scenario and aims at finding the maximum margin hyperplane which separates the data from different classes. Traditionally, MMC is formulated as a non-convex integer programming problem and is thus difficult to solve. Several methods have been proposed in the literature to solve the MMC problem based on either semidefinite programming or alternative optimization. However, these methods are time demanding while handling large scale datasets and therefore unsuitable for real world applications. In this paper, we propose the cutting plane maximum margin clustering (CPMMC) algorithm, to solve the MMC problem. Specifically, we construct a nested sequence of successively tighter relaxations of the original MMC problem, and each optimization problem in this sequence could be efficiently solved using the constrained concave-convex procedure (CCCP). Moreover, we prove theoretically that the CPMMC algorithm takes time O(sn) to converge with guaranteed accuracy, where n is the total number of samples in the dataset and s is the average number of non-zero features, i.e. the sparsity. Experimental evaluations on several real world datasets show that CPMMC performs better than existing MMC methods, both in efficiency and accuracy.	algorithm;cluster analysis;computation;concave function;converge;convex optimization;cutting-plane method;integer programming;mathematical optimization;memory management controller;optimization problem;semidefinite programming;sparse matrix;support vector machine;time complexity;unsupervised learning	Bin Zhao;Fei Wang;Changshui Zhang	2008		10.1137/1.9781611972788.68	machine learning;hyperplane;artificial intelligence;cutting-plane method;semidefinite programming;support vector machine;cluster analysis;integer programming;algorithm;mathematical optimization;optimization problem;mathematics	ML	22.142062880475713	-38.547191969093255	14961
2ad5cad4f3438016fe7ddce217f77d8fe8bf4299	generalized flexible fuzzy inference systems	pattern clustering;merging fuzzy systems covariance matrices approximation methods vectors ellipsoids complexity theory;fuzzy reasoning;combined adjacency homogenuity relation;projection concept;fuzzy set theory;gen flexfis;combined adjacency homogenuity relation generalized takagi sugeno ts fuzzy systems data stream regression gen flexfis projection concept rule merging;pattern clustering computational complexity fuzzy reasoning fuzzy set theory fuzzy systems learning artificial intelligence merging;data stream regression;rule merging;computational complexity;model complexity generalized flexible fuzzy inference systems incremental fuzzy systems extraction evolving fuzzy systems extraction data streams gen flexfis flexfis methodology generalized takagi sugeno fuzzy systems generalized rotated rules high dimensional kernel evolving clustering learning engine evq a ellipsoidal clusters extraction merging concept combined adjacency homogenuity relation generalized ts fuzzy systems projection concept one dimensional fuzzy sets query samples;merging;generalized takagi sugeno ts fuzzy systems;learning artificial intelligence;fuzzy systems	In this paper, we propose a new variant for incremental, evolving fuzzy systems extraction from data data streams, termed as GEN-FLEXFIS (short for Generalized Flexible Fuzzy Inference Systems). It builds upon the FLEXFIS methodology (published by the authors before) and extends it for generalized Takagi-Sugeno (TS) fuzzy systems, which implement generalized rotated rules in arbitrary position, employing a high-dimensional kernel rather than a connection of one-dimensional components (fuzzy sets) with t-norms. The extension includes the development of the evolving clustering learning engine, termed as eVQ-A, to extract ellipsoidal clusters in arbitrary position. Furthermore, a new merging concept based on a combined adjacency-homogenuity relation between two clusters (rules) is proposed in order to prune unnecessary rules and to keep the complexity of the generalized TS fuzzy systems low. Equipped with a new projection concept for high-dimensional kernels onto one-dimensional fuzzy sets, the new approach also provides equivalent conventional TS fuzzy systems, thus maintaining interpretability when inferring new query samples. GEN-FLEXFIS will be evaluated based on high-dimensional real-world data (streaming) sets in terms of accuracy versus final model complexity, compared with conventional FLEXFIS and other well-known (evolving) fuzzy systems approaches.	adjacency matrix;cluster analysis;fuzzy control system;fuzzy logic;fuzzy set;humo-gen;sugeno integral;t-norm	Edwin Lughofer;Carlos Cernuda;Mahardhika Pratama	2013	2013 12th International Conference on Machine Learning and Applications	10.1109/ICMLA.2013.97	discrete mathematics;membership function;defuzzification;adaptive neuro fuzzy inference system;type-2 fuzzy sets and systems;fuzzy mathematics;fuzzy classification;computer science;artificial intelligence;fuzzy number;neuro-fuzzy;machine learning;data mining;mathematics;fuzzy set;fuzzy associative matrix;computational complexity theory;fuzzy set operations;fuzzy control system	DB	2.2714280122000705	-39.26566486926551	14983
52fab8aabebec519e4f30b67d8144909274b973f	an equivalence between adaptive dynamic programming with a critic and backpropagation through time	dynamic programming;learning artificial intelligence backpropagation dynamic programming heuristic programming;adaptive dynamic programming general smooth nonlinear function approximator greedy policy backpropagation through time vgl value gradient learning continuous state spaces control problem optimization learned model functions critic function dhp dual heuristic programming;heuristic programming;backpropagation;qa75 electronic computers computer science;bf psychology;value gradient learning adaptive dynamic programming adp backpropagation through time dual heuristic programming dhp neural networks;learning artificial intelligence;rc0321 neuroscience biological psychiatry neuropsychiatry;trajectory vectors convergence equations approximation algorithms algorithm design and analysis neural networks	We consider the adaptive dynamic programming technique called Dual Heuristic Programming (DHP), which is designed to learn a critic function, when using learned model functions of the environment. DHP is designed for optimizing control problems in large and continuous state spaces. We extend DHP into a new algorithm that we call Value-Gradient Learning, VGL(λ), and prove equivalence of an instance of the new algorithm to Backpropagation Through Time for Control with a greedy policy. Not only does this equivalence provide a link between these two different approaches, but it also enables our variant of DHP to have guaranteed convergence, under certain smoothness conditions and a greedy policy, when using a general smooth nonlinear function approximator for the critic. We consider several experimental scenarios including some that prove divergence of DHP under a greedy policy, which contrasts against our proven-convergent algorithm.	adenosine diphosphate;approximation algorithm;artificial neural network;backpropagation through time;convergence (action);dual-energy x-ray absorptiometry;dynamic programming;experiment;gradient;greedy algorithm;heuristic;learning disorders;nonlinear system;rprop;turing completeness;usb on-the-go	Michael Fairbank;Eduardo Alonso;Danil V. Prokhorov	2013	IEEE Transactions on Neural Networks and Learning Systems	10.1109/TNNLS.2013.2271778	mathematical optimization;computer science;artificial intelligence;backpropagation;machine learning;dynamic programming	ML	20.267023407694303	-25.803710845778593	15023
a9f7cfa972a502f2a9d724057ec94321f7a0fc21	self-organizing maps: ordering, convergence properties and energy functions	energy;modele mathematique;multidimensional system;energia;relacion orden;relacion convergencia;ordering;taux convergence;convergence rate;modelo matematico;one dimensional structure;energy function;relation ordre;energie;self organized feature map;cognition;mathematical model;cognicion;sistema n dimensiones;self organized map;estructura 1 dimension;systeme n dimensions;structure 1 dimension;reseau neuronal;red neuronal;fonction voisinage;neural network	We investigate the convergence properties of the self-organizing feature map algorithm for a simple, but very instructive case: the formation of a topographic representation of the unit interval [0,1] by a linear chain of neurons. We extend the proofs of convergence of Kohonen and of Cottrell and Fort to hold in any case where the neighborhood function, which is used to scale the change in the weight values at each neuron, is a monotonically decreasing function of distance from the winner neuron. We prove that the learning dynamics cannot be described by a gradient descent on a single energy function, but may be described using a set of potential functions, one for each neuron, which are independently minimized following a stochastic gradient descent. We derive the correct potential functions for the oneand multi-dimensional case, and show that the energy functions given by Tolat (1990) are an approximation which is no longer valid in the case of highly disordered maps or steep neighborhood functions.	algorithm;approximation;convergence (action);mathematical optimization;neuron;neurons;numerous;organizing (structure);self-organization;self-organizing map;stochastic gradient descent;topography	E. Erwin;Klaus Obermayer;Klaus Schulten	1992	Biological Cybernetics	10.1007/BF00201801	energy;cognition;multidimensional systems;order theory;computer science;calculus;mathematical model;mathematics;geometry;rate of convergence;artificial neural network;quantum mechanics	ML	19.51043269086607	-27.69001347852909	15055
fa98e977923ea9854c4e942879c5eecf975d0d47	an adaptive dynamic evolution feedforward neural network on modified particle swarm optimization	input output representation form;feedforward neural network;feedforward neural networks;generalization capacity;evolutionary computation;premature convergence;neural networks feedforward neural networks particle swarm optimization nonlinear dynamical systems delay effects nonlinear systems convergence white noise logistics delay systems;white noise adaptive systems computational complexity delays evolutionary computation feedforward neural nets generalisation artificial intelligence gradient methods identification learning artificial intelligence mathematical operators nonlinear dynamical systems particle swarm optimisation search problems;nonlinear dynamical systems;training;adaptive dynamic evolution feedforward neural network training;gradient method complexity adaptive dynamic evolution feedforward neural network training modified particle swarm optimization generalization capacity nonlinear dynamic system identification adaptive long time delay operator pso method input output representation form premature convergence white noise logistic mapping global search;adaptive dynamics;modified particle swarm optimization;logistic map;gradient method complexity;time delay;mathematical operators;input output;global search;artificial neural networks;adaptive systems;computational complexity;heuristic algorithms;particle swarm optimization;identification;gradient methods;feedforward neural nets;search problems;generalisation artificial intelligence;learning artificial intelligence;nonlinear system;nonlinear dynamic system identification;particle swarm optimisation;adaptive long time delay operator;white noise;nonlinear dynamic system;pso method;delays;logistic mapping;neural network	In order to improve the generalization capacity of neural networks for poorly known nonlinear dynamic system with long time-delay, a novel adaptive dynamic feedforward neural network on modified Particle Swarm Optimization (PSO) algorithm is proposed. The adaptive time delay operator is adopted between input layer and the first hidden layer, and also the last hidden layer and output layer. Utilizing these dynamic time delay parameters, the proposed structure can adequately identify different classes of nonlinear systems expressed in the input-output representation form and pure time delay. Otherwise, to overcome the particles' premature convergence, the white noise and Logistic mapping are used to enhance the particles' search performance. Furthermore, the parameters in the dynamic feedforward neural network are trained by the modified PSO method. The proposed neural network shows a satisfactory global search and quick convergence capability, avoiding the complexity of gradient calculation. Simulation results demonstrate that the proposed algorithm is effective and accurate in identifying long-time delay nonlinear systems through the comparison with other methods.	algorithm;artificial neural network;broadcast delay;dynamical system;feedforward neural network;gradient;mathematical optimization;nonlinear system;particle swarm optimization;premature convergence;simulation;white noise	Min Han;Jianchao Fan;Bing Han	2009	2009 International Joint Conference on Neural Networks	10.1109/IJCNN.2009.5178662	feedforward neural network;mathematical optimization;probabilistic neural network;computer science;artificial intelligence;machine learning;time delay neural network;artificial neural network	ML	15.920091462336558	-25.44318774351586	15089
d4e1c6d6583451740e4c43651044f8bce46692aa	system identification using kernel-based regularization: new insights on stability and consistency issues	learning from examples;system identification;reproducing kernel hilbert spaces of dynamic systems;kernel-based regularization;bibo stability;regularization networks;generalization and consistency	Learning from examples is one of the key problems in science and engineering. It deals with function reconstruction from a finite set of direct and noisy samples.  Regularization in reproducing kernel Hilbert spaces  (RKHSs) is widely used to solve this task and includes powerful estimators such as regularization networks. Recent achievements include the proof of the statistical consistency of these kernel-based approaches. Parallel to this, many different system identification techniques have been developed but the interaction with machine learning does not appear so strong yet. One reason is that the RKHSs usually employed in machine learning do not embed the information available on dynamic systems, e.g. BIBO stability. In addition, in system identification the independent data assumptions routinely adopted in machine learning are never satisfied in practice. This paper provides some new results which strengthen the connection between system identification and machine learning. Our starting point is the introduction of RKHSs of dynamic systems. They contain functionals over spaces defined by system inputs and allow to interpret system identification as learning from examples. In both linear and nonlinear settings, it is shown that this perspective permits to derive in a relatively simple way conditions on RKHS stability (i.e. the property of containing only BIBO stable systems or predictors), also facilitating the design of new kernels for system identification. Furthermore, we prove the convergence of the regularized estimator to the optimal predictor under conditions typical of dynamic systems.	kernel (operating system);system identification	Gianluigi Pillonetto	2018	Automatica	10.1016/j.automatica.2018.03.065	mathematical optimization;hilbert space;kernel (linear algebra);dynamical system;bibo stability;nonlinear system;system identification;mathematics;regularization (mathematics);reproducing kernel hilbert space	ML	22.431371301750698	-34.05551176220662	15090
eb6c347d81066bdc428c8a7d1a5e21de3c2f9660	exploration and exploitation of high dimensional biological datasets using a wrapper approach based on strawberry plant algorithm		This paper presents a wrapper approach based on Strawberry Plant Algorithm (SPA) for gene selection in high dimension data classification problem by selecting the most relevant genes for each biological dataset. In order to perform an integrated exploration-exploitation approach to deal the near-optimal (small) gene subset problem obtained from high dimensional microarray data. First, a statistical filter is proposed for gene selection. After, a SPA is proposed to find the most informative genes from the previous gene selection, SPA is applied to explore and exploit new regions of this search and overall to overcome premature convergence. Empirical studies based in five public DNA-microarray datasets it is observed that our model gets the best performances using a smaller number of selected genes than other methods reported in the literature recently.	algorithm	Edmundo Bonilla Huerta;Roberto Morales-Caporal;M. Antonio Arjona-López	2018		10.1007/978-3-319-95933-7_38	artificial intelligence;support vector machine;pattern recognition;empirical research;machine learning;data classification;computer science;algorithm;exploit;microarray analysis techniques;premature convergence	ML	9.947829481670144	-43.57202951278102	15103
cd7b51fcd4d7c01cadff0ff58037368cab216bc0	classification by vertical and cutting multi-hyperplane decision tree induction	extraction information;modelizacion;piecewise linear;decision tree;analisis datos;information extraction;piecewise linear techniques;systeme aide decision;modele lineaire;prise de decision;clasificador;sistema ayuda decision;modelo lineal;arbol decision;data mining;classification;technique lineaire par morceau;discriminant analysis;modelisation;data analysis;decision support system;mixed integer program;classifier;data mining application;programacion mixta entera;linearisation morceau;fouille donnee;mathematical programming;multiple decision;discrimination analysis;linear model;security key;linearizacion trozo;piecewise linear models;classificateur;programmation partiellement en nombres entiers;mixed integer programming;decision multiple;analyse donnee;hiperplano;decision tree induction;classification accuracy;cle securite;toma decision;discriminacion;modeling;hyperplane;programmation mathematique;busca dato;arbre decision;programacion matematica;clasificacion;extraccion informacion;piecewise linearization;hyperplan;discrimination;llave seguridad	Two-group classification is a key task in decision making and data mining applications. We introduce two new mixed integer programming formulations that make use of multiple separating hyperplanes. They represent a generalization of previous piecewise-linear models that embed rules having the form of hyperplanes, which are used to successively separate the two groups. In fact, the classifiers obtained are particular types of decision trees which are allowed to grow in depth and not in width. Computational results show that our models achieve better classification accuracy in less time than previous approaches.	cross-sectional data;data mining;decision tree;eclipse;goal programming;linear model;linear programming;nonlinear system;programming model;scalability;tree structure	Marco Better;Fred Glover;Michele Samorani	2010	Decision Support Systems	10.1016/j.dss.2009.06.004	discrimination;systems modeling;decision support system;piecewise linear function;classifier;biological classification;computer science;hyperplane;machine learning;decision tree;linear model;data mining;data analysis;information extraction;algorithm	AI	8.922773213492244	-33.52574652024826	15104
115c79d3616c3070b663527b262ed6cce560c365	covering numbers for support vector machines	covering number;ucl;entropy numbers;kernel function;discovery;theses;conference proceedings;indexing terms;feature space;eigenvalues;support vector;strongly sequential;martingale limit theory;digital web resources;functional analysis;statistical learning theory;ucl discovery;large deviations performance;open access;integral operator;gaussian kernel;prediction with experts;ucl library;support vector machine;book chapters;open access repository;probably approximately correct;universal predicition;ucl research	Support vector (SV) machines are linear classifiers that use the maximum margin hyperplane in a feature space defined by a kernel function. Until recently, the only bounds on the generalization performance of SV machines (within Valiant’s probably approximately correct framework) took no account of the kernel used except in its effect on the margin and radius. More recently, it has been shown that one can bound the relevant covering numbers using tools from functional analysis. In this paper, we show that the resulting bound can be greatly simplified. The new bound involves the eigenvalues of the integral operator induced by the kernel. It shows that the effective dimension depends on the rate of decay of these eigenvalues. We present an explicit calculation of covering numbers for an SV machine using a Gaussian kernel, which is significantly better than that implied by previous results.	effective dimension;feature vector;kernel (operating system);linear classifier;linux;probably approximately correct learning;support vector machine;systemverilog	Ying Guo;Peter L. Bartlett;John Shawe-Taylor;Robert C. Williamson	1999		10.1145/307400.307467	functional analysis;support vector machine;kernel method;combinatorics;string kernel;radial basis function kernel;computer science;artificial intelligence;machine learning;data mining;mathematics;variable kernel density estimation;polynomial kernel;algorithm;statistics	ML	20.53384433056598	-33.249480152458325	15220
5365776e05723617dbb8094053de5db76e106833	nonconvex regularization for sparse genomic variant signal detection		Recent research suggests an overwhelming proportion of humans have genomic structural variants (SVs): rearrangements of regions in the genome such as inversions, insertions, deletions and duplications. The standard approach to detecting SVs in an unknown genome involves sequencing paired-reads from the genome in question, mapping them to a reference genome, and analyzing the resulting configuration of fragments for evidence of rearrangements. Because SVs occur relatively infrequently in the human genome, and erroneous read-mappings may suggest the presence of an SV, approaches to SV detection typically suffer from high false-positive rates. Our approach aims to more accurately distinguish true from false SVs in two ways: First, we solve a constrained optimization equation consisting of a negative Poisson log-likelihood objective function with an additive penalty term that promotes sparsity. Second, we analyze multiple related individuals simultaneously and enforce familial constraints. That is, we require any SVs predicted in children to be present in one of their parents. Our problem formulation decreases the false positive rate despite a large amount of error from both DNA sequencing and mapping. By incorporating additional information, we improve our model formulation and increase the accuracy of SV prediction methods.	constrained optimization;detection theory;futures studies;gene prediction;inversion (discrete mathematics);loss function;mathematical optimization;optimization problem;sensor;sparse matrix;systemverilog;utility functions on indivisible goods	Mario Banuelos;Lasith Adhikari;Rubi Almanza;Andrew Fujikawa;Jonathan Sahagun;Katharine Sanderson;Melissa Spence;Suzanne Sindi;Roummel F. Marcia	2017	2017 IEEE International Symposium on Medical Measurements and Applications (MeMeA)	10.1109/MeMeA.2017.7985889	false positive rate;human genome;constrained optimization;genome;detection theory;reference genome;poisson distribution;dna sequencing;mathematics;bioinformatics	Comp.	7.092540829344044	-51.21458204133046	15266
5d1053b6822f251c157757ae5d7d33dc00a11f41	"""correction to: """"on interactive fuzzy numbers"""" [fuzzy sets and systems 143(2004) 355-369]"""	fuzzy set;fuzzy number		fuzzy sets and systems	Robert Fullér;Péter Majlender	2005	Fuzzy Sets and Systems	10.1016/j.fss.2004.10.021	fuzzy logic;discrete mathematics;membership function;defuzzification;adaptive neuro fuzzy inference system;type-2 fuzzy sets and systems;fuzzy mathematics;fuzzy classification;computer science;artificial intelligence;fuzzy number;neuro-fuzzy;fuzzy measure theory;mathematics;fuzzy set;fuzzy associative matrix;fuzzy set operations;fuzzy control system	NLP	1.0288390008858173	-23.969542655633923	15303
539a16ba57089752dacfaf7f9b26b753c1af5f35	classification of ultrasound medical images using distance based feature selection and fuzzy-svm	medical image classification;fuzzy svm;feature selection	This paper presents a method of classifying ultrasound medical images towards dealing with two important aspects: (i) optimal feature subset selection for representing ultrasound medical images and (ii) improvement of classification accuracy by avoiding outliers. An objective function combining the concept of between-class distance and within-class divergence among the training dataset has been proposed as the evaluation criteria of feature selection. Searching for the optimal subset of features has been performed using Multi-Objective Genetic Algorithm (MOGA). Applying the proposed criteria, a subset of Grey Level Co-occurrence Matrix (GLCM) and Grey Level Run Length Matrix (GLRLM) based statistical texture descriptors have been identified that maximizes separability among the classes of the training dataset. To avoid the impact of noisy data during classification, Fuzzy Support Vector Machine (FSVM) has been adopted that reduces the effects of outliers by taking into account the level of significance of each training sample. The proposed approach of ultrasound medical image classification has been tested using a database of 679 ultrasound ovarian images and 89.60% average classification accuracy has been achieved.	co-occurrence matrix;computer vision;decision support system;feature selection;genetic algorithm;kullback–leibler divergence;linear separability;loss function;medical imaging;optimization problem;powera;run-length encoding;signal-to-noise ratio;support vector machine;visual descriptor	Abu Sayeed Md. Sohail;Prabir Bhattacharya;Sudhir P. Mudur;Srinivasan Krishnamurthy	2011		10.1007/978-3-642-21257-4_22	computer science;machine learning;pattern recognition;data mining;feature selection	Vision	11.632789031341067	-43.716147333669674	15356
748608ab5539a2834f447fb32d8420af0a757385	an efficient method to factorize fuzzy attribute-oriented concept lattices	fuzzy attribute oriented concept lattice;similarity relation	Factorization by similarity is a mathematical technique used in formal concept analysis with fuzzy attributes for reducing the complexity of different types of fuzzy concept lattices. In this paper we find the structure of the factor lattice of a fuzzy attributeoriented concept lattice, namely the intervals representing the blocks of this lattice. We provide a procedure for generating the infimum and the supremum concepts of these intervals as fixpoints of a fuzzy closure operator. This theoretical result allows to develop a more efficient algorithm for building the factor lattice of the fuzzy attribute-oriented concept lattice. A comparison between our approach and the existing algorithms is presented. © 2016 Elsevier B.V. All rights reserved.	algorithm;formal concept analysis;fuzzy concept	Gabriel Ciobanu;Cristian Vaideanu	2017	Fuzzy Sets and Systems	10.1016/j.fss.2016.07.004	fuzzy logic;combinatorics;discrete mathematics;defuzzification;type-2 fuzzy sets and systems;fuzzy mathematics;fuzzy classification;computer science;fuzzy subalgebra;fuzzy number;neuro-fuzzy;mathematics;lattice miner;fuzzy set operations	AI	-3.0595367659458317	-25.56700432830203	15450
92b1cf9ca8b429f082002a03f67bf474898b4517	remote sensing textual image classification based on extreme learning machine and hybrid rice optimization algorithm		In view of textual remote sensing image classification, a classification approach based on Extreme Learning Machine (ELM) in introduced. As the performance of ELM is mainly affected by the value of input weights and hidden biases genetic algorithm (GA) and particle swarm optimization algorithm (PSO) have been used to learn these parameters for ELM in order to improve the stability of extreme learning machine. However, these algorithms are easy to fall into the local optimum themselves. Therefore, the newly proposed hybrid rice optimization algorithm (HRO) is proposed to train the best parameters for ELM in the paper. To demonstrate the superior performance of the model, five UCI public data sets are tested firstly then the model is applied to distinguish some remote sensing textural images. Experimental results display that the proposed model is superior to other models involved in the paper, which is a very promising machine learning approach.	computer vision;elm;genetic algorithm;information privacy;local optimum;machine learning;mathematical optimization;particle swarm optimization	Yuqian Hou;Zhiwei Ye;Wei Xu;Lie Ma	2017	2017 9th IEEE International Conference on Intelligent Data Acquisition and Advanced Computing Systems: Technology and Applications (IDAACS)	10.1109/IDAACS.2017.8095194	local optimum;genetic algorithm;machine learning;computer vision;feature extraction;artificial intelligence;data modeling;extreme learning machine;remote sensing;computer science;contextual image classification;statistical classification;algorithm;particle swarm optimization;pattern recognition	Robotics	10.453947461688891	-41.870754162500035	15541
c317a257f6a6da795a7c6ad54897c6fe0e440196	bionet: an artificial neural network model for diagnosis of diseases	hard learning problem;xor problem;design and development;benchmark problem;multilayer feedforward neural network;parity checking;neck and arm pain diseases;backpropagation;a priori knowledge;diagnosis of diseases;learning problems;delta rule;multilayer feedforward neural network model;backpropagation learning;artificial neural network	An arti®cial neural network model called BIONET proposed in this paper, is used for diagnosis of diseases. The diseases are classi®ed based on a priori knowledge. BIONET is a multilayer feedforward neural network with known number of hidden nodes. Diagnosis of neck and arm pain diseases has been attempted as a case study using BIONET and the results are encouraging. The proposed model has also been tested for solving an important benchmark problem known as XOR problem. In this paper due attention is given for designing and developing an arti®cial neural network model, diagnosing diseases and solution strategy for solving XOR problem. Major applications of BIONET include diagnosis of diseases and parity checking. Quicker convergence during training is the main advantage of BIONET without loss of accuracy. Ó 2000 Elsevier Science B.V. All rights reserved.	artificial neural network;biosci;benchmark (computing);exclusive or;feedforward neural network;multilayer perceptron;network model;parity bit	S. Thamarai Selvi;S. Arumugam;L. Ganesan	2000	Pattern Recognition Letters	10.1016/S0167-8655(00)00027-1	a priori and a posteriori;simulation;delta rule;computer science;artificial intelligence;backpropagation;parity bit;machine learning;time delay neural network;artificial neural network	AI	14.126064745422713	-25.486244326618262	15560
a5c3158c5453c1d59b7f712194b5b860dcd73bb2	extending adaboost to iteratively vary its base classifiers	article	This paper introduces AdaBoost Dynamic, an extension of AdaBoost.M1 algorithm by Freund and Shapire. In this extension we use different “weak” classifiers in subsequent iterations of the algorithm, instead of AdaBoost’s fixed base classifier. The algorithm is tested with various datasets from UCI database, and results show that the algorithm performs equally well as AdaBoost with the best possible base learner for a given dataset. This result therefore relieves a machine learning analyst from having to decide which base classifier to use.	adaboost;algorithm;iteration;machine learning	Erico N. de Souza;Stan Matwin	2011		10.1007/978-3-642-21043-3_46	adaboost;brownboost;computer science;machine learning;pattern recognition;data mining;boosting	AI	14.82919423364982	-39.99873596221591	15595
8f72787f5c84b0299b3289510d029534e9430d5d	consensus clustering with robust evidence accumulation	median partition;clustering algorithm;clustering weighting;clustering selection;evidence accumulation clustering;clustering ensembles	Consensus clustering methodologies combine a set of partitions on the clustering ensemble providing a consensus partition. One of the drawbacks of the standard combination algorithms is that all the partitions of the ensemble have the same weight on the aggregation process. By making a differentiation among the partitions the quality of the consensus could be improved. In this paper we propose a novel formulation that tries to find a median-partition for the clustering ensemble process based on the evidence accumulation framework, but including a weighting mechanism that allows to differentiate the importance of the partitions of the ensemble in order to become more robust to noisy ensembles. Experiments on both synthetic and real benchmark data show the effectiveness of the proposed approach.	algorithm;benchmark (computing);cluster analysis;consensus (computer science);consensus clustering;dhrystone;experiment;mathematical optimization;tree accumulation	André Lourenço;Samuel Rota Bulò;Ana L. N. Fred;Marcello Pelillo	2013		10.1007/978-3-642-40395-8_23	correlation clustering;constrained clustering;data stream clustering;k-medians clustering;fuzzy clustering;flame clustering;computer science;canopy clustering algorithm;machine learning;consensus clustering;pattern recognition;cure data clustering algorithm;data mining;mathematics;cluster analysis;single-linkage clustering;brown clustering;dbscan;biclustering;clustering high-dimensional data;conceptual clustering	AI	1.6343533527926102	-41.10268926403307	15718
9c99d65d07cc1c5e7059cf8e0e67c57f3d161621	kernel-based clustering with automatic cluster number selection	cluster algorithm;pattern clustering;cluster number selection;k means;rival penalization data clustering kernel based clustering cluster number selection on line learning;matrix algebra;data clustering;rival penalization automatic cluster number selection kernel k means kernel based clustering methods kernel space online learning framework kecans prototype descriptor real valued matrix;degeneration;clustering method;rival penalization;number of clusters;learning artificial intelligence;pattern clustering learning artificial intelligence matrix algebra;local minima;prototypes kernel arrays clustering algorithms clustering methods indexes convergence;kernel based clustering;on line learning	Kernel k-means is one of the most well-known kernel-based clustering methods for discovering nonlinearly separable clusters. However, like its original counterpart k-means, kernel k-means has two inherent drawbacks: (1) it is easily trapped into degenerate local minima when the prototypes of clusters are ill-initialized, and (2) the actual number of clusters has to be provided in advance. Although some algorithms have been proposed to handle the first problem, there is still a lack of methods for automatically estimating the number of clusters in kernel space. In this paper, inspired by the on-line learning framework and the rival penalization mechanism, we propose a novel kernel-based clustering method with automatic cluster number selection (KeCans for short). In KeCans, prototypes are represented by a prototype descriptor, which is a real-valued matrix with each row representing a prototype. The prototype descriptor is allocated with more than the actual number of rows in initialization. Rival penalization is utilized in competition process to eliminate the redundant rows. Experimental results demonstrate the effectiveness of the proposed method in revealing the real number of clusters in kernel space. And compared with the state-of-the-art kernel-based clustering algorithms, the proposed method achieves comparable clustering results.	algorithm;cluster analysis;computer cluster;k-means clustering;kernel (operating system);maxima and minima;nonlinear system;online and offline;online machine learning;penalty method;prototype;user space	Chang-Dong Wang;Jianhuang Lai;Dong Huang	2011	2011 IEEE 11th International Conference on Data Mining Workshops	10.1109/ICDMW.2011.107	correlation clustering;kernel method;mathematical optimization;string kernel;kernel embedding of distributions;radial basis function kernel;computer science;machine learning;maxima and minima;pattern recognition;data mining;mathematics;cluster analysis;tree kernel;single-linkage clustering;variable kernel density estimation;polynomial kernel;k-means clustering	Vision	21.18746971606734	-40.95286752950808	15744
d6e01dcbc0e59b431cac1ee9c0617ccf25c4ac6a	minimum entropy clustering and applications to gene expression analysis	new clustering algorithm;posteriori probability;minimum entropy clustering;clustering algorithm;proposed criterion;conditional entropy;efficient iterative algorithm;minimum entropy;minimum entropy criterion;gene expression analysis;good criterion;hierarchical clustering;estimation theory;genetics;indexation;entropy;k means;iterative methods;nearest neighbor method;iterative algorithm	Clustering is a common methodology for analyzing the gene expression data. We present a new clustering algorithm from an information-theoretic point of view. First, we propose the minimum entropy (measured on a posteriori probabilities) criterion, which is the conditional entropy of clusters given the observations. Pane's inequality indicates that it could be a good criterion for clustering. We generalize the criterion by replacing Shannon's entropy with Havrda-Charvat's structural /spl alpha/-entropy. Interestingly, the minimum entropy criterion based on structural /spl alpha/-entropy is equal to the probability error of the nearest neighbor method when /spl alpha/ = 2. This is another evidence that the proposed criterion is good for clustering. With a nonparametric approach for estimating a posteriori probabilities, an efficient iterative algorithm is then established to minimize the entropy. The experimental results show that the clustering algorithm performs significantly better than k-means/medians, hierarchical clustering, SOM, and EM in terms of adjusted Rand index. Particularly, our algorithm performs very well even when the correct number of clusters is unknown. In addition, most clustering algorithms produce poor partitions in presence of outliers while our method can correctly reveal the structure of data and effectively identify outliers simultaneously.	algorithm;artocarpus heterophyllus ab.ige:acnc:pt:ser:qn;conditional entropy;eisenstein's criterion;estimated;gene expression;hierarchical clustering;information theory;iterative method;k-means clustering;nearest neighbor search;probability;rand index;shannon (unit);single linkage cluster analysis;social inequality;statistical cluster	Haifeng Li;Keshu Zhang;Tao Jiang	2004	Proceedings. 2004 IEEE Computational Systems Bioinformatics Conference, 2004. CSB 2004.	10.1109/CSB.2004.1332427	correlation clustering;constrained clustering;determining the number of clusters in a data set;joint entropy;binary entropy function;transfer entropy;k-medians clustering;fuzzy clustering;maximum entropy probability distribution;principle of maximum entropy;canopy clustering algorithm;machine learning;pattern recognition;cure data clustering algorithm;mathematics;iterative method;cluster analysis;genetics;conditional entropy;statistics	ML	2.6422153500033794	-40.99227576774085	15757
69769cbade5749dc866e0892d32ffc4fc4e79a11	quantifying the resilience of machine learning classifiers used for cyber security		The use of machine learning algorithms for cyber security purposes gives rise to questions of adversarial resilience, namely: Can we quantify the effort required of an adversary to manipulate a system that is based on machine learning techniques? Can the adversarial resilience of such systems be formally modeled and evaluated? Can we quantify this resilience such that different systems can be compared using empiric metrics? Past works have demonstrated how an adversary can manipulate a system based on machine learning techniques by changing some of its inputs. However, comparatively little work has emphasized the creation of a formal method for measuring and comparing the adversarial resilience of different machine learning models to these changes. In this work we study the adversarial resilience of detection systems based on supervised machine learning models. We provide a formal definition for adversarial resilience while focusing on multisensory fusion systems. We define the model robustness (MRB) score, a metric for evaluating the relative resilience of different models, and suggest two novel feature selection algorithms for constructing adversary aware classifiers. The first algorithm selects only features that cannot realistically be modified by the adversary, while the second algorithm allows control over the resilience versus accuracy tradeoff. Finally, we evaluate our approach with a real-life use case of dynamic malware classification using an extensive, up-to-date corpus of benign and malware executables. We demonstrate the potential of using adversary aware feature selection for building more resilient classifiers and provide empirical evidence supporting the inherent resilience of ensemble algorithms compared to single model algorithms.	adversarial machine learning;adversary (cryptography);algorithm;computer security;cyber resilience;ensemble learning;executable;feature selection;formal methods;malware;real life;supervised learning	Ziv Katzir;Yuval Elovici	2018	Expert Syst. Appl.	10.1016/j.eswa.2017.09.053	machine learning;data mining;robustness (computer science);psychological resilience;adversary model;artificial intelligence;malware;adversary;computer security;computer science;adversarial system;formal methods;feature selection	Security	18.427954397668472	-51.37113857079173	15767
1d87ed479a84f8266c173774e925af40b2bf6d5c	fnm-based and rfcm-based fuzzy clustering for tri-relational data	standard regularization fnm based fuzzy clustering rfcm based fuzzy clustering trirelational data data points fuzzy nonmetric model relational fuzzy c means entropy regularization;relational databases entropy fuzzy set theory numerical analysis pattern clustering	In this paper, some fuzzy clustering methods are proposed for relational data which represents the dissimilarity for triples of data points. One method is based on the fuzzy nonmetric model and the other is on the relational fuzzy c-means. Each method has two options of fuzzification; the standard and the entropy-regularization. Through some numerical experiments, the feature of the proposed methods is discussed.	cluster analysis;data point;experiment;fuzzy clustering;fuzzy set;numerical analysis;triangular function	Yuchi Kanzawa	2012	The 6th International Conference on Soft Computing and Intelligent Systems, and The 13th International Symposium on Advanced Intelligence Systems	10.1109/SCIS-ISIS.2012.6505050	membership function;defuzzification;fuzzy clustering;flame clustering;fuzzy classification;computer science;fuzzy number;neuro-fuzzy;machine learning;pattern recognition;fuzzy measure theory;data mining;mathematics;fuzzy set;fuzzy associative matrix;fuzzy set operations	Robotics	2.696330593341922	-39.8254420701603	15793
a815a1c11c46707ef3dea75aed17a1e8f7399fd9	multi-k machine learning ensembles		Ensemble machine learning models often surpass single models in classification accuracy at the expense of higher computational requirements during training and execution. In this paper we present a novel ensemble algorithm called Multi-K which uses unsupervised clustering as a form of dataset preprocessing to create component models that lead to effective and efficient ensembles. We also present a modification of Multi-K that we call Multi-KX that incorporates a metalearner to help with ensemble classifications. We compare our algorithms to several existing algorithms in terms of classification accuracy and computational speed.	algorithm;cluster analysis;ensemble kalman filter;machine learning;preprocessor;requirement	Matthew Whitehead;Larry S. Yaeger	2012			cluster analysis;ensemble learning;artificial intelligence;machine learning;preprocessor;computer science	ML	12.331344617169593	-41.30707117929448	15842
075bd4ffdac8b3d3a2039b90cbc0619408d2905a	a comparison of methods for rule subset selection applied to associative classification		This paper presents Garss, a new algorithm for rule subset selection based on genetic algorithms, which uses the area under the ROC curve – AUC – as fitness function. Garss is a post-processing method that can be applied to any rule learning algorithm. In this work, Garss is analysed in the context of associative classification, where an association rule algorithm generates a set rules to be used as a classifier. An experimental evaluation was performed in order to analyse the behaviour of the proposed method. Results are compared with Roccer, a recently proposed algorithm for rule subset selection based on ROC analysis.	apriori algorithm;association rule learning;c4.5 algorithm;combining rules;experiment;fitness function;genetic algorithm;receiver operating characteristic;video post-processing	Gustavo E. A. P. A. Batista;Claudia Regina Milaré;Ronaldo C. Prati;Maria Carolina Monard	2006	Inteligencia Artificial, Revista Iberoamericana de Inteligencia Artificial		genetic algorithm;computer science;machine learning;pattern recognition;data mining;receiver operating characteristic	AI	9.04262004956373	-42.04656320137377	15927
8a357857cb5d38adce1ec0f3765e82dd60d86a2f	mutual information estimation with random forests	part of book or chapter of book	We present a new method for estimating mutual information based on the random forests classifiers. This method uses random permutation of one of the two variables to create data where the two variables are independent. We show that mutual information can be estimated by the class probabilities of a probabilistic classifier trained on the independent against the dependent data. This method has the robustness and flexibility that random forests offers as well as the possibility to use mixtures of continuous and discrete data, unlike most other approaches for estimating mutual information. We tested our method on a variety of data and found it to be accurate with medium or large datasets yet inaccurate with smaller datasets. On the positive side, our method is capable to estimate the mutual information between sets of both continuous and discrete variables and appears to be relatively insensitive to the addition of noise variables.	mutual information;random forest	Mike Koeman;Tom Heskes	2014		10.1007/978-3-319-12640-1_63	computer science;artificial intelligence;operations research	Vision	16.629641636897738	-37.95299307305805	15973
1aaa7845905800988478fb1c497af09838bd8c57	detecting changes in rare patterns from data streams		Current drift detection techniques in data streams focus on finding changes in streams with labeled data intended for supervised machine learning methods. Up to now there has been no research that considers drift detection on item based data streams with unlabeled data intended for unsupervised association rule mining. In this paper we address and discuss the current issues in performing drift detection of rare patterns in data streams and present a working approach that enables the detection of rare pattern changes. We propose a novel measure, called the M measure, that facilitates pattern change detection and through our experiments we show that this measure can be used to detect changes in rare patterns in data streams efficiently and accurately.	sensor	David Tse Jung Huang;Yun Sing Koh;Gillian Dobbie;Russel Pears	2014		10.1007/978-3-319-06605-9_36	labeled data;computer science;data mining;streams;data stream;data stream mining;change detection;association rule learning	DB	-0.3404409873354862	-35.65924200288441	15991
006f30d436fe1db192d8e5e4be4a21cdec03f56d	a divide-and-conquer method for multi-net classifiers	classifier fusion;unsupervised learning;fusion classificateur;methode diviser pour regner;eficacia sistema;classifier combination;learning algorithm;supervised learning;combinaison classificateur;taux erreur;performance systeme;metodo dividir para vencer;apprentissage non supervise;algorithme apprentissage;system performance;multiple classifiers;clustering;clustering method;divide and conquer method;classification system;pattern classification;pattern recognition;error rate;systeme classificateur multiple;reconnaissance forme;apprentissage supervise;reseau neuronal;reconocimiento patron;indice error;multiple classifier system;algoritmo aprendizaje;divide and conquer;red neuronal;neural network;classification forme	Several researchers have shown that substantial improvements can be achieved in difficult pattern recognition problems by combining the outputs of multiple neural networks. In this work, we present and test a pattern classification multi-net system based on both supervised and unsupervised learning. Following the ‘divide-and-conquer’ framework, the input space is partitioned into overlapping subspaces and neural networks are subsequently used to solve the respective classification subtasks. Finally, the outputs of individual classifiers are appropriately combined to obtain the final classification decision. Two clustering methods have been applied for input space partitioning and two schemes have been considered for combining the outputs of the multiple classifiers. Experiments on well-known data sets indicate that the multi-net classification system exhibits promising performance compared with the case of single network training, both in terms of error rates and in terms of training speed (especially if the training of the classifiers is done in parallel).	algorithm;artificial neural network;benchmark (computing);cluster analysis;experiment;memory-level parallelism;mixture model;norm (social);pattern recognition;portable document format;primary direction;probabilistic turing machine;space partitioning;supervised learning;support vector machine;test set;unsupervised learning;weight function	Dimitrios Frosyniotis;Andreas Stafylopatis;Aristidis Likas	2003	Pattern Analysis & Applications	10.1007/s10044-002-0174-6	random subspace method;unsupervised learning;divide and conquer algorithms;word error rate;computer science;artificial intelligence;machine learning;pattern recognition;cluster analysis;supervised learning;library classification	ML	10.484287280768761	-33.12441577317344	15993
d43086414f3096703857c3869d2f7b2ec2d48e28	nearest neighbor classification by partially fuzzy clustering	unsupervised learning;cluster algorithm;fuzzy clustering method;pattern clustering;partially clustering;classification algorithm;cluster based training algorithm;k nearest neighbours knn;computer model;partially clustering classification k nearest neighbours knn representatives;representatives;training;testing phase;classification;fuzzy set theory;data model;training data;accuracy;fuzzy clustering;computational modeling;model building;computational complexity;training classification algorithms clustering algorithms training data data models accuracy computational modeling;linear time;classification algorithms;linear time complexity nearest neighbor classification partially fuzzy clustering k nearest neighbour data classification testing phase knn model based classifier model building problem cluster based training algorithm fuzzy clustering method unsupervised learning;pattern classification;clustering algorithms;model building problem;linear time complexity;partially fuzzy clustering;k nearest neighbour;data classification;nearest neighbor classification;knn model based classifier;training algorithm;data models;unsupervised learning computational complexity fuzzy set theory pattern classification pattern clustering	The k-Nearest-Neighbours(kNN) is a simple and effective method for data classification. One of the major drawbacks of kNN is its low efficiency in its testing phase due to the lack of an explicit classification model. Recently, kNN model-based classifiers have been proposed to improve the conventional kNN. However, their building incurs high computational costs. In this paper, we tackle the model building problem by developing a cluster-based training algorithm to learn an optimized set of representatives that approximate the distributions of training data. The training algorithm adopts a fuzzy clustering method for unsupervised learning on the partial training set, and has a linear time complexity with respect to the size of the set. The experimental results conducted on real-world datasets demonstrate that the new method outperforms the previous kNN model-based classifier in the accuracy and possesses outstanding efficiency compared to kNN based classifiers.	approximation algorithm;cluster analysis;computation;effective method;fuzzy clustering;k-nearest neighbors algorithm;test set;time complexity;unsupervised learning	Lifei Chen;Gongde Guo;Shengrui Wang	2012	2012 26th International Conference on Advanced Information Networking and Applications Workshops	10.1109/WAINA.2012.23	unsupervised learning;time complexity;data modeling;training set;model building;fuzzy clustering;biological classification;data model;computer science;machine learning;pattern recognition;data mining;accuracy and precision;fuzzy set;cluster analysis;computational complexity theory;computational model	AI	12.271499441938962	-40.71826004698751	16016
744e4967c5dce1e4d8f31a649202f98e70d6deb7	variable density based clustering	complexity theory;data mining;shape;merging;linear programming;clustering algorithms;optimization	The class of density-based clustering algorithms excels in detecting clusters of arbitrary shape. DBSCAN, the most common representative, has been demonstrated to be useful in a lot of applications. Still the algorithm suffers from two drawbacks, namely a non-trivial parameter estimation for a given dataset and the limitation to data sets with constant cluster density. The first was already addressed in our previous work, where we presented two hierarchical implementations of DBSCAN. In combination with a simple optimization procedure, those proofed to be useful in detecting appropriate parameter estimates based on an objective function. However, our algorithm was not capable of producing clusters of differing density. In this work we will use the hierarchical information to extract variable density clusters and nested cluster structures. Our evaluation shows that the clustering approach based on edge-lengths of the dendrogram or based on area estimates successfully detects clusters of arbitrary shape and density.	algorithm;alpha shape;approximation;cluster analysis;dbscan;dendrogram;estimation theory;experiment;level of detail;loss function;mathematical optimization;optimization problem;sensor;shape analysis (digital geometry)	Alexander Dockhorn;Christian Braune;Rudolf Kruse	2016	2016 IEEE Symposium Series on Computational Intelligence (SSCI)	10.1109/SSCI.2016.7849925	correlation clustering;mathematical optimization;determining the number of clusters in a data set;subclu;k-medians clustering;fuzzy clustering;machine learning;data mining;mathematics;hierarchical clustering;cluster analysis;single-linkage clustering;dbscan;optics algorithm;hierarchical clustering of networks;clustering high-dimensional data	ML	0.34887232219228637	-40.4848416282735	16037
013dbe183759b858c83e03105c1138c09b4746c0	learning bounds via sample width for classifiers on finite metric spaces	learning algorithms;generalization error;qa mathematics;qa75 electronic computers computer science;machine learning	In a recent paper [M. Anthony, J. Ratsaby, Maximal width learning of binary functions, Theoretical Computer Science 411 (2010) 138-147] the notion of sample width for binary classifiers mapping from the real line was introduced, and it was shown that the performance of such classifiers could be quantified in terms of this quantity. This paper considers how to generalize the notion of sample width so that we can apply it where the classifiers map from some finite metric space. By relating the learning problem to one involving the domination numbers of certain graphs, we obtain generalization error bounds that depend on the sample width and on certain measures of u0027densityu0027 of the underlying metric space. We also discuss how to employ a greedy set-covering heuristic to bound generalization error.	approximation algorithm;generalization error;graph theory;greedy algorithm;heuristic;vc dimension	Martin Anthony;Joel Ratsaby	2014	Theor. Comput. Sci.	10.1016/j.tcs.2013.07.004	combinatorics;discrete mathematics;computer science;machine learning;mathematics;algorithm;statistics;algebra;generalization error	AI	20.539450986236364	-32.157911941820316	16066
49368c6296766321dc1a7a3ffa54a21399b8dc6f	active learning with model selection in linear regression	importance sampling;sequential learning;batch learning;regression. covariate shift;active learning;generalization error;model selection;regression;linear regression	Optimally designing the location of training input points (active learning) and choosing the best model (model selection) are two important components of supervised learning and have been studied extensively. However, these two issues seem to have been investigated separately as two independent problems. If training input points and models are simultaneously optimized, the generalization performance would be further improved. In this paper, we propose a new approach called ensemble active learning for solving the problems of active learning and model selection at the same time. We demonstrate by numerical experiments that the proposed method compares favorably with alternative approaches such as iteratively performing active learning and model selection in a sequential manner.	experiment;model selection;numerical analysis;supervised learning	Masashi Sugiyama;Neil Rubens	2008		10.1137/1.9781611972788.47	model selection;linear predictor function;supervised learning;machine learning;active learning;pattern recognition;artificial intelligence;computer science;proper linear model;principal component regression;linear model;linear probability model	ML	22.52054797262293	-34.18603240188267	16091
032fdf5c6a3a005acc93ce42de77801f6b0e4154	learning with feature feedback: from theory to practice		In supervised learning, a human annotator only needs to assign each data point (document, image, etc.) its correct label. But in many situations, the human can also provide richer feedback at essentially no extra cost. In this paper, we examine a particular type of feature feedback that has been used, with some success, in information retrieval and in computer vision. We formalize two models of feature feedback, give learning algorithms for them, and quantify their usefulness in the learning process. Our experiments also show the efficacy of these methods.	algorithm;computer vision;data point;experiment;feedback;information retrieval;machine learning;supervised learning	Stefanos Poulis;Sanjoy Dasgupta	2017			machine learning;algorithmic learning theory;artificial intelligence;error-driven learning;computer science	ML	16.363206216203103	-35.53338852069447	16186
1622f0de2d24225ef6ea21003fa94d4a5836aac8	deep bottleneck feature for image classification	bof;t technology;image classification;transfer learning;cnn	Effective image representation plays an important role for image classification and retrieval. Bag-of-Features (BoF) is well known as an effective and robust visual representation. However, on large datasets, convolutional neural networks (CNN) tend to perform much better, aided by the availability of large amounts of training data. In this paper, we propose a bag of Deep Bottleneck Features (DBF) for image classification, effectively combining the strengths of a CNN within a BoF framework. The DBF features, obtained from a previously well-trained CNN, form a compact and low-dimensional representation of the original inputs, effective for even small datasets. We will demonstrate that the resulting BoDBF method has a very powerful and discriminative capability that is generalisable to other image classification tasks.	artificial neural network;computer vision;convolutional neural network	Yan Song;Ian Vince McLoughlin;Li-Rong Dai	2015		10.1145/2671188.2749314	computer vision;contextual image classification;transfer of learning;computer science;machine learning;pattern recognition	Vision	24.500364944136415	-51.907805845555515	16219
a4b66678d1de93a3f8bc21bdb7cd0110bc303331	investigating heterogeneous ensembles with filter feature selection for software effort estimation		Ensemble Effort Estimation (EEE) consists on predicting the software development effort by combining more than one single estimation technique. EEE has recently been investigated in software development effort estimation (SDEE) in order to improve the estimation accuracy. The overall results suggested that the EEE yield better prediction accuracy than single techniques. On the other hand, feature selection (FS) methods have been used in the area of SDEE for the purpose of reducing the dimensionality of a dataset size by eliminating the irrelevant and redundant features. Thus, the SDEE techniques are trained on a dataset with relevant features which can lead to improving the accuracy of their estimations. This paper aims at investigating the impact of two Filter feature selection methods: Correlation based Feature Selection (CFS) and RReliefF on the estimation accuracy of Heterogeneous (HT) ensembles. Four machine learning techniques (K-Nearest Neighbor, Support Vector Regression, Multilayer Perceptron and Decision Trees) were used as base techniques for the HT ensembles of this study. We evaluate the accuracy of these HT ensembles when their base techniques were trained on datasets preprocessed by the two feature selection methods. The HT ensembles use three combination rules: average, median, and inverse ranked weighted mean. The evaluation was carried out by means of eight unbiased accuracy measures through the leave-one-out-cross validation (LOOCV) technique over six datasets. The overall results suggest that all the attributes of most datasets used are relevant for building an accurate predictive technique since the ensembles constructed without features selection outperformed in general the ones using features selection. As for the combination rule, the median generally produces better results than the other two used in this empirical study.	climate forecast system;cross-validation (statistics);decision tree;embedded system;feature selection;filesystem-level encryption;heterogeneous computing;k-nearest neighbors algorithm;machine learning;memory-level parallelism;multilayer perceptron;preprocessor;relevance;security device event exchange;software development effort estimation;support vector machine	Mohamed Hosni;Ali Idri;Alain Abran	2017		10.1145/3143434.3143456	software development effort estimation;curse of dimensionality;support vector machine;decision tree;feature selection;artificial intelligence;machine learning;multilayer perceptron;ranking;pattern recognition;weighted arithmetic mean;computer science	HCI	11.2710837046658	-40.88206303455252	16228
2e905896cf513e54a19b3bab78234ed6c9d89e23	convergent learning: do different neural networks learn the same representations?		Recent successes in training large, deep neural networks have prompted active investigation into the representations learned on their intermediate layers. Such research is difficult because it requires making sense of non-linear computations performed by millions of learned parameters, but valuable because it increases our ability to understand current models and training algorithms and thus create improved versions of them. In this paper we investigate the extent to which neural networks exhibit what we call convergent learning, which is when the representations learned by multiple nets converge to a set of features which are either individually similar between networks or where subsets of features span similar lowdimensional spaces. We propose a specific method of probing representations: training multiple networks and then comparing and contrasting their individual, learned representations at the level of neurons or groups of neurons. We begin research into this question by introducing three techniques to approximately align different neural networks on a feature or subspace level: a bipartite matching approach that makes one-to-one assignments between neurons, a sparse prediction and clustering approach that finds one-to-many mappings, and a spectral clustering approach that finds many-to-many mappings. This initial investigation reveals a few interesting, previously unknown properties of neural networks, and we argue that future research into the question of convergent learning will yield many more. The insights described here include (1) that some features are learned reliably in multiple networks, yet other features are not consistently learned; (2) that units learn to span low-dimensional subspaces and, while these subspaces are common to multiple networks, the specific basis vectors learned are not; (3) that the representation codes are a mix between a local (single unit) code and slightly, but not fully, distributed codes across multiple units; (4) that the average activation values of neurons vary considerably within a network, yet the mean activation values across different networks converge to an almost identical distribution. 1	algorithm;align (company);artificial neural network;basis (linear algebra);cluster analysis;code;computation;converge;deep learning;many-to-many;matching (graph theory);neuron;nonlinear system;one-to-many (data model);one-to-one (data model);sparse matrix;spectral clustering	Yixuan Li;Jason Yosinski;Jeff Clune;Hod Lipson;John E. Hopcroft	2015			computer science;artificial intelligence;machine learning;data mining;mathematics	ML	21.20187169696668	-49.88127692816823	16247
4d90063c2cc54ec60a6a55d29eedcf2ba234dca8	boosting learning machines with function compositions to avoid local minima in regression problems	boosting machine learning neural networks support vector machines educational institutions guidelines learning systems mathematical model least squares methods size measurement;probability;mathematical functions composition;support vector machines;additive model;learning methods;cascaded learning method;svm;regression analysis;learning artificial intelligence;local minima;boosting learning machine;svm boosting learning machine regression problem cascaded learning method mathematical functions composition probability;regression problem;support vector machines learning artificial intelligence regression analysis	We present an improved cascaded learning method that is based on mathematical functions compositions, instead of additive models as normally done in boosting approaches. Regression experiments are done to support the usefulness of this architecture and training procedure. The method allows to produce a strong learner with increased probability of avoiding local minima.	additive model;experiment;maxima and minima	Pablo Zegers;Gonzalo Correa	2007	2007 International Joint Conference on Neural Networks	10.1109/IJCNN.2007.4371263	semi-supervised learning;unsupervised learning;support vector machine;least squares support vector machine;instance-based learning;algorithmic learning theory;computer science;artificial intelligence;online machine learning;machine learning;pattern recognition;stability;computational learning theory;active learning;gradient boosting;boosting;artificial neural network;generalization error	Vision	15.41810903621106	-33.0569191788052	16256
ac5c44620123e26aec3714b1b039828e6259a80b	an adaptive graph learning method based on dual data representations for clustering		Abstract Adaptive graph learning methods for clustering, which adjust a data similarity matrix while taking into account its clustering capability, have drawn increasing attention in recent years due to their promising clustering performance. Existing adaptive graph learning methods are based on either original data or linearly projected data and thus rely on the assumption that either representation is a good indicator of the underlying data structure. However, this assumption is sometimes not met in high dimensional data. Studies have shown that high-dimensional data in many problems tend to lie on an embedded nonlinear manifold structure. Motivated by this observation, in this paper, we develop dual data representations, i.e., original data and a nonlinear embedding of the data obtained via an Extreme Learning Machine (ELM)-based neural network, and propose to use them as the more reliable basis for graph learning. The resulting algorithm based on ELM and Constrained Laplacian Rank (ELM-CLR) further improves the clustering capability and robustness, while retaining the advantages of adaptive graph learning, such as not requiring any post-processing to extract cluster indicators. The empirical study shows that the proposed algorithm outperforms the state-of-the-art graph-based clustering methods on a broad range of benchmark datasets.	cluster analysis	Tianchi Liu;Chamara Kasun Liyanaarachchi Lekamalage;Guang-Bin Huang;Zhiping Lin	2018	Pattern Recognition	10.1016/j.patcog.2017.12.001	machine learning;robustness (computer science);artificial neural network;cluster analysis;nonlinear system;extreme learning machine;pattern recognition;clustering high-dimensional data;mathematics;artificial intelligence;embedding;data structure	Vision	24.152170816883118	-42.69682862485409	16341
2633d2ff1c70c1f6bb9285915616ca4909c77f36	feature selection by genetic algorithms to improve ranking and classification models			feature selection;genetic algorithm	Sérgio Francisco da Silva	2011				NLP	9.176276182379953	-40.666704580182376	16342
821c1e493e7c9d78fb27759a5eaef355b95890cc	linear density-based clustering with a discrete density model		Density-based clustering techniques are used in a wide range of data mining applications. One of their most attractive features consists in not making use of prior knowledge of the number of clusters that a dataset contains along with their shape. In this paper we propose a new algorithm named Linear DBSCAN (Lin-DBSCAN), a simple approach to clustering inspired by the density model introduced with the well known algorithm DBSCAN. Designed to minimize the computational cost of density based clustering on geospatial data, Lin-DBSCAN features a linear time complexity that makes it suitable for real-time applications on low-resource devices. Lin-DBSCAN uses a discrete version of the density model of DBSCAN that takes advantage of a grid-based scan and merge approach. The name of the algorithm stems exactly from its main features outlined above. The algorithm was tested with well known data sets. Experimental results prove the efficiency and the validity of this approach over DBSCAN 1 ar X iv :1 80 7. 08 15 8v 1 [ cs .L G ] 2 1 Ju l 2 01 8 in the context of spatial data clustering, enabling the use of a densitybased clustering technique on large datasets with low computational cost.	algorithm;algorithmic efficiency;big data;cluster analysis;computation;computer vision;curse of dimensionality;dbscan;data mining;pattern recognition;real-time clock;requirement;time complexity;whole earth 'lectronic link	Roberto Pirrone;Vincenzo Cannella;Sergio Monteleone;Gabriella Giordano	2018	CoRR		grid;geospatial analysis;time complexity;machine learning;spatial analysis;artificial intelligence;cluster analysis;mathematics;dbscan;data set;linear density	ML	-1.0548897418924683	-40.271888039885376	16405
c87fd5ea81b9f278b9153f9b30e6f2345029eedc	filter-based deep-compression with global average pooling for convolutional networks		Deep neural networks are powerful, but using these networks is both memory and time consuming for their numerous parameters and large amounts of computation. There are many studies in compressing the models. On the parameter-level, one of the compressing methods is to spend lots of time performing the iterative process consisting of pruning weights and fine-tuning the models. On the bit-level, many studies use quantization to cut down on the number of need bits. Hence, we propose an efficient strategy to compress on the layers which are computation or memory consuming. We compress the model by adding the global average pooling, iteratively pruning on the filters with proposed order-deciding scheme to prune more efficiently, applying the truncated SVD to the fully-connected layer, and performing the two-stage quantization. Experiments on the VGG16 model show that we can reach a 60.9× compression ratio in off-line storage with about 0.848% and 0.1378% loss of accuracy on the top-1 and top-5 classification results with the validation dataset of ILSVRC2012.		Ting-Yun Hsiao;Yung-Chang Chang;Ching-Te Chiu	2018	2018 IEEE International Workshop on Signal Processing Systems (SiPS)	10.1109/SiPS.2018.8598453	compression ratio;algorithm;memory management;parallel computing;computation;quantization (signal processing);pooling;artificial neural network;iterative and incremental development;singular value decomposition;computer science	Vision	21.285433089765213	-49.14088640773876	16435
c1a7ceeb72fda9c4095644c13cb7b345119f20cf	deep learning: an introduction for applied mathematicians		Multilayered artificial neural networks are becoming a pervasive tool in a host of application fields. At the heart of this deep learning revolution are familiar concepts from applied and computational mathematics; notably, in calculus, approximation theory, optimization and linear algebra. This article provides a very brief introduction to the basic ideas that underlie deep learning from an applied mathematics perspective. Our target audience includes postgraduate and final year undergraduate students in mathematics who are keen to learn about the area. The article may also be useful for instructors in mathematics who wish to enliven their classes with references to the application of deep learning techniques. We focus on three fundamental questions: what is a deep neural network? how is a network trained? what is the stochastic gradient method? We illustrate the ideas with a short MATLAB code that sets up and trains a network. We also show the use of state-of-the art software on a large scale image classification problem. We finish with references to the current literature.	approximation theory;artificial neural network;computational mathematics;computer vision;deep learning;gradient method;graphic art software;linear algebra;matlab;mathematical optimization;pervasive informatics	Catherine F. Higham;Desmond J. Higham	2018	CoRR		mathematical optimization;approximation theory;mathematics;overfitting;mathematics education;linear algebra;computational mathematics;artificial neural network;deep learning;target audience;software;artificial intelligence	ML	20.439833375571528	-36.21898332682032	16493
0ad62aaf1e931f981a2bb50628f6b7e03c0c5d83	an algorithm combining discrete and continuous methods for optical mapping	discrete optimization;maximum likelihood;combinatorial algorithm;false negative;continuous optimization;false positive;continuation method;optical mapping;em algorithm;restriction maps	Optical mapping is a novel technique for generating the restriction map of a DNA molecule by observing many single, partially digested, copies of it, using fluorescence microscopy. The real-life problem is complicated by numerous factors: false positive and false negative cut observations, inaccurate location measurements, unknown orientations and faulty molecules. We present an algorithm for solving the real-life problem. The algorithm combines continuous optimization and combinatorial algorithms, applied to a non-uniform discretization of the data. We present encouraging results on real experimental data.	continuous optimization;copy (object);discretization;mathematical optimization;mental orientation;microscopy, fluorescence;optical mapping;real life;voltage-sensitive dye imaging;algorithm	Richard M. Karp;Itsik Pe'er;Ron Shamir	1999	Proceedings. International Conference on Intelligent Systems for Molecular Biology	10.1089/106652701446189	discrete optimization;mathematical optimization;combinatorics;optical mapping;discrete mathematics;type i and type ii errors;expectation–maximization algorithm;restriction map;mathematics;maximum likelihood;continuous optimization;statistics	Robotics	1.9684681896383176	-51.352742107468565	16494
6fcfc6445ffa584c930e0c679328ca9ae2f0c357	a brief discussion on moderatism based local gradient learning rules	learning experience;neural nets;backpropagation;neural net;neurons error correction neural networks multi layer neural network biological system modeling cost function artificial neural networks backpropagation algorithms equations;signal processing;error backpropagation rule local gradient learning rules ann learning rule artificial neural networks neurons potential moderatism based local pattern learning experiment error based weight update rule;signal processing neural nets backpropagation	"""Moderatism [Y. Okabe et al., 1988], which is a learning rule for ANNs, is based on the principle that individual neurons and neural nets as a whole try to sustain a """"moderate"""" level in their input and output signals. In this way, a close mutual relationship with the outside environment is maintained. In this paper, two potential moderatism-based local, gradient learning rules are proposed. Then, a pattern learning experiment is performed to compare the learning performances of these two learning rules, the error based weight update (EBWU) rule [Tanvir Islam, M et al., December 2001][Tanvir Islam, M et al., September 2001], and error backpropagation [Bishop, CM et al., 1995]."""		Mohammad Tanvir Islam;Yoichi Okabe	2003		10.1109/ISSPA.2003.1224858	types of artificial neural networks;delta rule;computer science;artificial intelligence;backpropagation;machine learning;pattern recognition;deep learning;artificial neural network	ML	15.868471614071929	-29.408095345429498	16534
4f521264ccb7ca45e0e3955ec0824908983a7185	a probabilistic measure of similarity for binary data in pattern recognition	image processing;measurement;analisis datos;binary image;procesamiento imagen;classification;traitement image;similitude;data analysis;medida;image binaire;pattern recognition;imagen binaria;analyse donnee;mesure;binary data;reconnaissance forme;similitud;reconocimiento patron;clasificacion	A new index of association, or proximity, between binary vectors that represent features, or characteristics of objects. The proposed index, called the permutation index, is the probability of achieving no more than the observed number of matches under a random labelling, or permutation, hypothesis	binary data;pattern recognition	Xiaobo Li;Richard C. Dubes	1989	Pattern Recognition	10.1016/0031-3203(89)90049-6	random binary tree;computer vision;binary image;image processing;biological classification;computer science;artificial intelligence;similitude;pattern recognition;mathematics;bit-reversal permutation;data analysis;measurement;statistics	Vision	8.577358041538083	-34.672445744926165	16537
e3f5405d91f45d66e5562c442b9262d597247e28	substring count estimation in extremely long strings	tecnologia electronica telecomunicaciones;base donnee;metodo arborescente;string database;count q gram tree;database;count estimation;base dato;algorithme;algorithm;indexing;indexation;count suffix tree;indizacion;tree structured method;appariement chaine;methode arborescente;tecnologias;string matching;grupo a;count qgram tree;algoritmo	To estimate the number of substring matches against string data, count suffix trees (CS-tree) have been used as a kind of alphanumeric histograms. Although the trees are useful for substring count estimation in short data strings (e.g. name or title), they reveal several drawbacks when the target is changed to extremely long strings. First, it becomes too hard or at least slow to build CS-trees, because their origin, the suffix tree, has memory-bottleneck problem with long strings. Secondly, some of CS-tree-node counts are incorrect due to frequent pruning of nodes. Therefore, we propose the count q-gram tree (CQ-tree) as an alphanumeric histogram for long strings. By adopting q-grams (or length-q substrings), CQ-trees can be created fast and correctly within small available memory. Furthermore, we mathematically provide the lower and upper bounds that the count estimation can reach to. To the best of our knowledge, our work is the first one to present such bounds among research activities to estimate the alphanumeric selectivity. Our experimental study shows that the CQ-tree outperforms the CS-tree in terms of the building time and accuracy. key words: string database, count estimation, count suffix tree, count qgram tree	conjunctive query;decision tree;experiment;grams;monte carlo tree search;n-gram;selectivity (electronic);substring;suffix tree;von neumann architecture	Jinuk Bae;Sukho Lee	2006	IEICE Transactions	10.1093/ietisy/e89-d.3.1148	search engine indexing;longest common substring problem;speech recognition;computer science;substring;artificial intelligence;theoretical computer science;operating system;machine learning;data mining;longest repeated substring problem;fm-index;algorithm;statistics;string searching algorithm	DB	-3.181265757200977	-34.406523732359176	16558
239fb202758779f3d9c1569843a3ea0cd5f4c4ac	online relative margin maximization for statistical machine translation		Recent advances in large-margin learning have shown that better generalization can be achieved by incorporating higher order information into the optimization, such as the spread of the data. However, these solutions are impractical in complex structured prediction problems such as statistical machine translation. We present an online gradient-based algorithm for relative margin maximization, which bounds the spread of the projected data while maximizing the margin. We evaluate our optimizer on Chinese-English and ArabicEnglish translation tasks, each with small and large feature sets, and show that our learner is able to achieve significant improvements of 1.2-2 BLEU and 1.7-4.3 TER on average over state-of-the-art optimizers with the large feature set.	bleu;expectation–maximization algorithm;gradient;mathematical optimization;statistical machine translation;structured prediction	Vladimir Eidelman;Yuval Marton;Philip Resnik	2013			mathematical optimization;margin;computer science;machine learning;pattern recognition	NLP	23.737418318050523	-32.54877021313966	16594
5bb199d85e2d7938fb850613e3edf82ee822e944	a novel clustering method combining heuristics and information theorem	clustering methods clustering algorithms prototypes entropy data mining shape partitioning algorithms educational institutions laboratories intelligent systems;unsupervised learning;pattern clustering;kernel;partition entropy;partition entropy clustering method heuristics information theorem data mining unsupervised data set partitioning initialization sensitivity hyper ellipsoidal clusters entropy guided splitting competitive learning;unsupervised learning data mining entropy pattern clustering;entropy guided splitting competitive learning;hyper ellipsoidal clusters;probability density function;prototypes;unsupervised data set partitioning;prior knowledge;data mining;competitive learning;clustering;clustering method;number of clusters;merging;initialization sensitivity;clustering algorithms;information theorem;entropy;heuristics;entropy competitive learning clustering information theorem	Many data mining tasks require the unsupervised partitioning of a data set into clusters. However, in many case we do not really know any prior knowledge about the clusters, for example, the density or the shape. This paper addresses two major issues associated with conventional competitive learning, namely, sensitivity to initialization and difficulty in determining the number of clusters. Many methods exist for such clustering, but most of then have assumed hyper-ellipsoidal clusters. Many heuristically proposed competitive learning methods and its variants, are somewhat ad hoc without any theoretical support. Under above considerations, we propose an algorithm named as Entropy guided Splitting Competitive Learning (ESCL) in the information theorem framework. Simulations show that minimization of partition entropy can be used to guide the competitive learning process, so to estimate the number and structure of probable data generators.	algorithm;cluster analysis;competitive learning;computer simulation;data mining;heuristic;hoc (programming language)	Zeng-Shun Zhao;Zeng-Guang Hou;Min Tan	2009	2009 Fifth International Conference on Natural Computation	10.1109/ICNC.2009.571	machine learning;pattern recognition;data mining;mathematics;competitive learning	ML	3.593206662856224	-40.2323230316955	16634
bfea24aa02ac48858dbc51b86c35176d4ce2709b	structure of set of association rules based on concept lattice	algebraic approach;satisfiability;association rule mining;equivalence relation;association rule;concept lattice	  It is important to propose effective algorithms that find basic association rules and generate all consequence association  rules from those basic rules. In this paper, we propose the new concept of eliminable  itemset to show how to represent itemset by generators and eliminable itemsets. Using algebraic approach based on equivalence relations,  we propose a new approach to partition the set of association rules into basic and consequence sets. After describing their  strict relations, we propose two ways to derive all consequence association rules from the basic association rules. These  two ways satisfy the properties: sufficiency, preserved confidence. Moreover, they do not derive repeated consequence rules. Hence, we save much time for discovering association rule mining.    	formal concept analysis	Tin C. Truong;Anh N. Tran	2010		10.1007/978-3-642-12090-9_19	combinatorics;discrete mathematics;mathematics;lattice miner	DB	-3.234305721117545	-26.235894834205485	16640
71a599466f5e0635c0fd4c2c3c65b8eb36a29c6b	design for self-organizing fuzzy neural network with extended kalman filter	automatic control;structure learning;nonlinear filters;design automation;fuzzy neural networks neurons neural networks radio access networks fuzzy control fuzzy logic fuzzy systems resource management automatic control design automation;fuzzy neural network;learning algorithm;fuzzy neural nets;neural networks;design and development;approximation algorithms;fuzzy control;training;kalman filters;resource management;prediction algorithms;fnn self organizing fuzzy neural network design extended kalman filter learning algorithm ekf;fuzzy logic;fnn;artificial neural networks;self organizing fuzzy neural network design;self organising feature maps;control system synthesis;comparative study;self organization;neurons;ekf;learning artificial intelligence;fuzzy neural networks;extended kalman filter;self organising feature maps control system synthesis fuzzy neural nets kalman filters learning artificial intelligence nonlinear filters;high performance;fuzzy systems;radio access networks	In this paper, a Self-organizing Fuzzy Neural Network employing an Extended Kalman Filter (EKF), termed Self-organizing Fuzzy Neural Networks with Extended Kalman Filter (SOFNNEKF) is designed and developed. The learning algorithm based on an EKF is simple and effective and is able to generate a fuzzy neural network with a high accuracy and compact structure. The structure learning of the SOFNNEKF, based on adding and pruning techniques is proposed. The EKF algorithm is used to adjust free parameters of the SOFNNEKF. Simulation and comparative studies with other methods demonstrate that a more compact structure with high performance can be achieved by the proposed algorithm.	algorithm;approximation;artificial neural network;extended kalman filter;machine learning;neuro-fuzzy;organizing (structure);self-organization;simulation;time series	Fan Liu;Meng Joo Er	2010	IEEE ICCA 2010	10.1109/ICCA.2010.5524416	control engineering;invariant extended kalman filter;computer science;artificial intelligence;neuro-fuzzy;machine learning;extended kalman filter;moving horizon estimation;artificial neural network	Robotics	12.665041905423855	-24.76787350147639	16643
daf0109ed9c9a17500b87d926d0c068ffed830e5	research on rss data optimization and dfl localization for non-empty environments	rss filtering;data correlation;device-free localization (dfl);ensemble learning	Device-free localization (DFL) is a new technique which can estimate the target location through analyzing the shadowing effect on surrounding radio frequency (RF) links. In a relatively complex environment, the influences of random disturbance and the multipath effect are more serious. There are kinds of noises and disturbances in the received signal strength (RSS) data of RF links and the data itself can even be distorted, which will seriously affect the DFL accuracy. Most of the common filtering methods adopted in DFL field are not targeted and the filtering effects are unstable. This paper researches the characteristics of RSS data with random disturbances and proposes two-dimensional double correlation (TDDC) distributed wavelet filtering. It can filter out the random disturbances and noise while preserving the RSS fluctuations which are helpful for the DFL, thus improving the quality of RSS data and localization accuracy. Furthermore, RSS variation rules for the links are different in complex environments and hence, it is difficult for the collected training samples to cover all possible patterns. Therefore, a single machine learning model with poor generalization ability finds it difficult to achieve ideal localization results. In this paper, the Adaboost.M2 ensemble learning model based on the Gini decision tree (GDTE) is proposed to improve the generalization ability for unknown patterns. Extensive experiments performed in two different drawing rooms demonstrate that the TDDC distributed wavelet filtering and the GDTE localization model have obvious advantages compared with other methods. The localization accuracy rates of 87% and 95% can be achieved respectively in the two environments.		Wenyu Mao;Rongxuan Shen;Ke Wang;Guoliang Gong;Yi Xiao;Huaxiang Lu	2018		10.3390/s18124419		AI	7.110896855897949	-41.604981366293096	16649
5f0fbe8e37dc21deed6fae461858fc9621f30092	crossprop: learning representations by stochastic meta-gradient descent in neural networks		Representations are fundamental to artificial intelligence. The performance of a learning system depends on how the data is represented. Typically, these representations are hand-engineered using domain knowledge. Recently, the trend is to learn these representations through stochastic gradient descent in multi-layer neural networks, which is called backprop. Learning representations directly from the incoming data stream reduces human labour involved in designing a learning system. More importantly, this allows in scaling up a learning system to difficult tasks. In this paper, we introduce a new incremental learning algorithm called crossprop, that learns incoming weights of hidden units based on the meta-gradient descent approach. This meta-gradient descent approach was previously introduced by Sutton (1992) and Schraudolph (1999) for learning stepsizes. The final update equation introduces an additional memory parameter for each of these weights and generalizes the backprop update equation. From our empirical experiments, we show that crossprop learns and reuses its feature representation while tackling new and unseen tasks whereas backprop relearns a new feature representation.	algorithm;artificial intelligence;artificial neural network;backpropagation;experiment;layer (electronics);neural network software;stochastic gradient descent	Vivek Veeriah;Shangtong Zhang;Richard S. Sutton	2017		10.1007/978-3-319-71249-9_27	machine learning;artificial neural network;domain knowledge;data stream;scaling;incremental learning;supervised learning;gradient descent;artificial intelligence;stochastic gradient descent;computer science	AI	17.70943094747264	-31.631479379571953	16667
f5097af1b621bd805f3431c94fa0d3d9c3736801	experts' boasting in trainable fusion rules	generalization error;pattern recognition trainable fusion rule expert classifiers behavior space knowledge training set fusion rule generalization error resubstitution error complexity;expert systems;experimental procedure;complexity;small samples;resubstitution error;classification system;pattern classification;fusion rule;generalisation artificial intelligence;pattern recognition feature extraction voting classification tree analysis decision trees error correction fuses degradation aggregates decision making;expert classifiers;learning artificial intelligence;generalisation artificial intelligence pattern classification expert systems learning artificial intelligence	We consider the trainable fusion rule design problem when the expert classifiers provide crisp outputs and the behavior space knowledge method is used to fuse local experts’ decisions. If the training set is utilized to design both the experts and the fusion rule, the experts’ outputs become too self-assured. In small sample situations, “optimistically biased” experts’ outputs bluffs the fusion rule designer. If the experts differ in complexity and in classification performance, then the experts’ boasting effect and can severely degrade the performance of a multiple classification system. Theoretically-based and experimental procedures are suggested to reduce the experts’ boasting effect.	complexity;expert system;test set	Sarunas Raudys	2003	IEEE Trans. Pattern Anal. Mach. Intell.	10.1109/TPAMI.2003.1227993	complexity;computer science;artificial intelligence;machine learning;pattern recognition;data mining;expert system;generalization error	ML	14.591753766572193	-36.11983218435068	16695
4bed96c83ef5821481ad3201df885c15b2f0376a	context-based unsupervised data fusion for decision making		Big Data received from sources such as social media, in-stream monitoring systems, networks, and markets is often mined for discovering patterns, detecting anomalies, and making decisions or predictions. In distributed learning and realtime processing of Big Data, ensemble-based systems in which a fusion center (FC) is used to combine the local decisions of several classifiers, have shown to be superior to single expert systems. However, optimal design of the FC requires knowledge of the accuracy of the individual classifiers which, in many cases, is not available. Moreover, in many applications supervised training of the FC is not feasible since the true labels of the data set are not available. In this paper, we propose an unsupervised joint estimation-detection scheme to estimate the accuracies of the local classifiers as functions of data context and to fuse the local decisions of the classifiers. Numerical results show the dramatic improvement of the proposed method as compared with the state of the art approaches.	big data;expert system;mined;numerical method;optimal design;sensor;social media;supervised learning;unsupervised learning	Erfan Soltanmohammadi;Mort Naraghi-Pour;Mihaela van der Schaar	2015			random subspace method;computer science;machine learning;pattern recognition;data mining	ML	17.128274310148594	-41.54247810328778	16712
0d0529af79cd24b9d62c982c4fbae18605d487fc	mining high-quality clusters in pattern-based clustering	analytical models;cluster algorithm;highly overlapping clusters pattern based clustering pattern similarity error analysis qscore;pattern clustering;high quality cluster mining;pattern similarity;approximate algorithm;approximation algorithms;pattern based clustering;data mining;highly overlapping clusters;pattern clustering data mining;error analysis;data analysis;data mining algorithm;clustering algorithms;pattern weighting;dna microarray data;clustering algorithms data mining algorithm design and analysis approximation algorithms error analysis data analysis analytical models;qscore;algorithm design and analysis;pattern similarity high quality cluster mining pattern based clustering error analysis pattern weighting qscore highly overlapping clusters;analytical model	Pattern-based clustering, which capture the similarity of the patterns exhibited by objects in a subset of dimensions, has broad applications in DNA microarray data analysis, customer segmentation, e-business data analysis, etc. However, pattern-based clustering often returns a large number of highly-overlapping clusters, which makes it hard for users to identify interesting patterns from the huge mining results. Moreover, there lacks a general measurement to evaluate the quality of Clusters which pattern-based clustering obtained. In this paper, we discuss factors which cause highly-overlapping, make error analysis and pattern weighting, and propose qScore as a key evaluation parameters on quality of Clusters. A algorithm which based on qScore is presented to solve the problem of high-overlapping and get better quality clustering results.	algorithm;algorithmic efficiency;approximation algorithm;cluster analysis;computation;computer cluster;dna microarray;electronic business;error analysis (mathematics);mean squared error;requirement	Qian Ma;Jingfeng Guo	2011	2011 Eighth International Conference on Fuzzy Systems and Knowledge Discovery (FSKD)	10.1109/FSKD.2011.6019708	correlation clustering;constrained clustering;algorithm design;determining the number of clusters in a data set;data stream clustering;k-medians clustering;fuzzy clustering;flame clustering;computer science;canopy clustering algorithm;machine learning;consensus clustering;pattern recognition;cure data clustering algorithm;data mining;hierarchical clustering;cluster analysis;single-linkage clustering;data analysis;brown clustering;approximation algorithm;affinity propagation;clustering high-dimensional data	DB	-1.4573058424264491	-40.757134046259104	16751
3a5f5aca6138abcf22ede1af5572e01eb0f761d1	optimizing multivariate performance measures from multi-view data		To date, many machine learning applications have multiple views of features, and different applications require specific multivariate performance measures, such as the F-score for retrieval. However, existing multivariate performance measure optimization methods are limited to single-view data, while traditional multi-view learning methods cannot optimize multivariate performance measures directly. To fill this gap, in this paper, we propose the problem of optimizing multivariate performance measures from multi-view data, and an effective method to solve it. We propose to learn linear discriminant functions for different views, and combine them to construct an overall multivariate mapping function for multiview data. To learn the parameters of the linear discriminant functions of different views to optimize a given multivariate performance measure, we formulate an optimization problem. In this problem, we propose to minimize the complexity of the linear discriminant function of each view, promote the consistency of the responses of different views over the same data points, and minimize the upper boundary of the corresponding loss of a given multivariate performance measure. To optimize this problem, we develop an iterative cuttingplane algorithm. Experiments on four benchmark data sets show that it not only outperforms traditional single-view based multivariate performance optimization methods, but also achieves better results than ordinary multi-view learning methods.	algorithm;benchmark (computing);cutting-plane method;data point;effective method;f1 score;integer programming;iterative method;linear discriminant analysis;machine learning;mathematical optimization;optimization problem;optimizing compiler;performance tuning	Jim Jing-Yan Wang;Ivor W. Tsang;Xin Gao	2016			mathematical optimization;computer science;machine learning;data mining;multivariate analysis;statistics	AI	21.933029312925225	-39.542224939081805	16806
edb2e7cf4bec46c51387b5b7e7dbc82674812f50	rough-neuro-fuzzy system with micog defuzzification	fuzzy classification;fuzzy neural nets;rough set theory;fuzzy set theory;rough set theory rough neuro fuzzy system classifier modified indexed center of gravity defuzzification fuzzy information classification object feature classification;rough neuro fuzzy system classifier;feature extraction;neuro fuzzy;indexation;modified indexed center of gravity defuzzification;center of gravity;neuro fuzzy system;pattern classification;fuzzy information classification;object feature classification;fuzzy sets argon set theory gravity fuzzy systems rough sets fuzzy reasoning bayesian methods decision theory probability;rough set theory feature extraction fuzzy neural nets fuzzy set theory pattern classification	This paper presents a new approach to fuzzy classification in case of missing information about object features. The rough set theory is incorporated into neuro-fuzzy structures and the rough-neuro-fuzzy classifier is derived. The architecture of the classifier is determined by the MICOG (modified indexed center of gravity) defuzzification method. Some illustrative examples are given.	defuzzification;fuzzy classification;fuzzy control system;neuro-fuzzy;rough set;set theory	Robert Nowicki	2006	2006 IEEE International Conference on Fuzzy Systems	10.1109/FUZZY.2006.1681972	rough set;defuzzification;feature extraction;fuzzy classification;computer science;neuro-fuzzy;machine learning;pattern recognition;data mining;mathematics;fuzzy set;center of gravity	Robotics	2.6318760701323782	-28.58803459069771	16851
a47a46d705db3f4c27657d369a6c1de57ba6f352	a hopfield neural network approach to decentralized self-synchronizing sensor networks	transformation of self synchronizing sensor networks into hopfield neural networks;estado equilibrio;calcul neuronal;neural computation;etat equilibre;hopfield neural nets;decentralized inference of sensor networks;62m45;espace parametre;sensor network;hopfield neural network;captador medida;measurement sensor;capteur mesure;hopfield neural networks;reseau neuronal hopfield;espacio par metro;parameter space;estimation statistique;reseau hopfield;reseau neuronal;self synchronizing sensor networks;estimacion estadistica;statistical estimation;red neuronal;computacion neuronal;equilibrium state;neural network	Decentralized inference of a sensor network in the difficult case of a nonreciprocal nonlinear context is investigated by transforming the sensor network into a Hopfield neural network. Equilibrium states of the latter correspond to situations of global consensus in the sensor network, characterized by suitable regions (consensus regions) in the space of its parameters. The said transformation was recently proposed by the author and applied to the simple case of three sensors. The general case of more than three sensors is investigated in the present paper. A procedure is developed for determining the structure and the properties of the consensus regions.	artificial neural network;hopfield network;linear equation;nonlinear system;sensor;system of linear equations;the matrix	Giuseppe Martinelli	2010	Neural Computing and Applications	10.1007/s00521-010-0369-5	wireless sensor network;telecommunications;thermodynamic equilibrium;computer science;artificial intelligence;machine learning;parameter space;hopfield network;artificial neural network;statistics;models of neural computation	Mobile	19.129709570947636	-27.215025177516473	16900
82c91e6dab0dce6b653f4d53423ca0bf220bb263	fuzzy clustering of intuitionistic fuzzy data	fuzzy c means clustering;fuzzy intuitionistic data	In the paper a new method of fuzzy clustering basing on fuzzy features is presented. Objects are described by set of features with intutionistic fuzzy values. Generally, the method uses the concept of modified fuzzy c-means procedure applied to intuitionistic fuzzy data which describes the features. New distance measure between data and cluster centers is suggested. Some examples of clustering results are presented. The method is efficient and very fast.	fuzzy clustering;fuzzy logic	Bohdan S. Butkiewicz	2012		10.1007/978-3-642-29347-4_25	fuzzy logic;membership function;defuzzification;fuzzy clustering;adaptive neuro fuzzy inference system;type-2 fuzzy sets and systems;flame clustering;fuzzy mathematics;fuzzy classification;computer science;fuzzy number;neuro-fuzzy;machine learning;pattern recognition;fuzzy measure theory;data mining;mathematics;fuzzy set;fuzzy associative matrix;fuzzy set operations;fuzzy control system	NLP	0.03280570617408017	-26.387569782805283	16937
d54055b4dc2e4c40f9fd2ff66e01f9df7b8425a3	robust local feature weighting hard c-means clustering algorithm	robust clustering;local feature weighting;non euclidean metric	In view of local feature weighting hard C-means (LWHCM) clustering algorithm sensitive to noise, based on a non-Euclidean metric, a robust local feature weighting hard C-means (RLWHCM) clustering algorithm is presented. The robustness of RLWHCM is analyzed by using the location M-estimate in robust statistical theory. By endowing each data point with a dynamic weighting function on each feature of data point, RLWHCM can estimate the clustering center more accurately in noisy environment. Experimental results on synthetic and real world data sets demonstrate the advantages of RLWHCM over LWHCM.	algorithm;cluster analysis	Xiaobin Zhi;Jiulun Fan;Feng Zhao	2011		10.1007/978-3-642-31919-8_75	correlation clustering;data stream clustering;k-medians clustering;fuzzy clustering;flame clustering;canopy clustering algorithm;machine learning;pattern recognition;cure data clustering algorithm;data mining;mathematics;cluster analysis	Vision	1.5138361086290524	-40.890884938099006	16955
c0f9f1db553d0da6d524863447b52b6f4035e35b	a comparative study of divisive and agglomerative hierarchical clustering algorithms	hierarchical clustering;dissimilarity data;splitting procedures;evaluation of hierarchy;dendrogram;ultrametrics	A general scheme for divisive hierarchical clustering algorithms is proposed. It is made of three main steps: first a splitting procedure for the subdivision of clusters into two subclusters, second a local evaluation of the bipartitions resulting from the tentative splits and, third, a formula for determining the node levels of the resulting dendrogram. A set of 12 such algorithms is presented and compared to their agglomerative counterpart (when available). These algorithms are evaluated using the Goodman-Kruskal correlation coefficient. As a global criterion it is an internal goodness-of-fit measure based on the set order induced by the hierarchy compared to the order associated with the given dissimilarities. Applied to a hundred random data tables and to three real life examples, these comparisons are in favor of methods which are based on unusual ratio-type formulas to evaluate the intermediate bipartitions, namely the Silhouette formula, the Dunn's formula and the Mollineda et al. formula. These formulas take into account both the within cluster and the between cluster mean dissimilarities. Their use in divisive algorithms performs very well and slightly better than in their agglomerative counterpart.	algorithm;hierarchical clustering	Maurice Roux	2018	J. Classification	10.1007/s00357-018-9259-9	silhouette;statistics;correlation coefficient;mathematics;hierarchical clustering;algorithm;dendrogram;hierarchy	ML	2.4392030102878297	-38.009798098406584	16970
a6b97ab43f3c2fa8f015eda88ab27cc24ddf192d	partially supervised learning by a credal em approach	transferable belief model;modelizacion;belief;belief function;learning;supervised learning;incertidumbre;uncertainty;informacion incompleta;belief functions;intelligence artificielle;probabilistic approach;classification;imperfect information;modelisation;incomplete information;croyance;enfoque probabilista;approche probabiliste;information incomplete;algorithme em;informacion imperfecta;artificial intelligence;algoritmo em;incertitude;inteligencia artificial;apprentissage supervise;creencia;aprendizaje supervisado;em algorithm;modeling;clasificacion;em;information imparfaite	In this paper, we propose a Credal EM (CrEM) approach for partially supervised learning. The uncertainty is represented by belief functions as understood in the transferable belief model (TBM). This model relies on a non probabilistic formalism for representing and manipulating imprecise and uncertain information. We show how the EM algorithm can be applied within the TBM framework when applied for the classification of objects and when the learning set is imprecise (the actual class of each object is only known as belonging to a subset of classes), and/or uncertain (the knowledge about the actual class is represented by a probability function or by a belief function).	supervised learning	Patrick Vannoorenberghe;Philippe Smets	2005		10.1007/11518655_80	systems modeling;uncertainty;expectation–maximization algorithm;biological classification;computer science;artificial intelligence;perfect information;belief;machine learning;mathematics;em;supervised learning;complete information;algorithm;statistics	ML	7.86659294937594	-31.319720135346614	16978
c7225f17217e25f7f7271e6fe6ea36de2fd45687	artificial neural networks - a state-of-the-art computing technique in stage discharge relationship	artificial neural network		artificial neural network;neural networks	Adel Mani;V. R. Desai	2005			machine learning;artificial intelligence;pattern recognition;computer science;neuro-fuzzy;artificial neural network;time delay neural network;types of artificial neural networks;intelligent control;nervous system network models;physical neural network	ML	12.767303921680913	-26.848189143210305	16986
9621ea6ee45897c7adf14d5e467412e0f882fa14	neural network applications	neural network application;neural nets;engineering areas neural network applications science business neural network simulators character recognition;digital simulation neural nets character recognition;radial basis function;neural networks neurons artificial neural networks systems engineering and theory hopfield neural networks process control knowledge engineering supervised learning clustering algorithms application software;character recognition;back propagation;digital simulation;artificial neural network;neural network	Artificial neural networks, also called neural networks, have been used successfully in many fields including engineering. science and business. This paper presents the implementation of several neural network simulators and their applications in chnracter recognition and other engineering areas.	artificial neural network;simulation	E. Vonk;Lakhmi C. Jain;L. P. J. Veelenturf	1995		10.1109/ETD.1995.403490	stochastic neural network;nervous system network models;cellular neural network;probabilistic neural network;types of artificial neural networks;computer science;artificial intelligence;recurrent neural network;machine learning;neural modeling fields;evolutionary acquisition of neural topologies;physical neural network;data mining;time delay neural network;deep learning;neocognitron;artificial neural network	ML	12.610787990222605	-26.179532578005222	16989
431623dd881590b4ec64d6e6ff06504fa9e2b3a4	learning fair classifiers: a regularization-inspired approach		We present a regularization-inspired approach for reducing bias in learned classifiers. In particular, we focus on binary classification tasks over individuals from two populations, where, as our criterion for fairness, we wish to achieve similar false positive rates in both populations, and similar false negative rates in both populations. As a proof of concept, we implement our approach and empirically evaluate its ability to achieve both fairness and accuracy, using the COMPAS scores data for prediction of recidivism.	binary classification;fairness measure;matrix regularization;population	Yahav Bechavod;Katrina Ligett	2017	CoRR		proof of concept;binary classification;regularization (mathematics);machine learning;artificial intelligence;mathematics	ML	18.83393998107562	-35.343888352714664	17070
ee869b3bbc23784949e74be3fc4504d1198a9ba5	modeling of the counter-examples and association rules interestingness measures behavior.	efficient algorithm;interestingness measure;knowledge discovery in data;association rule;it evaluation	Association rules discovery is one of the most important tasks in Knowledge Discovery in Data Bases. Since the initial APRIORI algorithm, many efforts have been done in order to develop efficient algorithms. It is well known that APRIORI-like algorithms within the (unsatisfying) support/confidence framework may produce huge amounts of rules and thus one of the most important steps in association rules discovery is nowadays the evaluation and interpretation of their interestingness. Thus there has been substantial works that addressed the problem of association rules interestingness and many interestingness measures have been defined and used in order to find the best rules in a post-processing step. Measures provide numerical information on the quality of a rule and a rule A→ B is said “of quality” if its evaluation by a measure is greater than a user defined threshold. These measures can be studied as functions of the number of counter-examples of rules. In this paper we present three modelings of counter-examples and examine the consequences of such modelizations on two important desired properties of association rules interestingness measures, that are the decrease with the number of counterexamples and the tolerance to the apparition of the first counterexamples. We here present results for ten well known measures.	apriori algorithm;association rule learning;database;flickr;numerical analysis;synthetic data;video post-processing	Benoît Vaillant;Stéphane Lallich;Philippe Lenca	2006			machine learning;pattern recognition;data mining	DB	-2.002487522629209	-31.978766508334335	17106
1ed60ded6053d751d7099917c8aa148995766b72	learning stable multilevel dictionaries for sparse representation of images		Dictionaries adapted to the data provide superior performance when compared to predefined dictionaries in applications involving sparse representations. Algorithmic stability and generalization are desirable characteristics for dictionary learning algorithms that aim to build global dictionaries which can efficiently model any test data similar to the training samples. In this paper, we propose an algorithm to learn dictionaries for sparse representation of image patches, and prove that the proposed learning algorithm is stable and generalizable asymptotically. The algorithm employs a 1-D subspace clustering procedure, the K-lines clustering, in order to learn a hierarchical dictionary with multiple levels. Furthermore, we propose a regularized pursuit scheme for computing sparse representations using a multilevel dictionary. Using simulations, we demonstrate the stability and generalization characteristics of the proposed algorithm with natural image patches. Finally, we employ multilevel dictionaries for compressed recovery and demonstrate improvements in recovery performance using both random and optimized projections when compared to baseline K-SVD dictionaries.	algorithm;baseline (configuration management);cluster analysis;clustering high-dimensional data;compressed sensing;dictionary;hierarchical clustering;k-svd;machine learning;sample complexity;simulation;singular value decomposition;sparse approximation;sparse matrix;stability (learning theory);test data	Jayaraman J. Thiagarajan;Karthikeyan Natesan Ramamurthy;Andreas Spanias	2011	CoRR		machine learning;pattern recognition;sparse approximation	ML	24.011869535408724	-42.867523649864346	17121
5d7adcd3309e7989dd6cddcb109333833d18c842	similarity-adaptive latent low-rank representation for robust data representation		We propose a novel Similarity-Adaptive Latent Low-Rank Representation (SA-LatLRR) model for the robust representation and subspace recovery. SA-LatLRR inherits all merits of recent LatLRR, and further improves it by enhancing the representations. SA-LatLRR aims at decomposing given data into a principal feature part encoded by the Frobenius-norm based coefficients, a similarity-adaptive salient feature part and a sparse error part. Specifically, our SA-LatLRR incorporates a reconstructive error minimization term over coefficients and salient features, which can clearly preserve the neighborhood information of salient features adaptively. The added regularization can also encourage the coefficients to be block-diagonal and discriminative, as the shared coefficients could minimize the reconstruction errors over both original data and salient features at the same time, where the embedded salient features contain less noise and unfavorable features than the original data. Moreover, to make salient features more informative and robust to noise, SA-LatLRR imposes the sparse L2,1-norm and low-rank constraints on the projection jointly so that the features are more notable and discriminative. The Frobenius-norm based principal feature part can also make the coefficients coding process very efficient. Extensive comparison results demonstrate the validity of our SA-LatLRR.		Lei Wang;Zhaoxing Zhang;Sheng Li;Guangcan Liu;Chenping Hou;Jie Qin	2018		10.1007/978-3-319-97304-3_6	machine learning;pattern recognition;computer science;artificial intelligence;salient;subspace topology;discriminative model;regularization (mathematics);robust statistics	ML	24.295758085821213	-43.40640911395915	17176
72d7e11b30767f4f5993d794fc040328b23868b5	deep neural network acceleration framework under hardware uncertainty		Deep Neural Networks (DNNs) are known as effective model to perform cognitive tasks. However, DNNs are computationally expensive in both train and inference modes as they require the precision of floating point operations. Although, several prior work proposed approximate hardware to accelerate DNNs inference, they have not considered the impact of training on accuracy. In this paper, we propose a general framework called FramNN, which adjusts DNN training model to make it appropriate for underlying hardware. To accelerate training FramNN applies adaptive approximation which dynamically changes the level of hardware approximation depending on the DNN error rate. We test the efficiency of the proposed design over six popular DNN applications. Our evaluation shows that in inference, our design can achieve 1.9× energy efficiency improvement and 1.7× speedup while ensuring less than 1% quality loss. Similarly, in training mode FramNN can achieve 5.0× energy-delay product improvement as compared to baseline AMD GPU.	analysis of algorithms;approximation algorithm;artificial neural network;baseline (configuration management);computation;deep learning;error message;graphics processing unit;neural network software;speedup;vii	Mohsen Imani;Pushen Wang;Tajana Simunic	2018	2018 19th International Symposium on Quality Electronic Design (ISQED)	10.1109/ISQED.2018.8357318	elementary cognitive task;real-time computing;computer hardware;acceleration;speedup;word error rate;floating point;artificial neural network;computer science;inference	Arch	18.25335588251967	-32.644278196021666	17270
340e55a44793226a51ad06612f340f2c520e3575	g2denet: global gaussian distribution embedding network and its application to visual recognition		Recently, plugging trainable structural layers into deep convolutional neural networks (CNNs) as image representations has made promising progress. However, there has been little work on inserting parametric probability distributions, which can effectively model feature statistics, into deep CNNs in an end-to-end manner. This paper proposes a Global Gaussian Distribution embedding Network (G2DeNet) to take a step towards addressing this problem. The core of G2DeNet is a novel trainable layer of a global Gaussian as an image representation plugged into deep CNNs for end-to-end learning. The challenge is that the proposed layer involves Gaussian distributions whose space is not a linear space, which makes its forward and backward propagations be non-intuitive and non-trivial. To tackle this issue, we employ a Gaussian embedding strategy which respects the structures of both Riemannian manifold and smooth group of Gaussians. Based on this strategy, we construct the proposed global Gaussian embedding layer and decompose it into two sub-layers: the matrix partition sub-layer decoupling the mean vector and covariance matrix entangled in the embedding matrix, and the square-rooted, symmetric positive definite matrix sub-layer. In this way, we can derive the partial derivatives associated with the proposed structural layer and thus allow backpropagation of gradients. Experimental results on large scale region classification and fine-grained recognition tasks show that G2DeNet is superior to its counterparts, capable of achieving state-of-the-art performance.	artificial neural network;backpropagation;convolutional neural network;coupling (computer programming);end-to-end principle;gaussian blur;gradient;image retrieval;norm (social);statistical model;the matrix	Qilong Wang;Peihua Li	2017	2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)	10.1109/CVPR.2017.689	convolutional neural network;artificial intelligence;gaussian function;gaussian random field;pattern recognition;covariance matrix;matrix (mathematics);mathematical optimization;embedding;gaussian;symmetric matrix;mathematics	Vision	23.32475657236113	-48.604241412406914	17290
652e721a5426aa8958df997099eb30cfda87a26b	machine learning techniques for probability forecasting and their practical evaluations			machine learning	David George Lindsay	2007				Crypto	10.304691936743462	-25.92078870719105	17297
0aaebfaf718f9f2decb7f70847a14e0cf0a0eee9	handwritten digit, recognition road to contest victory	optimal solution;classification algorithm;generic model;data gathering;handwritten digit recognition;data mining;pattern classification data mining handwritten character recognition;handwriting recognition data mining testing pixel data analysis algorithm design and analysis classification algorithms computational intelligence informatics world wide web;pattern classification;model test;classification algorithms handwritten digit recognition data mining;point of view;handwritten character recognition	With growing amount of data gathered nowadays, need for efficient data mining methodologies is getting more and more common. There is a large number of different classification algorithms, but choosing the best one for given data is still a difficult task. Thanks to different data mining contests we can gather lots of meta level information about classification problems and strategies leading to optimal (or close to optimal) solutions. One of the contests was organized in parallel with the ICAISC'06 conference held in Zakopane. We took part in it, and our model classified the test data with the highest accuracy. The process which led to the winner model was not simple t required multiaspect analysis of the data and different algorithms (from the point of view of suitability to the data). This article presents our road to the winner model with numerous comments on both successful and unsuccessful efforts. It also presents our model testing methodology, which always plays important role in the pursuit of accurate and well generalizing models	algorithm;data mining;test data	Norbert Jankowski;Krzysztof Grabczewski	2007	2007 IEEE Symposium on Computational Intelligence and Data Mining	10.1109/CIDM.2007.368915	computer science;artificial intelligence;machine learning;pattern recognition;data mining;data collection	ML	8.017487529727589	-39.02225267816056	17316
3c0322c24a487ffe1042ab73ba244b6be080bcc8	reducts and constructs in classic and dominance-based rough sets approach	dominance;indiscernibility;similarity;rough sets approach;construct;reduct	The idea of the reduct, as defined in the Classic Rough Sets Approach (CRSA), has proven to be inspiring enough to get into closely related theories, including the Dominance-based Rough Sets Approach (DRSA). The procedure of reduction is generally similar to that of Feature Selection, but narrower, as it is the descriptive, rather than the predictive, aspect of data exploration that constitutes its principal goal. CRSA reducts are thus defined as minimal subsets of attributes that retain sufficiently high quality of object description. Developed within CRSA, the CRSA reducts have given rise to the generalized notion of CRSA constructs, which have turned out to be superior to reducts in numerous practical experiments with real-life data sets. The generalization process is continued in this paper, in which a definition of constructs in the context of DRSA is introduced. The definition, fully analogous to that of CRSA constructs, differs only in that it is context-based in DRSA, while context-free in CRSA. Consequently, the presented DRSA constructs are expected to have analogous properties to that of CRSA constructs, including superiority to DRSA reducts in experiments with real-life data sets.	dominance-based rough set approach	Robert Susmaga	2014	Inf. Sci.	10.1016/j.ins.2014.02.100	discrete mathematics;similarity;construct;data mining;reduct;mathematics;dominance;algorithm	DB	-3.5283610726086034	-27.43636460505254	17319
484679c84356f4f6a60b370bb83aadacbcddd1e1	convex clustering: an attractive alternative to hierarchical clustering	software;hierarchical clustering;genomics;paper;tesla c2050;databases genetic;biology;cluster analysis;clustering;package;nvidia;algorithms;pattern recognition automated;humans;computational biology;opencl;gene expression profiling;bioinformatics	The primary goal in cluster analysis is to discover natural groupings of objects. The field of cluster analysis is crowded with diverse methods that make special assumptions about data and address different scientific aims. Despite its shortcomings in accuracy, hierarchical clustering is the dominant clustering method in bioinformatics. Biologists find the trees constructed by hierarchical clustering visually appealing and in tune with their evolutionary perspective. Hierarchical clustering operates on multiple scales simultaneously. This is essential, for instance, in transcriptome data, where one may be interested in making qualitative inferences about how lower-order relationships like gene modules lead to higher-order relationships like pathways or biological processes. The recently developed method of convex clustering preserves the visual appeal of hierarchical clustering while ameliorating its propensity to make false inferences in the presence of outliers and noise. The solution paths generated by convex clustering reveal relationships between clusters that are hidden by static methods such as k-means clustering. The current paper derives and tests a novel proximal distance algorithm for minimizing the objective function of convex clustering. The algorithm separates parameters, accommodates missing data, and supports prior information on relationships. Our program CONVEXCLUSTER incorporating the algorithm is implemented on ATI and nVidia graphics processing units (GPUs) for maximal speed. Several biological examples illustrate the strengths of convex clustering and the ability of the proximal distance algorithm to handle high-dimensional problems. CONVEXCLUSTER can be freely downloaded from the UCLA Human Genetics web site at http://www.genetics.ucla.edu/software/.	algorithm;bioinformatics;cluster analysis;computer graphics;graphics processing unit;hierarchical clustering;k-means clustering;loss function;maximal set;method (computer programming);missing data;optimization problem;physical object;trees (plant)	Gary K. Chen;Eric C. Chi;John Michael O Ranola;Kenneth Lange	2015		10.1371/journal.pcbi.1004228	correlation clustering;biology;constrained clustering;genomics;data stream clustering;fuzzy clustering;flame clustering;computer science;bioinformatics;canopy clustering algorithm;machine learning;consensus clustering;cure data clustering algorithm;data mining;hierarchical clustering;cluster analysis;single-linkage clustering;brown clustering;dbscan;biclustering;statistics;hierarchical clustering of networks;clustering high-dimensional data;conceptual clustering	ML	6.40057631960491	-50.65040402932036	17438
5e21a98095d3e224dbcac1348ba04ca100b98d25	a novel approach to pre-extracting support vectors based on the theory of belief functions		Applications of the support vector machine (SVM) in the large scale datasets are seriously hampered by its high computational cost for training. In SVM training, the classification hyperplane is determined by support vectors (SVs). If those samples likely to be SVs can be pre-extracted and used for training, the computational cost can be reduced without the loss of classification accuracy. An approach to pre-extracting SVs is proposed where the training samples’ uncertainty in terms of classification is modeled using belief functions. Those samples with a higher degree of uncertainty are more likely to be SVs. Our approach can also detect outliers and noisy samples. Experimental results based on benchmark datasets show that the proposed approach performs better compared with traditional approaches, where the training time is significantly reduced (approximate to one or two orders of magnitude), meanwhile it can obtain good classification accuracies.		Deqiang Han;Weibing Liu;Jean Dezert;Yi Yang	2016	Knowl.-Based Syst.	10.1016/j.knosys.2016.07.029	machine learning;pattern recognition;data mining;statistics	DB	15.660302193028494	-40.728245057678734	17579
26de38f28172c5bd05f623469449a860b0409b11	binarized convolutional neural networks for efficient inference on gpus		Convolutional neural networks have recently achieved significant breakthroughs in various image classification tasks. However, they are computationally expensive, which can make their feasible implementation on embedded and low-power devices difficult. In this paper convolutional neural network binarization is implemented on GPU-based platforms for real-time inference on resource constrained devices. In binarized networks, all weights and intermediate computations between layers are quantized to +1 and −1, allowing multiplications and additions to be replaced with bit-wise operations between 32-bit words. This representation completely eliminates the need for floating point multiplications and additions and decreases both the computational load and the memory footprint compared to a full-precision network implemented in floating point, making it well-suited for resource-constrained environments. We compare the performance of our implementation with an equivalent floating point implementation on one desktop and two embedded GPU platforms. Our implementation achieves a maximum speed up of $7.4\times$ with only 4.4 % loss in accuracy compared to a reference implementation.		Mir Khan;Heikki Huttunen;Jani Boutellier	2018	2018 26th European Signal Processing Conference (EUSIPCO)	10.23919/EUSIPCO.2018.8553594	memory footprint;convolutional neural network;machine learning;floating point;artificial intelligence;speedup;instruction set;inference;mathematics;contextual image classification;reference implementation	Robotics	23.402337874226323	-51.88931425232801	17604
dbd3b0a8e0b041841d1ec3097ca480da679607f9	multiclass credit cardholders' behaviors classification methods	carte credit;multiclass;multicriteria analysis;banking;multiple criteria mathematical programming mcmp;decision tree;analisis estadistico;tarjeta de credito;multiclase;secteur bancaire;credit;multiple criteria;arbol decision;classification a vaste marge;multiclasse;statistical analysis;credito;mathematical programming;multi group classification;multiple decision;analyse statistique;credit card;portfolio management;decision multiple;binary classification;gestion cartera;analisis multicriterio;support vector machine;information system;analyse multicritere;maquina ejemplo soporte;vector support machine;gestion portefeuille;programmation mathematique;multiclass classification;arbre decision;programacion matematica;systeme information;see5;credit cards;one against all svm;sistema informacion	In credit card portfolio management a major challenge is to classify and predict credit cardholders’ behaviors in a reliable precision because cardholders’ behaviors are rather dynamic in nature. Multiclass classification refers to classify data objects into more than two classes. Many real-life applications require multiclass classification. The purpose of this paper is to compare three multiclass classification approaches: decision tree, Multiple Criteria Mathematical Programming (MCMP), and Hierarchical Method for Support Vector Machines (SVM). While MCMP considers all classes at once, SVM was initially designed for binary classification. It is still an ongoing research issue to extend SVM from two-class classification to multiclass classification and many proposed approaches use hierarchical method. In this paper, we focus on one common hierarchical method – one-against-all classification. We compare the performance of See5, MCMP and SVM oneagainst-all approach using a real-life credit card dataset. Results show that MCMP achieves better overall accuracies than See5 and one-against-all SVM.	algorithm;algorithmic efficiency;binary classification;computation;decision tree;mathematical optimization;multiclass classification;real life;support vector machine	Gang Kou;Yi Peng;Yong Shi;Zhengxin Chen	2006		10.1007/11758549_68	binary classification;support vector machine;computer science;machine learning;decision tree;multiclass classification;pattern recognition;data mining;information system;project portfolio management	ML	8.942602801420737	-33.791485321767546	17619
22517c1d768502fd819ce0249cf5f25d48095d55	domain adaptation via multi-layer transfer learning	multi layer;cross domain classification;transfer learning;non negative matrix tri factorization	Transfer learning, which leverages labeled data in a source domain to train an accurate classifier for classification tasks in a target domain, has attracted extensive research interests recently for its effectiveness proven by many studies. Previous approaches adopt a common strategy that models the shared structure as a bridge across different domains by reducing distribution divergences. However, those specific latent spaces contain specific latent factors, lacking which will lead to ineffective distinct concept learning. Additionally, only learning latent factors in one latent feature space layer may ignore those in the other layers. The missing latent factors may also help us to model the latent structure shared as the bridge. This paper proposes a novel transfer learning method Multi-Layer Transfer Learning (MLTL). MLTL first generates specific latent feature spaces. Second, it combines these specific latent feature spaces with common latent feature space into one latent feature space layer. Third, it generates multiple layers to learn the corresponding distributions on different layers with their pluralism simultaneously. Specifically, the pluralism of the distributions on different layers means that learning the distributions on one layer can help us to learn the distributions on the others. Furthermore, an iterative algorithm based on Non-Negative Matrix Tri-Factorization is proposed to solve the optimization problem. Comprehensive experiments demonstrate that MLTL can significantly outperform the state-of-the-art learning methods on topic and sentiment classification tasks. & 2016 Published by Elsevier B.V.	algorithm;concept learning;domain adaptation;experiment;feature vector;iterative method;latent variable;mathematical optimization;off topic;optimization problem;pluralism (philosophy)	Jianhan Pan;Xuegang Hu;Pei-Pei Li;Huizong Li;Wei He;Yuhong Zhang;Yaojin Lin	2016	Neurocomputing	10.1016/j.neucom.2015.12.097	transfer of learning;computer science;machine learning;pattern recognition;data mining;mathematics;probabilistic latent semantic analysis	AI	23.06670595787724	-43.942533605756125	17686
1f473c1ebefb5cc4a3b815e251226371dd3638c0	the evolving tree—a novel self-organizing network for data analysis	base dato multidimensional;consumer search;tecnologia electronica telecomunicaciones;computacion informatica;high dimensionality;analisis datos;metodo arborescente;branching;image classification;multidimensional database;carte autoorganisatrice;analisis programa;neural gas;data analysis;tree structured neural network;complex data;self organising feature maps;ciencias basicas y experimentales;ramificacion;tree structure;classification image;self organizing map;autoorganizacion;ramification;self organization;tree structured method;analyse donnee;self organized map;base donnee multidimensionnelle;methode arborescente;program analysis;reseau neuronal;analyse programme;tecnologias;grupo a;red neuronal;autoorganisation;neural network	The Self-Organizing Map (SOM) is one of the best known and most popular neural network-based data analysis tools. Many variants of the SOM have been proposed, like the Neural Gas by Martinetz and Schulten, the Growing Cell Structures by Fritzke, and the Tree-Structured SOM by Koikkalainen and Oja. The purpose of such variants is either to make a more flexible topology, suitable for complex data analysis problems or to reduce the computational requirements of the SOM, especially the time-consuming search for the best-matching unit in large maps. We propose here a new variant called the Evolving Tree which tries to combine both of these advantages. The nodes are arranged in a tree topology that is allowed to grow when any given branch receives a lot of hits from the training vectors. The search for the best matching unit and its neighbors is conducted along the tree and is therefore very efficient. A comparison experiment with high dimensional real world data shows that the performance of the proposed method is better than some classical variants of SOM.	artificial neural network;computation;computational complexity theory;erkki oja;experiment;learning rule;network topology;neural gas;organizing (structure);requirement;self-organization;self-organizing map;tree (data structure);tree network	Jussi Pakkanen;Jukka Iivarinen;Erkki Oja	2004	Neural Processing Letters	10.1007/s11063-004-2156-8	neural gas;program analysis;contextual image classification;self-organization;self-organizing map;branching;computer science;artificial intelligence;machine learning;ramification;tree structure;data analysis;artificial neural network;complex data type	ML	11.519002657269134	-31.133633089249223	17702
08fd0d8034d5bd624aef740180fa9aa07730ed84	a priori synthetic over-sampling methods for increasing classification sensitivity in imbalanced data sets		Compare OUPS and Safe Level OUPS against popular SMOTE generalizations.Safe Level OUPS resulted in the highest sensitivity and g-mean.OUPS modification did perform moderately well within neural networks.Safe Level OUPS improves prediction of noisy minority members using Linear SVM. Building accurate classifiers for predicting group membership is made difficult when using data that is skewed or imbalanced which is typical of real world data sets. The classifier has a tendency to be biased towards the over represented or majority group as a result. Re-sampling techniques offer simple approaches that can be used to minimize the effect. Over-sampling methods aim to combat class imbalance by increasing the number of minority group samples also refereed to as members of the minority group. Over the last decade SMOTE based methods have been used and extended to overcome this problem. There has been little emphasis on improvements to this approach with consideration to data intrinsic properties beyond that of class imbalance alone. In this paper we introduce modifications to a priori based methods Safe Level OUPS and OUPS that result in improvement for sensitivity measures over competing approaches using the SMOTE based method such as the Local neighborhood extension to SMOTE (LN-SMOTE), Borderline-SMOTE and Safe-Level-SMOTE.	oversampling;sampling (signal processing);synthetic intelligence	William A. Rivera;Petros Xanthopoulos	2016	Expert Syst. Appl.	10.1016/j.eswa.2016.09.010	artificial intelligence;machine learning;data mining;mathematics;statistics	Vision	14.170851243860703	-41.337413201834416	17711
db49a4e3f68cdbf33fc4394435c6f685956c3c72	funn: flexible unsupervised neural network		Deep neural networks have demonstrated high accuracy in image classification tasks. However, they were shown to be weak against adversarial examples: a small perturbation in the image which changes the classification output dramatically. In recent years, several defenses have been proposed to solve this issue in supervised classification tasks. We propose a method to obtain robust features in unsupervised learning tasks against adversarial attacks. Our method differs from existing solutions by directly learning the robust features without the need to project the adversarial examples in the original examples distribution space. A first auto-encoder A1 is in charge of perturbing the input image to fool another auto-encoder A2 which is in charge of regenerating the original image. A1 tries to find the less perturbed image under the constraint that the error in the output of A2 should be at least equal to a threshold. Thanks to this training, the encoder of A2 will be robust against adversarial attacks and could be used in different tasks like classification. Using state-of-art network architectures, we demonstrate the robustness of the features obtained thanks to this method in classification tasks.	adversary (cryptography);artificial neural network;autoencoder;computer vision;convolutional neural network;distribution (mathematics);encoder;supervised learning;unsupervised learning	David Vigouroux;Sylvain Picard	2018	CoRR			Vision	19.604419171383427	-51.10555566698048	17766
db374308655256da1479c272582d7c7139c97173	mobiface: a lightweight deep learning face recognition on mobile devices		Deep neural networks have been widely used in numerous computer vision applications, particularly in face recognition. However, deploying deep neural network face recognition on mobile devices is still limited since most highaccuracy deep models are both time and GPU consumption in the inference stage. Therefore, developing a lightweight deep neural network is one of the most promising solutions to deploy face recognition on mobile devices. Such the lightweight deep neural network requires efficient memory with small number of weights representation and low cost operators. In this paper a novel deep neural network named MobiFace, which is simple but effective, is proposed for productively deploying face recognition on mobile devices. The experimental results have shown that our lightweight MobiFace is able to achieve high performance with 99.7% on LFW database and 91.3% on large-scale challenging Megaface database. It is also eventually competitive against large-scale deep-networks face recognition while significant reducing computational time and memory consumption.	artificial neural network;computation;computational resource;computer vision;deep learning;facial recognition system;graphics processing unit;mobile device;network planning and design;time complexity	Chi Nhan Duong;Kha Gia Quach;Ngan Le;Nghia Nguyen;Khoa Luu	2018	CoRR			Vision	23.531571747583747	-51.674320142076965	17775
086f19561c91c0b2537ab770fe7111aacefe9240	object identification when imprecise information is available from multiple sources of unequal reliability		In this article we consider the problem of object identification when there is imprecise and perhaps conflicting information from information sources of unequal reliability. Data is represented by fuzzy sets, and the decision set in which the value of this imprecise information is modified by its importance in the context of the specific problem at hand is a type II fuzzy set in which the memberships are themselves fuzzy sets. Three criteria are proposed for making the classification based on the information contained in this type II fuzzy set. A simple example illustrates the procedure.		Robert M. Kleyle;André de Korvin	1994	Journal of Intelligent and Fuzzy Systems	10.3233/IFS-1994-2207	defuzzification;type-2 fuzzy sets and systems;fuzzy classification;fuzzy number;machine learning;pattern recognition;data mining;mathematics;fuzzy set operations	Robotics	-0.7109842361992815	-27.98654693683526	17799
e7b27902e61330393864121917bfb377b42b2b5e	fuzzy time series prediction method based on fuzzy recurrent neural network	medida informacion;forecasting;time series forecasting;prevision;linguistique;fuzzy neural nets;fuzzy number;informacion incompleta;mesure information;logique floue;logica difusa;reseau neuronal flou;analyse temporelle;time series;algoritmo genetico;analisis temporal;imperfect information;time analysis;fuzzy logic;incomplete information;systeme incertain;linguistica;time series analysis;information measure;information incomplete;serie temporelle;serie temporal;algorithme genetique;informacion imperfecta;genetic algorithm;reseau neuronal recurrent;recurrent neural nets;recurrent neural network;reseau neuronal;sistema incierto;uncertain system;red neuronal;forecasting method;time series prediction;historical data;neural network;information imparfaite;linguistics	One of the frequently used forecasting methods is the time series analysis. Time series analysis is based on the idea that past data can be used to predict the future data. Past data may contain imprecise and incomplete information coming from rapidly changing environment. Also the decisions made by the experts are subjective and rest on their individual competence. Therefore, it is more appropriate for the data to be presented by fuzzy numbers instead of crisp numbers. A weakness of traditional crisp time series forecasting methods is that they process only measurement based numerical information and cannot deal with the perception-based historical data represented by fuzzy numbers. Application of a fuzzy time series whose values are linguistic values, can overcome the mentioned weakness of traditional forecasting methods. In this paper we propose a fuzzy recurrent neural network (FRNN) based fuzzy time series forecasting method using genetic algorithm. The effectiveness of the proposed fuzzy time series forecasting method is tested on benchmark examples.	recurrent neural network;time series	Rafik A. Aliev;Bijan Fazlollahi;Rashad R. Aliev;Babek Guirimov	2006		10.1007/11893257_95	defuzzification;adaptive neuro fuzzy inference system;type-2 fuzzy sets and systems;fuzzy classification;computer science;artificial intelligence;fuzzy number;neuro-fuzzy;machine learning;time series;fuzzy set operations;artificial neural network;algorithm;statistics	ML	8.452909259438272	-28.662814069126444	17841
dfa0b819383d331baa976ba86a7eee79ebed75e6	generalized fuzzy soft set based fusion strategy for activity classification in smart home		In recent years, a plethora of different studies for design of traditional ensemble classifiers has been proposed in order to improve final recognition accuracy. However, among the ensemble classifiers, combination methods are focused on building independent classifiers of the same or different algorithms using majority voting methods. In this paper, we present a new fusion scheme for ensemble classifiers based on a new concept called Generalized Fuzzy Soft Set (GFSS), which we apply in activity classification. Essentially, we apply a weighted aggregate operator to the output of each classifier in order to fuse the GFSS into a more reliable classifier. The proposed fusion method is based on a new ranking algorithm to classify activities. We show that the proposed method produces more accurate results than the best single classifier and its effectiveness is demonstrated by comparing it with single classifier in terms of activity recognition accuracy.	activity recognition;aggregate data;algorithm;ensemble forecasting;ensemble learning;fuzzy measure theory;fuzzy set;heart rate variability;home automation;plausibility structure;statistical classification	Sofiane Bouznad;Faouzi Sebbak;Abdelghani Chibani;Farid Benhammadi	2017	2017 IEEE International Conference on Fuzzy Systems (FUZZ-IEEE)	10.1109/FUZZ-IEEE.2017.8015549	fuzzy logic;random subspace method;machine learning;artificial intelligence;operator (computer programming);computer science;soft set;activity recognition;cascading classifiers;classifier (linguistics);ranking;pattern recognition	Robotics	10.542680894741979	-39.90096329743942	17847
efd9a54cd7b7ca8d46217aa80675946454a1539f	a lake selection method based on dynamic multi-scale clustering		Current lake selection methods mostly uses the form of selecting as a whole, and are difficult to take into account the attribute characteristics, distribution characteristics and topological characteristics of the lake. By analyzing and imitating the cognitive behavior and process of artificial lakes selection, this paper proposes a lake selection method based on dynamic multiscale clustering. First, we set the area threshold to select the lakes with large area, then select the “isolated” lake through the buffer, then utilize the dynamic multi-scale clustering to the lake group to divide into areas with different density, decide the selection numbers by square root law and adopt the different selection strategy for the different areas, among which lakes are selected according to the comprehensive evaluation of importance calculated by iterative principal component analysis in the lake group class with a large number of features until the number of lakes reaches the selection number. Contrast of experiments show that the method maintains the morphological structure and density contrast of the lake group effectively, under the premise of considering the importance.		P. Duan;Haizhong Qian;Haiwei He;Limin Xie	2018		10.1109/GEOINFORMATICS.2018.8557179	premise;data mining;principal component analysis;cluster analysis;computer science;cartographic generalization;pattern recognition;artificial intelligence	EDA	2.964748409527267	-37.50374759791608	17862
1aee3468d835effae5ac439e0e5307370e4f33c0	sparse representations based attribute learning for flower classification	flower classification;attribute reduce;attribute learning;sparse representation	Classification for flowers is a very difficult task. Traditional methods need to built a classifier for each flower category, and obtain large number of flower samples to train these classifiers. In practice, many different types of flowers make the job become very difficult and boring. In this work, we present an attribute based approach for flowers recognition. Particularly, instead of training for a specific category of flowers directly based on manually designed features such as SIFT and HoG, we extract a series of visual attributes from a given set of flower images and generalize these to new images with possibly unknown flowers. A recently proposed sparse representations classification scheme is employed to predict the attributes of a given flower image from any category. In addition, we use a genetic algorithm to find the most discriminative attributes among others for better performance during the stage of flower classification. The effectiveness of the proposed method is validated on a publicly available flower classification database with promising results.	sparse	Keyang Cheng;Xiaoyang Tan	2014	Neurocomputing	10.1016/j.neucom.2014.05.011	computer science;machine learning;pattern recognition;sparse approximation;data mining;mathematics	Vision	18.852335092093316	-42.40437071212401	17871
8202da548a128b28dd1f3aa9f86a0523ec2ecb26	a skin detection approach based on the dempster-shafer theory of evidence	skin detection;image processing;dempster shafer theory of evidence;pattern recognition	Skin detection is an important step for a wide range of research related to computer vision and image processing and several methods have already been proposed to solve this problem. However, most of these methods suffer from accuracy and reliability problems when they are applied to a variety of images obtained under different conditions. Performance degrades further when fewer training data are available. Besides these issues, some methods require long training times and a significant amount of parameter tuning. Furthermore, most state-of-the-art methods incorporate one or more thresholds, and it is difficult to determine accurate threshold settings to obtain desirable performance. These problems arise mostly because the available training data for skin detection are imprecise and incomplete, which leads to uncertainty in classification. This requires a robust fusion framework to combine available information sources with some degree of certainty. This paper addresses these issues by proposing a fusion-based method termed Dempster–Shafer-based Skin Detection (DSSD). This method uses six prominent skin detection criteria as sources of information (SoI), quantifies their reliabilities (confidences), and then combines their confidences based on the Dempster–Shafer Theory (DST) of evidence. We use the DST as it offers a powerful and flexible framework for representing and handling uncertainties in available information and thus helps to overcome the limitations of the current state-ofthe-art methods. We have verified this method on a large dataset containing a variety of images, and achieved a 90.17% correct detection rate (CDR). We also demonstrate how DSSD can be used when very little training data are available, achieving a CDR as high as 87.47% while the best result achieved by a Bayesian classifier is only 68.81% on the same dataset. Finally, a generalized DSSD (GDSSD) is proposed achieving 91.12% CDR. 2012 Elsevier Inc. All rights reserved.	computer vision;image processing;naive bayes classifier	Mohammad Shoyaib;Mohammad Abdullah-Al-Wadud;Oksam Chae	2012	Int. J. Approx. Reasoning	10.1016/j.ijar.2012.01.003	image processing;computer science;artificial intelligence;machine learning;data mining;statistics	Vision	16.07791696885059	-40.91197937691076	17873
283579be57efda9444eee7a2994af065ee73802c	optimization of stack filters using sample selection probabilities.	sample selection			Ilya Shmulevich;Vladimir P. Melnik;Karen O. Egiazarian	1999			computer science	NLP	9.636913263802084	-36.563581750693565	17904
5d85435d7d275a3fb533f180014b3f5077bb843f	lightweight clustering technique for distributed data mining applications	minimum variance;cluster algorithm;number of clusters;distributed data mining	Many parallel and distributed clustering algorithms have already been proposed. Most of them are based on the aggregation of local models according to some collected local statistics. In this paper, we propose a lightweight distributed clustering algorithm based on minimum variance increases criterion which requires a very limited communication overhead. We also introduce the notion of distributed perturbation to improve the globally generated clustering. We show that this algorithm improves the quality of the overall clustering and manage to find the real structure and number of clusters of the global dataset.	algorithm;cluster analysis;clustering coefficient;computer data storage;data mining;distributed algorithm;loose coupling;overhead (computing);performance	Lamine M. Aouad;Nhien-An Le-Khac;M. Tahar Kechadi	2007		10.1007/978-3-540-73435-2_10	correlation clustering;constrained clustering;distributed algorithm;determining the number of clusters in a data set;minimum-variance unbiased estimator;data stream clustering;k-medians clustering;fuzzy clustering;flame clustering;computer science;theoretical computer science;canopy clustering algorithm;machine learning;consensus clustering;cure data clustering algorithm;data mining;hierarchical clustering;cluster analysis;single-linkage clustering;brown clustering;dbscan;biclustering;affinity propagation;statistics;clustering high-dimensional data	ML	0.7837805486123525	-40.861617048602035	17991
6eefd358f35c0222c5d64fda847d2bf6e1d48a8f	fuzzy sets-based methods and techniques for modern analytics			fuzzy set	Ali Ebrahimnejad;José L. Verdegay	2018		10.1007/978-3-319-73903-8	data mining;fuzzy set;computer science;analytics	DB	1.4814031139301902	-24.96715874910116	18003
d52f80ac8f3142b7cf51f5e35219340417a1b4ae	developing a feature weight self-adjustment mechanism for a k-means clustering algorithm	classification automatique statistiques;cluster algorithm;analyse multivariable;optimisation;analisis numerico;multivariate analysis;optimizacion;analisis datos;k means;65kxx;optimization method;metodo optimizacion;analyse numerique;experimental result;algorithme;49xx;discriminant analysis;analyse discriminante;optimization problem;algorithm;data analysis;analisis discriminante;iteraccion;numerical analysis;marginal distribution;62h30;mathematical programming;statistical computation;calculo estadistico;feature weighting;methode optimisation;resultado experimental;iteration;ley marginal;analisis multivariable;analyse donnee;k means algorithm;calcul statistique;optimization;cluster analysis statistics;resultat experimental;programmation mathematique;programacion matematica;k means clustering;loi marginale;algoritmo	K-means is one of the most popular and widespread partitioning clustering algorithms due to its superior scalability and efficiency. Typically, the K-means algorithm treats all features fairly and sets weights of all features equally when evaluating dissimilarity. However, a meaningful clustering phenomenon often occurs in a subspace defined by a specific subset of all features. To address this issue, this paper proposes a novel feature weight self-adjustment (FWSA) mechanism embedded into K-means in order to improve the clustering quality of K-means. In the FWSA mechanism, finding feature weights is modeled as an optimization problem to simultaneously minimize the separations within clusters and maximize the separations between clusters. With this objective, the adjustment margin of a feature weight can be derived based on the importance of the feature to the clustering quality. At each iteration in K-means, all feature weights are adaptively updated by adding their respective adjustment margins. A number of synthetic and real data are experimented on to show the benefits of the proposed FWAS mechanism. In addition, when compared to a recent similar feature weighting work, the proposed mechanism illustrates several advantages in both the theoretical and experimental results.	algorithm;cluster analysis;k-means clustering	Chieh-Yuan Tsai;Chuang-Cheng Chiu	2008	Computational Statistics & Data Analysis	10.1016/j.csda.2008.03.002	correlation clustering;constrained clustering;econometrics;fuzzy clustering;flame clustering;machine learning;mathematics;cluster analysis;linear discriminant analysis;feature;algorithm;statistics;k-means clustering	ML	8.914367110942038	-34.96514730191413	18029
056988f2353f5a7054ef7fd95cb529c48ef186bf	hierarchical multilabel classification based on path evaluation	multi label classification;chain classifiers;hierarchical classification	Multi-label classification assigns more than one label for each instance; when the labels are ordered in a predefined structure, the task is called Hierarchical Multi-label Classification (HMC). In HMC there are global and local approaches. Global approaches treat the problem as a whole but tend to explode with large datasets. Local approaches divide the problem into local subproblems, but usually do not exploit the information of the hierarchy. This paper addresses the problem of HMC for both tree and Direct Acyclic Graph (DAG) structures whose labels do not necessarily reach a leaf node. A local classifier per parent node is trained incorporating the prediction of the parent(s) node(s) as an additional attribute to include the relations between classes. In the classification phase, the branches with low probability to occur are pruned, performing non-mandatory leaf node prediction. Our method evaluates each possible path from the root of the hierarchy, taking into account the prediction value and the level of the nodes; selecting the path (or paths in the case of DAGs) with the highest score. We tested our method with 20 datasets with tree and DAG structured hierarchies against a number of state-of-the-art methods. Our method proved to obtain superior results when dealing with deep and populated hierarchies. A novel Hierarchical Multilabel Classification algorithm for tree and DAG structures.It adds an extra attribute to include relations between classes.It incorporates a novel weighting scheme and scores all the paths.It incorporates a novel pruning technique for non-mandatory leaf node prediction.	alpha–beta pruning;constant phase element;directed acyclic graph;population;tree (data structure)	Mallinali Ramírez-Corona;Luis Enrique Sucar;Eduardo F. Morales	2016	Int. J. Approx. Reasoning	10.1016/j.ijar.2015.07.008	machine learning;pattern recognition;data mining;mathematics	AI	17.398664094729437	-36.67214524371685	18071
76948cd2d9d5a954375bcea50dc6eae44dec7d89	discrimination of protein thermostability based on a new integrated neural network	integrated;genetic algorithm based selected ensemble;particle swarm optimization;protein thermostability;artificial neural network	The research of protein thermostability has been vigorously studied in the field of biophysical and biological technology. What is more, protein thermostability in the level of amino acid sequence is still a challenge in the research of the protein pattern recognition. In this paper, we try to use new integrated feedforward artificial neural network which was optimized by particle swarm optimization (PSO-NN) to recognize the mesophilic and thermophilic proteins. Here, we adopted Genetic Algorithm based Selected Ensemble (GASEN) as our integration methods. A better accuracy was got by GASEN. So, the integrated methods were proved to be effectual.	artificial neural network	Jingru Xu;Yuehui Chen	2011		10.1007/978-3-642-24955-6_13	computer science;bioinformatics;machine learning;particle swarm optimization;artificial neural network	NLP	12.414402689071464	-27.913598854851617	18111
0b7c1ce9677dbb720fc67ed82066ef351e5575e6	the relationship between classifier factorisation and performance in stochastic vector quantisation	traitement signal;classifier combination;euclidean theory;analisis estadistico;cost function;loi probabilite;ley probabilidad;posterior probability;euclidean distance;data fusion;probabilistic approach;classification;funcion coste;plan classement;multiple classifiers;cuantificacion vectorial;posterior distribution;vector quantization;statistical analysis;enfoque probabilista;approche probabiliste;signal processing;fusion donnee;probability distribution;probabilite a posteriori;analyse statistique;theorie euclidienne;probabilidad a posteriori;ley a posteriori;fonction cout;plan clasificacion;sparse data;vector quantisation;fusion datos;procesamiento senal;loi a posteriori;clasificacion;teoria euclidiana;classification scheme;quantification vectorielle	We seek to address the issue of multiple classifier formation within Luttrell's stochastic vector quantisation (SVQ) methodology. In particular, since (single layer) SVQs minimise a Euclidean distance cost function they tend to act as very faithful encoders of the input: however, for sparse data, or data with a large noise component, merely faithful encoding can give rise to a classifier with poor generalising abilities. We therefore seek to asses how the SVQs' ability to spontaneously factorise into independent classifiers relates to overall classification performance. In doing so, we shall propose a statistic to directly measure the aggregate 'factoriality' of code vector posterior probability distributions, which, we anticipate, will form the basis of a robust strategy for determining the capabilities of stochastic vector quantisers to act as unified classification/classifier-combination schemes.	vector quantization	David Windridge;Robin Patenall;Josef Kittler	2004		10.1007/978-3-540-25966-4_19	computer science;machine learning;signal processing;pattern recognition;mathematics;posterior probability;statistics	Vision	12.554977740636817	-33.879851496968314	18119
854747459415e4d8490fedaca19a67958f62c90a	fuzzy bayesian networks - a general formalism for representation, inference and learning with hybrid bayesian networks	loi discrete;bayes estimation;directed acyclic graph;discrete distribution;ley discreta;grafo aciclico;processus gauss;quantization;bayesian network;cuantificacion;fuzzy set;bayes net;sistema hibrido;learning;continuous variable;logique floue;conjunto difuso;logica difusa;loi conditionnelle;graphe acyclique;ensemble flou;ley condicional;curva gauss;quantification;hybrid bayesian networks;acyclic graph;aprendizaje;fuzzy logic;reseau bayes;estimacion bayes;apprentissage;gaussian mixture models;directed graph;graphe oriente;inferencia;hybrid system;loi normale;grafo orientado;gaussian process;proceso gauss;gaussian distribution;conditional distribution;inference;estimation bayes;systeme hybride	This paper proposes a general formalism for representation, inference and learning with general hybrid Bayesian networks in which continuous and discrete variables may appear anywhere in a directed acyclic graph. The formalism fuzzifies a hybrid Bayesian network into two alternative forms: the first form replaces each continuous variable in the given directed acyclic graph (DAG) by a partner discrete variable and adds a directed link from the partner discrete variable to the continuous one. The mapping between two variables is not crisp quantization but is approximated (fuzzified) by a conditional Gaussian (CG) distribution. The CG model is equivalent to a fuzzy set but no fuzzy logic formalism is employed. The conditional distribution of a discrete variable given its discrete parents is still assumed to be multinomial as in discrete Bayesian networks. The second form only replaces each continuous variable whose descendants include discrete variables by a partner discrete variable and adds a directed link from that partner discrete variable to the continuous one. The dependence between the partner discrete variable and the original continuous variable is approximated by a CG distribution, but the dependence between a continuous variable and its continuous and discrete parents is approximated by a conditional Gaussian regression (CGR) distribution. Obviously, the second form is a finer approximation, but restricted to CGR models, and requires more complicated inference and learning algorithms. This results in two general approximate representations of a general hybrid Bayesian networks, which are called here the fuzzy Bayesian network (FBN) form-I and form-II. For the two forms of FBN, general exact inference algorithms exists, which are extensions of the junction tree inference algorithm for discrete Bayesian networks. Learning fuzzy Bayesian networks from data is different from learning purely discrete Bayesian networks because not only all the newly converted discrete variables are latent in the data, but also the number of discrete states for each of these variables and the CG or CGR distribution of each continuous variable given its partner discrete parents or both continuous and discrete parents have to be determined.	bayesian network;semantics (computer science)	Heping Pan;Lin Liu	2000	IJPRAI	10.1142/S021800140000060X	discrete time and continuous time;discrete mathematics;computer science;artificial intelligence;machine learning;discrete system;pattern recognition;bayesian network;discrete-time stochastic process;mathematics;lambda-connectedness;directed acyclic graph;statistics	AI	20.746050892942662	-26.914832127507385	18138
c718328b5c62b4561890e72020157e8ac7fb1f63	privacy preserving identification using sparse approximation with ambiguization		In this paper, we consider a privacy preserving encoding framework for identification applications covering biometrics, physical object security and the Internet of Things (IoT). The proposed framework is based on a sparsifying transform, which consists of a trained linear map, an element-wise nonlinearity, and privacy amplification. The sparsifying transform and privacy amplification are not symmetric for the data owner and data user. We demonstrate that the proposed approach is closely related to sparse ternary codes (STC), a recent information-theoretic concept proposed for fast approximate nearest neighbor (ANN) search in high dimensional feature spaces that being machine learning in nature also offers significant benefits in comparison to sparse approximation and binary embedding approaches. We demonstrate that the privacy of the database outsourced to a server as well as the privacy of the data user are preserved at a low computational cost, storage and communication burdens.		Behrooz Razeghi;Slava Voloshynovskiy;Dimche Kostadinov;Olga Taran	2017	2017 IEEE Workshop on Information Forensics and Security (WIFS)	10.1109/WIFS.2017.8267664	theoretical computer science;computer science;k-nearest neighbors algorithm;encoding (memory);sparse approximation;server;biometrics;binary number;embedding;linear map	Security	19.757789729021365	-46.32040235053658	18184
deabe931a38911e3341b38876af6f16fd5061781	"""corrigendum to """"a two-stage genetic algorithm for automatic clustering"""" [neurocomputing 81 (2012) 49-59]"""	two-stage genetic algorithm;automatic clustering		cluster analysis;genetic algorithm;neurocomputing	Hong He;Yonghong Tan	2012	Neurocomputing	10.1016/j.neucom.2012.02.009		NLP	8.874416821895245	-40.579889819506754	18210
c8225d6e468458ed0fe47ee52465e1b9ed297a9b	fuzzy set theory and medical expert systems: survey and model	fuzzy set theory;fuzzy logic;medical expert system;fuzzy inference;smooth transition;medical diagnosis	In recent years, fuzzy set theory and Fuzzy Logic are applied successfuly in medical expert systems as CADIAG, MILORD etc. This paper intends to provide a short survey on application of fuzzy set theory in medicine, especialy, fuzzy logic in medical expert systems. An improved fuzzy inference model of CADIAG2 for medical diagnosis combining negative and positive evidence is presented. This model can be used for obtain more smooth transition between confirmed and disconfirmed diagnoses.	expert system;fuzzy logic;fuzzy set;set theory	Nguyen Hoang Phuong	1995		10.1007/3-540-60609-2_29	fuzzy logic;legal expert system;membership function;defuzzification;adaptive neuro fuzzy inference system;fuzzy classification;computer science;artificial intelligence;neuro-fuzzy;machine learning;medical diagnosis;data mining;mathematics;fuzzy set;fuzzy associative matrix;fuzzy set operations;fuzzy control system	AI	2.3342458637766192	-26.811940077124785	18333
c10a63b30a2fb0d1aebf37c10938835c6ae937bc	a clustering system for data sequence partitioning	fuzzy equivalence relation;clustering;cluster system;transitive closure;fuzzy compatible relation;data sequence;clustered data	In data analyzing, data is often presented as sequences. To partition the data sequences, we propose a sequence clustering system in which a fuzzy compatible relation is employed to show the similarity between any two sequences. Moreover, the max–min transitive closure is applied to transfer the fuzzy compatible relation into a fuzzy equivalence relation. It is found that the data sequences with more similar variations are clustered together by using the proposed clustering system. In that case, the sequences are partitioned easily and quickly into clusters. 2010 Elsevier Ltd. All rights reserved.	cluster analysis;multistage interconnection networks;sequence clustering;transitive closure;turing completeness	Yu-Jie Wang	2011	Expert Syst. Appl.	10.1016/j.eswa.2010.07.017	correlation clustering;discrete mathematics;fuzzy clustering;flame clustering;computer science;machine learning;data mining;cluster analysis;transitive closure;algorithm	AI	-2.570762815308793	-29.64042817412196	18353
70383a99dd407724e455280dc142369277f8175d	associating ids alerts by an improved apriori algorithm	candidate set list searching;generalized association rule;itemsets;maximal frequent itemsets;transaction processing data mining pattern recognition search problems security of data;intrusion detection;association rules;data mining;association rule mining;frequent itemset;intrusion detection system ids alert association apriori algorithm association rule mining algorithm database scanning candidate anthology maximal frequent itemsets intersection operation transaction database memory space reduction candidate set list searching;candidate anthology;association rule;intersection operation;pattern recognition;itemsets data mining association rules apriori algorithm;apriori algorithm;search problems;intrusion detection association rules itemsets data mining transaction databases iterative algorithms partitioning algorithms data engineering space technology data security;transaction processing;transaction database;optimal algorithm;ids alert association;association rule mining algorithm;security of data;algorithm design and analysis;memory space reduction;intrusion detection system;database scanning	Among a large number of association rule mining algorithms, Apriori algorithm is the most classic one, but the Apriori algorithm has three deficiencies, namely: the need for scanning databases many times, generating a large number of Candidate Anthology, as well as frequent itemsets iteratively. The paper presents a method that solves the maximal frequent itemsets through one intersection operation. The degree of support is obtained through the times of intersection without having to scan the transaction database, by numbering some of the properties to reduce memory space and search the candidate set list easily, thereby enhancing the efficiency of the algorithm. Finally, it can generate association rules for Intrusion Detection System. Experimental results show that the optimized algorithm can effectively improve the efficiency of mining association rules.	apriori algorithm;association rule learning;dspace;database;intrusion detection system;maximal set;the times	Wang Taihua;Guo Fan	2010	2010 Third International Symposium on Intelligent Information Technology and Security Informatics	10.1109/IITSI.2010.47	gsp algorithm;computer science;pattern recognition;data mining;database;fsa-red algorithm;apriori algorithm	DB	-4.527568064668038	-36.86039260918503	18389
c33373b83f8dd1c4270a58ed4cd8326d9b99f4d5	scale: a scalable framework for efficiently clustering transactional data	cluster algorithm;cluster validation;transactional data clustering;cluster assessment;transactional data clustering cluster assessment cluster validation frequent itemset mining weighted coverage density;bepress selected works;evaluation metric;transaction data;cluster analysis;frequent itemset mining;cluster validity;weighted coverage density;similarity measure;domain specificity	This paper presents SCALE, a fully automated transactional clustering framework. The SCALE design highlights three unique features. First, we introduce the concept of Weighted Coverage Density as a categorical similarity measure for efficient clustering of transactional datasets. The concept of weighted coverage density is intuitive and it allows the weight of each item in a cluster to be changed dynamically according to the occurrences of items. Second, we develop the weighted coverage density measure based clustering algorithm, a fast, memory-efficient, and scalable clustering algorithm for analyzing transactional data. Third, we introduce two clustering validation metrics and show that these domain specific clustering evaluation metrics are critical to capture the transactional semantics in clustering analysis. Our SCALE framework combines the weighted coverage density measure for clustering over a sample dataset with self-configuring methods. These self-configuring methods can automatically tune the two important parameters of our clustering algorithms: (1) the candidates of the best number K of clusters; and (2) the application of two domain-specific cluster validity measures to find the best result from the set of clustering results. We have conducted extensive experimental evaluation using both synthetic and real datasets and our results show that the weighted coverage density approach powered by the SCALE framework can efficiently generate high quality clustering results in a fully automated manner.	algorithm;categorical variable;cluster analysis;display resolution;domain-specific language;dynamic data;iterative method;refinement (computing);sampling (signal processing);scalability;similarity measure;streaming media;synthetic intelligence;transaction processing	Hua Yan;Keke Chen;Ling Liu;Zhang Yi	2009	Data Mining and Knowledge Discovery	10.1007/s10618-009-0134-5	correlation clustering;constrained clustering;data stream clustering;k-medians clustering;fuzzy clustering;flame clustering;computer science;data science;canopy clustering algorithm;machine learning;transaction data;consensus clustering;cure data clustering algorithm;data mining;database;hierarchical clustering;cluster analysis;single-linkage clustering;brown clustering;dbscan;biclustering;affinity propagation;clustering high-dimensional data;conceptual clustering	ML	0.031187083449942983	-41.21395538130749	18427
09da4e44b951796e77568913a56b6496813b2476	technology of intelligent diagnostics based on volterra kernels moments	analytical models;object recognition;kernel;nonlinear dynamical systems;volterra series fault diagnosis reliability theory;kernel nonlinear dynamical systems computational modeling mathematical model artificial intelligence object recognition analytical models;computational modeling;mathematical model;feature space dimensionality reduction fault diagnosis efficiency of diagnostics volterra kernels;artificial intelligence;reliability intelligent diagnostics volterra kernels moments informational technology nonlinear dynamic object model based diagnostics method nonparametric identification nonlinear dynamic objects simulation model fault diagnosis	The paper presents an informational technology for improving the reliability of nonlinear dynamic objects fault diagnosing using model-based diagnostics method of nonparametric identification. Diagnostic models build on the base of Volterra kernels moments. The efficiency of the proposed diagnostic models analyzes on an nonlinear dynamic objects simulation model.	linux;nonlinear system;simulation	Oleksandr Fomin;Andrew Medvedev;Vitaliy D. Pavlenko	2015	2015 IEEE 8th International Conference on Intelligent Data Acquisition and Advanced Computing Systems: Technology and Applications (IDAACS)	10.1109/IDAACS.2015.7341412	mathematical optimization;kernel;computer science;artificial intelligence;theoretical computer science;cognitive neuroscience of visual object recognition;machine learning;mathematical model;computational model;statistics	Robotics	21.899838752092087	-24.781628689635557	18436
3503ffddb0f5bf2a5463442a677daf6611403b16	universality of bayesian mixture predictors		The problem is that of sequential probability forecasting for discrete-valued time series. The data is generated by an unknown probability distribution over the space of all one-way infinite sequences. It is known that this measure belongs to a given set C, but the latter is completely arbitrary (uncountably infinite, without any structure given). The performance is measured by asymptotic average log loss. In this work it is shown that the minimax asymptotic performance is always attainable, and it is attained by a Bayesian mixture over countably many measures from the set C. This was previously only known for the case when the best achievable asymptotic error is 0. The new result can be interpreted as a complete-class theorem for prediction. It also contrasts previous results that show that in the non-realizable case all Bayesian mixtures may be suboptimal. This leads to a very general conclusion concerning model selection for a problem of sequential inference: it is better to take a model large enough to make sure it includes the process that generates the data, even if it entails positive asymptotic average loss, for otherwise any combination of predictors in the model class may be useless.	bayesian network;cross entropy;minimax;model selection;one-way function;time series;universality probability	Daniil Ryabko	2017			statistics;discrete mathematics;probability distribution;contrast (statistics);universality (philosophy);mathematical optimization;uncountable set;mathematics;minimax;convex combination;bayesian probability	ML	20.94520522981232	-31.18976581196472	18455
fcdecef00bc2fe688c079a65ba2203bb0002d59a	high-dimensional data analysis with subspace comparison using matrix visualization		Due to the intricate relationship between different dimensions of high-dimensional data, subspace analysis is often conducted to decompose dimensions and give prominence to certain subsets of dimensions, i.e. subspaces. Exploring and comparing subspaces are important to reveal the underlying features of subspaces, as well as to portray the characteristics of individual dimensions. To date, most of the existing high-dimensional data exploration and analysis approaches rely on dimensionality reduction algorithms (e.g. principal component analysis and multi-dimensional scaling) to project high-dimensional data, or their subspaces, to two-dimensional space and employ scatterplots for visualization. However, the dimensionality reduction algorithms are sometimes difficult to fine-tune and scatterplots are not effective for comparative visualization, making subspace comparison hard to perform. In this article, we aggregate high-dimensional data or their subspaces by computing pair-wise distances between all data...		Junpeng Wang;Xiaotong Liu;Han-Wei Shen	2019	Information Visualization	10.1177/1473871617733996	scaling;linear subspace;computer vision;clustering high-dimensional data;machine learning;principal component analysis;dimensionality reduction;visualization;computer science;subspace topology;matrix (mathematics);artificial intelligence	Visualization	-0.04881318288349217	-42.335154080364205	18500
d4f83936c145d2e355b3adce51f2a72b095c5422	an algorithm for mining outliers in categorical data through ranking	pattern clustering;data clustering data mining outlier detection categorical data;data mining;computational complexity;clustering algorithms roads algorithm design and analysis greedy algorithms data mining benchmark testing computational complexity;public domain categorical data sets outlier mining algorithm data mining outlier detection two phase algorithm data clustering independent ranking schemes attribute value frequencies clustering structure computational complexity;pattern clustering computational complexity data mining	The rapid growth in the field of data mining has lead to the development of various methods for outlier detection. Though detection of outliers has been well explored in the context of numerical data, dealing with categorical data is still evolving. In this paper, we propose a two-phase algorithm for detecting outliers in categorical data based on a novel definition of outliers. In the first phase, this algorithm explores a clustering of the given data, followed by the ranking phase for determining the set of most likely outliers. The proposed algorithm is expected to perform better as it can identify different types of outliers, employing two independent ranking schemes based on the attribute value frequencies and the inherent clustering structure in the given data. Unlike some existing methods, the computational complexity of this algorithm is not affected by the number of outliers to be detected. The efficacy of this algorithm is demonstrated through experiments on various public domain categorical data sets.	algorithm;anomaly detection;categorical variable;cluster analysis;computational complexity theory;data mining;experiment;level of measurement;sensor;two-phase locking	N. N. R. Ranga Suri;M. Narasimha Murty;Gopalasamy Athithan	2012	2012 12th International Conference on Hybrid Intelligent Systems (HIS)	10.1109/HIS.2012.6421342	correlation clustering;data stream clustering;k-medians clustering;fuzzy clustering;computer science;canopy clustering algorithm;machine learning;pattern recognition;cure data clustering algorithm;data mining;fsa-red algorithm;cluster analysis;dbscan;affinity propagation;clustering high-dimensional data	ML	-0.5630418923516712	-40.33458423744407	18529
3e9b684ed357949b4ea4a314da58a905b7a100e0	evaluation of the decision performance of the decision rule set from an ordered decision table	ordered decision tables;decision evaluation;decision rules;knowledge granulation;rough sets	An ordered decision table is one of the most effective frameworks for the intelligent decision-making systems. As two classical measures, approximation accuracy and quality of approximation can be extended for evaluating the decision performance of an ordered decision table. However, from the viewpoint of evaluating the decision performance of a set of decision rules, these two measures are still not able to well measure the entire certainty and consistency of an ordered decision rule set. To overcome this deficiency, we first present three new measures for evaluating the decision performance of a decision-rule set extracted from an ordered decision table, and then analyze how each of these new measures depends on the condition granulation and the decision granulation of an ordered decision table. Applications and experimental analysis of five types of ordered decision tables show that the three new measures appear to be well suited for evaluating the decision performance of a decision-rule set extracted from each of these five types of decision tables and the results are much better than those of the two extended measures.	algorithm;decision table	Yuhua Qian;Jiye Liang;Peng Song;Chuangyin Dang;Wei Wei	2012	Knowl.-Based Syst.	10.1016/j.knosys.2012.05.006	decision table;rough set;optimal decision;influence diagram;decision analysis;weighted product model;computer science;decision analysis cycle;machine learning;decision tree;pattern recognition;incremental decision tree;data mining;decision rule;admissible decision rule;evidential reasoning approach;evidential decision theory;weighted sum model;dominance-based rough set approach;decision matrix	ML	-2.0651283680434678	-25.82117214732036	18561
034657ca4953a0e4615dfe4189898ca7bbb0f94d	vehicle incident hot spots identification: an approach for big data		In this work we introduce a fast big data approach for road incident hot spot identification using Apache Spark. We implement an existing immuno-inspired mechanism, namely SeleSup, as a series of MapReduce-like operations. SeleSup is composed of a number of iterations that remove data redundancies and result in the detection of areas of high likelihood of vehicles incidents. It has been successfully applied to large datasets, however, as the size of the data increases to millions of instances, its performance drops significantly. Our objective therefore is to re-conceptualise the method for big data. In this paper we present the new implementation, the challenges faced when converting the method for the Apache Spark platform as well as the outcomes obtained. For our experiments we employ a large dataset containing hundreds of thousands of Heavy Good Vehicles incidents, collected via telematics. Results show a significant improvement in performance with no detriment to the accuracy of the method.		Isaac Triguero;Grazziela Patrocinio Figueredo;Mohammad Mesgarpour;Jonathan M. Garibaldi;Robert Ivor John	2017	2017 IEEE Trustcom/BigDataSE/ICESS	10.1109/Trustcom/BigDataSE/ICESS.2017.329	computer security;data mining;computer science;spark (mathematics);big data;distributed database;telematics	ML	1.3409552603431991	-34.84985196892083	18573
7a39e8559f823cfaf3220bbd5038da4c3591eccc	effective active learning strategy for multi-label learning		Abstract Data labelling is commonly an expensive process that requires expert handling. In multi-label data, data labelling is further complicated owing to the experts must label several times each example, as each example belongs to various categories. Active learning is concerned with learning accurate classifiers by choosing which examples will be labelled, reducing the labelling effort and the cost of training an accurate model. The main challenge in performing multi-label active learning is designing effective strategies that measure the informative potential of unlabelled examples across all labels. This paper presents a new active learning strategy for working on multi-label data. Two uncertainty measures based on the base classifier predictions and the inconsistency of a predicted label set, respectively, were defined to select the most informative examples. The proposed strategy was compared to several state-of-the-art strategies on a large number of datasets. The experimental results showed the effectiveness of the proposal for better multi-label active learning.	multi-label classification	Oscar Gabriel Reyes Pupo;Carlos Morell;Sebastián Ventura	2018	Neurocomputing	10.1016/j.neucom.2017.08.001	semi-supervised learning;artificial intelligence;machine learning;labelling;multi-label classification;active learning;pattern recognition;active learning (machine learning);stability (learning theory);computer science	Vision	15.948164110620505	-40.060134405050185	18658
615072166f223895d015a834e601fbfa46a29318	improving classification accuracy of decision trees for different abstraction levels of data	decision tree;data mining;classification;abstraction levels;data quality;classification accuracy	Classification is an important problem in data mining. Given a database of records, each tagged with a class label, a classifier generates a concise and meaningful description for each class that can be used to classify subsequent records. Since the data is collected from disparate sources in many actual data mining environments, it is common to have data values in different abstraction levels. This article introduces the multiple abstraction level problem in decision tree classification, and proposes a method to deal with it. The proposed method adopts the notion of fuzzy relation for solving the multiple abstraction level problem. The experimental results show that the proposed method reduces classification error rates significantly when multiple abstraction levels of data are involved.		Mina Jeong;Doheon Lee	2005	IJDWM	10.4018/jdwm.2005070101	data quality;biological classification;computer science;machine learning;decision tree;pattern recognition;data mining;database	ML	-2.737032001658969	-30.364326271574345	18672
6eeeb96350c676bbb9bf765851362e590e32eaed	max-margin zero-shot learning for multi-class classification		Due to the dramatic expanse of data categories and the lack of labeled instances, zero-shot learning, which transfers knowledge from observed classes to recognize unseen classes, has started drawing a lot of attention from the research community. In this paper, we propose a semi-supervised max-margin learning framework that integrates the semisupervised classification problem over observed classes and the unsupervised clustering problem over unseen classes together to tackle zero-shot multi-class classification. By further integrating label embedding into this framework, we produce a dual formulation that permits convenient incorporation of auxiliary label semantic knowledge to improve zero-shot learning. We conduct extensive experiments on three standard image data sets to evaluate the proposed approach by comparing to two state-of-the-art methods. Our results demonstrate the efficacy of the proposed framework.	cluster analysis;experiment;ibm notes;kernel method;machine learning;multiclass classification;semi-supervised learning;semiconductor industry;supervised learning	Xin Li;Yuhong Guo	2015			unsupervised learning;multiclass classification;learning classifier system	ML	23.084252831680608	-44.680343014535666	18731
00baea1a0c74ea173e4994c3920f2cbb719d2007	multi-layer unsupervised learning in a spiking convolutional neural network		Spiking neural networks (SNNs) have advantages over traditional, non-spiking networks with respect to biorealism, potential for low-power hardware implementations, and theoretical computing power. However, in practice, spiking networks with multi-layer learning have proven difficult to train. This paper explores a novel, bio-inspired spiking convolutional neural network (CNN) that is trained in a greedy, layer-wise fashion. The spiking CNN consists of a convolutional/pooling layer followed by a feature discovery layer, both of which undergo bio-inspired learning. Kernels for the convolutional layer are trained using a sparse, spiking auto-encoder representing primary visual features. The feature discovery layer uses a probabilistic spike-timing-dependent plasticity (STDP) learning rule. This layer represents complex visual features using WTA-thresholded, leaky, integrate-and-fire (LIF) neurons. The new model is evaluated on the MNIST digit dataset using clean and noisy images. Intermediate results show that the convolutional layer is stack-admissible, enabling it to support a multi-layer learning architecture. The recognition performance for clean images is above 98%. This performance is accounted for by the independent and informative visual features extracted in a hierarchy of convolutional and feature discovery layers. The performance loss for recognizing the noisy images is in the range 0.1% to 8.5%. This level of performance loss indicates that the network is robust to additive noise.	action potential;additive white gaussian noise;autoencoder;backpropagation;biological neuron model;british informatics olympiad;convolutional neural network;encoder;experiment;feature extraction;greedy algorithm;information;layer (electronics);learning rule;low insertion force;low-power broadcasting;mnist database;machine learning;software propagation;sparse matrix;spiking neural network;supervised learning;synapse;unsupervised learning;utility functions on indivisible goods;weapon target assignment problem	Amirhossein Tavanaei;Anthony S. Maida	2017	2017 International Joint Conference on Neural Networks (IJCNN)	10.1109/IJCNN.2017.7966099	convolutional neural network;machine learning;convolutional code;spiking neural network;feature extraction;deep learning;computer science;pattern recognition;unsupervised learning;mnist database;learning rule;artificial intelligence	ML	22.851171382528648	-51.62002838114909	18743
979e7f7f530487f95da415a5bcc86c240953a5ea	abnormal quality pattern recognition of industrial process based on multi-support vector machine		"""This paper studies the quality pattern recognition of industrial process based on the statistical process control (SPC). An abnormal quality pattern recognition model based on multi-support vector machine was proposed, which can be used to solve the problem of abnormal pattern recognition in the intelligent manufacturing process for products. The combination of """"one-to-one"""" and """"one-to-many"""" support vector machine (SVM) classifiers is arranged according to the structure of directed acyclic graphs in the model. At the same time, a structural optimization method was proposed to reduce the cumulative error problem. The model uses the original features of the data stream of quality. For the support vector machine classifier with low recognition accuracy, the statistical features and shape features form the data stream of quality are integrated with the original features. Relief algorithm is used to reduce the fusion features in order to reduce the consumption caused by increased features. The experimental results demonstrate that the model improves the accuracy of the recognition of abnormal patterns, and its structure also has a good time advantage."""		Lauren E Curtis;Lianglun Cheng	2018	JSW	10.17706/jsw.13.9.506-519	machine learning;support vector machine;computer science;artificial intelligence;pattern recognition	AI	9.996656440653123	-38.379739357573875	18750
f0381274dd80d2302f5e32843bd1fa5e3e691112	an inexact subsampled proximal newton-type method for large-scale machine learning		We propose a fast proximal Newton-type algorithm for minimizing regularized finite sums that returns an -suboptimal point in Õ(d(n + √ κd) log( 1 )) FLOPS, where n is number of samples, d is feature dimension, and κ is the condition number. As long as n > d, the proposed method is more efficient than state-of-the-art accelerated stochastic first-order methods for non-smooth regularizers which requires Õ(d(n+ √ κn) log( 1 )) FLOPS. The key idea is to form the subsampled Newton subproblem in a way that preserves the finite sum structure of the objective, thereby allowing us to leverage recent developments in stochastic first-order methods to solve the subproblem. Experimental results verify that the proposed algorithm outperforms previous algorithms for `1-regularized logistic regression on real datasets.	algorithm;chroma subsampling;condition number;flops;first-order predicate;first-order reduction;logistic regression;machine learning;newton	Xuanqing Liu;Cho-Jui Hsieh;Jason D. Lee;Yuekai Sun	2017	CoRR		flops;discrete mathematics;machine learning;mathematical optimization;artificial intelligence;tilde;mathematics;feature dimension;condition number	ML	24.34040641279501	-33.59443157002473	18755
c7ee8863e3d33ada56abd99ec3c8f0ba26378df6	a study of the radial basis function neural network classifiers using known data of varying accuracy and complexity	network performance;multilayer perceptron;mlp neural network;radial basis function;radial basis function neural network;speech recognition;neural network	Neural networks are increasingly used in a wide variety of applications such as speech recognition, diagnostic prediction, income prediction and credit screening. This paper empirically compares the performance of Radial Basis Function (RBF) and Multilayer Perceptron (MLP) neural networks using artificially generated data sets, enabling us to accurately chart the effectiveness of each network type and to provide some guidance to practitioners as to which type of network to use with their data. We find that when the discriminator is simple, RBF and MLP network performances are similar; when the number of data points is relatively small the MLP outperforms the RBF; when the discriminator is complex the RBF outperforms the MLP; and when the data has an unrelated input and the underlying discriminator is simple, the MLP outperforms the RBF.		Patricia S. Crowther;Robert J. Cox;Dharmendra Sharma	2004		10.1007/978-3-540-30134-9_30	probabilistic neural network;computer science;artificial intelligence;machine learning;pattern recognition;time delay neural network;multilayer perceptron;radial basis function network	AI	10.96056952458027	-38.00010398305417	18777
b6153933c4fe36a86e9bb0870f13a25c91df51cd	an optimal design of fuzzy (m, n) rank order filtering with hard decision neural learning	boolean functions;fuzzy control;information filtering;image restoration;fuzzy set theory;fuzzy sets;optimal design;computer science;information filters;algorithm design and analysis;filtering theory;filtering theory image restoration fuzzy set theory fuzzy control boolean functions information filtering information filters fuzzy sets algorithm design and analysis computer science		artificial neural network;optimal design	Rong-Chung Chen;Pao-Ta Yu	1995	J. Inf. Sci. Eng.	10.1109/ISCAS.1995.520385	fuzzy logic;discrete mathematics;membership function;defuzzification;adaptive neuro fuzzy inference system;fuzzy mathematics;fuzzy classification;computer science;fuzzy number;theoretical computer science;neuro-fuzzy;machine learning;mathematics;fuzzy set;fuzzy associative matrix;fuzzy set operations;algorithm;fuzzy control system	ML	3.314227374460977	-25.18479986146496	18790
4f081951130e81ed4ccafc7c938e3377f7297bba	logical vision: meta-interpretive learning for simple geometrical concepts		Progress in statistical learning in recent years has enabled computers to recognize objects with near-human ability. However, recent studies have revealed particular drawbacks in current computer vision systems which suggest there exist considerable differences between the way these systems function compared with human visual cognition. Major differences are that: 1) current computer vision systems learn high-level notions directly from the low-level feature space and ignore the mid-level representations, which makes them difficult to incorporate background knowledge. 2) typical computer vision systems learn visual concepts discriminatively instead of encoding the knowledge necessary to produce a visual representation of the class. In this paper, we introduce a framework referred as Logical Vision which is demonstrated on learning visual concepts constructively and symbolically. Given a set of images, a set of first-order logic formulae of background knowledge and a set of examples of target visual concepts, Logical Vision extracts logical facts concerning geometrical elements from an image by sampling low-level features guided by the background knowledge and conjecturing geometrical elements as output. It first extracts logical facts of mid-level features, then generative Meta-Interpretive Learning technique is applied to learn high-level notions because it is capable of learning recursions, inventing predicates and so on. Owing to its symbolic representation paradigm, in our implementation, Logical Vision is fully implemented in Prolog apart from low-level image feature extraction primitives. In our implementation, Logical Vision was used to extract polygon edges as mid-level symbols, and a generalized Meta-Interpreter Learner was applied to learn high-level geometrical notions. Experiments are conducted on learning shapes (e.g. triangles, quadrilaterals, etc.), regular polygons and right-angle triangles. These demonstrates that learning visual concepts constructively and symbolically is effective.	cognition;computer vision;discriminative model;existential quantification;feature (computer vision);feature extraction;feature vector;first-order logic;first-order predicate;high- and low-level;machine learning;programming paradigm;prolog;recursion;sampling (signal processing)	Wang-Zhou Dai;Stephen Muggleton;Zhi-Hua Zhou	2015			mathematics;artificial intelligence	AI	5.838033299156489	-31.766461365607334	18797
c825b78cb7ddd6bbeefe94cf6a15a90695302503	on improving recurrent neural network for image classification		The paper proposes a new method for improving the performance of Recurrent Neural Networks. The proposed method uses two parallel recurrent layers which execute independent of each other. The final output of recurrent layer at any time step is computed as the mean of the modulus of the output of these two layers. The proposed method attempts to overcome the limitations of the existing Recurrent Neural Networks with regard to the flow of gradient. Comparative performance of the proposed method has been carried out with Long Short Term Memory (LSTM) and Identity initialized RNN (IRNN), the latest improved version of RNN for classification of images. On benchmark image datasets, it has been shown that the proposed method outperforms both IRNN and LSTM.	activation function;artificial neural network;benchmark (computing);computer vision;gradient;long short-term memory;modulus of continuity;neural networks;random neural network;recurrent neural network;vanishing gradient problem	Bala Chandra;Rajesh Kumar Sharma	2017	2017 International Joint Conference on Neural Networks (IJCNN)	10.1109/IJCNN.2017.7966083	long short term memory;pattern recognition;artificial intelligence;machine learning;deep learning;computer science;backpropagation;contextual image classification;recurrent neural network;logic gate;benchmark (computing)	ML	22.478606145378684	-51.104004528651494	18808
7f71833e2d9d374d2fb1fc37e3c99911d545980f	multimodal generative models for scalable weakly-supervised learning		Multiple modalities often co-occur when describing natural phenomena. Learning a joint representation of these modalities should yield deeper and more useful representations. Previous generative approaches to multi-modal input either do not learn a joint distribution or require additional computation to handle missing data. Here, we introduce a multimodal variational autoencoder (MVAE) that uses a product-of-experts inference network and a sub-sampled training paradigm to solve the multi-modal inference problem. Notably, our model shares parameters to efficiently learn under any combination of missing modalities. We apply the MVAE on four datasets and match state-of-the-art performance using many fewer parameters. In addition, we show that the MVAE is directly applicable to weaklysupervised learning, and is robust to incomplete supervision. We then consider two case studies, one of learning image transformations—edge detection, colorization, segmentation—as a set of modalities, followed by one of machine translation between two languages. We find appealing results across this range of tasks.		Mike Wu;Noah D. Goodman	2018			autoencoder;machine learning;generative grammar;artificial intelligence;supervised learning;modalities;computer science;scalability;computation;missing data;inference	ML	24.39884160469183	-48.05649721962866	18816
16d5bbb925c2797e6112c3be3de99ea363e7cd33	an improved set covering problem for isomap supervised landmark selection	isometric feature mapping;set covering problem;classification;nonlinear dimensionality reduction;landmark selection	In this paper we present a novel method for supervised landmark selection to be framed within Landmark Isomap algorithm (L-Isomap). It is based on a weighted set covering problem aimed at finding a set of landmarks whose neighborhoods cover all the points at minimum cost. The cost associated to each neighborhood is a function of two indices measuring, respectively, the closeness of the points within the neighborhood and its class homogeneity. The resulting set covering problem is solved by means of a heuristic procedure based on Lagrangian relaxation with subgradient optimization. Computational tests performed on five labeled data sets showed the usefulness of L-Isomap combined with the new landmark selection technique. Indeed, it dominated effective competing methods and emerged as a valuable alternative to Isomap for efficient dimensionality reduction in supervised learning contexts. 2014 Elsevier B.V. All rights reserved.	centrality;computation;covering problems;experiment;heuristic;isomap;lagrangian relaxation;linear programming relaxation;machine learning;mathematical optimization;nonlinear dimensionality reduction;selection (genetic algorithm);selection algorithm;set cover problem;subderivative;subgradient method;supervised learning	Carlotta Orsenigo	2014	Pattern Recognition Letters	10.1016/j.patrec.2014.07.007	mathematical optimization;biological classification;computer science;machine learning;pattern recognition;mathematics;set cover problem;nonlinear dimensionality reduction	AI	20.864733680931952	-41.22848794420952	18817
6b0a4e4615daa1e7040c90e7666312a720325736	contrast pattern mining and its application for building robust classifiers	data mining;pattern mining;real world application	The ability to distinguish, differentiate and contrast between different data sets is a key objective in data mining. Such ability can assist domain experts to understand their data and can help in building classification models. This presentation will introduce the techniques for contrasting data sets. It will also focus on some important real world applications that illustrate how contrast patterns can be applied effectively for building robust classifiers.	data mining;robustness (computer science)	Kotagiri Ramamohanarao	2010		10.1007/978-3-642-16184-1_28	computer science;data science;machine learning;data mining;data stream mining	ML	6.530684051972269	-43.03090920673467	18833
309c72a9b7470b518110087e6be1fb4fdfe5c495	aksda-msvm: a gpu-accelerated multiclass learning framework for multimedia	gpu;discriminant analysis;svm;multiclass classification	In this paper, a combined nonlinear dimensionality reduction and multiclass classification framework is proposed. Specifically, a novel discriminant analysis (DA) technique, called accelerated kernel subclass discriminant analysis (AKSDA), derives a discriminant subspace, and a linear multiclass support vector machine (MSVM) computes a set of separating hyperplanes in the derived subspace. Moreover, within this framework an approach for accelerating the computation of multiple Gram matrices and an associated late fusion scheme are presented. Experimental evaluation in five multimedia datasets, on tasks such as video event detection and news document classification, shows that the proposed framework achieves excellent results in terms of both training time and generalization performance.	computation;document classification;gramian matrix;linear discriminant analysis;multiclass classification;nonlinear dimensionality reduction;nonlinear system;support vector machine	Stavros Arestis-Chartampilas;Nikolaos Gkalelis;Vasileios Mezaris	2016		10.1145/2964284.2967263	support vector machine;computer science;machine learning;multiclass classification;pattern recognition;data mining;optimal discriminant analysis;linear discriminant analysis;multiple discriminant analysis	ML	23.13047822652176	-42.76462690455816	18857
00cfa7e9899d2289024de7d2f6c3b26d5e02c592	dynamic information system and its rough set model based on time sequence	mathematics;information systems;cancer;information science;sorting;set theory;dynamic information;data analysis;information systems set theory information science mathematics medical treatment data analysis information analysis displays cancer sorting;displays;medical treatment;rough set;information analysis	Uncertain problems in fields of economy, population, medical treatment and real estate always present the extraordinary nature of inconsistency and process. With the aim to adapt traditional rough set theory and put it into dynamic information system, this paper first constructs dynamic information system based on time sequence and relevant rough set model, on the circumstances of keeping universe and attribute set intact. Secondly, it presents some properties of equivalent class and rough set based on time sequence during the alterative process of information system. Thus, this paper paves the way for further research on the theories and applications of rough set based on dynamic information systems.	information system;rough set;set theory;time series	Xiaowei He;Liming Xu;Wenzhong Shen	2006	2006 IEEE International Conference on Granular Computing	10.1109/GRC.2006.1635860	information algebra;information science;computer science;artificial intelligence;theoretical computer science;machine learning;data mining;data analysis;dominance-based rough set approach	DB	-3.6825101980581403	-26.697551917187543	18917
1034ac2ae2fcaded6e827af110ad068482ff8b6e	a new sequence distance measure for phylogenetic tree construction	lempel ziv;arbre phylogenetique;evolutionary model;alignement sequence;phylogeny;distance measure;phylogenese;alineacion secuencia;arbol filogenetico;modelo;construccion;phylogenetic tree;filogenesis;genome;inferencia;modele;sequence alignment;genoma;multiple;distance matrix;construction;models;phylogenetic inference;inference;multiple alignment	MOTIVATION Most existing approaches for phylogenetic inference use multiple alignment of sequences and assume some sort of an evolutionary model. The multiple alignment strategy does not work for all types of data, e.g. whole genome phylogeny, and the evolutionary models may not always be correct. We propose a new sequence distance measure based on the relative information between the sequences using Lempel-Ziv complexity. The distance matrix thus obtained can be used to construct phylogenetic trees.   RESULTS The proposed approach does not require sequence alignment and is totally automatic. The algorithm has successfully constructed consistent phylogenies for real and simulated data sets.   AVAILABILITY Available on request from the authors.	approximation;computational phylogenetics;contain (action);distance matrix;evolutionary algorithm;genome;hamming distance;inference;kolmogorov complexity;lz77 and lz78;lempel–ziv–stac;models of dna evolution;multiple sequence alignment;phylogenetic tree;trees (plant)	Hasan H. Otu;Khalid Sayood	2003	Bioinformatics	10.1093/bioinformatics/btg295	biology;combinatorics;phylogenetic tree;construction;distance matrix;distance matrices in phylogeny;multiple sequence alignment;bioinformatics;computational phylogenetics;sequence alignment;mathematics;phylogenetic network;algorithm;multiple;alignment-free sequence analysis;phylogenetics;genome	Comp.	0.9099146439730108	-51.45186956291125	18970
5fb103c8b65f88bc1a1457e1b0af9b1571af7c55	rule learning for classification based on neighborhood covering reduction	theoretical framework;covering reduction;rough set theory;rule learning;data mining;feature space;attribute reduction;real world application;machine learning;neighborhood covering;relative covering reduction;numerical experiment;rough set	Rough set theory has been extensively discussed in the domain of machine learning and data mining. Pawlak’s rough set theory offers a formal theoretical framework for attribute reduction and rule learning from nominal data. However, this model is not applicable to numerical data, which widely exist in real-world applications. In this work, we extend this framework to numerical feature spaces by replacing partition of universe with neighborhood covering and derive a neighborhood covering reduction based approach to extracting rules from numerical data. We first analyze the definition of covering reduction and point out its advantages and disadvantages. Then we introduce the definition of relative covering reduction and develop an algorithm to compute it. Given a feature space, we compute the neighborhood of each sample and form a neighborhood covering of the universe, and then employ the algorithm of relative covering reduction to the neighborhood covering, thus derive a minimal covering rule set. Some numerical experiments are presented to show the effectiveness of the proposed technique. 2011 Elsevier Inc. All rights reserved.	algorithm;approximation;c4.5 algorithm;data mining;decision tree learning;experiment;feature selection;feature vector;learning vector quantization;level of measurement;machine learning;numeric character reference;numerical analysis;overfitting;relevance;rough set;set theory	Yong Du;Qinghua Hu;Pengfei Zhu;Peijun Ma	2011	Inf. Sci.	10.1016/j.ins.2011.07.038	discrete mathematics;rough set;computer science;machine learning;data mining;mathematics	AI	1.363263716610502	-29.65649390869464	18972
16f5ef8e9e32c78655442ac30fdeb063f9ad3c59	radial basis function networks simulation of age-structure population				Tibor Kmet;Maria Kmetova	2018		10.1007/978-3-030-04070-3_32		ECom	11.423476342920518	-26.126714736333103	18976
822e2b2139b75667ea04d487932989a14059c393	semi-supervised learning of hidden conditional random fields for time-series classification	semi supervised learning;large margin methods;hidden conditional random fields;time series classification	Annotating class labels of a large number of time-series data is generally an expensive task. We propose novel semi-supervised learning algorithms that can improve the classification accuracy significantly by exploiting a relatively larger amount of unlabeled data in conjunction with a few labeled samples. Our algorithms utilize the unlabeled data as regularizers for opting for classifiers with stronger certainty on the unlabeled data. For the state-of-the-art conditional probabilistic sequence model called the hidden conditional random field, we first suggest the entropy minimization algorithm that was previously applied for static classification setups. More sophisticated margin-based approaches are then introduced, motivated by the semi-supervised support vector machines originally aimed for non-sequential data. We provide effective ways to incorporate and minimize the hat loss function for sequence data via probabilistic treatment in a principled manner. We show the performance improvement achieved by our methods on several semi-supervised time-series data classification scenarios.	conditional random field;semi-supervised learning;semiconductor industry;supervised learning;time series	Minyoung Kim	2013	Neurocomputing	10.1016/j.neucom.2013.03.024	semi-supervised learning;computer science;machine learning;pattern recognition;data mining;statistics	ML	17.36568632359367	-38.57561068700059	18978
69c9169c275287f2495a3ef37f5481fa27962c10	a reliable method for the diagnosis of gastric carcinoma	ensemble of classifiers;machine learning;prediction accuracy;genetic algorithm;feature selection;gastric carcinoma	Predicting the different levels of gastric carcinoma from clinical and histopathological investigations is an important problem in bioinformatics and a challenging task for machine learning algorithms. In this paper, we have investigated an ensemble of classifiers and tested it on a real-world dataset. A genetic algorithm is applied to select the most relevant features. The obtained results are very encouraging, our results improve the average predictive accuracy obtained in previously published works. r 2005 Elsevier B.V. All rights reserved.	bioinformatics;genetic algorithm;implantable gastric stimulation;machine learning	Loris Nanni	2006	Neurocomputing	10.1016/j.neucom.2005.08.001	genetic algorithm;computer science;bioinformatics;machine learning;pattern recognition;feature selection	AI	9.223516542708868	-48.66933811830363	19054
a1038dcafa26de6dc5dda37942bf1f1fa1db5b01	instance-ranking: a new perspective to consider the instance dependency for classification	multi label classification;knn;instance ranking;ml knn	Single-label classification refers to the task to predict an instance to be one unique label in a set of labels. Different from single-label classification, for multi-label classification, one instance is associated with one or more labels in a set of labels simultaneously. Various works have focused on the algorithms for those two types of classification. Since the ranking problem is always coexisting with the classification problem, and traditional researches mainly assume the uniform distribution for the instances, in this paper, we propose a new perspective for the ranking problem. With the assumption that the distribution for the instance is not uniform, different instances have different influences for the distribution, the Instance-Ranking algorithm is presented. With the InstanceRanking algorithm, the famous K-nearest-neighbors (KNN) algorithm is modified to confirm the validity of our algorithm. Lastly, the Instance-Ranking algorithm is combined with the ML.KNN algorithm for multi-label classification. Experiment with different datasets show that our Instance-Ranking algorithm achieves better performance than the original state-of-art algorithm such as KNN and ML.KNN.	data mining;experiment;k-nearest neighbors algorithm;multi-label classification;semi-supervised learning;semiconductor industry	Xin Xia;Xiaohu Yang;Shanping Li;Chao Wu	2012		10.1007/978-3-642-36778-6_10	computer science;machine learning;pattern recognition;data mining;mathematics;k-nearest neighbors algorithm	AI	15.469463181054298	-42.608547927011905	19071
b1e94fb9529b438de9467ab2c0f4ed58f27252f4	combining multiple biometric traits with an order-preserving score fusion algorithm	order preserving algorithm;multibiometric system;tree structured ensemble;score fusion	Multibiometric systems based on score fusion can effectively combine the discriminative power of multiple biometric traits and overcome the limitations of individual trait, leading to a better performance of biometric authentication. To tackle multiple adverse issues with the established classifierbased or probability-based algorithms, in this paper we propose a novel order-preserving probabilistic score fusion algorithm, Order-Preserving Tree (OPT), by casting the score fusion problem into an optimisation problem with the natural order-preserving constraint. OPT is an algorithm fully non-parametric and widely applicable, not assuming any parametric forms of probabilities or independence among sources, directly estimating the posterior probabilities from maximum likelihood estimation, and exploiting the power of tree-structured ensembles. We demonstrate the effectiveness of our OPT algorithm by comparing it with many widely-used score fusion algorithms on two prevalent multibiometric databases.	algorithm;authentication;benchmark (computing);biometrics;curse of dimensionality;database;experiment;mathematical optimization;nist hash function competition	Yicong Liang;Xiaoqing Ding;Changsong Liu;Jing-Hao Xue	2016	Neurocomputing	10.1016/j.neucom.2015.06.039	machine learning;pattern recognition;data mining;mathematics;statistics	AI	17.9352932397643	-43.255898365386265	19100
5d7c5f98bb0037d2929f1693e5a72156717da483	mutual information based minimum spanning trees model for selecting discriminative genes	selection model;discriminative genes;time complexity;filter methods;mutual information based minimum spanning trees;genetics arrays biotechnology genetic algorithms;genetics;gene expression;arrays;microarray data analysis;mutual information gene selection minimum spanning trees;convergent algorithms;gene expression mutual information based minimum spanning trees discriminative genes microarray data analysis filter methods convergent algorithms mimst biotechnology;minimum spanning tree;mutual information;genetic algorithms;mimst;mutual information filters data analysis computer science shape data engineering gene expression signal to noise ratio euclidean distance helium;classification accuracy;gene selection;biotechnology;minimum spanning trees	Recent studies have shown that gene selection is a crucial technology in microarray data analysis as a result of its large number of genes and relatively small number of samples. Filter methods are fast convergent algorithms with low time complexity. However, filter methods neglect correlation among genes. Other methods for gene selection also have disadvantages. For example, the measurement used to calculate the correlation in other methods can not effectively reflect function similarity among genes, the time complexity will be high based on the whole gene set. Therefore, we propose a novel selection model called mutual information based minimum spanning trees (MIMST) which considers both gene interaction and complementary genes. In this new model, we first use filter methods to remove non-relevant genes, and then compute the interdependence of top-ranked genes. Finally, we construct MST to remove the redundant genes. The experiment results show that MIMST can find the smallest siMIMSTgnificant genes subset with higher classification accuracy compared with other methods.	algorithm;file spanning;interdependence;microarray;minimum spanning tree;mutual information;time complexity	Fang Zhou;Jieyue He;Wei Zhong	2007	2007 IEEE 7th International Symposium on BioInformatics and BioEngineering	10.1109/BIBE.2007.4375687	gene-centered view of evolution;time complexity;biology;microarray analysis techniques;gene expression;genetic algorithm;computer science;bioinformatics;minimum spanning tree;machine learning;pattern recognition;mutual information;genetics	Comp.	5.913817024634398	-47.911255858851895	19120
6a0ce4bb16e6ff6294ba19ae58837359a802a5d6	training neural networks using predictor-corrector gradient descent		We improve the training time of deep feedforward neural networks using a modified version of gradient descent we call Predictor-Corrector Gradient Descent (PCGD). PCGD uses predictor-corrector inspired techniques to enhance gradient descent. This method uses a sparse history of network parameter values to make periodic predictions of future parameter values in an effort to skip unnecessary training iterations. This method can cut the number of training epochs needed for a network to reach a particular testing accuracy by nearly one half when compared to stochastic gradient descent (SGD). PCGD can also outperform, with some trade-offs, Nesterov’s Accelerated Gradient (NAG).	artificial neural network;gradient descent	Amy Nesky;Quentin F. Stout	2018		10.1007/978-3-030-01424-7_7	machine learning;feedforward neural network;artificial neural network;artificial intelligence;one half;stochastic gradient descent;gradient descent;predictor–corrector method;computer science	ML	17.298833358137692	-32.33586506581396	19157
77af55d36d2c2381ba55cf45acdd7cd1ad44fa6c	experimental comparison of combination rules using simulated data	classifier ensemble;simulation pattern classification;ensemble of classifiers;simulation;null;simulator;combination rule;recognition performance matrix;simulation methods;simulated data;pattern classification;voting particle measurements performance analysis noise measurement noise level estimation error automatic generation control;performance profile;experimental comparison;performance profile combination rule simulated data experimental comparison classifier ensemble recognition performance matrix simulator	In this paper, we report an experimental comparison between widely used combination rules, i.e. sum, product, maximum, borda count and best rank rules. We focus on the behavior of the considered combination rules for ensembles of classifiers exhibiting different performance of recognition. To this end, a simulation method using as input a specified performance matrix (i.e. recognition rates for each position of the true class and rejection rates) is proposed. This simulator generates ensembles of classifier outputs with specified profiles of performance within their list of solutions. Our experimental results tend to show that these profiles of performance are one of the factors that affect the behavior of the combination rules	best practice;ensembles of classifiers;rejection sampling;simulation;statistical classification	Héla Zouari;Laurent Heutte;Yves Lecourtier	2006	18th International Conference on Pattern Recognition (ICPR'06)	10.1109/ICPR.2006.516	computer science;machine learning;pattern recognition;data mining	Robotics	13.080560214759368	-42.459897054918436	19262
0ec9ee064d9acc194adc0deace107d50a7f50c93	new perspectives and methods in link prediction	networks;supervised learning;evaluation method;link prediction;class imbalance;machine learning;high performance;variance reduction	This paper examines important factors for link prediction in networks and provides a general, high-performance framework for the prediction task. Link prediction in sparse networks presents a significant challenge due to the inherent disproportion of links that can form to links that do form. Previous research has typically approached this as an unsupervised problem. While this is not the first work to explore supervised learning, many factors significant in influencing and guiding classification remain unexplored. In this paper, we consider these factors by first motivating the use of a supervised framework through a careful investigation of issues such as network observational period, generality of existing methods, variance reduction, topological causes and degrees of imbalance, and sampling approaches. We also present an effective flow-based predicting algorithm, offer formal bounds on imbalance in sparse network link prediction, and employ an evaluation method appropriate for the observed imbalance. Our careful consideration of the above issues ultimately leads to a completely general framework that outperforms unsupervised link prediction methods by more than 30% AUC.	algorithm;sampling (signal processing);sparse matrix;supervised learning;unsupervised learning;variance reduction	Ryan Lichtenwalter;Jake T. Lussier;Nitesh V. Chawla	2010		10.1145/1835804.1835837	computer science;artificial intelligence;machine learning;data mining;supervised learning;statistics;variance reduction	ML	19.862650719916775	-44.00385055021337	19302
3b0370af352286e23e5ae5845bd02cebd7034cf2	cluster validity index based on n-sphere	geometrical shape cluster validity index cvi n sphere;pattern clustering geometry;indexes volume measurement clustering algorithms iris partitioning algorithms shape vectors;indexes;shape;vectors;clustering algorithms;volume measurement;iris;partitioning algorithms	In this paper, we propose a new cluster validity index (CVI) based on geometrical shape. Classic CVIs are based on a combination of separation and compactness measures and may include a measure of overlap between clusters. The proposed CVI combines measures of compactness and over-lap using n-sphere shape. We conducted experiments on several real data sets from the UCI repository and compared the performances of the proposed CVI with widely used CVIs. Results demonstrate that the proposed CVI performs better than the others even when used with complicated data sets.	cluster analysis;experiment;labwindows/cvi;performance	Ahmed Ben Said;Sebti Foufou;Mongi A. Abidi	2014	2014 IEEE/ACS 11th International Conference on Computer Systems and Applications (AICCSA)	10.1109/AICCSA.2014.7073191	database index;shape;computer science;machine learning;pattern recognition;cluster analysis	Vision	1.7750508476490772	-40.04549556714742	19319
8ad94d60e30095a5bffb71149d627ed0791b19be	semi-supervised fuzzy-rough feature selection	science general;semi supervised learning;dk atira pure researchoutput researchoutputtypes contributiontobookanthology conference;feature selection;fuzzy rough sets	With the continued and relentless growth in dataset sizes in recent times, feature or attribute selection has become a necessary step in tackling the resultant intractability. Indeed, as the number of dimensions increases, the number of corresponding data instances required in order to generate accurate models increases exponentially. Fuzzy-rough set-based feature selection techniques offer great flexibility when dealing with real-valued and noisy data; however, most of the current approaches focus on the supervised domain where the data object labels are known. Very little work has been carried out using fuzzy-rough sets in the areas of unsupervised or semi-supervised learning. This paper proposes a novel approach for semi-supervised fuzzy-rough feature selection where the object labels in the data may only be partially present. The approach also has the appealing property that any generated subsets are also valid (super)reducts when the whole dataset is labelled. The experimental evaluation demonstrates that the proposed approach can generate stable and valid subsets even when up to 90% of the data object labels are missing.	feature selection;little big adventure;resultant;rough set;semi-supervised learning;semiconductor industry;signal-to-noise ratio;supervised learning;unsupervised learning	Richard Jensen;Sarah Vluymans;Neil MacParthalain;Chris Cornelis;Yvan Saeys	2015		10.1007/978-3-319-25783-9_17	computer science;artificial intelligence;machine learning;pattern recognition;data mining;mathematics;feature selection;statistics	AI	14.610477736063732	-39.004553640485994	19328
1296eeb0858f28856d446015298c9848330b147c	langevin dynamics with continuous tempering for training deep neural networks		Minimizing non-convex and high-dimensional objective functions is challenging, especially when training modern deep neural networks. In this paper, a novel approach is proposed which divides the training process into two consecutive phases to obtain better generalization performance: Bayesian sampling and stochastic optimization. The first phase is to explore the energy landscape and to capture the ‘fat” modes; and the second one is to fine-tune the parameter learned from the first phase. In the Bayesian learning phase, we apply continuous tempering and stochastic approximation into the Langevin dynamics to create an efficient and effective sampler, in which the temperature is adjusted automatically according to the designed “temperature dynamics”. These strategies can overcome the challenge of early trapping into bad local minima and have achieved remarkable improvements in various types of neural networks as shown in our theoretical analysis and empirical experiments.	artificial neural network;bayesian network;convex function;deep learning;experiment;file allocation table;mathematical optimization;maxima and minima;sampling (signal processing);stochastic approximation;stochastic optimization	Nanyang Ye;Zhanxing Zhu;Rafal Mantiuk	2017			langevin dynamics;stochastic optimization;machine learning;mathematical optimization;artificial intelligence;energy landscape;maxima and minima;artificial neural network;sampling (statistics);mathematics;bayesian inference;stochastic approximation	ML	18.614103207144613	-32.62952749582728	19364
bc68ba8db6d2fc769105c583ac9eb9c813ba90dc	generating an interpretable family of fuzzy partitions from data	hierarchical clustering;food processing;fuzzy c mean;rule induction;fuzzy set;agricultural data fuzzy partitions fuzzy sets data distribution merging technique fuzzy inference system;neural networks;learning;semantic integration;multidimensional data;inference mechanisms;interpretability;indexing terms;fuzzy set theory;fuzzy sets;data distribution;discriminant analysis;fuzzy partitioning;fuzzy clustering;statistical analysis;data structures;clustering method;fuzzy inference system;merging;statistics;agricultural data;agriculture;humans;fuzzy systems fuzzy sets merging multidimensional systems clustering methods humans neural networks statistics;fuzzy partitions;clustering methods;fuzzy systems;multidimensional systems;distance;merging technique;statistical analysis fuzzy set theory agriculture data structures inference mechanisms fuzzy systems	In this paper, we propose a new method to construct fuzzy partitions from data. The procedure generates a hierarchy including best partitions of all sizes from n to two fuzzy sets. The maximum size n is determined according to the data distribution and corresponds to the finest resolution level. We use an ascending method for which a merging criterion is needed. This criterion is based on the definition of a special metric distance suitable for fuzzy partitioning, and the merging is done under semantic constraints. The distance we define does not handle the point coordinates, but directly their membership degrees to the fuzzy sets of the partition. This leads to the introduction of the notions of internal and external distances. The hierarchical fuzzy partitioning is carried independently over each dimension, and, to demonstrate the partition potential, they are used to build fuzzy inference system using a simple selection mechanism. Due to the merging technique, all the fuzzy sets in the various partitions are interpretable as linguistic labels. The tradeoff between accuracy and interpretability constitutes the most promising aspect in our approach. Well known data sets are investigated and the results are compared with those obtained by other authors using different techniques. The method is also applied to real world agricultural data, the results are analyzed and weighed against those achieved by other methods, such as fuzzy clustering or discriminant analysis.	cluster analysis;fuzzy clustering;fuzzy set;inference engine;linear discriminant analysis	Serge Guillaume;Brigitte Charnomordic	2004	IEEE Transactions on Fuzzy Systems	10.1109/TFUZZ.2004.825979	data structure;membership function;defuzzification;adaptive neuro fuzzy inference system;type-2 fuzzy sets and systems;fuzzy classification;computer science;fuzzy number;machine learning;pattern recognition;fuzzy measure theory;data mining;mathematics;fuzzy set;fuzzy associative matrix;linear discriminant analysis;fuzzy set operations;artificial neural network;fuzzy control system	Visualization	2.8097950129993023	-29.8939178948201	19383
85098268f3c3ae9c30979d53f1835851a314fe61	deep binary reconstruction for cross-modal hashing		With the increasing demand of massive multimodal data storage and organization, cross-modal retrieval based on hashing technique has drawn much attention nowadays. It takes the binary codes of one modality as the query to retrieve the relevant hashing codes of another modality. However, the existing binary constraint makes it difficult to find the optimal cross-modal hashing function. Most approaches choose to relax the constraint and perform thresholding strategy on the real-value representation instead of directly solving the original objective. In this paper, we first provide a concrete analysis about the effectiveness of multimodal networks in preserving the inter- and intra-modal consistency. Based on the analysis, we provide a so-called Deep Binary Reconstruction (DBRC) network that can directly learn the binary hashing codes in an unsupervised fashion. The superiority comes from a proposed simple but efficient activation function, named as Adaptive Tanh (ATanh). The ATanh function can adaptively learn the binary codes and be trained via back-propagation. Extensive experiments on three benchmark datasets demonstrate that DBRC outperforms several state-of-the-art methods in both image2text and text2image retrieval task.	activation function;backpropagation;benchmark (computing);binary code;binary constraint;binary number;computer data storage;embedded system;experiment;hash function;modal logic;multimodal interaction;software propagation;thresholding (image processing);unsupervised learning	Xuelong Li;Di Hu;Feiping Nie	2017		10.1145/3123266.3123355	binary code;binary constraint;pattern recognition;artificial intelligence;machine learning;universal hashing;hash function;k-independent hashing;thresholding;dynamic perfect hashing;computer science;activation function	AI	21.080124857534887	-48.04688118354189	19405
23521fcc46ef352c5dd233e9e801604f64375608	learning random subspace novelty detection filters	training training data neural networks data models ionosphere testing noise measurement;g mean metric random subspace novelty detection filter orthogonal projection operator sampling technique bootstrap idea ensemble idea random feature selection ndf induction process online learning algorithm cross validation experiment precision and recall metric false positive rate metric false negative rate metric f measure metric;sampling methods learning artificial intelligence;novelty detection;learning artificial intelligence;sampling methods	In this paper we propose a novelty detection framework based on the orthogonal projection operators and the bootstrap idea. Our approach called Random Subspace Novelty Detection Filter (RS - NDF) combines the sampling technique and the ensemble idea. RS - NDF is an ensemble of NDF, induced from bootstrap samples of the training data, using random feature selection in the NDF induction process. Prediction is made by aggregating the predictions of the ensemble. RS - NDF generally exhibits a substantial performance improvement over the single NDF. Thanks to an online learning algorithm, the RS-NDF approach is also able to track changes in data over time. The RS - NDF method is compared to single NDF and other novelty detection methods with tenfold cross-validation experiments on publicly available datasets, where the methods superiority is demonstrated. Performance metrics such as precision and recall, false positive rate and false negative rate, F-measure, AUC and G-mean are computed. The proposed approach is shown to improve the prediction accuracy of the novelty detection, and have favorable performance compared to the existing algorithms.	algorithm;authentication;booting;bootstrapping (statistics);cross-validation (statistics);ensemble learning;event (computing);experiment;f1 score;feature selection;mathematical induction;novelty detection;precision and recall;programming paradigm;reed–solomon error correction;sampling (signal processing)	Fatma Hamdi;Younès Bennani	2011	The 2011 International Joint Conference on Neural Networks	10.1109/IJCNN.2011.6033512	sampling;computer science;artificial intelligence;machine learning;pattern recognition;statistics	Vision	14.420895266739366	-41.096028424523865	19422
27d2f587317d0b2b4805cedec5b9502c2aacccc8	s-knowledge mining and its attribute transfer dependence	finite element methods;the principle of mining dependence;attribute transfer;mathematics;electronic mail;rough set theory data mining;heritage;rough set theory;outer mining degree s knowledge mining f fmacr attribute transfer dependence s rough sets inner mining degree;s knowledge mining;data mining;one direction s rough sets;the principle of mining dependence one direction s rough sets s knowledge attribute transfer mining degree;mining degree;dynamic characteristic;rough set;outer mining degree;f;s rough sets;s knowledge;fmacr attribute transfer dependence;fuzzy systems;mathematics electronic mail fuzzy systems statistics finance knowledge engineering rough sets knowledge transfer;inner mining degree	S-rough sets have dynamic characteristic. Using S-rough sets and the (f, fmacr)-attribute transfer dependence, the concepts of inner mining degree and outer mining degree are presented, and inner and outer transfer dependence of attributes and the value characteristics of knowledge inner and outer mining are discussed. According to the concepts of inner mining degree and outer mining degree, the minimum inner mining degree theorem of inner mining knowledge, the maximum outer mining degree theorem of outer mining knowledge, and the theorem of attributes transfer dependence are given in this paper.	data mining;rough set	Xiumei Hao;Yingling Du	2008	2008 Fifth International Conference on Fuzzy Systems and Knowledge Discovery	10.1109/FSKD.2008.301	rough set;computer science;machine learning;pattern recognition;data mining;mathematics;fuzzy control system	ML	-1.6264452091438004	-25.34288368946573	19442
391b1da42652c9d9ec82850b09910fd2241fa086	a study of possible improvements to the alopex training algorithm	probability;annealing probability temperature testing stochastic processes neural networks energy measurement computer networks distributed computing logistics;recurrent neural nets;learning artificial intelligence;probability recurrent neural nets learning artificial intelligence;training algorithm;recurrent neural networks alopex algorithm learning algorithm local correlations	We studied the performance of the Alopex algorithm, and proposed modifications that improve the training time, and simplified the algorithm. We tested different variations of the algorithm. We describe the best cases and summarize the conclusions we arrived at. One of the proposed variations (99/B) performs slightly faster than the Alopex algorithm described by Unnikrishnan et al. (1994), showing less unsuccessful training attempts, while being simpler to implement. Like Alopex, our versions are based on local correlations between changes in individual weights and changes in the global error measure. Our algorithm is also stochastic, but it differs from Alopex in the fact that no annealing scheme is applied during the training process and hence it uses less parameters.	alopex;algorithm	Alejandro Bia	2000		10.1109/SBRN.2000.889726	simulation;computer science;artificial intelligence;machine learning;probability;statistics	NLP	16.95542512715672	-29.180184391395674	19465
28b054c89adb5204589b4496101bb2dc08d49757	a study of quality and accuracy trade-offs in process mining	quality metric;quality accuracy trade off;quality based algorithm;process mining;knowledge discovery	"""The goal of process mining is to extract semantic knowledge from a log consisting of process execution traces for the purposes of process understanding, innovation and improvement. In recent years many algorithms have been proposed to extract process models from logs. The process models describe the ordering relationships between tasks in a process in terms of standard constructs like sequence, parallel, choice and loop. Most algorithms assume that each trace in a log represents a correct execution sequence based on a model. In practice, logs are noisy and algorithms designed for correct logs are not able to handle noisy logs. In this paper we share our key insights from a study of noise in process logs both real and synthetic. Our first finding is that all process logs can be explained by using self-loop and optional structures. Therefore, it is not difficult to build a fully accurate process model for any given log, even logs that contain inaccurate data or noise. Secondly, there is usually not one single, unique process model that can explain a log, i.e. the same log can be explained by a large number of different models. Thirdly, some models are of higher """"quality"""" than others, and given that so many models can explain the same log, it is important to have a metric of quality for a model. Fourth, if a log contains noisy execution traces, a fully accurate process model that explains every trace in the log is not very meaningful because its quality is low. By controlling the use of self-loop and optional structures around tasks and blocks of tasks we can balance the quality and accuracy tradeoff to derive high-quality process models that explains a given percentage of traces in the log. Finally, we describe a novel quality-based algorithm for model extraction in the context of our noisy logs. The results of the experiments with the algorithm on real and synthetic data are reported and analyzed at length."""	algorithm;experiment;loop (graph theory);parallel computing;process modeling;synthetic data;tracing (software)	Zan Huang;Akhil Kumar	2012	INFORMS Journal on Computing	10.1287/ijoc.1100.0444	computer science;data science;data mining;database;knowledge extraction;process mining;statistics	ML	-2.667117348254654	-41.345128891765604	19486
593bf0b0004ce897f9aa25f9a5e2b850f7f2be1e	adversarial framework for general image inpainting		We present a novel adversarial framework to solve the arbitrarily sized image random inpainting problem, where a pair of convolution generator and discriminator is trained jointly to fill the relatively large but random “holes”. The generator is a symmetric encoder-decoder just like an hourglass but with added skip connections. The skip connections act like information shortcut to transfer some necessary details that discarded by the “bottleneck” layer. Our discriminator is trained to distinguish whether an image is natural or not and find out the hidden holes from a reconstructed image. A combination of a standard pixel-wise L2 loss and an adversarial loss is used to guided the generator to preserve the known part of the origin image and fills the missing part with plausible result. Our experiment is conducted on over 1.24M images with uniformly random 25% missing part. We found the generator is good at capturing structure context and performs well in arbitrary size images without complex texture.	convolution;discriminator;encoder;inpainting;keyboard shortcut;pixel;unsupervised learning	Wei Huang;Hongliang Yu	2018		10.1007/978-3-319-93713-7_50	inpainting;mathematical optimization;adversarial system;discriminator;machine learning;convolution;computer science;bottleneck;artificial intelligence	Vision	23.835704377352368	-49.48428504421707	19491
b314695603e2a5752013fb0b669f0d18062208ef	generating actionable knowledge by expert-guided subgroup discovery	learning algorithm;intelligence artificielle;algorithme apprentissage;decision maker;classification;subgroup discovery;classification rules;decouverte connaissance;artificial intelligence;descubrimiento conocimiento;inteligencia artificial;algoritmo aprendizaje;clasificacion;knowledge discovery	This paper discusses actionable knowledge generation. Actionable knowledge is explicit symbolic knowledge, typically presented in the form of rules, that allows the decision maker to recognize some important relations and to perform an action, such as targeting a direct marketing campaign, or planning a population screening campaign aimed at targeting individuals with high disease risk. The disadvantages of using standard classification rule learning for this task are discussed, and a subgroup discovery approach proposed. This approach uses a novel definition of rule quality which is extensively discussed.	domain driven data mining	Dragan Gamberger;Nada Lavrac	2002		10.1007/3-540-45681-3_14	decision-making;biological classification;computer science;artificial intelligence;data mining;knowledge extraction;operations research	ML	-0.14956846287015876	-30.91631467619062	19501
e336025b8bbaa7eef13cea73409b9ec33fb1669b	smoothing profiles with sliding windows: better to wear a hat!	secuencia aminoacido;proteine;sequence aminoacide;aminoacid sequence;computerized processing;tratamiento informatico;data smoothing;weighting;ponderacion;windows;algorithme;algorithm;proteins;fenetre;lissage donnees;ventana;proteina;ponderation;alisadura datos;traitement informatique;fenetre triangulaire;sliding window;algoritmo	A general way to analyze sequences is to turn them into lists of position-dependent numerical values, the graphical representation of which provides a sequence profile suitable for visual inspection and «pattern recognition». We examine here the merit of the «triangular» window, which consists of associating linearly decreasing weights with the positions starting from the center («hat» average)		Jean-Michel Claverie;C. Daulmerie	1991	Computer applications in the biosciences : CABIOS	10.1093/bioinformatics/7.1.113	sliding window protocol;computer science;artificial intelligence;weighting;algorithm;smoothing	DB	8.446714159359956	-35.182328288580344	19508
4236b2ce58a8802b5b0c6328459d7c21b2cd42aa	gene selection in cancer classification using sparse logistic regression with bayesian regularization	cross entropy;model selection;bayesian regularization;bayesian approach;performance estimation;logistic regression;colon cancer;machine learning;relevance vector machine;medical application;cross validation;cancer classification;gene selection;conditional probability;leave one out;selection bias	MOTIVATION Gene selection algorithms for cancer classification, based on the expression of a small number of biomarker genes, have been the subject of considerable research in recent years. Shevade and Keerthi propose a gene selection algorithm based on sparse logistic regression (SLogReg) incorporating a Laplace prior to promote sparsity in the model parameters, and provide a simple but efficient training procedure. The degree of sparsity obtained is determined by the value of a regularization parameter, which must be carefully tuned in order to optimize performance. This normally involves a model selection stage, based on a computationally intensive search for the minimizer of the cross-validation error. In this paper, we demonstrate that a simple Bayesian approach can be taken to eliminate this regularization parameter entirely, by integrating it out analytically using an uninformative Jeffrey's prior. The improved algorithm (BLogReg) is then typically two or three orders of magnitude faster than the original algorithm, as there is no longer a need for a model selection step. The BLogReg algorithm is also free from selection bias in performance estimation, a common pitfall in the application of machine learning algorithms in cancer classification.   RESULTS The SLogReg, BLogReg and Relevance Vector Machine (RVM) gene selection algorithms are evaluated over the well-studied colon cancer and leukaemia benchmark datasets. The leave-one-out estimates of the probability of test error and cross-entropy of the BLogReg and SLogReg algorithms are very similar, however the BlogReg algorithm is found to be considerably faster than the original SLogReg algorithm. Using nested cross-validation to avoid selection bias, performance estimation for SLogReg on the leukaemia dataset takes almost 48 h, whereas the corresponding result for BLogReg is obtained in only 1 min 24 s, making BLogReg by far the more practical algorithm. BLogReg also demonstrates better estimates of conditional probability than the RVM, which are of great importance in medical applications, with similar computational expense.   AVAILABILITY A MATLAB implementation of the sparse logistic regression algorithm with Bayesian regularization (BLogReg) is available from http://theoval.cmp.uea.ac.uk/~gcc/cbl/blogreg/	analysis of algorithms;benchmark (computing);biological factors;biological markers;colon carcinoma;colon classification;computation;cross reactions;cross entropy;cross-validation (statistics);estimated;gucy2c protein, human;logistic regression;matlab;machine learning;matrix regularization;maxima and minima;model selection;neoplasms;nonlinear system;pattern recognition;population parameter;radial (radio);radial basis function;regression analysis;relevance vector machine;science;selection algorithm;selection bias;silo (dataset);sparse matrix;whole earth 'lectronic link;leukemia;orders - hl7publishingdomain;triangulation	Gavin C. Cawley;Nicola L. C. Talbot	2006	Bioinformatics	10.1093/bioinformatics/btl386	gene-centered view of evolution;bayesian interpretation of regularization;selection bias;conditional probability;bayesian probability;machine learning;pattern recognition;mathematics;logistic regression;cross entropy;relevance vector machine;cross-validation;model selection;statistics	ML	11.222032159108604	-51.67658796620066	19587
64a1ad122cc5bba9b6114aae8314248d9ff19faf	an inductive learning algorithm with a partial completeness and consistence via a modified set covering problem	learning algorithm;aplicacion medical;algorithme glouton;apprentissage inductif;metodo formal;methode formelle;inductive logic programming;intelligence artificielle;algorithme apprentissage;set covering problem;classification;formal method;probleme recouvrement;couverture;aprendizaje por induccion;problema recubrimiento;classification rules;inductive learning;recouvrement ensemble;greedy algorithm;artificial intelligence;algoritmo gloton;medical application;coverage;inteligencia artificial;set covering;cubierta conjunto;covering problem;algoritmo aprendizaje;clasificacion;programmation logique inductive;application medicale;cobertura	We present an inductive learning algorithm that allows for a partial completeness and consistence, i.e. that derives classification rules correctly describing, e.g, most of the examples belonging to a class and not describing most of the examples not belonging to this class. The problem is represented as a modification of the set covering problem that is solved by a greedy algorithm. The approach is illustrated on some medical data.	algorithmic learning theory;covering problems;greedy algorithm;inductive reasoning;set cover problem	Janusz Kacprzyk;Grazyna Szkatula	2005		10.1007/11550907_105	greedy algorithm;formal methods;biological classification;computer science;artificial intelligence;machine learning;mathematics;set cover problem;algorithm	ML	8.49331321324205	-31.57944045393267	19600
0398945b04a0d77d24047aa0989b1f7c8ce27144	evaluation of constructive neural networks with cascaded architectures	model selection;layer by layer;constructive neural networks;active network;network training;cascade correlation;generalization;neural network;numerical simulation	In this study, we have investigated 2ve di3erent constructive neural network algorithms, of which four were methods found in the literature and one was our own recently developed algorithm. The algorithms that were studied were Cascade-Correlation, Modi2ed Cascade-Correlation, Cascade, Cascade Network, and our own recently developed Fixed Cascade Error. The investigated algorithms have many similarities: they all have a cascaded architecture and they automatically increase the size of the neural network by adding new hidden units to the network as the training proceeds. Furthermore, the networks are trained in a layer-by-layer style, i.e. as the hidden units are installed in the network, their input weights are frozen so that they do not change in the later stages of the network training. The basic versions of the algorithms (which use only one randomly initialized candidate unit in the hidden unit training) were improved during the course of this research by adding a deterministic initialization method and the utilization of multiple candidate units in the training phase of the hidden units. The key idea of the deterministic initialization method is to create a large pool of randomly initialized hidden units, of which only the best unit is further trained and installed in the network. On the other hand, when we utilize multiple candidate units, we train a number of candidate units to the 2nal solution, after which the best one of them is selected to be installed as a hidden unit in the active network. The numerical simulations show that especially the multiple candidate unit versions of the algorithms produce usually better results than the basic versions of the algorithms. In addition, the computational costs of the algorithms do not increase when using the deterministic initialization method, but in most cases we can even reduce the computational costs needed for the network training. Moreover, it should be noticed that our own algorithm produces rather often the best performance level among the investigated algorithms. c © 2002 Elsevier Science B.V. All rights reserved. ∗Corresponding author. Tel.: +358-3-365-3835; fax: +358-3-365-3095. E-mail address: janil@cs.tut.2 (J.J.T. Lahnajarvi). 0925-2312/02/$ see front matter c © 2002 Elsevier Science B.V. All rights reserved. PII: S0925-2312(01)00630-0 574 J.J.T. Lahnajarvi et al. / Neurocomputing 48 (2002) 573–607	algorithm;artificial neural network;automation;benchmark (computing);computation;computational complexity theory;fax;multiple encryption;neurocomputing;numerical analysis;personally identifiable information;randomness;simulation;stepwise regression	Jani J. T. Lahnajärvi;Mikko Lehtokangas;Jukka Saarinen	2002	Neurocomputing	10.1016/S0925-2312(01)00630-0	computer simulation;layer by layer;generalization;active networking;simulation;computer science;artificial intelligence;machine learning;artificial neural network;model selection;statistics	AI	16.79867181267363	-29.845381588576487	19639
993c395d6273f32205924e41313139bf10d74c11	feature selection using genetic algorithm and cluster validation	image features;cluster validation;low level image features;feature sets;two directions;feature extraction;clustering algorithms;genetic algorithm;genetic algorithms;feature selection;cluster validity;taguchi methods;convergence time;hubert s γ statistics;taguchi;retrieval accuracy;taguchi method;image retrieval systems;image retrieval	Feature selection plays an important role in image retrieval systems. The better selection of features usually results in higher retrieval accuracy. This work tries to select the best feature set from a total of 78 low level image features, including regional, color, and textual features, using the genetic algorithms (GA). However, the GA is known to be slow to converge. In this work we propose two directions to improve the convergence time of the GA. First we employ the Taguchi method to reduce the number of necessary offspring to be tested in every generation in the GA. Second we propose to use an alternative measure, the Hubert's @C statistics, to evaluate the fitness of each offspring instead of evaluating the retrieval accuracy directly. The experiment results show that the proposed techniques improve the feature selection results by using the GA in both time and accuracy.	cluster analysis;feature selection;genetic algorithm	Yi-Leh Wu;Cheng-Yuan Tang;Maw-Kae Hor;Pei-Fen Wu	2011	Expert Syst. Appl.	10.1016/j.eswa.2010.08.062	taguchi methods;image retrieval;computer science;machine learning;pattern recognition;data mining;feature selection	NLP	5.780232508671505	-42.34465233511196	19656
5819bba55f579465f5a74598e74d37a06873cbf4	"""the """"off line learning approximation"""" in continuous time neural networks: an adiabatic theorem"""	continuous time;short term memory;global asymptotic stability;learning;stabilite asymptotique;long term memory;aproximacion;convergent dynamics;asymptotic stability;theoreme adiabatique;approximation;aprendizaje;apprentissage;adiabatic estimations;self organization;network dynamics;estabilidad asintotica;reseau neuronal;red neuronal;averaging;neural network	In this paper we consider the justification of the ''Off Line Approximation'' in continuous time neural networks from a rigorous mathematical point of view. In real time models, the behavior of a network is characterized by two distinct dynamics evolving according different time scales, the weight dynamics which are the ''slow'' and the activation dynamics which are the ''fast.'' The ''off-line approximation'' assumes that during the learning process, neural activities are in their steady states. Such an approximation is a common dogma often used to provide an analysis of network behavior. In this paper we consider convergent networks and prove that this approximation is valid on the time scale 1/@e where @e is the learning rate parameter which controls the learning velocity. We apply these results to prove the stability of Hebbian learning in a two-layered neural network which can be seen as a continuous time version of the self-organizing Kohonen's model.	approximation;artificial neural network	Michel Benaïm	1993	Neural Networks	10.1016/S0893-6080(05)80109-1	self-organization;long-term memory;computer science;artificial intelligence;network dynamics;machine learning;approximation;calculus;mathematics;short-term memory;artificial neural network;algorithm	ML	18.780128588042846	-27.276548433785432	19669
a303338f58c7957ddf46b3d1c11cb344ca0a562f	improve the classifier accuracy for continuous attributes in biomedical datasets using a new discretization method	discretization;data mining;classification	Abstract   In real-time data mining applications discrete values play vital role in knowledge representation as they are easy to handle and very close to knowledge level representation than continuous attributes. Discretization is a major step in data mining process where continuous attributes are transformed into discrete values. However, most of the classifications algorithms are require discrete values as the input. Even though some data mining algorithms directly contract with continuous attributes, the learning process yields low quality results. In this paper, we introduce a new discretization method based on standard deviation technique called ‘z-score’ for continuous attributes on biomedical datasets. We compare performance of the proposed algorithm with the state-of- the-art discretization techniques. The experiment results show the efficiency in terms of accuracy and also minimize the classifier confusion for decision making process.	discretization	G. Madhu;T. V. Rajinikanth;A. Govardhan	2014		10.1016/j.procs.2014.05.315	discretization error;computer science;machine learning;pattern recognition;discretization;data mining;discretization of continuous features	Vision	7.396236440612584	-43.14483693347722	19684
6ff3e8a756017726c3523147b9fc78a0497bd221	combination, cooperation and selection of classifiers: a state of the art	combination;multiple classifier systems;ensemble of classifiers;cooperation;dynamic selection;adaptive selection	When several classifiers are brought to contribute to the same task of recognition, various strategies of decisions, implying these classifiers in different ways, are possible. A first strategy consists in deciding using different opinions: it corresponds to the combination of classifiers. A second strategy consists in using one or more opinions for better guiding other classifiers in their training stages, and/or to improve the decision-making of other classifiers in the classification stage: it corresponds to the cooperation of classifiers. The third and last strategy consists in giving more importance to one or more classifiers according to various criteria or situations: it corresponds to the selection of classifiers. The temporal aspect of Pattern Recognition (PR), i.e. the possible evolution of the classes to be recognized, can be treated by the strategy of selection.		Veyis Gunes;Michel Ménard;Pierre Loonis;Simon Petit-Renaud	2003	IJPRAI	10.1142/S0218001403002897	random subspace method;cascading classifiers;combination;machine learning;pattern recognition;data mining;cooperation	NLP	12.506381236771453	-44.48490386305853	19687
e29532cc4b76c3796880aa0a51d3416f8e596f2a	using bayesian optimization to jointly tune the classifier and the random field for spatial-spectral hyperspectral classification		The framework consisting of a pixel-wise classification followed by a Markov random field has been very successful for spatial-spectral hyperspectral classification. While training such frameworks, the classifier and the Markov random field are generally tuned greedily one after another. However, better results could be obtained by tuning both of the components simultaneously with the objective of producing the best result at the end. This paper investigates the joint optimization of the hyperparameters of the classifier and the random field using Bayesian optimization. Experimental evaluation on the model comprising of a support vector machine classifier and a grid-structured Markov random field is provided. The results of the experiments, conducted on two independent datasets, suggest that the jointly tuned models can provide better accuracy.	bayesian optimization;experiment;greedy algorithm;markov chain;markov random field;mathematical optimization;performance tuning;pixel;support vector machine	Utsav B. Gewali;Sildomar T. Monteiro	2017	2017 IEEE International Geoscience and Remote Sensing Symposium (IGARSS)	10.1109/IGARSS.2017.8127800	bayesian optimization;markov random field;computer vision;support vector machine;random field;hyperparameter;computer science;hyperspectral imaging;markov process;linear programming;artificial intelligence;pattern recognition	Vision	24.251899932510305	-46.90159264892893	19710
14987ea6fa42326bef7dd9b0fb6f747175735d12	a fast natural newton method	newton method	Machine learning often looks like optimization: write down the likelihood of some training data under some model and find the model parameters which maximize that likelihood, or which minimize some divergence between the model and the data. In this context, conventional wisdom is that one should find in the optimization literature the state of the art optimizer for one’s problem and use it. Furthermore, many machine learning objective functions are smooth in the optimization sense, so secondorder optimizers are the tools of choice. And indeed, comparing second order methods to first order ones shows significant improvements in learning speed. However, recent research (Le Roux et al., 2008) has shown that, by paying attention to the special structure of machine learning problems (viewing the gradient obtained as a noisy estimate of the true gradient of the function we are really interested in), one can obtain faster convergence than first order gradient descent methods without using the Hessian. We investigate whether this improvement is due to the similarity of these methods to approximate second-order methods or, if this is not the case, if we can combine these improvements with those obtained when using the information contained in the Hessian.	approximation algorithm;gradient descent;hessian;machine learning;mathematical optimization;newton's method	Nicolas Le Roux;Andrew W. Fitzgibbon	2010			steffensen's method;halley's method;quasi-newton method;computer science;newton's method in optimization;newton's method	ML	24.2279438882634	-33.091703996486984	19724
3e45445065a044fbd280e1fb76a083a5e47a2e35	accelerating convolutional neural networks with dominant convolutional kernel and knowledge pre-regression		Aiming at accelerating the test time of deep convolutional neural networks (CNNs), we propose a model compression method that contains a novel dominant kernel (DK) and a new training method called knowledge pre-regression (KP). In the combined model DK(^2)PNet, DK is presented to significantly accomplish a low-rank decomposition of convolutional kernels, while KP is employed to transfer knowledge of intermediate hidden layers from a larger teacher network to its compressed student network on the basis of a cross entropy loss function instead of previous Euclidean distance. Compared to the latest results, the experimental results achieved on CIFAR-10, CIFAR-100, MNIST, and SVHN benchmarks show that our DK(^2)PNet method has the best performance in the light of being close to the state of the art accuracy and requiring dramatically fewer number of model parameters.	convolutional neural network;kernel (operating system)	Zhenyang Wang;Zhidong Deng;Shiyao Wang	2016		10.1007/978-3-319-46484-8_32	theoretical computer science;machine learning;pattern recognition;deep learning;convolutional neural network	Vision	21.48422636449463	-49.47566972363666	19730
eaf804dc7654b452c2b6955e3cb1a3eba5c63bf1	is big data sufficient for a reliable detection of non-technical losses?	non technical losses;machine learning;big data;bias;covariate shift	Non-technical losses (NTL) occur during the distribution of electricity in power grids and include, but are not limited to, electricity theft and faulty meters. In emerging countries, they may range up to 40% of the total electricity distributed. In order to detect NTLs, machine learning methods are used that learn irregular consumption patterns from customer data and inspection results. The Big Data paradigm followed in modern machine learning reflects the desire of deriving better conclusions from simply analyzing more data, without the necessity of looking at theory and models. However, the sample of inspected customers may be biased, i.e. it does not represent the population of all customers. As a consequence, machine learning models trained on these inspection results are biased as well and therefore lead to unreliable predictions of whether customers cause NTL or not. In machine learning, this issue is called covariate shift and has not been addressed in the literature on NTL detection yet. In this work, we present a novel framework for quantifying and visualizing covariate shift. We apply it to a commercial data set from Brazil that consists of 3.6M customers and 820K inspection results. We show that some features have a stronger covariate shift than others, making predictions less reliable. In particular, previous inspections were focused on certain neighborhoods or customer classes and that they were not sufficiently spread among the population of customers. This framework is about to be deployed in a commercial product for NTL detection.	big data;branch predictor;machine learning;ntl;programming paradigm	Patrick O. Glauner;Angelo Migliosi;Jorge Augusto Meira;Eric A. Antonelo;Petko Valtchev;Radu State;Franck Bettinger	2017	2017 19th International Conference on Intelligent System Application to Power Systems (ISAP)		econometrics;computer science;data mining;statistics	ML	1.5815680253199094	-33.69687080530715	19846
e424ce556a56d1eac5f876c1ebcc97b63ef15048	new feature selection for gene expression classification based on degree of class overlap in principal dimensions	dimension reduction;micro array data;feature extraction;feature selection;analysis;support vector machine;principal component	Micro-array data are typically characterized by high dimensional features with a small number of samples. Several problems in identifying genes causing diseases from micro-array data can be transformed into the problem of classifying the features extracted from gene expression in micro-array data. However, too many features can cause low prediction accuracy as well as high computational complexity. Dimensional reduction is a method to eliminate irrelevant features to improve the prediction accuracy. Typically, the eigenvalues or dimensional data variance from principal component analysis are used as criteria to select relevant features. This approach is simple but not efficient since it does not concern the degree of data overlap in each dimension in the feature space. A new method to select relevant features based on degree of dimensional data overlap with proper feature selection was introduced. Furthermore, our study concentrated on small sized data sets which usually occur in reality. The experimental results signified that this new approach can achieve substantially higher prediction accuracy when compared with other methods.		Somsak Rakkeitwinai;Chidchanok Lursinsap;Chatchawit Aporntewan;Apiwat Mutirangura	2015	Computers in biology and medicine	10.1016/j.compbiomed.2015.01.022	support vector machine;feature extraction;computer science;machine learning;pattern recognition;analysis;data mining;mathematics;feature selection;feature;dimensionality reduction;principal component analysis	ML	9.090583722944977	-47.516748525625225	19900
3234e2dae45ca2ff7801f98d604accd5a256ea05	inferring latent task structure for multitask learning by multiple kernel learning	learning algorithm;limiting factor;prior information;multiple kernel learning;prior knowledge;computational biology bioinformatics;machine learning;learning scenario;learning problems;artificial intelligence;algorithms;combinatorial libraries;computational biology;computer appl in life sciences;databases protein;microarrays;bioinformatics	The lack of sufficient training data is the limiting factor for many Machine Learning applications in Computational Biology. If data is available for several different but related problem domains, Multitask Learning algorithms can be used to learn a model based on all available information. In Bioinformatics, many problems can be cast into the Multitask Learning scenario by incorporating data from several organisms. However, combining information from several tasks requires careful consideration of the degree of similarity between tasks. Our proposed method simultaneously learns or refines the similarity between tasks along with the Multitask Learning classifier. This is done by formulating the Multitask Learning problem as Multiple Kernel Learning, using the recently published q-Norm MKL algorithm. We demonstrate the performance of our method on two problems from Computational Biology. First, we show that our method is able to improve performance on a splice site dataset with given hierarchical task structure by refining the task relationships. Second, we consider an MHC-I dataset, for which we assume no knowledge about the degree of task relatedness. Here, we are able to learn the task similarities ab initio along with the Multitask classifiers. In both cases, we outperform baseline methods that we compare against. We present a novel approach to Multitask Learning that is capable of learning task similarity along with the classifiers. The framework is very general as it allows to incorporate prior knowledge about tasks relationships if available, but is also able to identify task similarities in absence of such prior information. Both variants show promising results in applications from Computational Biology.	algorithm;baseline (configuration management);bioinformatics;computation;computational biology;computer multitasking;kernel (operating system);learning disorders;machine learning;math kernel library;model of hierarchical complexity;multiple kernel learning;problem domain;regular expression;scientific publication;silo (dataset);splice (system call)	Christian Widmer;Nora C. Toussaint;Yasemin Altun;Gunnar Rätsch	2010		10.1186/1471-2105-11-S8-S5	semi-supervised learning;unsupervised learning;biology;multi-task learning;instance-based learning;limiting factor;dna microarray;computer science;bioinformatics;data science;machine learning;pattern recognition;stability;active learning;generalization error	ML	9.865444815500076	-51.45293819595924	19909
81516cc1d17d20a9e4a81aca296fdf121c0ec763	travel speed prediction using fuzzy reasoning	fuzzy reasoning;qa mathematics;outlier detection;random noise;electronic and computer engineering;fuzzy inference system;cross validation;fuzzy system	The speed prediction algorithm introduced in this paper takes advantage of fuzzy systems that are insensitive to random noise, robust to uncertainties, and transparent to interpretation. The proposed algorithm for outlier detection selects the potential outliers based on the density rather than the deviation adopted in conventional approaches. To evaluate the developed system, a seris of experiments conducted on the real world data. The result of the comparison performed to evaluate the outliler detection method proposed reveals the benefit from the consideration of density. The cross validation results indicate the effectiveness of the fuzzy inference system developed.		Yang Wang;Honghai Liu;Patrick Beullens;David J. Brown	2008		10.1007/978-3-540-88513-9_48	anomaly detection;defuzzification;adaptive neuro fuzzy inference system;computer science;artificial intelligence;neuro-fuzzy;machine learning;data mining;fuzzy set operations;fuzzy control system;cross-validation;statistics	AI	7.755360638213083	-40.88576730912871	19913
fa348dd9a443ef99a0e1df89dd813b36a4ff95ee	isolation kernel and its effect on svm		This paper investigates data dependent kernels that are derived directly from data. This has been an outstanding issue for about two decades which hampered the development of kernel-based methods. We introduce Isolation Kernel which is solely dependent on data distribution, requiring neither class information nor explicit learning to be a classifier. In contrast, existing data dependent kernels rely heavily on class information and explicit learning to produce a classifier. We show that Isolation Kernel approximates well to a data independent kernel function called Laplacian kernel under uniform density distribution. With this revelation, Isolation Kernel can be viewed as a data dependent kernel that adapts a data independent kernel to the structure of a dataset. We also provide a reason why the proposed new data dependent kernel enables SVM (which employs a kernel through other means) to improve its predictive accuracy. The key differences between Random Forest kernel and Isolation Kernel are discussed to examine the reasons why the latter is a more successful tree-based kernel.	kernel (operating system);random forest;statistical classification	Kai Ming Ting;Yue Zhu;Zhi-Hua Zhou	2018		10.1145/3219819.3219990	machine learning;kernel (linear algebra);artificial intelligence;computer science;support vector machine;kernel (statistics);random forest;uniform distribution (continuous);laplace operator	ML	19.77428602984348	-45.10576416925558	19968
6d89a03926fce54eac2a86e9dae49dbaf0b72c5b	outlier detection and ranking based on subspace clustering	004;outlier detection outlier ranking subspace clustering data mining	Detecting outliers is an important task for many applications including fraud detection or consistency validation in real world data. Particularly in the presence of uncertain data or imprecise data, similar objects regularly deviate in their attribute values. The notion of outliers has thus to be defined carefully. When considering outlier detection as a task which is complementary to clustering, binary decisions whether an object is regarded to be an outlier or not seem to be near at hand. For high-dimensional data, however, objects may belong to different clusters in different subspaces. More fine-grained concepts to define outliers are therefore demanded. By our new OutRank approach, we address outlier detection in heterogeneous high dimensional data and propose a novel scoring function that provides a consistent model for ranking outliers in the presence of different attribute types. Preliminary experiments demonstrate the potential for successful detection and reasonable ranking of outliers in high dimensional data sets.	anomaly detection;cluster analysis;clustering high-dimensional data;experiment;scoring functions for docking;uncertain data	Thomas Seidl;Emmanuel Müller;Ira Assent;Uwe Steinhausen	2008			pattern recognition;data mining;mathematics;statistics	DB	-0.8018723029261753	-42.21673148393005	19993
6d7d4fe1dca7c565c1e7478f72dad3f6e25b788d	on-line relational som for dissimilarity data		In some applications and in order to address real world situations better, data may be more complex than simple vectors. In some examples, they can be known through their pairwise dissimilarities only. Several variants of the Self Organizing Map algorithm were introduced to generalize the original algorithm to this framework. Whereas median SOM is based on a rough representation of the prototypes, relational SOM allows representing these prototypes by a virtual combination of all elements in the data set. However, this latter approach suffers from two main drawbacks. First, its complexity can be large. Second, only a batch version of this algorithm has been studied so far and it often provides results having a bad topographic organization. In this article, an on-line version of relational SOM is described and justified. The algorithm is tested on several datasets, including categorical data and graphs, and compared with the batch version and with other SOM algorithms for non vector data.	algorithm;batch processing;categorical variable;cluster analysis;computation;graph (discrete mathematics);numerical analysis;online and offline;performance;self-organizing map;topography;vector graphics	Madalina Olteanu;Nathalie Villa-Vialaneix;Marie Cottrell	2012		10.1007/978-3-642-35230-0_2	computer science;artificial intelligence;machine learning;data mining	ML	0.8838581626780533	-40.109970439469734	20020
88d00889ec10b81bdf88f93b93a09750b1a6e7db	object-oriented function points: an empirical validation	software metrics;pilot study;normalized mean square error;function point;oo size estimation;empirical evidence;object oriented systems;lines of code;object oriented;size prediction;empirical validation;linear model;software metric;cross validation	We present an empirical validation of object-oriented size estimation models. In previous work we proposed object oriented function points (OOFP), an adaptation of the function points approach to object-oriented systems. In a small pilot study, we used the OOFP method to estimate lines of code (LOC). In this paper we extend the empirical validation of OOFP substantially, using a larger data set and comparing OOFP with alternative predictors of LOC. The aim of the paper is to gain an understanding of which factors contribute to accurate size prediction for OO software, and to position OOFP within that knowledge. A cross validation approach was adopted to build and evaluate linear models where the independent variable was either a traditional OO entity (classes, methods, association, inheritance, or a combination of them) or an OOFP-related measure. Using the full OOFP process, the best size predictor achieved a normalized mean squared error of 38%. By removing function point weighting tables from the OOFP process, and carefully analyzing collected data points and developer practices, we identified several factors that influence size estimation. Our empirical evidence demonstrates that by controlling these factors size estimates could be substantially improved, decreasing the normalized mean squared error to 15%—in relative terms, a 56% reduction.	cross-validation (statistics);data point;function point;kerrison predictor;linear model;mean squared error;source lines of code	Giuliano Antoniol;Roberto Fiutem;Christopher J. Lokan	2003	Empirical Software Engineering	10.1023/A:1024472727275	reliability engineering;computer science;software engineering;data mining;software metric;statistics	SE	4.248146724190682	-33.90948324623748	20035
4c3034847c5462a96913e85632cbf8a92765296b	incorporating fuzzy modelling in a hybrid hmm-anns system for csr tasks.	fuzzy modelling			Xavier Menéndez-Pidal;Ricardo de Córdoba;Javier Ferreiros;José Manuel Pardo	1995			computer science;neuro-fuzzy	Robotics	10.28441596159836	-26.023886559106888	20051
bc547793b7f9b7dbad5e293768298a34925ccbcb	adaptive differential evolution fuzzy clustering algorithm with spatial information and kernel metric for remote sensing imagery	differential evolution;kernel metric;fuzzy clustering;adaptive;remote sensing	In this paper, an adaptive differential evolution fuzzy clustering algorithm with spatial information and kernel metric for remote sensing imagery, namely KADESFC, is proposed. In KADESFC, the clustering problem is transformed into an optimization problem, which minimizes a proposed kernelized objective function with an adaptive spatial constraint term. Differential evolution algorithm is utilized to optimize the kernelized objective function, which uses several differential evolution operators. Experimental results on two remote sensing images show that the proposed algorithm is promising compared with several traditional clustering algorithms.		Ailong Ma;Yanfei Zhong;Liangpei Zhang	2013		10.1007/978-3-642-41278-3_34	differential evolution;correlation clustering;mathematical optimization;data stream clustering;fuzzy clustering;computer science;canopy clustering algorithm;adaptive behavior;machine learning;pattern recognition;mathematics;cluster analysis	Vision	4.743470424140727	-41.29590257442227	20120
9928149bee70d4e7bc6a3b61b7a0749974773a1b	multivalued associative memories based on recurrent networks	weighted average process;neural networks;weighted averaging;similarity measure computation;associative memory neural networks nonlinear equations neurons swaging computational modeling information processing power system interconnection asymptotic stability lyapunov method;nonlinear function recurrent neural nets multivalued neural associative memory model exponential correlation associative memories storage capacity error correction weighted average process similarity measure computation;power system interconnection;asymptotic stability;computational modeling;lyapunov method;nonlinear function;recurrent network;error correction;storage capacity;information processing;associative memory;multivalued neural associative memory model;nonlinear equations;recurrent neural nets;neurons;recurrent neural nets content addressable storage;content addressable storage;similarity measure;exponential correlation associative memories;swaging	A multivalued neural associative memory model based on a recurrent network structure is proposed. This model adopts the same principle proposed in the authors' previous work, the exponential correlation associative memories (ECAM). The model also has a very high storage capacity and strong error-correction capability. The major components of the new model include a weighted average process and some similarity-measure computation. As in ECAM, in order to enhance the differences among the weights and make the largest weights more overwhelming, the new model incorporates a nonlinear function in the calculation of weights. Several possible similarity measures suitable for this model are suggested. Simulation results of the performance of the new model with different measures show that, loaded with 500 64-component patterns, the model can sustain noise with power about one fifth to three fifths of the average signal power.		Tzi-Dar Chiueh;Hung-Kai Tsai	1993	IEEE transactions on neural networks	10.1109/72.207604	error detection and correction;swaging;nonlinear system;computer science;artificial intelligence;theoretical computer science;machine learning;computational model	ML	16.108917052479672	-26.17602524915747	20137
a6575faa867797a058664b83d72e0eaf86aa3d1e	simultaneous feature selection and classification based on genetic algorithms: an application to colonic polyp detection	databases;bass;concurrent;decision tree;aplicacion;robalo;computer aided diagnosis;deteccion;colon;polyp;detection;bar poisson;algoritmo genetico;classification;polipo;artificial neural networks;gases;polype;medical diagnostics;simultaneo;algorithme genetique;computer aided detection;genetic algorithm;simultane;genetic algorithms;feature selection;support vector machine;application;clasificacion;cohort study;artificial neural network	Selecting a set of relevant features is a crucial step in the process of building robust classifiers. Searching all possible subsets of features is computationally impractical for large number of features. Generally, classifiers are used for the evaluation of the separability of a certain feature subset. The performance of these classifiers depends on some predefined parameters. However, the choice of these parameters for a given classifier is influenced by the given feature subset and vice versa. The computational cost for feature selection would be largely increased by including the selection of optimal parameters for the classifier (for each subset). This paper attempts to tackle the problem by introducing genetic algorithms (GAs) to combine the processes. The proposed approach can choose the most relevant features from a feature set whilst simultaneously optimising the parameters of the classifier. Its performance was tested on a colon polyp database from a cohort study using a weighted support vector machine (SVM) classifier. As a general approach, other classifiers such as artificial neural networks (ANN) and decision trees could be used. This approach could also be applied to other classification problems such as other computer aided detection/diagnosis applications.	feature selection;genetic algorithm	Yalin Zheng;Xiaoyun Yang;Musib Siddique;Gareth Beddoe	2008		10.1117/12.770561	random subspace method;genetic algorithm;computer science;machine learning;linear classifier;pattern recognition;data mining;feature;artificial neural network	AI	10.83877321527592	-35.15328406665642	20175
ffd34e42300d49e2c398c94d0b58b8699760ded4	scalable and interpretable one-class svms with deep learning and random fourier features		One-class support vector machine (OC-SVM) for a long time has been one of the most effective anomaly detection methods and extensively adopted in both research as well as industrial applications. The biggest issue for OC-SVM is yet the capability to operate with large and high-dimensional datasets due to optimization complexity. Those problems might be mitigated via dimensionality reduction techniques such as manifold learning or autoencoder. However, previous work often treats representation learning and anomaly prediction separately. In this paper, we propose autoencoder based one-class support vector machine (AE1SVM) that brings OC-SVM, with the aid of random Fourier features to approximate the radial basis kernel, into deep learning context by combining it with a representation learning architecture and jointly exploit stochastic gradient descent to obtain end-to-end training. Interestingly, this also opens up the possible use of gradient-based attribution methods to explain the decision making for anomaly detection, which has ever been challenging as a result of the implicit mappings between the input space and the kernel space. To the best of our knowledge, this is the first work to study the interpretability of deep learning in anomaly detection. We evaluate our method on a wide range of unsupervised anomaly detection tasks in which our end-to-end training architecture achieves a performance significantly better than the previous work using separate training.	anomaly detection;approximation algorithm;autoencoder;deep learning;end-to-end encryption;end-to-end principle;experiment;feature learning;loss function;machine learning;mathematical optimization;nonlinear dimensionality reduction;radial (radio);response time (technology);sensor;stochastic gradient descent;support vector machine;unsupervised learning;user space	Minh-Nghia Nguyen;Ngo Anh Vien	2018		10.1007/978-3-030-10925-7_10	machine learning;autoencoder;support vector machine;anomaly detection;deep learning;dimensionality reduction;stochastic gradient descent;mathematics;nonlinear dimensionality reduction;artificial intelligence;feature learning	AI	20.01160612574755	-48.80718751764178	20252
1453481cf3f27d2fa2fbe9605d8572250b55c70f	huge data mining based on rough set theory and granular computing	complexity theory;knowledge reduction algorithm huge data mining rough set theory granular computing quick sort divide and conquer method time complexity;sorting;rough set theory;kiviat figures;set theory;data mining;computational modeling;computational complexity;heuristic algorithms;classification algorithms;recommending systems;lifelong learning;algorithm design and analysis;data mining set theory algebra intelligent agent algorithm design and analysis information entropy decision trees telecommunication computing information science computer science;learning efficiency;sorting computational complexity data mining rough set theory	Data mining is a hot research field which has been studied by a lot of scientists and technicians for many years. Unfortunately, it is still a very difficult problem to mine huge data sets efficiently. Many researchers are working on developing fast data mining technologies and methods for processing huge data sets efficiently. The basic idea of quick sort is the divide and conquer method. It represents the idea of granular computing (GrC). The average time complexity of quick sort for an m dimensions table containing n records were usually considered to be m X n X logn since the average time complexity of quick sort for a one detention array with n records is n X logn. However, we find that it is just n X (m+logn), while not m X n X logn. Based on this finding, there is an assumption that divide and conquer method can be used to improve the existed knowledge reduction algorithms in rough set theory and granular computing. It may be a good way to solve the problem of huge data mining. In this paper, we present our research plan about huge data mining based on rough set theory and granular computing. Besides, we also present our recent achievements.	algorithm;data mining;granular computing;quicksort;rough set;set theory;time complexity	Feng Hu;Guoyin Wang	2008	2008 IEEE/WIC/ACM International Conference on Web Intelligence and Intelligent Agent Technology	10.1109/WIIAT.2008.84	statistical classification;algorithm design;rough set;computer science;sorting;artificial intelligence;theoretical computer science;machine learning;data mining;lifelong learning;computational complexity theory;computational model;algorithm;set theory	DB	-4.0417475403172585	-36.21506424911638	20297
07f04f2313c86fb82231abb7bcb29884e487926c	projection-free bandit convex optimization		In this paper, we propose the first computationally efficient projection-free algorithm for bandit convex optimization (BCO). We show that our algorithm achieves a sublinear regret of O(nT ) (where T is the horizon and n is the dimension) for any bounded convex functions with uniformly bounded gradients. We also evaluate the performance of our algorithm against baselines on both synthetic and real data sets for quadratic programming, portfolio selection and matrix completion problems.	algorithm;algorithmic efficiency;convex function;convex optimization;dhrystone;gradient;mathematical optimization;quadratic programming;regret (decision theory)	Lin Chen;Mingrui Zhang;Amin Karbasi	2018	CoRR		mathematical optimization;matrix completion;mathematics;quadratic programming;regular polygon;bounded function;convex optimization;convex function;uniform boundedness;sublinear function	ML	24.372210716662675	-33.17396352070743	20298
0711782ac6cfb0e6096a4699c05b529c7979b134	grey wolf algorithm-based clustering technique			algorithm;computer cluster	Vijay Kumar;Jitender Kumar Chhabra;Dinesh Kumar	2017	J. Intelligent Systems	10.1515/jisys-2014-0137	cluster analysis;artificial intelligence;pattern recognition;computer science	Logic	3.9363489782787147	-42.51807242513128	20300
a638a10bd418f4d448662075d67ea7be34b726bc	caraf: complex aggregates within random forests		This paper presents an approach integrating complex aggregate features into a relational random forest learner to address relational data mining tasks. CARAF, for Complex Aggregates within RAndom Forests, has two goals. Firstly, it aims at avoiding exhaustive exploration of the large feature space induced by the use of complex aggregates. Its second purpose is to reduce the overfitting introduced by the expressivity of complex aggregates in the context of a single decision tree. CARAF compares well on real-world datasets to both random forests based on the propositionalization method RELAGGS, and the relational random forest learner FORF.	aggregate data;algorithm;big data;decision tree;feature vector;hill climbing;overfitting;random forest;relational data mining	Clément Charnay;Nicolas Lachiche;Agnès Braud	2015		10.1007/978-3-319-40566-7_2	machine learning;overfitting;artificial intelligence;relational data mining;feature selection;random forest;decision tree;computer science;feature vector;expressivity	ML	9.11982399997141	-39.6196785795971	20311
008363aa3040e593090a5bf6248ad2ae2f91da7f	a pac-bayesian margin bound for linear classifiers: why svms work	bayesian framework;model selection;generalization error;probability;bayes methods;marginal models;lattices vector quantization codes silicon kelvin error correction support vector machines;indexing terms;learning automata;feature space;computational science;computational engineering;feature vector;error analysis;particle methods;learning artificial intelligence probability signal classification bayes methods learning automata error analysis;machine learning;machine learning pac bayesian margin bound linear classifiers generalization error refined margin quantity training sample probably approximately correct geometrical arguments exponential improvement tightest margin bound luckiness framework inverse margin input dimensions nontrivial bound values maximum margins complexity hypothesis space support vector machine feature vectors support vector machines normalized feature vectors numerical simulations error bound model selection;signal classification;cse;cfd;support vector machine;error bound;learning artificial intelligence;computational biology;evolutionary optimization;computational learning theory;probably approximately correct;numerical simulation	We present a bound on the generalisation error of linear classifiers in terms of a refined margin quantity on the training sample. The result is obtained in a PAC-Bayesian framework and is based on geometrical arguments in the space of linear classifiers. The new bound constitutes an exponential improvement of the so far tightest margin bound, which was developed in the luckiness framework, and scales logarithmically in the inverse margin. Even in the case of less training examples than input dimensions sufficiently large margins lead to nontrivial bound values and—for maximum margins—to a vanishing complexity term. In contrast to previous results, however, the new bound does depend on the dimensionality of feature space. The analysis shows that the classical margin is too coarse a measure for the essential quantity that controls the generalisation error: the fraction of hypothesis space consistent with the training sample. The practical relevance of the result lies in the fact that the well-known support vector machine is optimal with respect to the new bound only if the feature vectors in the training sample are all of the same length. As a consequence we recommend to use SVMs on normalised feature vectors only. Numerical simulations support this recommendation and demonstrate that the new error bound can be used for the purpose of model selection.	feature vector;generalization error;linear classifier;model selection;numerical linear algebra;relevance;simulation;support vector machine;time complexity;whole earth 'lectronic link	Ralf Herbrich;Thore Graepel	2000	IEEE Trans. Information Theory	10.1109/TIT.2002.805090	margin classifier;mathematical optimization;feature vector;computer science;machine learning;pattern recognition;mathematics;computational learning theory;statistics	ML	20.41833818028204	-33.0739692152622	20313
091652093acaa243d31b432eed1a7fec57c3db0d	two learning algorithms for forward pruning	learning algorithm		algorithm	Levente Kocsis;H. Jaap van den Herik;Jos W. H. M. Uiterwijk	2003	ICGA Journal		semi-supervised learning;unsupervised learning;null-move heuristic;instance-based learning;wake-sleep algorithm;computer science;online machine learning;machine learning;pattern recognition;learning classifier system;stability;killer heuristic;computational learning theory;active learning;pruning;population-based incremental learning;generalization error	Theory	15.226481342587011	-31.195180448736572	20315
a01050dbcb32384ac8741180a31483b939014963	fuzzy algorithms: applying fuzzy logic to the golden ratio search to find solutions faster		Applying the concept of fuzzy logic (an abstract version of Boolean logic) to well-known algorithms generates an abstract version (i.e., fuzzy algorithm) that often results in computational improvements. Precision may be reduced but counteracted by gaining computational efficiency. The trade-offs (e.g., small increase in space, loss of precision) for a variety of applications are deemed acceptable. The fuzzification of an algorithm can be accomplished using a simple three-step framework. Creating a new fuzzy algorithm goes beyond simply converting the data from raw data into fuzzy data by additionally converting the operators and concepts into their abstract equivalents. This paper demonstrates: (1) how to apply the general framework by developing a fuzzy algorithm for a simple linear search algorithm and (2) the success of this process through the development of the Fuzzy Golden Ratio Section Search.	boolean algebra;computation;fuzzy logic;fuzzy set;linear search;logical connective;search algorithm	Stephany Coffman-Wolph	2016			fuzzy logic;fuzzy electronics;discrete mathematics;membership function;defuzzification;adaptive neuro fuzzy inference system;fuzzy transportation;type-2 fuzzy sets and systems;fuzzy classification;fuzzy number;neuro-fuzzy;machine learning;mathematics;fuzzy set;fuzzy associative matrix;fuzzy set operations;algorithm;fuzzy control system	NLP	0.43208874971675354	-27.405585282874306	20326
783f22f9ad77e437438f24f2d0a7c1397468ec88	a new quadratic classifier applied to biometric recognition	classifier combination;high dimensionality;maximum likelihood;discriminant function;discriminant analysis;covariance matrices;classification error;maximum entropy;covariance estimation;leave one out;direct method;covariance matrix	In biometric recognition applications, the number of training examples per class is limited and consequently the conventional quadratic classifier either performs poorly or cannot be calculated. Other non-conventional quadratic classifiers have been used in limited sample and high dimensional classification problems. In this paper, a new quadratic classifier called Maximum Entropy Covariance Selection (MECS) is presented. This classifier combines the sample group covariance matrices and the pooled covariance matrix under the principle of maximum entropy. This approach is a direct method that not only deals with the singularity and instability of the maximum likelihood covariance estimator, but also does not require an optimisation procedure. In order to evaluate the MECS effectiveness, experiments on face and fingerprint recognition were carried out and compared with other similar classifiers, including the Reguralized Discriminant Analysis (RDA), the Leave-One-Out Covariance estimator (LOOC) and the Simplified Quadratic Discriminant Function (SQDF). In both applications, using the publicly released databases FERET and NIST-4, the MECS classifier achieved the lowest classification error.	biometrics;computation;direct method in the calculus of variations;experiment;feret (facial recognition technology);feature vector;fingerprint recognition;handwritten biometric recognition;instability;linear discriminant analysis;mathematical optimization;principle of maximum entropy;quadratic classifier;quadratic function;remote database access;technological singularity	Carlos E. Thomaz;Duncan Fyfe Gillies;Raul Queiroz Feitosa	2002		10.1007/3-540-47917-1_19	direct method;matérn covariance function;estimation of covariance matrices;covariance intersection;covariance matrix;quadratic classifier;principle of maximum entropy;machine learning;pattern recognition;discriminant function analysis;mathematics;maximum likelihood;linear discriminant analysis;rational quadratic covariance function;statistics;covariance function	ML	24.591308643077415	-40.304619740192976	20360
85bd1539519bfea9b219bf9d790ea09c390cc1b4	on roc curve analysis of artificial neural network classifiers			artificial neural network;receiver operating characteristic	Chulwoo Kim;Sung-Hyuk Cha;Yoo Jung An;Ned Wilson	2017			artificial intelligence;machine learning;artificial neural network;computer science;pattern recognition	ML	9.053981432359656	-36.93038148303882	20361
d5f15f4c41e9f74489a76c1f18782a108479b3c3	a simplex design of linear hyperplane decision networks	simplex design;linear hyperplane decision networks	A new type of two-layer aritficial neural network is presented. In contrast to its conventional counterpart, the new network is capable of forming any desired decision region in the input space. The new network consists of a conventional input (hidden) layer and an output layer that is, in essence, a Boolean function of the hidden layer output. Each node of the hidden layer forms a decision hyperplane and the set of hyperplanes constituted by the hidden layers perform a partition of the input space into a number of cells. These cells can be labeled according to their location (binary code) relative to all hyperplanes. The sole function of the output layer is then to group all these cells together appropriately, to form an arbitrary decision region in the input space. In conventional approaches, this is accomplished by a linear combination of the binary decisions (outputs) of the nodes of the hidden layer. This traditional approach is very limited concerning the possible shape of the decision region. A much more natural approach is to form the decision region as a Boolean function of the biniary hidden layer “word” which has as many digits as there are nodes in the hidden layer. The training procedure of the new network can be split in two completely decoupled phases. First, the construction of the decision hyperplanes formed by the hidden layer can be posed as a linear programming problem which can be solved using the Simplex algorithm. Moreover, a fast algorithm for approximate solution of this linear programming problem based on an elliptic approximation of the Simplex can be devised. The second step in the design of the network is the appropriate construction of the Boolean function of the output layer. The key trick here is the adequate incorporation of don’t cares in the Boolean function so that the decision regions formed by the output layer cover the entire input space but are still not overlapping.	influence diagram	Peter Strobach	1989		10.1007/978-3-642-75102-8_77	mathematical optimization;combinatorics;discrete mathematics;mathematics;decision boundary	EDA	17.502941549457642	-29.677671311300966	20370
e3f22fb8c3bcb800f6abe4632192e1ee014f26f8	recognition model of cerebral cortex based on approximate belief revision algorithm	belief networks;biology computing;bayesian network;brain;visual areas;learning algorithm;probability;performance evaluation;computer model;approximation algorithms convergence bayesian methods brain modeling approximation methods belief propagation random variables;approximation theory;probability approximation theory belief maintenance belief networks biology computing brain;belief revision;approximate belief propagation algorithm cerebral cortex recognition computational model approximate belief revision algorithm mpe calculation most probable explanation bayesian networks linear sum cpt model conditional probability table learning algorithm sparse coding orientation selectivity reproduction;belief propagation;most probable explanation;conditional probability table;cerebral cortex;orientation selectivity;belief maintenance;convergence time;sparse coding	We propose a computational model of recognition of the cerebral cortex, based on an approximate belief revision algorithm. The algorithm calculates the MPE (most probable explanation) of Bayesian networks with a linear-sum CPT (conditional probability table) model. Although the proposed algorithm is simple enough to be implemented by a fixed circuit, results of the performance evaluation show that this algorithm does not have bad approximation accuracy. The mean convergence time is not sensitive to the number of nodes if the depth the network is constant. The computation amount is linear to the number of nodes if the number of edges per node is constant. The proposed algorithm can be used as a part of a learning algorithm for a kind of sparse-coding, which reproduces orientation selectivity of the primary visual area. The circuit that executes the algorithm shows better correspondence to the anatomical structure of the cerebral cortex, namely its six-layer and columnar features, than the approximate belief propagation algorithm that has been proposed before. These results suggest that the proposed algorithm is a promising starting point for the model of the recognition mechanism of the cerebral cortex.	approximation algorithm;bayesian network;belief propagation;belief revision;cpt (file format);computation;computational model;neural coding;pattern recognition;performance evaluation;selectivity (electronic);software propagation;sparse matrix	Yuuji Ichisugi	2011	The 2011 International Joint Conference on Neural Networks	10.1109/IJCNN.2011.6033247	computer simulation;forward algorithm;suurballe's algorithm;ramer–douglas–peucker algorithm;computer science;artificial intelligence;theoretical computer science;machine learning;probability;bayesian network;mathematics;neural coding;belief revision;belief propagation;conditional probability table;population-based incremental learning;approximation theory	ML	22.65685820365229	-26.885078402875088	20424
7ca85747bcb5b36cf0dc736c8ef3b0c30e119814	hypersphere art and artmap for unsupervised and supervised, incremental learning	unsupervised learning;learning algorithm;fuzzy artmap;knowledge representation adaptive resonance theory neural network architecture hypersphere art unsupervised learning training set generalization;subspace constraints resonance testing computer science postal services neural networks computer architecture unsupervised learning supervised learning error analysis;supervised learning;theorie resonance adaptative;logique floue;logica difusa;intelligence artificielle;apprentissage non supervise;algorithme apprentissage;unsupervised learning art neural nets;classification;fuzzy logic;multi dimensional;incremental learning;error rate;artificial intelligence;inteligencia artificial;apprentissage supervise;art neural nets;reseau neuronal;knowledge representation;algoritmo aprendizaje;clasificacion;red neuronal;adaptive resonance theory;neural network	A novel adaptive resonance theory (ART) neural network architecture is being proposed. The new model, called Hypersphere ART (H-ART) is based on the same principals like Fuzzy-ART does and, thus, inherits most of its qualities for unsupervised learning. Among these properties is fast, stable, incremental learning on the training set and good generalization on the testing set. While H-ART is intended for clustering tasks, its extension, H-ARTMAP is playing the role of Fuzzy-ARTMAP’s counterpart for the supervised learning of real-valued, multi-dimensional mappings. Also in this paper, some experimental results are presented involving the comparison of H-ARTMAP and Fuzzy-ARTMAP in simple, illustrative classification problems. The results are indicating comparable performances in error rate but also a good potential for substantial superiority of H-ARTMAP in terms of nodes (categories) utilized. The latter effect can be attributed to H-ART’s more efficient internal knowledge representation.	adaptive resonance theory;artificial neural network;bit error rate;cluster analysis;knowledge representation and reasoning;network architecture;performance;supervised learning;test set;unsupervised learning	Georgios C. Anagnostopoulos;Michael Georgiopoulos	2000		10.1109/IJCNN.2000.859373	fuzzy logic;semi-supervised learning;unsupervised learning;biological classification;word error rate;computer science;artificial intelligence;adaptive resonance theory;machine learning;pattern recognition;supervised learning;artificial neural network;generalization error	AI	9.890075684742897	-31.89087619197802	20433
b49d903cf53db41124537ee596cfd5e9cb8f36bf	learning of bayesian discriminant functions by a layered neural network	learning;activation function;quadratic form;random sampling;discriminant function;layered neural network;bayesian;networked learning;neural network	Learning of Bayesian discriminant functions is a difficult task for ordinary one-hidden-layer neural networks, because the teacher signals are dichotomic random samples. When the neural network is trained, the parameters, the weights and thresholds, are usually all supposed to be optimized. However, those included in the activation functions of the hidden-layer units are optimized at the second step of the BP learning. We often experience difficulty in training such 'inner' parameters when teacher signals are dichotomic. To overcome this difficulty, we construct one-hidden-layer neural networks with a smaller number of the inner parameters to be optimized, fixing some components of the parameters. This inevitably causes increment of the hidden-layer units, but the network learns the Bayesian discriminant function better than ordinary neural networks.	artificial neural network;discriminant	Yoshifusa Ito;Cidambi Srinivasan;Hiroyuki Izumi	2007		10.1007/978-3-540-69158-7_26	stochastic neural network;sampling;feedforward neural network;probabilistic neural network;types of artificial neural networks;quadratic form;wake-sleep algorithm;bayesian probability;computer science;artificial intelligence;machine learning;pattern recognition;time delay neural network;discriminant function analysis;deep learning;activation function;artificial neural network	ML	17.47028035319315	-30.72347741946163	20463
03431ec353a9be94f32df79d9745e7784db72585	clustering based on a mixture of fuzzy models approach		In this work we propose a clustering methodology model named as Mixture of Fuzzy Models (MFMs). We adopt two assumptions: the data points are generated by a membership function and the sum of the memberships to all of the clusters must be greater or equal than zero. The objective is to obtain a set of membership functions which represent the data. It is formulated as a multiobjective optimization problem with two objectives: to maximize the sum of memberships within each cluster and to maximize the differences of memberships between clusters.		Miguel Pagola;Edurne Barrenechea Tartas;Aranzazu Jurio;Daniel Paternain;Humberto Bustince	2014		10.1007/978-3-319-08855-6_48	correlation clustering;fuzzy clustering;flame clustering;fuzzy classification;canopy clustering algorithm;cure data clustering algorithm;cluster analysis;conceptual clustering	NLP	2.8842246165080208	-39.90464819179748	20562
3991ce0c35af332098b80ceb19a0270216523ca0	specification and implementation of a digital hopfield-type associative memory with on-chip training	hopfield model;cmos integrated circuits;neurone;modele hopfield;concepcion circuito;memoire associative;neural networks;integrated circuit;learning;neural nets;modelo hopfield;implementation;circuit design;associative memory neurons circuits biological neural networks hopfield neural networks silicon arithmetic network on a chip neural networks cmos technology;circuito integrado;chip;aprendizaje;ejecucion;apprentissage;neurona;learning rules digital associative memory digital ic vlsi hopfield type on chip training neural network cmos;digital integrated circuits;associative storage;memory architecture;vlsi;associative memory;memoria asociativa;pastilla electronica;conception circuit;trainning;perceptron;reseau neuronal;content addressable storage;puce electronique;red neuronal;neuron;circuit integre;vlsi cmos integrated circuits content addressable storage digital integrated circuits neural nets;neural network	The definition of the requirements for the design of a neural network associative memory, with on-chip training, in standard digital CMOS technology is addressed. Various learning rules that can be integrated in silicon and the associative memory properties of the resulting networks are investigated. The relationships between the architecture of the circuit and the learning rule are studied in order to minimize the extra circuitry required for the implementation of training. A 64-neuron associative memory with on-chip training has been manufactured, and its future extensions are outlined. Beyond the application to the specific circuit described, the general methodology for determining the accuracy requirements can be applied to other circuits and to other autoassociative memory architectures.	architecture as topic;artificial neural network;autoassociative memory;biological neural networks;cmos;content-addressable memory;electronic circuit;hopfield network;learning rule;memory disorders;requirement;rule (guideline);silicon	Anne Johannet;Léon Personnaz;Gérard Dreyfus;Jean-Dominique Gascuel;Michel Weinfeld	1992	IEEE transactions on neural networks	10.1109/72.143369	chip;computer science;artificial intelligence;integrated circuit;perceptron;machine learning;circuit design;content-addressable memory;very-large-scale integration;flat memory model;implementation;cmos;artificial neural network;memory map	EDA	16.053385905331698	-27.006581574598556	20582
163b73bb623349ca37666c1b2f9bac42cce0d2df	semi-supervised matrixized least squares support vector machine		Abstract The matrix learning, which studies how to design algorithms based on matrix patterns, is proven to have some significant advantages over the vector learning such as the improved classification performance and the low computational complexity. However, most of the traditional matrix learning algorithms are supervised ones which require labels of all patterns. In practice, the difficult acquisition of labeled patterns is a major challenge for supervised algorithms. An effective approach to handle this problem is the manifold regularization, which is known as one of the most elegant frameworks for the semi-supervised learning (SSL). The Laplacian regularized least squares (LapRLS) is a classical vector learning algorithm following this framework. Inspired by the advantages of the matrix learning and the SSL, in this paper, we propose a novel semi-supervised matrix learning algorithm by incorporating the manifold regularization into the matrixized least squares support vector machine (MatLSSVM), termed as Laplacian matrixized LSSVM, or LapMatLSSVM for short. MatLSSVM, which has been built by combining the merits of the matrix learning and LSSVM, is a promising supervised algorithm. As an extension of MatLSSVM to the SSL, LapMatLSSVM can not only directly operate on matrix patterns, but also effectively exploit the geometric information embedded in unlabeled matrix patterns. Moreover, its generalization risk bound is tighter than that of LapRLS in terms of the Rademacher complexity. For the implementation, LapMatLSSVM learns in an iterative manner, and solves a least squares optimization problem at each iteration. Extensive experiments have been conducted across two kinds of datasets: image datasets and UCI datasets. Experimental results confirm the benefits of the proposed algorithm.	least squares support vector machine;semiconductor industry	Huimin Pei;Kuaini Wang;Ping Zhong	2017	Appl. Soft Comput.	10.1016/j.asoc.2017.07.040	machine learning;semi-supervised learning;mathematical optimization;online machine learning;mathematics;rademacher complexity;computational complexity theory;least squares;matrix (mathematics);least squares support vector machine;optimization problem;pattern recognition;artificial intelligence	ML	22.566393719283422	-38.50543762496993	20625
ddeda2741ad6d178938ddc9bcc8fa2a3c9dd6004	the application of techniques of neural network to product structure analysis of iron and steel corporation	unsupervised learning;neural networks iron steel gaussian processes clustering algorithms radial basis function networks network topology function approximation helium inorganic materials;iron;radial basis function networks;production control;manufacturing data processing;iron industry radial basis function neural network product structure analysis function approximation self learning steel industry;rbf neural network;steel industry;manufacturing data processing steel industry radial basis function networks production control unsupervised learning;structure analysis;neural network	In the past, the method of product structure analysis was based on OLS AutoDregression. By using the techniques of RBF neural network that have the property of the approximation ability and self learning, this paper gives a new method for the product structure analysis of an iron and steel industry.		Xing Chen;Xiqin He;Wenzhong Wang;Huaguang Zhang;Xihuai Yang	1999		10.1109/IJCNN.1999.836204	unsupervised learning;computer science;artificial intelligence;machine learning;iron;artificial neural network	NLP	11.98723910435481	-25.143921541373864	20633
7d4f9d0f3b5f747734a4167cb5057b79e84ada69	gml learning, a generic machine learning model for network measurements analysis		The application of machine learning models to the analysis of network measurement problems has largely increased in the last decade; however, there is still no clear best-practice or silver bullet approach to address these problems in a general context, and only adhoc and tailored approaches have been evaluated so far. While deep-learning models have provided a major breakthrough in highly-dimensional problems such as image processing, it is difficult to say today which is the best model to address the analysis of large volumes of highly-dimensional data collected in operational networks. In this paper we present a potential solution to fill this gap, exploring the application of ensemble learning models to multiple network measurement problems. We introduce GML Learning, a generic Machine Learning model for the analysis of network measurements. The GML model is a generalization of the well-known stacking approach to ensemble learning, and follows the concepts of the Super Learner model. The Super Learner performs asymptotically as well as the best input base or weak learners, providing a very powerful approach to tackle multiple problems with the same technique. In addition, it defines an approach to minimize over-fitting likelihood during training, using a variant of cross-validation. We deploy the GML model on top of Big-DAMA, a big data analytics framework for network measurement applications. We test the proposed solution in five different and assorted network measurement problems, including detection of network attacks and anomalies, QoE modeling and prediction, and Internet-paths dynamics tracking. Results confirm that the GML model provides better results than any of the single baseline models of the stack, and outperforms traditional bagging and boosting ensemble learning approaches. The GML Learning model opens the door for a generalization of a best-practice technique for the analysis of network measurements.	baseline (configuration management);big data;cross-validation (statistics);deep learning;ensemble learning;image processing;machine learning;no silver bullet;overfitting;stacking;whole earth 'lectronic link	Pedro Casas;Juan Martin Vanerio;Kensuke Fukuda	2017	2017 13th International Conference on Network and Service Management (CNSM)	10.23919/CNSM.2017.8255998	boosting (machine learning);image processing;ensemble learning;data modeling;big data;computer science;machine learning;artificial intelligence	ML	17.4955504024403	-38.64758838232504	20704
8c089049a9d1e0e9d42479178a70b93cc4d440e7	genetic multivariate polynomials: an alternative tool to neural networks	genetique;modelizacion;matematicas aplicadas;image processing;mathematiques appliquees;variable independante;genetica;analyse fonctionnelle;procesamiento imagen;algoritmo genetico;traitement image;genetics;modelisation;analisis regresion;multivariate polynomial;functional analysis;algorithme genetique;pattern recognition;analyse regression;genetic algorithm;regression analysis;variable independiente;reconnaissance forme;reseau neuronal;reconocimiento patron;applied mathematics;modeling;red neuronal;independent variable;neural network;analisis funcional	One of the basic problems of applied mathematics is to find a synthetic expression (model) which captures the essence of a system given a (necessarily) finite sample which reflects selected characteristics. When the model considers several independent variables its mathematical treatment may become burdensome or even downright impossible from a practical standpoint.	neural networks	Ángel Fernando Kuri Morales;Federico Juárez-Almaraz	2005		10.1007/11578079_28	variables;functional analysis;systems modeling;genetic algorithm;image processing;computer science;artificial intelligence;machine learning;artificial neural network;algorithm;regression analysis	Theory	9.119750925817343	-30.579042337454453	20706
41cfbd31ccb96e6ed484e14a19beab77b9f8c9ab	near-optimal supervised feature selection among frequent subgraphs	optimal solution;ucl;search space;anomaly detection;discovery;theses;conference proceedings;graph mining;digital web resources;ucl discovery;open access;ucl library;feature selection;book chapters;open access repository;function prediction;scene analysis;ucl research	Graph classification is an increasingly important step in numerous application domains, such as function prediction of molecules and proteins, computerised scene analysis, and anomaly detection in program flows. Among the various approaches proposed in the literature, graph classification based on frequent subgraphs is a popular branch: Graphs are represented as (usually binary) vectors, with components indicating whether a graph contains a particular subgraph that is frequent across the dataset. On large graphs, however, one faces the enormous problem that the number of these frequent subgraphs may grow exponentially with the size of the graphs, but only few of them possess enough discriminative power to make them useful for graph classification. Efficient and discriminative feature selection among frequent subgraphs is hence a key challenge for graph mining. In this article, we propose an approach to feature selection on frequent subgraphs, called CORK, that combines two central advantages. First, it optimizes a submodular quality criterion, which means that we can yield a near-optimal solution using greedy feature selection. Second, our submodular quality function criterion can be integrated into gSpan, the state-of-the-art tool for frequent subgraph mining, and help to prune the search space for discriminative frequent subgraphs even during frequent subgraph mining.	anomaly detection;feature selection;greedy algorithm;structure mining;submodular set function	Marisa Thoma;Hong Cheng;Arthur Gretton;Jiawei Han;Hans-Peter Kriegel;Alexander J. Smola;Le Song;Philip S. Yu;Xifeng Yan;Karsten M. Borgwardt	2009		10.1137/1.9781611972795.92	anomaly detection;searching the conformational space for docking;computer science;data science;machine learning;data mining;feature selection;information retrieval	ML	12.945763538360088	-47.728979335167985	20728
393d58275ecade61cd68716b64a62a2ebc802826	evolutionary strategy for learning multiple-valued logic functions	logic functions neural networks strips computer science network synthesis multi layer neural network neurons poles and towers mathematics information technology;evolutionary computation;multilayer perceptrons;point location;evolutionary strategy;evolution strategy;feedforward neural nets;evolutionary computation multivalued logic feedforward neural nets multilayer perceptrons;partitioning method minimal multilayer feedforward neural networks multiple valued multiple threshold perceptrons evolutionary strategy multiple valued logic function learning inter parallel hyperplane strips hidden units;multivalued logic;neural network;multiple valued logic	We consider the problem of synthesizing multiple-valued logic functions by neural networks. An evolutionary strategy (ES) which finds the longest strip in V/spl sube/K/sup n/ is described. A strip contains points located between two parallel hyperplanes. Repeated application of ES partitions the space V into a certain number of strips, each of them corresponding to a hidden unit. We construct neural networks based on these hidden units. Preliminary experimental results are presented and discussed.	algorithm;artificial neural network;evolution strategy;strips;sube card;software release life cycle	Alioune Ngom;Dan A. Simovici;Ivan Stojmenovic	2004	Proceedings. 34th International Symposium on Multiple-Valued Logic	10.1109/ISMVL.2004.1319935	feedforward neural network;computer science;artificial intelligence;machine learning;time delay neural network;mathematics;evolution strategy;artificial neural network;algorithm;intelligent control;evolutionary computation	Logic	14.94498306190592	-25.747739153067172	20785
12a2cd7c993800228dfd368c3b844b0f5ea3a5d7	neural tangent kernel: convergence and generalization in neural networks		At initialization, artificial neural networks (ANNs) are equivalent to Gaussian processes in the infinite-width limit [12, 9], thus connecting them to kernel methods. We prove that the evolution of an ANN during training can also be described by a kernel: during gradient descent on the parameters of an ANN, the network function fθ (which maps input vectors to output vectors) follows the kernel gradient of the functional cost (which is convex, in contrast to the parameter cost) w.r.t. a new kernel: the Neural Tangent Kernel (NTK). This kernel is central to describe the generalization features of ANNs. While the NTK is random at initialization and varies during training, in the infinite-width limit it converges to an explicit limiting kernel and it stays constant during training. This makes it possible to study the training of ANNs in function space instead of parameter space. Convergence of the training can then be related to the positive-definiteness of the limiting NTK. We then focus on the setting of least-squares regression and show that in the infinitewidth limit, the network function fθ follows a linear differential equation during training. The convergence is fastest along the largest kernel principal components of the input data with respect to the NTK, hence suggesting a theoretical motivation for early stopping. Finally we study the NTK numerically, observe its behavior for wide networks, and compare it to the infinite-width limit.	early stopping;fastest;fitts's law;gaussian process;gradient descent;kernel (operating system);kernel method;least squares;map;neural networks;nonlinear system;numerical analysis;suicidegirls;transfer function	Arthur Jacot;Franck Gabriel;Clément Hongler	2018			early stopping;mathematical optimization;kernel method;artificial intelligence;kernel (linear algebra);artificial neural network;function space;machine learning;principal component analysis;mathematics;gradient descent;gaussian process	ML	18.555488096964385	-30.10590032206271	20831
ed54048cb45e243919e888967d93d6e797b31203	effort estimation using analogy	project management;software cost estimation;software development management;software tools;angel automated environment;euclidean distance minimisation;analogous project collection;analogous project identification;analogous project storage;analogy;computation;datasets;effort estimation;n-dimensional space;observations;software project;variables	The staff resources or effort required for a software project are notoriously difficult to estimate in advance. To date most work has focused upon algorithmic cost models such as COCOMO and Function Points. These can suffer from the disadvantage of the need to calibrate the model to each individual measurement environment coupled with very variable accuracy levels even after calibration. An alternative approach is to use analogy for estimation. We demonstrate that this method has considerable promise in that we show it to out perform traditional algorithmic methods for six different datasets. A disadvantage of estimation by analogy is that it requires a considerable amount of computation. The paper describes an automated environment known as ANGEL that supports the collection, storage and identification of the most analogous projects in order to estimate the effort for a new project. ANGEL is based upon the minimisation of Euclidean distance in n-dimensional space. The software is flexible and can deal with differing datasets both in terms of the number of observations (projects) and in the variables collected. Our analogy approach is evaluated with six distinct datasets drawn from a range of different environments and is found to outperform other methods. It is widely accepted that effective software effort estimation demands more than one technique. We have shown that estimating by analogy is a candidate technique and that with the aid of an automated environment is an eminently practical technique.	algorithm;cocomo;computation;cost estimation in software engineering;estimation theory;euclidean distance;function point;software development effort estimation;software project management	Martin J. Shepperd;Chris Schofield;Barbara A. Kitchenham	1996			variables;project management;calibration;simulation;analogy;computer science;systems engineering;engineering;resource management;function point;software engineering;computation;data mining;euclidean distance;management;observation;metrics;cost estimate	SE	6.549057403738085	-40.50852050166915	20893
4884c765b6ceab7bdfb6703489810c8a386fd2a8	potential boosters?		Recent interpretations of the Adaboost algorithm view it as performing a gradient descent on a potential function. Simply changing the potential function allows one to create new algorithms related to AdaBoost. However, these new algorithms are generally not known to have the formal boosting property. This paper examines the question of which potential functions lead to new algorithms that are boosters. The two main results are general sets of conditions on the potential; one set implies that the resulting algorithm is a booster, while the other implies that the algorithm is not. These conditions are applied to previously studied potential functions , such as those used by LogitBoost and Doom II.	adaboost;algorithm;booster (electric power);boosting (machine learning);doom ii: hell on earth;gradient descent;logitboost	Nigel Duffy;David P. Helmbold	1999				ML	17.86464947655984	-34.13327082834579	20896
e6c60bf1c1d8d9cfb493beaa0cf3d1c3a45f47ac	training fourier series neural networks to map closed curves.	fourier series;neural network	The paper presents the closed curve mapping method using several Fourier series neural networks having one input and one output only. The proposed method is also excellently fitted for a lossy compression of closed curves. The method does not require a large number of operations and may be used for multidimensional curves. Fourier series neural networks are especially well fitted for described purposes.	analysis of algorithms;artificial neural network;lossy compression;monochrome	Krzysztof Halawa	2009			speech recognition;artificial intelligence;machine learning	ML	18.64598223995754	-30.06928222138439	20904
164b0e2a03a5a402f66c497e6c327edf20f8827b	sparse deep transfer learning for convolutional neural network	deep model compression;transfer learning;convolutional neural network	Extensive studies have demonstrated that the representations of convolutional neural networks (CNN), which are learned from a large-scale data set in the source domain, can be effectively transferred to a new target domain. However, compared to the source domain, the target domain often has limited data in practice. In this case, overfitting may significantly depress transferability, due to the model redundancy of the intensive CNN structures. To deal with this difficulty, we propose a novel sparse deep transfer learning approach for CNN. There are three main contributions in this work. First, we introduce a Sparse-SourceNet to reduce the redundancy in the source domain. Second, we introduce a Hybrid-TransferNet to improve the generalization ability and the prediction accuracy of transfer learning, by taking advantage of both model sparsity and implicit knowledge. Third, we introduce a Sparse-TargetNet, where we prune our Hybrid-TransferNet to obtain a highlycompact, source-knowledge-integrated CNN in the target domain. To examine the effectiveness of our methods, we perform our sparse deep transfer learning approach on a number of benchmark transfer learning tasks. The results show that, compared to the standard fine-tuning approach, our proposed approach achieves a significant pruning rate on CNN while improves the accuracy of transfer learning.	artificial neural network;benchmark (computing);convolutional neural network;experiment;overfitting;sparse matrix;transfer-based machine translation	Jiaming Liu;Yali Wang;Yu Qiao	2017			multi-task learning;transfer of learning;computer science;artificial intelligence;theoretical computer science;machine learning;convolutional neural network	AI	22.02941834461208	-49.934636442319835	20931
55f2770b7fecdeaedec5bc5ec5c1c3029c39efd3	an improved minibrain that learns through both positive and negative feedback	neural nets feedback learning artificial intelligence;neural nets;reinforcement learning;rel network minibrain positive feedback negative feedback reinforcement learned neural network;negative feedback biological neural networks learning neural networks performance evaluation biological system modeling brain modeling parallel processing road vehicles vehicle driving;feedback;negative feedback;learning artificial intelligence;neural network	A new reinforcement learned neural network, that follows the ideas of the minibrain network but includes exploration and learns through both positive and negative feedback, is proposed. The proposed ReL network is evaluated against the minibrain network in the n times n grid world domain and the taxi domain and is shown to perform significantly better than the minibrain network.	ap computer science a;artificial neural network;greedy algorithm;machine learning;negative feedback;rel	Chee Wee Phua;Alan Blair	2006	The 2006 IEEE International Joint Conference on Neural Network Proceedings	10.1109/IJCNN.2006.246768	computer science;artificial intelligence;machine learning;time delay neural network;feedback;negative feedback;artificial neural network	Robotics	16.873124046632384	-25.811050301695865	20943
f749cab671639965967b3e3b2f2c417cffcbb04e	genetic-based em algorithm for learning gaussian mixture models	unsupervised learning;optimal solution;mdl criterion;genetic operator;space exploration clustering algorithms convergence genetic algorithms stochastic processes probability distribution parametric statistics robustness iterative algorithms statistical learning;learning artificial intelligence gaussian processes genetic algorithms;gaussian processes;index terms unsupervised learning;search space;algorithms artificial intelligence cluster analysis computer simulation handwriting image enhancement image interpretation computer assisted information storage and retrieval models statistical normal distribution numerical analysis computer assisted pattern recognition automated;apprentissage non supervise;indexing terms;algoritmo genetico;critere mdl;modele melange gauss;gaussian mixture model;expectation maximization;mixture model;clustering;gaussian mixture models;minimum description length;algorithme genetique;algorithme em;genetic algorithm;genetic algorithms;algoritmo em;minimum description length index terms unsupervised learning clustering gaussian mixture models em algorithm genetic algorithm;mdl criterio;learning artificial intelligence;em algorithm;multivariate data;monotonic convergence genetic based expectation maximization algorithm learning gaussian mixture models multivariate data minimum description length criterion population based stochastic search;stochastic search	We propose a genetic-based expectation-maximization (GA-EM) algorithm for learning Gaussian mixture models from multivariate data. This algorithm is capable of selecting the number of components of the model using the minimum description length (MDL) criterion. Our approach benefits from the properties of genetic algorithms (GA) and the EM algorithm by combination of both into a single procedure. The population-based stochastic search of the GA explores the search space more thoroughly than the EM method. Therefore, our algorithm enables escaping from local optimal solutions since the algorithm becomes less sensitive to its initialization. The GA-EM algorithm is elitist which maintains the monotonic convergence property of the EM algorithm. The experiments on simulated and real data show that the GA-EM outperforms the EM method since: (1) we have obtained a better MDL score while using exactly the same termination condition for both algorithms; (2) our approach identifies the number of components which were used to generate the underlying data more often than the EM algorithm.	convergence (action);electron microscopy;expectation–maximization algorithm;experiment;genetic algorithm;mdl (programming language);minimum description length;mixture model;model selection;normal statistical distribution;population parameter;software release life cycle;solutions;stochastic optimization;benefit	Franz Pernkopf;Djamel Bouchaffra	2005	IEEE Transactions on Pattern Analysis and Machine Intelligence	10.1109/TPAMI.2005.162	unsupervised learning;ramer–douglas–peucker algorithm;weighted majority algorithm;cultural algorithm;computer science;machine learning;pattern recognition;mixture model;mathematics;fsa-red algorithm;statistics;population-based incremental learning	ML	4.040543844643262	-40.25465359887171	20995
57c0b0fa5744a4f82514d76f111e3599f939eef4	tuning support vector machines for minimax and neyman-pearson classification	minimax classification;ajustamiento modelo;estimation theory;minimax problem;analisis estadistico;validacion cruzada;2c svm;support vector machine tuning;support vector machines;problema minimax;perforation;metodo minimax;analisis forma;training;deteccion neyman pearson;minimax method;parameter selection minimax classification neyman pearson classification support vector machine error estimation;minimax criteria;svm classifiers;intelligence artificielle;neyman pearson;detection neyman pearson;probleme minimax;cost sensitive svm;ajustement modele;training data;error analysis;classification a vaste marge;2 nu svm parameter;minimax techniques;smoothing methods;estimation erreur;support vector machines error analysis estimation theory minimax techniques pattern classification statistical analysis;statistical analysis;machine learning;parameter selection;error estimation;erreur estimation;smoothing;model matching;analyse statistique;estimacion error;methode minimax;validation croisee;parameter space;pattern classification;alisamiento;classification error;error estimacion;artificial intelligence;neyman pearson classification;pattern analysis;support vector machines support vector machine classification minimax techniques error analysis costs smoothing methods performance gain computational efficiency performance loss design optimization;cross validation;inteligencia artificial;estimation error;support vector machine;maquina ejemplo soporte;vector support machine;error estimate;computational efficiency;lissage;analyse forme;2 nu svm parameter support vector machine tuning minimax criteria neyman pearson classification svm classifiers cost sensitive svm error estimation cross validation 2c svm;neyman pearson detection	This paper studies the training of support vector machine (SVM) classifiers with respect to the minimax and Neyman-Pearson criteria. In principle, these criteria can be optimized in a straightforward way using a cost-sensitive SVM. In practice, however, because these criteria require especially accurate error estimation, standard techniques for tuning SVM parameters, such as cross-validation, can lead to poor classifier performance. To address this issue, we first prove that the usual cost-sensitive SVM, here called the 2C-SVM, is equivalent to another formulation called the 2\nu-SVM. We then exploit a characterization of the 2\nu-SVM parameter space to develop a simple yet powerful approach to error estimation based on smoothing. In an extensive experimental study, we demonstrate that smoothing significantly improves the accuracy of cross-validation error estimates, leading to dramatic performance gains. Furthermore, we propose coordinate descent strategies that offer significant gains in computational efficiency, with little to no loss in performance.	computation;coordinate descent;cross-validation (statistics);estimated;experiment;minimax;performance;population parameter;smoothing (statistical technique);statistical classification;support vector machine;triangulation	Mark A. Davenport;Richard G. Baraniuk;Clayton D. Scott	2010	IEEE Transactions on Pattern Analysis and Machine Intelligence	10.1109/TPAMI.2010.29	support vector machine;computer science;machine learning;pattern recognition;mathematics;statistics	ML	20.80336659436932	-35.631542458132024	21054
197f8f22c8fd93749b053dbddc568873997fa845	a model and its different applications to case-based reasoning	case base reasoning;neural net;parallel architecture	A model to implement the case-based reasoning developed from using a neural net as a base to calculate a measure of similarity between the new problem and each case is presented. It is shown how the neural net provides a mechanism to retrieve cases considering information that in other models needs a parallel architecture. Moreover, in this paper it is analyzed how the model can be employed to create expert networks and case-based planners. ~ 1997 Elsevier Science B.V. All rights reserved.	artificial neural network;case-based reasoning;parallel computing	María Matilde García Lorenzo;Rafael Bello	1996	Knowl.-Based Syst.	10.1016/S0950-7051(96)01058-1	case-based reasoning;computer science;artificial intelligence;machine learning;data mining;artificial neural network	AI	5.714225043822566	-28.789240757496938	21057
0fb6a8dd0abd71a12e789b11069e7f47a9cb6e71	an improved rbf neural network based on evolutionary programming	gradient descent method;control systems;neural networks genetic programming functional programming computer networks computer architecture process design vectors feedforward neural networks integrated circuit technology nonlinear systems;network design;evolutionary computation;training;evolutionary programming;evolutionary programming local minimum gradient descent method radial basis function;local minimum;radial basis function networks;artificial neural networks;radial basis function;nonlinear system control rbf neural network evolutionary programming local minimum gradient descent method radial basis function neural network;rbf neural network;radial basis function neural network;radial basis function networks evolutionary computation gradient methods;mathematical model;gradient methods;optimization;nonlinear system control;nonlinear system;programming;conferences	For the problem of local minimum for gradient descent method used to train an RBF (Radial Basis Function) neural network, EP (evolutionary programming) is introduced to the training of RBF neural network in this paper. The combination method of EP and gradient descent method can effectively avoid local minimum, and provides a more reasonable network design. The effectiveness of the proposed scheme is demonstrated by the simulation of a nonlinear system control.	artificial neural network;evolutionary programming;expectation propagation;gradient descent;maxima and minima;network planning and design;nonlinear system;radial (radio);radial basis function;simulation	Lin Zhang;Xuanju Dang;Silin Zeng	2009	2009 Third International Conference on Genetic and Evolutionary Computing	10.1109/WGEC.2009.80	evolutionary programming;gradient descent;programming;feedforward neural network;mathematical optimization;network planning and design;radial basis function;probabilistic neural network;nonlinear system;computer science;artificial intelligence;machine learning;maxima and minima;mathematical model;artificial neural network;evolutionary computation	Robotics	14.62452973823762	-24.828664620518246	21118
a71185cfa1c014070be783df5763c5661c402293	wrpn: training and inference using wide reduced-precision networks		For computer vision applications, prior works have shown the efficacy of reducing numeric precision of model parameters (network weights) in deep neural networks but also that reducing the precision of activations hurts model accuracy much more than reducing the precision of model parameters. We study schemes to train networks from scratch using reduced-precision activations without hurting the model accuracy. We reduce the precision of activation maps (along with model parameters) using a novel quantization scheme and increase the number of filter maps in a layer, and find that this scheme compensates or surpasses the accuracy of the baseline full-precision network. As a result, one can significantly reduce the dynamic memory footprint, memory bandwidth, computational energy and speed up the training and inference process with appropriate hardware support. We call our scheme WRPN wide reduced-precision networks. We report results using our proposed schemes and show that our results are better than previously reported accuracies on ILSVRC-12 dataset while being computationally less expensive compared to previously reported reduced-precision networks.	artificial neural network;baseline (configuration management);computer vision;deep learning;map;memory bandwidth;memory footprint;memory management	Asit K. Mishra;Jeffrey J. Cook;Eriko Nurvitadhi;Debbie Marr	2017	CoRR		machine learning	ML	21.839370088287406	-50.12478738572118	21124
89ea8da25d5fb0cbf91a54de4d2b43dfffa496d2	opening the black box: low-dimensional dynamics in high-dimensional recurrent neural networks	true fixed point;recurrent neural networks rnns;training rnns;black box;trained rnns;slow point;slow movement;high-dimensional recurrent neural network;low-dimensional dynamic;high-dimensional rnn example;fixed point;slow region;linearized dynamic	Recurrent neural networks (RNNs) are useful tools for learning nonlinear relationships between time-varying inputs and outputs with complex temporal dependencies. Recently developed algorithms have been successful at training RNNs to perform a wide variety of tasks, but the resulting networks have been treated as black boxes: their mechanism of operation remains unknown. Here we explore the hypothesis that fixed points, both stable and unstable, and the linearized dynamics around them, can reveal crucial aspects of how RNNs implement their computations. Further, we explore the utility of linearization in areas of phase space that are not true fixed points but merely points of very slow movement. We present a simple optimization technique that is applied to trained RNNs to find the fixed and slow points of their dynamics. Linearization around these slow regions can be used to explore, or reverse-engineer, the behavior of the RNN. We describe the technique, illustrate it using simple examples, and finally showcase it on three high-dimensional RNN examples: a 3-bit flip-flop device, an input-dependent sine wave generator, and a two-point moving average. In all cases, the mechanisms of trained networks could be inferred from the sets of fixed and slow points and the linearized dynamics around them.	algorithm;artificial neural network;black box;computation;control theory;flops;flip-flop (electronics);inference;mathematical optimization;neural network simulation;neural networks;nonlinear system;random neural network;recurrent neural network;reverse engineering;short interspersed nucleotide elements;unstable medical device problem	David Sussillo;Omri Barak	2013	Neural Computation	10.1162/NECO_a_00409	simulation;artificial intelligence;machine learning;mathematics	ML	19.035746356329955	-24.973778743785193	21142
490a2ac91a17aaa750cbf473811e7a049017d119	learning methods for dynamic topic modeling in automated behavior analysis		Semisupervised and unsupervised systems provide operators with invaluable support and can tremendously reduce the operators’ load. In the light of the necessity to process large volumes of video data and provide autonomous decisions, this paper proposes new learning algorithms for activity analysis in video. The activities and behaviors are described by a dynamic topic model. Two novel learning algorithms based on the expectation maximization approach and variational Bayes inference are proposed. Theoretical derivations of the posterior estimates of model parameters are given. The designed learning algorithms are compared with the Gibbs sampling inference scheme introduced earlier in the literature. A detailed comparison of the learning algorithms is presented on real video data. We also propose an anomaly localization procedure, elegantly embedded in the topic modeling framework. It is shown that the developed learning algorithms can achieve 95% success rate. The proposed framework can be applied to a number of areas, including transportation systems, security, and surveillance.		Olga Isupova;Danil Kuzin;Lyudmila S. Mihaylova	2018	IEEE Transactions on Neural Networks and Learning Systems	10.1109/TNNLS.2017.2735364	semi-supervised learning;machine learning;artificial intelligence;unsupervised learning;pattern recognition;empirical risk minimization;inference;computational learning theory;computer science;gibbs sampling;wake-sleep algorithm;dynamic topic model	ML	17.79338551843544	-34.830712245817026	21151
49914c2a22cd7fc8a9737642eb2910ea94dc18ac	on using prototype reduction schemes to optimize dissimilarity-based classification	mahalanobis distance;europa;image recognition;reconocimiento imagen;pays bas;netherlands;learning;dissimilarity measure;dissimilarity based classification;implementation;analisis forma;prototype selection;mahalanobis distances mds;similitude;dissimilarity representation;aprendizaje;discriminant analysis;analyse discriminante;prototipo;accuracy;analisis discriminante;apprentissage;precision;holanda;signal classification;similarity;reconnaissance image;pattern classification;pattern recognition;classification signal;pattern analysis;reconnaissance forme;similitud;error bound;europe;classification automatique;reconocimiento patron;classification accuracy;implementacion;automatic classification;clasificacion automatica;prototype;conditional distribution;analyse forme;prototype reduction schemes prss;classification forme	The aim of this paper is to present a strategy by which a new philosophy for pattern classification, namely that pertaining to dissimilaritybased classifiers (DBCs), can be efficiently implemented. This methodology, proposed by Duin and his co-authors (see Refs. [Experiments with a featureless approach to pattern recognition, Pattern Recognition Lett. 18 (1997) 1159–1166; Relational discriminant analysis, Pattern Recognition Lett. 20 (1999) 1175–1181; Dissimilarity representations allow for buillding good classifiers, Pattern Recognition Lett. 23 (2002) 943–956; Dissimilarity representations in pattern recognition, Concepts, theory and applications, Ph.D. Thesis, Delft University of Technology, Delft, The Netherlands, 2005; Prototype selection for dissimilarity-based classifiers, Pattern Recognition 39 (2006) 189–208]), is a way of defining classifiers between the classes, and is not based on the feature measurements of the individual patterns, but rather on a suitable dissimilarity measure between them. The advantage of this methodology is that since it does not operate on the class-conditional distributions, the accuracy can exceed the Bayes’ error bound. The problem with this strategy is, however, the need to compute, store and process the interpattern dissimilarities for all the training samples, and thus, the accuracy of the classifier designed in the dissimilarity space is dependent on the methods used to achieve this. In this paper, we suggest a novel strategy to enhance the computation for all families of DBCs. Rather than compute, store and process the DBC based on the entire data set, we advocate that the training set be first reduced into a smaller representative subset. Also, rather than determine this subset on the basis of random selection, or clustering, etc., we advocate the use of a prototype reduction scheme (PRS), whose output yields the points to be utilized by the DBC. The rationale for this is explained in the paper. Apart from utilizing PRSs, in the paper we also propose simultaneously employing the Mahalanobis distance as the dissimilarity-measurement criterion to increase the DBCs classification accuracy. Our experimental results demonstrate that the proposed mechanism increases the classification accuracy when compared with the “conventional” approaches for samples involving real-life as well as artificial data sets—even though the resulting dissimilarity criterion is not symmetric. 2007 Pattern Recognition Society. Published by Elsevier Ltd. All rights reserved.	cluster analysis;computation;design rationale;linear discriminant analysis;naive bayes classifier;pattern recognition;procedural reasoning system;prototype;real life;statistical classification;test set	Sang-Woon Kim;B. John Oommen	2007	Pattern Recognition	10.1016/j.patcog.2007.03.006	computer science;machine learning;pattern recognition;data mining;mathematics;accuracy and precision;linear discriminant analysis;algorithm;statistics	Vision	10.98905271129361	-34.43235960915427	21158
0041351cdc5c513b23c46814d5b8dfc081324aba	a general probabilistic formulation for supervised neural classifiers	information geometry;relative entropy;normal mixture;channel equalization;probability model;em algorithm;information theoretic;partial likelihood;neural network	We use partial likelihood (PL) theory to introduce a general probabilistic framework for the design and analysis of neural classifiers. The formulation allows for the training samples used in the design to have correlations in time, and for use of a wide range of neural network probability models including recurrent structures. We use PL theory to establish a fundamental information-theoretic connection, show the equivalence of likelihood maximization and relative entropy minimization, without making the common assumptions of independent training samples and true distribution information. We use this result to construct the information geometry of partial likelihood and derive the information geometric e- and m-projection (em) algorithm for class conditional density modeling by finite normal mixtures. We demonstrate the successful application of the algorithm by a channel equalization example and give simulation results to show the efficiency of the scheme.		Hongmei Ni;Tülay Adali;Bo Wang;Xiao Liu	2000	VLSI Signal Processing	10.1023/A:1008107819882	expectation–maximization algorithm;computer science;equalization;machine learning;pattern recognition;mathematics;kullback–leibler divergence;artificial neural network;information geometry;statistics	ML	21.28280774157379	-34.6408762543206	21188
8bf6a42d6ec4d76152f87438e1caaa4d5344148b	process-oriented iterative multiple alignment for medical process mining	knowledge discovery;medical healthcare informatics;process mining;trace alignment;workflow analysis	Adapted from biological sequence alignment, trace alignment is a process mining technique used to visualize and analyze workflow data. Any analysis done with this method, however, is affected by the alignment quality. The best existing trace alignment techniques use progressive guide-trees to heuristically approximate the optimal alignment in O(N2L2) time. These algorithms are heavily dependent on the selected guide-tree metric, often return sum-of-pairs-score-reducing errors that interfere with interpretation, and are computationally intensive for large datasets. To alleviate these issues, we propose process-oriented iterative multiple alignment (PIMA), which contains specialized optimizations to better handle workflow data. We demonstrate that PIMA is a flexible framework capable of achieving better sum-of-pairs score than existing trace alignment algorithms in only O(NL2) time. We applied PIMA to analyzing medical workflow data, showing how iterative alignment can better represent the data and facilitate the extraction of insights from data visualization.	approximation algorithm;data visualization;handling (psychology);heuristic;imagery;iteration;iterative method;maxima and minima;multiple endocrine neoplasia;multiple sequence alignment;rule (guideline);sparse matrix;subgroup;time complexity;trees (plant);benefit	Shuhong Chen;Sen Yang;Moliang Zhou;Randall S. Burd;Ivan Marsic	2017	2017 IEEE International Conference on Data Mining Workshops (ICDMW)	10.1109/ICDMW.2017.63	artificial intelligence;machine learning;data mining;data visualization;merge (version control);sequence alignment;process mining;multiple sequence alignment;computer science;workflow;heuristic;dynamic programming	Visualization	-1.8028053005528806	-49.97996795926682	21210
f67076c0c20bb5beade74d14375fe1a70abb324a	closed-set lattice and modular matroid induced by covering-based rough sets		Covering is a common form of data representation, and covering-based rough sets, a technique of granular computing, provide an effective tool to deal with this type of data. However, many important problems of covering-based rough sets, such as covering reduction, are NP-hard so that most algorithms to solve them are greedy ones. Matroid theory, based on linear algebra and graph theory, provides well-established platforms for greedy algorithms. Lattice has been widely used in diverse fields, especially algorithm design, which plays an important role in covering reduction. Therefore, it is necessary to integrate covering-based rough sets with matroid and lattice. In this paper, we construct three types of matroids through covering-based rough sets and investigate their modularity. Moreover, we investigate some characteristics of these types of closed-set lattices induced by these three types of matroids and the relationships among these closed-set lattices. First, based on covering-based rough sets, three families of sets are constructed and proved to satisfy independent set axiom of matroids. So three types of matroids are induced by covering-based rough sets in this way. Second, some characteristics of these matroids, such as rank function, closure operator and closed set, are presented. Moreover, we investigate the characteristics of these closed-set lattices induced by these three types of matroids, such as modular pair, modular element. Finally, the relationships among these closed-set lattices induced by these three types of matroids are investigated. Especially, we prove that these three types of matroids induced by covering-based rough sets are all modular matroids.	matroid;rough set	Lirun Su;William Zhu	2017	Int. J. Machine Learning & Cybernetics	10.1007/s13042-014-0314-5	matroid;combinatorics;discrete mathematics;graphic matroid;topology;mathematics	Theory	-1.9333994920703224	-24.52864936003832	21219
cb83b7ecf0a2708f1e1b32cfe15d3ffe296e9c24	probabilistic aggregation of classifiers for incremental learning	posterior probability;feature space;incremental learning;incremental algorithm;majority voting	We work with a recently proposed algorithm where an ensemble of base classifiers, combined using weighted majority voting, is used for incremental classification of data. To successfully accommodate novel information without compromising previously acquired knowledge this algorithm requires an adequate strategy to determine the voting weights. Given an instance to classify, we propose to define each voting weight as the posterior probability of the corresponding hypothesis given the instance. By operating with priors and the likelihood models the obtained weights can take into account the location of the instance in the different class-specific feature spaces but also the coverage of each class k given the classifier and the quality of the learned hypothesis. This approach can provide important improvements in the generalization performance of the resulting classifier and its ability to control the stability/plasticity tradeoff. Experiments are carried out with three real classification problems already introduced to test incremental algorithms.	algorithm;dynamic problem (algorithms);probabilistic database	Patricia Trejo;Ricardo Ñanculef;Héctor Allende;Claudio Moraga	2007		10.1007/978-3-540-73007-1_17	majority rule;feature vector;computer science;machine learning;pattern recognition;data mining;mathematics;posterior probability;statistics	ML	16.109336159844958	-38.81585307172171	21225
c3b9987f5b459e12f175e2e62ba662a7b17172d0	a novel identification method for takagi-sugeno fuzzy model		Based on the Xie–Beni index and an improved particle swarm optimization algorithm, a novel identification method for the Takagi–Sugeno fuzzy model is proposed in this paper. Firstly, Xie–Beni indices with a fuzzy c-means clustering algorithm are adopted to find the rule number of the Takagi–Sugeno fuzzy model. By utilizing the particle swarm optimization algorithm, the initial membership function and the consequent parameters of the fuzzy model are obtained. In addition, through an improved fuzzy c-regression model and orthogonal least-square method, the premise structure and consequent parameters can be obtained to establish the Takagi–Sugeno fuzzy model. Some well-known models are used to demonstrate that the proposed method outperforms some existing methods. © 2017 Elsevier B.V. All rights reserved.	algorithm;approximation error;cluster analysis;fitness function;fuzzy cognitive map;fuzzy rule;mathematical optimization;ordinary least squares;particle swarm optimization;time complexity;x image extension	Shun-Hung Tsai;Yu-Wen Chen	2018	Fuzzy Sets and Systems	10.1016/j.fss.2017.10.012		AI	6.059018970198331	-26.195857063009	21279
2ba1479ed62042ad0adba3360c070d9572d01686	optimization on active learning strategy for object category retrieval	locality sensitive hashing;complexity theory;support vector machines;active learning;training;locality sensitive hashing active learning image retrieval relevance feedback support vector machines;very large database;machine learning;computational complexity;relevance feedback computational complexity content based retrieval image retrieval learning artificial intelligence;image databases image retrieval feedback machine learning computational complexity information retrieval learning systems scalability indexes histograms;approximation methods;scalability;support vector machine;learning artificial intelligence;content based image retrieval;relevance feedback;content based retrieval;very large database active learning strategy object category retrieval content based image retrieval machine learning technique relevance feedback iterations computational complexity locality sensitive hashing voc2006 database;on line learning;image retrieval	Active learning is a machine learning technique which has attracted a lot of research interest in the content-based image retrieval (CBIR) in recent years. To be effective, an active learning system must be fast and efficient using as few (relevance) feedback iterations as possible. Scalability is the major problem for such an on-line learning method, since the complexity of such methods on a database of size n is in the best case O(n * log(n)). In this article we propose a strategy to overcome this limitation. Our technique exploits ultra fast retrieval methods like Locality Sensitive Hashing (LSH), recently applied for unsupervised image retrieval. Combined with active selection, our method is able to achieve very fast active learning task in very large database. Experiments on VOC2006 database are reported, results are obtained four times faster while preserving the accuracy.	active learning (machine learning);best, worst and average case;content-based image retrieval;experiment;iteration;locality of reference;locality-sensitive hashing;online and offline;online machine learning;relevance feedback;scalability;lsh	David Gorisse;Matthieu Cord;Frédéric Precioso	2009	2009 16th IEEE International Conference on Image Processing (ICIP)	10.1109/ICIP.2009.5413554	unsupervised learning;support vector machine;image retrieval;computer science;machine learning;pattern recognition;active learning;information retrieval	Vision	18.081943111266266	-46.283779169539905	21297
cc7424b0eadf08a8edac27109d45f39294f9af7e	creating abstract concepts for classification by finding top- n maximal weighted cliques	optimisation;entropia;optimizacion;loi probabilite;ley probabilidad;graph clique;intelligence artificielle;probabilistic approach;data mining;classification;fonction objectif;objective function;optimization problem;branch and bound method;metodo branch and bound;fouille donnee;enfoque probabilista;approche probabiliste;classification rules;probability distribution;entropie;artificial intelligence;funcion objetivo;optimization;entropy;inteligencia artificial;methode separation et evaluation;clique graphe;branch and bound;busca dato;clasificacion;possibility distribution	This paper presents a method for creating abstract concepts for classification rule mining. We try to find abstract concepts that are useful for the classification in the sense that assuming such a concept can well discriminate a target class and supports data as much as possible. Our task of finding useful concepts is formalized as an optimization problem in which its constraint and objective function are given by entropy and probability of class distributions, respectively. Concepts to be found can be stated in terms of maximal weighted cliques in a graph constructed from the possible distributions. From the graph, as useful abstract concepts, top-N maximal weighted cliques are efficiently extracted with two pruning techniques: branch-and-bound and entropy-based pruning. It is shown that our entropy-based pruning can safely prune only useless cliques by adding distributions in increasing order of their entropy in the process of clique expansion. Preliminary experimental results show that useful concepts can be created in our framework.	maximal set	Yoshiaki Okubo;Makoto Haraguchi	2003		10.1007/978-3-540-39644-4_41	entropy;combinatorics;computer science;artificial intelligence;machine learning;mathematics;algorithm	Logic	7.469829884749209	-32.489681259495555	21307
e4001efa35f2b2d259849d1598d48b6f92f6b1b3	on exploring genome rearrangement phylogenetic patterns	optimal solution;genome rearrangement;inversion;protein sequence;reconstruction;edit distance;statistical significance;correspondence problem;breakpoint graphs;gene order;permutations;phylogenetic inference;evolution	The study of genome rearrangement is much harder than the corresponding problems on DNA and protein sequences, because of the occurrences of numerous combinatorial structures. By explicitly exploring these combinatorial structures, the recently developed adequate subgraph theory shows that a family of these structures, adequate subgraphs, are informative in finding the optimal solutions to the rearrangement median problem. Its extension gives rise to the tree scoring method GASTS, which provides quick and accurate estimation of the number of rearrangement events, for any given topology. With a similar motivation, this paper discusses and provides solid but somewhat initial results, on combinatorial structures that are informative in phylogenetic inference. These structures, called rearrangement phylogenetic patterns, provide more insights than algorithmic approaches, and may provide statistical significance for inferred phylogenies and lead to efficient and robust phylogenetic inference methods on large sets of taxa. We explore rearrangement phylogenetic patterns with respect to both the breakpoint distance and the DCJ distance. The latter has a simple formulation and well approximates other edit distances. On four genomes, we prove that a contrasting shared adjacency, where a gene forms one adjacency in two genomes and a different adjacency in the other two genomes, is a rearrangement phylogenetic pattern. Phylogenetic inferences based on the numbers of this pattern, are very accurate and robust against short internal edges, tested on 55,000 datasets simulated by random inversions. Further analysis shows that the numbers of this pattern well explain the variations in the number of rearrangement events over different topologies.	breakpoint;computational phylogenetics;edit distance;hybrid genome assembly;information;maximum parsimony (phylogenetics);occam's razor;peptide sequence;phylogenesis	Andrew Wei Xu	2010		10.1007/978-3-642-16181-0_11	inversion;biology;combinatorics;edit distance;bioinformatics;evolution;mathematics;statistical significance;correspondence problem;phylogenetic network;genetics;statistics	Comp.	0.9290061006437221	-51.09896263655981	21387
f0f3b03dec756906c5f4aff8347f603daac70c6a	an iterative constrained optimization approach to classifier design	constrained optimization;optimisation;degradation;constraint optimization;design engineering;bridges;satisfiability;design optimization;pareto optimization;classifier design;objective function;iterative constrained optimization approach;iterative methods constraint optimization design optimization machine learning design engineering text categorization pareto optimization degradation error analysis bridges;iterative methods;error analysis;machine learning;text categorization iterative constrained optimization approach classifier design constrained nonlinear optimization techniques automatic language identification;pattern classification;constrained nonlinear optimization techniques;language identification;pattern classification iterative methods optimisation;nonlinear optimization;constrained optimization problem;text categorization;automatic language identification	In this paper, we propose an iterative constrained optimization (ICO) approach to classifier design. When a set of conflicting objectives needs to be simultaneously satisfied, it is often not easy to combine all the utilities in a single overall objective function for optimization. We instead formulate the problem with conflicting objectives as a single-objective optimization scenario while embedding other competing objectives in constraints so that the original problem can be solved by adopting conventional constrained nonlinear optimization techniques. The bounds needed to constrain each objective are determined based on the objective function values obtained in the previous iterate. The so-formed individual constrained optimization problems are solved until a stable solution is obtained. We illustrate the utility of our framework in the context of designing classifiers for text categorization and automatic language identification. The results of our experiments demonstrate that our approach achieves a significant improvement in one objective with only slight degradation of the other conflicting objective	categorization;constrained optimization;document classification;elegant degradation;experiment;iteration;iterative method;language identification;mathematical optimization;nonlinear programming;nonlinear system;optimization problem	Sibel Yaman;Chin-Hui Lee	2006	2006 IEEE International Conference on Acoustics Speech and Signal Processing Proceedings	10.1109/ICASSP.2006.1661308	language identification;mathematical optimization;constrained optimization;multidisciplinary design optimization;degradation;computer science;multi-objective optimization;machine learning;pattern recognition;mathematics;iterative method;vector optimization;satisfiability	Vision	18.35660559854516	-43.17480623669121	21397
2421f1e1061457bd623068a602deb122af483d00	transfer learning by kernel meta-learning		A crucial issue in machine learning is how to learn appropriate representations for data. Recently, much work has been devoted to kernel learning, that is, the problem of finding a good kernel matrix for a given task. This can be done in a semi-supervised learning setting by using a large set of unlabeled data and a (typically small) set of i.i.d. labeled data. Another, even more challenging problem, is how one can exploit partially labeled data of a source task to learn good representations for a different, but related, target task. This is the main subject of transfer learning. In this paper, we present a novel approach to transfer learning based on kernel learning. Specifically, we propose a kernel meta-learning algorithm which, starting from a basic kernel, tries to learn chains of kernel transforms that are able to produce good kernel matrices for the source tasks. The same sequence of transformations can be then applied to compute the kernel matrix for new related target tasks. We report on the application of this method to the five datasets of the Unsupervised and Transfer Learning (UTL) challenge benchmark, where we won the first phase of the competition.	algorithm;benchmark (computing);kernel (operating system);machine learning;semi-supervised learning;semiconductor industry;supervised learning;unsupervised learning	Fabio Aiolli	2012			semi-supervised learning;unsupervised learning;multi-task learning;kernel method;instance-based learning;string kernel;kernel embedding of distributions;radial basis function kernel;computer science;theoretical computer science;machine learning;pattern recognition;graph kernel;tree kernel;polynomial kernel	ML	23.163161989825998	-44.033899293489284	21415
0de224879f8040664717ed2b0c3bfe01891304aa	reducing memory requirements of scope approximator in reinforcement learning	scope approximator;memory requirements;reinforcement learning	Scope classification is an instance-based technique, which can be used as a function approximator in reinforcement learning system. However, without any storage management mechanism, its memory requirements can be huge. This paper presents modified version of scope approximator using density threshold to control memory usage. Computational experiments investigating the performance of the system and results achieved are reported.	reinforcement learning	Artur Michalski	2002			error-driven learning;computer science;artificial intelligence;machine learning;pattern recognition	NLP	15.292756247287484	-31.362979065404218	21429
249ec9c20ff96245da594f096c34c0015827699f	similarity-based contrastive divergence methods for energy-based deep learning models		Energy-based deep learning models like Restricted Boltzmann Machines are increasingly used for real-world applications. However, all these models inherently depend on the Contrastive Divergence (CD) method for training and maximization of log likelihood of generating the given data distribution. CD, which internally uses Gibbs sampling, often does not perform well due to issues such as biased samples, poor mixing of Markov chains and highmass probability modes. Variants of CD such as PCD, Fast PCD and Tempered MCMC have been proposed to address this issue. In this work, we propose a new approach to CDbased methods, called Diss-CD, which uses dissimilar data to allow the Markov chain to explore new modes in the probability space. This method can be used with all variants of CD (or PCD), and across all energy-based deep learning models. Our experiments on using this approach on standard datasets including MNIST, Caltech-101 Silhouette and Synthetic Transformations, demonstrate the promise of this approach, showing fast convergence of error in learning and also a better approximation of log likelihood of the data.	approximation;caltech 101;deep learning;expectation–maximization algorithm;experiment;gibbs sampling;mnist database;markov chain monte carlo;process-centered design;restricted boltzmann machine;sampling (signal processing);synthetic intelligence;teaching method;viz: the computer game;word lists by frequency	Adepu Ravi Sankar;Vineeth N. Balasubramanian	2015			computer science;machine learning;mathematics;algorithm;statistics	ML	24.506721801595038	-30.688701403554667	21436
c3e504cb9090045fb9da6ca4d9b0f701ebc3b439	neural networks: are stochastic global optimization methods worth the trouble?	global optimization;neural network		global optimization;neural networks;optimizing compiler	Lonnie Hamm;B. Wade Brorsen;Martin T. Hagan	2002			stochastic neural network;mathematical optimization;computer science;artificial intelligence;recurrent neural network;machine learning;artificial neural network	Vision	13.388966856449573	-26.49157513768234	21482
b3955ecf14a289cccbf14f93a4222b7b7df7757a	an extended id3 decision tree algorithm for spatial data	patial decision tree;classification algorithm;decision tree;rivers;spatiainformation gain;spatial information gain;spatial data;attribute selection;visual databases data mining decision trees feature extraction pattern classification terrain mapping;spatial measure id3 algorithm spatial decision tree spatial information gain spatial relation;prediction algorithms;data mining;spatial database;spatial data mining;spatial relation;spatial databases decision trees classification algorithms partitioning algorithms data mining rivers prediction algorithms;feature extraction;spatial decision tree;spatial databases;classification algorithms;pattern classification;splitting layer extended id3 decision tree algorithm spatial data classification spatial data mining algorithm pattern extraction nonspatial dataset polygon features discrete feature representation attribute selection spatial information gain explanatory layer;terrain mapping;decision trees;information gain;article;spatial information;id3 algorithm;spatial measure;partitioning algorithms;visual databases	Utilizing data mining tasks such as classification on spatial data is more complex than those on non-spatial data. It is because spatial data mining algorithms have to consider not only objects of interest itself but also neighbours of the objects in order to extract useful and interesting patterns. One of classification algorithms namely the ID3 algorithm which originally designed for a non-spatial dataset has been improved by other researchers in the previous work to construct a spatial decision tree from a spatial dataset containing polygon features only. The objective of this paper is to propose a new spatial decision tree algorithm based on the ID3 algorithm for discrete features represented in points, lines and polygons. As in the ID3 algorithm that use information gain in the attribute selection, the proposed algorithm uses the spatial information gain to choose the best splitting layer from a set of explanatory layers. The new formula for spatial information gain is proposed using spatial measures for point, line and polygon features. Empirical result demonstrates that the proposed algorithm can be used to join two spatial objects in constructing spatial decision trees on small spatial dataset. The proposed algorithm has been applied to the real spatial dataset consisting of point and polygon features. The result is a spatial decision tree with 138 leaves and the accuracy is 74.72%.	data mining;decision tree model;id3 algorithm;information gain in decision trees;kullback–leibler divergence;list of algorithms;spatial database;test set	Imas S. Sitanggang;Razali Yaakob;N. Mustapha;A. A. B. Nuruddin	2011	Proceedings 2011 IEEE International Conference on Spatial Data Mining and Geographical Knowledge Services	10.1109/ICSDM.2011.5969003	statistical classification;computer science;machine learning;decision tree;pattern recognition;incremental decision tree;data mining;spatial analysis;id3 algorithm;spatial database;statistics;spatial query	ML	1.4430604187948897	-38.33719476155439	21495
6cb9ba3f14e7a1e45e56200ba8017cabe850cd84	using closed itemsets for discovering representative association rules	algorithme rapide;representation;concept;base donnee;analisis forma;conceptual analysis;database;base dato;analisis conceptual;frequent itemset;regle association;association rule;frequent closed itemset;fast algorithm;pattern analysis;analyse conceptuelle;algoritmo rapido;analyse forme;formal concept analysis;representacion;concepto	A set of association rules is called representative if it is a minimal set of rules from which all association rules can be generated. The existing algorithms for generating representative association rules use all the frequent itemsets as input. In this paper, we present a new approach for generating representative association rules that uses only a subset of the set of frequent itemsets called frequent closed itemsets. This results in a big reduction in the input size and, therefore, faster algorithms for generating representative association rules. Our approach uses ideas from formal concept analysis to find frequent closed itemsets.	algorithm;association rule learning;formal concept analysis;full configuration interaction;information	Jamil Saquer;Jitender S. Deogun	2000		10.1007/3-540-39963-1_52	association rule learning;computer science;formal concept analysis;machine learning;data mining;database;mathematics;concept;representation;algorithm	DB	-3.2304877584688496	-32.910387374353554	21553
370b9d3352e1f7a1a4ab5981141471aae794a381	flexible learning of k-dependence bayesian network classifiers	bayesian classifier;bayesian network classifier;flexible learning;estimation of distribution algorithm;performance improvement;probability distribution	In this paper we present an extension to the classical k-dependence Bayesian network classifier algorithm. The original method intends to work for the whole continuum of Bayesian classifiers, from naïve Bayes to unrestricted networks. In our experience, it performs well for low values of k. However, the algorithm tends to degrade in more complex spaces, as it greedily tries to add k dependencies to all feature nodes of the resulting net.  We try to overcome this limitation by seeking for optimal values of k on a feature per feature basis. At the same time, we look for the best feature ordering. That is, we try to estimate the joint probability distribution of optimal feature orderings and individual number of dependencies. We feel that this preserves the essence of the original algorithm, while providing notable performance improvements.	bayesian network;greedy algorithm;naivety;triune continuum paradigm	Arcadio Rubio;José A. Gámez	2011		10.1145/2001576.2001741	probability distribution;naive bayes classifier;variable-order bayesian network;estimation of distribution algorithm;computer science;machine learning;pattern recognition;data mining;bayesian statistics	AI	16.860980072665974	-37.2775472630503	21555
300293526a31b64ce7849b88bca46631592ce115	concept hierarchy construction by combining spectral clustering and subsumption estimation	tratamiento automatico;graphe non oriente;documento electronico;graph theory;metodo espectral;web documents;analyse amas;teoria grafo;navegacion informacion;non directed graph;descomposicion grafo;red www;guidage;navigation information;relation semantique;reseau web;relacion semantica;information browsing;guiado;classification;theorie graphe;document electronique;spectral clustering;graphe pondere;automatic processing;cluster analysis;graph partitioning;internet;grafo pondero;grafo no orientado;analyse spectrale;spectral method;concept hierarchy;guidance;world wide web;analisis espectral;analisis cluster;methode spectrale;semantic relation;weighted graph;information system;spectral analysis;traitement automatique;clasificacion;systeme information;electronic document;graph decomposition;decomposition graphe;sistema informacion	With the rapid development of the Web, how to add structural guidance (in the form of concept hierarchies) for Web document navigation becomes a hot research topic. In this paper, we present a method for the automatic acquisition of concept hierarchies. Given a set of concepts, each concept is regarded as a vertex in an undirected, weighted graph. The problem of concept hierarchy construction is then transformed into a modified graph partitioning problem and solved by spectral methods. As the undirected graph cannot accurately depict the hyponymy information regarding the concepts, subsumption estimation is introduced to guide the spectral clustering algorithm. Experiments on real data show very encouraging results.	algorithm;cluster analysis;computer science;experiment;graph (discrete mathematics);graph partition;partition problem;spectral clustering;spectral method;subsumption architecture;vertex (graph theory);world wide web	Jing Chen;Qing Li	2006		10.1007/11912873_22	the internet;biological classification;computer science;graph partition;artificial intelligence;graph theory;machine learning;data mining;mathematics;graph;cluster analysis;information system;spectral clustering;algorithm;spectral method	AI	-3.4898047003315007	-32.580880928625675	21588
e82692144e682eedf0582dd70893757203ee1643	a nuclear power plant expert system using artificial neural networks	simulation ordinateur;modelizacion;sistema experto;accident;simulator;modelisation;simulador;parametre critique;parametro critico;simulateur;computer codes;nuclear power plant;centrale nucleaire;accidente;simulacion computadora;systeme expert;reseau neuronal;modeling;computer simulation;red neuronal;central nuclear;critical parameter;code informatique;artificial neural network;neural network;expert system	In this study, ANNs are introduced to act as a bridge between detailed computer codes and compact simulators with an aim to improve the capabilities of compact expert system. The ANNs compensate for the inaccuracies of a compact expert system occurring from simplified governing equations and a reduced number of physical control volumes, and predict the critical parameter usually calculated from the sophisticated computer code. To verify the appli-cability of the proposed methodology, computer simulations are undertaken for loss of flow accidents (LOFA).	artificial neural network;expert system;neural networks	Malrey Lee;Hye-Jin Jeong;Young Joon Choi;Thomas M. Gatton	2006		10.1007/11760023_180	simulation;systems modeling;computer science;artificial intelligence;machine learning;operations research;artificial neural network	Robotics	9.42341411580865	-24.81211478076261	21598
243652c5725acb87c7d01c71bee073e10a53811c	support vector machine parameters optimization by enhanced fireworks algorithm		Support vector machines are widely used as superior classifiers for many different applications. Accuracy of the constructed support vector machine classifier depends on the proper parameter tuning. One of the most common used techniques for parameter determination is grid search. This optimization can be done more precisely and computationally more efficiently by using stochastic search metaheuristics. In this paper we propose using enhanced fireworks algorithm for support vector machine parameter optimization. We tested our approach on standard benchmark datasets from the UCI Machine Learning Repository and compared the results with grid search and with results obtained by other swarm intelligence approaches from the literature. Enhanced fireworks algorithm proved to be very successful, but most importantly it significantly outperformed other algorithms for more realistic cases for which there were separate test sets, rather than doing only cross validation.	fireworks algorithm;support vector machine	Eva Tuba;Milan Tuba;Marko Beko	2016		10.1007/978-3-319-41000-5_52	artificial intelligence;machine learning;support vector machine;computer science;hyperparameter optimization;cross-validation;swarm intelligence;fireworks;metaheuristic;algorithm	ML	10.77512539337706	-42.52389821889998	21675
9d4aae39dac6f2c4c629dfa593cf2ff764760275	voting over multiple condensed nearest neighbors	nonparametric estimation;similarity solution;lazy learning;voting;nearest neighbor;k nearest neighbor;nearest neighbor classifier;condensed nearest neighbor	Lazy learning methods like the k-nearest neighbor classifier require storing the whole training set and may be too costly when this set is large. The condensed nearest neighbor classifier incrementally stores a subset of the sample, thus decreasing storage and computation requirements. We propose to train multiple such subsets and take a vote over them, thus combining predictions from a set of concept descriptions. We investigate two voting schemes: simple voting where voters have equal weight and weighted voting where weights depend on classifiers' confidences in their predictions. We consider ways to form such subsets for improved performance: When the training set is small, voting improves performance considerably. If the training set is not small, then voters converge to similar solutions and we do not gain anything by voting. To alleviate this, when the training set is of intermediate size, we use bootstrapping to generate smaller training sets over which we train the voters. When the training set is large, we partition it into smaller, mutually exclusive subsets and then train the voters. Simulation results on six datasets are reported with good results. We give a review of methods for combining multiple learners. The idea of taking a vote over multiple learners can be applied with any type of learning scheme.	bootstrapping (compilers);computation;converge;k-nearest neighbors algorithm;lazy evaluation;lazy learning;nearest neighbour algorithm;requirement;simulation;test set	Ethem Alpaydin	1997	Artificial Intelligence Review	10.1023/A:1006563312922	computer science;machine learning;pattern recognition;data mining;k-nearest neighbors algorithm	AI	15.274633139545129	-40.01269919973904	21713
3dd97946feb19b17d7aad8a6a91b66d3a8015ce0	a new fuzzy reinforcement learning vector quantization algorithm for image compression	codebook design;topology;pattern clustering vector quantisation image coding fuzzy neural nets learning artificial intelligence;cluster algorithm;frlvq;pattern clustering;gla;learning rate;fuzzy neural nets;image coding;fuzzy k means;data compression;learning;reinforcement learning;distortion measurement;minimization methods;generalised lloyd algorithm;training data;learning vector quantization image coding clustering algorithms distortion measurement knowledge engineering topology data compression training data minimization methods;pair wise competition;vector quantization;image compression;topology knowledge;fkm algorithm;membership function;fuzzy k means clustering algorithm;codevector;learning rate sequences;clustering algorithms;repellent force;training vectors;vector quantizer;learning artificial intelligence;learning rate sequences fuzzy reinforcement learning vector quantization algorithm vq algorithm frlvq image compression fuzzy k means clustering algorithm topology knowledge reinforcement learning codevector pair wise competition training vector repellent force generalised lloyd algorithm training vectors fuzzy k means membership function simulation results gla fkm algorithm codebook design;vector quantisation;simulation results;vq algorithm;fuzzy reinforcement learning vector quantization algorithm;training vector;knowledge engineering	A new unsupervised fuzzy reinforcement learning vector quantization (FRLVQ) algorithm for image compression based on the combination of fuzzy K-means clustering algorithm and topology knowledge is proposed. In each iteration of reinforcement learning (RL), the size and direction of the movement of a codevector is decided by the overall pair-wise competition between the attraction of each training vector and the repellent force of the corresponding winning codevector. While each training vector only affects the winning codevector in the generalised Lloyd algorithm (GLA) strategy, and only the attraction of training vectors are considered in the fuzzy K-means (FKM) strategy. The competition is measured by the membership function. Simulation results are presented to compare the proposed FRLVQ with GLA and FKM algorithms. It is apparent that FRLVQ has the better quality of codebook design, is very insensitive to the selection of the initial codebook, and relatively insensitive to the choice of learning rate sequences.	algorithm;image compression;learning vector quantization;reinforcement learning	Wenhuan Xu;Asoke K. Nandi;Jihong Zhang	2003		10.1109/ICASSP.2003.1199159	data compression;training set;membership function;image compression;computer science;artificial intelligence;machine learning;knowledge engineering;pattern recognition;mathematics;cluster analysis;linde–buzo–gray algorithm;reinforcement learning;vector quantization	ML	13.78894212558232	-32.5313917318117	21795
3de14c000cb84be719235c214a0b94c5cb27b1e7	multi-objective particle swarm optimization approach for cost-based feature selection in classification	biological patents;ieee transactions;biomedical journals;text mining;europe pubmed central;multi objective;citation search;citation networks;multi objective feature selection cost particle swarm optimization;research articles;optimization classification algorithms genetic algorithms bioinformatics particle swarm optimization search problems ieee transactions;abstracts;particle swarm optimization;open access;classification algorithms;life sciences;clinical guidelines;genetic algorithms;feature selection;optimization;search problems;full text;cost;rest apis;orcids;europe pmc;biomedical research;bioinformatics;literature search	Feature selection is an important data-preprocessing technique in classification problems such as bioinformatics and signal processing. Generally, there are some situations where a user is interested in not only maximizing the classification performance but also minimizing the cost that may be associated with features. This kind of problem is called cost-based feature selection. However, most existing feature selection approaches treat this task as a single-objective optimization problem. This paper presents the first study of multi-objective particle swarm optimization PSO for cost-based feature selection problems. The task of this paper is to generate a Pareto front of nondominated solutions, that is, feature subsets, to meet different requirements of decision-makers in real-world applications. In order to enhance the search capability of the proposed algorithm, a probability-based encoding technology and an effective hybrid operator, together with the ideas of the crowding distance, the external archive, and the Pareto domination relationship, are applied to PSO. The proposed PSO-based multi-objective feature selection algorithm is compared with several multi-objective feature selection algorithms on five benchmark datasets. Experimental results show that the proposed algorithm can automatically evolve a set of nondominated solutions, and it is a highly competitive feature selection method for solving cost-based feature selection problems.	archive;benchmark (computing);bioinformatics;choose (action);classification;crowding;dominating set;feasible region;feature selection;genetic selection;mathematical optimization;numerous;optimization problem;pareto efficiency;particle swarm optimization;preprocessor;requirement;selection algorithm;signal processing;solutions	Yong Zhang;Dun-Wei Gong;Jian Cheng	2017	IEEE/ACM Transactions on Computational Biology and Bioinformatics	10.1109/TCBB.2015.2476796	text mining;genetic algorithm;computer science;bioinformatics;data science;machine learning;data mining;particle swarm optimization;feature selection;feature;dimensionality reduction	SE	10.023607645429562	-43.69361587128663	21808
53adb4f7f4003b42dad552896907c3fe2b8c023f	lazy induction of descriptions using two fuzzy versions of the rand index	fuzzy set;distance measure;lazy learning;machine learning;indexation	In this paper we introduce an extension of the lazy learning method called Lazy Induction of Descriptions (LID). This new version is able to deal with fuzzy cases, i.e., cases described by attributes taking continuous values represented as fuzzy sets. LID classifies new cases based on the relevance of the attributes describing them. This relevance is assessed using a distance measure that compares the correct partition (i.e., the correct classification of cases) with the partitions induced by each one of the attributes. The fuzzy version of LID introduced in this paper uses two fuzzy versions of the Rand index to compare fuzzy partitions: one proposed by Campello and another proposed by Hüllermeier and Rifqi. We experimented with both indexes on data sets from the UCI machine learning repository.	algorithmic efficiency;application domain;computation;description logic;experiment;fuzzy logic;fuzzy set;lazy evaluation;lazy learning;machine learning;rand index;relevance;t-norm	Eva Armengol;Àngel García-Cerdaña	2010		10.1007/978-3-642-14055-6_41	defuzzification;type-2 fuzzy sets and systems;fuzzy mathematics;fuzzy classification;computer science;artificial intelligence;fuzzy number;machine learning;data mining;mathematics;fuzzy set;fuzzy set operations;algorithm	AI	0.2445551441638048	-27.146575908905103	21814
58a7b8d98d299d73ada923d928a57f56e09639d8	analysis of the generalization error: empirical risk minimization over deep artificial neural networks overcomes the curse of dimensionality in the numerical approximation of black-scholes partial differential equations		The development of new classification and regression algorithms based on empirical risk minimization (ERM) over deep neural network hypothesis classes, coined Deep Learning, revolutionized the area of artificial intelligence, machine learning, and data analysis. More recently, these methods have been applied to the numerical solution of high dimensional partial differential equations (PDEs) with great success. In particular, recent simulations indicate that deep learning based algorithms are capable of overcoming the curse of dimensionality for the numerical solution of linear Kolmogorov PDEs. Kolmogorov PDEs have been widely used in models from engineering, finance, and the natural sciences. In particular Kolmogorov PDEs are highly employed in models for the approximative pricing of financial derivatives. Nearly all approximation methods for Kolmogorov PDEs in the literature suffer under the curse of dimensionality. By contrast, in recent work by some of the authors it was shown that deep ReLU neural networks are capable of approximating solutions of Kolmogorov PDEs without incurring the curse of dimensionality. The present paper considerably strengthens these results by providing an analysis of the generalization error. In particular we show that for Kolmogorov PDEs with affine drift and diffusion coefficients and a given accuracy ε > 0, ERM over deep neural network hypothesis classes of size scaling polynomially in the dimension d and ε−1 and with a number of training samples scaling polynomially in the dimension d and ε−1 approximates the solution of the Kolmogorov PDE to within accuracy ε with high probability. We conclude that ERM over deep neural network hypothesis classes breaks the curse of dimensionality for the numerical solution of linear Kolmogorov PDEs with affine drift and diffusion coefficients. To the best of our knowledge this is the first rigorous mathematical result that proves the efficiency of deep learning methods for high dimensional problems.	algorithm;approximation;artificial intelligence;artificial neural network;black–scholes model;coefficient;curse of dimensionality;deep learning;empirical risk minimization;generalization error;image scaling;machine learning;numerical analysis;numerical partial differential equations;rectifier (neural networks);simulation;with high probability	Julius Berner;Philipp Grohs;Arnulf Jentzen	2018	CoRR		deep learning;partial differential equation;empirical risk minimization;scaling;mathematical optimization;artificial neural network;affine transformation;curse of dimensionality;black–scholes model;artificial intelligence;mathematics	ML	21.561701094073005	-32.268557369323375	21819
5d143551ec9f9f3197b8826a2b1319c970a42ed1	a distributed svm for image annotation	mapreduce based distributed implementation;training support vector machines classification algorithms training data accuracy algorithm design and analysis program processors;support vector machines;sequential minimal optimization distributed svm image annotation generalization property platt smo support vector machines decomposition technique mapreduce based distributed implementation hadoop multiple core processors distributed smo;distributed processing;training;decomposition technique;image classification;multiple core processors;image annotation;training data;accuracy;machine learning;distributed svm;distributed svm image anotation machine learning smo mapreduce;distributed smo;classification algorithms;smo;sequential minimal optimization;multiprocessing systems;mapreduce;generalisation artificial intelligence;support vector machine;support vector machines distributed processing generalisation artificial intelligence image classification multiprocessing systems;hadoop;program processors;platt smo;algorithm design and analysis;image anotation;generalization property	The popularity of SVMs has grown tremendously in the last few years for many different classification problems due to its generalization properties, however training SVMs require high computational power. Platt's SMO is one the fastest algorithm for training support vector machines, which takes the decomposition technique to the extreme by selecting a set of only two points as the working set then solving them analytically. However SMO becomes slow for large size training data set. In this paper we present a MapReduce based distributed implementation of SMO using Hadoop. The distributed SMO uses multiple core processors to process the training data. By partitioning the training data set into smaller subsets and allocating each of the partitioned subsets to a single Map task, each Map task optimizes the partition in parallel and finally the reducer combine the results. Experiments show the efficiency of the distributed SMO increases with the increase of the number of processors, the training speed of distributed SMO with 12 Map task is about 11times higher than standalone SMO. There is no significant difference in accuracy between distributed and standalone SMO.	algorithm;apache hadoop;automatic image annotation;central processing unit;computation;experiment;fastest;mapreduce;sequential minimal optimization;support vector machine;test set;working set	Nasullah Khalid Alham;Maozhen Li;Suhel Hammoud;Yang Liu;Mahesh Ponraj	2010	2010 Seventh International Conference on Fuzzy Systems and Knowledge Discovery	10.1109/FSKD.2010.5569084	statistical classification;support vector machine;computer science;machine learning;pattern recognition;data mining;automatic image annotation	ML	13.365198876951942	-38.03054208479517	21830
eb31269b9c2f293f4696e22a989faf4a0a08ea92	an adaptiveweighted fuzzy mean filter based on cloud model				Kannan Kanagraj	2016	Int. Arab J. Inf. Technol.		fuzzy logic;machine learning;median filter;artificial intelligence;cloud computing;pattern recognition;computer science	DB	3.5606428109893957	-25.320210540960723	21854
51ea83be2b88590e587462f5025ec9140c93545a	towards property-based classification of clustering paradigms		Clustering is a basic data mining task with a wide variety of applications. Not surprisingly, there exist many clustering algorithms. However, clustering is an ill defined problem given a data set, it is not clear what a “correct” clustering for that set is. Indeed, different algorithms may yield dramatically different outputs for the same input sets. Faced with a concrete clustering task, a user needs to choose an appropriate clustering algorithm. Currently, such decisions are often made in a very ad hoc, if not completely random, manner. Given the crucial effect of the choice of a clustering algorithm on the resulting clustering, this state of affairs is truly regrettable. In this paper we address the major research challenge of developing tools for helping users make more informed decisions when they come to pick a clustering tool for their data. This is, of course, a very ambitious endeavor, and in this paper, we make some first steps towards this goal. We propose to address this problem by distilling abstract properties of the input-output behavior of different clustering paradigms. In this paper, we demonstrate how abstract, intuitive properties of clustering functions can be used to taxonomize a set of popular clustering algorithmic paradigms. On top of addressing deterministic clustering algorithms, we also propose similar properties for randomized algorithms and use them to highlight functional differences between different common implementations of k-means clustering. We also study relationships between the properties, independent of any particular algorithm. In particular, we strengthen Kleinberg’s famous impossibility result, while providing a simpler proof.	cluster analysis;data mining;existential quantification;hoc (programming language);k-means clustering;randomized algorithm	Margareta Ackerman;Shai Ben-David;David Loker	2010			constrained clustering;fuzzy clustering;computer science;theoretical computer science;machine learning;consensus clustering;data mining;mathematics;brown clustering;statistics;conceptual clustering	ML	0.3318017637072613	-38.30586042537863	21888
d7538d48ae4526618b8b8fee6d9d69c41b0d2fa9	design of hierarchical fuzzy model for classification problem using gas	hierarchical fuzzy model;knowledge acquisition;fuzzy if then rules;genetic algorithm;genetic algorithms;classification problem;fuzzy model	This paper proposes a new hierarchical fuzzy model (HFM) to solve the classification problem. The developed classification model comprises of two stages; one is to generate the fuzzy IF-THEN rules for each subsystem and the other is to determine the classification unit. For the classification problem, number of rules and the correct classification rate are the fundamental requirements. In this paper, we also advance two genetic algorithms (GAs) to tune the HFM. One is used to determine the combination of the input features for each subsystem on the HFM and the other is to reduce the number of rules in each fuzzy subsystem. The performance has been tested by simulations on the well known Wine and Iris databases. Simulations demonstrate that the proposed HFM under a few rules can provide sufficiently high classification rate even with higher feature dimensions.		Nai Ren Guo;Tzuu-Hseng S. Li;Chao-Lin Kuo	2006	Computers & Industrial Engineering	10.1016/j.cie.2005.06.007	genetic algorithm;defuzzification;fuzzy classification;computer science;artificial intelligence;fuzzy number;neuro-fuzzy;machine learning;data mining;fuzzy associative matrix;fuzzy set operations	SE	5.1012582277412974	-27.5439921714521	21985
1da28fb47a62eab34d5efb5ee55f46eefcb88a32	inverting feedforward neural networks using linear and nonlinear programming	feedforward neural network;non linear programming;nonlinear programming;multilayer perceptrons;simplex method;multilayer perceptron;indexing terms;iterative methods;inverse problem;mathematical programming;radial basis function neural network;ill posed problem;linear programming;linear program;neural networks feedforward neural networks linear programming inverse problems mathematical programming computer architecture computer networks iterative methods iterative algorithms algorithm design and analysis;generalized inverse;feedforward neural nets;generalisation artificial intelligence;learning artificial intelligence;iterative methods feedforward neural nets multilayer perceptrons learning artificial intelligence generalisation artificial intelligence nonlinear programming linear programming inverse problems;iterative inversion algorithms feedforward neural networks linear programming nonlinear programming inverse problem separable programming multilayer perceptrons radial basis function neural networks generalization learning;inverse problems;neural network	The problem of inverting trained feedforward neural networks is to find the inputs which yield a given output. In general, this problem is an ill-posed problem because the mapping from the output space to the input space is a one-to-many mapping. In this paper, we present a method for dealing with the inverse problem by using mathematical programming techniques. The principal idea behind the method is to formulate the inverse problem as a nonlinear programming (NLP) problem, a separable programming (SP) problem, or a linear programming (LP) problem according to the architectures of networks to be inverted or the types of network inversions to be computed. An important advantage of the method over the existing iterative inversion algorithm is that various designated network inversions of multilayer perceptrons (MLP's) and radial basis function (RBF) neural networks can be obtained by solving the corresponding SP problems, which can be solved by a modified simplex method, a well-developed and efficient method for solving LP problems. We present several examples to demonstrate the proposed method and the applications of network inversions to examining and improving the generalization performance of trained networks. The results show the effectiveness of the proposed method.	architecture as topic;artificial neural network;chromosome inversion;feedforward neural network;generalization (psychology);iterative method;linear programming;mathematical optimization;mathematics;multilayer perceptron;natural language processing;nonlinear programming;nonlinear system;one-to-many (data model);quad flat no-leads package;radial (radio);radial basis function;simplex algorithm;well-posed problem	Bao-Liang Lu;Hajime Kita;Yoshikazu Nishikawa	1999	IEEE transactions on neural networks	10.1109/72.809074	mathematical optimization;nonlinear programming;computer science;inverse problem;linear programming;artificial intelligence;machine learning;mathematics	ML	17.804587792660328	-28.796211542171132	22023
ec5077218e9c64ce2154d9a079c377d2e35962a0	designing adversarially resilient classifiers using resilient feature engineering		We provide a methodology, resilient feature engineering, for creating adversarially resilient classifiers. According to existing work, adversarial attacks identify weakly correlated or non-predictive features learned by the classifier during training and design the adversarial noise to utilize these features. Therefore, highly predictive features should be used first during classification in order to determine the set of possible output labels. Our methodology focuses the problem of designing resilient classifiers into a problem of designing resilient feature extractors for these highly predictive features. We provide two theorems, which support our methodology. The Serial Composition Resilience and Parallel Composition Resilience theorems show that the output of adversarially resilient feature extractors can be combined to create an equally resilient classifier. Based on our theoretical results, we outline the design of an adversarially resilient classifier.		Kevin Eykholt;Atul Prakash	2018	CoRR			ML	18.955530973530575	-51.16275894421315	22024
773cf90c95ef76099b3c11fd61af011c9c6fa5ca	feature genes selection using fisher transformation method				Huiyu Mu;Jiucheng Xu;Yun Wang;Lin Yan Sun	2018	Journal of Intelligent and Fuzzy Systems	10.3233/JIFS-17710	mathematics;machine learning;fisher transformation;gene;artificial intelligence	Robotics	7.584828009235141	-46.122573864568395	22050
3380848ed1a398d5204984f899f82c9c672ca152	reconstruction of the matrix of causal dependencies for the fuzzy inductive reasoning method	chaotic time series;dynamic system;fuzzy inductive reasoning;exhaustive search	Fuzzy Inductive Reasoning (FIR) methodology is a very powerful tool for creating a mixed qualitative-quantitative model of any dynamical system by using its input and output signals. One of the key issue of this methodology is the creation of the  mask , i.e. a matrix that contains the causal dependencies among the signals of the systems for particular time steps. This paper describes the ARMS --- Automatic Reconstruction of the Mask Scheme --- methodology that gives the opportunity of creating a sub-optimal mask with very good performances without an exhaustive search in the space of all the possibilities. This methodology has been validated on a wide class of dynamical system (from LTI systems to chaotic time series) and it has been compared to other methods proposed in literature.	causal filter;inductive reasoning;the matrix	Guido Sangiovanni;Michèle Lavagna	2007		10.1007/978-3-540-73400-0_7	computer science;artificial intelligence;dynamical system;machine learning;brute-force search;algorithm	AI	6.4537277900795385	-25.69926811839327	22076
2b3ceb40dced78a824cf67054959e250aeaa573b	differentially private subspace clustering		Subspace clustering is an unsupervised learning problem that aims at grouping data points into multiple “clusters” so that data points in a single cluster lie approximately on a low-dimensional linear subspace. It is originally motivated by 3D motion segmentation in computer vision, but has recently been generically applied to a wide range of statistical machine learning problems, which often involves sensitive datasets about human subjects. This raises a dire concern for data privacy. In this work, we build on the framework of differential privacy and present two provably private subspace clustering algorithms. We demonstrate via both theory and experiments that one of the presented methods enjoys formal privacy and utility guarantees; the other one asymptotically preserves differential privacy while having good performance in practice. Along the course of the proof, we also obtain two new provable guarantees for the agnostic subspace clustering and the graph connectivity problem which might be of independent interests.	algorithm;cluster analysis;clustering high-dimensional data;computer vision;connectivity (graph theory);data point;differential privacy;experiment;information privacy;machine learning;provable security;unsupervised learning	Yining Wang;Yu-Xiang Wang;Aarti Singh	2015			theoretical computer science;machine learning;data mining;mathematics;cluster analysis;statistics	ML	21.57723435400485	-34.338928410071944	22078
be6d63cb01c35598b44382890b1d9f4bc91958eb	externally growing cell structures for data evaluation of chemical gas sensors	growing cell structure;mixture;learning;melange;supervised learning;toluene;structure cellulaire;cafe;fonction base radiale;propanol;captador quimico;gas sensor;dynamical system;aprendizaje;systeme dynamique;chemical sensor;cell structure;apprentissage;coffee;radial basis function;gcs;capteur chimique;autoorganizacion;self organization;som;apprentissage supervise;sistema dinamico;reseau neuronal;estructura celular;tolueno;red neuronal;autoorganisation;self organising map;mezcla;neural network	Based on Fritzke’s GCS (Growing Cell Structures), we present here a new incremental self-organising neural network, the Externally Growing Cell Structures (EGCS). Our goals are to speed up the convergence and to improve the generalisation performance. The mechanism of internally growing cells in EGCS is the same as in GCS. However, when the Maximum Resource Vertex (MRV) or the Maximum Error Vertex (MEV) is a boundary node, the new cell is grown externally. Simulation results on neural network benchmarks, two-spiral problem and sonar mine/rock separation, indicate that EGCS performs better than the original GCS, measured by classification rate and the required number of epochs. As a new classification and regression method, the EGCS for Data Evaluation of Chemical Gas Sensors is introduced.	algorithm;artificial neural network;benchmark (computing);gnu compiler collection;michael j. fischer;sonar (symantec);self-organization;sensor;simulation;speedup;towed array sonar	Guojian Cheng;Andreas Zell	2001	Neural Computing & Applications	10.1007/s005210170021	radial basis function;self-organization;simulation;computer science;artificial intelligence;mélange;glasgow coma scale;dynamical system;machine learning;supervised learning;mixture;artificial neural network	ML	12.04770260273591	-30.18367249219672	22101
60a321fdb2f79b768709a322151533b570a5acda	dio: efficient interactive outlier analysis over dynamic datasets		Outlier detection is an important data mining topic, and distance-based outlier detection is one of the representative methods. However, it is known that selecting parameter values suited for detecting outliers matching the user intent is not easy. To address this problem, an interactive outlier analysis framework named ONION was proposed. ONION analyzes datasets in advance and constructs index structures, which support several types of interactive outlier analysis and help users choose appropriate parameter values. However, ONION assumes static datasets, and updates to the datasets are not considered. In this work, we propose a novel scheme named DIO (Dynamic and Interactive Outlier analysis) to make ONION-like interactive outlier analysis applicable to dynamic datasets. DIO provides a grid structure for data objects and neighboring object counters to avoid expensive distance recomputations and enables efficient updates of the index structures. Intensive experiments prove that DIO achieves remarkable performance improvements.	algorithm;anomaly detection;data mining;experiment;sensor	Chihiro Sakazume;Hiroyuki Kitagawa;Toshiyuki Amagasa	2017	2017 Twelfth International Conference on Digital Information Management (ICDIM)	10.1109/ICDIM.2017.8244652	anomaly detection;information management;computer science;user intent;data mining;grid;outlier	DB	-3.3612012232783584	-38.80923820321044	22204
5170d07ef871ba183aeda9abfec310f5fd4bb99a	feature similarity based redundancy reduction for gene selection.	high dimensionality;gene expression data;ranking algorithm;classification accuracy;gene expression data analysis;gene selection;similarity measure	this paper we propose a feature similarity based redundancy reduction (FSRR) algorithm for high-dimensional gene expression data analysis. FSRR has two steps. First, the relevance of each feature is evaluated. Second, based on the relevance, the redundant features are removed by feature similarity. The efficiency and effectiveness of our algorithm is established through an experimental study using gene expression data. Four state-of-art feature ranking algorithms and three feature similarity measures are compared and discussed in our work. The results indicate that our algorithm has the capability of finding a well-suited feature set and improving the classification accuracy.	algorithm;experiment;feature model;feature selection;relevance;unsupervised learning	Xuezheng Fu;Feng Tan;Hao Wang;Yanqing Zhang;Robert W. Harrison	2006			minimum redundancy feature selection;bioinformatics;pattern recognition;data mining	ML	11.501882434277485	-45.02324130993687	22286
83f78d702a228451f14e2051558243b3f095be6f	an adaptive hybrid model for monthly streamflow forecasting	takagi sugeno model;online algorithm;filtering;optimisation;learning algorithm;recursive learning algorithm;optimization technique;economic forecasting;water resources;time series;takagi sugeno fuzzy systems;systems engineering and theory;model complexity;hybrid model;hybrid power systems;optimization technique adaptive hybrid model monthly streamflow forecasting takagi sugeno fuzzy systems time series prediction expectation maximization algorithm recursive learning algorithm;adaptive learning;expectation maximization algorithm;robustness;predictive models;monthly streamflow forecasting;predictive models power generation economics economic forecasting hybrid power systems takagi sugeno model fuzzy systems filtering robustness systems engineering and theory optimization methods;learning artificial intelligence;adaptive hybrid model;water resources expectation maximisation algorithm fuzzy systems learning artificial intelligence optimisation time series;fuzzy systems;fuzzy system;time series prediction;power generation economics;optimization methods;time series model;expectation maximisation algorithm	This paper suggests a new algorithm for generating Takagi-Sugeno fuzzy systems applied for time series prediction. The model proposed comprises two phases. First, the model structure is initialized in a constructive offline fashion, via an expectation maximization algorithm (EM). In the second phase the system is modified dynamically, via adding and pruning operators. At this stage, we propose a recursive learning algorithm, which is based on the EM optimization technique. This online algorithm determines automatically the number of rules necessary at each step. In this way, the model structure and parameters are updated during the adaptive training. The adaptive learning process reduces model complexity and defines automatically its structure providing an efficient model. The proposed approach is applied to build a time series model for monthly streamflow forecasting. The performance of the approach is compared with conventional models used to forecast streamflows. Results show similar errors, however, the suggested model presents a simpler and more parsimonious structure.	expectation–maximization algorithm;fuzzy control system;mathematical optimization;occam's razor;online algorithm;online and offline;recursion;time series	Ivette Luna;Secundino Soares;Rosangela Ballini	2007	2007 IEEE International Fuzzy Systems Conference	10.1109/FUZZY.2007.4295539	mathematical optimization;computer science;artificial intelligence;machine learning;time series;fuzzy control system;statistics	DB	6.968156301072411	-26.020159438578577	22287
308101e4442b9d2d14b42131ab230f497ed9d7c5	identifying simple discriminatory gene vectors with an information theory approach	gene expression profile;cancer;statistical analysis cancer genetics medical computing vectors;low complexity;genetics;medical computing;gene expression;information theory gene expression mutual information predictive models genetic communication cancer entropy statistics phase noise equations;statistical analysis;vectors;mutual information;feature selection;cancer classification;correlation coefficient;gene expression pattern;information theory;lower complexity models feature selection cancer classification signal to noise statistic coefficient correlation coefficient class distinction gene expression occam razor mutual information gene vectors	In the feature selection of cancer classification problems, many existing methods consider genes individually by choosing the top genes which have the most significant signal-to-noise statistic or correlation coefficient. However the information of the class distinction provided by such genes may overlap intensively, since their gene expression patterns are similar The redundancy of including many genes with similar gene expression patterns results in highly complex classifiers. According to the principle of Occam's razor, simple models are preferable to complex ones, if they can produce comparable prediction performances to the complex ones. In this paper, we introduce a new method to learn accurate and low-complexity classifiers from gene expression profiles. In our method, we use mutual information to measure the relation between a set of genes, called gene vectors, and the class attribute of the samples. The gene vectors are in higher-dimensional spaces than individual genes, therefore, they are more diverse, or contain more information than individual genes. Hence, gene vectors are more preferable to individual genes in describing the class distinctions between samples since they contain more information about the class attribute. We validate our method on 3 gene expression profiles. By comparing our results with those from literature and other well-known classification methods, our method demonstrated better or comparable prediction performances to the existing methods, however, with lower-complexity models than existing methods.	choose (action);coefficient;feature selection;gene expression;gene co-expression network;html attribute;information theory;mutual information;neoplasms;occam's razor;performance;signal-to-noise ratio;occam	Zheng Yun;Kwoh Chee Keong	2005	2005 IEEE Computational Systems Bioinformatics Conference (CSB'05)	10.1109/CSB.2005.35	biology;gene expression;information theory;bioinformatics;machine learning;pattern recognition;mathematics;mutual information;feature selection;genetics;statistics;cancer	Comp.	8.001227733050262	-48.40352900991669	22321
9a72bf55da970f7f39f5cc424aacf6dbb2a6ec95	locally adaptive metric nearest-neighbor classification	probability;query location adaptivity locally adaptive metric nearest neighbor classification class conditional probabilities locally adaptive nearest neighbor classification method bias minimization chi squared distance analysis;curse of dimensionality;classification;feature relevance;local adaptation;chi squared distance;nearest neighbors;nearest neighbor;pattern classification probability;pattern classification;probability pattern classification;high dimension;conditional probability;nearest neighbor classification	Nearest neighbor classiication assumes locally constant class conditional probabilities. This assumption becomes invalid in high dimensions with nite samples due to the curse of dimensionality. Severe bias can be introduced under these conditions when using the nearest neighbor rule. We propose a locally adaptive nearest neighbor classiication method to try to minimize bias. We use a Chi-squared distance analysis to compute a exible metric for producing neighborhoods that are highly adaptive to query locations. Neighborhoods are elongated along less relevant feature dimensions and constricted along most innuential ones. As a result, the class conditional probabilities tend to be smoother in the mod-iied neighborhoods, whereby better classiication performance can be achieved. The eecacy of our method is validated and compared against other techniques using a variety of simulated and real world data.	chi;curse of dimensionality;feature vector;information;k-nearest neighbors algorithm;nearest neighbor search;relevance;simulation;synapomorphy	Carlotta Domeniconi;Jing Peng;Dimitrios Gunopulos	2002	IEEE Trans. Pattern Anal. Mach. Intell.	10.1109/TPAMI.2002.1033219	curse of dimensionality;conditional probability;biological classification;computer science;machine learning;pattern recognition;probability;mathematics;nearest neighbor search;k-nearest neighbors algorithm;statistics	Vision	15.466896211509221	-38.84480585431455	22348
79a24e4da57febc78c7727bb81e81bc63996a2c0	preprocessing compensation techniques for improved classification of imbalanced medical datasets		The paper describes the study on the problem of applying classification techniques in medical datasets with a class imbalance. The aim of the research is to identify factors that negatively affect classification results and propose actions that may be taken to improve the performance. To alleviate the impact of uneven and complex class distribution, methods of balancing the datasets are proposed and compared. The experiments were conducted on five datasets — three binary and two multiclass. They comprise several data preprocessing methods applied on data and the classification with different techniques. The study shows that for some datasets there exists a combination of a certain preprocessing method and a classification technique which outperforms other approaches. For datasets with complex distribution or too many features the ratio of correctly predicted labels may be low regardless what resampling method and classification technique has been applied.	aggregate data;algorithm;artificial intelligence;artificial neural network;benchmark (computing);bitwise operation;data pre-processing;experiment;failover;feature selection;machine learning;motion compensation;oversampling;preprocessor;principal component analysis;resampling (statistics);sparse matrix;statistical classification	Agnieszka Wosiak;Sylwia Karbowiak	2017	2017 Federated Conference on Computer Science and Information Systems (FedCSIS)	10.15439/2017F82	resampling;support vector machine;computer science;data mining;machine learning;algorithm design;preprocessor;data pre-processing;decision tree;binary number;artificial intelligence;pattern recognition	AI	13.718369380786964	-42.51220744151613	22356
7604e4cb49e3d432a7e9d9f0ead12344528fa9f9	the use of neural networks in sensor failure detection and signal reconstruction	failure detection;signal reconstruction;neural network			Geoff Waterworth	2002			artificial neural network;computer vision;signal reconstruction;artificial intelligence;computer science	ML	12.21287707195731	-26.790985113119977	22404
4a54ca2e667e20a9412f357f7d900016e48c609f	fuzzy inputs and missing data in similarity-based heterogeneous neural networks	eficacia sistema;systeme intelligent;fuzzy neural nets;dato que falta;hybrid network;continuous variable;sistema inteligente;performance systeme;similarity relation;reseau neuronal flou;system performance;donnee manquante;intelligent system;missing data;neural network model;heterogeneous network;neural network	Fuzzy heterogeneous networks are recently introduced feed-forward neural network models composed of neurons of a general class whose inputs and weights are mixtures of continuous variables (crisp and/or fuzzy) with discrete quantities, also admitting missing data. These networks have net input functions based on similarity relations between the inputs to and the weights of a neuron. They thus accept heterogeneous {possibly missing{ inputs, and can be coupled with classical neurons in hybrid network architectures, trained by means of genetic algorithms or other evolutionary methods. This report compares the eeectiveness of the fuzzy heterogeneous model based on similarity with that of the classical feed-forward one, in the context of an investigation in the eld of environmental sciences, namely, the geochemical study of natural waters in the Arctic (Spitzbergen). Classiication accuracy, the eeect of working with crisp or fuzzy inputs, the use of traditional scalar product vs. similarity based functions, and the presence of missing data, are studied. The results obtained show that, from these standpoints, fuzzy heterogeneous networks based on similarity perform better than classical feed-forward models. This behaviour is consistent with previous results in other application domains.	application domain;artificial neural network;evolutionary algorithm;feedforward neural network;genetic algorithm;missing data;neural network software;neuron	Lluís A. Belanche Muñoz;Julio J. Valdés	1999		10.1007/BFb0100554	heterogeneous network;missing data;fuzzy classification;computer science;artificial intelligence;neuro-fuzzy;machine learning;data mining;mathematics;fuzzy set operations;artificial neural network	ML	5.071076253250613	-27.457233238848826	22405
913271f9951303427b76cdbf4ab91e8687e1b5c5	refhap: a reliable and fast algorithm for single individual haplotyping	maximum cut;heuristic;efficiency;haplotyping;heuristic method;association study;objective function;fragments;human genome;fast algorithm;algorithms;variants;heuristic algorithm	Full human genomic sequences have been published in the latest two years for a growing number of individuals. Most of them are a mixed consensus of the two real haplotypes because it is still very expensive to separate information coming from the two copies of a chromosome. However, latest improvements and new experimental approaches promise to solve these issues and provide enough information to reconstruct the sequences for the two copies of each chromosome through bioinformatics methods such as single individual haplotyping. Full haploid sequences provide a complete understanding of the structure of the human genome, allowing accurate predictions of translation in protein coding regions and increasing power of association studies.  In this paper we present a novel problem formulation for single individual haplotyping. We start by assigning a score to each pair of fragments based on their common allele calls and then we use these score to formulate the problem as the cut of fragments that maximize an objective function, similar to the well known max-cut problem. Our algorithm initially finds the best cut based on a heuristic algorithm for max-cut and then builds haplotypes consistent with that cut. We have compared both accuracy and running time of ReFHap with other heuristic methods on both simulated and real data and found that ReFHap performs significantly faster than previous methods without loss of accuracy.	algorithm;bioinformatics;heuristic (computer science);loss function;maximum cut;optimization problem;simulation;time complexity;whole earth 'lectronic link	Jorge Duitama;Thomas Huebsch;Gayle McEwen;Eun-Kyung Suk;Margret R. Hoehe	2010		10.1145/1854776.1854802	heuristic;biology;maximum cut;human genome;heuristic;haplotype;computer science;bioinformatics;machine learning;mathematics;efficiency;genetics;algorithm	Comp.	1.2359434726094825	-51.66562062584165	22436
2af10476a9ac84ec5276efc255e7a7186939f407	mcfptree: a fp-tree-based algorithm for multi-constrained patterns discovery	databases;itemsets;news;frequent pattern;confiance;routing;structure arborescente;probability density function;metodo arborescente;fp tree;routage;software systems;association rules;communication system software;trees mathematics;item constraint;data mining;vigilancia economica;trees mathematics data mining;pattern discovery;fp tree based algorithm;confidence;transaction databases;confianza;fouille donnee;estructura arborescente;tree structure;decouverte connaissance;multi constraint pattern mining;aggregation constraint;software algorithms;competitive intelligence;noticias;descubrimiento conocimiento;economic intelligence;tree structured method;multiconstrained patterns discovery;terminology;apriori like algorithm mcfptree fp tree based algorithm multiconstrained patterns discovery item constraint aggregation constraint cardinality constraint;methode arborescente;computer science;mcfptree;cardinality constraint;actualites;veille economique;busca dato;data mining association rules itemsets competitive intelligence communication system software software systems software algorithms computer science terminology algorithm design and analysis;algorithm design and analysis;apriori like algorithm;knowledge discovery;enrutamiento	In this paper, the problem of constraint-based pattern discovery is investigated. By allowing more user-specified constraints other than traditional rule measurements, e.g., minimum support and confidence, research work on this topic endeavor to reflect real interest of analysts and relief them from the overabundance of rules. Surprisingly very little research has been conducted to deal with multiple types of constraints. In our previous work, we have studied this problem, specifically focusing on three different types of constraints, including item constraint, aggregation constraint, and cardinality constraint. And an efficient Apriori-like algorithm, called MCFP, is proposed. In this paper, we propose a new algorithm called MCFPTree, which is based on the FP-tree structure and thus does not suffer from the problem of candidate itemsets generation. Experimental results show that our MCFPTree algorithm is significantly faster than MCFP and an intuitive method FP-Growth+, i.e., post processing the frequent patterns generated by FP-Growth, against user-specified constraints.	apriori algorithm;association rule learning;cardinality (data modeling);constraint logic programming;constraint programming;data mining;han unification;real life;tree structure;video post-processing	Wen-Yang Lin;Ko-Wei Huang	2009	2009 International Conference on Complex, Intelligent and Software Intensive Systems	10.1109/CISIS.2009.83	computer science;machine learning;data mining;constraint;algorithm	DB	-3.970945982114075	-33.246417041673084	22492
1f771522b77ae58e60df3a04cbe9b334633b7b80	optimal vaccination schedules using simulated annealing	optimal solution;vacunacion;personal computer;bioinformatique;simulated annealing;vaccination;high performance computer;system biology;genetic algorithm;bioinformatica;optimal algorithm;bioinformatics	SUMMARY Since few years the problem of finding optimal solutions for drug or vaccine protocols have been tackled using system biology modeling. These approaches are usually computationally expensive. Our previous experiences in optimizing vaccine or drug protocols using genetic algorithms required the use of a high performance computing infrastructure for a couple of days. In the present article we show that by an appropriate use of a different optimization algorithm, the simulated annealing, we have been able to downsize the computational effort by a factor 10(2). The new algorithm requires computational effort that can be achieved by current generation personal computers.   AVAILABILITY Software and additional data can be found at http://www.immunomics.eu/SA/	analysis of algorithms;computation (action);experience;gallium;genetic algorithm;gymnophrys cometa;mathematical optimization;personal computers;personal computer;protocols documentation;requirement;schedule (document type);scientific publication;simulated annealing;software release life cycle;solutions;supercomputer;systems biology	Marzio Pennisi;Roberto Catanuto;Francesco Pappalardo;Santo Motta	2008	Bioinformatics	10.1093/bioinformatics/btn260	mathematical optimization;simulation;genetic algorithm;simulated annealing;computer science;bioinformatics;theoretical computer science;vaccination;systems biology	Comp.	2.1347059287230405	-47.100032562520354	22500
071ec4f3fb4bfe6ae9980477d208a7b12691710e	learning multimodal latent attributes	zero shot learning attribute learning latent attribute space multitask learning transfer learning;sensitivity and specificity;object recognition;zero shot learning;videos semantics ontologies data models feature extraction media noise;photography;journal article;multimedia computing;social networking online learning artificial intelligence multimedia computing object recognition;attribute learning;image interpretation computer assisted;n shot transfer learning learning multimodal latent attributes social media sharing automatic media classification annotation techniques semantic gap data sparsity object recognition multimedia data multimodal content unified framework multimedia sparse data learning multitask learning;social networking online;video recording;reproducibility of results;transfer learning;artificial intelligence;algorithms;pattern recognition automated;learning artificial intelligence;latent attribute space;information storage and retrieval;multitask learning;documentation	The rapid development of social media sharing has created a huge demand for automatic media classification and annotation techniques. Attribute learning has emerged as a promising paradigm for bridging the semantic gap and addressing data sparsity via transferring attribute knowledge in object recognition and relatively simple action classification. In this paper, we address the task of attribute learning for understanding multimedia data with sparse and incomplete labels. In particular, we focus on videos of social group activities, which are particularly challenging and topical examples of this task because of their multimodal content and complex and unstructured nature relative to the density of annotations. To solve this problem, we 1) introduce a concept of semilatent attribute space, expressing user-defined and latent attributes in a unified framework, and 2) propose a novel scalable probabilistic topic model for learning multimodal semilatent attributes, which dramatically reduces requirements for an exhaustive accurate attribute ontology and expensive annotation effort. We show that our framework is able to exploit latent attributes to outperform contemporary approaches for addressing a variety of realistic multimedia sparse data learning tasks including: multitask learning, learning with label noise, N-shot transfer learning, and importantly zero-shot learning.	annotation;arabic numeral 0;automatic media;bridging (networking);computer multitasking;learning disorders;multimedia;multimodal interaction;outline of object recognition;partial;programming paradigm;requirement;scalability;social media;sparse matrix;statistical classification;topic model;unified framework	Yanwei Fu;Timothy M. Hospedales;Tao Xiang;Shaogang Gong	2014	IEEE Transactions on Pattern Analysis and Machine Intelligence	10.1109/TPAMI.2013.128	semi-supervised learning;computer vision;documentation;computer science;artificial intelligence;photography;machine learning;pattern recognition;data mining	Vision	24.173208896557714	-45.395168039954214	22601
6e2bd0d417f37f768f763f584868f5652ad4bd7e	performance comparison of item-to-item skills models with the irt single latent trait model	tan;learner model;learner models;performance comparison;irt;bayesian models;bayesian model	Assessing a learner's mastery of a set of skills is a fundamental issue in intelligent learning environments. We compare the predictive performance of two approaches for training a learner model with domain data. One is based on the principle of building the model solely from observable data items, such as exercises or test items. Skills modelling is not part of the training phase, but instead dealt with at later stage. The other approach incorporates a single latent skill in the model. We compare the capacity of both approaches to accurately predict item outcome (binary success or failure) from a subset of item outcomes. Three types of item-to-item models based on standard Bayesian modeling algorithms are tested: (1) Naive Bayes, (2) Tree-Augmented Naive Bayes (TAN), and (3) a K2 Bayesian Classifier. Their performance is compared to the widely used IRT-2PL approach which incorporates a single latent skill. The results show that the item-to-item approaches perform as well, or better than the IRT-2PL approach over 4 widely different data sets, but the differences vary considerably among the data sets. We discuss the implications of these results and the issues relating to the practical use of item-to-item models.	algorithm;bayesian network;item response theory;latent variable model;learner-generated context;naive bayes classifier;observable	Michel C. Desmarais	2011		10.1007/978-3-642-22362-4_7	econometrics;computer science;artificial intelligence;machine learning	ML	24.561498972985564	-25.107262822340328	22608
d0713f3d192f6dda90a15cdbc871c0bc55c44146	sorting signed circular permutations by super short reversals	super short reversals;circular permutation	We consider the problem of sorting a circular permutation by reversals of length at most 2, a problem that finds application in comparative genomics. Polynomial-time solutions for the unsigned version of this problem are known, but the signed version remained open. In this paper, we present the first polynomial-time solution for the signed version of this problem. Moreover, we perform an experiment for inferring distances and phylogenies for published Yersinia genomes and compare the results with the phylogenies presented in previous works.	sorting;super smash bros.	Gustavo Rodrigues Galvão;Christian Baudet;Zanoni Dias	2015		10.1007/978-3-319-19048-8_23	arithmetic;biology;combinatorics;circular permutation in proteins;computer science;bioinformatics;mathematics;algorithm	Vision	-0.2647499959235209	-51.51161670174046	22671
356456b5d8797d6f9a8a8a1d4ac00534ab8bf069	on tolerant fuzzy c-means clustering with l1-regularization	optimal solution;fuzzy c mean;optimal method;karush kuhn tucker;optimization problem;fuzzy c means clustering	We have proposed tolerant fuzzy c-means clustering (TFCM) from the viewpoint of handling data more flexibly. This paper presents a new type of tolerant fuzzy c-means clustering with L1-regularization. L1-regularization is wellknown as the most successful techniques to induce sparseness. The proposed algorithm is different from the viewpoint of the sparseness for tolerance vector. In the original concept of tolerance, a tolerance vector attributes to each data. This paper develops the concept to handle data flexibly, that is, a tolerance vector attributes not only to each data but also each cluster. First, the new concept of tolerance is introduced into optimization problems. These optimization problems are based on conventional fuzzy c-means clustering (FCM). Second, the optimization problems with tolerance are solved by using Karush-Kuhn-Tucker conditions and an optimization method for L1-regularization. Third, new clustering algorithms are constructed based on the explicit optimal solutions. Finally, the effectiveness of the proposed algorithm is verified through some numerical examples. Keywords— fuzzy c-means clustering, L1-regularization, optimization, tolerance, uncertainty	algorithm;cluster analysis;fuzzy cognitive map;karush–kuhn–tucker conditions;mathematical optimization;missing data;neural coding;numerical analysis;optimization problem;tucker decomposition	Yukihiro Hamasuna;Yasunori Endo;Sadaaki Miyamoto	2009			mathematical optimization;fuzzy clustering;machine learning;mathematics;algorithm	ML	3.7123566600126425	-39.45368406645274	22739
7ff00c3c910b441c4a20b7a759f23ff3da57f495	time-series classification based on individualised error prediction	nearest neighbor searches;discrete time warping;data set;individualized error prediction;training;discrete time;regression model;time series;set theory;data mining;classification;time series data mining error analysis learning artificial intelligence pattern classification regression analysis set theory;error estimation time series classification;training data;error analysis;accuracy;k nn classifier;time series analysis predictive models training accuracy nearest neighbor searches data models training data;machine learning;time series analysis;regression model machine learning k nn classifier discrete time warping time series classification data set individualized error prediction;error estimation;pattern classification;classification error;time series data;predictive models;regression analysis;experimental evaluation;time series classification;learning artificial intelligence;data models	Time-series classification is an active research topic in machine learning, as it finds applications in numerous domains. The k-NN classifier, based on the discrete time warping (DTW) distance, had been shown to be competitive to many state-of-the art time-series classification methods. Nevertheless, due to the complexity of time-series data sets, our investigation demonstrates that a single, global choice for k (>= 1) can become sub optimal, because each individual region of a data set may require a different k value. In this paper, we proposed a novel individualized error prediction (IEP) mechanism that considers a range of k-NN classifiers (for different k values) and uses secondary regression models that predict the error of each such classifier. This permits to perform k-NN time-series classification in a more fine grained fashion that adapts to the varying characteristics among different regions by avoiding the restriction of a single value of k. Our experimental evaluation, using a large collection of real time-series data, indicates that the proposed method is more robust and compares favorably against two examined baselines by resulting in significant reduction in the classification error.	baseline (configuration management);k-nearest neighbors algorithm;machine learning;overhead (computing);run time (program lifecycle phase);time series	Krisztian Buza;Alexandros Nanopoulos;Lars Schmidt-Thieme	2010	2010 13th IEEE International Conference on Computational Science and Engineering	10.1109/CSE.2010.16	computer science;machine learning;linear classifier;time series;pattern recognition;data mining;bayes error rate;statistics	ML	14.902702294480362	-39.09502104047119	22822
46765372a899af94e411726029c5c958fdf0c96c	swami: a framework for collaborative filtering algorithm development and evaluation	image database searching;search behavior;collaborative filtering;graphical representation;support vector machine;searching for images;image retrieval	We present a Java-based framework, SWAMI (Shared Wisdom through the Amalgamation of Many Interpretations) for building and studying collaborative filtering systems. SWAMI consists of three components: a prediction engine, an evaluation system, and a visualization component. The prediction engine provides a common interface for implementing different prediction algorithms. The evaluation system provides a standardized testing methodology and metrics for analyzing the accuracy and run-time performance of prediction algorithms. The visualization component suggests how graphical representations can inform the development and analysis of prediction algorithms. We demonstrate SWAMI on the Each Movie data set by comparing three prediction algorithms: a traditional Pearson correlation-based method, support vector machines, and a new accurate and scalable correlation-based method based on clustering techniques.	algorithm;cluster analysis;collaborative filtering;graphical user interface;java;scalability;support vector machine	Danyel Fisher;Kirsten Hildrum;Jason I. Hong;Mark W. Newman;Megan Thomas;Richard W. Vuduc	2000		10.1145/345508.345658	support vector machine;image retrieval;computer science;data science;theoretical computer science;collaborative filtering;machine learning;data mining;world wide web;information retrieval	Visualization	10.992313135754538	-49.31223840904037	22846
d3c1ef7f3d403dca28d84e9fd893d49e2aa145d0	support vector machines and the multiple hypothesis test problem	test hypothese;optimisation;metodo vectorial;multiuser detection;cdma support vector machines multiple hypothesis test problem multicategory classification binary classification svm m ary svm representation octaphase shift keying pattern space 8 psk equality constraints classification boundary two user multiuser detection pattern space;optimizacion;test hipotesis;signal detection;indexing terms;learning automata;classification;multiuser channels;phase shift keying;code division multiple access;vector method;pattern classification;pattern recognition;multiple hypothesis testing;methode vectorielle;optimization;binary classification;support vector machines testing support vector machine classification pattern recognition multiuser detection cost function parametric statistics mathematical programming reflective binary codes decision feedback equalizers;reconnaissance forme;support vector machine;reconocimiento patron;code division multiple access learning automata multiuser channels signal detection phase shift keying pattern classification;clasificacion;hypothesis test	Two enhancements are proposed to the application and theory of support vector machines. The first is a method of multicategory classification based on the binary classification version of the support vector machine (SVM). The method, which is called the M-ary SVM, represents each category in binary format, and to each bit of that representation is assigned a conventional SVM. This approach requires only [log/sub 2/(K)] SVMs, where K is the number of classes. We give an example of classification on an octaphase-shift-keying (8-PSK) pattern space to illustrate the main concepts. The second enhancement is that of adding equality constraints to the conventional binary classification SVM. This allows pinning the classification boundary to points that are known a priori to lie on the boundary. Applications of this method often arise in problems having some type of symmetry, We present one such example where the M-ary SVM is used to classify symbols of a CDMA two-user, multiuser detection pattern space.	support vector machine	Daniel J. Sebald;James A. Bucklew	2001	IEEE Trans. Signal Processing	10.1109/78.960434	binary classification;support vector machine;code division multiple access;statistical hypothesis testing;index term;biological classification;computer science;phase-shift keying;theoretical computer science;machine learning;pattern recognition;mathematics;multiple comparisons problem;structured support vector machine;statistics;detection theory	EDA	22.958568496174465	-38.722831921221456	22858
b7cbde3d629d22f3d158bf7b5fd213d097960738	digital multiplierless realization of a calcium-based plasticity model	field programmable gate array fpga calcium based plasticity model spike timing dependent plasticity stdp;biological system modeling calcium mathematical model biological information theory biological neural networks brain modeling	Calcium is a highly widespread and versatile intracellular ion that can control a wide range of temporal dynamics in the brain such as synaptic plasticity. This brief presents a novel and efficient digital circuit for implementing a calcium-based plasticity model aimed at reproducing relevant biological dynamics. Accordingly, we investigate the feasibility of the proposed model in a minimal neural network stressing on the effect of calcium oscillations on synaptic plasticity with various neuronal stimulation protocols. MATLAB simulations and physical implementations on field-programmable gate array confirm that the proposed model, with considerably low hardware overhead, can fairly mimic the relevant biological dynamics.	artificial neural network;clock rate;critical path method;digital electronics;field-programmability;field-programmable gate array;matlab;neuron;overhead (computing);real-time transcription;simulation;synapse;synaptic package manager;triplet state	Ehsan Jokar;Hamid Soleimani	2017	IEEE Transactions on Circuits and Systems II: Express Briefs	10.1109/TCSII.2016.2621823	synaptic plasticity;artificial neural network;gate array;plasticity;digital electronics;calcium;electronic engineering;computer science	EDA	17.35338178470434	-24.97960801490981	22874
235aaf3937fd8644ddc31774192d7d567a342ddf	research on internet information mining based on agent algorithm		Abstract With the rapid development of information technology, especially network technology, people’s ability to collect, store and transmit data are increasing. The data have exploded in an explosive manner. In sharp contrast, the ability to make valuable data for decision making is very poor. In this paper, data mining is the most basic problem. In order to overcome the shortcomings of the traditional clustering algorithm for k-means clustering, it is difficult to determine the initial clustering center and the k-means algorithm is improved. When determining the initial K-, the convergence factor is improved and the global optimum is achieved, so as to realize the determination of clustering center. By using improved k-means algorithm to approximate the criminal data, the validity of this method is verified.	algorithm;data mining	Shaofei Wu;Mingqing Wang;Yuntao Zou	2018	Future Generation Comp. Syst.	10.1016/j.future.2018.04.040	the internet;cluster analysis;computer science;algorithm;information technology;global optimum;convergence (routing)	DB	4.3125392826417634	-38.61363850969498	22877
0fbf373d25f2710e2e4eaf64e00e071f734ad84f	mapping and revising markov logic networks for transfer learning	transfer learning	Transfer learning addresses the problem of how to leverage knowledge acquired in a source domain to improve the accuracy and speed of learning in a related target domain. This paper considers transfer learning with Markov logic networks (MLNs), a powerful formalism for learning in relational domains. We present a complete MLN transfer system that first autonomously maps the predicates in the source MLN to the target domain and then revises the mapped structure to further improve its accuracy. Our results in several real-world domains demonstrate that our approach successfully reduces the amount of time and training data needed to learn an accurate model of a target domain over learning from scratch.	brute-force search;experiment;ibm notes;map;markov chain;markov logic network;semantics (computer science);tamar schlick	Lilyana Mihalkova;Tuyen N. Huynh;Raymond J. Mooney	2007			semi-supervised learning;multi-task learning;simulation;transfer of learning;computer science;artificial intelligence;machine learning;inductive transfer	AI	17.083580505597467	-34.80814383394891	23027
8b4558ab9d0339955ec628d2e7073469375a61d0	on the need for a neural abstract machine	abstract machine;sequence learning;domain knowledge;adaptive learning rate;problem complexity;neural network model;training algorithm;neural network	The complexity of learning tasks and their variety, as well as the number of different neural networks models for sequence learning is quite high. Moreover, in addition to architectural details and training algorithms peculiarities, there are other relevant factors which add complexity to the management of a neural network for the adaptive processing of sequences. For example, training heuristics, such as adaptive learning rates, regularization, and pruning, are very important, as well as insertion of a priori domain knowledge. All these issues must be considered and matched with the complexity of the application domain at hand. This means that the successful application of a neural network to a real world domain has to answer to several questions on the type of architecture, training algorithms, training heuristics, and knowledge insertion, according to the problem complexity.	abstract machine;abstract state machines;algorithm;artificial neural network;bayesian network;expert system;fuzzy control system;heuristic (computer science);hoc (programming language);matrix regularization;model of computation;network architecture;neural network software;numerical analysis;principle of abstraction;programming language;programming tool;recurrent neural network;semantics (computer science)	Diego Sona;Alessandro Sperduti	2001		10.1007/3-540-44565-X_7	unsupervised learning;stochastic neural network;nervous system network models;feedforward neural network;cellular neural network;probabilistic neural network;types of artificial neural networks;wake-sleep algorithm;computer science;artificial intelligence;recurrent neural network;online machine learning;machine learning;pattern recognition;time delay neural network;deep learning;learning classifier system;stability;competitive learning;computational learning theory;active learning;artificial neural network	NLP	13.68902814442996	-29.153120014831718	23032
532832014bfcb1c9f75bc195c6539fcc30560de1	a general soft method for learning svm classifiers with l1-norm penalty	libre mercado;approximation l2;evaluation performance;performance evaluation;soft convex hulls;capsula convexa;learning;support vector machines;evaluacion prestacion;schlesinger kozinec s algorithms;simulacion numerica;maquina vector soporte;aproximacion l2;general techniques;classification;v svms;mitchell dem yanov malozemov s algorithms;marche concurrentiel;enveloppe convexe;algorithme;aprendizaje;algorithm;machine vecteur support;apprentissage;nearest points;ν;gilbert s algorithms;theoretical analysis;simulation numerique;signal classification;l2 approximation;classification signal;nu svms;geometric algorithm;support vector machine;open market;classification automatique;convex hull;automatic classification;clasificacion automatica;ν svms;numerical simulation;algoritmo	Based on the geometric interpretation of support vector machines (SVMs), this paper presents a general technique that allows almost all the existing L2-norm penalty based geometric algorithms, including Gilbert’s algorithm, Schlesinger–Kozinec’s (SK) algorithm and Mitchell–Dem’yanov–Malozemov’s (MDM) algorithm, to be softened to achieve the corresponding learning L1-SVM classifiers. Intrinsically, the resulting soft algorithms are to find -optimal nearest points between two soft convex hulls. Theoretical analysis has indicated that our proposed soft algorithms are essentially generalizations of the corresponding existing hard algorithms, and consequently, they have the same properties of convergence and almost the identical cost of computation. As a specific example, the problem of solving -SVMs by the proposed soft MDM algorithm is investigated and the corresponding solution procedure is specified and analyzed. To validate the general soft technique, several real classification experiments are conducted with the proposed L1-norm based MDM algorithms and numerical results have demonstrated that their performance is competitive to that of the corresponding L2-norm based algorithms, such as SK and MDM algorithms. 2007 Pattern Recognition Society. Published by Elsevier Ltd. All rights reserved.		Qing Tao;Gao-wei Wu;Jue Wang	2008	Pattern Recognition	10.1016/j.patcog.2007.08.004	computer simulation;support vector machine;computer science;artificial intelligence;machine learning;pattern recognition;mathematics;algorithm	AI	23.15084165577603	-38.87340209762171	23091
c9848196bef086e8df22089cbb4c6fb2eb939f26	application of direction basis function neural network to adaptive identification and control	learning vector quantization;real time control;neural network;least square	In this paper, adaptive identification and control of nonlinear dynamical systems are investigated using Two Synaptic Weight Neural Networks (TSWNN). Firstly, a novel approach to train the TWSWNN is introduced, which employs an Adaptive Fuzzy Generalized Learning Vector Quantization (AFGLVQ) technique and recursive least squares algorithm with variable forgetting factor (VRLS). The AFGLVQ adjusts the kernels of the TSWNN while the VRLS updates the connection weights of the network. The identification algorithm has the properties of rapid convergence and persistent adaptability that make it suitable for real-time control. Secondly, on the basis of the one-step ahead TSWNN predictor, the control law is optimized iteratively through a numerical Stable Davidon's Least Squares-based (SDLS) minimization approach. A nonlinear example is simulated to demonstrate the effectiveness of the identification and control algorithms.	artificial neural network;basis function	Mahdi Jalili	2004		10.1007/978-3-540-24677-0_2	adaptive control;computer science;artificial intelligence;machine learning;control theory;mathematics;least squares;artificial neural network;algorithm	ML	15.4423590099142	-28.604740941350325	23108
4bdef16e02c6b723d3e6d39a2a51cbcf9dbc2a05	evolutionary model building under streaming data for classification tasks: opportunities and challenges	streaming data;diversity;ensemble learning;imbalanced data;active learning;dynamic environment;non stationary processes;task decomposition;evolvability;memory	Streaming data analysis potentially represents a significant shift in emphasis from schemes historically pursued for offline (batch) approaches to the classification task. In particular, a streaming data application implies that: (1) the data itself has no formal ‘start’ or ‘end’; (2) the properties of the process generating the data are non-stationary, thus models that function correctly for some part(s) of a stream may be ineffective elsewhere; (3) constraints on the time to produce a response, potentially implying an anytime operational requirement; and (4) given the prohibitive cost of employing an oracle to label a stream, a finite labelling budget is necessary. The scope of this article is to provide a survey of developments for model building under streaming environments from the perspective of both evolutionary and non-evolutionary frameworks. In doing so, we bring attention to the challenges and opportunities that developing solutions to streaming data classification tasks are likely to face using evolutionary approaches.	active learning (machine learning);algorithm design;anytime algorithm;closed-world assumption;concept drift;coupling (computer programming);desktop computer;discriminant;double-precision floating-point format;dummy variable (statistics);ensemble learning;evolutionary algorithm;evolutionary computation;feature vector;feedback;genetic algorithm;greedy algorithm;heuristic (computer science);hyper-heuristic;linear model;naive bayes classifier;nonlinear gameplay;nonlinear system;novelty detection;online and offline;preprocessor;real-time clock;real-time computing;refinement (computing);semi-supervised learning;semiconductor industry;sensor;sigmoid function;stationary process;stream (computing);streaming algorithm;streaming media;supervised learning;symbolic regression;system identification;trust (emotion)	Malcolm I. Heywood	2014	Genetic Programming and Evolvable Machines	10.1007/s10710-014-9236-y	real-time computing;computer science;artificial intelligence;machine learning;data mining;active learning;ensemble learning;memory;genetics;evolvability	AI	14.504482146125989	-37.410582816407896	23144
d2647c3f571d2c9d8f71c27d830f897733401553	inverse reinforcement learning for video games		Deep reinforcement learning achieves superhuman performance in a range of video game environments, but requires that a designer manually specify a reward function. It is often easier to provide demonstrations of a target behavior than to design a reward function describing that behavior. Inverse reinforcement learning (IRL) algorithms can infer a reward from demonstrations in low-dimensional continuous control environments, but there has been little work on applying IRL to high-dimensional video games. In our CNN-AIRL baseline, we modify the state-of-the-art adversarial IRL (AIRL) algorithm to use CNNs for the generator and discriminator. To stabilize training, we normalize the reward and increase the size of the discriminator training dataset. We additionally learn a low-dimensional state representation using a novel autoencoder architecture tuned for video game environments. This embedding is used as input to the reward network, improving the sample efficiency of expert demonstrations. Our method achieves high-level performance on the simple Catcher video game, substantially outperforming the CNN-AIRL baseline. We also score points on the Enduro Atari racing game, but do not match expert performance, highlighting the need for further work.	algorithm;atari;autoencoder;baseline (configuration management);discriminator;high- and low-level;reinforcement learning	Aaron Tucker;Adam Gleave;Stuart Russell	2018	CoRR		autoencoder;machine learning;architecture;inverse;reinforcement learning;discriminator;mathematics;artificial intelligence	AI	19.264785166706073	-49.840540872347816	23197
da4170c862d8ae39861aa193667bfdbdf0ecb363	multi-task cnn model for attribute prediction	latent tasks matrix;training;matrix decomposition visualization training semantics predictive models;semantics;under sampled classifiers multitask cnn model joint multitask learning algorithm deep convolutional neural networks learning binary semantic attributes attribute specific feature representations latent task matrix combination matrix;joints;journal article;semantic attributes deep cnn latent tasks matrix multi task learning;visualization;matrix decomposition;multi task learning;predictive models;clothing;semantic attributes;deep cnn;neural nets image classification learning artificial intelligence matrix algebra	This paper proposes a joint multi-task learning algorithm to better predict attributes in images using deep convolutional neural networks (CNN). We consider learning binary semantic attributes through a multi-task CNN model, where each CNN will predict one binary attribute. The multi-task learning allows CNN models to simultaneously share visual knowledge among different attribute categories. Each CNN will generate attribute-specific feature representations, and then we apply multi-task learning on the features to predict their attributes. In our multi-task framework, we propose a method to decompose the overall model's parameters into a latent task matrix and combination matrix. Furthermore, under-sampled classifiers can leverage shared statistics from other classifiers to improve their performance. Natural grouping of attributes is applied such that attributes in the same group are encouraged to share more knowledge. Meanwhile, attributes in different groups will generally compete with each other, and consequently share less knowledge. We show the effectiveness of our method on two popular attribute datasets.	algorithm;artificial neural network;benchmark (computing);computer multitasking;convolutional neural network;encode;experiment;information;latent dirichlet allocation;multi-task learning	Abrar H. Abdulnabi;Gang Wang;Jiwen Lu;Kui Jia	2015	IEEE Transactions on Multimedia	10.1109/TMM.2015.2477680	multi-task learning;computer vision;visualization;computer science;artificial intelligence;clothing;machine learning;pattern recognition;semantics;predictive modelling;matrix decomposition	Vision	24.52416280738918	-46.08042784686255	23225
b33d4017cf999ca90a02b7095a88838e0353b7c3	quantum-inspired multidirectional associative memory for human-robot interaction system	associative memory neurons robots quantum mechanics matrix decomposition noise mathematical model;t technology;quantum computing fuzzy reasoning human robot interaction;multimodal sensory inputs quantum inspired multidirectional associative memory human robot interaction system quantum inspired computational intelligence quantum postulates quantum mechanics robot application mutual communication	Quantum-Inspired Computational Intelligence based on quantum postulates is an emerging research area that exploit the parallelism of quantum mechanics. However, existing research efforts are limited to theoretical simulations and has not been implemented in robot application. With regards as Human-Robot Interaction, associative memory become essential for mutual communication. However, associative memory always suffers from limited memory capacity and high sensitivity to noise and the ability to recall from multi-modal sensory inputs. In this paper, we propose a Quantum-Inspired Multidirectional Associative Memory. This is the first attempt to overcome these two problems effectively with robot application.	computational intelligence;computational linguistics;content-addressable memory;fuzzy logic;human–robot interaction;mathematical formulation of quantum mechanics;modal logic;parallel computing;quantum mechanics;regular expression;robot;simulation	Naoki Masuyama;Chu Kiong Loo	2014	2014 IEEE International Conference on Fuzzy Systems (FUZZ-IEEE)	10.1109/FUZZ-IEEE.2014.6891858	artificial intelligence;machine learning;mathematics	Robotics	9.32586690797545	-27.14175377222335	23231
d131639c2d9df9b80623e1ea757214bae62b1707	refined spectral clustering via embedded label propagation		Spectral clustering is a key research topic in the field of machine learning and data mining. Most of the existing spectral clustering algorithms are built on gaussian Laplacian matrices, which is sensitive to parameters. We propose a novel parameter-free distance-consistent locally linear embedding. The proposed distance-consistent LLE can promise that edges between closer data points are heavier. We also propose a novel improved spectral clustering via embedded label propagation. Our algorithm is built on two advancements of the state of the art. First is label propagation, which propagates a node's labels to neighboring nodes according to their proximity. We perform standard spectral clustering on original data and assign each cluster with -nearest data points and then we propagate labels through dense unlabeled data regions. Second is manifold learning, which has been widely used for its capacity to leverage the manifold structure of data points. Extensive experiments on various data sets validate the superiority of the proposed algorithm compared to state-of-the-art spectral algorithms.	anatomic node;approximation algorithm;arc diagram;cluster analysis;data mining;data point;embedding;experiment;machine learning;nonlinear dimensionality reduction;normal statistical distribution;population parameter;software propagation;spectral clustering;manifold;statistical cluster	Yan-shuo Chang;Feiping Nie;Zhihui Li;Xiaojun Chang;Heng Huang	2017	Neural Computation	10.1162/neco_a_01022	data stream clustering;mathematics;correlation clustering;machine learning;consensus clustering;cluster analysis;k-medians clustering;cure data clustering algorithm;canopy clustering algorithm;artificial intelligence;affinity propagation;pattern recognition	ML	1.132644446142781	-41.95608671012752	23271
5f1f2748867ef3f119d5318d34745a9ebb9d2087	multiclass alternating decision trees	decision tree;document profiling;intelligence artificielle;aprendizaje probabilidades;arbol decision;classification;conference contribution;text classification;apprentissage probabilites;artificial intelligence;inteligencia artificial;computer science;empirical evaluation;arbre decision;clasificacion;probability learning	The alternating decision tree (ADTree) is a successful classification technique that combines decision trees with the predictive accuracy of boosting into a set of interpretable classification rules. The original formulation of the tree induction algorithm restricted attention to binary classification problems. This paper empirically evaluates several wrapper methods for extending the algorithm to the multiclass case by splitting the problem into several two-class problems. Seeking a more natural solution we then adapt the multiclass LogitBoost and AdaBoost.MH procedures to induce alternating decision trees directly. Experimental results confirm that these procedures are comparable with wrapper methods that are based on the original ADTree formulation in accuracy, while inducing much smaller trees.	adaboost;algorithm;alternating decision tree;binary classification;logitboost;modified huffman coding	Geoff Holmes;Bernhard Pfahringer;Richard Kirkby;Eibe Frank;Mark A. Hall	2002		10.1007/3-540-36755-1_14	biological classification;computer science;artificial intelligence;machine learning;decision tree;multiclass classification;alternating decision tree;data mining;algorithm	ML	8.547078488447749	-32.45334164399173	23297
4270bd84ac93a0090f2fe888d27db6a6eece29c1	the use of stratified sampling to improve the performance of classification trees			decision tree;sampling (signal processing);stratified sampling	Abdul Aziz Gill	2004				Vision	9.44891217887947	-36.66927200649646	23298
2902755a6462d78c1629d0b24ae14e0244f450df	competitive quantization for approximate nearest neighbor search	gradient descent approach competitive quantization compq hierarchical algorithm approximate nearest neighbor search ann search vector quantization algorithm joint competitive learning strategy quantization error minimization codebooks optimization;nearest neighbor searches;electronic mail;vector quantization approximate nearest neighbor search binary codes large scale retrieval;hamming distance;vector quantization;optimization;vector quantisation data handling gradient methods minimisation search problems unsupervised learning;encoding;vector quantization encoding optimization hamming distance electronic mail nearest neighbor searches	In this study, we propose a novel vector quantization algorithm for Approximate Nearest Neighbor (ANN) search, based on a joint competitive learning strategy and hence called as competitive quantization (CompQ). CompQ is a hierarchical algorithm, which iteratively minimizes the quantization error by jointly optimizing the codebooks in each layer, using a gradient decent approach. An extensive set of experimental results and comparative evaluations show that CompQ outperforms the-state-of-the-art while retaining a comparable computational complexity.	algorithm;codebook;competitive learning;computation;computational complexity theory;definition;gradient;line code;mathematical optimization;nearest neighbor search;quantization (signal processing);vector quantization	Ezgi C. Ozan;Serkan Kiranyaz;Moncef Gabbouj	2016	IEEE Transactions on Knowledge and Data Engineering	10.1109/TKDE.2016.2597834	nearest-neighbor chain algorithm;large margin nearest neighbor;hamming distance;best bin first;learning vector quantization;quantization;computer science;theoretical computer science;machine learning;pattern recognition;mathematics;nearest neighbor search;linde–buzo–gray algorithm;vector quantization;encoding	Vision	23.272358417526878	-36.95437263571969	23312
5d64ba938fc61485c9376b0ea471ae8b1ac14326	stochastic competitive learning in complex networks	unsupervised learning;community detection;pattern clustering;complex networks;stochastic process;legged locomotion;neural nets;preferential walk;complex network;competitive learning;data clustering;large scale;vectors;machine learning;stochastic processes;computational complexity;random walk;indexation;number of clusters;unsupervised learning computational complexity neural nets pattern clustering;mathematical model;stochastic competitive learning;stochastic competitive learning community detection complex networks data clustering preferential walk random walk;communities;communities stochastic processes complex networks legged locomotion machine learning vectors mathematical model;evaluator index stochastic competitive learning complex networks machine learning approach artificial neural networks large scale networks particle walking rule random movements preferential movements community detection data clustering problems computational complexity;article;computer simulation;artificial neural network	Competitive learning is an important machine learning approach which is widely employed in artificial neural networks. In this paper, we present a rigorous definition of a new type of competitive learning scheme realized on large-scale networks. The model consists of several particles walking within the network and competing with each other to occupy as many nodes as possible, while attempting to reject intruder particles. The particle's walking rule is composed of a stochastic combination of random and preferential movements. The model has been applied to solve community detection and data clustering problems. Computer simulations reveal that the proposed technique presents high precision of community and cluster detections, as well as low computational complexity. Moreover, we have developed an efficient method for estimating the most likely number of clusters by using an evaluator index that monitors the information generated by the competition process itself. We hope this paper will provide an alternative way to the study of competitive learning..	artificial neural network;cdisc sdtm evaluator terminology;cluster analysis;competitive learning;complex network;computation;computational complexity theory;dominating set;estimated;generalization (psychology);inspiration function;interaction;interpreter (computing);machine learning;movement;new type;nonlinear system;population parameter;robustness (computer science);sensor;simulation preorder;social system;stochastic process;subatomic particle;vertex;statistical cluster	Thiago C. Silva;Liang Zhao	2012	IEEE Transactions on Neural Networks and Learning Systems	10.1109/TNNLS.2011.2181866	stochastic process;computer science;artificial intelligence;online machine learning;machine learning;pattern recognition;competitive learning;artificial neural network;complex network	ML	3.308612614808601	-42.7625708693931	23322
ff46ace8958565814ffa67e36499cbcf7d55d247	hierarchical classification of web pages using support vector machine	web documents;web pages;imbalanced data;hierarchical classification;svm;web page;support vector machine	In this paper, a novel method for web page hierarchical classification is addressed. In our approach, SVM is used as the basic algorithm to separate any two sub-categories under the same parent node. In order to alleviate the ill shift of SVM classifier caused by imbalanced training data, we try to combine the original SVM classifier with BEV algorithm to create classifier called VOTEM. Then, a web document is assigned to a sub-category based on voting from all category-tocategory classifiers. This hierarchical classification algorithm starts its work from the top of the hierarchical tree downward recursively until it triggers a stop condition or reaches the leaf nodes. And our experiment reveals that proposed algorithm obtains better results.	algorithm;binary classification;category theory;hierarchical clustering;recursion;support vector machine;tree (data structure);web page	Yi Wang;Zhiguo Gong	2008		10.1007/978-3-540-89533-6_2	support vector machine;web query classification;computer science;machine learning;pattern recognition;web page;data mining;world wide web;structured support vector machine	ML	12.960336927989113	-39.86691382923817	23324
dd91b336683eb9012eb57765c48874a3356fde5b	distributed nearest neighbor classification for large-scale multi-label data on spark		Abstract Modern data is characterized by its ever-increasing volume and complexity, particularly when data instances belong to many categories simultaneously. This learning paradigm is known as multi-label classification and one of its most renowned methods is the multi-label k nearest neighbor ( Ml-knn ). The traditional implementations of this method are not feasible for large-scale multi-label data due to its complexity and memory restrictions. We propose a distributed Ml-knn implementation based on the MapReduce programming model, implemented on Apache Spark. We compare three strategies for distributed nearest neighbor search: 1) iteratively broadcasting instances, 2) using a distributed tree-based index structure, and 3) building hash tables to group instances. The experimental study evaluates the trade-off between the quality of the predictions and runtimes on 22 benchmark datasets, and compares the scalability using different sizes of data. The results indicate that the tree-based index strategy outperforms the other approaches, having a speedup of up to 266x for the largest dataset, while achieving an accuracy equivalent to the exact methods. This strategy enables Ml-knn to scale efficiently with respect to the size of the problem.	multi-label classification	Jorge Gonzalez-Lopez;Sebastián Ventura;Alberto Cano	2018	Future Generation Comp. Syst.	10.1016/j.future.2018.04.094	hash table;implementation;spark (mathematics);scalability;speedup;programming paradigm;computer science;distributed computing;k-nearest neighbors algorithm;nearest neighbor search	DB	-4.267696878432305	-39.92475581232043	23334
5e01d5c69882589607f34bc4b994a618444613a4	sgd and hogwild! convergence without the bounded gradients assumption		Stochastic gradient descent (SGD) is the optimization algorithm of choice in many machine learning applications such as regularized empirical risk minimization and training deep neural networks. The classical convergence analysis of SGD is carried out under the assumption that the norm of the stochastic gradient is uniformly bounded. While this might hold for some loss functions, it is always violated for cases where the objective function is strongly convex. In (Bottou et al., 2016), a new analysis of convergence of SGD is performed under the assumption that stochastic gradients are bounded with respect to the true gradient norm. Here we show that for stochastic problems arising in machine learning such bound always holds; and we also propose an alternative convergence analysis of SGD with diminishing learning rate regime, which results in more relaxed conditions than those in (Bottou et al., 2016). We then move on the asynchronous parallel setting, and prove convergence of Hogwild! algorithm in the same regime, obtaining the first convergence results for this method in the case of diminished learning rate. Department of Industrial and Systems Engineering, Lehigh University, USA. IBM Thomas J. Watson Research Center, USA. Department of Electrical and Computer Engineering, University of Connecticut, USA. KAUST, KSA — Edinburgh, UK — MIPT, Russia. Correspondence to: Lam M. Nguyen <LamNguyen.MLTD@gmail.com>, Phuong Ha Nguyen <phuongha.ntu@gmail.com>, Marten van Dijk <marten.van dijk@uconn.edu>, Peter Richtárik <Peter.Richtarik@ed.ac.uk>, Katya Scheinberg <katyas@lehigh.edu>, Martin Takáč <Takac.MT@gmail.com>. Proceedings of the 35 th International Conference on Machine Learning, Stockholm, Sweden, PMLR 80, 2018. Copyright 2018 by the author(s).	algorithm;artificial neural network;computer engineering;deep learning;empirical risk minimization;ibm notes;international conference on machine learning;lam/mpi;loss function;mathematical optimization;microsoft customer care framework;rate of convergence;recursion;scott continuity;stochastic gradient descent;systems engineering;thomas j. watson research center	Lam M. Nguyen;Phuong Ha Nguyen;Marten van Dijk;Peter Richtárik;Katya Scheinberg;Martin Takác	2018			artificial neural network;mathematical optimization;mathematics;uniform boundedness;empirical risk minimization;convex function;bounded function;stochastic gradient descent;convergence (routing)	ML	22.092166236861978	-32.58313215905401	23336
1ca2945c75d7352eb25482c2d415333875143562	an optimal procedure for gap closing in whole genome shotgun sequencing	whole genome shotgun;theoretical framework;dna fragmentation;multiplex pcr;streptococcus pneumoniae;lower bound	Tettelin et. al. proposed a new method for closing the gaps in whole genome shotgun sequencing projects. The method uses a multiplex PCR strategy in order to minimize the time and effort required to sequence the DNA in the missing gaps. This procedure has been used in a number of microbial sequencing projects including Streptococcus pneumoniae and other bacteria. In this paper we describe a theoretical framework for this problem and propose an improved method that guarantees to minimize the number of steps involved in the gap closure procedures. In given particular collection of n/2 DNA fragments we describe a strategy that requires. 0.75 log n work in eight parallel rounds of experiment closely matching a corresponding lower bound 0.5 log of n	closing (morphology);multiplexing	Richard Beigel;Noga Alon;Simon Kasif;Mehmet Serkan Apaydin;Lance Fortnow	2001		10.1145/369133.369152	multiplex polymerase chain reaction;biology;dna fragmentation;molecular biology;bioinformatics;upper and lower bounds;genetics;shotgun sequencing	Comp.	-0.6796098282117919	-51.281038896393696	23360
5818f97e9bf453e0331bad3ffe1b72832d186449	finding global optima in nonconvex stochastic semidefinite optimization with variance reduction		There is a recent surge of interest in nonconvex reformulations via low-rank factorization for stochastic convex semidefinite optimization problem in the purpose of efficiency and scalability. Compared with the original convex formulations, the nonconvex ones typically involve much fewer variables, allowing them to scale to scenarios with millions of variables. However, it opens a new challenge that under what conditions the nonconvex stochastic algorithms may find the global optima effectively despite their empirical success in applications. In this paper, we provide an answer that a stochastic gradient descent method with variance reduction, can be adapted to solve the nonconvex reformulation of the original convex problem, with a global linear convergence, i.e., converging to a global optimum exponentially fast, at a proper initial choice in the restricted strongly convex case. Experimental studies on both simulation and real-world applications on ordinal embedding are provided to show the effectiveness of the proposed algorithms.	approximation error;borwein's algorithm;converge;convex function;convex optimization;fast fourier transform;flat rate;global optimization;low-rank approximation;mathematical optimization;optimization problem;ordinal data;provable security;rate of convergence;scalability;simulation;stochastic gradient descent;variance reduction	Jinshan Zeng;Ke Ma;Yuan Yao	2018			discrete mathematics;rate of convergence;mathematical optimization;ordinal number;mathematics;variance reduction;factorization;stochastic gradient descent;convex function;convex optimization;optimization problem	ML	24.167324574995313	-33.6447711724474	23380
a7a41d23b405d9d0d66bfec5d65de71c467184e9	semi-supervised agglomerative hierarchical clustering algorithms with pairwise constraints	centroid method;kernel couplings clustering algorithms numerical models data analysis merging euclidean distance;pattern clustering;kernel;transitive closure algorithm;ward method semisupervised agglomerative hierarchical clustering algorithm pairwise constraint transitive closure algorithm centroid method;euclidean distance;data analysis;agglomerative hierarchical clustering;statistical analysis;merging;clustering algorithms;semisupervised agglomerative hierarchical clustering algorithm;transitive closure;couplings;ward method;numerical models;learning artificial intelligence;statistical analysis learning artificial intelligence pattern clustering;pairwise constraint;semi supervised clustering	Recently semi-supervised clustering has been studied by many researchers, but there are no extensive studies using different types of algorithms. In this paper we consider ag-glomerative hierarchical algorithms with pairwise constraints. The constraints are directly introduced to the single linkage which is equivalent to the transitive closure algorithm, while the centroid method and the Ward methods need kernelization of the algorithms. Simple numerical examples are shown to see how the constraints work.	algorithm;cluster analysis;constrained clustering;essence;hierarchical clustering;kernel (operating system);kernelization;linkage (software);numerical analysis;semi-supervised learning;semiconductor industry;single-linkage clustering;transitive closure	Sadaaki Miyamoto;Akihisa Terami	2010	International Conference on Fuzzy Systems	10.1109/FUZZY.2010.5584625	constrained clustering;kernel;computer science;machine learning;pattern recognition;data mining;euclidean distance;mathematics;ward's method;cluster analysis;coupling;single-linkage clustering;data analysis;transitive closure;statistics	DB	2.9557804239243404	-39.80730547854871	23527
4505ec3d4488d2bd1856b7223f1921d750acfd79	fuzzy support vector machines for biomedical data analysis	support vector machines;fuzzy support vector machine;fuzzy system fuzzy support vector machines biomedical data analysis;data analysis;support vector machines bioinformatics data analysis support vector machine classification kernel training data fuzzy systems testing machine learning computer science;optimal hyperplane support vector machines svms fuzzy system kernels;medical information systems;support vector machine;learning artificial intelligence;fuzzy systems;fuzzy system;fuzzy systems medical information systems support vector machines learning artificial intelligence	The generalization ability of SVMs is unreliable when the user selects SVMs randomly to classify data examples. The paper proposes a fuzzy system called fuzzy support vector machines (FSVMs) to deal with the problem. Margin values from three different SVMs are fuzzified, combining with the accuracy information of each SVM. The final decision is determined based on all of the SVMs. Experimental results show that the proposed fuzzy SVMs are more stable and reliable than randomly selected SVMs.	atm adaptation layer;data point;emoticon;execution unit;fuzzy control system;fuzzy logic;randomness;stand up to cancer;support vector machine;test-driven development	Xiujuan Chen;Robert W. Harrison;Yanqing Zhang	2005	2005 IEEE International Conference on Granular Computing	10.1109/GRC.2005.1547251	margin classifier;support vector machine;least squares support vector machine;fuzzy classification;computer science;neuro-fuzzy;machine learning;pattern recognition;data mining;relevance vector machine;fuzzy set operations;fuzzy control system	Robotics	8.437900705179633	-40.37667740164668	23548
6d6beb1e2e0e3c9505d20735a25eefa141f85492	application of conceptual learning techniques to generalized group technology	extraction information;group technology;learning;analisis datos;information extraction;production system;conceptual analysis;systeme production;technologie groupe;intelligence artificielle;productique;analisis conceptual;sistema produccion;algorithme;aprendizaje;algorithm;data analysis;apprentissage;robotica;artificial intelligence;analyse donnee;inteligencia artificial;tecnologia grupo;analyse conceptuelle;computer integrated manufacturing;algoritmo;extraction informacion	Abstract In this article, we first point out the advantages and limitations of the keywords filtering techniques and the standard automatic clustering techniques for group technology applications. We consider, then, a product, or more generally an item, as a conjunction of symbolic attributes. We present a new method to recognize homogeneous families of products and to interpret the families by extraction of their concepts. Finally, the method is applied to analyze a population of 1010 mechanical parts.		B. Mutel;Leila Bouzid;R. De Guio	1992	Applied Artificial Intelligence	10.1080/08839519208949966	computer science;artificial intelligence;computer-integrated manufacturing;production system;data analysis;operations research;information extraction	AI	-2.8488898934932396	-31.76373219749973	23599
fdab5ebab3c76bfdc64d057afbcb6bd4e4e8ea9d	a robust correlation analysis framework for imbalanced and dichotomous data with uncertainty		Abstract Correlation analysis is one of the fundamental mathematical tools for identifying dependence between classes. However, the accuracy of the analysis could be jeopardized due to variance error in the data set. This paper provides a mathematical analysis of the impact of imbalanced data concerning Pearson Product Moment Correlation (PPMC) analysis. To alleviate this issue, the novel framework Robust Correlation Analysis Framework (RCAF) is proposed to improve the correlation analysis accuracy. A review of the issues due to imbalanced data and data uncertainty in machine learning is given. The proposed framework is tested with in-depth analysis of real-life solar irradiance and weather condition data from Johannesburg, South Africa. Additionally, comparisons of correlation analysis with prominent sampling techniques, i.e., Synthetic Minority Over-Sampling Technique (SMOTE) and Adaptive Synthetic (ADASYN) sampling techniques are conducted. Finally, K-Means and Wards Agglomerative hierarchical clustering are performed to study the correlation results. Compared to the traditional PPMC, RCAF can reduce the standard deviation of the correlation coefficient under imbalanced data in the range of 32.5%–93.02%.		Chun Sing Lai;Yingshan Tao;Fangyuan Xu;Daniel S. Yeung;Youwei Jia;Haoliang Yuan;Chao Huang;Loi Lei Lai;Zhao Xu;Giorgio Locatelli	2019	Inf. Sci.	10.1016/j.ins.2018.08.017	statistics;solar irradiance;artificial intelligence;machine learning;pearson product-moment correlation coefficient;standard deviation;correlation coefficient;mathematics;sampling (statistics);hierarchical clustering;correlation	AI	6.883279074670407	-41.80941120652188	23663
fafa343ce6485abacbc6c16f534dfa5eb28fb62b	multilayered echo-state machine: a novel architecture for efficient intrusion detection		Computers and other smart gadgets have become of a paramount importance in today’s transactions. Connected to the Internet, those devices offer the possibility to benefit from a myriad of electronic services, including social networking, banking, trade marketing, education and so on. Such activities are producing huge volume of information transiting with high velocity each day. Parallel to that, we have witnessed an epidemic increase in the number and the sophistication of cyberattacks, as they became more persistent and highly structured. In this context, modern intrusion detection systems are to be modeled so as to issue high detection rates in a tiny period of time in order to mitigate the risks. This paper is built on recurrent neural network with multilayered echo-state machine (ML-ESM) to model an intrusion detection. We assess our model on three publicly available data sets, namely, the DARPA KDD’99, NSL-KDD a reformed version of the latter, and UNSW NB 15. Performance metrics for both binary classification and multilabel classification are calculated and compared with those of some existing machine learning techniques and the recent state-of-the-art intrusion detection systems. Results indicate that the ML-ESM wins the challenge in both achieving a higher accuracy and considerably optimizing the processing time.		Taha Ait Tchakoucht;Mostafa Ezziyyani	2018	IEEE Access	10.1109/ACCESS.2018.2867345	support vector machine;the internet;architecture;feature extraction;computer science;finite-state machine;intrusion detection system;distributed computing;recurrent neural network	Security	4.831971908144519	-36.26317849662775	23664
3ac6cf665ed9b77785e2cd32f28df3fc792f366e	distributional multivariate policy evaluation and exploration with the bellman gan		The recently proposed distributional approach to reinforcement learning (DiRL) is centered on learning the distribution of the reward-to-go, often referred to as the value distribution. In this work, we show that the distributional Bellman equation, which drives DiRL methods, is equivalent to a generative adversarial network (GAN) model. In this formulation, DiRL can be seen as learning a deep generative model of the value distribution, driven by the discrepancy between the distribution of the current value, and the distribution of the sum of current reward and next value. We use this insight to propose a GAN-based approach to DiRL, which leverages the strengths of GANs in learning distributions of high-dimensional data. In particular, we show that our GAN approach can be used for DiRL with multivariate rewards, an important setting which cannot be tackled with prior methods. The multivariate setting also allows us to unify learning the distribution of values and state transitions, and we exploit this idea to devise a novel exploration method that is driven by the discrepancy in estimating both values and states.	bellman equation;discrepancy function;generative model;reinforcement learning	Dror Freirich;Ron Meir;Aviv Tamar	2018	CoRR		machine learning;generative grammar;generative model;reinforcement learning;exploit;computer science;multivariate statistics;bellman equation;artificial intelligence	ML	24.111879357478465	-30.37660910100382	23678
9b921adb61dc894e7ddf4eeb54f4befde7a7e0b4	system identification via a virtual higher-resolution fuzzy model	gradient descent method;fuzzy identification;fuzzy systems	Abstract A fuzzy identification algorithm with an inherent knowledge generalization mechanism is reported in this paper. In the proposed identification algorithm, a low-resolution fuzzy model is used to mimic the effect of a virtual higher-resolution model. The gradient descent optimization method is then applied to update the rule-base by using the difference between the actual system output and the model output. Simulation studies are included to demonstrate the performance of the algorithm.	system identification	K. M. Chow;Ahmad B. Rad	2000	Intelligent Automation & Soft Computing	10.1080/10798587.2000.10642793	gradient descent;defuzzification;adaptive neuro fuzzy inference system;fuzzy classification;computer science;artificial intelligence;fuzzy number;neuro-fuzzy;machine learning;control theory;fuzzy associative matrix;fuzzy set operations;fuzzy control system	Robotics	5.731539425414037	-26.800533206588202	23691
f6fabf7286b384ce9f74d730a4ae64dcb66d2615	orthogonal locally discriminant spline embedding for plant leaf recognition	plant leaf recognition;orthogonal locally discriminant spline embedding oldse;maximum margin criterion mmc;manifold learning;local spline embedding lse	Based on local spline embedding (LSE) and maximum margin criterion (MMC), two orthogonal locally discriminant spline embedding techniques (OLDSE-I and OLDSE-II) are proposed for plant leaf recognition in this paper. By OLDSE-I or OLDSE-II, the plant leaf images are mapped into a leaf subspace for analysis, which can detect the essential leaf manifold structure. Different from principal component analysis (PCA) and linear discriminant analysis (LDA) which can only deal with flat Euclidean structures of plant leaf space, OLDSE-I and OLDSE-II not only inherit the advantages of local spline embedding (LSE), but makes full use of class information to improve discriminant power by introducing translation and rescaling models. The proposed OLDSE-I and OLDSE-II methods are applied to recognize the plant leaf and are examined using the ICL-PlantLeaf and Swedish plant leaf image databases. The numerical results show compared with MMC, LDA, SLPP, and LDSE, the proposed OLDSE-I and OLDSE-II methods can achieve higher recognition rate. 2013 Elsevier Inc. All rights reserved.	algorithm;computation;computational complexity theory;curse of dimensionality;database;hilbert space;icl;linear approximation;linear discriminant analysis;machine learning;map;memory management controller;nonlinear system;numerical analysis;principal component analysis	Ying-Ke Lei;Ji-Wei Zou;Tianbao Dong;Zhu-Hong You;Yuan Yuan;Yihua Hu	2014	Computer Vision and Image Understanding	10.1016/j.cviu.2013.12.001	mathematical optimization;combinatorics;topology;computer science;machine learning;mathematics;nonlinear dimensionality reduction	AI	23.72245445871128	-40.676606005382965	23698
490d8b546a6369fa48aaf24af9437b286e28f690	performance analysis of clustering algorithms for gene expression data		Microarray technology is a process that allows thousands of genes simultaneously monitor to various experimental conditions. It is used to identify the co-expressed genes in specific cells or tissues that are actively used to make proteins, This method is used to analysis the gene expression, an important task in bioinformatics research. Cluster analysis of gene expression data has proved to be a useful tool for identifying co-expressed genes, biologically relevant groupings of genes and samples. In this paper we analysed K-Means with Automatic Generations of Merge Factor for ISODATAAGMFI, to group the microarray data sets on the basic of ISODATA. AGMFI is to generate initial values for merge and Spilt factor, maximum merge times instead of selecting effic ient values as in ISODATA. The initial seeds for each cluster were normally chosen either sequentially or randomly. The quality of the final clusters was found to be influenced by these initial seeds. For the real life problems, the suitable number of clusters cannot be predicted. To overcome the above drawback the current research focused on developing the clustering algorithms without giving the initial number of clusters.	algorithm;bioinformatics;cluster analysis;dna microarray;k-means clustering;profiling (computer programming);randomness;real life;seeds (cellular automaton)	T. Chandrasekhar;K. Thangavel;E. Elayaraja	2012	CoRR		computer science;bioinformatics;data science;data mining	Comp.	5.783510994736913	-49.35553123151417	23776
219db69a4ccdfaf2d2ea1e2a959c75df74eabb11	multiple-view multiple-learner semi-supervised learning	ensemble learning;multiple view learning;semi supervised learning;neural network	Some recent successful semi-supervised learning methods construct more than one learner from both labeled and unlabeled data for inductive learning. This paper proposes a novel multiple-view multiple-learner (MVML) framework for semi-supervised learning, which differs from previous methods in possession of both multiple views and multiple learners. This method adopts a co-training styled learning paradigm in enlarging labeled data from a much larger set of unlabeled data. To the best of our knowledge it is the first attempt to combine the advantages of multiple-view learning and ensemble learning for semi-supervised learning. The use of multiple views is promising to promote performance compared with single-view learning because information is more effectively exploited. At the same time, as an ensemble of classifiers is learned from each view, predictions with higher accuracies can be obtained than solely adopting one classifier from the same view. Experiments on different applications involving both multiple-view and single-view data sets show encouraging results of the proposed MVML method.	artificial neural network;co-training;computer multitasking;ensemble learning;experiment;horner's method;multi-task learning;programming paradigm;semi-supervised learning;semiconductor industry;statistical classification;supervised learning;universal instantiation;verification and validation	Shiliang Sun;Qingjiu Zhang	2011	Neural Processing Letters	10.1007/s11063-011-9195-8	semi-supervised learning;unsupervised learning;multi-task learning;instance-based learning;preference learning;algorithmic learning theory;computer science;online machine learning;machine learning;pattern recognition;data mining;inductive transfer;ensemble learning;learning classifier system;stability;competitive learning;active learning;artificial neural network;generalization error	ML	22.480329058572053	-44.769992955903334	23779
118c0c734add3b986ab0eafa0647a0594a2bf436	maximum margin ranking algorithms for information retrieval	exponentiated gradient;information retrieval;optimization problem;machine learning;evaluation criteria;stochastic gradient;ranking algorithm;support vector machine	Machine learning ranking methods are increasingly applied to ranking tasks in information retrieval (IR). However ranking tasks in IR often differ from standard ranking tasks in machine learning, both in terms of problem structure and in terms of the evaluation criteria used to measure performance. Consequently, there has been much interest in recent years in developing ranking algorithms that directly optimize IR ranking measures. Here we propose a family of ranking algorithms that preserve the simplicity of standard pair-wise ranking methods in machine learning, yet show performance comparable to state-of-theart IR ranking algorithms. Our algorithms optimize variations of the hinge loss used in support vector machines (SVMs); we discuss three variations, and in each case, give simple and efficient stochastic gradient algorithms to solve the resulting optimization problems. Two of these are stochastic gradient projection algorithms, one of which relies on a recent method for l1,∞-norm projections; the third is a stochastic exponentiated gradient algorithm. The algorithms are simple and efficient, have provable convergence properties, and in our preliminary experiments, show performance close to state-of-the-art algorithms that directly optimize IR ranking measures.	algorithm;eurographics;expect;experiment;hinge loss;information retrieval;loss function;machine learning;mathematical optimization;pagerank;provable security;rate of convergence;relevance;stochastic gradient descent;support vector machine;web search engine	Shivani Agarwal;Michael Collins	2010		10.1007/978-3-642-12275-0_30	optimization problem;support vector machine;mathematical optimization;ranking;computer science;machine learning;pattern recognition;ranking svm;learning to rank	Web+IR	22.408772166624853	-37.23359469736201	23815
4d5b191105886058bf6e8e7219414237bc3de441	assessing the differences in accuracy between gfss with bootstrap tests		The study of the balance between linguistic interpretability and numerical accuracy in genetic fuzzy systems is an active area of research, and a rich set of procedures for comparing the understandability of fuzzy rule bases is available. Nevertheless, comparing the numerical accuracy of two GFS is relegated to a second plane, or assumed solved, as most of the researchers in this area use classical, parametric hypotheses based, statistical tests. With this paper, we intend to show that the straight use of classical tests to compare the accuracy of different machine learning algorithms may produce misleading results, and propose to substitute them by bootstrap tests in the experimental designs of the cross-validation kind.	algorithm;booting;cross-validation (statistics);design of experiments;fuzzy control system;fuzzy rule;genetic fuzzy systems;machine learning;numerical analysis	Luciano Sánchez;José Otero;Jesús Alcalá-Fdez	2005				ML	10.871898322471166	-36.501026752081124	23840
bf2e48c76b0d4028267db0959f9920243929ba83	time series prediction with recurrent neural networks trained by a hybrid pso-ea algorithm	learning algorithm;time series;particle swarm optimizer;particle swarm optimization;global optimization;recurrent neural networks;missing values;recurrent neural network;evolutionary algorithm;time series prediction;hybrid algorithm;training algorithm	To predict the 100 missing values from a time series of 5000 data points, given for the IJCNN 2004 time series prediction competition, recurrent neural networks (RNNs) are trained with a new learning algorithm. This training algorithm is based on a hybrid of particle swarm optimization (PSO) and evolutionary algorithm (EA). By combining the searching abilities of these two global optimization methods, the evolution of individuals is no longer restricted to be in the same generation, and better performing individuals may produce offspring to replace those with poor performance. Experimental results show that RNNs, trained by the hybrid algorithm, are able to predict the missing values in the time series with minimum error, in comparison with those trained with standard EA and PSO algorithms. r 2007 Elsevier B.V. All rights reserved.	artificial neural network;benchmark (computing);data point;evolutionary algorithm;global optimization;hybrid algorithm;mathematical optimization;maxima and minima;missing data;neurocomputing;optimization problem;particle swarm optimization;phase-shift oscillator;preprocessor;propagation delay;random neural network;recurrent neural network;simulation;software propagation;the 100;the offspring;time series	Xindi Cai;Nian Zhang;Ganesh K. Venayagamoorthy;Donald C. Wunsch	2007	Neurocomputing	10.1016/j.neucom.2005.12.138	mathematical optimization;multi-swarm optimization;computer science;artificial intelligence;recurrent neural network;machine learning;evolutionary algorithm;time series;global optimization;population-based incremental learning	AI	12.81007451350526	-24.099436351042847	23841
a7a243bfd74843d6bcad943d74018a4ae160e366	classification using geometric level sets	article	A variational level set method is developed for the supervis d classification problem. Nonlinear classifier decision boundaries are obtained by minimizing a n energy functional that is composed of an empirical risk term with a margin-based loss and a geometr ic r gularization term new to machine learning: the surface area of the decision boundary. This ge ometric level set classifier is analyzed in terms of consistency and complexity through the calculat ion of its ε-entropy. For multicategory classification, an efficient scheme is developed using a loga rithmic number of decision functions in the number of classes rather than the typical linear numbe r of decision functions. Geometric level set classification yields performance results on benc hmark data sets that are competitive with well-established methods.	bitwise operation;calculus of variations;complexity;computation;decision boundary;feature selection;kernel method;machine learning;matrix regularization;nonlinear system;relevance;statistical classification	Kush R. Varshney;Alan S. Willsky	2010	Journal of Machine Learning Research	10.1145/1756006.1756020	geometric data analysis	ML	21.5555497534391	-37.694143763865874	23894
eb7c47b6149f70a9b6dcc3b5a36125a8ead013dd	a soft davies-bouldin separation measure		We present a soft separation measure to validate fuzzy clustering results without defuzzyficaton. It is the generalization of Davies-Bouldin validation index (DB) for crisp clustering in the soft clustering domain; we named the measure Soft Davies-Bouldin index (SDB). We compared DB and SDB when applied to k-means and fuzzy c-means algorithms using eight datasets with ground-truth and two experimental fMRI datasets without ground-truth. We found that i) in more than half datasets, the optimal score of Soft Davies-Bouldin index was less than Davies-Bouldin index, ii) in half datasets that have ground-truth, the optimal score of Soft Davies-Bouldin index was less than Davies-Bouldin index in correspondence of the truth number of patterns, iii) the Soft Davies-Bouldin index outperformed the Davies-Bouldin index as central tendency of all datasets along the complete range of clusters considered.	aim alliance;algorithm;benchmark (computing);cluster analysis;davies–bouldin index;decibel;fuzzy clustering;ground truth;inverted index;k-means clustering;sdb (debugger)	Alberto A. Vergani;Elisabetta Binaghi	2018	2018 IEEE International Conference on Fuzzy Systems (FUZZ-IEEE)	10.1109/FUZZ-IEEE.2018.8491581	artificial intelligence;machine learning;fuzzy logic;fuzzy set;fuzzy clustering;cluster analysis;computer science	Vision	2.0833870523520335	-39.10795992198184	23898
91666d6169f8bd272c8b1a01c009fc9532cc28e6	triclustering on temporary microarray data using the trigen algorithm	microarray data;trigeneration gene expression algorithm design and analysis clustering algorithms genetic algorithms;pattern clustering data analysis genetic algorithms genetics;temporary data;pattern clustering;genetics;data clustering;genetic algorithms triclustering microarrays temporary data;data analysis;gene expression temporary microarray data triclustering trigen algorithm biclustering grouping constraints temporal microarray data analysis evolutionary computation genetic algorithms;genetic algorithm;genetic algorithms;triclustering;evolutionary computing;microarrays	The analysis of microarray data is a computational challenge due to the characteristics of these data. Clustering techniques are widely applied to create groups of genes that exhibit a similar behavior under the conditions tested. Biclustering emerges as an improvement of classical clustering since it relaxes the constraints for grouping allowing genes to be evaluated only under a subset of the conditions and not under all of them. However, this technique is not appropriate for the analysis of temporal microarray data in which the genes are evaluated under certain conditions at several time points. In this paper, we propose the TriGen algorithm, which finds triclusters that take into account the experimental conditions and the time points, using evolutionary computation, in particular genetic algorithms, enabling the evaluation of the gene's behavior under subsets of conditions and of time points.	biclustering;cluster analysis;evaluation function;evolutionary computation;genetic algorithm;image analysis;microarray;parallel computing;software release life cycle;systems design	David Gutiérrez-Avilés;Cristina Rubio-Escudero;José Cristóbal Riquelme Santos	2011	2011 11th International Conference on Intelligent Systems Design and Applications	10.1109/ISDA.2011.6121768	gene chip analysis;genetic algorithm;computer science;bioinformatics;machine learning;data mining;cluster analysis;biclustering;evolutionary computation;clustering high-dimensional data	Robotics	4.783955002439042	-47.49548038164065	23911
b5c12c44d9c3ba7d8150ea53628d0931488b66b0	generalized deterministic policy gradient algorithms		We study a setting of reinforcement learning, where the state transition is a convex combination of a stochastic continuous function and a deterministic function. Such a setting include as a special case the stochastic state transition setting, namely the setting of deterministic policy gradient (DPG). We firstly give a simple example to illustrate that the deterministic policy gradient may not exist under deterministic state transitions, and introduce a theoretical technique to prove the existence of the policy gradient in this generalized setting. Using this technique, we prove that the deterministic policy gradient indeed exists for a certain set of discount factors, and further prove two conditions that guarantee the existence for all discount factors. We then derive a closed form of the policy gradient whenever exists. Interestingly, the form of the policy gradient in such setting is equivalent to that in DPG. Furthermore, to overcome the challenge of high sample complexity of DPG in this setting, we propose the Generalized Deterministic Policy Gradient (GDPG) algorithm. The main innovation of the algorithm is to optimize a weighted objective of the original Markov decision process (MDP) and an augmented MDP that simplifies the original one, and serves as its lower bound. To solve the augmented MDP, we make use of the model-based methods which enable fast convergence. We finally conduct extensive experiments comparing GDPG with state-of-the-art methods on several standard benchmarks. Results demonstrate that GDPG substantially outperforms other baselines in terms of both convergence and long-term rewards.	algorithm;augmented lagrangian method;baseline (configuration management);benchmark (computing);experiment;gradient;markov chain;markov decision process;reinforcement learning;sample complexity;state transition table	Qingpeng Cai;Ling Pan;Pingzhong Tang	2018	CoRR		markov decision process;algorithm;special case;sample complexity;reinforcement learning;convergence (routing);convex combination;continuous function;upper and lower bounds;computer science	ML	23.479461879417986	-32.89756667244824	23958
7936aa266de04fb339a7c82eaf508a8a7f2caf80	ermma: expected risk minimization for matrix approximation-based recommender systems		Matrix approximation (MA) is one of the most popular techniques in today’s recommender systems. In most MA-based recommender systems, the problem of risk minimization should be defined, and how to achieve minimum expected risk in model learning is one of the most critical problems to recommendation accuracy. This paper addresses the expected risk minimization problem, in which expected risk can be bounded by the sum of optimization error and generalization error. Based on the uniform stability theory, we propose an expected risk minimized matrix approximation method (ERMMA), which is designed to achieve better tradeoff between optimization error and generalization error in order to reduce the expected risk of the learned MA models. Theoretical analysis shows that ERMMA can achieve lower expected risk bound than existing MA methods. Experimental results on the MovieLens and Netflix datasets demonstrate that ERMMA outperforms six state-of-the-art MA-based recommendation methods in both rating prediction problem and item ranking problem.	approximation;generalization error;mathematical optimization;matrix regularization;movielens;recommender system;singular value decomposition	Dongsheng Li;Chao Chen;Qin Lv;Li Shang;Stephen M. Chu;Hongyuan Zha	2017			artificial intelligence;mathematical optimization;recommender system;machine learning;minification;computer science;matrix (mathematics)	AI	24.270677229450108	-35.44250319709113	24010
bae834ce18924c06802981d7c65775e6896dbc20	supervised intra- and inter-modality similarity preserving hashing for cross-modal retrieval		Cross-modal hashing has drawn considerable interest in multimodal retrieval due to the explosive growth of big data on multimedia. However, the existing methods mainly focus on unified hash codes learning and investigate the local geometric structure in the original space, resulting in low-discriminative power hash code of out-of-sample instances. To address this important problem, this paper is dedicated to investigate the hashing functions learning by considering the modality correlation preserving in the expected low-dimensional common space. A cross-modal hashing method based on supervised collective matrix factorization is proposed by taking intra-modality and inter-modality similarity preserving into account. For more flexible hashing functions, label information is embedded into the hashing functions learning procedure. Specifically, we explore the intra-modality similarity preserving in the expected low-dimensional common space. In addition, a supervised shrinking scheme is used to enhance the local geometric consistency in each modality. The proposed method learns unified hash codes as well as hashing functions for different modalities; the overall objective function, consisting of collective matrix factorization and intra- and inter-modality similarity embedding, is solved using an alternative optimization in an iterative scheme. Extensive experiments on three benchmark data sets demonstrate that the proposed method is more flexible to new coming data and can achieve superior performance to the state-of-the-art supervised cross-modal hashing approaches in most of the cases.	benchmark (computing);big data;code;embedded system;experiment;hash function;iterative method;loss function;mathematical optimization;modal logic;modality (human–computer interaction);multimodal interaction;optimization problem	Zhikui Chen;Fangming Zhong;Geyong Min;Yonglin Leng;Yiming Ying	2018	IEEE Access	10.1109/ACCESS.2018.2832141	sparse matrix;distributed computing;computer science;hash function;big data;matrix decomposition;correlation;embedding;pattern recognition;artificial intelligence;data set	AI	24.254192059646744	-43.59347834777868	24044
542e13384ef5acbef12bd0c2d875d47fb3d9e850	adaptive interaction and its application to neural networks	cost function;adaptive interaction;adaptive algorithm;gradient descent;back propagation algorithm;back propagation;neural network	Adaptive interaction is a new approach to introduce adaptability into man made systems In this approach a system is decomposed into interconnected subsystems that we call devices and adaptation occurs in the interactions More precisely interac tion weights among these devices will be adapted in order to achieve the objective of minimizing a given cost function The adaptation algorithm developed is mathemati cally equivalent to a gradient descent algorithm but requires only local information in its implementation One particular application of adaptive interaction that we study in this paper is in neural networks By applying adaptive interaction we can achieve essentially the same adaptation as that using the well known back propagation algo rithm but without the need of a feedback network to propagate the errors which has many advantages in practice A simulation is provided to show the e ectiveness of our approach	algorithm;artificial neural network;backpropagation;gradient descent;interaction;loss function;neural network software;simulation;software propagation;whole earth 'lectronic link	Robert D. Brandt;Feng Lin	1999	Inf. Sci.	10.1016/S0020-0255(99)00090-0	gradient descent;computer science;artificial intelligence;backpropagation;machine learning;artificial neural network	ML	16.317837849098225	-28.636970277630965	24072
70ecb9e8de9e57588ef1e318a3b7c24166853ae2	learning-induced categorical perception in a neural network model		In human cognition, the expansion of perceived between-category distances and compression of within-category distances is known as categorical perception (CP). There are several hypotheses about the causes of CP (e.g., language, learning, evolution) but no functional model. Whether CP is essential to categorisation or simply a by-product of it is not yet clear, but evidence is accumulating that CP can be induced by category learning. We provide a model for learning-induced CP as expansion and compression of distances in hidden-unit space in neural nets. Basic conditions from which the current model predicts CP are described, and clues as to how these conditions might generalize to more complex kinds of categorization begin to emerge. 1 Categorical Perception Categorical Perception (CP) is defined by the expansion of the perceived differences among members of different categories and/or the compression of the perceived differences among members of the same category (Harnad 1987). In simple terms, if a1 and a2 belong to category A and b1 belongs to category B, then a1 is perceived subjectively as more different from b1 than from a2 even when the objective differences are equal. A clear consensus on the conditions generating CP has yet to be reached. According to the “Whorf Hypothesis” (Kay & Kempton 1984; Hussein 2012), the between-category separation and/or within-category compression that defines CP is cause by “language”. (Things given different names look more different than things Figure 1. Hues crossing the boundary between two adjacent color categories in the spectrum are perceived as more distant than hues within the same category, even when physical (wavelength) distances are the same. Thériault, Pérez-Gay, Rivas & Harnad: Model for Learned categorical perception 2 given the same name.) Without ruling out language as a factor in CP, genetics (i.e. biological evolution) and learning are also known influences. Biological factors are supported by the case of color perception: Two colors separated by the same distance in wavelength are perceived as more different when each color resides on separate sides of a color boundary. This CP effect is not a result of language, but a result of the brain’s innate feature-detectors for colors (Jacobs 2013). Evidence (Bao 2015; Folstein et al. 2015; de Leeuw et al 2016; Goldstone et al. 2017; Edwards 2017; Cangelosi 2017; Pérez-Gay J, 2017) also suggests that CP can be induced by learning in other sensory domains. In such cases, perceived distances before learning are independent of category membership, but after the category has been learned, there is a perceived expansion of the distance between members of different categories and a compression of the distance between members of the same category. We propose a model for CP induced by category learning based on an idea originally proposed by Stephen J. Hanson (Harnad, Hanson & Lubin 1995), consisting of an unsupervised learning phase before category learning followed by a supervised category-learning phase. As a potential explanation for human experimental findings on learned CP our model examines the functional role of between-category separation and within-category compression in the internal representation of input stimuli before and after category learning. The explanation hinges on the number and proportion of category-invariant dimensions relative to the total number of dimensions in a simple binary stimulus feature-space. Figure 2. Human experimental data showing how pairwise stimulus dissimilarity judgments changed from before to after successfully learning the category through trial and error training with corrective feedback (adapted from Perez & al 2017). Thériault, Pérez-Gay, Rivas & Harnad: Model for Learned categorical perception 3 1.1 Unsupervised and Supervised Learning An initial analytical understanding of CP can be derived from two families of learning algorithms for pattern classification (Richard O & al, 2001, Bishop, 2006): unsupervised and supervised learning. Unsupervised learning extracts the intrinsic structure of data without any information about category membership, whereas supervised learning partitions data into categories on the basis of corrective feedback. A basic model of CP emerges when comparing data representations resulting from these two families of algorithms, with their different goals. By learning relevant features and discarding irrelevant ones, both families of algorithms can modify the distances among data-points. Unsupervised learning does so by converging on statistically relevant patterns inherent in the data-structure itself (feature frequencies and correlations), whereas supervised learning separates the data into categories based on external feedback on correct and incorrect categorization). Within their respective families, multiple candidates (i.e., principal component analysis, independent component analysis, singular value decomposition, support vector machine, linear regression), share similar behaviors and could serve our purposes. Basic principles of category learning and CP can be expressed in particularly simple terms by principal component analysis (PCA) and linear discriminant analysis (LDA), both of which can be related to neural network models. PCA belongs to the family of unsupervised learning algorithms. Given a set of n observations represented by n column vectors X = {x1, x2, x3 ... , xn} in an m dimensional space R, PCA transforms these observations into a basis of n uncorrelated principal components B = {u1, u2, u3 ... , un} (Pearson, 1901). These components are found by minimizing the error of reconstruction when projecting data points on a subset of principal components. Figure 3 illustrates this principle for a two-dimensional space. The first component found by PCA captures the most variation in X. The following components successively capture the most variance in directions orthogonal to the previous components. As a result, PCA finds the lower dimensional linear space that best reconstructs the data with uncorrelated components. The components found by PCA can be defined by the eigenvectors of the covariance matrix C with entries (i, j) Ci,j = (xi − ?̅?) (xj − ?̅?) . (1) As only the maximum explained variance matters, PCA yields a good reconstruction but does not take category information into account. In fact, the projection on the main component may yield a representation that is worse than the initial representation in terms of category separation. Thériault, Pérez-Gay, Rivas & Harnad: Model for Learned categorical perception 4 Figure 4 illustrates this effect. Although the main direction found by PCA gives a good linear approximation of the data, the projective direction which best separates the categories is a different one. Linear discriminant analysis (LDA) provides this direction (Fisher, 1936), and belongs to the family of supervised learning algorithms. Linear discriminant analysis (LDA) uses categorical information about the data to find a projecting vector (i.e. an hyperplane) which separates the categories by maximizing the ratio	algorithm;artificial neural network;categorization;category utility;cognition;color vision;concept learning;data point;data structure;emergence;evolution;function model;independent component analysis;linear approximation;linear discriminant analysis;machine learning;network model;principal component analysis;relevance;sensor;singular value decomposition;supervised learning;support vector machine;unsupervised learning;word lists by frequency	Christian Thériault;Fernanda Pérez-Gay;Dan Rivas;Stevan Harnad	2018	CoRR		machine learning;categorical perception;categorization;artificial neural network;artificial intelligence;mathematics;cognition;concept learning	ML	16.633253736029065	-48.3574757092243	24074
9ae234ed0103bda34804f38e8cc401dc502061bc	the fuzzy associative memory of max-min fuzzy neural network with threshold	fuzzy neural network;fuzzy neural nets;memoire associative;metodo minimax;minimax method;reseau neuronal flou;capacite stockage;capacidad almacenaje;storage capacity;methode minimax;associative memory;memoria asociativa	Abstract   In this paper, we introduce the max-min fuzzy neural network with threshold which generalizes the fuzzy neural network models in [1,4–;6,8,10] and show that the storage capacity of the two-layer max-min fuzzy neural network is identical with one of the max-min fuzzy neural network with hidden layers. For given fuzzy pattern pairs ( X  1 ,  Y  1 ),…, ( X   p  ,  Y   p  ), we obtain an equivalent condition which the family of given fuzzy pattern pairs can be stored in the fuzzy neural network. Finally, we give a example to demonstrate our conclusions.	artificial neural network;content-addressable memory;multistage interconnection networks;neuro-fuzzy	Puyin Liu	1999	Fuzzy Sets and Systems	10.1016/S0165-0114(97)00352-7	adaptive neuro fuzzy inference system;computer science;artificial intelligence;fuzzy number;neuro-fuzzy;machine learning;content-addressable memory;mathematics;fuzzy associative matrix;artificial neural network;algorithm	ML	10.712344352380953	-28.663667388077947	24206
12b6a7eb4014338fba3edef956be32775d271c78	a randomized gradient-free attack on relu networks		It has recently been shown that neural networks but also other classifiers are vulnerable to so called adversarial attacks e.g. in object recognition an almost non-perceivable change of the image changes the decision of the classifier. Relatively fast heuristics have been proposed to produce these adversarial inputs but the problem of finding the optimal adversarial input, that is with the minimal change of the input, is NPhard. While methods based on mixed-integer optimization which find the optimal adversarial input have been developed, they do not scale to large networks. Currently, the attack scheme proposed by Carlini and Wagner is considered to produce the best adversarial inputs. In this paper we propose a new attack scheme for the class of ReLU networks based on a direct optimization on the resulting linear regions. In our experimental validation we improve in all except one experiment out of 18 over the Carlini-Wagner attack with a relative improvement of up to 9%. As our approach is based on the geometrical structure of ReLU networks, it is less susceptible to defences targeting their functional properties.	artificial neural network;gradient;heuristic (computer science);mathematical optimization;outline of object recognition;randomized algorithm;rectifier (neural networks)	Francesco Croce;Matthias Hein	2018	CoRR			ML	19.17123569677499	-51.277096910040264	24230
bba5482d690bc799d780e0e01d790f7ca5d40337	heuristic classifier chains for multi-label classification		Multi-label classification, in opposite to conventional classification, assumes that each data instance may be associated with more than one labels simultaneously. Multi-label learning methods take advantage of dependencies between labels, but this implies greater learning computational complexity.#R##N##R##N#The paper considers Classifier Chain multi-label classification method, which in original form is fast, but assumes the order of labels in the chain. This leads to propagation of inference errors down the chain. On the other hand recent Bayes-optimal method, Probabilistic Classifier Chain, overcomes this drawback, but is computationally intractable. In order to find the trade off solution it is presented a novel heuristic approach for finding appropriate label order in chain. It is demonstrated that the method obtains competitive overall accuracy and is also tractable to higher-dimensional data.	classifier chains;heuristic;multi-label classification	Tomasz Kajdanowicz;Przemyslaw Kazienko	2013		10.1007/978-3-642-40769-7_48	computer science;artificial intelligence;machine learning;pattern recognition	ML	17.67563013836589	-37.09101864683792	24238
ec319312372948eb3a0d2ecad22cc0cf3f523a4f	silhouette-based feature selection for classification of medical images	k nearest neighbors;class separability;fcbf;cluster algorithm;evaluation function;silhouette based genetic algorithm search;computer aided diagnosis;filter based feature selection algorithms;medical image classification;training;silhouette statistic;image classification;biomedical imaging;greedy algorithms;genetic algorithms feature extraction clustering algorithms training biological cells biomedical imaging accuracy;k nearest neighbors silhouette based feature selection medical image classification computer aided diagnosis systems filter based feature selection algorithms evaluation function silhouette based greedy search silhouette based genetic algorithm search silhouette statistic class separability sigas algorithm cfs fcbf relieff knngas;knngas;accuracy;biological cells;medical image;sigas algorithm;relieff;feature extraction;medical image processing;search problems genetic algorithms greedy algorithms image classification medical image processing;classification error;clustering algorithms;silhouette based greedy search;genetic algorithm;genetic algorithms;cfs;feature selection;search problems;silhouette based feature selection;computer aided diagnosis systems	Classification is an important task for computer-aided diagnosis systems (CADs). However, many classifiers may not perform well, presenting poor generalization and high computational cost, especially when dealing with high-dimensional datasets. Thus, feature selection can greatly mitigate these problems. In this paper, we propose two filter-based feature selection algorithms that calculate the simplified silhouette statistic as evaluation function: the silhouette-based greedy search (SiGS) and the silhouette-based genetic algorithm search (SiGAS). Silhouette statistic is used to guide the search for features that provide better class separability. Experiments performed on three datasets have shown that the SiGAS algorithm overcomes traditional filter algorithms, such as CFS, FCBF and reliefF. It also outperforms a similar algorithm, kNNGAS, based on genetic algorithm that minimizes the classification error of k-nearest neighbors. Additionally, results have shown that SiGAS produces better accuracy than SiGS.	algorithmic efficiency;approximation algorithm;computation;evaluation function;experiment;feature interaction problem;feature selection;feature vector;filesystem-level encryption;genetic algorithm;greedy algorithm;k-nearest neighbors algorithm;linear separability;medical imaging;peterson's algorithm;software release life cycle;whole earth 'lectronic link	Sérgio Francisco da Silva;Bruno Brandoli;Danilo Medeiros Eler;João Batista Neto;Agma J. M. Traina	2010	2010 IEEE 23rd International Symposium on Computer-Based Medical Systems (CBMS)	10.1109/CBMS.2010.6042662	medical imaging;genetic algorithm;computer science;machine learning;pattern recognition;data mining;feature selection	Vision	10.647818335618418	-42.41736188440674	24240
66f28035899efb82803f89112edd1e63b7487f1b	poster: machine learning based code smell detection through wekanose		Code smells can be subjectively interpreted, the results provided by detectors are usually different, the agreement in the results is scarce, and a benchmark for the comparison of these results is not yet available. The main approaches used to detect code smells are based on the computation of a set of metrics. However code smell detectors often use different metrics and/or different thresholds, according to their detection rules. As result of this inconsistency the number of detected smells can increase or decrease accordingly, and this makes hard to understand when, for a specific software, a certain characteristic identifies a code smell or not. In this work, we introduce WekaNose, a tool that allows to perform an experiment to study code smell detection through machine learning techniques. The experiment's purpose is to select rules, and/or obtain trained algorithms, that can classify an instance (method or class) as affected or not by a code smell. These rules have the main advantage of being extracted through an example-based approach, rather then a heuristic-based one.	algorithm;benchmark (computing);code smell;computation;heuristic;machine learning;method (computer programming);sensor	Umberto Azadi;Francesca Arcelli Fontana;Marco Zanoni	2018	2018 IEEE/ACM 40th International Conference on Software Engineering: Companion (ICSE-Companion)	10.1145/3183440.3194974	code smell;computation;machine learning;software;heuristic;computer science;artificial intelligence;code (cryptography)	SE	6.602274661912761	-39.84405341578156	24286
fcdf8fee148179f7bf26a8254cb82c86321811d2	understanding individual neuron importance using information theory		In this work, we characterize the outputs of individual neurons in a trained feed-forward neural network by entropy, mutual information with the class variable, and a class selectivity measure based on Kullback-Leibler divergence. By cumulatively ablating neurons in the network, we connect these information-theoretic measures to the impact their removal has on classification performance on the test set. We observe that, looking at the neural network as a whole, none of these measures is a good indicator for classification performance, thus confirming recent results by Morcos et al. However, looking at specific layers separately, both mutual information and class selectivity are positively correlated with classification performance. We thus conclude that it is ill-advised to compare these measures across layers, and that different layers may be most appropriately characterized by different measures. We then discuss pruning neurons from neural networks to reduce computational complexity of inference. Drawing from our results, we perform pruning based on information-theoretic measures on a fully connected feed-forward neural network with two hidden layers trained on MNIST dataset and compare the results to a recently proposed pruning method. We furthermore show that the common practice of re-training after pruning can partly be obviated by a surgery step called bias balancing, without incurring significant performance degradation.	artificial neural network;computational complexity theory;elegant degradation;feedforward neural network;information theory;kullback–leibler divergence;mnist database;mutual information;neuron;norm (social);selectivity (electronic);test set	Kairen Liu;Rana Ali Amjad;Bernhard C. Geiger	2018	CoRR		artificial neural network;pruning;class variable;machine learning;mutual information;artificial intelligence;information theory;inference;mathematics;mnist database;test set	ML	16.69420771600918	-32.072091134598374	24302
7ee4f1ba24e3ed954135811b2a20c5929bc30e00	a hybrid approach to detect ddos attacks using koad and the mahalanobis distance		Distributed Denial of Service (DDoS) attacks continue to adversely affect internet-based services and applications. Various approaches have been proposed to detect different types of DDoS attacks. The computational and memory complexities of most algorithms, however prevent them from being employed in online manner. In this paper, we propose a novel victim-end online DDoS attack detection framework based on the celebrated Kernel-based Online Anomaly Detection (KOAD) algorithm and the Mahalanobis distance. We have employed the KOAD algorithm to adaptively model the normal behavior of network traffic, and then constructed the normal and abnormal datasets based on the results of KOAD. Subsequently, the Mahalanobis distance metric was calculated between datapoints of the abnormal and normal subsets. Finally, the chi-square test was used on the Mahalanobis distance values to segregate the DDoS attack datapoints from the normal ones. We have validated our algorithm on simulated DDoS scenarios, as well as real baseline data from a company operating in cyber security. Our results have revealed that our proposed hybrid approach boosts the performance of sole KOAD algorithm and Mahalanobis distance in detecting DDoS traffic in terms of both false positive and detection rates.		Salva Daneshgadeh;Thomas Kemmerich;Tarem Ahmed;Nazife Baykal	2018	2018 IEEE 17th International Symposium on Network Computing and Applications (NCA)	10.1109/NCA.2018.8548334	machine learning;support vector machine;anomaly detection;kernel (linear algebra);the internet;mahalanobis distance;artificial intelligence;computer science;denial-of-service attack	Metrics	6.1852799695564125	-37.6156326161426	24308
cb919954e93726aff490458bd61d6b3d8155fbd7	cross-domain recommendation: an embedding and mapping approach		Data sparsity is one of the most challenging problems for recommender systems. One promising solution to this problem is cross-domain recommendation, i.e., leveraging feedbacks or ratings from multiple domains to improve recommendation performance in a collective manner. In this paper, we propose an Embedding and Mapping framework for Cross-Domain Recommendation, called EMCDR. The proposed EMCDR framework distinguishes itself from existing crossdomain recommendation models in two aspects. First, a multi-layer perceptron is used to capture the nonlinear mapping function across domains, which offers high flexibility for learning domain-specific features of entities in each domain. Second, only the entities with sufficient data are used to learn the mapping function, guaranteeing its robustness to noise caused by data sparsity in single domain. Extensive experiments on two cross-domain recommendation scenarios demonstrate that EMCDR significantly outperforms stateof-the-art cross-domain recommendation methods.	entity;experiment;multilayer perceptron;nonlinear system;recommender system;sparse matrix;test set	Tong Man;Huawei Shen;Xiaolong Jin;Xueqi Cheng	2017		10.24963/ijcai.2017/343	machine learning;artificial intelligence;computer science;embedding	AI	22.560987579125786	-45.59346076449079	24323
ceea0a56e16bfeb0e55575b6dcb77bbc699adc33	learning within the bdi framework: an empirical analysis	modelizacion;artificial intelligence and image processing not elsewhere classified;learning algorithm;belief desire intention model;methode empirique;empirical analysis;belief desire intention;metodo empirico;empirical method;intelligence artificielle;algorithme apprentissage;modelisation;dynamic environment;bdi agents;modelo bdi;artificial intelligence;modele bdi;inteligencia artificial;algoritmo aprendizaje;modeling	One of the limitations of the BDI (Belief-Desire-Intention) model is the lack of any explicit mechanisms within the architecture to be able to learn. In particular, BDI agents do not possess the ability to adapt based on past experience. This is important in dynamic environments since they can change, causing methods for achieving goals that worked well previously to become inefficient or ineffective. We present a model in which learning can be utilised by a BDI agent and verify this model experimentally using two learning algorithms.	algorithm;cyclic redundancy check;experiment;inductive reasoning;machine learning;simile	Toan Phung;Michael Winikoff;Lin Padgham	2005		10.1007/11553939_41	systems modeling;computer science;artificial intelligence;empirical research	ML	8.65585702738497	-31.59021784988002	24340
2fa81bc72d55828bb868137016459c8a694d2bff	video event detection using kernel support vector machine with isotropic gaussian sample uncertainty (ksvm-igsu)	kernel methods;very few positive samples;learning with uncertainty;relevance degree svms;related samples;video event detection	In this paper, we propose an algorithm that learns from uncertain data and exploits related videos for the problem of event detection; related videos are those that are closely associated, though not fully depicting the event of interest. In particular, two extensions of the linear SVM with Gaussian Sample Uncertainty are presented, which a) lead to non-linear decision boundaries and b) incorporate related class samples in the optimization problem. The resulting learning methods are especially useful in problems where only a limited number of positive and related training observations are provided, e.g., for the 10Ex subtask of TRECVID MED, where only ten positive and five related samples are provided for the training of a complex event detector. Experimental results on the TRECVID MED 2014 dataset verify the effectiveness of the proposed methods.		Christos Tzelepis;Vasileios Mezaris;Ioannis Patras	2016		10.1007/978-3-319-27671-7_1	kernel method;computer science;machine learning;pattern recognition;data mining;statistics	ML	24.13777425926593	-46.00054265283571	24351
0322f4ac352f69741fed8731175d2bf03b3d5c09	on feature selection: learning with exponentially many irrelevant features as training examples	generalization error;electrical engineering and computer science;thesis;feature selection	"""We consider feature selection in the \wrap-per"""" model of feature selection. This typically involves an NP-hard optimization problem that is approximated by heuristic search for a \good"""" feature subset. First considering the idealization where this optimization is performed exactly, we give a rigorous bound for generalization error under feature selection. The search heuristics typically used are then immediately seen as trying to achieve the error given in our bounds, and succeeding to the extent that they succeed in solving the optimization. The bound suggests that, in the presence of many \irrelevant"""" features, the main source of error in wrapper model feature selection is from \overrt-ting"""" hold-out or cross-validation data. This motivates a new algorithm that, again under the idealization of performing search exactly, has sample complexity (and error) that grows logarithmically in the number of \irrelevant"""" features { which means it can tolerate having a number of \irrelevant"""" features exponential in the number of training examples { and search heuristics are again seen to be directly trying to reach this bound. Experimental results on a problem using simulated data show the new algorithm having much higher tolerance to irrelevant features than the standard wrapper model. Lastly, we also discuss ramiications that sample complexity logarithmic in the number of irrelevant features might have for feature design in actual applications of learning."""	approximation algorithm;cross-validation (statistics);feature selection;generalization error;heuristic (computer science);mathematical optimization;np-hardness;optimization problem;relevance;sample complexity;time complexity	Andrew Y. Ng	1998			computer science;artificial intelligence;data science;machine learning;feature selection;generalization error	ML	18.6743635451731	-33.67566809428062	24353
747beaf1eb402c616f9932f245a92802f344eec6	designing a decompositional rule extraction algorithm for neural networks with bound decomposition tree	experimental design;software;calcul neuronal;neural computation;decomposition;aplicacion medical;tree;extraction regle;logiciel;05bxx;05c05;metodo descomposicion;arbol;resolution math;methode decomposition;plan experiencia;conception;rule extraction;62m45;raisonnement;algorithme;resolucion problema;algorithm;decomposition method;62k99;plan experience;decomposition algorithm;razonamiento;diseno;arbre;resolucion matematica;logicial;design;decision process;medical application;descomposicion;reasoning;reseau neuronal;boolean rule;solving;red neuronal;computacion neuronal;problem solving;resolution probleme;neural network;application medicale;algoritmo	The neural networks are successfully applied to many applications in different domains. However, due to the results made by the neural networks are difficult to explain the decision process of neural networks is supposed as a black box. The explanation of reasoning is important to some applications such like credit approval application and medical diagnosing software. Therefore, the rule extraction algorithm is becoming more and more important in explaining the extracted rules from the neural networks. In this paper, a decompositional algorithm is analyzed and designed to extract rules from neural networks. The algorithm is simple but efficient; can reduce the extracted rules but improve the efficiency of the algorithm at the same time. Moreover, the algorithm is compared to the other two algorithms, M-of-N and Garcez, by solving the MONK’s problem.	algorithm;artificial neural network;black box;rule induction	Jia-Sheng Heh;Jen-Cheng Chen;Maiga Chang	2007	Neural Computing and Applications	10.1007/s00521-007-0115-9	design;decomposition method;computer science;artificial intelligence;machine learning;time delay neural network;tree;decomposition;artificial neural network;algorithm	ML	8.59788856305303	-30.434721756004212	24361
5e40cd810acce22e9c556de5353c8747f65e1db2	performance assessment of a novel fault diagnosis system based on support vector machines	large data sets;machine learning;evaluation measure;design and implementation;indexation;fault diagnosis system;support vector machine;article;performance assessment;fault diagnosis	Fault diagnosis in chemical plants is reviewed and discussed, while an innovative data-based fault diagnosis system (FDS) approach is proposed. The use of support vector machines (SVM) is considered for#R##N#their simpler design and implementation, and for allowing the better handling of complex and large data sets. In order to compare results with previously reported works, a standard case study such as the Tennessee Eastman (TE) process benchmark is considered. SVM achieves consistent and promising results. However, the difficulties arising when comparing SVM with previously reported results reveals the need for a systematic procedure for contrasting the performance of different FDS. Hence, general performance assessment indexes based on precision and recall of each FDS are proposed and used. In this sense, this study provides a data set and evaluation measures that could be used as a framework for future#R##N#comparisons.	support vector machine	Ignacio Yélamos-Ruiz;Gerard Escudero;Moisès Graells;Luis Puigjaner	2009	Computers & Chemical Engineering	10.1016/j.compchemeng.2008.08.008	reliability engineering;support vector machine;computer science;engineering;machine learning;data mining	AI	1.8114285408512902	-32.18278411986276	24401
97a69014c60ecfd302a933aa1b5ccdf6fe88e0a3	training soft margin support vector machines by simulated annealing: a dual approach		Abstract A theoretical advantage of support vector machines (SVM) is the empirical and structural risk minimization which balances the complexity of the model against its success at fitting the training data. Metaheuristics have mostly been used with support vector machines to either tune hyperparameters or to perform feature selection. In this paper, we present a new approach to obtain sparse support vector machines (SVM) based on simulated annealing (SA), named SATE. In our proposal, SA was used to solve the quadratic optimization problem that emerges from support vector machines rather than tune the hyperparameters. We have compared our proposal with sequential minimal optimization (SMO), kernel adatron (KA), a usual QP solver, as well as with recent Particle Swarm Optimization (PSO) and Genetic Algorithms(GA)-based versions. Generally speaking, one can infer that the SATE is equivalent to SMO in terms of accuracy and mean of support vectors and sparser than KA, QP, LPSO, and GA. SATE also has higher accuracies than the GA and PSO-based versions. Moreover, SATE successfully embedded the SVM constraints and provides a competitive classifier while maintaining its simplicity and high sparseness in the solution.		Madson Luiz Dantas Dias;Ajalmar R. da Rocha Neto	2017	Expert Syst. Appl.	10.1016/j.eswa.2017.06.016	machine learning;artificial intelligence;support vector machine;sequential minimal optimization;computer science;feature selection;metaheuristic;simulated annealing;quadratic programming;structural risk minimization;particle swarm optimization	ML	20.742955624062198	-37.53756635824082	24417
fcd5831fd494c36c2e69a36479c9f35cd11b0de3	error analysis for the sparse graph-based semi-supervised classification algorithm	graph based semi supervised learning;excess misclassification error;fenchel legendre conjugate;sparsified manifold regularizer	Recently, semi-supervised learning (SSL) has attracted significant attention in machine learning fields. While numerous experimental results have shown the effectiveness of SSL methods, the theoretical analysis in this area is still poorly understood. In this paper, we investigate the generalization performance of the recently proposed sparse graph-based semi-supervised classification algorithm. We use a computationally more simple way to solve the algorithm and present the excess misclassification error bounds. In detail, the Fenchel-Legendre conjugate is first employed to reform the algorithm to an inf-sup problem. Then, the covering number is used to estimate the excess misclassification error. Experiment results are given to demonstrate the effectiveness of the sparse SSL algorithm with new solving strategy.	algorithm;convex conjugate;iterative method;machine learning;mathematical optimization;offset binary;semi-supervised learning;semiconductor industry;sparse graph code;sparse matrix;supervised learning;transport layer security	Ling Zuo;Jiangtao Peng	2013	IJWMIP	10.1142/S0219691313500458	mathematical optimization;machine learning;pattern recognition;mathematics;statistics;generalization error	AI	22.84784146589909	-37.7933623579524	24426
8836a6c97904f0b02e51613a62c206295cf287e1	fuzzy rule interpolation based on the ratio of fuzziness of interval type-2 fuzzy sets	fuzzy rule based system;fuzzy set;bell shaped interval type 2 fuzzy sets;fuzzy rules;fuzzy rule interpolation;polygonal interval type 2 fuzzy sets;type 2 fuzzy set;sparse fuzzy rule based systems	In recent years, some fuzzy rule interpolation methods have been presented for sparse fuzzy rule-based systems based on interval type-2 fuzzy sets. However, the existing methods have the drawbacks that they cannot guarantee the convexity of the fuzzy interpolated result and may generate the same fuzzy interpolated results with respect to different observations. Moreover, they also cannot deal with fuzzy rule interpolation with bell-shaped interval type-2 fuzzy sets. In this paper, we present a new method for fuzzy rule interpolation for sparse fuzzy rule-based systems based on the ratio of fuzziness of interval type-2 fuzzy sets. The proposed method can overcome the drawbacks of the existing methods. First, it calculates the weights of the closest fuzzy rules with respect to the observation to obtain an intermediate consequence fuzzy set. Then, it uses the ratio of fuzziness of interval type-2 fuzzy sets to infer the fuzzy interpolated result based on the intermediate consequence fuzzy set. We also use some examples to compare the fuzzy interpolated results of the proposed method with the results by the existing methods. The experimental results show that the proposed fuzzy rule interpolation method gets more reasonable results than the existing methods. 2011 Elsevier Ltd. All rights reserved.	convex function;fuzzy rule;fuzzy set;interpolation;rule-based system;sparse matrix;type-2 fuzzy sets and systems	Shyi-Ming Chen;Yu-Chuan Chang	2011	Expert Syst. Appl.	10.1016/j.eswa.2011.03.084	fuzzy logic;mathematical optimization;mathematical analysis;discrete mathematics;membership function;defuzzification;adaptive neuro fuzzy inference system;type-2 fuzzy sets and systems;fuzzy mathematics;fuzzy classification;computer science;artificial intelligence;fuzzy subalgebra;fuzzy number;neuro-fuzzy;fuzzy measure theory;mathematics;fuzzy set;fuzzy associative matrix;fuzzy set operations;fuzzy control system	AI	-0.3221956944124835	-25.417954063460872	24490
dc078939477a7076c3c44a2039443f6e6967421b	an analysis of the rule weights and fuzzy reasoning methods for linguistic rule based classification systems applied to problems with highly imbalanced data sets	fuzzy reasoning;rule weight;fuzzy rule based classification systems;rule based;fuzzy reasoning method;over sampling;fuzzy rule base;classification system;imbalanced data sets	In this contribution we carry out an analysis of the rule weights and Fuzzy Reasoning Methods for Fuzzy Rule Based Classification Systems in the framework of imbalanced data-sets with a high imbalance degree. We analyze the behaviour of the Fuzzy Rule Based Classification Systems searching for the best configuration of rule weight and Fuzzy Reasoning Method also studying the cooperation of some pre-processing methods of instances. To do so we use a simple rule base obtained with the Chi (and co-authors’) method that extends the wellknown Wang and Mendel method to classification problems. The results obtained show the necessity to apply an instance preprocessing step and the clear differences in the use of the rule weight and Fuzzy Reasoning Method. Finally, it is empirically proved that there is a superior performance of Fuzzy Rule Based Classification Systems compared to the 1-NN and C4.5 classifiers in the framework of highly imbalanced data-sets.	c4.5 algorithm;chi;fuzzy rule;preprocessor;rule-based system	Alberto Fernández;Salvador García;Francisco Herrera;María José del Jesús	2007		10.1007/978-3-540-73400-0_21	rule-based system;oversampling;defuzzification;type-2 fuzzy sets and systems;fuzzy mathematics;fuzzy classification;computer science;artificial intelligence;fuzzy number;neuro-fuzzy;machine learning;pattern recognition;data mining;fuzzy set operations;library classification	AI	8.901805644438872	-41.42372871815622	24522
396b98052920e949ea1b19a0a358efa323538407	concurrent control chart patterns recognition with singular spectrum analysis and support vector machine	singular spectrum analysis;control charts;support vector machine;concurrent patterns	0360-8352/$ see front matter 2012 Elsevier Ltd. A http://dx.doi.org/10.1016/j.cie.2012.10.009 q This manuscript was processed by Area Editor Mi ⇑ Corresponding author. Tel.: +61 3 52272268; fax: E-mail addresses: liangjunxie@gmail.com (L. Xie) Gu), dalong.li@hp.com (D. Li), zhiqiang.cao@ia.ac.cn ( Tan), saeid.nahavandi@deakin.edu.au (S. Nahavandi). Since abnormal control chart patterns (CCPs) are indicators of production processes being out-of-control, it is a critical task to recognize these patterns effectively based on process measurements. Most methods on CCP recognition assume that the process data only suffers from single type of unnatural pattern. In reality, the observed process data could be the combination of several basic patterns, which leads to severe performance degradations in these methods. To address this problem, some independent component analysis (ICA) based schemes have been proposed. However, some limitations are observed in these algorithms, such as lacking of the capability of monitoring univariate processes with only one key measurement, misclassifications caused by the inherent permutation and scaling ambiguities, and inconsistent solution. This paper proposes a novel hybrid approach based on singular spectrum analysis (SSA) and support vector machine (SVM) to identify concurrent CCPs. In the proposed method, the observed data is first separated by SSA into multiple basic components, and then these separated components are classified by SVM for pattern recognition. The scheme is suitable for univariate concurrent CCPs identification, and the results are stable since it does not have shortcomings found in the ICA-based schemes. Furthermore, it has good generalization performance of dealing with the small samples. Superior performance of the proposed algorithm is achieved in simulations. 2012 Elsevier Ltd. All rights reserved.	algorithm;column (database);endeavour (supercomputer);experiment;fax;image scaling;independent computing architecture;independent component analysis;learning vector quantization;os-tan;pattern recognition;scheme;simulation;support vector machine;the australian;twisted pair;universal storage platform;x image extension	Liangjun Xie;Nong Gu;Dalong Li;Zhiqiang Cao;Min Tan;Saeid Nahavandi	2013	Computers & Industrial Engineering	10.1016/j.cie.2012.10.009	support vector machine;mathematical optimization;control chart;computer science;artificial intelligence;machine learning;pattern recognition;data mining;mathematics;singular spectrum analysis;statistics	AI	10.44858730534322	-36.69221302849317	24538
fef2218d08ffd0bd3cc946340694cfce52504ddd	new linguistic hedges in construction of interval type-2 fls	fuzzy set;computing with words;hybrid system	The paper presents a methodology for application of an interval type-2 codebook to computing with words. The crucial problem in this task is to formulate new hedge operators for fuzzy sets. The proposed hybrid system is demonstrated in a numerical example.		Piotr Dziwiñski;Janusz T. Starczewski;Lukasz Bartczuk	2010		10.1007/978-3-642-13232-2_54	computer science;artificial intelligence;machine learning;mathematics;fuzzy set;algorithm;hybrid system	NLP	2.5634928644740604	-24.85465421224868	24547
9c144d929ca2eff7b8e73cfea589866f94636784	the role of meta-learners in the adaptive selection of classifiers		The use of machine learning techniques able to classify source code components in defective or not received a lot of attention by the research community in the last decades. Previous studies indicated that no machine learning classifier is capable of providing the best accuracy in any context, highlighting interesting complementarity among them. For these reasons ensemble methods, that combines several classifier models, have been proposed. Among these, it was proposed ASCI (Adaptive Selection of Classifiers in bug predIction), an adaptive method able to dynamically select among a set of machine learning classifiers the one that better predicts the bug proneness of a class based on its characteristics. In summary, ASCI experiments each classifier on the training set and then use a meta-learner (e.g., Random Forest) to select the most suitable classifier to use for each test set instance. In this work, we conduct an empirical investigation on 21 open source software systems with the aim of analyzing the performance of several classifiers used as meta-learner in combination with ASCI. The results show that the selection of the meta-learner has not strong influence in the results achieved by ASCI in the context of within-project bug prediction. Indeed, the use of lightweight classifiers such as Naive Bayes or Logistic Regression is suggested.	boosting (machine learning);bootstrap aggregating;complementarity theory;ensemble learning;experiment;logistic regression;machine learning;multilayer perceptron;naive bayes classifier;open-source software;performance;random forest;self-replicating machine;software system;statistical classification;test set	Dario Di Nucci;Andrea De Lucia	2018	2018 IEEE Workshop on Machine Learning Techniques for Software Quality Evaluation (MaLTeSQuE)	10.1109/MALTESQUE.2018.8368452	support vector machine;software bug;naive bayes classifier;source code;random forest;ensemble learning;learning classifier system;artificial intelligence;computer science;pattern recognition;test set	SE	11.738002818371541	-41.29623691709936	24562
0e5373d51ae5c93cefdb25429f88eec6c56311d0	pattern based sequence classification	association rules itemsets classification algorithms buildings computer science;feature vectors;itemsets;machine learning algorithm pattern based sequence classification data mining association rule pattern feature based model;interesting patterns;association rules;feature vectors sequence classification interesting patterns classification rules;sequence classification;classification rules;classification algorithms;pattern classification data mining feature extraction learning artificial intelligence;computer science;buildings	Sequence classification is an important task in data mining. We address the problem of sequence classification using rules composed of interesting patterns found in a dataset of labelled sequences and accompanying class labels. We measure the interestingness of a pattern in a given class of sequences by combining the cohesion and the support of the pattern. We use the discovered patterns to generate confident classification rules, and present two different ways of building a classifier. The first classifier is based on an improved version of the existing method of classification based on association rules, while the second ranks the rules by first measuring their value specific to the new data object. Experimental results show that our rule based classifiers outperform existing comparable classifiers in terms of accuracy and stability. Additionally, we test a number of pattern feature based models that use different kinds of patterns as features to represent each sequence as a feature vector. We then apply a variety of machine learning algorithms for sequence classification, experimentally demonstrating that the patterns we discover represent the sequences well, and prove effective for the classification task.	algorithm;association rule learning;data mining;experiment;feature vector;machine learning;statistical classification	Cheng Zhou;Boris Cule;Bart Goethals	2016	IEEE Transactions on Knowledge and Data Engineering	10.1109/TKDE.2015.2510010	statistical classification;association rule learning;feature vector;feature;computer science;machine learning;linear classifier;classification rule;pattern recognition;data mining;mathematics;one-class classification	ML	12.182818857750545	-46.13778045471324	24581
ca6df247cac619e6d1c39a292c9672373362d7c3	comparison study on different core attributes	skowron s discernibility matrix;attribute reduction;core;positive region;information entropy;rough set;simplified discernibility matrix	How to find the core attributes is important for attribute reduction based on rough set. However, there are few literatures discussing this topic, and most existing works are mainly based on Skowron’s discernibility matrix. Till now, there are main three kinds of core attributes: core of the skowron’s discernibility matrix (denoted by Core1(C)), core of the positive region (denoted by Core2(C)), and core of the information entropy (denoted by Core3(C)). Some researchers have been pointed out that these three kinds of cores are not equivalent to each other. Based on the above three kinds of core attributes, we at first propose three kinds of simplified discernibility matrices and their corresponding cores, which are denoted by SDCore1(C), SDCore2(C) and SDCore3(C), respectively. Then it is proved that Core1(C) = SDCore1(C),Core2(C) = SDCore2(C), and Core3(C) = SDCore3(C). Finally, based on three proposed simplified discernibility matrices and their corresponding cores, it is proved that Core2(C) ⊆ Core3(C) ⊆ Core1(C).	algorithm;decision table;entropy (information theory);rough set	Bingru Yang;Zhangyan Xu;Wei Song;Zefeng Song	2008	FO & DM	10.1007/s10700-008-9044-z	core;discrete mathematics;rough set;computer science;machine learning;data mining;mathematics;algorithm;statistics;entropy	DB	-2.878914825539228	-25.632659651643507	24585
1ca6ea74b7cd5ab0c4d69cbf7d1cc763531a0405	evolving better multiple sequence alignments	cluster algorithm;time complexity;protein sequence;genetic algorithm;neighbor joining;multiple sequence alignment;molecular structure	Aligning multiple DNA or protein sequences is a fundamental step in the analyses of phylogeny, homology and molecular structure. Heuristic algorithms are applied because optimal multiple sequence alignment is prohibitively expensive. Heuristic alignment algorithms represent a practical trade-off between speed and accuracy, but they can be improved. We present EVALYN (EVolved ALYNments), a novel approach to multiple sequence alignment in which sequences are progressively aligned based on a guide tree optimized by a genetic algorithm. We hypothesize that a genetic algorithm can find better guide trees than traditional, deterministic clustering algorithms. We compare our novel evolutionary approach to CLUSTAL W and find that EVALYN performs consistently and significantly better as measured by a common alignment scoring technique. Additionally, we hypothesize that evolutionary guide tree optimization is inherently efficient and has less time complexity than the commonly-used neighbor-joining algorithm. We present a compelling analysis in support of this scalability hypothesis.	clustalw/clustalx;cluster analysis;genetic algorithm;heuristic;homology (biology);iterative and incremental development;mathematical optimization;multiple sequence alignment;neighbor joining;peptide sequence;phylogenetics;scalability;time complexity	Luke Sheneman;James A. Foster	2004		10.1007/978-3-540-24854-5_45	time complexity;mathematical optimization;genetic algorithm;molecule;multiple sequence alignment;computer science;bioinformatics;machine learning;protein sequencing;sequence alignment;neighbor joining;alignment-free sequence analysis	Comp.	-0.403722444214441	-50.582849394683976	24677
2aff68cf1166fac1d22b3ac8eeea29d915a1b8d7	variable-chromosome-length genetic algorithm for time series discretization		The symbolic aggregate approximation method (SAX) of time series is a widely-known dimensionality reduction technique of time series data. SAX assumes that normalized time series have a high-Gaussian distribution. Based on this assumption SAX uses statistical lookup tables to determine the locations of the breakpoints on which SAX is based. In a previous work, we showed how this assumption oversimplifies the problem, which may result in high classification errors. We proposed an alternative approach, based on the genetic algorithms, to determine the locations of the breakpoints. We also showed how this alternative approach boosts the performance of the original SAX. However, the method we presented has the same drawback that existed in the original SAX; it was only able to determine the locations of the breakpoints but not the corresponding alphabet size, which had to be input by the user in the original SAX. In the method we previously presented we had to run the optimization process as many times as the range of the alphabet size. Besides, performing the optimization process in two steps can cause overfitting. The novelty of the present work is twofold; first, we extend a version of the genetic algorithms that uses chromosomes of different lengths. Second, we apply this new version of variable-chromosome-length genetic algorithm to the problem at hand to simultaneously determine the number of the breakpoints, together with their locations, so that the optimization process is run only once. This speeds up the training stage and also avoids overfitting. The experiments we conducted on a variety of datasets give promising results.	discretization;genetic algorithm;time series	Muhammad Marwan Muhammad Fuad	2016		10.1007/978-3-319-44406-2_35	discretization error;discretization;discretization of continuous features	AI	7.620013162584099	-42.61475382517229	24781
9bd65867b47e20a02027ad094e2d2918a9a88c20	a comparative study of artificial intelligent techniques in the detection of coronary artery disease	artificial intelligence coronary arteriosclerosis artificial neural networks acoustic signal detection fuzzy logic biological neural networks arteries intelligent networks expert systems medical diagnostic imaging;generalisation capability artificial intelligent techniques coronary artery disease expert system fuzzy logic neural networks knowledge base;expert systems;neural networks;neural nets;arteries;coronary arteriosclerosis;generalisation capability;artificial intelligent techniques;medical expert systems;artificial intelligent;fuzzy logic;coronary artery disease;artificial neural networks;diagnostic expert systems;acoustic signal detection;diagnostic expert systems fuzzy logic neural nets medical expert systems;artificial intelligence;intelligent networks;biological neural networks;medical diagnostic imaging;neural network;knowledge base;expert system	This paper presents a comparative study of expert system, fuzzy logic and neural networks in the detection of coronary artery disease. It is evident from this study that expert systems can be useful in training and providing expert assistance to the user. Fuzzy logic simplifies the knowledge base in the system. Neural networks are faster and have generalisation capability. >		R. Jain;J. Mazumdar;W. Moran	1995		10.1109/ETD.1995.403483	engineering;artificial intelligence;neuro-fuzzy;machine learning;data mining	Robotics	5.5125191131166025	-28.574567292908647	24788
deacc7595f6fc07d2b214f693cc19ce664b61434	inferring gene regulatory networks from expression data with prior knowledge by linear programming	biological studies;genomics;gene regulatory network inference;sparse linkages;gene regulatory networks;biological system modeling;inference mechanisms;prior knowledge;gene expression data;satisfiability;genetics;gene expression;simulation experiment;sparsity;linear programming;linear program;optimization;biological system modeling genetics;linear programming bioinformatics genomics inference mechanisms;gene regulatory network;linear programming gene regulatory network inference gene expression sparsity prior knowledge;optimization model;inferring;sparse linkages linear programming gene regulatory networks gene expression data biological studies optimization inferring;bioinformatics	Inferring gene regulatory networks from gene expression data is an important task in biological studies. In this work, we proposed an optimization model to infer regulatory relations among the functional genes from expression data based on the structural spar-sity and/or prior knowledge. Specifically, we achieved the structural sparsity of the network by implementing a linear programming model, which also satisfies the conditions of the existing knowledge. The gene regulatory network is reconstructed by enforcing the sparse linkages with the consistency to the prior knowledge. The effectiveness of the method are demonstrated by several simulated experiments.	experiment;gene regulatory network;linear programming;mathematical optimization;programming model;sparse matrix	Zhi-Ping Liu;Xiang-Sun Zhang;Luonan Chen	2010	2010 International Conference on Machine Learning and Cybernetics	10.1109/ICMLC.2010.5580748	gene regulatory network;computer science;bioinformatics;linear programming;machine learning;data mining	Comp.	7.452276807563913	-51.40535439305863	24815
2520e74d1339df6d60e01b616282deca7c18fda7	feature selection with redundancy-complementariness dispersion	classification;redundancy;期刊论文;pairwise approximation;feature selection;relevance;redundancy complementariness dispersion	Feature selection has attracted significant attention in data mining and machine learning in the past decades. Many existing feature selection methods eliminate redundancy by measuring pairwise inter-correlation of features, whereas the complementariness of features and higher inter-correlation among more than two features are ignored. In this study, a modification item concerning the complementariness of features is introduced in the evaluation criterion of features. Additionally, in order to identify the interference effect of already-selected False Positives (FPs), the redundancy-complementariness dispersion is also taken into account to adjust the measurement of pairwise inter-correlation of features. To illustrate the effectiveness of proposed method, classification experiments are applied with four frequently used classifiers on ten datasets. Classification results verify the superiority of proposed method compared with five representative feature selection methods.	algorithm;causality;data envelopment analysis;data mining;experiment;feature selection;first-order predicate;heuristic (computer science);imperative programming;interference (communication);machine learning;order of approximation;relevance;subscriber identity module	Zhijun Chen;Chaozhong Wu;Yishi Zhang;Zhen Huang;Bin Ran;Ming Zhong;Nengchao Lyu	2015	Knowl.-Based Syst.	10.1016/j.knosys.2015.07.004	relevance;minimum redundancy feature selection;biological classification;computer science;machine learning;pattern recognition;data mining;redundancy;feature selection;feature	AI	11.999260880519415	-44.142310323520945	24908
8dcdfd8e5d65a185534196ae443c83a472954d72	ordered treemap layouts	dynamic change;stock market;data visualization clustering algorithms displays computer science electronic switching systems read only memory monte carlo methods testing filling;hierarchical data;information visualization;testing;filling;hierarchies;trees;treemaps;displays;data visualization;clustering algorithms;electronic switching systems;computer science;ordered treemaps;monte carlo;read only memory;monte carlo methods;aspect ratio	Treemaps, a space-filling method of visualizing large hierarchical data sets, are receiving increasing attention. Several algorithms have been proposed to create more useful displays by controlling the aspect ratios of the rectangles that make up a treemap. While these algorithms do improve visibility of small items in a single layout, they introduce instability over time in the display of dynamically changing data, and fail to preserve an ordering of the underlying data. This paper introduces the ordered treemap, which addresses these two shortcomings. The ordered treemap algorithm ensures that items near each other in the given order will be near each other in the treemap layout. Using experimental evidence from Monte Carlo trials, we show that compared to other layout algorithms ordered treemaps are more stable while maintaining relatively low aspect ratios of the constituent rectangles. A second test set uses stock market data.	algorithm;hierarchical database model;instability;monte carlo method;test set;treemapping	Ben Shneiderman;Martin Wattenberg	2001		10.1109/INFVIS.2001.963283	simulation;information visualization;computer science;theoretical computer science;data mining;data visualization;statistics;monte carlo method	ML	-2.9057156214430186	-42.982398401776926	24928
a939f2269853e91ad9675d184ecd24b4f5e33fbc	digital multiplierless implementation of the biological fitzhugh-nagumo model	piecewise linear model;field programmable gate array fpga;spiking neural network;model;fitzhugh nagumo fhn	High accuracy implementation of biological neural networks (NN) is a task with high computational overheads, especially in the case of large scale realizations of neuromorphic algorithms. This paper presents a set of piecewise linear FitzHugh Nagumo (FHN) models, which can reproduce different behaviors, similar to the biological neuron. This paper presents a set of equations as a model to describe the mechanisms of a single neuron, which are implementable on digital platforms. Simulation results show that the model can reproduce different behaviors of the neuron. The proposed models are investigated, in terms of digital implementation feasibility and computational overhead, targeting low cost hardware realization. Hardware synthesis and physical implementations on FPGA show that the proposed models can produce a range of neuron behaviors with higher performance and lower implementation costs compared to the original model. & 2015 Elsevier B.V. All rights reserved.	algorithm;artificial neural network;field-programmable gate array;fitzhugh–nagumo model;neuromorphic engineering;neuron;overhead (computing);piecewise linear continuation;signal processing;simulation	Moslem Nouri;Gholamreza Karimi;Arash Ahmadi;Derek Abbott	2015	Neurocomputing	10.1016/j.neucom.2015.03.084	simulation;computer science;theoretical computer science;machine learning;spiking neural network	AI	17.292224405404554	-25.0656163840062	24955
749f0e86d68deaaa0180bfd8187ce8dee032d2d2	fast generalized cross-validation algorithm for sparse model learning	metodo cuadrado menor;algorithme rapide;methode moindre carre;calcul neuronal;neural computation;learning algorithm;validacion cruzada;least squares method;linear regression model;competitive algorithms;linear regression;algorithme apprentissage;smoothing parameter;generalized cross validation;orthogonal least square;algorithme competitif;fast algorithm;relevance vector machine;validation croisee;regresion lineal;school of automation;cross validation;incremental algorithm;reseau neuronal;algoritmo aprendizaje;algoritmo rapido;parametre lissage;regression lineaire;red neuronal;computacion neuronal;algorithme incremental;computer science automation formerly;neural network	We propose a fast, incremental algorithm for designing linear regression models. The proposed algorithm generates a sparse model by optimizing multiple smoothing parameters using the generalized cross-validation approach. The performances on synthetic and real-world data sets are compared with other incremental algorithms such as Tipping and Faul's fast relevance vector machine, Chen et al.'s orthogonal least squares, and Orr's regularized forward selection. The results demonstrate that the proposed algorithm is competitive.	algorithm;cross reactions;cross-validation (statistics);dynamic problem (algorithms);entity–relationship model;increment;least squares;performance;relevance vector machine;smoothing (statistical technique);sparse matrix;stepwise regression;synthetic intelligence;triangulation	S. Sundararajan;Shirish K. Shevade;S. Sathiya Keerthi	2007	Neural Computation	10.1162/neco.2007.19.1.283	computer science;linear regression;artificial intelligence;machine learning;mathematics;artificial neural network;algorithm;population-based incremental learning	ML	12.030831056750365	-30.46541625434528	24957
20532b1f80b509f2332b6cfc0126c0f80f438f10	a deep matrix factorization method for learning attribute representations	face clustering algorithms matrix decomposition data models algorithm design and analysis feature extraction face recognition;0801 artificial intelligence and image processing;journal article;face classification semi nmf deep semi nmf unsupervised feature learning face clustering semi supervised learning wsf matrix factorization;face classification semi nmf deep semi nmf unsupervised feature learning face clustering semi supervised learning deep wsf wsf matrix factorization;0906 electrical and electronic engineering;0806 information systems;artificial intelligence image processing;mixed attribute knowledge deep matrix factorization method learning attribute representations seminonnegative matrix factorization low dimensional dataset representation clustering interpretation data matrix complex hierarchical information implicit lower level hidden attributes classical one level clustering methodology deep seminmf model semisupervised learning algorithm deep wsf;pattern clustering learning artificial intelligence matrix decomposition	Semi-Non-negative Matrix Factorization is a technique that learns a low-dimensional representation of a dataset that lends itself to a clustering interpretation. It is possible that the mapping between this new representation and our original data matrix contains rather complex hierarchical information with implicit lower-level hidden attributes, that classical one level clustering methodologies cannot interpret. In this work we propose a novel model, Deep Semi-NMF, that is able to learn such hidden representations that allow themselves to an interpretation of clustering according to different, unknown attributes of a given dataset. We also present a semi-supervised version of the algorithm, named Deep WSF, that allows the use of (partial) prior information for each of the known attributes of a dataset, that allows the model to be used on datasets with mixed attribute knowledge. Finally, we show that our models are able to learn low-dimensional representations that are better suited for clustering, but also classification, outperforming Semi-Non-negative Matrix Factorization, but also other state-of-the-art methodologies variants.	cluster analysis;experiment;face;forty nine;high- and low-level;multi-source;name;non-negative matrix factorization;numerous;semiconductor industry;sense of identity (observable entity);silo (dataset);spatial variability;speech disorders;speech recognition;algorithm;anatomical layer;research study;statistical cluster	George Trigeorgis;Konstantinos Bousmalis;Stefanos P. Zafeiriou;Björn W. Schuller	2017	IEEE Transactions on Pattern Analysis and Machine Intelligence	10.1109/TPAMI.2016.2554555	computer science;machine learning;pattern recognition;data mining;cluster analysis;conceptual clustering	ML	22.193819108824044	-44.276795012451636	24983
daff621207314691dbb250ded13cdbb96a69f9a2	balanced relative margin machine - the missing piece between fda and svm classification	support vector machines;kernel methods;regularization;mathematical programming;linear discriminant analysis	We suggest a new method called BRMM by modifying the existing RMM.The new method generalizes other well-known methods (SVM, RFDA, SVR).We prove and visualize the connections to the other methods.We suggest a sparse BRMM and prove an upper bound on the number of features. In this theoretical work we approach the class of relative margin classification algorithms from the mathematical programming perspective. In particular, we propose a Balanced Relative Margin Machine (BRMM) and then extend it by a 1-norm regularization. We show that this new classifier concept connects Support Vector Machines (SVM) with Fisher's Discriminant Analysis (FDA) by the insertion of a range parameter. It is also strongly connected to the Support Vector Regression. Using this BRMM it is now possible to optimize the classifier type instead of choosing it beforehand. We verify our findings empirically by means of simulated and benchmark data.	support vector machine	Mario Michael Krell;David Feess;Sirko Straube	2014	Pattern Recognition Letters	10.1016/j.patrec.2013.09.018	margin classifier;support vector machine;regularization;kernel method;margin;computer science;machine learning;pattern recognition;data mining;mathematics;linear discriminant analysis;structured support vector machine;statistics	Vision	13.94681018358498	-40.390780907620425	25079
8faf13ed01e7cbe0ca22754434bb28e1ebbdeb90	an improved categorization of classifier's sensitivity on sample selection bias	decision trees classifier sensitivity categorization sample selection bias classifier learning bayesian classifier logistic regression hard margin support vector machine naive bayes;bayesian classifier;learning algorithm;decision tree;support vector machines;bayes methods;naive bayes;decision trees pattern classification learning artificial intelligence bayes methods regression analysis support vector machines;logistic regression;feature vector;bayesian methods logistics decision trees computer science training data data mining testing classification tree analysis regression tree analysis support vector machines;pattern classification;regression analysis;sample selection bias;learning artificial intelligence;decision trees;selection bias	"""A recent paper categorizes classifier learning algorithms according to their sensitivity to a common type of sample selection bias where the chance of an example being selected into the training sample depends on its feature vector x but not (directly) on its class label y. A classifier learner is categorized as """"local"""" if it is insensitive to this type of sample selection bias, otherwise, it is considered """"global"""". In that paper, the true model is not clearly distinguished from the model that the algorithm outputs. In their discussion of Bayesian classifiers, logistic regression and hard-margin SVMs, the true model (or the model that generates the true class label for every example) is implicitly assumed to be contained in the model space of the learner, and the true class probabilities and model estimated class probabilities are assumed to asymptotically converge as the training data set size increases. However, in the discussion of naive Bayes, decision trees and soft-margin SVMs, the model space is assumed not to contain the true model, and these three algorithms are instead argued to be """"global learners"""". We argue that most classifier learners may or may not be affected by sample selection bias; this depends on the dataset as well as the heuristics or inductive bias implied by the learning algorithm and their appropriateness to the particular dataset."""	algorithm;bayesian network;categorization;converge;decision tree;feature vector;heuristic (computer science);inductive bias;logistic regression;machine learning;naive bayes classifier;norm (social);selection bias;test set;verification and validation	Wei Fan;Ian Davidson;Bianca Zadrozny;Philip S. Yu	2005	Fifth IEEE International Conference on Data Mining (ICDM'05)	10.1109/ICDM.2005.24	naive bayes classifier;selection bias;computer science;machine learning;decision tree;pattern recognition;data mining	ML	16.486915593445474	-38.67729443491858	25145
188aef346ae7b0a28b12afbc168dda477a905385	pac generalization bounds for co-training	unlabeled data;generalization error;maximum likelihood;rule based;objective function;probability distribution;global optimization;local minima;em algorithm;training algorithm;generalization bounds	The rule-based bootstrapping introduced by Yarowsky, and its cotraining variant by Blum and Mitchell, have met with considerable empirical success. Earlier work on the theory of co-training has been only loosely related to empirically useful co-training algorithms. Here we give a new PAC-style bound on generalization error which justifies both the use of confidences — partial rules and partial labeling of the unlabeled data — and the use of an agreement-based objective function as suggested by Collins and Singer. Our bounds apply to the multiclass case, i.e., where instances are to be assigned one of labels for .	algorithm;blum axioms;co-training;generalization error;logic programming;loss function;mitchell corporation;optimization problem	Sanjoy Dasgupta;Michael L. Littman;David A. McAllester	2001			probability distribution;expectation–maximization algorithm;computer science;machine learning;maxima and minima;pattern recognition;mathematics;maximum likelihood;statistics;global optimization;generalization error	ML	20.561078154887458	-35.028803329821926	25146
148b9948b63b06bb9044737d8ba750be6e52c424	label ranking by learning pairwise preferences	minimisation;correlacion;minimization;competitividad;complex structure;minimizacion;intelligence artificielle;natural extension;fonction perte;funcion perdida;ranking function;ranking by pairwise comparison;hierarchical classification;round robin;ranking;learning scenario;mathematical programming;voting;loss function;preference learning;competitiveness;preferencia;classification hierarchique;artificial intelligence;preference;voto;inteligencia artificial;correlation;vote;pairwise classification;competitivite;programmation mathematique;clasificacion jerarquizada;rank correlation;programacion matematica;partial order;constraint classification	Preference learning is a challenging problem that involves the prediction of complex structures, such as weak or partial order relations, rather than single values. In the recent literature, the problem appears in many different guises, which we will first put into a coherent framework. This work then focuses on a particular learning scenario called label ranking, where the problem is to learn a mapping from instances to rankings over a finite number of labels. Our approach for learning such a ranking function, ranking by pairwise comparison (RPC), first induces a binary preference relation from suitable training data using a natural extension of pairwise classification. A ranking is then derived from the learned relation relation by means of a ranking procedure, whereby different ranking functions can be used for minimizing different loss functions. In particular, we show that weighted voting minimizes the Spearman rank correlation. Finally, we compare RPC to constraint classification, an alternative approach to label ranking, and show empirically and theoretically that RPC is computationally more efficient.	algorithm;coherence (physics);computation;computational complexity theory;experiment;loss function;machine learning;preference learning;ranking (information retrieval);schedule (computer science);statistical classification	Eyke Hüllermeier;Johannes Fürnkranz;Weiwei Cheng;Klaus Brinker	2008	Artif. Intell.	10.1016/j.artint.2008.08.002	partially ordered set;minimisation;preference learning;voting;ranking;computer science;artificial intelligence;machine learning;pattern recognition;data mining;generalized complex structure;mathematics;ranking svm;correlation;rank correlation;electoral-vote.com;loss function	ML	11.115707315281151	-33.396969410357165	25204
695a3652c5312d2cb277bd0585da778921f57fe4	enhanced cooperative co-evolution genetic algorithm for rule-based pattern classification	soft computing;rule based;pattern classification;genetic algorithm;classifiers;genetic algorithms;cooperative co evolution	Genetic algorithms (GAs) have been widely used as soft computing techniques in various application domains, while cooperative co-evolution algorithms were proposed in the literature to improve the performance of basic GAs. In this paper, an enhanced cooperative co-evolution genetic algorithm (ECCGA) is proposed for rule-based pattern classification. Concurrent local and global evolution and conclusive global evolution are proposed to improve further the classification performance. Different approaches of ECCGA are evaluated on benchmark classification data sets, and the results show that ECCGA can achieve better performance than the cooperative co-evolution genetic algorithm and normal GA.	benchmark (computing);evolution;genetic algorithm;logic programming;software release life cycle;statistical classification	Fangming Zhu;Steven Guan	2008		10.1007/978-3-540-87656-4_15	genetic algorithm;computer science;artificial intelligence;machine learning;genetic representation;pattern recognition;data mining;soft computing	AI	9.47330645233422	-40.97727510331027	25276
ef2389b7981f566806e06ea815f51c9e35ff48b1	learning concepts in parallel based upon the strategy of version space	tratamiento paralelo;training analysis;algoritmo paralelo;generalizacion;learning algorithm;parallel algorithm;traitement parallele;version space;time complexity;hypothese;configuration management learning artificial intelligence parallel algorithms computational complexity generalisation artificial intelligence;apprentissage conceptuel;metodo dividir para vencer;parallel learning;specialization process concept learning parallel version space learning algorithm divide and conquer method time complexity training instances application domains bounded processor number generalization process hypothesis;parallel version space learning algorithm;indexing terms;algorithme parallele;training instance;learning algorithm design and analysis concurrent computing parallel processing performance analysis artificial intelligence costs councils computer science information science;hipotesis;methode diviser pour gagner;complexite temps;generalisation;aprendizaje conceptual;bounded processor number;theoretical analysis;computational complexity;application domains;divide and conquer method;generalization process;concept learning;learning problems;psychanalyse didactique;generalisation artificial intelligence;hypothesis;learning artificial intelligence;complejidad tiempo;article;configuration management;divide and conquer;generalization;training instances;parallel processing;specialization process;psicoanalisis didactico;parallel algorithms	AbstructIn this paper, we have attempted to apply the technique of parallel processing to concept learning. A parallel version-space learning algorithm based upon the principle of divide-and-conquer is proposed. Its time complexity is analyzed to be O(klog, n ) with n processors, where n is the number of given training instances and b is a coefficient depending on application domains. For a bounded number of processors in the real situations, a modified parallel learning algorithm is then proposed. Experimental results are then performed on a real learning problem, showing our parallel learning algorithm works and being quite consistent with results of theoretic analysis. We have finally concluded that when the number of training instances is large, it is worth learning in parallel because of its faster execution.	algorithm;central processing unit;coefficient;concept learning;parallel computing;theory;time complexity	Tzung-Pei Hong;Shian-Shyong Tseng	1994	IEEE Trans. Knowl. Data Eng.	10.1109/69.334877	semi-supervised learning;generalization;parallel processing;multi-task learning;instance-based learning;concept learning;wake-sleep algorithm;computer science;artificial intelligence;theoretical computer science;online machine learning;machine learning;data mining;mathematics;parallel algorithm;stability;active learning;algorithm;population-based incremental learning;generalization error	ML	10.842292179248862	-31.179275067438585	25350
c7889786d1cafe3c8c16ef55e5429afe7c338da0	the application of alternative splicing graphs in quantitative analysis of alternative splicing form from est database	splicing;alternative splicing;base donnee;rna splicing;empalme;epissage alternatif;temps lineaire;database;linear time algorithm;base dato;empalme alternativo;tiempo lineal;weighted alternative splicing graph;protein diversity;algorithme;single gene;algorithm;epissage;programacion lineal;marqueur est;molecular biology;linear time;linear programming;alternative splicing form;graph algorithm;quantitative analysis;programmation lineaire;linear program;algorithms;experimental validation;est;marcador est;splicing graph;expressed sequence tag;expressed sequence tag est;algoritmo	Alternative splicing of a single pre-mRNA can give rise to different mRNA transcripts. Alternative splicing of pre-messenger RNA is an important layer of gene expression regulation in eukaryotic cell. Consequently, alternative splicing is an important mechanism for generating protein diversity from a single gene. Although alternative splicing is an important biological process, standard molecular biology techniques have only identified several hundred alternative splicing variants and create a bottleneck in terms of experimental validation. In this paper, we propose methods of obtaining models of weighted alternative splicing graphs and ways of generating all alternative splicing forms from a weighted alternative splicing graph and formulate linear programming models and use the popular linear programming solver to obtain the quantitative distributions of various alternative splicing forms. Basically, the method uses the UniGene clusters of human expressed sequence tags (ESTs) to identify alternative splicing sites. Furthermore, we propose linear time algorithms that correctly produce all possible alternative splicing variants with their corresponding probabilities. Using these methods, we infer several sets of putative alternative splicing forms; these results are then compared with methods proposed by others. Then by aligning sequences of EST database to the genomic data, we identify locations of exons as well as the alternative splicing sites. To quantify these putative alternative splicing forms, we choose segments in genome to count the EST number, and combine the information of EST and alternative splicing form by constructing the suitable linear programming model.	algorithm;gene expression profiling;linear programming;programming model;sequence alignment;solver;time complexity;unigene	Hsun-Chang Chang;Po-Shun Yu;Tze-Wei Huang;Fang-Rong Hsu;Yaw-Ling Lin	2004	Proceedings. Fourth IEEE Symposium on Bioinformatics and Bioengineering	10.1504/IJCAT.2005.006799	computer science;bioinformatics;linear programming;rna splicing	Comp.	-0.5475773228441919	-51.0635614111754	25371
55c0acc72e22927f52fdadf0a8af3eb49b49186c	decision tree using class-dependent feature subsets	decision tree;classifier system;clasificador;arbol decision;classifier;pattern recognition;classificateur;feature selection;reconnaissance forme;reconocimiento patron;arbre decision;selection forme	In pattern recognition, feature selection is an important technique for reducing the measurement cost of features or for improving the performance of classifiers, or both. Removal of features with no discriminative information is effective for improving the precision of estimated parameters of parametric classifiers. Many feature selection algorithms choose a feature subset that is useful for all classes in common. However, the best feature subset for separating one group of classes from another may depend on groups. In this study, we investigate the effectiveness of choosing feature subsets depending on groups of classes (class-dependent features), and propose a classifier system that is built as a decision tree in which nodes have class-dependent feature subsets.	decision tree	Kazuaki Aoki;Mineichi Kudo	2002		10.1007/3-540-70659-3_80	feature;classifier;computer science;machine learning;decision tree;pattern recognition;data mining;mathematics;feature selection;feature	NLP	10.565024423554569	-34.270290409734486	25396
ddceb821e0662a00f92e0ea5c8251fa1c2de1e0f	an introduction to support vector machines: a review	support vector machine	In the preface of the book, Cristianini and Shawe-Taylor state that their intention is to present an organic, integrated introduction to support vector machines (SVMs). The authors believe that SVMs are a topic now sufficiently mature that it should be viewed as its own subfield of machine learning. SVMs, first introduced by Vladimir Vapnik, are a type of linear learning machines much like the famous perceptron algorithm and, thus, function to classify input patterns by first being trained on labeled data sets (supervised learning). However, SVMs represent a significant enhancement in function over perceptrons. The power of SVMs lies in their use of nonlinear kernel functions that implicitly map input into high-dimensional feature spaces. In the high-dimensional feature spaces, linear classifications are possible; they become nonlinear in the transformation back to the original input space. Thus, although SVMs are linear learning machines with respect to the high-dimensional feature spaces, they are in effect nonlinear classifiers. The authors review and synthesize a wide range of materials, including the dual representation characteristic of linear learning machines, feature spaces, learning theory, generalization theory, and optimization theory, that are necessary for a comprehensive introduction to SVMs. The topics are introduced in an iterative and problem-triggered manner: Problems are presented, followed by concepts the last section of chapter 2, the dual representation of linear learning machines is introduced. Dual representation is one of the crucial concepts in developing SVMs. The limited computational power of linear learning machines leads to the topic of the third chapter, “Kernel-Induced Feature Spaces.” To increase the computational power of the linear learning machines, nonlinear mappings can be used to transform the data into a high-dimensional feature space in which a linear learning methodology is then applied. Kernel functions can implicitly combine these two steps (nonlinear mapping and linear learning) into one step in constructing a nonlinear learning machine. A linearly inseparable problem can become linearly separable in a higher-dimensional feature space. As a consequence of the dual representation of linear learning machines, the dimension of the feature space need not affect the computation because only the inner product is computed by evaluating the kernel function. The use of kernel functions is an attractive computational shortcut. The use of kernel functions to construct nonlinear learning machines greatly increases the expressive power of learning machines and retains the underlying linearity that ensures the tractability of learning. However, the increased flexibility increases the risk of overfitting, which can lead to bad generalization performance. Chapter 4, “Generalization Theory,” introduces the theory of Vapnik and Chervonenkis (VC) to control the increased flexibility of kernel-induced feature space and lead to good generalization. Loosely speaking, the most important result of VC theory is that the upper bound of the generalization risk for a learning machine is controlled by the empirical risk and the VC dimension, which is fixed for a hypothesis space of the learning machine. The theory presented in chapter 4 shows that the learning machine with the lowest upper bound of generalization risk is achieved by selecting a machine that minimizes the empirical risk. This discussion sets An Introduction to Support Vector Machines	alexey chervonenkis;algorithm;computation;feature vector;iterative method;keyboard shortcut;linear logic;linear separability;machine learning;mathematical optimization;nonlinear system;overfitting;perceptron;separable polynomial;spaces;supervised learning;support vector machine;vc dimension;vapnik–chervonenkis theory	Yiling Chen;Isaac G. Councill	2003	AI Magazine		support vector machine;computer science;artificial intelligence;data science;engineering physics	ML	20.560614639586852	-34.199782938920464	25570
f7482769eafee77371b83e5f9db242cb9094597e	fast training of support vector machines for regression	loss measurement;quadratic programming;block toeplitz matrices;neural nets learning artificial intelligence statistical analysis quadratic programming toeplitz matrices;kernel;interpolation;quadratic program;constraint optimization;learning;support vector machines;neural nets;gradient computation;multilayer perceptrons;neural nets support vector machines regression gradient computation learning constrained quadratic programming problem block toeplitz matrices matrix vector products;support vector machines kernel quadratic programming interpolation grid computing constraint optimization multilayer perceptrons loss measurement hilbert space extraterrestrial measurements;matrix vector products;hilbert space;regression;statistical analysis;constrained quadratic programming problem;support vector machine;learning artificial intelligence;extraterrestrial measurements;grid computing;toeplitz matrices	We propose a fast way to perform the gradient computation in Support Vector Machine (SVM) learning, when samples are positioned on an m-dimensional grid. Our method takes advantage of the particular structure of the constrained quadratic programming problem arising in this case. We show how such structure is connected to the properties of block Toeplitz matrices and how they can be used to speed-up the computation of matrix-vector products.	support vector machine	Davide Anguita;Andrea Boni;Stefano Pace	2000		10.1109/IJCNN.2000.861459	support vector machine;least squares support vector machine;mathematical optimization;discrete mathematics;computer science;machine learning;mathematics;quadratic programming	ML	23.25393312360053	-37.447001197294334	25588
59c94f4639d04c7437ebdbf6f70ce5f53b15b695	calculation of multi-category minimum distance classifier recognition error for binomial measurement distributions	minimum distance	Abstract   This paper presents an algorithm for calculating recognition error for minimum Hamming distance classifiers, a special case of the Bayes (optimum) classifier under certain constraints. The error rate algorithm is derived for the two-category case when the binary components of the measurement vector are binomially distributed. The algorithm is easily extended to the multi-category case when the ratio of total measurements to measurements used per dichotomization is large.  A number of categorizers were designed using conventional methods and actual quantized typewritten characters. The recognition error was calculated:   1.   (1) theoretically, using the algorithm; and   2.   (2) experimentally, using an independent test set of characters for the categorizers.   #N# Both sets of results are presented for comparison, verifying the ability of the algorithnm to predict recognition error of categorizers.		Robert M. Bowman;Eugene S. McVey	1972	Pattern Recognition	10.1016/0031-3203(72)90006-4	computer science;machine learning;pattern recognition;mathematics;statistics	Vision	16.13917872296198	-43.07670616121892	25649
467d5a66f414ea9eae37020739528019b34e74da	encoding subcomponents in cooperative co-evolutionary recurrent neural networks	high dimensionality;decomposition method;genetic algorithm;genetic algorithms;grammatical inference;neuro evolution;recurrent neural networks;recurrent neural network;evolutionary algorithm;cooperative coevolution;group interaction;neural network	Cooperative coevolution employs evolutionary algorithms to solve a high-dimensional search problem by decomposing it into low-dimensional subcomponents. Efficient problem decomposition methods or encoding schemes group interacting variables into separate subcomponents in order to solve them separately where possible. It is important to find out which encoding schemes efficiently group separability. This paper introduces a novel encoding scheme in cooperative coevolution for training recurrent neural networks. The method is tested on grammatical inference problems. The results show that the proposed encoding scheme achieves better performance when compared to a previous encoding scheme. & 2011 Elsevier B.V. All rights reserved.	artificial neural network;cooperative coevolution;evolutionary algorithm;grammar induction;interaction;line code;linear separability;network topology;neurocomputing;programming paradigm;recurrent neural network;search problem;synapse	Rohitash Chandra;Marcus R. Frean;Mengjie Zhang;Christian W. Omlin	2011	Neurocomputing	10.1016/j.neucom.2011.05.003	genetic algorithm;computer science;artificial intelligence;recurrent neural network;machine learning;evolutionary algorithm;pattern recognition;artificial neural network	AI	15.003690814026736	-24.45226220334877	25689
d90fe6d3ee1fbd6164cbf1ad3c82fe8a057f0cf4	exploratory multilevel hot spot analysis: australian taxation office case study	real life datasets;self organizing maps;neural networks;australian taxation office;imbalanced data;k means;conformal mapping;journal article;hot spot;drill down;visualization;cluster analysis;data visualization;taxation;clustering algorithms;data mining cluster analysis;flow visualization;sub populations;neural network;keywords data sets	Population based real-life datasets often contain smaller clusters of unusual sub-populations. While these clusters, called ‘hot spots’, are small and sparse, they are usually of special interest to an analyst. In this paper we introduce a visual drill-down SelfOrganizing Map (SOM)-based approach to explore such hot spots characteristics in real-life datasets. Iterative clustering algorithms (such as k-means) and SOM are not designed to show these small and sparse clusters in detail. The feasibility of our approach is demonstrated using a large real life dataset from the Australian Taxation Office.	algorithm;cluster analysis;data drilling;exploratory testing;hot spare;k-means clustering;population;real life;sparse matrix;the australian	Denny;Graham J. Williams;Peter Christen	2007			computer science;bioinformatics;data science;machine learning;data mining;cluster analysis;artificial neural network	ML	0.5900749366319791	-39.200513623895816	25706
1023278072c6a12cda93cc20b0b4cf7d024fb695	quality-relevant fault detection of nonlinear processes based on kernel concurrent canonical correlation analysis		Canonical correlation analysis (CCA) has been used for concurrent quality and process monitoring to extract multidimensional correlation structure between process and quality variables. In this paper, a new kernel concurrent CCA (KCCCA) algorithm is proposed for quality-relevant nonlinear process monitoring, which decomposes the original space into five subspaces, including correlation subspace, quality-principal subspace, quality-residual subspace, process-principal subspace and process-residual subspace. The proposed KCCCA considers the nonlinearity in both process and quality variables, and incorporates a regularization term as well for numerical robustness. In the case studies, the Tennessee Eastman process is employed to demonstrate the effectiveness of the proposed KCCCA.	algorithm;algorithmic efficiency;computation;fault detection and isolation;kernel (operating system);nonlinear system;robustness (computer science);simulation	Qinqin Zhu;Qiang Liu;S. Joe Qin	2017	2017 American Control Conference (ACC)	10.23919/ACC.2017.7963795	linear subspace;random subspace method;kernel principal component analysis;computer science;kernel (linear algebra);canonical correlation;fault detection and isolation;principal component analysis;artificial intelligence;subspace topology;pattern recognition	EDA	23.51929432037041	-24.46974909971759	25745
a2922e5ab4ad25db53ec4d571ad957dce8b73ad0	unsupervised data clustering and image segmentation using natural computing techniques	unsupervised learning;pattern clustering;swarm intelligence;image segmentation;fuzzy k means;pso algorithm;neural nets;natural computing;unsupervised learning fuzzy set theory genetic algorithms image classification image segmentation image texture neural nets particle swarm optimisation pattern clustering;k means;fuzzy k means algorithm;image classification;brainweb system;image intensity segmentation;unsupervised data clustering;image segmentation clustering algorithms particle swarm optimization biology computing genetic algorithms fuzzy neural networks data analysis evolution biology iris image texture;data mining;fuzzy set theory;genetics;complex optimization problem;image texture;data clustering;optimization problem;natural computing technique;brainweb system unsupervised data clustering image intensity segmentation natural computing technique nc approach evolutionary computing technique genetic algorithm particle swarm optimization algorithm pso algorithm neural network classification problem data analysis evolutionary biology individual to population adaptation swarm intelligence complex optimization problem fuzzy k means algorithm uci dataset image texture;data analysis;particle swarm optimizer;individual to population adaptation;evolutionary biology;particle swarm optimization;evolutionary computing technique;classification algorithms;clustering algorithms;genetic algorithm;genetic algorithms;classification problem;optimization;evolutionary techniques;particle swarm optimization algorithm;particle swarm optimisation;natural computing unsupervised data clustering image segmentation evolutionary techniques genetic algorithms particle swarm optimization;uci dataset;nc approach;neural network;evolutionary computing	Natural computing (NC) is a novel approach to solve real life problems inspired in the life itself. A diversity of algorithms had been proposed such as evolutionary techniques, genetic algorithms and particle swarm optimization (PSO). These approaches, together with fuzzy and neural networks, give powerful tools for researchers in a diversity of problems of optimization, classification, data analysis and clustering. This paper presents concepts and experimental results of approaches to data clustering and image segmentation using NC approaches. The main focus are on evolutionary computing, which is based on the concepts of the evolutionary biology and individual-to-population adaptation, and swarm intelligence, which is inspired in the behavior of individuals, together, try to achieve better results for a complex optimization problem. Genetic and PSO based K-means and fuzzy K-means algorithms are described. Results are shown for data clustering using UCI datasets such as Ruspini, Iris and Wine and for image texture and intensity segmentation using images from BrainWeb system.	approximation algorithm;artificial neural network;cluster analysis;evolutionary computation;genetic algorithm;image segmentation;image texture;k-means clustering;mathematical optimization;natural computing;optimization problem;particle swarm optimization;real life;statistical classification;swarm intelligence;unsupervised learning	José Alfredo Ferreira Costa;Jackson Gomes de Souza	2009	2009 IEEE International Conference on Systems, Man and Cybernetics	10.1109/ICSMC.2009.5346039	genetic algorithm;fuzzy clustering;computer science;artificial intelligence;machine learning;pattern recognition;cluster analysis;particle swarm optimization;artificial neural network	Robotics	3.946406625697539	-41.770407260872496	25912
91c5ce538f54996410021ba1acf17f15d4bb3fdd	an efficient algorithm for inducing fuzzy rules from numerical data	time complexity;efficient algorithm;fuzzy rules;data mining;fuzzy inference;space complexity;fuzzy if then rules	This paper proposes a modified but more powerful algorithm for inducing fuzzy if-then rules from numerical data. Data mining is performed before the process of fuzzy inference in view of the presence of noise in data. Therefore, the minimum number of learning attributes can be used to induce fuzzy rules automatically from training examples. The results obtained by this modified method demonstrate that it is more efficient and effective than relevant works in aspects of time complexity and space complexity.	algorithm;dspace;data mining;feature selection;fuzzy logic;fuzzy rule;inductive reasoning;level of measurement;numerical analysis;numerical method;rule 90;rule induction;time complexity	J. N. Wu;K. C. Cheung	1998			fuzzy logic;time complexity;defuzzification;adaptive neuro fuzzy inference system;fuzzy transportation;type-2 fuzzy sets and systems;fuzzy classification;computer science;fuzzy number;neuro-fuzzy;machine learning;pattern recognition;data mining;fuzzy associative matrix;dspace;fuzzy set operations;fuzzy control system	ML	3.418021811543853	-28.980229489432013	25937
1cf7ce28f64203d1f2dab1197a30722a608bcb7f	optimising area under the roc curve using gradient descent	objective function;statistical learning;gradient descent;bayes net structure learning;roc curve;bayesian networks graphical models	This paper introduces RankOpt, a linear binary classifier which optimises the area under the ROC curve (the AUC). Unlike standard binary classifiers, RankOpt adopts the AUC statistic as its objective function, and optimises it directly using gradient descent. The problems with using the AUC statistic as an objective function are that it is non-differentiable, and of complexity O(n2) in the number of data observations. RankOpt uses a differentiable approximation to the AUC which is accurate, and computationally efficient, being of complexity O(n.) This enables the gradient descent to be performed in reasonable time. The performance of RankOpt is compared with a number of other linear binary classifiers, over a number of different classification problems. In almost all cases it is found that the performance of RankOpt is significantly better than the other classifiers tested.	algorithm;approximation;binary classification;categorization;certificate authority;computational complexity theory;document classification;document processing;gradient descent;information retrieval;john d. wiley;journal of machine learning research;logistic regression;loss function;mathematical optimization;mehryar mohri;mir:ror;nonlinear system;optimization problem;optimizing compiler;ordinal data;pattern recognition;prentice hall international series in computer science;receiver operating characteristic;relevance feedback;sequential minimal optimization;smart system;statistical learning theory;support vector machine	Alan Herschtal;Bhavani Raskutti	2004		10.1145/1015330.1015366	gradient descent;computer science;backpropagation;machine learning;pattern recognition;mathematics;stochastic gradient descent;receiver operating characteristic;statistics	ML	18.39917651101682	-38.735232527841966	26019
6f22db3739cc6a27d3932c7a82bd47dad53b3165	a neural implementation of conceptual hierarchies with bayesian reasoning	intuitive semantics;neural nets;bayes methods;stochastic simulation;conceptual hierarchies;bayesian reasoning;translating high level descriptions;translating high level descriptions bayesian reasoning conceptual hierarchies intuitive semantics neural implementation stochastic simulation;stochastic processes;neural implementation;stochastic processes bayes methods neural nets;neural network	A scheme is presented for translating high-level descriptions of conceptual hierarchies into a neural network representation. The intuitive semantics of a conceptual hierarchy is provided by a Bayesian net, and the neural network implementation provably approximates the behavior of this net under a stochastic simulation rule		Pekka Orponen;Patrik Floréen;Petri Myllymäki;Henry Tirri	1990		10.1109/IJCNN.1990.137585	computer science;theoretical computer science;machine learning;stochastic simulation;data mining;bayesian inference;artificial neural network;statistics	AI	6.7711111516311995	-29.409248635398075	26115
ff90829bff22ad7d0b465f8ef54c01dd2d8f4864	sample-efficient learning of mixtures		We consider PAC learning of probability distributions (a.k.a. density estimation), where we are given an i.i.d. sample generated from an unknown target distribution, and want to output a distribution that is close to the target in total variation distance. Let F be an arbitrary class of probability distributions, and let Fk denote the class of k-mixtures of elements of F . Assuming the existence of a method for learning F with sample complexity mF (ε), we provide a method for learning Fk with sample complexity O(k log k ·mF (ε)/ε). Our mixture learning algorithm has the property that, if the F learner is proper and agnostic, then the Fk-learner would be proper and agnostic as well. This general result enables us to improve the best known sample complexity upper bounds for a variety of important mixture classes. First, we show that the class of mixtures of k axis-aligned Gaussians in R is PAC-learnable in the agnostic setting with  ̃ O(kd/ε) samples, which is tight in k and d up to logarithmic factors. Second, we show that the class of mixtures of k Gaussians in R is PAC-learnable in the agnostic setting with sample complexity  ̃ O(kd/ε), which improves the previous known bounds of  ̃ O(kd/ε) and  ̃ O(kd/ε) in its dependence on k and d. Finally, we show that the class of mixtures of k log-concave distributions over R is PAClearnable using  ̃ O(d(d+5)/2ε−(d+9)/2k) samples.	algorithm;apache axis;concave function;probably approximately correct learning;sample complexity	Hassan Ashtiani;Shai Ben-David;Abbas Mehrabian	2018			mathematical optimization;combinatorics;probability distribution;sample complexity;density estimation;logarithm;total variation;mathematics	AI	20.698189015830184	-32.734795486582065	26215
dc48205361a421a3675aca5ee72060f51a75460e	bitmap approach to trend clustering for prediction in time series databases	databases;prediccion;evaluation performance;base donnee;performance evaluation;raster graphics;analyse tendance;evaluacion prestacion;database;base dato;trend analysis;time series;classification;similitude;clustering;serie temporelle;similarity;serie temporal;time series data;similitud;prediction;clasificacion;analisis tendencia	This paper describes a bitmap approach to clustering and prediction of trends in time-series databases. Similar trend patterns, rather than similar data patterns, are extracted from time-series database. We consider four types of matches: (1) Exact match, (2) Similarity match, (3) Exact match by shift, and (4) Similarity match by shift. Each pair of time-series data may be matched in one of these four types if this pair is similar one to another, by similarity (or sim) notion over a threshold. Matched data can be clustered by the same way of matching. To improve performance, we use the notion of center of a cluster. The radius of a cluster is used to determine whether a given time-series data is included in the cluster. We also use a new notion of dissimilarity, called dissim, to make accurate clusters. It is likely that a time-series data is in one cluster rather than in another by using both notions, sim and dissim: a data is similar to one cluster while it is dissimilar to another. For a trend sequence, the cluster that is dissimilar to that sequence is called dissimilar-cluster. For a cluster, the notion dissim can be also used to identify a set of clusters that are dissimilar to the given cluster. A prediction of a trend can be made by (1) Intra-cluster Trend Prediction that refers to the trends in the cluster as that trend is involved and (2) Inter-cluster Trend Prediction that refers to other trends in the cluster that is dissimilar to that trend. The contribution of this paper includes (1) clustering by using not only similarity match but also dissimilarity match. In this way we prevent any positive and negative failures. (2) Prediction by using not only similar trend sequences but also dissimilar trend sequences. (3) A bitmap approach can improve performance of clustering and prediction.	bitmap;bitwise operation;cluster analysis;database;time series	Jong P. Yoon;Yixin Luo;Junghyun Nam	2001		10.1117/12.421085	computer science;data science;time series;data mining	DB	-3.3129504926109554	-33.030343938564634	26334
30e17fb7adfce6ee026909296eef6846954c7b52	a bound on the error of cross validation using the approximation and estimation rates, with conseque	simulation ordinateur;eficacia sistema;model selection;optimisation;generalization error;sample size;learning algorithm;experimental analysis;validacion cruzada;optimizacion;learning;complexite calcul;performance systeme;algorithme apprentissage;backpropagation;taux estimation;system performance;fonction objectif;approximation fonction;aprendizaje;objective function;vecino mas cercano;retropropagation;complejidad computacion;apprentissage;estimation erreur;function approximation;error estimation;computational complexity;estimacion error;validation croisee;approximation rate;plus proche voisin;funcion objetivo;nearest neighbour;optimization;cross validation;simulacion computadora;perceptron;reseau neuronal;formal analysis;algoritmo aprendizaje;retropropagacion;computer simulation;estimation rate;red neuronal;taux approximation;neural network;generalization bounds	We give a theoretical and experimental analysis of the generalization error of cross validation using two natural measures of the problem under consideration. The approximation rate measures the accuracy to which the target function can be ideally approximated as a function of the number of parameters, and thus captures the complexity of the target function with respect to the hypothesis model. The estimation rate measures the deviation between the training and generalization errors as a function of the number of parameters, and thus captures the extent to which the hypothesis model suffers from overfitting. Using these two measures, we give a rigorous and general bound on the error of the simplest form of cross validation. The bound clearly shows the dangers of making the fraction of data saved for testingtoo large or too small. By optimizing the bound with respect to , we then argue that the following qualitative properties of cross-validation behavior should be quite robust to significant changes in the underlying model selection problem: When the target function complexity is small compared to the sample size, the performance of cross validation is relatively insensitive to the choice of . The importance of choosing optimally increases, and the optimal value for decreases, as the target function becomes more complex relative to the sample size. There is nevertheless a single fixed value for that works nearly optimally for a wide range of target function complexity.	approximation algorithm;cross-validation (statistics);generalization error;model selection;optimization problem;overfitting;selection algorithm	Michael Kearns	1995	Neural Computation	10.1162/neco.1997.9.5.1143	computer simulation;sample size determination;econometrics;function approximation;computer science;artificial intelligence;backpropagation;perceptron;machine learning;mathematics;computational complexity theory;artificial neural network;cross-validation;model selection;statistics;experimental analysis of behavior;generalization error	ML	11.4081329954035	-32.88059087125428	26368
02c1a4c9efe5721e0e19d9b758fdc22ab3ba8b53	multiplex visibility graphs to investigate recurrent neural network dynamics		A recurrent neural network (RNN) is a universal approximator of dynamical systems, whose performance often depends on sensitive hyperparameters. Tuning them properly may be difficult and, typically, based on a trial-and-error approach. In this work, we adopt a graph-based framework to interpret and characterize internal dynamics of a class of RNNs called echo state networks (ESNs). We design principled unsupervised methods to derive hyperparameters configurations yielding maximal ESN performance, expressed in terms of prediction error and memory capacity. In particular, we propose to model time series generated by each neuron activations with a horizontal visibility graph, whose topological properties have been shown to be related to the underlying system dynamics. Successively, horizontal visibility graphs associated with all neurons become layers of a larger structure called a multiplex. We show that topological properties of such a multiplex reflect important features of ESN dynamics that can be used to guide the tuning of its hyperparamers. Results obtained on several benchmarks and a real-world dataset of telephone call data records show the effectiveness of the proposed methods.	artificial neural network;benchmark (computing);biological neural networks;dynamical system;echo state network;graph - visual representation;large;maximal set;multiplexing;neuron;neurons;random neural network;recurrent neural network;silo (dataset);system dynamics;time series;universal approximation theorem;visibility graph;anatomical layer	Filippo Maria Bianchi;Lorenzo Livi;Cesare Alippi;Robert Jenssen	2017		10.1038/srep44037	simulation;computer science;bioinformatics;artificial intelligence;machine learning	ML	22.210753629251137	-48.23183033026243	26408
683e70c06ec0a0c694413ca52417da03f3daf712	reduce and re-lift: bootstrapped lifted likelihood maximization for map	map inference;likelihood maximization;lifted inference	By handling whole sets of indistinguishable objects together, lifted belief propagation approaches have rendered large, previously intractable, probabilistic infer ence problems quickly solvable. In this paper, we show that Kumar and Zilberstein’s likelihood maximization (LM) approach to MAP inference is liftable, too, and actually provides additional structure for optimization. Specifically, it has been recognized that some pseudo marginals may converge quickly, turning intuitively into pseudo evidence. This additional evidence typically changes the structure of the lifted network: it may expand or reduce it. The current lifted network, however, can be viewed as an upper bound on the size of the lifted network required to finish likelihood maximization. Consequently, we re-lift the network only if the pseudo evidence yields a reduced network, which can efficiently be computed on the current lifted network. Our experimental results on Ising models, image segmentation and relational entity resolution demonstrate that this bootstrapped LM via “reduce and re-lift” finds MAP assignments comparable to those found by the original LM approach, but in a fraction of the time.	belief propagation;converge;decision problem;expectation–maximization algorithm;image segmentation;ising model;mathematical optimization;software propagation	Fabian Hadiji;Kristian Kersting	2013			artificial intelligence;machine learning;statistics	AI	24.317520199851824	-28.587401599109185	26409
1f3ffbcd5477be570abc4e713e1c812efd4a8761	good and bad practices in propositionalisation	extraction information;base relacional dato;record format;relational data;multiple instance;learning algorithm;analisis datos;information extraction;format enregistrement;intelligence artificielle;algorithme apprentissage;relational database;data mining;learning system;data analysis;fouille donnee;base donnee relationnelle;artificial intelligence;analyse donnee;inteligencia artificial;formato grabacion;relational data mining;algoritmo aprendizaje;busca dato;extraccion informacion	Data is mainly available in relational formats, so relational data mining receives a lot of interest. Propositionalisation consists in changing the representation of relational data in order to apply usual attribute-value learning systems. Data mining practitioners are not necessarily aware of existing works and try to propositionalise by hand. Unfortunately there exists some tempting pitfalls. This article aims at bridging the gap between data mining practitioners and relational data, pointing out the most usual traps and proposing correct approaches to propositionalisation. Similar situations with sequential data and the multiple-instance problem are also covered. Finally the strengths and weaknesses of propositionalisation are listed.	bridging (networking);data (computing);relational data mining	Nicolas Lachiche	2005		10.1007/11558590_5	relational database;computer science;artificial intelligence;machine learning;data mining;database;computer security;information extraction;algorithm	ML	7.90074105820752	-32.958688749824525	26534
ce7890384f2940a8ecb3ef71139931aa970b3b80	attributes reduction based on important degree of attributes in incomplete information system	rough set theory information systems;incomplete information system;information systems;search space;rough set theory;similarity relation;data mining;attribute reduction incomplete information system similarity relation owa operator finding attributes reduction search space;fuzzy sets;information systems set theory mathematics open wireless architecture uncertainty aggregates blindness helium rough sets machine learning;attribute reduction;incomplete information;blindness;open wireless architecture;owa operator;finding attributes reduction	In incomplete information systems, based on similarity relation, a method of attributes reduction is discussed in this paper. Relative important degree of attributes is defined. Important degree of attributes is obtained by using the OWA operator to aggregate relative important degree of attributes. Due to finding attributes reduction in accordance with the reorder of attributes which identified by important degree of attributes, the advantage of our method is to reduce the search space of attribute reduction and avoid blindness. Finally, the specific example shows our method is effective.	aggregate data;information system;internet information services	Jilin Yang;Dongmei Wei;Qiong Liu;Yufeng Hai	2009	2009 IEEE International Conference on Fuzzy Systems	10.1109/FUZZY.2009.5277286	discrete mathematics;rough set;computer science;machine learning;data mining;mathematics;fuzzy set;complete information;information system	DB	-2.2618295615296873	-26.198230570589836	26541
2b08ce497498d2177e9f65595439c4bd9ec65da2	ultra-fast shapelets for time series classification		Time series shapelets are discriminative subsequences and their similarity to a time series can be used for time series classification. Since the discovery of time series shapelets is costly in terms of time, the applicability on long or multivariate time series is difficult. In this work we propose Ultra-Fast Shapelets that uses a number of random shapelets. It is shown that Ultra-Fast Shapelets yield the same prediction quality as current state-of-theart shapelet-based time series classifiers that carefully select the shapelets by being by up to three orders of magnitudes. Since this method allows a ultra-fast shapelet discovery, using shapelets for long multivariate time series classification becomes feasible. A method for using shapelets for multivariate time series is proposed and Ultra-Fast Shapelets is proven to be successful in comparison to state-of-the-art multivariate time series classifiers on 15 multivariate time series datasets from various domains. Finally, time series derivatives that have proven to be useful for other time series classifiers are investigated for the shapelet-based classifiers. It is shown that they have a positive impact and that they are easy to integrate with a simple preprocessing step, without the need of adapting the shapelet discovery algorithm.	algorithm;discriminative model;fastest;feature selection;naive bayes classifier;preprocessor;random forest;time series;universal flash storage	Martin Wistuba;Josif Grabocka;Lars Schmidt-Thieme	2015	CoRR		machine learning;pattern recognition;data mining;mathematics	ML	15.563587728657453	-47.36745018649593	26580
49c9565fcedce33fdc426edd26c8dfe4c0d81489	clustering approaches for data with missing values: comparison and evaluation	cluster algorithm;prototypes;data collection;data set analysis;data missing value determination;data mining;data clustering;data missing value determination data clustering data set analysis data collection data transfer data cleaning partitioning clustering algorithms;accuracy;data analysis;estimation;clustering method;distributed databases;clustering algorithms;missing data mechanism;data mining data handling;data cleaning;partitioning clustering algorithms;missing values;data handling;clustering algorithms prototypes clustering methods partitioning algorithms accuracy distributed databases estimation;clustering methods;data transfer;partitioning algorithms	Traditional clustering methods were developed to analyse complete data sets. Faults during the data collection, data transfer or data cleaning often lead to missing values in data so that common clustering methods can not be used for the data analysis. Therefore, in these cases clustering methods which can handle missing values in data are of great use. In this paper we discuss different approaches proposed in the literature for adapting partitioning clustering algorithms for dealing with missing values in data. We analyse them on two appropriate data sets and compare them with each other. We give particular attention to the analysis of the accuracy of these methods depending on the different missing-data mechanisms and the percentage of missing values in the data sets.	algorithm;cluster analysis;experiment;matthews correlation coefficient;missing data;plasma cleaning;silhouette (clustering)	Ludmila Himmelspach;Stefan Conrad	2010	2010 Fifth International Conference on Digital Information Management (ICDIM)	10.1109/ICDIM.2010.5664691	correlation clustering;constrained clustering;fuzzy clustering;missing data;computer science;data science;consensus clustering;pattern recognition;cure data clustering algorithm;data mining;data pre-processing;cluster analysis;imputation;distributed database;statistics;clustering high-dimensional data	DB	0.6278703754865637	-39.03110008339332	26600
97401c81983108817ac426da739e7fcc873bf7ee	constrained topological mapping for nonparametric regression analysis	espacio n dimensiones;multidimensional space;espace n dimensions;methode non parametrique;curse of dimensionality;statistical regression;constrained topological mapping;metodo no parametrico;algorithme kohonen;regresion estadistica;nonparametric regression;non parametric method;self organization;application topologique contrainte;reseau neuronal;regression statistique;red neuronal;neural network;auto organisation	"""-The idea 0~' using Kohonen's self-organizing maps is applied to the problem of nonparametric regression attalysis, that is, evaluation (approximation) q[ the unknown .¢~mction of N-I variables given a number of data points (possibly corrupted by random noise) in N-dimensional input space. Simple examples show that the original Kohonen's algorithm perJbrms poorly/or regression problems of even low dimensionalitv, due to the ['act that topologically correct ordering o( units in N-dimensional space may violate the natural topological ordering of prolections of those units onto (N-I )-dimensional subspace q/ independent variables. A modification of the original algorithm called the constrained topological mapping algorithm is proposed Jor regression analysis applications. Given a number of data points in N-dimensional input space, the proposed algorithm performs correct topological mapping of units (as the original algorithm) and at the same time preserves topological ordering of projections of these units onto ( N-1)-dimensional subspace of independent coordinates. Simulation examples illustrate good performance (i. e., accuracy, convergence) of the proposed algorithm Jor approximating 2and 3-variable flmctions. Moreover. ]or ntultivariate problems the proposed neural approach may alleviate """"'the curse of dimensionality,"""" that is, redttce the size of the training set required/or evaluation ~1 the unknown [hnction (~)/ many variables), by increasing the number of units (knots) in the topological map. Keywords--Constrained topological mapping, Curse of dimensionality, Nonparametric regression, Self*organization. 1. I N T R O D U C T I O N A deep but largely unexplored connection exists between statistical techniques and neural networks (White, 1989). For instance, many neural networks with supervised learning (e.g., back propagation) can be viewed as a special case of parametric estimation models, where the model parameters (connection link weights) are being determined by the interpolation data (i.e., training data) during training. Generalization capabilities of such models can be easily understood from the statistical perspective. Namely, it is well known that in estimation problems the error of extrapolating (generalization) can be reduced if the extra degrees of freedom (in the model) are being constrained by the interpolation data (i.e., the trainAcknowledgments: The authors would like to thank Dr. Gary Oehlert from the Department of Applied Satistics at the University of Minnesota for valuable discussions and constructive criticism. We also acknowledge anonymous referees whose comments helped to improve the quality of the paper. Requests for reprints should be sent to Vladimir Cherkassky, Department of Electrical Engineering, University of Minnesota, Minneapolis. MN 55455. ing set). If these ideas are applied to back propagation, it can be expected that in order to achieve a given level of generalization, the network size (the total number of weights) should be determined by the size of the training set. Recent neural network research (Baum & Haussler, 1989; Baum, 1990) provides rigorous treatment of generalization capabilities of back propagation networks, and its conclusions are in good agreement with the above arguments. Therefore, statistical techniques can (and should) be applied to the neural network research. However, the focus of this paper is on the application of neural network models to solving hard statistical problems (e.g., nonparametric regression analysis). Regression analysis, or estimating a mathematical function from a set of possibly inaccurate data points, dates back to 1886, when Galton (1886) investigated the relationship between the height of parents and their children. Since then, the theory has gone through many phases of development, especially with the widespread use of modern computers. Today, regression models are widely used in economics, business administration, social, health, and biological sciences."""	approximation;artificial neural network;backpropagation;baum–welch algorithm;computer;curse of dimensionality;data point;electrical engineering;extrapolation;interpolation;mathematical model;noise (electronics);numerical analysis;organizing (structure);requests;self-organization;self-organizing map;simulation;software propagation;supervised learning;test set;topological sorting	Vladimir Cherkassky;Hossein Lari-Najafi	1991	Neural Networks	10.1016/0893-6080(91)90028-4	econometrics;self-organization;curse of dimensionality;computer science;machine learning;mathematics;nonparametric regression;artificial neural network;regression analysis;statistics	ML	17.057631467341526	-29.72117194411527	26606
2c5eb61b522a3965b01658c34400ac8c78a2124c	multi-task and multi-view learning for predicting adverse drug reactions	multi view learning;information technology;co regularization;boosting;multi task learning;inductive learning;dissertation;adverse drug reaction;bioinformatics	Adverse drug reactions (ADRs) present a major concern for drug safety and are a major obstacle in modern drug development. They account for about one-third of all late-stage drug failures, and approximately 4% of all new chemical entities are withdrawn from the market due to severe ADRs. Although off-target drug interactions are considered to be the major causes of ADRs, the adverse reaction profile of a drug depends on a wide range of factors such as specific features of drug chemical structures, its ADME/PK properties, interactions with proteins, the metabolic machinery of the cellular environment, and the presence of other diseases and drugs. Hence computational modeling for ADRs prediction is highly complex and challenging. We propose a set of statistical learning models for effective ADRs prediction systematically from multiple perspectives. We first discuss available data sources for protein-chemical interactions and adverse drug reactions, and how the data can be represented for effective modeling. We also employ biological network analysis approaches for deeper understanding of the chemical biological mechanisms underlying various ADRs. In addition, since proteinchemical interactions are an important component for ADRs prediction, identifying these interactions is a crucial step in both modern drug discovery and ADRs prediction. The performance of common supervised learning methods for predicting proteinchemical interactions have been largely limited by insufficient availability of binding data for many proteins. We propose two multi-task learning (MTL) algorithms for jointly predicting active compounds of multiple proteins, and our methods outperform existing states of the art significantly. All these related data, methods, and preliminary results are helpful for understanding the underlying mechanisms of ADRs and further studies. ADRs data are complex and noisy, and in many cases we do not fully understand the molecular mechanisms of ADRs. Due to the noisy and heterogeneous data set available for some ADRs, we propose a sparse multi-view learning (MVL) algorithm for predicting a specific ADR drug-induced QT prolongation, a major life-threatening adverse drug effect. It is crucial to predict the QT prolongation effect as early as possible in drug development. MVL algorithms work very well when complex data from diverse domains are involved and only limited labeled examples are available. Unlike existing MVL methods that use !2-norm co-regularization to obtain a smooth objective function, we propose an !1-norm co-regularized MVL algorithm for predicting QT prolongation, reformulate the objective function, and obtain its gradient in the analytic form. We optimize the decision functions on all views simultaneously and achieve 3-4 fold higher computational speedup, comparing to previous !2-norm coregularized MVL methods that alternately optimizes one view with the other views fixed until convergence. !1-norm co-regularization enforces sparsity in the learned mapping functions and hence the results are expected to be more interpretable. The proposed MVL method can only predict one ADR at a time. It would be advantageous to predict multiple ADRs jointly, especially when these ADRs are highly related. Advanced modeling techniques should be investigated to better utilize ADR data for more effective ADRs prediction. We study the quantitative relationship among drug structures, drug-protein interaction profiles, and drug ADRs. We formalize the modeling problem as a multi-view (drug structure data and drug-protein interaction profile data) multi-task (one drug may cause multiple ADRs and each ADR is a task) classification problem. We apply the co-regularized MVL on each ADR and use regularized MTL to increase the total sample size and improve model performance. Experimental studies on the ADR data set demonstrate the effectiveness of our MVMT	algorithm;biological network;computation;computational model;computer multitasking;entity;find-a-drug;flight recorder;gradient;interaction;machine learning;multi-task learning;optimization problem;public-key cryptography;qt (software);social network analysis;sparse matrix;speedup;statistical model;supervised learning	Jintao Zhang	2012			computer science;data science;machine learning;data mining	ML	18.69314243960547	-43.716892928007546	26622
1fea1f4e482a52e6a2b2332d9d69a889f1eae079	man: mass attraction network	hopfield network;neural nets;man mass attraction network binary associative memory hypercube attraction forces output pattern parallel operation;neural nets content addressable storage learning artificial intelligence parallel processing;associative memory simulated annealing cost function pattern analysis computational modeling computer simulation information theory gravity hamming distance equations;associative memory;learning artificial intelligence;content addressable storage;parallel processing	"""In th s study, a binary associative memory, inspired from Newton's mass attraction theory is proposed and some related analysis is given.In the model, memory items are considered as masses in the interior or at the corners of a hypercube.In recall, """"attraction forces"""" are computed and the memory item, whose """"forcell is the greatest, becomes the output pattern. Since the operation of the model is highly parallel, the network is extremely fast.Retrieving a memory item takes only two steps.The proposed model has been observed to be superior to Hamming net[l], Hopfield network[3] and Harmony theory[2] in various aspects. Yusuf Ozturk Ege University, Department of Computer Engineering, Izmir,TURKEY bilyoz@trm finds the global maximum as simulated annealing does, but much faster and with probability one."""	computer engineering;content-addressable memory;grid network;hamming distance;hopfield network;maxima and minima;newton;simulated annealing;window function	Mahmut Hilmi Erdem;Yusuf Öztürk	1994		10.1109/ISCAS.1994.409624	parallel processing;computer science;artificial intelligence;theoretical computer science;machine learning;bidirectional associative memory;hopfield network;artificial neural network;algorithm	ML	19.679313852324352	-24.768434310874536	26634
f6f2110997205921348d0ac0798d934af28caf43	mutually-inversistic rough fuzzy logic	granular computing;granular computing mutually inversistic rough fuzzy logic mutually inversistic fuzzy logic rough fuzzy sets fuzzy association rule mining of the lower and upper approximations of equivalence classes;fuzzy set;approximation method;rough set theory;rough set theory data mining fuzzy logic granular computing;data mining;fuzzy association rule mining mutually inversistic rough fuzzy logic rough fuzzy sets granule equivalence class;fuzzy logic;association rule;fuzzy logic approximation methods association rules fuzzy sets rain employment materials;fuzzy association rules	Mutually-inversistic rough fuzzy logic is the integration of mutually-inversistic fuzzy logic constructed by the author and rough fuzzy sets. Mutually-inversistic fuzzy logic can be used to mine fuzzy association rules on the finer granule objects, while mutually-inversistic rough fuzzy logic can be used to mine fuzzy association rules on the coarser granule equivalence classes.	association rule learning;fuzzy logic;fuzzy set;granule (oracle dbms);turing completeness	Xunwei Zhou	2011	2011 Eighth International Conference on Fuzzy Systems and Knowledge Discovery (FSKD)	10.1109/FSKD.2011.6019505	fuzzy logic;t-norm fuzzy logics;combs method;discrete mathematics;rough set;association rule learning;membership function;defuzzification;granular computing;adaptive neuro fuzzy inference system;type-2 fuzzy sets and systems;fuzzy mathematics;fuzzy classification;computer science;fuzzy subalgebra;fuzzy number;neuro-fuzzy;machine learning;fuzzy measure theory;data mining;mathematics;fuzzy set;fuzzy associative matrix;fuzzy set operations;fuzzy control system	Robotics	-1.0587826682199202	-24.814036570150126	26650
9fa456fedb34872a8da74de68000fdae59b1148c	a genetic algorithm approach for discovering tuned fuzzy classification rules with intra- and inter-class exceptions				Renu Bala;Saroj Ratnoo	2016	J. Intelligent Systems	10.1515/jisys-2015-0136	genetic algorithm;artificial intelligence;computer science;fuzzy classification;pattern recognition	ML	9.194185575761123	-41.54066140470058	26654
73f702aa1a5ba7d78bcbc8b55c61bd8d71ec588a	evidential reasoning based on multisensor data fusion for target identification	bayesian statistics;multisensor data fusion;target identification;evidence theory;evidential reasoning;conflict management;dempster shafer	Air target identification is an important issue in threat warning, airline security and surveillance. To obtain accuracy and reliability, the multisensor is used to give multiple sources information. Thus, an algorithm to fuse the information from the multisensor is needed. The (Dempster-Shafer) evidence theory is a generalization of Bayesian statistics. Evidential reasoning is suited to a range of decision-making activities. But it is invalid when dealing with conflicting probabilities. In this paper, a new weighted D-S combination rule is proposed to solve the conflicting management in the air target identification system. In the weighted method presented here, it is to modify evidences rather than to modify the combination rule. The rationality and effectiveness of the weighted method are evaluated by the target identification system.		Xin Wang;Yunxiao Wang;Xiao Yu;Zhengxuan Wang;Yunjie Pang	2007		10.1007/978-3-540-71618-1_60	dempster–shafer theory;machine learning;pattern recognition;data mining;mathematics;bayesian statistics;evidential reasoning approach;statistics	Robotics	-0.5903355540171745	-28.386150199928988	26673
98e5ac8e8c82320302970820ecc33d62dfbe006e	on a continuous degree of satisfaction of temporal logic formulae with applications to systems biology	temporal logic;system biology	Finding mathematical models satisfying a specification built from the formalization of biological experiments, is a common task of the modeller that techniques like model-checking help solving, in the qualitative but also in the quantitative case. In this article we propose to go one step further by defining a continuous degree of satisfaction of a temporal logic formula with constraints. We show how such a satisfaction measure can be used as a fitness function with state-of-the-art search methods in order to find biochemical kinetic parameter values satisfying a set of biological properties formalized in temporal logic. We also show how it can be used to define a measure of robustness of a biological model with respect to some specification. These methods are evaluated on models of the cell cycle and of the MAPK signalling cascade.	algorithm;computation;constraint satisfaction problem;experiment;fitness function;information;modeller;mathematical model;mathematical optimization;model checking;numerical analysis;robustness (computer science);systems biology;temporal logic;tracing (software)	Aurélien Rizk;Grégory Batt;François Fages;Sylvain Soliman	2008		10.1007/978-3-540-88562-7_19	discrete mathematics;simulation;temporal logic;computer science;bioinformatics;mathematics;systems biology;algorithm;statistics	Logic	12.776396813547803	-51.756863471010966	26712
4579a6b3952f3c3c1b7f8116cb15c21502e0984a	a framework for metric learning and embedding with topology learning neural networks	vector quantisation graph theory learning artificial intelligence pattern classification self organising feature maps;growing neural gas;biological neural networks neurons;metric learning;ssl experiment metric learning topology learning neural networks multidimensional scaling isomap vector quantization abilities growing neural gas self organizing incremental neural networks graph similarities semisupervised learning problem classification accuracy;self organizing incremental neural network;self organizing incremental neural network metric learning nonlinear embedding growing neural gas;nonlinear embedding	A framework for metric learning and embedding with topology learning neural networks is proposed. To stress the problems of low efficiency in both time and space in conventional embedding methods such as Multi-Dimensional Scaling and Isomap, we take the advantage of incremental training and vector quantization abilities of topology learning neural networks such as Growing Neural Gas and Self-Organizing Incremental Neural Networks to construct a representation of the data. Then the embeddings are approximated with the graph similarities of the neurons instead of pairwise similarities of input data. In an experiment the proposed metric learning is used in combine of Support Vector Machine to solve a semi-supervised learning (SSL) problem. The results show that our proposed method increased classification accuracy in the SSL experiment.	approximation algorithm;artificial neural network;isomap;multidimensional scaling;neural gas;neural network software;semi-supervised learning;semiconductor industry;supervised learning;support vector machine;vector quantization	Zhiyang Xiang;Zhu Xiao;Dong Wang	2015	2015 11th International Conference on Natural Computation (ICNC)	10.1109/ICNC.2015.7377976	semi-supervised learning;feature learning;self-organizing map;types of artificial neural networks;learning vector quantization;artificial intelligence;machine learning;pattern recognition;time delay neural network;mathematics;deep learning;competitive learning;artificial neural network	ML	23.399192728664612	-41.60947129936755	26733
a72df13fa64dcc35e6dab6e27af0ab50de9685a4	lending direction to neural networks	stochastic automaton;free energy minimization;neural networks;etude theorique;normal distribution;coupled oscillator;automata estocastico;mean field analysis;uncertainty representation and utilization;automate stochastique;mean field;systeme incertain;unite directionnelle;analyse champ moyen;recurrent network;circular normal distribution;estudio teorico;oscillateur couple;boltzmann machine;complex valued networks;theoretical study;reseau neuronal;learning in recurrent networks;sistema incierto;uncertain system;free energy;coupled oscillator models;boltzmann machines;machine boltzmann;oscilador acoplamiento;neural network	We present a general formulation for a network of stochastic directional units. This formulation is an extension of the Boltzmann machine in which the units are not binary, but take on values on a cyclic range, between 0 and 2 radians. This measure is appropriate to many domains, representing cyclic or angular values, e.g., wind direction, days of the week, phases of the moon. The state of each unit in a Directional-Unit Boltzmann Machine (DUBM) is described by a complex variable, where the phase component species a direction; the weights are also complex variables. We associate a quadratic energy function, and corresponding probability, with each DUBM connguration. The conditional distribution of a unit's stochastic state is a circular version of the Gaussian probability distribution, known as the von Mises distribution. In a mean-eld approximation to a stochastic dubm, the phase component of a unit's state represents its mean direction, and the magnitude component speciies the degree of certainty associated with this direction. This combination of a value and a certainty provides additional representational power in a unit. We present a proof that the settling dynamics for a mean-eld DUBM cause convergence to a free energy minimum. Finally, we describe a learning algorithm and simulations that demonstrate a mean-eld DUBM's ability to learn interesting mappings.	algorithm;angularjs;approximation;artificial neural network;boltzmann machine;mathematical optimization;simulation	Richard S. Zemel;Christopher K. I. Williams;Michael C. Mozer	1995	Neural Networks	10.1016/0893-6080(94)00094-3	normal distribution;boltzmann machine;computer science;artificial intelligence;von mises distribution;mean field theory;machine learning;mathematics;artificial neural network;algorithm;statistics	ML	20.0780623848864	-26.933914576593917	26745
2025aadf2dbd8c2bf5f68e1e094f9c0524ecf309	surrogate regret bounds for generalized classification performance metrics	generalized performance metric;regret bound;surrogate loss function;binary classification;multilabel classification;f-measure;jaccard similarity;am measure	We consider optimization of generalized performance metrics for binary classification by means of surrogate losses. We focus on a class of metrics, which are linear-fractional functions of the false positive and false negative rates (examples of which include $$F_{\beta }$$ F β -measure, Jaccard similarity coefficient, AM measure, and many others). Our analysis concerns the following two-step procedure. First, a real-valued function f is learned by minimizing a surrogate loss for binary classification on the training sample. It is assumed that the surrogate loss is a strongly proper composite loss function (examples of which include logistic loss, squared-error loss, exponential loss, etc.). Then, given f, a threshold $$\widehat{\theta }$$ θ ^ is tuned on a separate validation sample, by direct optimization of the target performance metric. We show that the regret of the resulting classifier (obtained from thresholding f on $$\widehat{\theta }$$ θ ^ ) measured with respect to the target metric is upperbounded by the regret of f measured with respect to the surrogate loss. We also extend our results to cover multilabel classification and provide regret bounds for micro- and macro-averaging measures. Our findings are further analyzed in a computational study on both synthetic and real data sets.	backup;binary classification;coefficient;computation;jaccard index;loss function;loss functions for classification;mathematical optimization;mean squared error;regret (decision theory);software metric;synthetic intelligence;time complexity	Wojciech Kotlowski;Krzysztof Dembczynski	2015	Machine Learning	10.1007/s10994-016-5591-7	mathematical optimization;machine learning;mathematics;statistics	ML	21.15755143326497	-36.411661237943974	26774
26b47ab38e6faba7664b6e7e20a318d527354fa4	contextual weighting for support vector machines in literature mining: an application to gene versus protein name disambiguation	software;data interpretation statistical;names;area under roc curve;name disambiguation;normal distribution;databases bibliographic;bayes theorem;data mining;computational biology bioinformatics;naive bayes classifier;cluster analysis;area under curve;proteins;genome human;roc curve;models statistical;artificial intelligence;algorithms;pattern recognition automated;humans;support vector machine;neural networks computer;combinatorial libraries;computational biology;computer appl in life sciences;computing methodologies;sequence analysis protein;microarrays;bioinformatics	The ability to distinguish between genes and proteins is essential for understanding biological text. Support Vector Machines (SVMs) have been proven to be very efficient in general data mining tasks. We explore their capability for the gene versus protein name disambiguation task. We incorporated into the conventional SVM a weighting scheme based on distances of context words from the word to be disambiguated. This weighting scheme increased the performance of SVMs by five percentage points giving performance better than 85% as measured by the area under ROC curve and outperformed the Weighted Additive Classifier, which also incorporates the weighting, and the Naive Bayes classifier. We show that the performance of SVMs can be improved by the proposed weighting scheme. Furthermore, our results suggest that in this study the increase of the classification performance due to the weighting is greater than that obtained by selecting the underlying classifier or the kernel part of the SVM.	additive model;area under curve;data mining;distance;naive bayes classifier;receiver operator characteristics;receiver operating characteristic;statistical classification;support vector machine;word-sense disambiguation	Tapio Pahikkala;Filip Ginter;Jorma Boberg;Jouni Järvinen;Tapio Salakoski	2004	BMC Bioinformatics	10.1186/1471-2105-6-157	normal distribution;support vector machine;naive bayes classifier;dna microarray;integral;computer science;bioinformatics;machine learning;pattern recognition;data mining;cluster analysis;bayes' theorem;receiver operating characteristic	ML	7.83624367928651	-49.06399749371729	26788
9489501aaf1eb5fdd757c879e95f990aa9cc0a7c	explanation-based neural network learning for robot control	reinforcement learning;prior knowledge;learning networks;learning methods;robot control;artificial neural net;neural network	How can artificial neural nets generalize better from fewer examples? In order to generalize successfully, neural network learning methods typically require large training data sets. We introduce a neural network learning method that generalizes rationally from many fewer data points, relying instead on prior knowledge encoded in previously learned neural networks. For example, in robot control learning tasks reported here, previously learned networks that model the effects of robot actions are used to guide subsequent learning of robot control functions. For each observed training example of the target function (e.g. the robot control policy), the learner explains the observed example in terms of its prior knowledge, then analyzes this explanation to infer additional information about the shape, or slope, of the target function. This shape knowledge is used to bias generalization when learning the target function. Results are presented applying this approach to a simulated robot task based on reinforcement learning.	artificial neural network;control function (econometrics);data point;reinforcement learning;robot control	Tom M. Mitchell;Sebastian Thrun	1992			semi-supervised learning;unsupervised learning;robot learning;multi-task learning;computer vision;instance-based learning;error-driven learning;types of artificial neural networks;wake-sleep algorithm;computer science;artificial intelligence;online machine learning;machine learning;deep learning;robot control;learning classifier system;stability;competitive learning;evolutionary robotics;reinforcement learning;artificial neural network;generalization error	ML	17.701881869602072	-30.696385483122857	26831
0f68911861ea5bd6f4e21d1b96935eed3d390e81	a new fixed-overlap partitioning algorithm for determining stability of bioinformatics gene rankers	fixed overlap partitions;dna microarray datasets new fixed overlap partitioning algorithm determining stability bioinformatics gene rankers feature gene selection bioinformatics datasets gene selection techniques fixed overlap partitions;stability;partitioning algorithms dna stability criteria bioinformatics measurement market research;fixed overlap partitions stability dna microarray;data handling;dna microarray;data handling bioinformatics;bioinformatics	Feature (gene) selection has become an important and necessary step for combating high dimensionality, a problem found in bioinformatics datasets. Many studies have focused on gene selection, examining both the design of these techniques and the classification performance of prediction models built using these techniques. However, it is only recently that any work has focused on the robustness or stability of these gene selection techniques. Robustness is important because techniques which do not give reliable gene lists cannot be trusted to give useful genes. Previous papers studying stability typically generate multiple random sub samples of the original dataset and compare the genes chosen from these with one another, or compare the genes from the sub samples directly with the genes from the original data. These methods both have known problems, either with comparing two randomly-generated datasets with an unknown level of overlap or with comparing two datasets of different sizes. This paper introduces a new algorithm for generating sub sample datasets called fixed-overlap partitions. This will generate sub samples which have exactly the desired level of overlap and number of instances. Using this method we evaluate nineteen feature selection techniques using twenty-six real world DNA microarray datasets. Our results show that there are three rankers (Deviance, Receiver Operating Characteristic curve, and Precision-Recall Curve) which are consistently the most stable. However, the level of overlap, the quality of the data, and the number of genes selected have an effect on which ranker will be the most stable in a given situation. The fixed-overlap partitions algorithm in particular is able to find how varying levels of overlap can cause different levels of difficulty to sometimes resemble one another (for example, moderate-difficulty datasets behave like easy-difficulty datasets at low levels of overlap, but diverge as the overlap increases).	algorithm;bioinformatics;dna microarray;feature selection;overlap–add method;randomness;receiver operating characteristic	Randall Wald;Taghi M. Khoshgoftaar;David J. Dittman	2012	2012 11th International Conference on Machine Learning and Applications	10.1109/ICMLA.2012.149	dna microarray;stability;computer science;bioinformatics;machine learning;group method of data handling;data mining	ML	8.099729826159871	-47.10920473912823	26894
185bebfd66ea9023a51f2362c1a981bbc5b6b17a	a closed-form solution for transcription factor activity estimation using network component analysis		Non-iterative network component analysis (NINCA), proposed by Jacklin at.al, employs convex optimization methods to estimate the transcription factor control strengths and transcription factor activities. While NINCA provides good estimation accuracy and higher consistency, the costly optimization routine used therein renders a high computational complexity. This correspondence presents a closed form solution to estimate the connectivity matrix which is tens of times faster, and provides similar accuracy and consistency, thus making the closed form NINCA (CFNINCA) algorithm useful for large data sets encountered in practice. The proposed solution is assessed for accuracy and consistency using synthetic and yeast cell cycle data sets by comparing with the existing state-of-the-art algorithms. The robustness of the algorithm to the possible inaccuracies in prior information is also analyzed and it is observed that CFNINCA and NINCA are much more robust to erroneous prior information as compared to FastNCA.	medical transcription	Amina Noor;Aitzaz Ahmad;Bilal Wajid;Erchin Serpedin;Mohamed N. Nounou;Hazem N. Nounou	2014		10.1007/978-3-319-07953-0_16	data mining;closed-form expression;computational complexity theory;convex optimization;component analysis;robustness (computer science);data set;gene regulatory network;matrix (mathematics);computer science	Vision	3.495677697911078	-51.556462421624026	26942
127a670c5c3ab00f8bad22bbca7d985d2fb1e14c	a novel fuzzy based approach for effort estimation in software development	pred 25;effort estimation;mmre;cocomo;fis;gmf;tmf	Accurate and credible software effort estimation is always a challenge for academic research and software industry. In the beginning, estimation was carried out using only human expertise or algorithmic models, but more recently, interest has turned to a range of Soft Computing techniques. New paradigms such as Fuzzy Logic enable a choice for software effort estimation. Constructive Cost Model (COCOMO) is considered to be the most widely used model for effort estimation. Effort drivers have immense influence on COCOMO and this paper investigates the role of cost drivers (effort features) in improving the precision of effort estimation using Fuzzy Logic. Fuzzy logic-based estimation models are more appropriate when indistinct and incorrect information is to be used. This paper aims at estimating effort in an efficient way using a Fuzzy technique. For this purpose, the COCOMO81 dataset and the Fuzzy Inference System (FIS) of MATLAB are used for implementation. At the end, the outcomes are compared against traditional methods using parameters like Mean Magnitude of Relative Error (MMRE) and Pred (25).	approximation error;cocomo;cost estimation in software engineering;fuzzy logic;matlab;mean squared error;serial ata;soft computing;software development effort estimation;software industry	Amit Sinhal;Bhupendra Verma	2013	ACM SIGSOFT Software Engineering Notes	10.1145/2507288.2507313	simulation;computer science;machine learning;cocomo;data mining	SE	3.4275856482293174	-33.29846288762979	26952
1bd5336f6244801a23b23c29f6ff35d976d46bca	understanding mixup training methods		Mixup is a neural network training method that generates new samples by linear interpolation of multiple samples and their labels. The mixup training method has better generalization ability than the traditional empirical risk minimization method (ERM). But there is a lack of a more intuitive understanding of why mixup will perform better. In this paper, several different sample mixing methods are used to test how neural networks learn and infer from mixed samples to illustrate how mixups work as a data augmentation method and how it regularizes neural networks. Then, a method of weighting noise perturbation was designed to visualize the loss functions of mixup and ERM training methods to analyze the properties of their high-dimensional decision surfaces. Finally, by analyzing the mixture of samples and their labels, a spatial mixup approach was proposed that achieved the state-of-the-art performance on the CIFAR and ImageNet data sets. This method also enables the generative adversarial nets to have more stable training process and more diverse sample generation ability.	artificial neural network;convolutional neural network;decision boundary;empirical risk minimization;imagenet;linear interpolation;loss function;teaching method	Daojun Liang;Feng Yang;Tian Zhang;Peter Yang	2018	IEEE Access	10.1109/ACCESS.2018.2872698	interpolation;task analysis;machine learning;distributed computing;linear interpolation;empirical risk minimization;artificial neural network;training set;computer science;data set;artificial intelligence;weighting	ML	22.17020699410975	-32.264583590729224	26961
9831dc24bba0aaaf32218989a5259d9110437950	normalized cut loss for weakly-supervised cnn segmentation		"""Most recent semantic segmentation methods train deep convolutional neural networks with fully annotated masks requiring pixel-accuracy for good quality training. Common weakly-supervised approaches generate full masks from partial input (e.g. scribbles or seeds) using standard interactive segmentation methods as preprocessing. But, errors in such masks result in poorer training since standard loss functions (e.g. cross-entropy) do not distinguish seeds from potentially mislabeled other pixels. Inspired by the general ideas in semi-supervised learning, we address these problems via a new principled loss function evaluating network output with criteria standard in """"shallow"""" segmentation, e.g. normalized cut. Unlike prior work, the cross entropy part of our loss evaluates only seeds where labels are known while normalized cut softly evaluates consistency of all pixels. We focus on normalized cut loss where dense Gaussian kernel is efficiently implemented in linear time by fast Bilateral filtering. Our normalized cut loss approach to segmentation brings the quality of weakly-supervised training significantly closer to fully supervised methods."""		Meng Tang;Abdelaziz Djelouah;Federico Perazzi;Yuri Boykov;Christopher Schroers	2018	2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition	10.1109/CVPR.2018.00195	pixel;time complexity;cross entropy;machine learning;gaussian function;convolutional neural network;artificial intelligence;pattern recognition;normalization (statistics);image segmentation;computer science;bilateral filter	Vision	22.667772751552263	-49.996348509290726	26978
c71717c002bc153190f15106f27d291f7381eb4e	probabilistic matching compared to deterministic matching for student enrollment records	erbium;complexity theory;erbium complexity theory rocks educational institutions probabilistic logic knowledge engineering error analysis;fellegi sunter model probabilistic matching deterministic matching student enrollment records entity resolution results student enrollment data;scoring rule;scoring rule entity resolution talburt wang index boolean match rules;talburt wang index;pattern matching educational administrative data processing;error analysis;entity resolution;boolean match rules;rocks;probabilistic logic;knowledge engineering	This paper compares entity resolution results obtained by using both probabilistic and deterministic matching when applied to the deduplication of student enrollment data. The approach outlined in this paper uses deterministic matching to represent equivalence for the calculation of weights to be used in probabilistic matching based on the Fellegi-Sunter model.	data deduplication;turing completeness	Pei Wang;Daniel Pullen;John R. Talburt;Ningning Wu	2014	2014 11th International Conference on Information Technology: New Generations	10.1109/ITNG.2014.17	scoring rule;erbium;name resolution;computer science;artificial intelligence;theoretical computer science;machine learning;knowledge engineering;data mining;probabilistic logic;statistics	Robotics	2.0239880468442837	-32.3340628505071	26987
5c8689710a4d5a75acd145335ed92b116fcd0c47	feature selection using fuzzy objective functions	multi criteria optimization;ant colony optimization;cost function;data mining;objective function;data analysis;classification error;feature selection;classification accuracy;optimal algorithm;data preprocessing;ant colony optimization algorithm	One of the most important stages in data preprocessing for data mining is feature selection. Real-world data analysis, data mining, classification and modeling problems usually involve a large number of candidate inputs or features. Less relevant or highly correlated features decrease, in general, the classification accuracy, and enlarge the complexity of the classifier. Feature selection is a multicriteria optimization problem, with contradictory objectives, which are difficult to properly describe by conventional cost functions. The use of fuzzy decision making may improve the performance of this type of systems, since it allows an easier and transparent description of the different criteria used in the feature selection process. In previous work an ant colony optimization algorithm for feature selection was presented, which minimizes two objectives: number of features and classification error. Two pheromone matrices and two different heuristics are used for each objective. In this paper, a fuzzy objective function is proposed to cope with the difficulty of weighting the different criteria involved in the optimization algorithm. Keywords— Feature selection, fuzzy decision functions, ant colony optimization.	algorithm;ant colony optimization algorithms;data mining;data pre-processing;feature selection;heuristic (computer science);mathematical optimization;optimization problem;preprocessor;statistical classification	Susana M. Vieira;João Miguel da Costa Sousa;Uzay Kaymak	2009			computer science;machine learning;pattern recognition;data mining	ML	9.96643104740508	-43.160687769271405	26994
f7617887d76f9177a0cc0387153a1534580a42e6	density-based multiscale analysis for clustering in strong noise settings with varying densities	density-based clustering;heterogeneous clusters;multiscale analysis;strong noise	"""Finding meaningful clustering patterns in data can be very challenging when the clusters are of arbitrary shapes, different sizes, or densities, and especially when the data set contains high percentage (e.g., 80%) of noise. Unfortunately, most existing clustering techniques cannot properly handle this tough situation and often result in dramatically deteriorating performance. In this paper, a purposefully designed clustering algorithm called Density-Based Multiscale Analysis for Clustering (DBMAC)-II is proposed, which is an improved version of the latest strong-noise clustering algorithm DBMAC. DBMAC is proposed under the assumption that all clusters are homogeneous and cannot work well when the data set contains clusters of varying densities. DBMAC-II overcomes the limitation of DBMAC by executing the multiscale analysis iteratively and can conduct strong noise-robust clustering without any strict assumption on the shapes and densities of clusters. In DBMAC-II, each data point or object is mapped into a feature space using its <inline-formula> <tex-math notation=""""LaTeX"""">${r}$ </tex-math></inline-formula>-neighborhood statistics with different <inline-formula> <tex-math notation=""""LaTeX"""">${r}$ </tex-math></inline-formula> (radius) values, which is similar to DBMAC. In general, the higher the value of <inline-formula> <tex-math notation=""""LaTeX"""">${r}$ </tex-math></inline-formula>-neighborhood statistics, the more likely the object is considered as a “clustered” object. Instead of trying to find a single optimal <inline-formula> <tex-math notation=""""LaTeX"""">${r}$ </tex-math></inline-formula> value, a set of radius values appropriate for separating “clustered” objects and “noisy” objects is identified, using a formal statistical method for multimodality test, referred to as multiscale analysis. For clusters with varying densities, multiscale analysis is applied to extract the clusters with the highest density from the current data set iteratively. Moreover, a statistical uniformity test for measuring clustering tendency is used as the self-adaptive stopping criterion of the iteration. Comprehensive experimental studies on a series of challenging benchmark data sets demonstrate that DBMAC-II is not only superior to classical density-based clustering approaches, including DBSCAN, OPTICS, and HDBSCAN, but also can consistently outperform the latest strong-noise robust clustering techniques, such as Skinny-dip."""	benchmark (computing);circuit complexity;cluster analysis;dbscan;data point;feature vector;image noise;iteration;optics algorithm	Tian-Tian Zhang;Bo Yuan	2018	IEEE Access	10.1109/ACCESS.2018.2836389	cluster (physics);anomaly detection;computer science;cluster analysis;feature vector;distributed computing;noise measurement;dbscan;homogeneous;artificial intelligence;data set;pattern recognition	ML	0.6327452480475899	-41.0942238374693	26996
4bc58d9aee2e31ffea83f44710457a81428f0d21	modeling of social transitions using intelligent systems	fuzzy neural nets;social sciences computing fuzzy neural nets inference mechanisms rough set theory self organising feature maps;hybrid intelligent systems;self organizing feature map;social transitions modeling;rough set theory;neuro fuzzy inference system;government;government society interactions;approximate reasoning methods;inference mechanisms;set theory;intelligent computing;data mining;hybrid intelligent system;artificial intelligent;approximate reasoning;complex systems social transitions modeling hybrid intelligent systems intelligent computing approximate reasoning methods self organizing feature map neuro fuzzy inference system rough set theory government society interactions;self organising feature maps;social sciences computing;organizing;self organized feature map;intelligent system;fuzzy inference system;complex systems;artificial intelligence;neurons;regulators;intelligent systems organizing set theory hybrid intelligent systems inference algorithms government artificial intelligence uncertainty monitoring medical services	In this study, we reproduce two new hybrid intelligent systems, involve three prominent intelligent computing and approximate reasoning methods: Self Organizing feature Map (SOM), Neuro-Fuzzy Inference System and Rough Set Theory (RST), called SONFIS and SORST. We show how our algorithms can be construed as a linkage of government-society (or any other similar systems) interactions, where government catches various states of behaviors: ldquosolid (absolute) or flexiblerdquo. So, transition of society, by changing of connectivity parameters (noise) from order to disorder is inferred.	approximation algorithm;image noise;intel matrix raid;interaction;linkage (software);neuro-fuzzy;rough set;set theory	Hamed Owladeghaffari;Witold Pedrycz;Mostafa Sharifzadeh	2008	2008 First International Conference on Complexity and Intelligence of the Artificial and Natural Complex Systems. Medical Applications of the Complex Systems. Biomedical Computing	10.1109/CANS.2008.8	complex systems;computer science;artificial intelligence;hybrid intelligent system;machine learning;data mining;government;set theory	Robotics	4.480260291190952	-25.557539015465206	27052
a6db1a8ea9429d31af7b6400e336beb4d45c5be2	discovering patterns and anomalies in graphs with discrete and numeric attributes				Michael Davis	2014				ML	-1.095668763017936	-32.64324676869007	27068
aad633d2e6331261b35685fba151757e301eadeb	online phenotype discovery based on minimum classification error model	test hypothese;health research;modelizacion;uk clinical guidelines;iterative method;rna interference;on line systems;processus gauss;biological patents;hierarchical system;metodo adaptativo;optimisation;mobile radiocommunication;optimizacion;telecommunication sans fil;europe pubmed central;test hipotesis;online phenotype discovery;systeme hierarchise;citation search;methode adaptative;radiocommunication service mobile;gap statistics;metodo iterativo;modelisation;sistema jerarquizado;gaussian mixture model;uk phd theses thesis;red celular;methode iterative;telecomunicacion sin hilo;systeme en ligne;cell network;reseau cellulaire;adaptive method;signal classification;life sciences;multiple hypothesis testing;classification signal;ground truth;optimization;teoria mezcla;gaussian process;high content screening;minimum classification error;classification automatique;radiocomunicacion servicio movil;proceso gauss;automatic classification;mixture theory;uk research reports;modeling;medical journals;clasificacion automatica;theorie melange;europe pmc;biomedical research;high content screen;error de clasificacion minimo;erreur classification minimale;erreur de classification minimale;bioinformatics;wireless telecommunication;hypothesis test	Identifying and validating novel phenotypes from images inputting online is a major challenge against high-content RNA interference (RNAi) screening. Newly discovered phenotypes should be visually distinct from existing ones and make biological sense. An online phenotype discovery method featuring adaptive phenotype modeling and iterative cluster merging using improved gap statistics is proposed. Clustering results based on compactness criteria and Gaussian mixture models (GMM) for existing phenotypes iteratively modify each other by multiple hypothesis test and model optimization based on minimum classification error (MCE). The method works well on discovering new phenotypes adaptively when applied to both of synthetic datasets and RNAi high content screen (HCS) images with ground truth labels.		Zheng Yin;Xiaobo Zhou;Youxian Sun;Stephen T. C. Wong	2009	Pattern recognition	10.1016/j.patcog.2008.09.032	statistical hypothesis testing;systems modeling;ground truth;rna interference;artificial intelligence;mixture model;gaussian process;mathematics;iterative method;hierarchical control system;multiple comparisons problem;algorithm;statistics;high-content screening	ML	6.250775142002888	-46.575772044493014	27070
3c693d9b46b65994d566d59d02fb832033137992	a parallel algorithm for bayesian network structure learning from large data sets		This paper considers a parallel algorithm for Bayesian network structure learning from large data sets. The parallel algorithm is a variant of the well known PC algorithm. The PC algorithm is a constraint-based algorithm consisting of five steps where the first step is to perform a set of (conditional) independence tests while the remaining four steps relate to identifying the structure of the Bayesian network using the results of the (conditional) independence tests. In this paper, we describe a new approach to parallelization of the (conditional) independence testing as experiments illustrate that this is by far the most time consuming step. The proposed parallel PC algorithm is evaluated on data sets generated at random from five different real-world Bayesian networks. The algorithm is also compared empirically with a process-based approach where each process manages a subset of the data over all the variables on the Bayesian network. The results demonstrate that significant time performance improvements are possible using both approaches. © 2016 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY license ( http://creativecommons.org/licenses/by/4.0/ ).		Anders L. Madsen;Frank Jensen;Antonio Salmerón;Helge Langseth;Thomas D. Nielsen	2017	Knowl.-Based Syst.	10.1016/j.knosys.2016.07.031	bayesian average;variable-order bayesian network;ramer–douglas–peucker algorithm;wake-sleep algorithm;computer science;machine learning;data mining;fsa-red algorithm;parallel algorithm;statistics;population-based incremental learning	ML	17.826105709680718	-36.564034906971074	27092
66b19040ad3c56a96dd826dc00499e46ec500a2d	missing value imputation using a fuzzy clustering-based em approach	fuzzy clustering;missing value imputation;data cleansing;data quality;data preprocessing	Data preprocessing and cleansing play a vital role in data mining by ensuring good quality of data. Data-cleansing tasks include imputation of missing values, identification of outliers, and identification and correction of noisy data. In this paper, we present a novel technique called A Fuzzy Expectation Maximization and Fuzzy Clustering-based Missing Value Imputation Framework for Data Pre-processing (FEMI). It imputes numerical and categorical missing values by making an educated guess based on records that are similar to the record having a missing value. While identifying a group of similar records and making a guess based on the group, it applies a fuzzy clustering approach and our novel fuzzy expectation maximization algorithm. We evaluate FEMI on eight publicly available natural data sets by comparing its performance with the performance of five high-quality existing techniques, namely EMI, GkNN, FKMI, SVR and IBLLS. We use thirty-two types (patterns) of missing values for each data set. Two evaluation criteria namely root mean squared error and mean absolute error are used. Our experimental results indicate (according to a confidence interval and $$t$$ t test analysis) that FEMI performs significantly better than EMI, GkNN, FKMI, SVR, and IBLLS.	approximation error;cluster analysis;data mining;data pre-processing;emi;expectation–maximization algorithm;fuzzy clustering;geo-imputation;mean squared error;missing data;numerical analysis;signal-to-noise ratio	Md. Geaur Rahman;Md Zahidul Islam	2015	Knowledge and Information Systems	10.1007/s10115-015-0822-y	data quality;fuzzy clustering;missing data;computer science;pattern recognition;data mining;data pre-processing;data cleansing;imputation;statistics	ML	5.823104117980759	-42.93109213659088	27129
31da2c91e387077907bd4081cebedd0fd839a8e1	preference moore machines for neural fuzzy integration	fuzzy set;fuzzy integral;simple recurrent network	This paper describes multidimensional neural preference classes and preference Moore machines as a principle for integrating di erent neural and/or symbolic knowledge sources. We relate neural preferences to multidimensional fuzzy set representations. Furthermore, we introduce neural preference Moore machines and relate traditional symbolic transducers with simple recurrent networks by using neural preference Moore machines. Finally, we demonstrate how the concepts of preference classes and preference Moore machines can be used to integrate knowledge from di erent neural and/or symbolic machines. We argue that our new concepts for preference Moore machines contribute a new potential approach towards general principles of neural symbolic integration.	fuzzy set;lisp machine;moore machine;symbolic integration;transducer	Stefan Wermter	1999			computer science;artificial intelligence;machine learning;mathematics;fuzzy set;algorithm	ML	0.8553850024998716	-25.22565204512982	27133
3f1d1031cf68df4551bff2f83cded5c465f5f26e	model selection for big data: algorithmic stability and bag of little bootstraps on gpus	information systems;artificial intelligence	Model selection is a key step in learning from data, because it allows to select optimal models, by avoiding both under- and over-tting. However, in the Big Data framework, the eectiveness of a model selec- tion approach is assessed not only through the accuracy of the learned model but also through the time and computational resources needed to complete the procedure. In this paper, we propose two model selection ap- proaches for Least Squares Support Vector Machine (LS-SVM) classiers, based on Fully-empirical Algorithmic Stability (FAS) and Bag of Little Bootstraps (BLB). The two methods scale sub-linearly respect to the size of the learning set and, therefore, are well suited for big data applica- tions. Experiments are performed on a Graphical Processing Unit (GPU), showing up to 30x speed-ups with respect to conventional CPU-based im- plementations.	big data;graphics processing unit;model selection;stability (learning theory)	Luca Oneto;Bernardo Pilarz;Alessandro Ghio;Davide Anguita	2015			computer science;data science;machine learning;data mining;information system	Theory	18.40767663220914	-36.90884530207476	27164
3b8365fe1cab2acb34d93ad285d4114f7f95f2dc	opening the black box - data driven visualization of neural networks	data visualization neural networks biological neural networks artificial neural networks computer networks software neural network hardware power system modeling neurons humans;neural nets;problem solving data visualisation neural nets backpropagation;nervous system;information visualization;backpropagation;classification;data visualisation;large scale;classification task black box opening data driven visualization artificial neural network human nervous system machine learning tool problem solving;machine learning;information processing;visualization application;problem solving;artificial neural network;neural network	Artificial neural networks are computer software or hardware models inspired by the structure and behavior of neurons in the human nervous system. As a powerful learning tool, increasingly neural networks have been adopted by many large-scale information processing applications but there is no a set of well defined criteria for choosing a neural network. The user mostly treats a neural network as a black box and cannot explain how learning from input data was done nor how performance can be consistently ensured. We have experimented with several information visualization designs aiming to open the black box to possibly uncover underlying dependencies between the input data and the output data of a neural network. In this paper, we present our designs and show that the visualizations not only help us design more efficient neural networks, but also assist us in the process of using neural networks for problem solving such as performing a classification task.	artificial neural network;black box;information processing;information visualization;problem solving	Fan-Yin Tzeng;Kwan-Liu Ma	2005	VIS 05. IEEE Visualization, 2005.	10.1109/VIS.2005.73	stochastic neural network;nervous system network models;cellular neural network;biological classification;computer science;artificial intelligence;backpropagation;machine learning;data mining;time delay neural network;deep learning;nervous system;artificial neural network	ML	12.540876416136024	-28.968781670210806	27178
df2dae9025b6da848547767226c1271d7fbd5dee	structured networks for adaptive language acquisition	metodologia;connectionism;learning;structured networks;conexionismo;lenguaje;langage;intelligence artificielle;systeme adaptatif;methodologie;aprendizaje;language acquisition;connexionnisme;apprentissage;construccion;adaptive system;acquisition;sistema adaptativo;artificial intelligence;inteligencia artificial;language;theorie information;reseau neuronal;methodology;construction;red neuronal;adquisicion;information theory;neural network;teoria informacion	We report on progress in understanding how to build machines which adaptively acquire the language for their task. The generic mechanism in our research has been an information-theoretic connectionist network embedded in a feedback control system. In this paper, we investigate the capability of such a network to learn associations between messages and meaningful responses to them as a task increases in size and complexity. Specifically, we consider how one might reflect task structure in a network architecture in order to provide improved generalization capability in language acquisition. We propose a method for constructing networks from component subnetworks, namely a product network, which provides improved generalization by factoring the associations between words and actions through an intermediate layer of semantic primitives. A two-dimensional product network was evaluated in a 1000-action data retrieval system, the object of which is to answer questions about 20 attributes of the 50 states of the USA. The system was tested by 13 subjects over a two-week period, during which over 1000 natural language dialogues were recorded. The experiment was conducted using typed input with unconstrained vocabulary and syntax. During the course of performing its task, the system acquired over 500 words and retained 92% of what it learned. We provide a description of the system and details on the experimental results.		Laura G. Miller;Allen L. Gorin	1993	IJPRAI	10.1142/S0218001493000443	language acquisition;natural language processing;connectionism;construction;information theory;computer science;artificial intelligence;adaptive system;machine learning;methodology;language;artificial neural network	Vision	10.664335789195864	-30.499008406296454	27200
840a1384b98efce0444690210ff3d4d8a1141e82	finding non-coincidental sporadic rules using apriori-inverse	disease;association rules;apriori inverse;maximum support;sporadic rules	Discovering association rules efficiently is an important data mining problem. We define sporadic rules as those with low support but high confidence; for example, a rare association of two symptoms indicating a rare disease. To find such rules using the well-known Apriori algorithm, minimum support has to be set very low, producing a large number of trivial frequent itemsets. To alleviate this problem, we propose a new method of discovering sporadic rules without having to produce all other rules above the minimum support threshold. The new method, called Apriori-Inverse, is a variation of the Apriori algorithm that uses the notion of maximum support instead of minimum support to generate candidate itemsets. Candidate itemsets of interest to us fall below a maximum support value but above a minimum absolute support value. Rules above maximum support are considered frequent rules, which are of no interest to us, whereas rules that occur by chance fall below the minimum absolute support value. We define two classes of sporadic rule: perfectly sporadic rules (those that consist only of items falling below maximum support) and imperfectly sporadic rules (those that may contain items over the maximum support threshold). This article is an expanded version of Koh and Rountree (2005).	apriori algorithm;association rule learning;data mining;randomness;whole earth 'lectronic link	Yun Sing Koh;Nathan Rountree;Richard A. O'Keefe	2006	IJDWM	10.4018/jdwm.2006040102	association rule learning;computer science;machine learning;pattern recognition;data mining	DB	-0.43056901567506506	-34.349854268413566	27212
725e434a507ca8a718eceabbf40437b2b88ec2ca	improving supervised learning performance by using fuzzy clustering method to select training data	fuzzy c mean;empirical study;supervised learning;border based selection;classification;fuzzy clustering;data selection;center based selection;hybrid selection	The crucial issue in many classification applications is how to achieve the best possible classifier with a limited number of labeled data for training. Training data selection is one method which addresses this issue by selecting the most informative data for training. In this work, we propose three data selection mechanisms based on fuzzy clustering method: center-based selection, border-based selection and hybrid selection. Center-based selection selects the samples with high degree of membership in each cluster as training data. Border-based selection selects the samples around the border between clusters. Hybrid selection is the combination of center-based selection and border-based selection. Compared with existing work, our methods do not require much computational effort. Moreover, they are independent with respect to the supervised learning algorithms and initial labeled data. We use fuzzy c-means to implement our data selection mechanisms. The effects of them are empirically studied on a set of UCI data sets. Experimental results indicate that, compared with random selection, hybrid selection can effectively enhance the learning performance in all the data sets, center-based selection shows better performance in certain data sets, border-based selection does not show significant improvement.	algorithm;cluster analysis;computation;fuzzy clustering;information;machine learning;supervised learning;test set	Donghai Guan;Weiwei Yuan;Young-Koo Lee;Andrey Gavrilov;Sungyoung Lee	2008	Journal of Intelligent and Fuzzy Systems		fuzzy clustering;biological classification;computer science;machine learning;pattern recognition;data mining;supervised learning;empirical research	ML	12.204080371937062	-41.67508754601282	27213
50b534c15c4f7e01b13c324564acb167c6e72c26	cosine: a vertical group difference approach to contrast set mining	vertical group difference approach;simple binning;new search algorithm;simple discretization technique;contrast set;attribute-value pair;vertical approach;continuous-valued attribute;interesting contrast set;mining maximal contrast set;g customer	Contrast sets have been shown to be a useful mechanism for describing differences between groups. A contrast set is a conjunction of attribute-value pairs that differ significantly in their distribution across groups. These groups are defined by a selected property that distinguishes one from the other (e.g customers who default on their mortgage versus those that don’t). In this paper, we propose a new search algorithm which uses a vertical approach for mining maximal contrast sets on categorical and quantitative data. We utilize a novel yet simple discretization technique, akin to simple binning, for continuous-valued attributes. Our experiments on real datasets demonstrate that our approach is more efficient than two previously proposed algorithms, and more effective in filtering interesting contrast sets.	attribute–value pair;discretization;experiment;maximal set;mined;product binning;search algorithm	Mondelle Simeon;Robert J. Hilderman	2011		10.1007/978-3-642-21043-3_43	data mining;algorithm	AI	-1.62200179404269	-34.567513088231806	27239
8b2aa630cd018b37ffa7173ce46b6bae42ea95e7	bayesian network structural learning from data: an algorithms comparison	structure learning;bayesian network	The manual determination of Bayesian Network structure or, more in general, of the probabilistic models, in particular in the case of remarkable dimensions domains, can be complex, time consuming and imprecise. Therefore, in the last years the interest of the scientific community in learning bayesian network structure from data is considerably increased. In fact, many techniques or disciplines, as data mining, text categorization, ontology description, can take advantages from this type of processes. In this paper we will describe some possible approaches to the structural learning of bayesian networks and introduce in detail some algorithms deriving from these ones. We will aim to compare results obtained using the main algorithms on databases normally used in literature. With this aim, we have selected and implemented five algorithms more used in literature. We will estimate the algorithms performances both considering the network topological reconstruction both the correct orientation of the obtained arcs.	algorithm;bayesian network;categorization;data mining;database;document classification;expectation–maximization algorithm;performance;scoring functions for docking;sorting algorithm	Francesco Colace;Massimo De Santo;Mario Vento;Pasquale Foggia	2004			unsupervised learning;probabilistic neural network;variable-order bayesian network;wake-sleep algorithm;computer science;machine learning;pattern recognition;bayesian network;data mining;graphical model;learning classifier system;dynamic bayesian network;intelligent control	AI	11.28540980630964	-47.28460674214241	27330
47677146ac42a6cb624e8232b3c61187ef4a9e3c	improved parameterized complexity of the maximum agreement subtree and maximum compatible tree problems	biology computing;sequences;consensus;maximum compatible tree problem;parameterized complexity;history;phylogeny;systematics;trees mathematics biology computing cellular biophysics evolution biological genetics isomorphism molecular biophysics;fixed parameter tractable;evolution biological;fixed parameter tractable algorithms;linear time algorithm;fixed parameter tractability;trees mathematics;indexing terms;packaging;maximum likelihood estimation;isomorphism;polynomials;genetics;supertrees;trees;fixed parameter tractability phylogenetics algorithms consensus pattern matching trees compatibility;evolutionary trees;pattern matching;fixed parameter tractable algorithms improved parameterized complexity maximum agreement subtree problem maximum compatible tree problem evolutionary trees taxa phylogenetics phylogeny supertrees linear time algorithms isomorphism;taxa;molecular biophysics;phylogeny history inference algorithms sequences bioinformatics polynomials pattern matching systematics packaging maximum likelihood estimation;horizontal gene transfer;compatibility;linear time algorithms;algorithms;inference algorithms;improved parameterized complexity;algorithms biological evolution evolution molecular genetics population likelihood functions models genetic pedigree phylogeny sequence analysis dna;cellular biophysics;maximum agreement subtree problem;tree of life;phylogenetics;bioinformatics	Given a set of evolutionary trees on a same set of taxa, the maximum agreement subtree problem (MAST), respectively, maximum compatible tree problem (MCT), consists of finding a largest subset of taxa such that all input trees restricted to these taxa are isomorphic, respectively compatible. These problems have several applications in phylogenetics such as the computation of a consensus of phylogenies obtained from different data sets, the identification of species subjected to horizontal gene transfers and, more recently, the inference of supertrees, e.g., Trees Of Life. We provide two linear time algorithms to check the isomorphism, respectively, compatibility, of a set of trees or otherwise identify a conflict between the trees with respect to the relative location of a small subset of taxa. Then, we use these algorithms as subroutines to solve MAST and MCT on rooted or unrooted trees of unbounded degree. More precisely, we give exact fixed-parameter tractable algorithms, whose running time is uniformly polynomial when the number of taxa on which the trees disagree is bounded. The improves on a known result for MAST and proves fixed-parameter tractability for MCT.	algorithm;cobham's thesis;computation (action);inference;largest;maximum agreement subtree problem;medical device incompatibility problem;mobile data terminal;parameterized complexity;phylogenetic tree;phylogenetics;polynomial;population parameter;subgroup;subroutine;time complexity;tree (data structure);trees (plant)	Vincent Berry;François Nicolas	2006	IEEE/ACM Transactions on Computational Biology and Bioinformatics	10.1109/TCBB.2006.39	biology;parameterized complexity;packaging and labeling;combinatorics;phylogenetic tree;taxon;consensus;index term;computer science;bioinformatics;pattern matching;tree rearrangement;sequence;mathematics;systematics;horizontal gene transfer;maximum likelihood;tree of life;isomorphism;weight-balanced tree;compatibility;split;algorithm;polynomial;phylogenetics	Theory	0.7810538100511359	-51.52054240759502	27363
9d1d63af5889ecd23176b6b9ed5b608ce6bf92cb	data mining for gene expression profiles from dna microarray	gene expression profile;mlp;bayesian approach;data mining;classification;biological data mining;colon cancer;gene expression;knn;sasom;machine learning;ensemble classifier;svm;feature selection;biological data;dna microarray;majority voting	Microarray technology has supplied a large volume of data, which changes many problems in biology into the problems of computing. As a result techniques for extracting useful information from the data are developed. In particular, microarray technology has been applied to prediction and diagnosis of cancer, so that it expectedly helps us to exactly predict and diagnose cancer. To precisely classify cancer we have to select genes related to cancer because the genes extracted from microarray have many noises. In this paper, we attempt to explore seven feature selection methods and four classifiers and propose ensemble classifiers in three benchmark datasets to systematically evaluate the performances of the feature selection methods and machine learning classifiers. Three benchmark datasets are leukemia cancer dataset, colon cancer dataset and lymphoma cancer data set. The methods to combine the classifiers are majority voting, weighted voting, and Bayesian approach to improve the performance of classification. Experimental results show that the ensemble with several basis classifiers produces the best recognition rate on the benchmark datasets.	benchmark (computing);colon classification;dna microarray;data mining;ensemble kalman filter;feature selection;machine learning;performance	Sung-Bae Cho;Hong-Hee Won	2003	International Journal of Software Engineering and Knowledge Engineering	10.1142/S0218194003001469	support vector machine;majority rule;gene expression;dna microarray;biological data;biological classification;bayesian probability;computer science;bioinformatics;machine learning;pattern recognition;data mining;feature selection;k-nearest neighbors algorithm	ML	8.436855652672888	-48.68635474908912	27487
766c5af28a1157796a80315d94c02417de528009	a novel semi-supervised svm based on tri-training	intrusion detection;semi supervised learning;co training;support vector machine;tri training	One of the main difficulties in machine learning is how to solve large-scale problems effectively, and the labeled data are limited and fairly expensive to obtain. In this paper a new semi-supervised SVM algorithm is proposed. It applies tri-training to improve SVM. The semi-supervised SVM makes use of the large number of unlabeled data to modify the classifiers iteratively. Although tri-training doesn't put any constraints on the classifier, the proposed method uses three different SVMs as the classification algorithm. Experiments on UCI datasets show that tri-training can improve the classification accuracy of SVM and can increase the difference of classifiers, the accuracy of final classifier will be higher. Theoretical analysis and experiments show that the proposed method has excellent accuracy and classification speed.	algorithm;experiment;machine learning;semi-supervised learning;semiconductor industry;triangular function	Jimin Li;Wei Zhang;Kunlun Li	2008	2008 Second International Symposium on Intelligent Information Technology Application	10.4304/jcp.5.4.638-645	semi-supervised learning;intrusion detection system;support vector machine;computer science;machine learning;linear classifier;pattern recognition;data mining;ranking svm;structured support vector machine	ML	13.347962485982414	-40.63354272049892	27616
dc7c006b2c80a4c2e5c58aa0ff006bc30c87f2e7	a fast hiton_pc algorithm	machine learning algorithms;bayesian network;mmpc algorithm;mmpc;causal discovery;bayesian methods;search strategy;inference mechanisms;small samples;variable ratio;hiton_pc;bayesian methods algorithm design and analysis insurance markov processes machine learning machine learning algorithms probability distribution;machine learning;probability distribution;causal discovery algorithm;mmpc algorithm causal discovery algorithm fast hiton_pc algorithm search strategy;mmpc causal discovery bayesian networks hiton_pc;search problems inference mechanisms learning artificial intelligence;search problems;markov processes;learning artificial intelligence;fast hiton_pc algorithm;algorithm design and analysis;insurance;bayesian networks	The HITON_PC algorithm which is a state-of-the-art local causal discovery algorithm can deal with a dataset with a very small sample-to-variable ratio efficiently. But it cannot perform inefficiently on a dataset with a very large sample. To address this problem, a fast HITON_PC algorithm is presented which uses a new yet simple search strategy from high order to low order to improve the efficiency of HITON-PC. Experimental results show our fast HITON_PC outperforms the HITON_PC algorithm. Moreover, we also apply the new search strategy to MMPC algorithm. Our method also is superior to MMPC.	causal filter;fast fourier transform;genetic algorithm	Wei Yang	2010	2010 International Conference on Computational Intelligence and Security	10.1109/CIS.2010.17	computer science;machine learning;pattern recognition;bayesian network;data mining;statistics	DB	13.82689071162996	-36.70214951381026	27756
1b158738e890a855ad8058abf83833c9a2395a2c	multi-modal retrieval via deep textual-visual correlation learning		In this paper, we consider multi-modal retrieval from the perspective of deep textual-visual learning so as to preserve the correlations between multi-modal data. More specifically, We propose a general multi-modal retrieval algorithm to maximize the canonical correlations between multi-modal data via deep learning, which we call Deep Textual-Visual correlation learning (DTV). In DTV, given pairs of images and their describing documents, a convolutional neural network is implemented to learn the visual representation of images and a dependency-tree recursive neural network(DT-RNN) is conducted to learn compositional textual representations of documents respectively, then DTV projects the visual-textual representation into a common embedding space where each pair of multi-modal data is maximally correlated subject to being unrelated with other pairs by matrix-vector canonical correlation analysis (CCA). The experimental results indicate the effectiveness of our proposed DTV when applied to multi-modal retrieval.	modal logic	Jun Song;Yueyang Wang;Fei Wu;Weiming Lu;Siliang Tang;Yueting Zhuang	2015		10.1007/978-3-319-23989-7_19	convolutional neural network;canonical correlation;machine learning;deep learning;recurrent neural network;embedding;artificial intelligence;correlation;computer science	Vision	23.951593400608868	-46.54907198614154	27757
4f25c208f73217cbee639b62349ea0c30dcf92ac	feature selection and approximate reasoning of large-scale set-valued decision tables based on α-dominance-based quantitative rough sets		Set-valued data are a common type of data for characterizing uncertain and missing information. Traditional dominance-based rough sets can not efficiently deal with large-scale set-valued decision tables and usually neglect the disjunctive semantics of sets. In this paper, we propose a general framework of feature selection and approximate reasoning for large-scale set-valued information tables by integrating quantitative rough sets and dominance-based rough sets. Firstly, we define two new partial orders for set-valued data via the conjunctive and disjunctive semantics of a set. Secondly, based on α-disjunctive dominance relation and α-conjunctive dominance relation defined by the inclusion measure, we present α-dominance-based quantitative rough set models for these two types of set-valued decision tables. Furthermore, we study the issue of feature selection in setvalued decision tables by employing α-dominance-based quantitative rough set models and discuss the relationships between the relative reductions and discernibility matrices. We also present approximate reasoning models based on α-dominance-based quantitative rough sets. Finally, the application of the approach is illustrated by some real-world data sets. © 2016 Elsevier Inc. All rights reserved.	approximation algorithm;decision table;disjunctive normal form;dominance-based rough set approach;feature selection;mathematical model	Hong-Ying Zhang;Shu Yun Yang	2017	Inf. Sci.	10.1016/j.ins.2016.06.028	machine learning;pattern recognition;data mining;mathematics;dominance-based rough set approach	AI	-2.6879157867865926	-28.14952673940216	27777
2eb64e00a2d5cc6596502e27cb9ae8e4bea77131	arc reversals in hybrid bayesian networks with deterministic variables	bayes estimation;anonymity;bayesian network;arc reversals;computacion informatica;fonction repartition;securite informatique;loi conditionnelle;intelligence artificielle;ley condicional;hybrid bayesian networks;approche deterministe;diagramme influence;deterministic variables;anonymat;deterministic approach;computer security;reseau bayes;funcion distribucion;estimacion bayes;distribution function;red bayes;ciencias basicas y experimentales;seguridad informatica;enfoque determinista;bayes network;artificial intelligence;influence diagrams;inteligencia artificial;grupo a;diagrama influencia;article;influence diagram;conditional distribution;estimation bayes;variance;variancia;anonimato	This article discusses arc reversals in hybrid Bayesian networks with deterministic variables. Hybrid Bayesian networks contain a mix of discrete and continuous chance variables. In a Bayesian network representation, a continuous chance variable is said to be deterministic if its conditional distributions have zero variances. Arc reversals are used in making inferences in hybrid Bayesian networks and influence diagrams. We describe a framework consisting of potentials and some operations on potentials that allows us to describe arc reversals between all possible kinds of pairs of variables. We describe a new type of conditional distribution function, called partially deterministic, if some of the conditional distributions have zero variances and some have positive variances, and show how it can arise from arc reversals. 2009 Elsevier Inc. All rights reserved.		Esma Nur Cinicioglu;Prakash P. Shenoy	2009	Int. J. Approx. Reasoning	10.1016/j.ijar.2009.02.005	econometrics;influence diagram;computer science;artificial intelligence;machine learning;bayesian network;mathematics;statistics	AI	21.0958069779396	-26.784936819657165	27879
c45521831a16335b97e8c40e1c15eeaf8c6a5cb6	effective solution for unhandled exception in decision tree induction algorithms	rule induction;decision tree;data mining;classification;pruning;influence factor;majority voting;decision tree induction	This paper deals with some improvements to rule induction algorithms in order to resolve the tie that appear in special cases during the rule generation procedure for specific training data sets. These improvements are demonstrated by experimental results on various data sets. The tie occurs in decision tree induction algorithm when the class prediction at a leaf node cannot be determined by majority voting. When there is a conflict in the leaf node, we need to find the source and the solution to the problem. In this paper, we propose to calculate the Influence factor for each attribute and an update procedure to the decision tree has been suggested to deal with the problem and provide subsequent rectification steps. 2009 Published by Elsevier Ltd.	algorithm;decision tree;exception handling;image rectification;information gain in decision trees;kullback–leibler divergence;randomness;rule induction;test data;tree (data structure);tree (descriptive set theory)	S. Appavu alias Balamurugan;Ramasamy Rajaram	2009	Expert Syst. Appl.	10.1016/j.eswa.2009.03.072	majority rule;decision tree learning;biological classification;computer science;pruning;machine learning;decision tree;incremental decision tree;data mining;id3 algorithm;algorithm	AI	13.451987717623311	-39.713240280643504	27905
512e736ee23e9a21fb9a0634f73a16bd0cadfa0f	using the negentropy increment to determine the number of clusters	negentropy;cluster validation;normal distribution;crisp clustering;data distribution;covariance matrices;indexation;number of clusters;cluster validity;covariance matrix	We introduce a new validity index for crisp clustering that is based on the average normality of the clusters. A normal cluster is optimal in the sense of maximum uncertainty, or minimum structure, and so performing further partitions on it will not reveal additional substructures. To characterize the normality of a cluster we use the negentropy, a standard measure of distance to normality which evaluates the difference between the cluster's entropy and the entropy of a normal distribution with the same covariance matrix. Although the definition of the negentropy involves the differential entropy, we show that it is possible to avoid its explicit computation by considering only negentropy increments with respect to the initial data distribution. The resulting  negentropy increment  validity index only requires the computation of determinants of covariance matrices. We have applied the index to randomly generated problems, and show that it provides better results than other indices for the assessment of the number of clusters.	increment and decrement operators;negentropy	Luis F. Lago-Fernández;Fernando J. Corbacho	2009		10.1007/978-3-642-02478-8_56	normal distribution;negentropy;covariance matrix;statistics	Theory	2.403290120332847	-38.326419738531364	27929
059d04a2420ae77fb821fa0c7b710260ef71693b	application of relief-f feature filtering algorithm to selecting informative genes for cancer classification using microarray data	cancer;classification;filtering theory;genetics;learning (artificial intelligence);medical computing;support vector machines;tumours;gain ratio;information gain;relief-f feature filtering algorithm;cancer classification;feature selection methods;k-nn;leave-one-out cross validation;linear svm;machine learning;microarray gene expression data;selecting informative genes;tissue samples	Numerous recent studies have shown that microarray gene expression data is useful for cancer classification. Classification based on microarray data is very different from previous classification problems in that the number of features (genes) greatly exceeds the number of instances (tissue samples). It has been shown that selecting a small set of informative genes can lead to improved classification accuracy. It is thus important to first apply feature selection methods prior to classification. In the machine learning field, one of the most successful feature filtering algorithms is the Relief-F algorithm. In this work, we empirically evaluate its performance on three published cancer classification data sets. We use the linear SVM and the k-NN as classifiers in the experiments, and compare the performance of Relief-F with other feature filtering methods, including Information Gain, Gain Ratio, and /spl chi//sup 2/-statistic. Using the leave-one-out cross validation, experimental results show that the performance of Relief-F is comparable with other methods.	cross-validation (statistics);experiment;feature selection;information;k-nearest neighbors algorithm;kullback–leibler divergence;machine learning;microarray	Yuhang Wang;Fillia Makedon	2004	Proceedings. 2004 IEEE Computational Systems Bioinformatics Conference, 2004. CSB 2004.	10.1109/CSB.2004.1332474	support vector machine;microarray analysis techniques;biological classification;computer science;bioinformatics;machine learning;linear classifier;pattern recognition;data mining;kullback–leibler divergence;feature selection;cross-validation;cancer	ML	13.224674975743142	-42.33133096976874	27968
95e8b695fda4933adf16b35787a78e4960344cd3	tsallis mutual information for document classification	classification;info eu repo semantics article;informacio teoria de la;mutual information;document classification;classificacio;tsallis entropy;information theory;image similarity	Mutual information is one of the mostly used measures for evaluating image similarity. In this paper, we investigate the application of three different Tsallis-based generalizations of mutual information to analyze the similarity between scanned documents. These three generalizations derive from the Kullback–Leibler distance, the difference between entropy and conditional entropy, and the Jensen–Tsallis divergence, respectively. In addition, the ratio between these measures and the Tsallis joint entropy is analyzed. The performance of all these measures is studied for different entropic indexes in the context of document classification and registration.	conditional entropy;database;document classification;document processing;entropic uncertainty;entropic vector;experiment;jensen's inequality;joint entropy;kullback–leibler divergence;mutual information;scientific literature;tsallis entropy	Màrius Vila;Anton Bardera;Miquel Feixas;Mateu Sbert	2011	Entropy	10.3390/e13091694	joint entropy;information diagram;information theory;biological classification;machine learning;pattern recognition;data mining;mathematics;mutual information;total correlation;conditional entropy;tsallis entropy;statistics;pointwise mutual information	ML	6.613599723896736	-34.615102104456525	27980
216f3f9f9fcf19e86f5b1a38cbd55898d5c11ebb	robust manifold learning based ordinal discriminative correlation regression		Canonical correlation analysis (CCA) is a typical learning paradigm of capturing the correlation components across multi-views of the same data. When countered with such data with ordinal labels, the accuracy performance yielded by traditional CCA is usually not desirable because of ignoring the ordinal relationships among data labels. In order to incorporate the ordinal information into the objective function of CCA, the so-called ordinal discriminative CCA (OR-DisCCA) was presented. Although OR-DisCCA can yield better ordinal regression results, its performance will be deteriorated when the data are corrupted with outliers because the ordered class centers easily tend to be biased by the outliers. To address this issue, in this work we construct robust manifold ordinal discriminative correlation regression (rmODCR) by replacing the traditional ((l_2)-norm) class centers with (l_p)-norm centers in objective optimization. Finally, we experimentally evaluate the effectiveness of the proposed method.	nonlinear dimensionality reduction;ordinal data	Qing Tian;Wenqiang Zhang;Liping Wang	2018		10.1007/978-3-030-00021-9_60	discriminative model;outlier;computer science;ordinal regression;canonical correlation;ordinal number;correlation;nonlinear dimensionality reduction;pattern recognition;distributed computing;artificial intelligence	Vision	21.156612175855113	-42.317594878960065	27984
a14a6c294c4ac92988599aa1c9b7383d1424097b	comparison studies on active cross-situational object-word learning using non-negative matrix factorization and latent dirichlet allocation		Future intelligent robots are expected to be able to adapt continuously to their environment. For this purpose, recognizing new objects and learning new words through interactive learning with humans is fundamental. Such setup results in ambiguous teaching data which humans have been shown to address using cross-situational learning, i.e., by analyzing common factors between multiple learning situations. Moreover, they have been shown to be more efficient when actively choosing the learning samples, e.g., which object they want to learn. Implementing such abilities on robots can be performed by latent-topic learning models such as non-negative matrix factorization or latent Dirichlet allocation. These cross-situational learning methods tackle referential and linguistic ambiguities, and can be associated with active learning strategies. We propose two such methods: 1) the maximum reconstruction error-based selection and 2) confidence base exploration. We present extensive experiments using these two learning algorithms through a systematic analysis on the effects of these active learning strategies in contrast with random choice. In addition, we study the factors underlying the active learning by focusing on the use of sample repetition, one of the learning behaviors that have been shown to be important for humans.		Yuxin Chen;Jean-Baptiste Bordes;David Filliat	2018	IEEE Transactions on Cognitive and Developmental Systems	10.1109/TCDS.2017.2725304	instance-based learning;algorithmic learning theory;artificial intelligence;machine learning;semi-supervised learning;active learning;computer science;unsupervised learning;inductive transfer;stability (learning theory);active learning (machine learning);pattern recognition	ML	16.48411749279817	-35.724639645119346	27987
c602b0e893e3b13655ea745d495d3afc08c0c79b	matrix completion and performance guarantees for single individual haplotyping		Single individual haplotyping is an NP-hard problem that emerges when attempting to reconstruct an organism’s inherited genetic variations using data typically generated by high-throughput DNA sequencing platforms. Genomes of diploid organisms, including humans, are organized into homologous pairs of chromosomes that differ from each other in a relatively small number of variant positions. Haplotypes are ordered sequences of the nucleotides in the variant positions of the chromosomes in a homologous pair; for diploids, haplotypes associated with a pair of chromosomes may be conveniently represented by means of complementary binary sequences. In this paper, we consider a binary matrix factorization formulation of the single individual haplotyping problem and efficiently solve it by means of alternating minimization. We analyze the convergence properties of the alternating minimization algorithm and establish theoretical bounds for the achievable haplotype reconstruction error. The proposed technique is shown to outperform existing methods when applied to synthetic as well as real-world Fosmid-based HapMap NA12878 datasets.	algorithm;high-throughput computing;homology (biology);international hapmap project;synthetic intelligence;throughput	Somsubhra Barik;Haris Vikalo	2018	CoRR		mathematical optimization;matrix completion;ploidy;logical matrix;homologous chromosome;fosmid;haplotype;genetic variation;mathematics;small number;artificial intelligence;pattern recognition	ML	1.5046991509983192	-51.92223595404746	28050
a67c20bb44fcbbb42190e9dc0d0561302b28c940	knowledge discovery in databases: pkdd 2004	information system;data privacy;current work;technical feasibility	We show how carefully crafted random matrices can achieve distance-preserving dimensionality reduction, accelerate spectral computations, and reduce the sample complexity of certain kernel methods.	computation;data mining;database;dimensionality reduction;ecml pkdd;kernel method;sample complexity	Jaime G. Carbonell	2004		10.1007/b100704	data mining;knowledge extraction;computer science	ML	-0.08566377791377237	-36.643042203870436	28124
25f160f11d69ace71a788c0327883adf88b71aac	learning problem-oriented decision structures from decision rule: the aqdt-2 system	attribute selection;machine learning;inductive learning;learning problems;decision process;decision rule	A decision structure is an acyclic graph that specifies an order of tests to be applied to an object (or a situation) to arrive at a decision about that object. and serves as a simple and powerful tool for organizing a decision process. This paper proposes a methodology for learning decision structures that are oriented toward specific decision making situations. The methodology consists of two phases: 1—determining and storing declarative rules describing the decision process, 2—deriving on-line a decision structure from the rules. The first step is performed by an expert or by an AQbased inductive learning program that learns decision rules from examples of decisions (AQ15 or AQ17). The second step transforms the decision rules to a decision structure that is most suitable for the given decision making situation. The system, AQDT-2, implementing the second step, has been applied to a problem in construction engineering. In the experiments, AQDT-2 outperformed all other programs applied to the same problem in terms of the accuracy and the simplicity of the generated decision structures.	directed acyclic graph;experiment;online and offline;organizing (structure)	Ryszard S. Michalski;Ibrahim F. Imam	1994		10.1007/3-540-58495-1_42	multi-task learning;error-driven learning;algorithmic learning theory;decision tree learning;decision analysis;decision engineering;computer science;artificial intelligence;machine learning;decision tree;pattern recognition;decision rule;learning classifier system;evidential reasoning approach;feature selection;id3 algorithm;active learning;business decision mapping	ML	5.095241808612742	-31.567588022086074	28137
d91334b1d2242452bdb04bb294b5a1ea391484d9	supervised learning with random labelling errors	qa75 electronic computers computer science	Classical supervised learning from a training set of labelled examples assumes that the labels are correct. But in reality labelling errors may originate, for example, from human mistakes, diverging human opinions, or errors of the measuring instruments. In such cases the training set is misleading and in consequence the learning may suffer. In this thesis we consider probabilistic modelling of random label noise. The goal of this research is two-fold. First, to develop new improved algorithms and architectures from a principled footing which are able to detect and bypass the unwanted effects of mislabelling. Second, to study the performance of such methods both empirically and theoretically. We build upon two classical probabilistic classifiers, the normal discriminant analysis and the logistic regression and introduce the label-noise robust versions of these classifiers. We also develop useful extensions such as a sparse extension and a kernel extension in order to broaden applicability of the robust classifiers. Finally, we devise an ensemble of the robust classifiers in order to understand how the robust models perform collectively. Theoretical and empirical analysis of the proposed models show that the new robust models are superior to the traditional approaches in terms of parameter estimation and classification performance. To my beloved family	algorithm;estimation theory;linear discriminant analysis;loadable kernel module;logistic regression;probabilistic automaton;robustness (computer science);sparse matrix;statistical classification;statistical model;supervised learning;test set	Jakramate Bootkrajang	2013			computer science;machine learning;pattern recognition;data mining	ML	16.567289387726472	-38.766147936827565	28143
158e4fad94d3400d07d9ab5730293cc3c27ccd5e	data mining algorithmic research and application based on information entropy	data correlation information entropy data mining predictive algorithm;lakes;entropy data mining;prediction algorithms;interior relationship;predictive algorithm;satisfiability;data mining algorithmic research;data mining;incremental predictive algorithm;data mining information entropy prediction algorithms lakes software algorithms computer science software engineering application software educational institutions data engineering;data mining algorithm;predictive models;entropy;correlation;couplings;information entropy;correlation coefficient;correlated data;data correlation;interior relationship data mining algorithmic research information entropy incremental predictive algorithm	Traditional data mining predictive algorithm dealt little with original data set and did not make full use of the relationship of the data, as a result, numerous mathematical operation resources was wasted and also the accuracy of the predicted result was not very high. Against with this problem, correlation coefficient and information entropy were introduced, a data mining algorithmic based on information entropy was put forward, and an incremental predictive algorithm had been realized, too. Because the algorithm makes full use of the data setspsila interior relationship, it makes the forecasted results more accurate, and achieves a satisfied result.	benchmark (computing);coefficient;data mining;entropy (information theory);genetic algorithm	Dingsheng Wan;Xiang Ren;Yuting Hu	2008	2008 International Conference on Computer Science and Software Engineering	10.1109/CSSE.2008.551	entropy;prediction;computer science;data science;machine learning;data mining;predictive modelling;coupling;correlation;statistics;entropy;satisfiability	Robotics	2.523100202562321	-32.79119088632342	28157
7042f79eca45456b3069b1f705bd1e20edd8fba0	border-sensitive learning in generalized learning vector quantization: an alternative to support vector machines		Learning vector quantization (LVQ) algorithms as powerful classifier models for class discrimination of vectorial data belong to the family of prototype-based classifiers with a learning scheme based on Hebbian learning as a widely accepted neuronal learning paradigm. Those classifier approaches estimate the class distribution and generate from this a class decision for vectors to be classified. The estimation can be done by the determination of class-typical sensitive prototypes inside the class distribution area like in LVQ or by detection of the class borders for class discrimination as preferred by support vector machines (SVMs). Both strategies provide advantages and disadvantages depending on the given classification task. Whereas LVQs are very intuitive and usually process the data during learning in the data space, frequently equipped with variants of the Euclidean metric, SVMs implicitly map the data into a high-dimensional kernel-induced feature space for better separation. In this Hilbert space, the inner product is compliant to the kernel. However, this implicit mapping makes a vivid interpretation more difficult. As an alternative, we propose in this paper two modifications of LVQ to make it comparable to SVM: first border-sensitive learning is introduced to achieve border-responsible prototypes comparable with support vectors in SVM. Second, kernel distances for differentiable kernels are considered, such that prototype learning takes place in a metric space isomorphic to the feature mapping space of SVM. Combination of both features gives a powerful prototype-based classifier while keeping the easy interpretation and the intuitive Hebbian learning scheme of LVQ.	learning vector quantization;support vector machine	Marika Kaden;Martin Riedel;Wieland Hermann;Thomas Villmann	2015	Soft Comput.	10.1007/s00500-014-1496-1	semi-supervised learning;least squares support vector machine;learning vector quantization;artificial intelligence;machine learning;pattern recognition;mathematics;competitive learning;active learning	ML	16.89231890334171	-44.97910700452471	28235
178d259ee7bc6d5b0b0f1fff34c8423922e2ca69	speed-up of the r4-rule for distance-based neural network learning	databases;neurons neural networks iterative algorithms vector quantization training data heuristic algorithms costs databases nearest neighbor searches cybernetics;pattern recognition distance based neural networks nearest neighbor classifiers neural networks linear vector quantization r 4 rule attentional learning;neural networks;cancer;neural nets;distance based neural network learning;training;r 4 rule;nearest neighbor classifier r 4 rule distance based neural network learning heuristic algorithm learning vector quantization algorithm distance preservation approach attentional learning concept public databases;data mining;distance based neural networks;public databases;linear vector quantization;neural nets learning artificial intelligence;nearest neighbor classifiers;pattern recognition;attentional learning concept;book reviews;vector quantizer;learning vector quantization algorithm;vehicles;neurons;learning artificial intelligence;nearest neighbor classifier;attentional learning;distance preservation approach;heuristic algorithm;learning vector quantization;neural network	The R4-rule is a heuristic algorithm for distance-based neural network (DBNN) learning. Experimental results show that the R4-rule can obtain the smallest or nearly smallest DBNNs. However, the computational cost of the R4-rule is relatively high because the learning vector quantization (LVQ) algorithm is used iteratively during learning. To reduce the cost of the R4-rule, we investigate three approaches in this paper. The first one is called the distance preservation (DP) approach, which tries to reduce the number of times for calculating the distance values, and the other two are based on the attentional learning concept, which try to reduce the number of data used for learning. The efficiency of these methods is verified through experiments on several public databases.	algorithm;algorithmic efficiency;artificial neural network;data structure;database;experiment;heuristic (computer science);learning vector quantization;nearest neighbor search;speedup	Qiangfu Zhao;Naoki Tominaga	2009	2009 IEEE International Conference on Systems, Man and Cybernetics	10.1109/ICSMC.2009.5346184	semi-supervised learning;heuristic;delta rule;learning vector quantization;computer science;artificial intelligence;machine learning;pattern recognition;artificial neural network;cancer	Robotics	14.09678621748385	-32.69141798976577	28249
8af1fb8d0bc8f0b28fb1969c3ddbdf4e1cbd610b	a multinomial - hidden markov model for communication systems influenced by external factors	optimisation;logistic hmm;multiple components;communication systems;convergence of numerical methods;pressure control;blood pressure control;training;biological system modeling;newton raphson method;training procedure;expectation maximization technique;baum welch scheme;training procedure communication systems multinomial hidden markov model catalyzers logistic hmm lhmm multiple components multinomial link functions bioinformatics calcium channel blood pressure control training algorithm baum welch scheme optimization newton raphson technique expectation maximization technique;hidden markov models;biological system modeling hidden markov models;calcium channel;lhmm;optimization;multinomial link functions;newton raphson technique;training bioinformatics convergence of numerical methods expectation maximisation algorithm hidden markov models newton raphson method optimisation pressure control;multinomial hidden markov model;training algorithm;catalyzers;bioinformatics;expectation maximisation algorithm	"""The paper proposes an extension of Hidden Markov models for communication systems that are influenced by external """"catalyzers"""" (e.g. environmental or experimental conditions). A simpler version of the model, the Logistic HMM (LHMM), was already introduced by the authors. In comparison with LHMM, this new extension of HMM allows the catalyzer to have multiple components, expressing the influence over the system through multinomial link functions. A possible application of the Multinomial Hidden Markov model (MHMM) could be in bio-informatics for example, to predict under different external conditions (different quantities of calcium channel blockers CCB and some antioxidants AO) the behavior of the calcium channel that holds an essential part in controlling the blood pressure. We introduce a training algorithm for MHMM based on the BaumWelch scheme, including nested algorithms for optimization such as the Newton - Raphson and the Expectation-Maximization technique for updating the parameters of the model. In order to explore the convergence of the proposed training procedure, a simulation study is provided."""	ambient occlusion;bioinformatics;british informatics olympiad;change control board;expectation–maximization algorithm;hidden markov model;markov chain;mathematical optimization;multinomial logistic regression;newton's method;simulation	Marina-Anca Cidotã;Monica Dumitrescu	2012	2012 7th IEEE International Symposium on Applied Computational Intelligence and Informatics (SACI)	10.1109/SACI.2012.6250008	mathematical optimization;computer science;machine learning;hidden semi-markov model;mathematics;newton's method;calcium channel;hidden markov model;communications system;statistics	Embedded	8.70585459433469	-51.929042333891296	28326
7513d097ede441337318eec348f12d2a7d773d30	a self-optimizing approach for knowledge acquisition with adaptively incremental sampling	sample size;knowledge acquisition sampling methods data mining databases delta modulation mobile communication knowledge engineering educational institutions arthritis medical diagnostic imaging;self adjusting systems;data mining;medical expert systems;adaptive systems;knowledge acquisition;chinese medical science self optimizing approach knowledge acquisition adaptive incremental sampling sampling approach sample size data mining algorithm training samples knowledge model rule generation diagnostic decision table rheumatoid arthritis;sampling methods;medical expert systems self adjusting systems decision tables sampling methods adaptive systems knowledge acquisition;decision tables;decision table;knowledge modeling;rheumatoid arthritis	The paper outlines a self-optimizing approach for knowledge acquisition with adaptively incremental sampling, which fused the self-optimizing approach for knowledge acquisition and sampling approaches in order to improve the efficiency of knowledge acquisition effectively. The proposed sampling approach enabled us to dynamically and adaptively adjust the sample size according to the data mining algorithm's performance on the training samples so as to utilize the sample size as small as possible without reducing the accuracy of the knowledge model. Finally, the self-optimizing approach for knowledge acquisition with adaptively incremental sampling was applied to rule generation from the diagnostic decision table for rheumatoid arthritis in Chinese medical science. Experimentation results showed that the approach was much better than other algorithms both in efficiency and in accuracy.	knowledge acquisition;sampling (signal processing)	Dan Pan;Qilun Zheng;Jing-Song Hu;Guihua Wen	2001		10.1109/ICSMC.2001.972950	decision table;computer science;artificial intelligence;data science;adaptive system;machine learning;data mining;statistics	ML	4.802067001801023	-35.20106628441072	28346
d01a9aedd8b66c73c179c195ac2cb468c2cb7934	preprocessing data patterns to simplify the identification of fuzzy models	tratamiento datos;gradient descent method;gradient method;data processing;traitement donnee;algoritmo genetico;identificacion sistema;methode gradient;system identification;metodo gradiente;clustering;fonction appartenance;membership function;algorithme genetique;genetic algorithm;sistema difuso;systeme flou;funcion pertenencia;identification systeme;fuzzy system;fuzzy model	In this paper we propose both data transformation and modified fuzzy clustering methods to simplify the identification of fuzzy models as well as to improve the system performance. Conventional fuzzy clustering methods contributed the clustering results from the original data to build the fuzzy models. Instead of exploiting the original data to construct the fuzzy models, the given data are transformed into other domains in the hope that the clustering results can provide a positive effect on the system performance. To improve the performance further, both the genetic algorithms and the gradient descent methods succeed in adjusting the projected membership functions from the clustering centroids and the consequent parts in the fuzzy rules. Different types of fuzzy rule are investigated and simulation results are compared. The simulation results verify that the proposed model outperforms conventional models.	preprocessor	O. Ping	1999	Int. J. Systems Science	10.1080/002077299292227	gradient descent;correlation clustering;data stream clustering;genetic algorithm;membership function;data processing;defuzzification;system identification;fuzzy clustering;adaptive neuro fuzzy inference system;flame clustering;fuzzy classification;computer science;gradient method;artificial intelligence;fuzzy number;neuro-fuzzy;mathematics;fuzzy associative matrix;cluster analysis;fuzzy set operations;algorithm	NLP	7.615330522991394	-29.057828676168594	28354
62cdf7791bb3138971fb6fab03693169260a88f6	bandit structured prediction for neural sequence-to-sequence learning		Bandit structured prediction describes a stochastic optimization framework where learning is performed from partial feedback. This feedback is received in the form of a task loss evaluation to a predicted output structure, without having access to gold standard structures. We advance this framework by lifting linear bandit learning to neural sequence-to-sequence learning problems using attention-based recurrent neural networks. Furthermore, we show how to incorporate control variates into our learning algorithms for variance reduction and improved generalization. We present an evaluation on a neural machine translation task that shows improvements of up to 5.89 BLEU points for domain adaptation from simulated bandit feedback.	algorithm;antithetic variates;artificial neural network;bleu;control variates;domain adaptation;lambda lifting;linear model;machine learning;mathematical optimization;neural machine translation;nonlinear system;numerical analysis;recurrent neural network;stochastic optimization;structured prediction;variance reduction	Julia Kreutzer;Artem Sokolov;Stefan Riezler	2017		10.18653/v1/P17-1138	machine learning;pattern recognition	NLP	22.876777312253104	-30.755354138887206	28361
44b210d815e1e26e65967c93c041749e21894ac9	artificial neural network training using a new efficient optimization algorithm	bird mating optimizer;fuel cell;weight training;artificial neural network	Because search space in artificial neural networks (ANNs) is high dimensional and multimodal which is usually polluted by noises and missing data, the process of weight training is a complex continuous optimization problem. This paper deals with the application of a recently invented metaheuristic optimization algorithm, bird mating optimizer (BMO), for training feed-forward ANNs. BMO is a population-based search method which tries to imitate the mating ways of bird species for designing optimum searching techniques. In order to study the usefulness of the proposed algorithm, BMO is applied to weight training of ANNs for solving three real-world classification problems, namely, Iris flower, Wisconsin breast cancer, and Pima Indian diabetes. The performance of BMO is compared with those of the other classifiers. Simulation results indicate the superior capability of BMO to tackle the problem of ANN weight training. BMO is also applied to model fuel cell system which has been addressed as an open and demanding problem in electrical engineering. The promising results verify the potential of BMO algorithm.	algorithm;artificial neural network;mathematical optimization	Alireza Askarzadeh;Alireza Rezazadeh	2013	Appl. Soft Comput.	10.1016/j.asoc.2012.10.023	mathematical optimization;simulation;computer science;artificial intelligence;strength training;machine learning;artificial neural network	ML	13.884431075595305	-24.469759228224067	28384
4e9b0ab5b697e0c31c6cb98de08f42bd97ceb9bb	voronoi feature selection model considering variable-scale map's balance and legibility	legibility;variable scale map;voronoi;information balance	Variable-scale map because of its variability, destroys the constant of original scale, causing the map enlarge regional information easy to read, other regions are severely compressed and difficult to identify, reducing the map legibility. In this paper, we proposed a new pattern called Voronoi Feature Selection to solve the problem of information compression, considering map's legibility and equilibrium. The main idea is that we use voronoi adjacency relationship model to select features, instead of traditional euclidean distance model, use voronoi influence ratio to determine the feature whether or not to remain, and remove the small influence features to reduce the loading of extrusion area, as well as improve the legibility of map. The comparative experiment results show that our methods make the transformed map readability and clearness to express, and it has a good feasibility.	feature selection	Hua Wang;Jiatian Li;Haixia Pu;Rui Li;Yufeng He	2012		10.1007/978-3-642-33469-6_5	computer vision;voronoi diagram	NLP	13.541048803162017	-47.536276816743865	28481
bf992928afe493c5210fd718b00caca4cdb29f19	interval set clustering of web users using modified kohonen self-organizing maps based on the properties of rough sets	kohonen self organizing map;unsupervised learning;text;fuzzy set;data mining;data clustering;kohonen self organizing maps;clustering;web usage mining;web mining;rough sets;genetic algorithm;k means algorithm;rough set;k means clustering;interval sets	Web usage mining involves application of data mining techniques to discover usage patterns from the web data. Clustering is one of the important functions in web usage mining. The likelihood of bad or incomplete web usage data is higher than the conventional applications. The clusters and associations in web usage mining do not necessarily have crisp boundaries. Researchers have studied the possibility of using fuzzy sets in web mining clustering applications. Recent attempts have adapted the K-means clustering algorithm as well as genetic algorithms based on rough sets to find interval sets of clusters. The genetic algorithms based clustering may not be able to handle large amounts of data. The K-means algorithm does not lend itself well to adaptive clustering. This paper proposes an adaptation of Kohonen self-organizing maps based on the properties of rough sets, to find the interval sets of clusters. Experiments are used to create interval set representations of clusters of web visitors on three educational web sites.	adaptive filter;cluster analysis;computer cluster;data mining;experiment;fuzzy set;genetic algorithm;k-means clustering;organizing (structure);plasma cleaning;rough set;self-organization;self-organizing map;semantic network;set theory;usage data;web mining	Pawan Lingras;Mofreh Hogo;Miroslav Snorek	2004	Web Intelligence and Agent Systems		correlation clustering;web mining;rough set;fuzzy clustering;computer science;data science;canopy clustering algorithm;machine learning;data mining;cluster analysis;affinity propagation;k-means clustering	ML	2.8273868064027754	-40.7554025740599	28542
d4191d22847646f99d951aa50d4e322030a4fecd	a fast fuzzy neural modelling method for nonlinear dynamic systems	fuzzy neural network;orthogonal least square;recursive algorithm;nonlinear dynamic system	The identification of nonlinear dynamic systems using fuzzy neural networks is studied. A fast recursive algorithm (FRA) is proposed to select both the fuzzy regressor terms and associated parameters. In comparison with the popular orthogonal least squares (OLS) method, FRA can achieve the fuzzy neural modelling with high accuracy and less computational effort.	algorithm;artificial neural network;computation;computational complexity theory;dynamical system;nonlinear system identification;oracle flashback;ordinary least squares;recursion (computer science);simulation	Barbara Pizzileo;Kang Li;George W. Irwin	2007		10.1007/978-3-540-72383-7_59	mathematical optimization;adaptive neuro fuzzy inference system;computer science;neuro-fuzzy;machine learning;artificial neural network;recursion	ML	14.712038979399178	-27.994443621421958	28573
1b42d9e030f20b4c75b181f3092304825fd20777	discrete hopfield model with graded response (analysis and applications)	optimisation;stability convergence discrete hopfield model graded response local minima neural networks optimization;convergence;neural networks;neural nets;discrete hopfield model;graded response;stability;optimisation neural nets;optimization;local minima;neural network	The author describes a discrete Hopfield model of neural networks consisting of neurons with graded response and investigates its basic properties. Detailed conditions for stability and convergence to local minima are considered. The results obtained can be easily applied in optimization. A new methodology that improves the quality of solutions obtained by the network calculation is proposed	hopfield network	P. Bozovsky	1990		10.1109/IJCNN.1990.137941	stochastic neural network;mathematical optimization;convergence;stability;computer science;artificial intelligence;machine learning;maxima and minima;mathematics;hopfield network;artificial neural network	NLP	16.604011136765212	-27.96991959610427	28594
6d2dbe4bb8c897dbea32f3df689f95b2fb418063	selection of multiple classifiers with no prior limit to the number of classifiers by minimizing the conditional entropy.	conditional entropy	In addition to a study on how to combine multiple classifiers in multiple classifier systems, recently a study on how to select multiple classifiers from a classifier pool has been investigated, because the performance of multiple classifier systems depends on the selected classifiers as well as a combination method. Previous studies on the selection of multiple classifiers select a classifier set based on the assumption that the number of selected classifiers is fixed in advance, or based on the clustering followed the diversity criteria of classifiers in the classifier overproduce and choose paradigm. In this paper, by minimizing the conditional entropy which is the upper bound of Bayes error rate, a new selection method is considered and devised with no prior limit to the number of classifiers, as illustrated in examples.	cluster analysis;conditional entropy;programming paradigm	Hee-Joong Kang	2009			random subspace method;machine learning;pattern recognition;statistics	ML	12.031774701982277	-43.23939222804094	28595
13e40ef9b4deb4716dd90fc281e50068b0b95e8f	neighborhood counting measure and minimum risk metric	neighborhood counting measure metric;minimum risk metric;distance measure;time measurement;time complexity;neighborhood counting measure;k nearest neighbor minimum risk metric neighborhood counting measure;theoretical analysis neighborhood counting measure metric minimum risk metric distance measure risk misclassification minimization time complexity;theoretical analysis;computational complexity;extraterrestrial measurements time measurement;pattern classification;k nearest neighbor;pattern classification computational complexity;extraterrestrial measurements;similarity measure;risk misclassification minimization	The neighborhood counting measure is a similarity measure based on the counting of all common neighborhoods in a data space. The minimum risk metric (MRM) is a distance measure based on the minimization of the risk of misclassification. The paper by Argentini and Blanzieri refutes a remark about the time complexity of MRM, and presents an experimental comparison of MRM and NCM. This paper is a response to the paper by Argentini and Blanzieri. The original remark is clarified by a combination of theoretical analysis of different implementations of MRM and experimental comparison of MRM and NCM using straightforward implementations of the two measures.	dataspaces;register machine;similarity measure;time complexity	Hui Wang	2010	IEEE Transactions on Pattern Analysis and Machine Intelligence	10.1109/TPAMI.2010.16	time complexity;combinatorics;discrete mathematics;computer science;mathematics;computational complexity theory;k-nearest neighbors algorithm;statistics;time	Vision	0.532140560713621	-32.109100672999055	28617
2907eb16b6ab49e5c5d69acf0ae5361f43a52fd1	a general model for clustering binary data	generic model;large data sets;data clustering;clustering;clustering method;number of clusters;matrix approximation;general model;binary data;cluster model;bag of words;general binaries	"""Clustering is the problem of identifying the distribution of patterns and intrinsic correlations in large data sets by partitioning the data points into similarity classes. This paper studies the problem of clustering binary data. This is the case for market basket datasets where the transactions contain items and for document datasets where the documents contain """"bag of words"""". The contribution of the paper is three-fold. First a general binary data clustering model is presented. The model treats the data and features equally, based on their symmetric association relations, and explicitly describes the data assignments as well as feature assignments. We characterize several variations with different optimization procedures for the general model. Second, we also establish the connections between our clustering model with other existing clustering methods. Third, we also discuss the problem for determining the number of clusters for binary clustering. Experimental results show the effectiveness of the proposed clustering model."""	bag-of-words model;binary data;cluster analysis;data point;mathematical optimization	Tao Li	2005		10.1145/1081870.1081894	complete-linkage clustering;correlation clustering;constrained clustering;determining the number of clusters in a data set;data stream clustering;k-medians clustering;fuzzy clustering;flame clustering;computer science;data science;canopy clustering algorithm;machine learning;consensus clustering;cure data clustering algorithm;data mining;mathematics;hierarchical clustering;cluster analysis;single-linkage clustering;brown clustering;dbscan;biclustering;affinity propagation;clustering high-dimensional data;conceptual clustering	ML	-0.9674350348237767	-42.38593343060318	28643
d81397814bdb0690e25eede279d2bdef8c8a9c22	knowledge engineering for a fuzzy power plant process controller	power plant;knowledge engineering		knowledge engineering	Youngchul Bae;Malrey Lee;Sang Doo Shin;Thomas M. Gatton;Yigon Kim	2007			control theory;knowledge engineering;fuzzy logic;power station;control engineering;engineering	SE	4.397089921844573	-24.308828074750792	28706
2ad7a1edee0dcb07d1b361a7800e04ae8a208d08	time in neural networks	connectionist models;neural model;pattern recognition;temporal processing;temporal reasoning;neural network	After the revival of interest in connectionism in the eighties and its successful application to pattern recognition problems, the time has come to consider its role in the field of temporal processing. We present here a general overview of the field of temporal neural networks. In order to give a broad framework to this presentation, we first present general properties of time that are used by AI models. This sets out the properties of time: - on its own, - with respect to a problem, - with respect to a model. We then present a short summary of time processing in symbolic AI. The main part of this article, a classification of temporal neural models, is introduced by a short presentation of basic connectionist models. This classification is then made and several relevant examples are presented. We conclude the article with underlining the difference between temporal reasoning and neural temporal processing, and give an introduction to the following papers of this Sigart special section.	connectionism;neural networks;pattern recognition;symbolic artificial intelligence	Jean-Cédric Chappelier;Alain Grumbach	1994	SIGART Bulletin	10.1145/181911.181912	natural language processing;computer science;artificial intelligence;machine learning;time delay neural network;artificial neural network	AI	7.001212523938115	-24.798185920427105	28707
f159fb4057dd7800af097f6d1d7a457ceb16572d	enhancing decision combination of face and fingerprint by exploitation of individual classifier space: an approach to multi-modal biometry	evaluation performance;classifying space;performance evaluation;decision profile;generic algorithm;learning;availability;fusion;disponibilidad;biometrie;evaluacion prestacion;biometrics;biometria;prior knowledge;linear discriminate analysis;separability;maximin problem;information presentation;response vector;algorithme;aprendizaje;discriminant analysis;analyse discriminante;algorithm;multiple classifiers;analisis discriminante;probleme maximin;apprentissage;automatic recognition;sum rules;lda;separabilidad;teoria dempster shafer;dempster shafer theory;signal classification;sensibilite elevee;problema maximin;pattern recognition;classification signal;separabilite;reconnaissance forme;alta sensibilidad;classification automatique;reconocimiento patron;automatic classification;scatter matrices;clasificacion automatica;disponibilite;high sensitivity;reconocimiento automatico;theorie dempster shafer;reconnaissance automatique;algoritmo	This paper presents a new approach to combine decisions from face and fingerprint classifiers for multi-modal biometry by exploiting the individual classifier space on the basis of availability of class-specific information present in the classifier space. We exploit the prior knowledge by training the face classifier using response vectors on a validation set, enhancing class separability (using parametric and nonparametric Linear Discriminant Analysis) in the classifier output space and thereby improving the performance of the face classifier. Fingerprint classifier often does not provide this information due to high sensitivity of available minutiae points, producing partial matches across subjects. The enhanced face and fingerprint classifiers are combined using a sum rule. We also propose a generalized algorithm for multiple classifier combination (MCC) based on our approach. Experimental results show superiority of the proposed method over other existing fusion techniques, such as sum, product, max, min rules, decision template and Dempster-Shafer theory.	biostatistics;fingerprint;modal logic	Arpita Patra;Sukhendu Das	2008	Pattern Recognition	10.1016/j.patcog.2007.12.004	margin classifier;availability;margin;genetic algorithm;dempster–shafer theory;fusion;quadratic classifier;computer science;artificial intelligence;classifying space;machine learning;pattern recognition;mathematics;linear discriminant analysis;biometrics	Vision	10.79329021460519	-34.257860341988334	28715
0afde5f49ea236fe5e79f3ec9a7e7e2f9a306b06	sparse multigraph embedding for multimodal feature representation	optimization clustering algorithms sparse matrices data integration correlation feature extraction learning systems;sparse representation machine learning feature fusion multimodal data graph embedding	Data fusion is used to integrate features from heterogenous data sources into a consistent and accurate representation for certain learning tasks. As an effective technique for data fusion, unsupervised multimodal feature representation aims to learn discriminative features, indicating the improvement of classification and clustering performance of learning algorithms. However, it is a challenging issue since varying modality favors different structural learning. In this paper, we propose an efficient feature learning method to represent multimodal images as a sparse multigraph structure embedding problem. First, an effective algorithm is proposed to learn a sparse multigraph construction from multimodal data, where each modality corresponds to one regularized graph structure. Second, incorporating the learned multigraph structure, the feature learning problem for multimodal images is formulated as a form of matrix factorization. An efficient corresponding algorithm is developed to optimize the problem and its convergence is also proved. Finally, the proposed method is compared with several state-of-the-art single-modal and multimodal feature learning techniques in eight publicly available face image datasets. Comprehensive experimental results demonstrate that the proposed method outperforms the existing ones in terms of clustering performance for all tested datasets.	algorithm;cluster analysis;feature learning;machine learning;modal logic;modality (human–computer interaction);multigraph;multimodal interaction;sparse matrix	Shiping Wang;Wenzhong Guo	2017	IEEE Transactions on Multimedia	10.1109/TMM.2017.2663324	discriminative model;artificial intelligence;pattern recognition;computer science;sparse matrix;cluster analysis;multigraph;feature extraction;sensor fusion;machine learning;sparse approximation;feature learning	AI	23.8245201525993	-44.17023693010263	28729
28f358e822ed5fce26b4faa2d25f26bb8b028592	feature selection for iot based on maximal information coefficient		Abstract This paper presents a feature selection method for Internet of Things (IoT) information processing, called MIMIC_FS. The maximal information coefficient (MIC), which can capture a wide range of correlations of variables, including linear, nonlinear, and nonfunctional correlations, is introduced to measure the relevance and redundancy between features and class labels. Based on this measure, the MIC-relevance-average-MIC-redundancy criterion is presented to evaluate the goodness of features, and an approximate-Markov-blanket search strategy is then proposed to improve the efficiency of feature selection. To validate the present study, MIC is also applied to feature selection directly by using the feature-ranking strategy. Experiments on six ASU datasets for IoT applications were conducted. The results show that the proposed method achieves better performance than the comparison methods, markedly reducing feature dimensionality in order to process the tremendous quantities of data in IoT.	feature selection;information theory;maximal information coefficient;maximal set	Guanglu Sun;Jiabin Li;Jian Dai;Zhichao Song;Fei Lang	2018	Future Generation Comp. Syst.	10.1016/j.future.2018.05.060	redundancy (engineering);information processing;feature selection;curse of dimensionality;nonlinear system;distributed computing;machine learning;artificial intelligence;maximal information coefficient;computer science;internet of things	Arch	11.552289391369074	-44.947909237223975	28794
3914e75bb6aebd25790b158f3140df2e70b1dac2	location of amide i mode of vibration in computed data utilizing constructed neural networks	genetic program;genetic programming;artificial intelligent;grammatical evolution;amide i mode;genetic algorithm;genetic algorithms;neural network model;neural network	An automatic location method of amide I mode of vibration between computed data is proposed, based on the well established neural network model of artificial intelligence. This method was developed by constructing and testing the neural network on previously computed and characterized data which were divided in the training and the testing set, respectively. The results show high level of success since the majority of amide I modes of vibration in the testing set were located 99.5%.	artificial neural network;normal mode	George Papamokos;Ioannis G. Tsoulos;I. N. Demetropoulos;Euripidis Glavas	2009	Expert Syst. Appl.	10.1016/j.eswa.2009.04.065	genetic algorithm;computer science;artificial intelligence;machine learning;time delay neural network;artificial neural network;algorithm	ML	14.714583731101772	-24.855896941869563	28876
67312d502f9195f33bffa64e7ba656c028f41964	the human kernel		Bayesian nonparametric models, such as Gaussian processes, provide a compelling framework for automatic statistical modelling: these models have a high degree of flexibility, and automatically calibrated complexity. However, automating human expertise remains elusive; for example, Gaussian processes with standard kernels struggle on function extrapolation problems that are trivial for human learners. In this paper, we create function extrapolation problems and acquire human responses, and then design a kernel learning framework to reverse engineer the inductive biases of human learners across a set of behavioral experiments. We use the learned kernels to gain psychological insights and to extrapolate in humanlike ways that go beyond traditional stationary and polynomial kernels. Finally, we investigate Occam’s razor in human and Gaussian process based function learning.	experiment;extrapolation;gaussian process;kernel (operating system);occam's razor;polynomial;reverse engineering;stationary process;statistical model;occam	Andrew Gordon Wilson;Christoph Dann;Christopher G. Lucas;Eric P. Xing	2015			computer science;artificial intelligence;theoretical computer science;machine learning;mathematics;statistics	ML	22.785079389692427	-29.512429689103286	28893
808aac2c865e06c4fb63ce4c62955cbae9a94c43	fuzzy data recall using polynomial bidirectional hetero-correlator	fuzzy neural nets;fuzzy data;correlation methods;energy function;signal noise ratio;polynomials equations stability associative memory correlators neural networks fuzzy systems surface fitting sufficient conditions signal analysis;associative memory fuzzy data recall polynomial bidirectional hetero correlator fuzzy memories energy function evolution equations signal noise ratio storage capacity;evolution equation;storage capacity;genetic algorithms;content addressable storage;correlation methods fuzzy neural nets content addressable storage genetic algorithms	A method of fuzzy data recall using polynomial bidirectional hetero-correlator is presented. This has a higher capacity for pattern pair storage than that of the conventional BAMs and fuzzy memories. A new energy function is defined. The polynomial bidirectional hetero-correlator (PBHC) takes advantage of fuzzy characteristics in evolution equations such that the signal-noise-ratio (SNR) is significantly increased. In this work, we prove the stability of fuzzy data recall using polynomial bidirectional hetero-correlator. The increase of SNR consequently enhances the capacity of the polynomial bidirectional hetero-correlator. The capacity of the fuzzy data recall using PBHC in the worst case is also estimated.	fuzzy logic;polynomial	Chua-Chin Wang;Cheng-Fa Tsai	1998		10.1109/ICSMC.1998.728180	genetic algorithm;adaptive neuro fuzzy inference system;computer science;artificial intelligence;fuzzy number;theoretical computer science;machine learning;mathematics;fuzzy associative matrix;signal-to-noise ratio;algorithm	AI	16.348726651699497	-25.791910565104388	28905
98ddcf830503accc33d42985b4ee46d3e005864c	gene selection based on multi-class svms and genetic algorithms	gene selection;genetic algorithm		genetic algorithm	Bruno Feres de Souza;André Carlos Ponce de Leon Ferreira de Carvalho	2004			genetic algorithm;support vector machine;gene;truncation selection;artificial intelligence;computer science;quality control and genetic algorithms;pattern recognition	NLP	9.395858950557152	-40.86466583171495	28933
f38110fe6d8c27c0503e64c042768cf78a181bfb	polynomial harmonic gmdh learning networks for time series modeling	metodo cuadrado menor;modelizacion;trigonometric function;fonction harmonique;evaluation performance;methode moindre carre;learning algorithm;fuzzy neural nets;algorithm performance;performance evaluation;methode plus grande pente;least squares method;backpropagation training;fonction polynomiale;estudio comparativo;evaluacion prestacion;steepest descent method;ajustement;network performance;reseau neuronal flou;algorithme apprentissage;funcion armonica;time series;backpropagation;learning networks;higher order;mode ordre eleve;fitting;expressive power;modelisation;etude comparative;mlp neural network;red multinivel;fonction trigonometrique;gradient descent;resultado algoritmo;backpropagation algorithm;metodo mas grande inclinacion;least square;serie temporelle;funcion trigonometrica;comparative study;performance algorithme;serie temporal;algorithme retropropagation;multilayer network;reseau multicouche;neural network model;reseau neuronal;funcion polinomial;ajuste;polynomial function;algoritmo aprendizaje;modeling;harmonic function;red neuronal;modo orden elevado;neural network;high order mode;time series model;algoritmo retropropagacion	This paper presents a constructive approach to neural network modeling of polynomial harmonic functions. This is an approach to growing higher-order networks like these build by the multilayer GMDH algorithm using activation polynomials. Two contributions for enhancement of the neural network learning are offered: (1) extending the expressive power of the network representation with another compositional scheme for combining polynomial terms and harmonics obtained analytically from the data; (2) space improving the higher-order network performance with a backpropagation algorithm for further gradient descent learning of the weights, initialized by least squares fitting during the growing phase. Empirical results show that the polynomial harmonic version phGMDH outperforms the previous GMDH, a Neurofuzzy GMDH and traditional MLP neural networks on time series modeling tasks. Applying next backpropagation training helps to achieve superior polynomial network performances.	activation function;algorithm;artificial neural network;backpropagation;biological neural networks;gradient descent;group method of data handling;least squares;memory-level parallelism;network performance;neural network simulation;polynomial;time series;weight	Nikolay I. Nikolaev;Hitoshi Iba	2003	Neural networks : the official journal of the International Neural Network Society	10.1016/S0893-6080(03)00188-6	computer science;artificial intelligence;backpropagation;machine learning;time series;mathematics;least squares;artificial neural network;algorithm	ML	11.401410724614951	-29.633659204195133	28964
293a76e63681be0d4ae5103938237d6707a15432	incoherent dictionary pair learning: application to a novel open-source database of chinese numbers		We enhance the efficacy of an existing dictionary pair learning algorithm by adding a dictionary incoherence penalty term. After presenting an alternating minimization solution, we apply the proposed incoherent dictionary pair learning (InDPL) method in classification of a novel open-source database of Chinese numbers. Benchmarking results confirm that the InDPL algorithm offers enhanced classification accuracy, especially when the number of training samples is limited.		Vahid Abolghasemi;Mingyang Chen;Ali Alameer;Saideh Ferdowsi;Jonathon A. Chambers;Kianoush Nazarpour	2018	IEEE Signal Processing Letters	10.1109/LSP.2018.2798406	pattern recognition;artificial intelligence;mathematics;benchmarking;minification;database;algorithm design;chinese numerals	ML	19.836271340959307	-42.28669474347204	29003
6834a469562cb563bc91ae08f4e2aa6b03e27b1a	diffusion decision making for adaptive k-nearest neighbor classification		This paper sheds light on some fundamental connections of the diffusion decision making model of neuroscience and cognitive psychology with k-nearest neighbor classification. We show that conventional k-nearest neighbor classification can be viewed as a special problem of the diffusion decision model in the asymptotic situation. By applying the optimal strategy associated with the diffusion decision model, an adaptive rule is developed for determining appropriate values of k in knearest neighbor classification. Making use of the sequential probability ratio test (SPRT) and Bayesian analysis, we propose five different criteria for adaptively acquiring nearest neighbors. Experiments with both synthetic and real datasets demonstrate the effectiveness of our classification criteria.	asymptote;bayesian network;benchmark (computing);cognitive science;computation;experiment;k-nearest neighbors algorithm;machine learning;parallel computing;synthetic intelligence	Yung-Kyun Noh;Frank Chongwoo Park;Daniel D. Lee	2012			computer science;machine learning;pattern recognition;data mining;statistics	ML	15.560405362177873	-34.19797533292196	29057
06ace84086b0159f3f277e82782c842f60d24566	inductive learning: a combinatorial optimization approach	set covering problem;thyroid cancer;classification rules;learning from examples;inductive learning;greedy algorithm;genetic algorithm;integer program;combinatorial optimization	We propose an improved inductive learning method to derive classi- fication rules correctly describing (at least) most of the positive examples and do not correctly describe (at least) most of the negative examples. We start with a pre-analysis of data to assign higher weights to those values of attributes which occur more often in the positive than in the negative examples. The in- ductive learning problem is represented as a modification of the set covering problem which is solved by an integer programming based algorithm using elements of a greedy algorithm or a genetic algorithm, for efficiency. The re- sults are very encouraging and are illustrated on a thyroid cancer data set.	combinatorial optimization;inductive reasoning;program optimization	Janusz Kacprzyk;Grazyna Szkatula	2010		10.1007/978-3-642-05177-7_4	multi-task learning;mathematical optimization;machine learning;mathematics;algorithm;population-based incremental learning	ML	9.539785456490602	-42.64779838948854	29075
f0488dde23b42da69225e2b2015a85c1e532d730	adaptive boosting: dividing the learning set to increase the diversity and performance of the ensemble	metodo adaptativo;validacion cruzada;modele agrege;supervised learning;adaptive boosting;database;base dato;modelo agregado;bibliografia;bibliography;methode adaptative;classification;adaptive method;bibliographie;validation croisee;base de donnees;aggregate model;cross validation;apprentissage supervise;reseau neuronal;aprendizaje supervisado;clasificacion;red neuronal;neural network	As shown in the bibliography, Boosting methods are widely used to build ensembles of neural networks. This kind of methods increases the performance with respect to a single network. Since Freund and Schapire introduced Adaptive Boosting in 1996 some authors have studied and improved Adaboost. In this paper we present Cross Validated Boosting a method based on Adaboost and Cross Validation. We have applied Cross Validation to the learning set in order to get an specific training set and validation set for each network. With this procedure the diversity increases because each network uses an specific validation set to finish its learning. Finally, we have performed a comparison among Adaboost and Crossboost on eight databases from UCI, the results show that Crossboost is the best performing method.		Joaquín Torres-Sospedra;Carlos Hernández-Espinosa;Mercedes Fernández-Redondo	2006		10.1007/11893028_77	adaboost;brownboost;speech recognition;biological classification;boosting methods for object categorization;computer science;artificial intelligence;machine learning;bibliography;supervised learning;boosting;artificial neural network;cross-validation	ML	9.766770399606868	-32.663911579219956	29102
cb96a33f59f96223997c015888e358766c14c96d	best approximation of gaussian neural networks with nodes uniformly spaced	gaussian radial basis functions rbfs;espace hilbert;oversampling parameter;functions band limited in frequency;processus gauss;theorie echantillonnage;teoria muestreo;gaussian series;selection problem;kernel;problema seleccion;forma truncada;gaussian radial basis function;espacio hilbert;neural networks;guidage;gaussian processes;best approximation;signal sampling;fonction reguliere;echantillonnage;forme tronquee;fonction base radiale;sampling methods gaussian processes polynomial approximation radial basis function networks;guiado;energy based argument;polynomials;fonction objectif;truncamiento;sampling;approximation property;hilbert space;objective function;radial basis function networks;uniqueness best approximation existence functions band limited in frequency gaussian radial basis functions rbfs sampling theory truncation;radial basis function;bande frequence;base orthonormale;neural networks frequency signal sampling signal processing kernel polynomials sampling methods hilbert space bandwidth radial basis function networks;troncature;frequency band;signal processing;mejor aproximacion;orthonormal basis;bandwidth;guidance;computer simulation neural networks computer nonlinear dynamics normal distribution pattern recognition automated;funcion objetivo;truncated shape;funcion regular;base orthonormal;gaussian process;reseau neuronal;truncation;sampling methods;muestreo;frequency;proceso gauss;funcion radial base;banda frecuencia;gaussian neural network;existence;red neuronal;uniqueness;smooth function;polynomial approximation;variance;neural network;variancia;oversampling parameter gaussian neural network gaussian radial basis function gaussian series hilbert space energy based argument polynomial approximation;sampling theory;probleme selection;meilleure approximation	This paper is aimed at exposing the reader to certain aspects in the design of the best approximants with Gaussian radial basis functions (RBFs). The class of functions to which this approach applies consists of those compactly supported in frequency. The approximative properties of uniqueness and existence are restricted to this class. Functions which are smooth enough can be expanded in Gaussian series converging uniformly to the objective function. The uniqueness of these series is demonstrated by the context of the orthonormal basis in a Hilbert space. Furthermore, the best approximation to a given band-limited function from a truncated Gaussian series is analyzed by an energy-based argument. This analysis not only gives a theoretical proof concerned with the existence of best approximations but addresses the problems of architectural selection. Specifically, guidance for selecting the variance and the oversampling parameters is provided for practitioners.		Juan Ignacio Mulero Martínez	2008	IEEE transactions on neural networks	10.1109/TNN.2007.905851	sampling;mathematical optimization;mathematical analysis;calculus;gaussian process;mathematics;artificial neural network;statistics	ML	20.045499794444055	-29.513429764677674	29108
61c569933bf4f8ef228791b62620dfacd1b86fd5	cloudtss: a tagsnp selection approach on cloud computing		SNPs are fundamental roles for various applications including medical diagnostic, phylogenies and drug design. They provide the highest-resolution genetic fingerprint for identifying disease associations and human features. Genetic variants that are near each other tend to be inherited together; these regions of linked variants are known as haplotypes. Recently, genetics researches revealed that SNPs within certain haplotype blocks induce only a few distinct common haplotypes in the majority of the population. The existence of haplotype block structure has serious implications for association-based methods for the mapping of disease genes. This paper proposes a parallel haplotype block partition and SNPs selection method under a diversity function by using the Hadoop MapReduce framework. The experiment shows that the proposed MapReduce-paralleled combinatorial algorithm performs well on the real-world data obtained in from the HapMap data set; the computation efficiency can be significantly improved proportional to the number of processors being used.	cloud computing	Che-Lun Hung;Yaw-Ling Lin;Guan-Jie Hua;Yu-Chen Hu	2011		10.1007/978-3-642-27180-9_64	computational biology;single-nucleotide polymorphism;international hapmap project;cloud computing;haplotype;fingerprint;population;computer science	HPC	2.9467878088832866	-51.463333743976584	29162
b21d433669b027d8ab695ccca75337ca6af66e15	lacova: a tree-based multi-label classifier using label covariance as splitting criterion	loss measurement;pattern classification covariance matrices decision trees divide and conquer methods learning artificial intelligence;splitting criteria multi label learning decision trees covariance matrix;prediction algorithms;binary relevance supervised learning problem tree based multilabel classifier divide and conquer approach decision trees local decisions label dependency lacova label powerset joint label distribution splitting criterion label covariance matrix horizontal split vertical split;accuracy;covariance matrices;decision trees correlation covariance matrices accuracy prediction algorithms loss measurement educational institutions;correlation;splitting criteria;multi label learning;decision trees;covariance matrix	Dealing with multiple labels is a supervised learning problem of increasing importance. Multi-label classifiers face the challenge of exploiting correlations between labels. While in existing work these correlations are often modelled globally, in this paper we use the divide-and-conquer approach of decision trees which enables taking local decisions about how best to model label dependency. The resulting algorithm establishes a tree-based multi-label classifier called LaCova which dynamically interpolates between two well-known baseline methods: Binary Relevance, which assumes all labels independent, and Label Power set, which learns the joint label distribution. The key idea is a splitting criterion based on the label covariance matrix at that node, which allows us to choose between a horizontal split (branching on a feature) and a vertical split (separating the labels). Empirical results on 12 data sets show strong performance of the proposed method, particularly on data sets with hundreds of labels.	algorithm;baseline (configuration management);decision tree;interpolation;multi-label classification;relevance;supervised learning	Reem Al-Otaibi;Meelis Kull;Peter A. Flach	2014	2014 13th International Conference on Machine Learning and Applications	10.1109/ICMLA.2014.17	covariance matrix;prediction;machine learning;decision tree;pattern recognition;data mining;mathematics;accuracy and precision;correlation;statistics	ML	18.758891907901813	-41.98224207085408	29211
d74751788f95e6d209245a98451cdc1aa272ea3f	stage-wise training: an improved feature learning strategy for deep models		Deep neural networks currently stand at the state of the art for many machine learning applications, yet there still remain limitations in the training of such networks because of their very high parameter dimensionality. In this paper we show that network training performance can be improved using a stage-wise learning strategy, in which the learning process is broken down into a number of related sub-tasks that are completed stage-bystage. The idea is to inject the information to the network gradually so that in the early stages of training the “coarse-scale” properties of the data are captured while the “finerscale” characteristics are learned in later stages. Moreover, the solution found in each stage serves as a prior to the next stage, which produces a regularization effect and enhances the generalization of the learned representations. We show that decoupling the classifier layer from the feature extraction layers of the network is necessary, as it alleviates the diffusion of gradient and over-fitting problems. Experimental results in the context of image classification support these claims.	artificial neural network;computer vision;coupling (computer programming);deep learning;feature extraction;feature learning;gradient;machine learning;matrix regularization;overfitting;randomness	Elnaz Barshan;Paul W. Fieguth	2015			simulation;engineering;artificial intelligence;machine learning	ML	22.310623044941632	-49.797977026323146	29227
a7e5e0348e237013e5e8617ec4a75ae4cbed9c8e	optimal randomized classification in adversarial settings	game theory;adversarial classification	The problem of learning to distinguish good inputs from malicious has come to be known as adversarial classification emphasizing the fact that, unlike traditional classification, the adversary can manipulate input instances to avoid being so classified. We offer the first general theoretical analysis of the problem of adversarial classification, resolving several important open questions in the process. First, we significantly generalize previous results on adversarial classifier reverse engineering (ACRE), showing that if a classifier can be efficiently learned, it can subsequently be efficiently reverse engineered with arbitrary precision. We extend this result to randomized classification schemes, but now observe that reverse engineering is imperfect, and its efficacy depends on the defender’s randomization scheme. Armed with this insight, we proceed to characterize optimal randomization schemes in the face of adversarial reverse engineering and classifier manipulation. What we find is quite surprising: in all the model variations we consider, the defender’s optimal policy tends to be either to randomize uniformly (ignoring baseline classification accuracy), which is the case for targeted attacks, or not to randomize at all, which is typically optimal when attacks are indiscriminate.	address space layout randomization;adversary (cryptography);arbitrary-precision arithmetic;baseline (configuration management);malware;randomized algorithm;reverse engineering;statistical classification	Yevgeniy Vorobeychik;Bo Li	2014			game theory;computer science;artificial intelligence;machine learning;data mining	Security	18.63727081827559	-51.19273748300848	29254
2bf596ea390af96b642834c209c7303424852c51	pkfcm - proximity based kernel fuzzy c-means for semi-supervised data clustering	proximity based fuzzy c means kernel methods fuzzy clustering semi supervised learning;pattern clustering;kernel;kernel clustering algorithms partitioning algorithms indexes optimization performance analysis educational institutions;kernel methods;semi supervised learning;fuzzy set theory;indexes;fuzzy clustering;performance analysis;clustering algorithms;optimization;parameter estimation;semisupervised learning pkfcm proximity based kernel fuzzy c means algorithm semisupervised data clustering p fcm algorithm proximity hints parameter selection kernel function synthetic data;learning artificial intelligence;proximity based fuzzy c means;partitioning algorithms;pattern clustering fuzzy set theory learning artificial intelligence parameter estimation	Proximity-based fuzzy c-means algorithm (P-FCM), a classical semi-supervised clustering algorithm, concerns with the number of proximity “hints” or constraints that specify an extent to which some pairs of instances are considered similar or. By replacing the fuzzy c-means in P-FCM with a kernel fuzzy c-means, this paper proposes a new semi-supervised clustering algorithm named proximity-based kernel fuzzy c-means (PKFCM), which not only can cluster non-linearly separable data but also can utilize the user inputs about proximity among data to guide the clustering. In addition, PKFCM is able to apply the user inputs to select decent parameters for kernel functions. Simulations on some synthetic data demonstrate the feasibility and advantages of proposed PKFCM.	algorithm;cluster analysis;computer simulation;fuzzy clustering;fuzzy cognitive map;kernel (operating system);linear separability;nonlinear system;semi-supervised learning;semiconductor industry;synthetic data	Jinbo Li;Long Chen	2012	2012 IEEE International Conference on Systems, Man, and Cybernetics (SMC)	10.1109/ICSMC.2012.6377788	semi-supervised learning;database index;constrained clustering;kernel method;data stream clustering;kernel;fuzzy clustering;flame clustering;computer science;fuzzy number;canopy clustering algorithm;machine learning;pattern recognition;data mining;mathematics;fuzzy set;cluster analysis;estimation theory;fuzzy set operations	DB	3.2306940085799916	-39.736138506670805	29271
cc1635161a572b7776449bb08a0aa09f3e5a88c1	improvement of subgroup descriptions in noisy data by detecting exceptions		The presence of noise in datasets to which data mining techniques are applied can greatly reduce the quality and interest of the knowledge extracted. Subgroup discovery is a supervised descriptive rule discovery technique which is not exempt from this problem. The aim of this paper is to improve the descriptions of subgroups previously obtained by any subgroup discovery algorithm in noisy datasets. This is achieved using the post-processing approach of the MEFES algorithm, that first detects exceptions in the input subgroups and then includes those exceptions in the descriptions. The experiments performed in noisy datasets show the suitability of the proposal to improve the quality of the results.	apriori algorithm;association rule learning;data mining;evolutionary algorithm;exception handling;experiment;fuzzy control system;image noise;secure digital;sensor;signal-to-noise ratio;video post-processing	Pedro González;Ángel Miguel García-Vico;Cristóbal J. Carmona;María José del Jesús	2017	Progress in Artificial Intelligence	10.1007/s13748-017-0131-7	computer science;data mining;noisy data;pattern recognition;artificial intelligence	AI	8.831206907993218	-42.22422425937189	29305
8f1c9237eb95dbc061ddbce0d2aed4945d255b6c	structuring the output space in multi-label classification by using feature ranking		Motivated by the increasing interest for the task of multi-label classification (MLC) in recent years, in this study we investigate a new approach for decomposition of the output space with the goal to improve the predictive performance. Namely, the structuring of the output/label space is performed by constructing a label hierarchy and then approaching the MLC task as a task of hierarchical multi-label classification (HMLC). Our approach is as follows. We first perform feature ranking for each of the labels separately and then represent each of the labels with its corresponding feature ranking. The construction of the hierarchy is performed by the (hierarchical) clustering of the feature rankings. To this end, we employ four clustering methods: agglomerative clustering with single linkage, agglomerative clustering with complete linkage, balanced k-means and predictive clustering trees. We then use predictive clustering trees to estimate the influence of the constructed hierarchies, i.e., we compare the predictive performance of models without exploiting the hierarchy and models using hierarchies constructed using label co-occurrences or per label feature rankings. Moreover, we investigate the influence of the hierarchy in the context of single models and ensembles of models. We evaluate the proposed approach across 8 datasets. The results show that the proposed method can yield predictive performance boost across several evaluation measures.		Stevanche Nikoloski;Dragi Kocev;Saso Dzeroski	2017		10.1007/978-3-319-78680-3_11	complete linkage;multi-label classification;single linkage;cluster analysis;hierarchical clustering;structuring;hierarchy;pattern recognition;ranking;computer science;artificial intelligence	Vision	12.442081032488515	-45.65864774982729	29362
0b9805c6f24b959663815dd999da5b264dd830c4	batch mode active learning with applications to text categorization and image retrieval	busqueda informacion;modelizacion;medida informacion;ajustamiento modelo;kernel;linguistique;learning algorithm;batch mode active learning;sistema activo;user relevance feedback;analisis datos;convex programming;batch production;recherche image;kernel logistic regression;redundancia;methode noyau;information retrieval;mesure information;active learning;procede discontinu;image classification;text analysis;kernel logistic regressions;logistic regressions;informacion fisher;text categorization image retrieval labeling information retrieval logistics kernel content based retrieval machine learning feedback measurement uncertainty;convex optimization;programmation convexe;intelligence artificielle;algorithme apprentissage;matrix algebra;fisher information matrix;measurement uncertainty;logistic regression;classification;systeme actif;active system;fisher information matrix batch mode active learning framework text categorization image retrieval machine learning data classification model information retrieval user relevance feedback;ajustement modele;modelisation;data analysis;regresion logistica;feedback;linguistica;produccion por lote;analisis regresion;redundancy;logistics;machine learning;information measure;recherche information;model uncertainty;model matching;regression logistique;metodo nucleo;text analysis image classification image retrieval learning artificial intelligence matrix algebra;production par lot;data classification model;batch process;retroaction pertinence;analyse regression;artificial intelligence;analyse donnee;kernel method;procedimiento discontinuo;regression analysis;model updating;inteligencia artificial;batch mode active learning framework;learning artificial intelligence;image retrieval batch mode active learning logistic regressions kernel logistic regressions convex optimization text categorization;algoritmo aprendizaje;modeling;data classification;relevance feedback;content based retrieval;information fisher;clasificacion	Most machine learning tasks in data classification and information retrieval require manually labeled data examples in the training stage. The goal of active learning is to select the most informative examples for manual labeling in these learning tasks. Most of the previous studies in active learning have focused on selecting a single unlabeled example in each iteration. This could be inefficient, since the classification model has to be retrained for every acquired labeled example. It is also inappropriate for the setup of information retrieval tasks where the user's relevance feedback is often provided for the top K retrieved items. In this paper, we present a framework for batch mode active learning, which selects a number of informative examples for manual labeling in each iteration. The key feature of batch mode active learning is to reduce the redundancy among the selected examples such that each example provides unique information for model updating. To this end, we employ the Fisher information matrix as the measurement of model uncertainty, and choose the set of unlabeled examples that can efficiently reduce the Fisher information of the classification model. We apply our batch mode active learning framework to both text categorization and image retrieval. Promising results show that our algorithms are significantly more effective than the active learning approaches that select unlabeled examples based only on their informativeness for the classification model.	active learning (machine learning);algorithm;batch processing;categorization;document classification;fisher information;formation matrix;image retrieval;information retrieval;iteration;machine learning;relevance feedback	Steven C. H. Hoi;Rong Jin;Michael R. Lyu	2009	IEEE Transactions on Knowledge and Data Engineering	10.1109/TKDE.2009.60	semi-supervised learning;unsupervised learning;convex optimization;computer science;artificial intelligence;fisher information;machine learning;pattern recognition;data mining;logistic regression;active learning;statistics	ML	19.776088073247397	-43.15504177921356	29393
466944effebd6ebf654724c989ce9ab7801b48c1	hybrid intelligent diagnosis systems	hybrid intelligent systems;reliability degree;application software;knowledge classification;null;computer networks;fuzzy logic;hybrid intelligent diagnosis systems;pattern classification fault diagnosis knowledge representation;intelligent systems;pattern classification;industrial application;hybrid intelligent systems decision making biological neural networks fuzzy logic fault diagnosis application software computer networks biomedical computing intelligent systems knowledge representation;information fusion;industrial applications;knowledge representation;decision making hybrid intelligent diagnosis systems biomedicine applications industrial applications reliability degree knowledge representation knowledge classification information fusion;biological neural networks;biomedicine applications;biomedical computing;fault diagnosis	In this paper, the main objective is to give a methodology to design hybrid intelligent diagnosis systems for a large field of biomedicine and industrial applications. At first, a brief description on diagnosis tasks in such applications is presented. Second, diagnosis systems are presented. Third, the main steps of hybrid intelligent diagnosis systems are developed, for each step emphasizing problems and suggesting solutions able to ensure the design of hybrid intelligent diagnosis systems with a satisfactory reliability degree. In fact, the main steps discussed are knowledge representation, classification, classifier issued information fusion, and decision-making. Finally, a discussion is given with regard to the suggested methodology.	knowledge representation and reasoning;statistical classification	Amine Chohra;Nadia Kanaoui;Kurosh Madani	2007	6th International Conference on Computer Information Systems and Industrial Management Applications (CISIM'07)	10.1109/CISIM.2007.36	fuzzy logic;knowledge representation and reasoning;application software;intelligent decision support system;computer science;artificial intelligence;machine learning;data mining	Robotics	3.6208081835786237	-27.30149152812614	29401
6423c8fb14f02051115d8233a4285c8843bb22cf	dualboost: handling missing values with feature weights and weak classifiers that abstain		Missing values in real world datasets are a common issue. Handling missing values is one of the most key aspects in data mining, as it can seriously impact the performance of predictive models. In this paper we proposed a unified Boosting framework that consolidates model construction and missing value handling. At each Boosting iteration, weights are assigned to both the samples and features. The sample weights make difficult samples become the learning focus, while the feature weights enable critical features to be compensated by less critical features when they are unavailable. A weak classifier that abstains (i.e, produce no prediction when required feature value is missing) is learned on a data subset determined by the feature weights. Experimental results demonstrate the efficacy and robustness of the proposed method over existing Boosting algorithms.	algorithm;boosting (machine learning);data mining;feature vector;iteration;missing data;predictive modelling;weak value	Weihong Wang;Jie Xu;Yang Wang;Chen Cai;Fang Chen	2018		10.1145/3269206.3269319	data mining;robustness (computer science);boosting (machine learning);missing data;computer science;pattern recognition;artificial intelligence	ML	15.459214882389375	-40.82590770248306	29420
976e05f37ac815d04c1d9ba109bdcf8373cfc35c	ideal observers and optimal roc hypersurfaces in n-class classification	likelihood ratio;data interpretation statistical;probability;sensitivity analysis medical image processing;receiver operator characteristic;expected utility;bayes theorem;indexing terms;n class classification;likelihood functions;sensitivity analysis;bayes risk;medical image processing;roc analysis;decision theory;true positive;roc curve;error rate;models statistical;humans;bayes theorem data interpretation statistical decision theory humans likelihood functions models statistical probability roc curve;false positive;decision rule;false positive fraction ideal observers optimal roc hypersurfaces receiver operating characteristic n class classification expected utility bayes risk decision rule true positive fraction;utility theory sensitivity radiology performance analysis error analysis probability density function signal to noise ratio cancer optical receivers optical sensors;ideal observer	"""The likelihood ratio, or ideal observer, decision rule is known to be optimal for two-class classification tasks in the sense that it maximizes expected utility (or, equivalently, minimizes the Bayes risk). Furthermore, using this decision rule yields a receiver operating characteristic (ROC) curve which is never above the ROC curve produced using any other decision rule, provided the observer's misclassification rate with respect to one of the two classes is chosen as the dependent variable for the curve (i.e., an """"inversion"""" of the more common formulation in which the observer's true-positive fraction is plotted against its false-positive fraction). It is also known that for a decision task requiring classification of observations into N classes, optimal performance in the expected utility sense is obtained using a set of N-1 likelihood ratios as decision variables. In the N-class extension of ROC analysis, the ideal observer performance is describable in terms of an (N/sup 2/-N-1)-parameter hypersurface in an (N/sup 2/-N)-dimensional probability space. We show that the result for two classes holds in this case as well, namely that the ROC hypersurface obtained using the ideal observer decision rule is never above the ROC hypersurface obtained using any other decision rule (where in our formulation performance is given exclusively with respect to between-class error rates rather than within-class sensitivities)."""	class;expected utility hypothesis;ideal observer theory;receiver operating characteristic;receiver operator characteristics;likelihood ratio;observers;receptor operated channel	Darrin C. Edwards;Charles E. Metz;Matthew A. Kupinski	2004	IEEE Transactions on Medical Imaging	10.1109/TMI.2004.828358	econometrics;computer science;pattern recognition;mathematics;receiver operating characteristic;statistics	ML	14.373059715034476	-50.722005110665734	29456
ce9e5cd0d127ed4f398d7b07a9d75e4f9317d612	ensemble learning: a survey			ensemble learning	Omer Sagi;Lior Rokach	2018	Wiley Interdiscip. Rev. Data Min. Knowl. Discov.	10.1002/widm.1249	boosting (machine learning);machine learning;artificial intelligence;ensemble learning;computer science;random forest;ensemble forecasting	AI	9.743254443396738	-37.03691623563749	29491
8f0d3345ee07d5b8cc8120aafe60a54425b2e445	knn-based weighted rough ν-twin support vector machine	tsvm;rough ν tsvm;weight;k nearest neighbor;local information	Twin support vector classification (TSVM) finds two nonparallel hyper-planes by solving a pair of smaller-sized quadratic programming problems (QPPs) rather than a single large one as in the classical support vector machine (SVM), which makes the learning speed of TSVM approximately four times faster than that of the standard SVM. However the same penalties are given to the samples, which reduces the classification accuracy of TSVM. To improve the classification accuracy, rough  ν -TSVM was proposed, where different penalties are given to the negative samples depending on their different positions when constructing separating hyper-plane for the positive samples. But the local information of positive samples is not exploited, and each positive sample shares the same weights in it. In fact, they have different effects on the separating hyper-planes. Inspired by the studies above, we propose a K-nearest neighbor (KNN)-based weighted rough  ν -twin support vector machine (Weighted rough  ν -TSVM) in this paper, in which not only different penalties are given to one class of samples, but also different weights are given to the other class of samples. So weighted rough  ν -TSVM yields higher testing accuracy in comparison with the state-of-the-art algorithms. Moreover, weighted rough  ν -TSVM costs lower than other algorithms since some redundant constraints are deleted. In addition, the influence of different number  K  of clusters is also discussed in this paper. Numerical experiments on forty-two benchmark datasets are performed to investigate the validity of our proposed algorithm. Experimental results show the effectiveness of our proposed algorithm.	k-nearest neighbors algorithm;support vector machine	Yitian Xu;Jia Yu;Yuqun Zhang	2014	Knowl.-Based Syst.	10.1016/j.knosys.2014.08.008	computer science;artificial intelligence;machine learning;pattern recognition;data mining;weight;k-nearest neighbors algorithm;statistics	ML	13.981402084637406	-40.40866214156791	29504
467e70f7c7eb83c817d370b9672b10d5d494fa0c	the best approximation to c2 functions and its error bounds using regular-center gaussian networks	regular mesh;optimisation;regular center gaussian networks;approximation error;best approximation;regular mesh best approximation c sup 2 functions error bounds regular center gaussian networks gaussian neural networks unit hypercube upper bound approximation error hidden neurons;upper bound;approximation theory;c 2 functions;error analysis;unit hypercube;gaussian neural networks;function approximation;approximation error neurons hypercubes interpolation neural networks upper bound nonhomogeneous media polynomials artificial neural networks fourier transforms;error analysis feedforward neural nets function approximation;radial basis network approximation c sup 2 functions error bounds gaussian neural networks hypercube upper bound hidden neurons;fourier transforms;optimisation feedforward neural nets function approximation approximation theory;error bounds;joining processes;hypercubes;hidden neurons;feedforward neural nets;approximation error fourier transforms hypercubes joining processes approximation methods;approximation methods;error bound;neural network	Gaussian neural networks are considered to approximate any C(2) function with support on the unit hypercube I(m)=[0, 1](m) in the sense of best approximation. An upper bound (O(N(-2))) of the approximation error is obtained in the present paper for a Gaussian network having N(m) hidden neurons with centers defined on a regular mesh in I(m).	approximation algorithm;approximation error;artificial neural network;gaussian elimination;neural network simulation;normal statistical distribution	Binfan Liu;Jennie Si	1994	IEEE transactions on neural networks	10.1109/72.317739	fourier transform;mathematical optimization;approximation error;combinatorics;function approximation;machine learning;mathematics;upper and lower bounds;artificial neural network;hypercube;approximation theory	ML	18.224981792227627	-29.358711168469714	29521
7737cb411c5992d57517ddcf31d8fde76d3b4fa4	rotation-based ensembles	decision tree;ensemble method;principal component analysis;random forest;experimental validation	A new method for ensemble generation is presented. It is based on grouping the attributes in di erent subgroups, and to apply, for each group, an axis rotation, using Principal Component Analysis. If the used method for the induction of the classi ers is not invariant to rotations in the data set, the generated classi er can be very different. Hence, once of the objectives aimed when generating ensembles is achieved, that the di erent classi ers were rather diverse. The majority of ensemble methods eliminate some information (e.g., instances or attributes) of the data set for obtaining this diversity. The proposed ensemble method transforms the data set in a way such as all the information is preserved. The experimental validation, using decision trees as base classi ers, is favorable to rotation based ensembles when comparing to Bagging, Random Forests and the most well-known version of Boosting.	apache axis;boosting (machine learning);decision tree;ensemble learning;principal component analysis;random forest	Juan José Rodríguez Diez;Carlos J. Alonso	2003		10.1007/978-3-540-25945-9_49	machine learning;pattern recognition;statistics	ML	14.216360927327528	-42.40486069968514	29540
4e2f01bad6dc38b85f07b68296d77f1389eec5ae	rnn-based model for self-adaptive systems		The human brain is the self-adaptive system par excellence. We claim that a hierarchical model for selfadaptive system can be built on two levels, the upper structural level S and the lower behavioral level B. The higher order structure naturally emerges from interactions of the system with its environment and it acts as coordinator of local interactions among simple reactive elements. The lower level regards the topology of the network whose elements self-organize to perform the behavior of the system. The adaptivity feature follows the self-organizing principle that supports the entanglement of lower level elements and the higher order structure. The challenging idea in this position paper is to represent the two-level model as a second order Long Short-Term Memory Recurrent Neural Network, a bio-inspired class of artificial neural networks, very powerful for dealing with the dynamics of complex systems and for studying the emergence of brain activities. It is our aim to experiment the model over real Electrocorticographical data (EcoG) for detecting the emergence of long-term neurological disorders such as epileptic seizures.	adaptive system;artificial neural network;british informatics olympiad;complex systems;emergence;hierarchical database model;interaction;long short-term memory;organizing (structure);quantum entanglement;random neural network;recurrent neural network;self-organization;sensor	Emanuela Merelli;Marco Piangerelli	2014		10.5220/0005165003560361	adaptive system;structural level;complex system;position paper;hierarchical database model;quantum entanglement;artificial neural network;artificial intelligence;machine learning;recurrent neural network;computer science	AI	11.251868437120454	-27.570579155944866	29573
09203047e4446e37d66134dbed1b011d8af7d2b6	coping with uncertainty in map learning	maps;learning;mobile robot;uncertainty;learning model;boolean function;graphs;space use;learning problems;inference;probably approximately correct;noise;approaches to learning	In many applications in mobile robotics, it is important for a robot to explore its environment in order to construct a representation of space useful for guiding movement. We refer to such a representation as a map, and the process of constructing a map from a set of measurements as map learning. In this paper, we develop a framework for describing map-learning problems in which the measurements taken by the robot are subject to known errors. We investigate approaches to learning maps under such conditions based on Valiant's probably approximately correct learning model. We focus on the problem of coping with accumulated error in combining local measurements to make global inferences. In one approach, the effects of accumulated error are eliminated by the use of local sensing methods that never mislead but occasionally fail to produce an answer. In another approach, the effects of accumulated error are reduced to acceptable levels by repeated exploration of the area to be learned. We also suggest some insights into why certain existing techniques for map learning perform as well as they do. The learning problems explored in this paper are quite different from most of the classification and boolean-function learning problems appearing in the literature. The methods described, while specific to map learning, suggest directions to take in tackling other learning problems.	map;mobile robot;probably approximately correct learning;robotics	Kenneth Basye;Thomas L. Dean;Jeffrey Scott Vitter	1989	Machine Learning	10.1023/A:1007418008480	semi-supervised learning;unsupervised learning;mobile robot;proactive learning;multi-task learning;instance-based learning;error-driven learning;algorithmic learning theory;uncertainty;computer science;noise;artificial intelligence;online machine learning;machine learning;data mining;inductive transfer;mathematics;boolean function;graph;stability;competitive learning;computational learning theory;active learning;probably approximately correct learning;statistics;generalization error	ML	17.714433860066464	-34.00726330402609	29589
7ee084d71812aafe809c92ce96a0f91e5bfae0c8	a soft decision rule for sparse signal modeling via dempster–shafer evidential reasoning	synthetic aperture radar sar target recognition classification dempster shafer theory of evidence ds soft decision sparse representation;uncertainty;training;measurement uncertainty;target recognition;image reconstruction;cognition;synthetic aperture radar bayes methods geophysical signal processing object recognition remote sensing by radar signal representation;synthetic aperture radar target recognition uncertainty image reconstruction training cognition measurement uncertainty;synthetic aperture radar target recognition sparse signal modeling bayesian estimation soft decision rule dempster shafer evidential reasoning samplewise ambiguity classwise ambiguity sparse representation coefficient;synthetic aperture radar	Recently, the problem of recovering sparse linear representation of a query in terms of a redundant dictionary has received great interest. The query sample is represented as a linear combination of the atoms of the dictionary. The unique representation is obtained via sparsity constraint, and the decision is made in terms of the characteristics of representation on reconstruction. The decision rule for sparse signal modeling can be viewed as a typical application of Bayesian estimation, where the likelihood function is inversely proportional to the reconstruction error. Different from the conventional rule, where the decision is directly made according to the overall reconstruction error associated with each class, this letter proposes a soft decision via Dempster-Shafer theory of evidence. To model the imprecision on uncertainty measurement, we introduce the samplewise ambiguity and the classwise ambiguity during the quantification of probability mass. Each sample that participates in the recovery of the query is considered as an item of evidence that supports certain hypothesis in regard to the class membership of query. The amount of evidence is quantified by a function of the distance between the query and the weighted training sample, where the weights result from the sparse representation coefficient. Then, various pieces of evidence derived from the candidate samples are pooled by means of Dempster's rule of combination, from which a soft decision can be reached.	coefficient;dictionary;sparse approximation;sparse matrix	Ganggang Dong;Gangyao Kuang	2016	IEEE Geoscience and Remote Sensing Letters	10.1109/LGRS.2016.2596301	iterative reconstruction;computer vision;synthetic aperture radar;cognition;uncertainty;machine learning;pattern recognition;mathematics;statistics;measurement uncertainty	Vision	-0.18022573968428396	-28.758180653046015	29637
b943952cf34256c59a6bbd0bc8e0d8e4c46a0bdd	a new model of evaluating concept similarity	concept similarity;concept lattice;join irreducible;meet irreducible;rough set	In this paper, a new similarity model is proposed, which based on rough set to evaluate the similarity degree of the two concepts of concept lattice. The proposed method combines featural and structural information into decision and has a higher correlation with human judgement, which can be viewed as the development of Tversky's similarity model. Compared with other similarity models this approach is convenient to measure the similarity of the concepts of the large contexts, by which we can avoid constructing Hasse diagram and looking through all concepts of the context.		Lidong Wang;Xiaodong Liu	2008	Knowl.-Based Syst.	10.1016/j.knosys.2008.03.042	semantic similarity;rough set;computer science;machine learning	NLP	-3.951534067709626	-25.231713150457704	29641
69b83ab508deee05bc028490fa7cdcb39960ce5a	induction of expressive rules using the binary coding method	conference;meeting	In most rule-induction algorithms, the only operator used against nominal attributes is the equality operator =. In this paper, we first propose the use of the inequality operator, , in addition to the equality operator, to increase the expressiveness of induced rules. Then, we present a new method, Binary Coding, which can be used along with an arbitrary rule-induction algorithm to make use of the inequality operator without any need to change the algorithm. Experimental results suggest that the Binary Coding method is promising enough for further investigation, especially in cases where the minimum number of rules is desirable. Keywords—Data mining, Inequality operator, Number of rules, Rule-induction.	algorithm;binary number;data mining;relational operator;rule induction;social inequality	Seyed R. Mousavi	2005			speech recognition;computer science;artificial intelligence;data mining	ML	-3.6332657633150145	-27.53662036936578	29677
0410659b6a311b281d10e0e44abce9b1c06be462	a gift from knowledge distillation: fast optimization, network minimization and transfer learning		We introduce a novel technique for knowledge transfer, where knowledge from a pretrained deep neural network (DNN) is distilled and transferred to another DNN. As the DNN performs a mapping from the input space to the output space through many layers sequentially, we define the distilled knowledge to be transferred in terms of flow between layers, which is calculated by computing the inner product between features from two layers. When we compare the student DNN and the original network with the same size as the student DNN but trained without a teacher network, the proposed method of transferring the distilled knowledge as the flow between two layers exhibits three important phenomena: (1) the student DNN that learns the distilled knowledge is optimized much faster than the original model, (2) the student DNN outperforms the original DNN, and (3) the student DNN can learn the distilled knowledge from a teacher DNN that is trained at a different task, and the student DNN outperforms the original DNN that is trained from scratch.	artificial neural network;autonomous robot;deep learning;machine learning;network security toolkit;gift	Junho Yim;Donggyu Joo;Jihoon Bae;Junmo Kim	2017	2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)	10.1109/CVPR.2017.754	knowledge engineering;artificial intelligence;transfer of learning;pattern recognition;minification;feature extraction;computer science;scratch;artificial neural network;machine learning;knowledge transfer	Vision	21.046728464598605	-49.68541249602334	29684
012c97ca0429492c8a30b1640ea2fe3ebfffc63d	individual sequence prediction using memory-efficient context trees	modelizacion;espace hilbert;on line systems;individual sequence;evaluation performance;optimisation;gestion memoire;shifting bounds context trees online learning perceptron;espacio hilbert;performance evaluation;optimizacion;learning;hilbert spaces;storage management;evaluacion prestacion;context tree;online optimization;tratamiento lenguaje;context trees;online learning;trees mathematics;indexing terms;algorithme;aprendizaje;upper bound;hilbert space;modelisation;algorithm;gestion memoria;arbre contextuel;apprentissage;machine learning;language processing;trees mathematics hilbert spaces learning artificial intelligence optimisation pattern recognition;systeme en ligne;machine learning hilbert space machine learning algorithms prediction algorithms context modeling predictive models particle separators upper bound stochastic processes game theory;traitement langage;prediccion lineal;pattern recognition;shifting mistake bound individual sequence prediction memory efficient context trees linear separator hilbert space machine learning online optimization perceptron algorithm shallow perceptron;optimization;linear prediction;perceptron;learning artificial intelligence;reseau neuronal;borne superieure;modeling;shifting bounds;arbol contextual;language model;prediction lineaire;cota superior;algoritmo	Context trees are a popular and effective tool for tasks such as compression, sequential prediction, and language modeling. We present an algebraic perspective of context trees for the task of individual sequence prediction. Our approach stems from a generalization of the notion of margin used for linear predictors. By exporting the concept of margin to context trees, we are able to cast the individual sequence prediction problem as the task of finding a linear separator in a Hilbert space, and to apply techniques from machine learning and online optimization to this problem. Our main contribution is a memory efficient adaptation of the perceptron algorithm for individual sequence prediction. We name our algorithm the shallow perceptron and prove a shifting mistake bound, which relates its performance with the performance of any sequence of context trees. We also prove that the shallow perceptron grows a context tree at a rate that is upper bounded by its mistake rate, which imposes an upper bound on the size of the trees grown by our algorithm.	algorithm;hilbert space;language model;linear separability;machine learning;margin (machine learning);mathematical optimization;online optimization;perceptron	Ofer Dekel;Shai Shalev-Shwartz;Yoram Singer	2009	IEEE Transactions on Information Theory	10.1109/TIT.2009.2030460	computer science;artificial intelligence;machine learning;mathematics;algorithm;statistics;language model;hilbert space	ML	19.951317046174356	-30.98898810957177	29727
83d53b1adfbf4d93e12e6abb220bd52224feee4a	using most similarity tree based clustering to select the top most discriminating genes for cancer detection	dna;dimensionalidad;cancerology;metodo adaptativo;analyse amas;raisonnement base sur cas;razonamiento fundado sobre caso;analisis estadistico;cancer;tumor maligno;redundancia;soft computing;information technology;dimensionality;hombre;curse of dimensionality;dna array;technologie information;methode adaptative;intelligence artificielle;calculo flexible;probabilistic approach;classification;similitude;cluster analysis;redundancy;statistical analysis;dimensionnalite;enfoque probabilista;approche probabiliste;cancerologie;adaptive method;analyse statistique;similarity;human;calcul souple;number of clusters;artificial intelligence;analisis cluster;tumeur maligne;cancerologia;inteligencia artificial;similitud;information system;case based reasoning;perceptron;reseau neuronal;tecnologia informacion;discriminacion;gene selection;similarity measure;clasificacion;red neuronal;systeme information;discrimination;redondance;malignant tumor;homme;neural network;sistema informacion	The development of DNA array technology makes it feasible to cancer detection with DNA array expression data. However, the research is usually plagued with the problem of “curse of dimensionality”, and the capability of discrimination is weakened seriously by the noise and the redundancy that are abundant in these datasets. This paper proposes a hybrid gene selection method for cancer detection based on clustering of most similarity tree (CMST). By this method, a number of non-redundant clusters and the most discriminating gene from each cluster can be acquired. These discriminating genes are then used for training of a perceptron that produces a very efficient classification. In CMST, the Gap statistic is used to determine the optimal similarity measure λ and the number of clusters. And a gene selection method with optimal self-adaptive CMST(OS-CMST) for cancer detection is presented. The experiments show that the gene pattern pre-processing based on CMST not only reduces the dimensionality of the attributes significantly but also improves the classification rate effectively in cancer detection. And the selection scheme based on OS-CMST can acquire the top most discriminating genes.		Xinguo Lu;Yaping Lin;Xiaolin Yang;Lijun Cai;Haijun Wang;Gustaph Sanga	2006		10.1007/11785231_98	curse of dimensionality;computer science;artificial intelligence;machine learning;data mining;mathematics;soft computing;information technology;artificial neural network;cancer	NLP	9.750695356243245	-32.76965374157574	29738
44afec6196baa0a6683c82b60f453e0c00c95cfe	decision tree twin support vector machine based on kernel clustering for multi-class classification		To deal with multi-class classification problems using twin support vector machines (TWSVMs), this paper proposes a novel multi-class classifier, decision tree twin support vector machine based on kernel clustering (DT2SVM-KC). We employ the kernel clustering algorithm to generate a binary tree, and for each non-leaf node, we obtain a pair of non-parallel hyperplanes by using TWSVM. Simulation results show that the proposed method can keep the strength of decision tree in computation time and has better performance on most used datasets compared with other multi-class classification methods based on TWSVMs.		Qingyun Dou;Li Zhang	2018		10.1007/978-3-030-04212-7_25	kernel (statistics);kernel (linear algebra);support vector machine;artificial intelligence;pattern recognition;cluster analysis;machine learning;decision tree;binary tree;computer science;classifier (linguistics);multiclass classification	ML	10.318758491446513	-40.550243635382564	29815
65ca5a05c7c7ea901c03b96441e5feb6f48ba678	a practical tutorial on autoencoders for nonlinear feature fusion: taxonomy, models, software and guidelines		Many of the existing machine learning algorithms, both supervised and unsupervised, depend on the quality of the input characteristics to generate a good model. The amount of these variables is also important, since performance tends to decline as the input dimensionality increases, hence the interest in using feature fusion techniques, able to produce feature sets that are more compact and higher level. A plethora of procedures to fuse original variables for producing new ones has been developed in the past decades. The most basic ones use linear combinations of the original variables, such as PCA (Principal Component Analysis) and LDA (Linear Discriminant Analysis), while others find manifold embeddings of lower dimensionality based on non-linear combinations, such as Isomap or LLE (Linear Locally Embedding) techniques. More recently, autoencoders (AEs) have emerged as an alternative to manifold learning for conducting nonlinear feature fusion. Dozens of AE models have been proposed lately, each with its own specific traits. Although many of them can be used to generate reduced feature sets through the fusion of the original ones, there also AEs designed with other applications in mind. The goal of this paper is to provide the reader with a broad view of what an AE is, how they are used for feature fusion, a taxonomy gathering a broad range of models, and how they relate to other classical techniques. In addition, a set of didactic guidelines on how to choose the proper AE for a given task is supplied, together with a discussion of the software tools available. Finally, two case studies illustrate the usage of AEs with datasets of handwritten digits and breast cancer.	algorithm;autoencoder;didactic organisation;evolutionary taxonomy;feature model;isomap;linear discriminant analysis;machine learning;nonlinear dimensionality reduction;nonlinear system;principal component analysis;supervised learning;taxonomy (general);unsupervised learning	David Charte;Francisco Charte;Salvador García;María José del Jesús;Francisco Herrera	2018	Information Fusion	10.1016/j.inffus.2017.12.007	isomap;pattern recognition;machine learning;artificial intelligence;mathematics;linear combination;curse of dimensionality;nonlinear system;software;linear discriminant analysis;nonlinear dimensionality reduction;principal component analysis	ML	18.17486781154622	-48.9922570512315	29943
aa5517cbd74324b94a66c5492cdea00150c2eacc	a novel variable selection approach for redundant information elimination purpose of process control	modified pls;least squares approximations;process industry case study;input variables process control multivariate regression fault detection;input variables;tennessee eastman process tep;pls regression;regression analysis least squares approximations process control;redundant information elimination;variable selection;variable selection modified pls process control tennessee eastman process;fault detection;process control;variable selection approach;tennessee eastman process;regression analysis;process industry case study variable selection approach redundant information elimination process control subset selection approach partial least squares regression pls regression;subset selection approach;modified partial least squares pls;multivariate regression;partial least squares regression	In this paper, an efficient variable and subset selection approach related to modified partial least squares (PLS) regression are proposed and applied to numerical and industry application to show the superior of the results. The main purpose of the proposed variable selection approach is to offer further useful information to identification, control as well as diagnosis. The significant advantage of the modified PLS-based variable selection method is to keep the superior fitting and prediction performance as well as the significantly reduced number of selected variables. To this aim, the canonical and modified PLS regression methods have been introduced. Then an effective and precise variable selection method which can select the most significant elements among huge redundant information is proposed. To this end, the effectiveness of the proposed variable selection method is demonstrated by the simulation results of a numerical instance and a process industry case study.	feature selection;numerical analysis;partial least squares regression;preprocessor;selection (genetic algorithm);simulation	Jiachen Li;Chaojing Duan;Zhongyang Fei	2016	IEEE Transactions on Industrial Electronics	10.1109/TIE.2015.2498909	econometrics;multivariate statistics;computer science;engineering;machine learning;process control;partial least squares regression;fault detection and isolation;regression analysis;statistics	EDA	23.32201938399521	-23.99937868919218	29965
b40368c6931fbb0f1dc4dbabb2e26234c5ac22b0	pathway-based microarray analysis for robust disease classification	phenotype correlated genes;microarray analysis;discriminative score;disease classification;pathway activity;negatively correlated feature sets	The advent of high-throughput technology has made it possible to measure genome-wide expression profiles, thus providing a new basis for microarray-based diagnosis of disease states. Numerous methods have been proposed to identify biomarkers that can accurately discriminate between case and control classes. Many of the methods used only a subset of ranked genes in the pathway and may not be able to fully represent the classification boundaries for the two disease classes. The use of negatively correlated feature sets (NCFS) to obtain more relevant features in form of phenotype-correlated genes (PCOGs) and inferring pathway activities is proposed in this study. The two pathway activity inference schemes that use NCFS significantly improved the power of pathway markers to discriminate between two phenotypes classes in microarray expression datasets of breast cancer. In particular, the NCFS-i method provided better contrasting features for classification purposes. The improvement is consistent for all cases of pathways used, using both within- and across-dataset validations. The results show that the two proposed methods that use NCFS clearly outperformed other pathway-based classifiers in terms of both ROC area and discriminative score. That is, the identification of PCOGs within each pathway, especially NCFS-i method, helps to reduce noisy or variable measurements, leading to a high performance and more robust classifier. In summary, we have demonstrated that effective incorporation of pathway information into expression-based disease diagnosis and using NCFS can provide better discriminative and more robust models.	discriminative model;gene regulatory network;high-throughput computing;linear classifier;memory-level parallelism;microarray;throughput	Pitak Sootanan;Santitham Prom-on;Asawin Meechai;Jonathan H. Chan	2011	Neural Computing and Applications	10.1007/s00521-011-0662-y	microarray analysis techniques;computer science;bioinformatics;pattern recognition;data mining	ML	8.914256155833447	-51.22245737425481	29971
7c583418d3eeff4bece6a08301a93a14c28672e7	artificial neural networks : biological inspirations - icann 2005 : 15th international conference, warsaw, poland, september 11-15, 2005 : proceedings, part i		Modeling the Brain and Cognitive Functions.- Novelty Analysis in Dynamic Scene for Autonomous Mental Development.- The Computational Model to Simulate the Progress of Perceiving Patterns in Neuron Population.- Short Term Memory and Pattern Matching with Simple Echo State Networks.- Analytical Solution for Dynamic of Neuronal Populations.- Dynamics of Cortical Columns - Sensitive Decision Making.- Dynamics of Cortical Columns - Self-organization of Receptive Fields.- Optimal Information Transmission Through Cortico-Cortical Synapses.- Ensemble of SVMs for Improving Brain Computer Interface P300 Speller Performances.- Modelling Path Integrator Recalibration Using Hippocampal Place Cells.- Coding of Objects in Low-Level Visual Cortical Areas.- A Gradient Rule for the Plasticity of a Neuronu0027s Intrinsic Excitability.- Building the Cerebellum in a Computer.- Special Session: The Development of Cognitive Powers in Embodied Systems.- Combining Attention and Value Maps.- Neural Network with Memory and Cognitive Functions.- Associative Learning in Hierarchical Self Organizing Learning Arrays.- A Review of Cognitive Processing in the Brain.- Spiking Neural Networks.- Neuronal Behavior with Sub-threshold Oscillations and Spiking/Bursting Activity Using a Piecewise Linear Two-Dimensional Map.- On-Line Real-Time Oriented Application for Neuronal Spike Sorting with Unsupervised Learning.- A Spiking Neural Sparse Distributed Memory Implementation for Learning and Predicting Temporal Sequences.- ANN-Based System for Sorting Spike Waveforms Employing Refractory Periods.- Emergence of Oriented Cell Assemblies Associated with Spike-Timing-Dependent Plasticity.- An Information Geometrical Analysis of Neural Spike Sequences.- Perceptual Binding by Coupled Oscillatory Neural Network.- Experimental Demonstration of Learning Properties of a New Supervised Learning Method for the Spiking Neural Networks.- Single-Unit Recordings Revisited: Activity in Recurrent Microcircuits.- A Hardware/Software Framework for Real-Time Spiking Systems.- Efficient Source Detection Using Integrate-and-Fire Neurons.- Associative Memory Models.- A Model for Hierarchical Associative Memories via Dynamically Coupled GBSB Neural Networks.- Balance Algorithm for Point-Feature Label Placement Problem.- Models of Self-correlation Type Complex-Valued Associative Memories and Their Dynamics.- Recovery of Performance in a Partially Connected Associative Memory Network Through Coding.- Optimal Triangle Stripifications as Minimum Energy States in Hopfield Nets.- Models of Biological Functions.- A Biophysical Model of Decision Making in an Antisaccade Task Through Variable Climbing Activity.- Can Dynamic Neural Filters Produce Pseudo-Random Sequences?.- Making Competition in Neural Fields Suitable for Computational Architectures.- Neural Network Computations with Negative Triggering Thresholds.- A Model for Delay Activity Without Recurrent Excitation.- Neuronal Coding Strategies for Two-Alternative Forced Choice Tasks.- Learning Features of Intermediate Complexity for the Recognition of Biological Motion.- Study of Nitric Oxide Effect in the Hebbian Learning: Towards a Diffusive Hebbu0027s Law.- Special Session: Projects in the Area of NeuroIT.- Deterministic Modelling of Randomness with Recurrent Artificial Neural Networks.- Action Understanding and Imitation Learning in a Robot-Human Task.- Comparative Investigation into Classical and Spiking Neuron Implementations on FPGAs.- HYDRA: From Cellular Biology to Shape-Changing Artefacts.- The CIRCE Head: A Biomimetic Sonar System.- Tools for Address-Event-Representation Communication Systems and Debugging.- New Ears for a Robot Cricket.- Reinforcement Learning in MirrorBot.- Evolutionary and Other Biological Inspirations.- Varying the Population Size of Artificial Foraging Swarms on Time Varying Landscapes.- Lamarckian Clonal Selection Algorithm with Application.- Analysis for Characteristics of GA-Based Learning Method of Binary Neural Networks.- Immune Clonal Selection Wavelet Network Based Intrusion Detection.- Investigation of Evolving Populations of Adaptive Agents.- Enhancing Cellular Automata by an Embedded Generalized Multi-layer Perceptron.- Intelligent Pattern Generation for a Tactile Communication System.- Self-organizing Maps and Their Applications.- Self-organizing Map Initialization.- Principles of Employing a Self-organizing Map as a Frequent Itemset Miner.- Spatio-Temporal Organization Map: A Speech Recognition Application.- Residual Activity in the Neurons Allows SOMs to Learn Temporal Order.- Ordering of the RGB Space with a Growing Self-organizing Network. Application to Color Mathematical Morphology.- SOM of SOMs: Self-organizing Map Which Maps a Group of Self-organizing Maps.- The Topographic Product of Experts.- Self Organizing Map (SOM) Approach for Classification of Power Quality Events.- SOM-Based Method for Process State Monitoring and Optimization in Fluidized Bed Energy Plant.- A New Extension of Self-optimizing Neural Networks for Topology Optimization.- A Novel Technique for Data Visualization Based on SOM.- Statistical Properties of Lattices Affect Topographic Error in Self-organizing Maps.- Increasing Reliability of SOMsu0027 Neighbourhood Structure with a Bootstrap Process.- Computer Vision.- Artificial Neural Receptive Field for Stereovision.- Pattern Detection Using Fast Normalized Neural Networks.- Neural Network Model for Extracting Optic Flow.- A Modular Single-Hidden-Layer Perceptron for Letter Recognition.- Fast Color-Based Object Recognition Independent of Position and Orientation.- Class-Specific Sparse Coding for Learning of Object Representations.- Neural Network Based Adult Image Classification.- Online Learning for Object Recognition with a Hierarchical Visual Cortex Model.- Extended Hopfield Network for Sequence Learning: Application to Gesture Recognition.- Accurate and Robust Image Superresolution by Neural Processing of Local Image Representations.- The Emergence of Visual Object Recognition.- Implicit Relevance Feedback from Eye Movements.- Image Segmentation by Complex-Valued Units.- Cellular Neural Networks for Color Image Segmentation.- Image Segmentation Using Watershed Transform and Feed-Back Pulse Coupled Neural Network.- Adaptive Switching Median Filter with Neural Network Impulse Detection Step.- Face Recognition and Detection.- Human Face Detection Using New High Speed Modular Neural Networks.- Face Detection Using Convolutional Neural Networks and Gabor Filters.- Face Identification Performance Using Facial Expressions as Perturbation.- Discriminative Common Images for Face Recognition.- Classification of Face Images for Gender, Age, Facial Expression, and Identity.- Sound and Speech Recognition.- Classifying Unprompted Speech by Retraining LSTM Nets.- Temporal Sound Processing by Cochlear Nucleus Octopus Neurons.- A SOM Based 2500 - Isolated - Farsi - Word Speech Recognizer.- Training HMM/ANN Hybrid Speech Recognizers by Probabilistic Sampling.- Chord Classifications by Artificial Neural Networks Revisited: Internal Representations of Circles of Major Thirds and Minor Thirds.- Bioinformatics.- Biclustering Gene Expression Data in the Presence of Noise.- Gene Extraction for Cancer Diagnosis by Support Vector Machines.- High-Throughput Multi-dimensional Scaling (HiT-MDS) for cDNA-Array Expression Data.- Biomedical Applications.- Comparing Neural Network Architecture for Pattern Recognize System on Artificial Noses.- Medical Document Categorization Using a Priori Knowledge.- A Neurofuzzy Methodology for the Diagnosis of Wireless-Capsule Endoscopic Images.- Neural Network Use for the Identification of Factors Related to Common Mental Disorders.- Development and Realization of the Artificial Neural Network for Diagnostics of Stroke Type.- Special Session: Information-Theoretic Concepts in Biomedical Data Analysis.- A First Attempt at Constructing Genetic Programming Expressions for EEG Classification.- SOM-Based Wavelet Filtering for the Exploration of Medical Images.- Functional MRI Analysis by a Novel Spatiotemporal ICA Algorithm.- Early Detection of Alzheimeru0027s Disease by Blind Source Separation, Time Frequency Representation, and Bump Modeling of EEG Signals.		Włodzisław Duch;Janusz Kacprzyk;Erkki Oja;Sławomir Zadrożny	2005		10.1007/11550822	computer science;artificial intelligence;machine learning;time delay neural network;artificial neural network	Robotics	-0.7350926274956653	-45.49711816811911	29986
f7bf5866019aefe9e647c472e0044eb665133300	extreme value theory for open set classification - gpd and gev classifiers		Classification tasks usually assume that all possible classes are present during the training phase. This is restrictive if the algorithm is used over a long time and possibly encounters samples from unknown classes. The recently introduced extreme value machine, a classifier motivated by extreme value theory, addresses this problem and achieves competitive performance in specific cases. We show that this algorithm can fail when the geometries of known and unknown classes differ. To overcome this problem, we propose two new algorithms relying on approximations from extreme value theory. We show the effectiveness of our classifiers in simulations and on the LETTER and MNIST data sets.	algorithm;approximation;extreme value theory;iso/iec 11404;mnist database;maxima and minima;simulation	Edoardo Vignotto;Sebastian Engelke	2018	CoRR		artificial intelligence;machine learning;extreme value theory;mathematics;open set;mnist database;classifier (linguistics);data set	ML	19.533709447798255	-33.989161418691126	30036
77772edad05145511591219b68fb3a161cd5f39c	ultrasonic transducer characterization by neural networks	fuzzy artmap;neural networks;backpropagation neural network;kultrasonic transducers;classification;competitive learning;radial basis function network;characterization;pattern recognition;self organized map;classification accuracy;probabilistic neural network;modular neural network;artificial neural network;learning vector quantization;neural network	"""This paper presents neural network-based system for the characterization of ultrasonic transducers. An automated system for characterizing ultrasonic transducers was designed and built. Different characterizing algorithms were applied and their performance was investigated and compared. It was found that artificial neural network (ANN) techniques, in general, provide better classification as compared to the pattern recognition techniques we applied earlier (M.S. Obaidat, J.W. Ekis, IEEE Transactions on Instrumentation and Measurements, 40 (5) (1991) 847-850). The Moody-Darken Radial Basis Function network (MD-RBFN), Learning Vector Quantization (LVQ) with 52 kohonen neurons, and Fuzzy ARTMAP classification network are the neural networks (NNs) that provided us with a classification accuracy of 100%. Several variants of Backpropagation neural network (BPNN) were tested for this application, and the classification results were seen to vary in the range 6.55%-98.35%. The best performing paradigm among several variants of the Modular Neural Network (MNN), Reinforcement Neural Network (RNN), Probabilistic Neural Network (PNN), and Counterpropagation Neural Network (CPNN) produced a classification accuracy of"""" 78.85%, 31.42%, 45.21°/,), and 79.28%, respectively. The competitive learning (CL) technique provided poor results as compared to the Self-Organizing-Map (SOM) for preclustering. © 1998 Elsevier Science Inc. All rights reserved."""	algorithm;artificial neural network;backpropagation;competitive learning;j.w. graham medal;learning vector quantization;modular neural network;pattern recognition;probabilistic neural network;programming paradigm;radial basis function network;random neural network;self-organizing map;transducer	Mohammad S. Obaidat;Humayun Khalid;Balqies Sadoun	1998	Inf. Sci.	10.1016/S0020-0255(97)10048-2	probabilistic neural network;types of artificial neural networks;learning vector quantization;biological classification;computer science;artificial intelligence;machine learning;pattern recognition;time delay neural network;competitive learning;radial basis function network;artificial neural network	ML	9.636024187083548	-37.17068512674738	30146
3897dde6e1b9e939a6d7be69c33c1c4bec5e6eaa	adaptive resolution min-max classifiers	performance evaluation sensitivity analysis particle measurements design automation function approximation intelligent systems force measurement system testing robustness;fuzzy neural nets;performance evaluation;sensitivity analysis adaptive resolution min max classifiers data driven modeling tools classification systems design training algorithms neurofuzzy classifiers min max networks hyperbox membership functions learning algorithms fuzzy min max neural classifiers adaptive resolution classifier pruning adaptive resolution classifier generalization recursive cutting procedure performance evaluation;automatic training;adaptive resolution classifier arc;classification;min max model;sensitivity analysis;pruning adaptive resolution classifier parc;pattern classification;performance evaluation pattern classification learning artificial intelligence fuzzy neural nets generalisation artificial intelligence;generalisation artificial intelligence;learning artificial intelligence	A high automation degree is one of the most important features of data driven modeling tools and it should be taken into consideration in classification systems design. In this regard, constructive training algorithms are essential to improve the automation degree of a modeling system. Among neuro-fuzzy classifiers, Simpson's (1992) min-max networks have the advantage of being trained in a constructive way. The use of the hyperbox, as a frame on which different membership functions can be tailored, makes the min-max model a flexible tool. However, the original training algorithm evidences some serious drawbacks, together with a low automation degree. In order to overcome these inconveniences, in this paper two new learning algorithms for fuzzy min-max neural classifiers are proposed: the adaptive resolution classifier (ARC) and its pruning version (PARC). ARC/PARC generates a regularized min-max network by a succession of hyperbox cuts. The generalization capability of ARC/PARC technique mostly depends on the adopted cutting strategy. By using a recursive cutting procedure (R-ARC and R-PARC) it is possible to obtain better results. ARC, PARC, R-ARC, and R-PARC are characterized by a high automation degree and allow to achieve networks with a remarkable generalization capability. Their performances are evaluated through a set of toy problems and real data benchmarks. The paper also proposes a suitable index that can be used for the sensitivity analysis of the classification systems under consideration.	algorithm;benchmark (computing);cns disorder;classification;entity name part qualifier - adopted;generalization (psychology);incised wound;machine learning;maxima and minima;multistage interconnection networks;neuro-fuzzy;performance;recursion;simpson's rule;succession;systems design;hiv-infection/aids	Antonello Rizzi;Massimo Panella;Fabio Massimo Frattale Mascioli	2002	IEEE transactions on neural networks	10.1109/72.991426	biological classification;computer science;artificial intelligence;machine learning;pattern recognition;sensitivity analysis	Robotics	4.310682903890475	-28.161467610169556	30189
af545cc5c02a2ac93765b457e6e4dff0f163fac8	on the structure of syntenic distance	gene order;connected component;lower bound	This paper examines some of the rich structure of the syntenic distance model of evolutionary distance, introduced by Ferretti et al. (1996). The syntenic distance between two genomes is the minimum number of fissions, fusions, and translocations required to transform one into the other, ignoring gene order within chromosomes. We prove that the previously unanalyzed algorithm given by Ferretti et al. (1996) is a 2-approximation and no better, and that, further, it always outperforms the algorithm presented by DasGupta et al. (1998). We also prove the same results for an improved version of the Ferretti et al. algorithm. We then prove a number of properties which give insight into the structure of optimal move sequences. We give instances in which any move sequence working solely within connected components is nearly twice optimal and prove a general lower bound based on the spread of genes from each chromosome. We then prove a monotonicity property for the syntenic distance, and bound the difficulty of the hardest instance of any size. We discuss the results of implementing these algorithms and testing them on real and simulated synteny data.	approximation algorithm;chromosomal translocation;chromosomes;connected component (graph theory);genome;ibm notes;synteny;version;whole exome sequencing	David Liben-Nowell	2001	Journal of computational biology : a journal of computational molecular cell biology	10.1089/106652701300099092	combinatorics;discrete mathematics;connected component;topology;mathematics;upper and lower bounds	Comp.	0.5749430705871593	-50.916641793045486	30249
0296f341ec90f47c4ff2e425350503b54499a860	a hybrid deep boltzmann functional link network for classification problems	electronic mail;support vector machines;training;nonlinear distortion;stochastic processes;benchmark testing	This paper proposes a hybrid deep learning algorithm, namely, the Deep Boltzmann Functional Link Network (DBFLN) for classification problems. A Deep Boltzmann Machine (DBM) with two layers of Restricted Boltzmann Machine is the generative model that is used to generate stochastic features and input weights for the discriminative model. A discriminative Functional Link Network (FLN) uses these features to approximate the nonlinear relationship between a set of features and their classes. FLN has three layers, namely, the input layer, the enhancement layer and the output layer. In a DBFLN, the features generated at the two hidden layers of the DBM act as the input features and the enhancement layer responses of the FLN. The output weights of the FLN are then estimated as a solution to a linear programming problem through pseudo-inverse. We first evaluate the performance of the DBFLN on three benchmark multi-category classification problems from the UCI machine learning repository, namely, the image segmentation problem, the vehicle classification problem and the glass identification problem. Performance study results on the benchmark classification problems show that DBFLN is an efficient classifier. We then use the DBFLN to classify the images in the TID2013 data set, based on their depth of distortions. The TID2013 data set comprises of 25 images, each with 5 levels of 24 distortion types. In all, the data set has 3000 images, which can be classified based on the depth of distortion. Thus, the IQA classification problem is defined as classifying the distorted images into one of the 5 classes (depending on the depth of distortion) using human visual image metrics as the input features. The performance of the DBFLN in classifying the image quality is compared with those of Support Vector Machines, Extreme Learning Machines, Random Vector Functional Link Network, and Deep Belief Network. Performance studies show the superior classification ability of the DBFLN.	approximation algorithm;bayesian network;benchmark (computing);dbm;deep belief network;deep learning;discriminative model;distortion;generative model;greedy algorithm;image quality;image segmentation;linear programming;machine learning;mike lesser;nonlinear system;restricted boltzmann machine;statistical classification;stochastic process;support vector machine	Ramasamy Savitha;Kit Yan Chan;Phyo Phyo San;Sai-Ho Ling;S. Suresh	2016	2016 IEEE Symposium Series on Computational Intelligence (SSCI)	10.1109/SSCI.2016.7850114	machine learning;pattern recognition;data mining;mathematics;deep belief network	ML	23.963985120302045	-47.188544822658876	30253
4e5ea1d4a85bf27a6105a9a6cc66f561b02de70f	accelerating microbiomic big data analysis by spectral interpolation	interpolation;phylogeny;sequential analysis;microbial communities accelerating microbiomic big data analysis dimensionality reduction dimensionality visualization intrinsic high dimensionality feature space microbiome sequencing data 16s rrna large scale microbiome computational complexity spectral interpolation technique;euclidean distance;phylogeny interpolation data visualization big data euclidean distance sequential analysis;visualization microbiome big data unifrac dimensionality reduction;big data;data visualization;spectral analysis bioinformatics cellular biophysics computational complexity data analysis interpolation microorganisms molecular biophysics molecular configurations rna	Dimensionality reduction and visualization are two important procedures in microbiome data analysis. With the intrinsic high dimensionality of the feature space in raw microbiome sequencing data, such as 16S rRNA, it requires proper simplification for possible further analysis. The explosively increasing size of data from large-scale microbiome studies inevitably and exponentially raises the computational complexity of existing algorithms, which is an urgent issue standing in the way requires addressing. This study proposed a new approach for dimensionality reduction and visualization on microbiome sequencing data associated with the very issue. This method not only greatly improves the efficiency of computing on microbiomic big data analysis by spectral interpolation technique but also preserves as much information as possible from original data with decent visualization results. With this adaptive method introduced to the large-scale studies of microbiome, we can better facilitate the revealing of patterns and insights of microbial communities.	algorithm;big data;computational complexity theory;dimensionality reduction;feature vector;interpolation;level of detail	Bo Song;Xingpeng Jiang;Xiaohua Hu	2014	2014 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)	10.1109/BIBM.2014.6999308	big data;interpolation;computer science;bioinformatics;data science;sequential analysis;data mining;euclidean distance;data visualization;statistics	Visualization	-1.006281094998981	-46.582519965819415	30313
04a06c9af6c38ea1ded355d1f932187017ec25d5	generalized k-labelset ensemble for multi-label classification	labelset;measurement;ensemble method;multi label classification;training;prediction algorithms;expansion coefficients generalized k labelset ensemble multilabel classification label powerset method multilabel learning algorithms random k labelset;laplace equations;vectors;pattern classification;pattern classification learning artificial intelligence;rocks;learning artificial intelligence;benchmark testing;training prediction algorithms rocks vectors laplace equations measurement benchmark testing;labelset multi label classification ensemble method	Label powerset (LP) method is one category of multi-label learning algorithms. It reduces the multi-label classification problem to a multi-class classification problem by treating each distinct combination of labels in the training set as a different class. This paper proposes a basis expansion model for multi-label classification, where a basis function is a LP classifier trained on a random k-labelset. The expansion coefficients are learned to minimize the global error between the prediction and the multi-label ground truth. We derive an analytic solution to learn the coefficients efficiently. We have conducted experiments using several benchmark datasets and compared our method with other state-of-the-art multi-label learning methods. The results show that our method has better or competitive performance against other methods.	algorithm;basis function;benchmark (computing);coefficient;experiment;ground truth;machine learning;multi-label classification;test set	Hung-Yi Lo;Shou-de Lin;Hsin-Min Wang	2012	2012 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)	10.1109/ICASSP.2012.6288315	benchmark;prediction;computer science;machine learning;pattern recognition;data mining;mathematics;measurement;statistics	Vision	18.813790821708633	-41.94833004106867	30333
31b0f318e4f1023fb9e31708c9ba774423da4c21	an algorithm for segmentation of metaphase spreads	chromosomes;metaphase spreads;segmentation	Abstract   An algorithm is proposed for locating chromosomes in photomicrographs of metaphase spreads. The algorithm resembles closely the method used by human operators to search microscopic fields. The algorithm was specially programmed to be used with small scale computers.	algorithm	G. L. Carayannopoulos;Edward A. Patrick	1976	Pattern Recognition	10.1016/0031-3203(76)90016-9	bioinformatics	Vision	0.9888205587889252	-48.17695113564242	30358
50f595784cd64e91d97381dff0366bf133b34628	consistency degrees of theories in the revised n-valued kleene logical system	general theory consistency degrees revised n valued kleene logical system generalized deduction theorem;consistency degree;lattices;generalized deduction theorem;data mining;fuzzy sets;fuzzy logic;indexes;cost accounting;hausdorff metric truth degree consistency degree;truth degree;indexation;formal logic;hausdorff metric;consistency degrees;general theory;revised n valued kleene logical system;fuzzy logic fuzzy systems paper technology algebra civil engineering logic functions fuzzy sets multivalued logic	Based on the truth degrees of formulas and the generalized deduction theorem, the present paper proposes an index reflecting the extent to which a general theory is consistent in the revised n-valued Kleene logical system. A sufficient and necessary condition for theories being consistent or inconsistent are given.	formal system;natural deduction;theory	Jun Li;Qian Lan	2009	2009 Fifth International Conference on Natural Computation	10.1109/ICNC.2009.611	combinatorics;discrete mathematics;kleene's recursion theorem;mathematics	Robotics	-0.5495123543841691	-24.337818871269608	30455
f6ade401e0487383b09515de9b30689626416f09	fuzzy cluster validation index based on inter-cluster proximity	fuzzy c means algorithm;fuzzy c mean;proximity measure;fuzzy clustering;indexation;fuzzy c means;cluster validity	A new cluster validity index is proposed for fuzzy partitions obtained from Fuzzy C-Means algorithm. The proposed validity index exploits an inter-cluster proximity between fuzzy clusters. The inter-cluster proximity is used to measure the degree of overlap between clusters. A low proximity value indicates well-partitioned clusters. The best fuzzy cpartition is obtained by minimizing the inter-cluster proximity with respect to c. Well-known data sets are tested to show the effectiveness and reliability of the proposed index. 2003 Elsevier B.V. All rights reserved.		Dae-Won Kim;Kwang Hyung Lee;Doheon Lee	2003	Pattern Recognition Letters	10.1016/S0167-8655(03)00101-6	discrete mathematics;defuzzification;fuzzy clustering;fuzzy classification;computer science;machine learning;data mining;mathematics	DB	1.9340986439852437	-39.73745838427359	30476
4d803175f620097987471a2dd5ac5619adef88b1	anomaly-aware traffic prediction based on automated conditional information fusion		Reliable and accurate short-term traffic prediction plays a key role in modern intelligent transportation systems (ITS) for achieving efficient traffic management and accident detection. Previous work has investigated this topic but lacks study on automated anomaly detection and conditional information fusion for ensemble methods. This works aims to improve prediction accuracy by fusing information considering different traffic conditions in ensemble methods. In addition to conditional information fusion, a day-week decomposition (DWD) method is introduced for preprocessing before anomaly detection. A k-nearest neighbours (kNN) based ensemble method is used as an example. Real-world data are used to test the proposed method with stratified ten-fold cross-validation. The results show that the proposed method with incident labels improves predictions up to 15.3% and the DWD enhanced anomaly-detection improves predictions up to 8.96 %. Conditional information fusion improves ensemble prediction methods, especially for incident traffic. The proposed method works well with enhanced detections and the procedure is fully automated. The accurate predictions lead to more robust traffic control and routing systems.	anomaly detection;conditional entropy;cross-validation (statistics);ensemble learning;k-nearest neighbors algorithm;preprocessor;routing;sensor	Bin Sun;Wei Cheng;Liyao Ma;Prashant Goswami	2018	2018 21st International Conference on Information Fusion (FUSION)	10.23919/ICIF.2018.8455244	artificial intelligence;computer science;anomaly detection;machine learning;intelligent transportation system;ensemble learning;decomposition of time series;preprocessor	Robotics	8.607214075378735	-23.996356521219838	30534
e795884dbc7185c004234e850b351ca1f3631eb0	theoretical analysis of a soft cut discretization	supervised learning;soft cut;discretization;discretizer;crisp descretization	Crisp discretization is widely-used and easy to implement, but it cannot work well on some situations, for example, when there is no clear boundary between attribute values or the attribute values are close to a cut point and possibly affected by random noise. A discretization method named Softcut was proposed to accommodate such situations and has been applied to face recognition. Softcut introduced a parameter τ that defined a symmetrical interval (0.5-τ, 0.5+τ) named uncertain interval. The attribute values in (0.5-τ, 0.5+τ) were undiscretizable. However, because the performance of Softcut may deteriorate in some situations, an extension named eSoftcut was proposed, in which the uncertain interval was defined by two parameters, (τj1, τj2). In this article, the theoretical aspects of eSoftcut including its definition, algorithm, and properties are introduced.	algorithm;cut (logic programming);discretization;facial recognition system;machine learning;noise (electronics);uc browser	Xuguang Chen	2017		10.1145/3077286.3077572	mathematical optimization;machine learning;pattern recognition	Vision	3.1833894548204653	-35.919694532566226	30537
b02f14ce2f5fd85a77abd1f8ea4bfe848b38971f	a new method to modify fuzzy contorl rules: rules-table rotating.				Yongquan Yu;Bi Zeng;Guokun Zhong;Xianchu Chen	2002			artificial intelligence;machine learning;pattern recognition;fuzzy logic;computer science	Robotics	3.5590545843572654	-25.162091210387846	30648
28de2533c379589ecdc4402610c26ae4e09341a4	on the learning potential of the approximated quantron	iris classification problem;learning algorithm;quantron;gradient search;spiking neuron	The quantron is a hybrid neuron model related to perceptrons and spiking neurons. The activation of the quantron is determined by the maximum of a sum of input signals, which is difficult to use in classical learning algorithms. Thus, training the quantron to solve classification problems requires heuristic methods such as direct search. In this paper, we present an approximation of the quantron trainable by gradient search. We show this approximation improves the classification performance of direct search solutions. We also compare the quantron and the perceptron's performance in solving the IRIS classification problem.		Richard Labib;Simon de Montigny	2012	International journal of neural systems	10.1142/S0129065712500104	computer science;artificial intelligence;machine learning;pattern recognition	ML	14.361963331653026	-28.752403714391253	30715
23c6c94534378c204c0ee21fdaebd23fd4691bcf	support vector machine learning for interdependent and structured output spaces	bayesian estimation;reinforcement learning;cutting plane algorithm;text classification;optimization problem;named entity recognition;machine learning;bias;feature extraction;generating function;sequence alignment;markov processes;support vector machine;variance	Learning general functional dependencies is one of the main goals in machine learning. Recent progress in kernel-based methods has focused on designing flexible and powerful input representations. This paper addresses the complementary issue of problems involving complex outputs such as multiple dependent output variables and structured output spaces. We propose to generalize multiclass Support Vector Machine learning in a formulation that involves features extracted jointly from inputs and outputs. The resulting optimization problem is solved efficiently by a cutting plane algorithm that exploits the sparseness and structural decomposition of the problem. We demonstrate the versatility and effectiveness of our method on problems ranging from supervised grammar learning and named-entity recognition, to taxonomic text classification and sequence alignment.	algorithm;cobham's thesis;context-free grammar;context-free language;cutting-plane method;document classification;functional dependency;hidden markov model;integer programming;interdependence;loss function;machine learning;markov chain;mathematical optimization;named-entity recognition;neural coding;optimization problem;sequence alignment;supervised learning;support vector machine	Ioannis Tsochantaridis;Thomas Hofmann;Thorsten Joachims;Yasemin Altun	2004		10.1145/1015330.1015341	semi-supervised learning;unsupervised learning;optimization problem;support vector machine;kernel method;instance-based learning;generating function;bayes estimator;wake-sleep algorithm;feature extraction;computer science;online machine learning;machine learning;linear classifier;bias;pattern recognition;sequence alignment;data mining;variance;markov process;stability;relevance vector machine;computational learning theory;reinforcement learning;active learning;structured support vector machine;generalization error	ML	22.791025410298737	-44.62500750560484	30779
ab3283fc1cd5b1f2f0b4429dea31540465c4b292	recurrent neural gas in electric load forecasting	unsupervised learning;cluster algorithm;local model;load forecasting clustering algorithms neural networks predictive models power engineering and energy backpropagation algorithms supervised learning systems engineering and theory computer science recurrent neural networks;elman neural network;clustering algorithm;neural networks;supervised learning;hourly electric load forecasting;backpropagation;systems engineering and theory;load forecasting;power engineering and energy;neural gas;recurrent neural gas;neural system;supervised networks;backpropagation through time;elman neural networks;backpropagation algorithms;clustering algorithms;recurrent neural nets load forecasting backpropagation unsupervised learning;predictive models;recurrent neural nets;recurrent neural networks;computer science;global mode;backpropagation through time recurrent neural gas hourly electric load forecasting supervised learning elman neural networks local model global mode clustering algorithm supervised networks	We have proposed for the task of hourly electric load forecasting a hybrid neural system combining unsupervised and supervised learning. The system consists of a recurrent neural gas (RNG) network and many Elman neural networks (ENs). RNG is a modification we introduced in the neural gas (NG) network in order to enable it to do clustering using a sequence of input data. For verifying the RNG's performance, many architectures are compared in the learning of global and local models. In a global model only one supervised network is trained and in a local model the training examples are grouped by a clustering algorithm and each one of these groups is sent to different supervised networks. These architectures use different clustering algorithms (NG and RNG) or different supervised networks for prediction (ENs that are trained by backpropagation or backpropagation through time, and feedforward networks).	electrical load;neural gas;recurrent neural network	Marcelo Andrade Teixeira;Gerson Zaverucha;Victor Navoarro Araujo Lemos da Silva;Guilherme Ferreira Ribeiro	1999		10.1109/IJCNN.1999.836223	unsupervised learning;types of artificial neural networks;computer science;artificial intelligence;machine learning;pattern recognition;deep learning;cluster analysis;supervised learning;multilayer perceptron;artificial neural network	ML	14.176707044417174	-26.40967513382581	30805
6abf30f1c8dba29e2358d0f18a7a0eb6537ecd2a	a continuous entropy rate estimator for spike trains using a k-means-based context tree	62f40;classification automatique statistiques;modelo markov oculto;neurone;calcul neuronal;neural computation;donnee experimentale;train potentiel action;62l05;shannon entropy;62p20;chaine markov;entropia;cadena markov;convergence;stochastic process;tree;temporal dynamics;51e24;intervalo confianza;analisis datos;modele markov cache;05c05;fonction repartition;probabilidad condicional;hidden markov model;structure arborescente;62f25;loi gamma;arbol;k means;modele markov variable cachee;probabilite conditionnelle;dato experimental;65c40;entropy estimation;spike;funcion distribucion;ley gama;data analysis;confidence interval;convergencia;distribution function;neurona;grand echantillon;hidden markov models;62h30;estructura arborescente;62g15;intervalle confiance;tree structure;entropie;processus stochastique;62e10;entropy rate;arbre;gamma distribution;analyse donnee;spike train;entropy;large sample;synthetic data;cluster analysis statistics;reseau neuronal;proceso estocastico;conditional probability;red neuronal;computacion neuronal;neuron;potentiel action;neuronal discharge;neural network;markov chain	Entropy rate quantifies the change of information of a stochastic process (Cover & Thomas, 2006). For decades, the temporal dynamics of spike trains generated by neurons has been studied as a stochastic process (Barbieri, Quirk, Frank, Wilson, & Brown, 2001; Brown, Frank, Tang, Quirk, & Wilson, 1998; Kass & Ventura, 2001; Metzner, Koch, Wessel, & Gabbiani, 1998; Zhang, Ginzburg, McNaughton, & Sejnowski, 1998). We propose here to estimate the entropy rate of a spike train from an inhomogeneous hidden Markov model of the spike intervals. The model is constructed by building a context tree structure to lay out the conditional probabilities of various subsequences of the spike train. For each state in the Markov chain, we assume a gamma distribution over the spike intervals, although any appropriate distribution may be employed as circumstances dictate. The entropy and confidence intervals for the entropy are calculated from bootstrapping samples taken from a large raw data sequence. The estimator was first tested on synthetic data generated by multiple-order Markov chains, and it always converged to the theoretical Shannon entropy rate (except in the case of a sixth-order model, where the calculations were terminated before convergence was reached). We also applied the method to experimental data and compare its performance with that of several other methods of entropy estimation.	bootstrapping (compilers);confidence intervals;convergence (action);differential entropy;entropy (information theory);entropy estimation;entropy rate;hidden markov model;interferon type ii;k-means clustering;koch snowflake;markov chain;probability;quirks mode;selaginella;shannon (unit);stochastic process;synthetic data;the spike (1997);tree structure;spike train	Tiger W. Lin;George N. Reeke	2010	Neural Computation	10.1162/neco.2009.11-08-912	econometrics;entropy;binary entropy function;transfer entropy;maximum entropy probability distribution;computer science;machine learning;mathematics;hidden markov model;statistics	ML	21.579237733382215	-26.38910919980327	30810
339ef0b7536c050859958d1f903aad61f0bb169b	multiple instance learning for sparse positive bags	multiple instance learning	We present a new approach to multiple instance learning (MIL) that is particularly effective when the positive bags are sparse (i.e. contain few positive instances). Unlike other SVM-based MIL methods, our approach more directly enforces the desired constraint that at least one of the instances in a positive bag is positive. Using both artificial and real-world data, we experimentally demonstrate that our approach achieves greater accuracy than state-of-the-art MIL methods when positive bags are sparse, and performs competitively when they are not. In particular, our approach is the best performing method for image region classification.	experiment;multiple instance learning;sparse matrix	Razvan C. Bunescu;Raymond J. Mooney	2007		10.1145/1273496.1273510	computer science;artificial intelligence;machine learning;pattern recognition;mathematics	ML	23.599558354965843	-44.62157045491638	30817
1a714e4f370fdac94248147eafc7a5111810e745	improving data quality through deep learning and statistical models		Outlier detection is an essential aspect of data quality control as it allows analysts and engineers the ability to identify data quality problems through the use of their own data as a tool. However, traditional data quality control methods are based on users’ experience or previously established business rules, and this limits performance in addition to being a very time consuming process and low accuracy. Utilizing big data, we can leverage computing resources and advanced techniques to overcome these challenges and provide greater value to the business. In this paper, we first review relevant works and discuss machine learning techniques, tools, and statistical quality models. Second, we offer a creative data profiling framework based on deep learning and statistical model algorithms for improving data quality. Third, authors use public Arkansas officials’ salaries, one of the open datasets available from the state of Arkansas’ official website, to demonstrate how to identify outlier data for improving data quality via machine learning. Finally, we discuss future works.	algorithm;anomaly detection;big data;data quality;deep learning;machine learning;statistical model	Wei Dai;Kenji Yoshigoe;William Parsley	2018	CoRR	10.1007/978-3-319-54978-1_66	leverage (finance);data science;machine learning;computer science;deep learning;statistical process control;artificial intelligence;statistical model;data quality;business rule	DB	1.5825183264076048	-34.466042713809884	30897
dc1054640903b15ecad445351217d6fa5e4d06ad	signal processing on graphs for improving automatic credit card fraud detection		In this paper, several methods based on signal processing on graphs are proposed to improve the performance of credit card fraud detection. The proposed methods consist of a variant of the classic iterative amplitude adjusted Fourier transform (IAAFT) and two methods that we have called iterative surrogate signals on graph algorithms (ISSG). The objective is to generate surrogate samples from the original scarce fraud samples to improve the training of the detectors by lowering the variance of the estimate. A reliable augmentation of the target scarce population of frauds is important considering issues such as labeling cost; algorithm testing; data confidentiality; and constantly changing of patterns in the data streaming source. We have approached several scenarios with different legitimate and non-legitimate transaction ratios showing the feasibility of improving detection capabilities evaluated by means of receiver operating characteristic (ROC) curves and several key performance indicators (KPI) commonly used in financial business.	algorithm;confidentiality;credit card fraud;graph theory;iterative method;receiver operating characteristic;sensor;signal processing;surrogate model	Luis Vergara;Addisson Salazar;Jordi Belda;Gonzalo Safont;Santiago Moral;Sergio Iglesias	2017	2017 International Carnahan Conference on Security Technology (ICCST)	10.1109/CCST.2017.8167820	data mining;credit card fraud;performance indicator;iterative method;artificial intelligence;computer vision;computer science;receiver operating characteristic;signal processing;population;detector;database transaction	ML	6.526125860342497	-36.79941411773138	30967
48d7ef60766819451fd76b00710e5fea7b0ddf7b	an analysis of stopping and filtering criteria for rule learning	filtering;filtrage;learning algorithm;heuristic method;filtrado;metodo heuristico;intelligence artificielle;algorithme apprentissage;rule learning;artificial intelligence;methode heuristique;inteligencia artificial;algoritmo aprendizaje	In this paper, we investigate the properties of commonly used prepruning heuristics for rule learning by visualizing them in PN-space. PN-space is a variant of ROC-space, which is particularly suited for visualizing the behavior of rule learning and its heuristics. On the one hand, we think that our results lead to a better understanding of the effects of stopping and filtering criteria, and hence to a better understanding of rule learning algorithms in general. On the other hand, we uncover a few shortcomings of commonly used heuristics, thereby hopefully motivating additional work in this area.	algorithm;heuristic (computer science);machine learning	Johannes Fürnkranz;Peter A. Flach	2004		10.1007/978-3-540-30115-8_14	filter;computer science;artificial intelligence;machine learning;algorithm	AI	8.315725858617682	-32.08815094127254	31013
2758639dc0e60220e2b3a8919225d7030df2a44a	improving variational encoder-decoders in dialogue generation		Variational encoder-decoders (VEDs) have shown promising results in dialogue generation. However, the latent variable distributions are usually approximated by a much simpler model than the powerful RNN structure used for encoding and decoding, yielding the KL-vanishing problem and inconsistent training objective. In this paper, we separate the training step into two phases: The first phase learns to autoencode discrete texts into continuous embeddings, from which the second phase learns to generalize latent representations by reconstructing the encoded embedding. In this case, latent variables are sampled by transforming Gaussian noise through multi-layer perceptrons and are trained with a separate VED model, which has the potential of realizing a much more flexible distribution. We compare our model with current popular models and the experiment demonstrates substantial improvement in both metric-based and human evaluations.	approximation algorithm;artificial neural network;blue (queue management algorithm);coherence (physics);control theory;encoder;experiment;feature learning;latent variable;machine learning;multilayer perceptron;natural language processing;random neural network;variational principle	Xiaoyu Shen;Hui Su;Shuzi Niu;Vera Demberg	2018			computer science;machine learning;encoder;perceptron;gaussian noise;artificial intelligence;encoding (memory);decoding methods;embedding;latent variable	NLP	23.48664506701386	-48.91234711255803	31015
4a3d7b1b67594b3204b1c634c2938a55b4a0b425	growing radial basis neural networks: merging supervised and unsupervised learning with network growth techniques	minimisation;metodo cuadrado menor;unsupervised learning;modelizacion;stopping criteria;minimization;evaluation performance;methode moindre carre;interpolation;radial basis function neural networks;learning algorithm;performance evaluation;neural networks;least squares method;learning;supervised learning;stopped criterion;gradient method;prototypes;evaluacion prestacion;fonction base radiale;surface fitting;indexing terms;algorithme;aprendizaje;modelisation;methode gradient;radial basis function networks;algorithm;stopping criterion;apprentissage;approximation par fonction;class conditional variance;radial basis function;vectors;function approximation;metodo gradiente;growing radial basis neural networks;clustering;neural networks merging unsupervised learning radial basis function networks prototypes surface fitting function approximation clustering algorithms vectors interpolation;rbf neural network;minimisation feedforward neural nets vector quantisation learning artificial intelligence pattern recognition;hybrid learning;merging;pattern recognition;clustering algorithms;conditional variance;feedforward neural nets;learning artificial intelligence;reseau neuronal;splitting criteria;vector quantisation;approximation by function;modeling;minimization growing radial basis neural networks supervised learning unsupervised learning radial basis function neural networks splitting criteria clustering learning vector quantization stopped criterion class conditional variance;red neuronal;aproximacion por funcion;learning vector quantization;neural network;algoritmo	This paper proposes a framework for constructing and training radial basis function (RBF) neural networks. The proposed growing radial basis function (GRBF) network begins with a small number of prototypes, which determine the locations of radial basis functions. In the process of training, the GRBF network gross by splitting one of the prototypes at each growing cycle. Two splitting criteria are proposed to determine which prototype to split in each growing cycle. The proposed hybrid learning scheme provides a framework for incorporating existing algorithms in the training of GRBF networks. These include unsupervised algorithms for clustering and learning vector quantization, as well as learning algorithms for training single-layer linear neural networks. A supervised learning scheme based on the minimization of the localized class-conditional variance is also proposed and tested. GRBF neural networks are evaluated and tested on a variety of data sets with very satisfactory results.	algorithm;artificial neural network;cluster analysis;learning vector quantization;machine learning;neural network simulation;prototype;radial (radio);radial basis function;sample variance;supervised learning;unsupervised learning;statistical cluster	Nicolaos B. Karayiannis;Glenn Weiqun Mi	1997	IEEE transactions on neural networks	10.1109/72.641471	computer science;artificial intelligence;machine learning;pattern recognition;mathematics;cluster analysis;artificial neural network	ML	12.268670478039352	-30.884966043679285	31016
3b369b08328648f708c187d124d30d9593421cdc	statistical analysis of electrophoresis time series for improving basecalling in dna sequencing	time series;statistical model;statistical analysis;bayesian estimator;a priori information;dna sequence	In automated DNA sequencing, the final algorithmic phase, referred to as basecalling, consists of the translation of four time signals in the form of peak sequences (electropherogram) to the corresponding sequence of bases. Commercial basecallers detect the peaks based on heuristics, and are very efficient when the peaks are distinct and regular in spread, amplitude and spacing. Unfortunately, in the practice the signals are subject to several degradations, among which peak superposition and peak merging are the most frequent. In these cases the experiment must be repeated and human intervention is required. Recently, there have been attempts to provide methodological foundations to the problem and to use statistical models for solving it. In this paper, we exploit a priori information and Bayesian estimation to remove degradations and recover the signals in an impulsive form which makes basecalling straightforward.	time series	Anna Tonazzini;Luigi Bedini	2006		10.1007/978-3-540-76300-0_15	econometrics;computer science;bioinformatics;statistics	ML	3.3269731256840287	-51.81104292611646	31051
86483c25d460ebc51bebdc3e6a686d707e0fe665	architectures for nanoelectronic neural networks: new results	hopfield network;multilayer perceptron;defect tolerance;power consumption;artificial neural network;neural network	Our group is developing artificial neural networks that may be implemented using hybrid semiconductor/molecular (“CMOL”) circuits. Estimates show that such networks (“CrossNets”) may eventually exceed the mammal brain in areal density, at much higher speed and acceptable power consumption. In this report, we demonstrate that CrossNets based on simple (two-terminal) molecular devices can work well in at least two modes: as Hopfield networks with high defect tolerance, as well as simple and multilayer perceptrons.	hopfield network;neural networks;perceptron;semiconductor;software bug	Özgür Türel;Jeong Hoon Lee;Xiaolong Ma;Konstantin Likharev	2004			computer science;artificial intelligence;machine learning;time delay neural network;multilayer perceptron;hopfield network;artificial neural network	ML	14.98439847373983	-26.531517861893686	31084
d33c84345d13303787c362f373915df4a0871f74	independent component analysis algorithms for microarray data analysis	independent component analysis;microarray data analysis	Oligonucleotide Microarrays have become powerful tools in Genetic Research, as they serve as parallel scanning mechanisms to detect the presence of genes using test probes composed of controlled segments of gene code built by masking techniques. The detection of each gene depends on the multichannel differential expression of perfectly matched segments against mismatched ones. This methodology, devised to robustify the detection process posses some interesting problems under the point of view of Genomic Signal Processing, as test probes express themselves in rather different patterns, not showing proportional expression levels for most of the segment pairs, as it would be expected. These cases may be influenced by unexpected hybridization dynamics, and are worth of being studied with a double objective: gain insight into hybridization dynamics in microarrays, and to improve microarray production and processing as well. Two methods are proposed in this paper: modelling the dynamics of expression dynamics and isolating gene expressions showing unexpected behaviour to proceed in their further classification and study.	algorithm;aliasing;cluster analysis;dna microarray;gene expression programming;independent computing architecture;independent component analysis;robustification;signal processing;statistical model	Raul Malutan;Pedro Gómez Vilda;Monica Borda	2010	Intell. Data Anal.	10.3233/IDA-2010-0416	independent component analysis;microarray analysis techniques;computer science;bioinformatics;machine learning;data mining	Comp.	4.248520052512199	-50.78506590067483	31199
9664778568004b26d3a51db03c2d2a0a865a136b	hierarchical document categorization with support vector machines	content management;discriminant function;upper bound;objective function;hierarchical classification;machine learning;subspace optimization;loss function;taxonomy;svm;document categorization;support vector machine;class relationship;hierarchical loss	Automatically categorizing documents into pre-defined topic hierarchies or taxonomies is a crucial step in knowledge and content management. Standard machine learning techniques like Support Vector Machines and related large margin methods have been successfully applied for this task, albeit the fact that they ignore the inter-class relationships. In this paper, we propose a novel hierarchical classification method that generalizes Support Vector Machine learning and that is based on discriminant functions that are structured in a way that mirrors the class hierarchy. Our method can work with arbitrary, not necessarily singly connected taxonomies and can deal with task-specific loss functions. All parameters are learned jointly by optimizing a common objective function corresponding to a regularized upper bound on the empirical loss. We present experimental results on the WIPO-alpha patent collection to show the competitiveness of our approach.	categorization;class hierarchy;content management system;discriminant;document classification;loss function;machine learning;support vector machine;taxonomy (general)	Lijuan Cai;Thomas Hofmann	2004		10.1145/1031171.1031186	support vector machine;hinge loss;computer science;artificial intelligence;machine learning;pattern recognition;data mining;relevance vector machine;structured support vector machine;taxonomy	AI	23.546268322206934	-42.93271060134936	31220
9aa6965efb392b9e49b7e9105c8f23553a88e264	extremal optimization for the protein structure alignment	biology computing;protein structure alignment;the contact map overlap;protein alignment;simulated annealing biology computing genetic algorithms molecular biophysics proteins;simulated annealing;data mining;meta heuristic algorithm;proteins;contact maps;heuristic algorithms;bioinformatics protein engineering testing prediction algorithms optimization methods heuristic algorithms automation biomedical engineering genetic algorithms simulated annealing;combinational optimization algorithm extremal optimization;simulated annealing protein structure alignment combinational optimization algorithm extremal optimization contact map overlap model meta heuristic algorithm genetic algorithm;molecular biophysics;extremal optimization protein alignment the contact map overlap;extremal optimization;amino acids;genetic algorithm;genetic algorithms;optimization;optimal algorithm;contact map overlap model;protein engineering;algorithm design and analysis;heuristic algorithm	This paper proposes a combinational optimization algorithm Extremal Optimization (EO) for protein structure alignment based on the Contact map overlap (CMO) model. EO is a meta-heuristic algorithm, as genetic algorithm and simulated annealing, but with a local fitness introduced to guide the improvement of the optimization. By exploiting similarity matrix between two contact maps, the results demonstrate that our algorithm is significantly faster and gets better results for most of the test sets.	combinational logic;extremal optimization;genetic algorithm;heuristic (computer science);mathematical optimization;mii;similarity measure;simulated annealing	Hengyun Lu;Genke Yang;Lam Fat Yeung	2009	2009 IEEE International Conference on Bioinformatics and Biomedicine	10.1109/BIBM.2009.48	mathematical optimization;meta-optimization;genetic algorithm;computer science;bioinformatics;machine learning;molecular biophysics	Robotics	3.3877982739030577	-48.140530306391064	31241
3682d9b96d5e70a24a07149565708f278f5c3b72	inference processes using incomplete knowledge in decision support systems - chosen aspects		The authors propose to use cluster analysis techniques (particularly clustering) to speed-up the process of finding rules to be activated in complex decision support systems with incomplete knowledge. The authors also wish to inference within such decision support systems using rules, of which premises are not fully covered by the facts. The AHC or mAHC algorithm is used. The authors adapted Salton’s most promising path method with own modifications for a fast look-up of the rules.	algorithm;cluster analysis;decision support system;lookup table	Agnieszka Nowak-Brzezinska;Tomasz Jach;Alicja Wakulicz-Deja	2012		10.1007/978-3-642-32115-3_17	intelligent decision support system;machine learning;data mining;mathematics;algorithm	Web+IR	-1.6355538344429241	-31.285037846367413	31296
443c079649722ba6bd28ed2b9cdab18e7a598d83	model selection in genetic programming	model selection;genetic program;genetic programming;symbolic regression	In this paper we discuss the problem of model selection in Genetic Programming. We present empirical comparisons between classical statistical methods (AIC, BIC) adapted to Genetic Programming and the Structural Risk Minimization method (SRM) based on Vapnik-Chervonenkis theory (VC), for symbolic regression problems with added noise. We also introduce a new model complexity measure for the SRM method that tries to measure the non-linearity of the model. The experimentation suggests practical advantages of using VC-based model selection with the new complexity measure, when using genetic training.	alexey chervonenkis;bayesian information criterion;complexity;genetic programming;model selection;nonlinear system;structural risk minimization;symbolic regression;vapnik–chervonenkis theory	Cruz E. Borges;César Luis Alonso;José Luis Montaña	2010		10.1145/1830483.1830662	genetic programming;mathematical optimization;computer science;artificial intelligence;genetic operator;machine learning;genetic representation;algorithm;model selection	ML	20.211453019061253	-25.423898318610675	31411
724f63df4d2d3c47430dd920d15cd156bfa3bed5	evolutionary support vector machines: a dual approach	kernel;support vector machines;training;logic gates;genetic algorithms;optimization;proposals	A theoretical advantage of large margin classifiers such as Support Vector Machines (SVM) concerns the empirical and structural risk minimization which balances the model complexity against its success at fitting the training data. Metaheuristics have been used in order to select features, to tune hyperparameters or even to achieve a reduced-set of support vectors for SVM. Although these tasks are interesting, metaheuristics do not play an important role in the process of solving the dual quadratic optimization problem, which arises from Support Vector Machines. Well-known methods such as, Sequential Minimal Optimization, Kernel Adatron and classical mathematical methods have been applied with this goal. In this paper, we propose the use of Genetic Algorithms to solve such quadratic optimization problem. Our proposal is promising when compared with those aforementioned methods because it does not need complex mathematical calculations and, indeed, the problem is solved in an astonishingly straightforward way. To achieve this goal, we successfully model an instance of Genetic Algorithms to handle the dual optimization problem and its constraints in order to obtain the Lagrange multipliers as well as the bias for the decision function.	competitive learning;embedded system;gate;genetic algorithm;genetic operator;lagrange multiplier;margin classifier;mathematical optimization;metaheuristic;neural coding;optimization problem;quadratic programming;sequential minimal optimization;structural risk minimization;support vector machine	Madson Luiz Dantas Dias;Ajalmar R. da Rocha Neto	2016	2016 IEEE Congress on Evolutionary Computation (CEC)	10.1109/CEC.2016.7744058	support vector machine;least squares support vector machine;mathematical optimization;kernel;genetic algorithm;logic gate;computer science;artificial intelligence;machine learning;mathematics;sequential minimal optimization;vector optimization;algorithm	ML	20.785470899461657	-37.494403856978046	31458
b5305ec8a0e4e3746d213c08ae9f2ee06fc434b4	effective learning in noisy environment using neural network ensemble	contradictionary data noisy environment neural network ensemble noisy training data set;multilayer perceptrons;neural network ensemble;learning artificial intelligence multilayer perceptrons;multi layer perceptron;intelligent networks working environment noise neural networks training data switches neurons physics transfer functions error correction degradation;learning artificial intelligence	We have previously (1999) proposed a model of a neural network ensemble composed of a number of multi layer perceptrons (MLP). The ensemble is trained so that each member has a unique expertise. It is also provided with a mechanism to automatically select the most relevant member with respect to the given environment, enabling the ensemble to adapt effectively in changing environment. In this research we trained the ensemble with a noisy training data set, which is a training set that contains a particular percentage of contradictionary (false) data. Based on the members' expertise the ensemble has the ability to distinguish contradictionary data and treat such a kind of data set as one unique environment that differs from the clean environment formed by correct data. In the training process the ensemble will automatically select one of its member to be trained in the clean environment and switch to another member whenever a contradictionary data is given, resulting that one of the ensemble member will be successfully adapting the clean environment.	artificial neural network	Pitoyo Hartono;Shuji Hashimoto	2000		10.1109/IJCNN.2000.857894	computer science;artificial intelligence;machine learning;data mining;ensemble learning;multilayer perceptron	ML	13.446801047144161	-35.02631289103271	31595
fcfff5aa6ad2365f65033c9ea705c4a77fcc11f1	a dna-based clustering method based on statistics adapted to heterogeneous coordinate data	dna;np complete problems dna based clustering method heterogeneous coordinate data;silicon;science general;heterogeneous coordinate data;automotive engineering;optimisation;biocomputing;heterogeneous data;np complete problems;data engineering;data mining;data clustering;distance measurement;data analysis;social science;cluster analysis;computational complexity;optimisation biocomputing computational complexity;engineering management;clustering method;dna based clustering method;statistics;optimization;dna computing;vehicles;clustering methods statistics dna computing data analysis engineering management science general automotive engineering data engineering np complete problem vehicles;clustering methods;encoding;np complete problem	A cluster analysis is often used in social sciences, management, general science and engineering, etc. with the objective of characterising structures in heterogeneous data sets. In this case, collections of information granules are obviously constructed through clustering techniques. However, clustering problems are intractable and NP-complete problems with a number of patterns. In this article, we discuss the use of DNA computing as a vehicle of heterogeneous coordinated data clustering, and elaborate on the fundamentals of DNA computing in the context of clustering tasks. A novel DNA-based clustering method is proposed, using statistics-based encoding of DNA strands, for clustering coordinated data from simulated DNA studies and experiments. The results also show the capabilities of this method when adapted to heterogeneous coordinate data.	cluster analysis;dna computing;experiment;karp's 21 np-complete problems	Ikno Kim;Junzo Watada	2009	2009 International Conference on Complex, Intelligent and Software Intensive Systems	10.1109/CISIS.2009.35	correlation clustering;constrained clustering;data stream clustering;fuzzy clustering;flame clustering;computer science;bioinformatics;theoretical computer science;consensus clustering;cure data clustering algorithm;data mining;cluster analysis;brown clustering;biclustering;affinity propagation;clustering high-dimensional data;conceptual clustering	DB	3.035675824926345	-42.70156875976606	31622
4bb1a4ebdfa98e30e12fffec3fe5a75c6c113bab	simultaneous sparsity and parameter tying for deep learning using ordered weighted ℓ1 regularization		A deep neural network (DNN) usually contains millions of parameters, making both storage and computation extremely expensive. Although this high capacity allows DNNs to learn sophisticated mappings, it also makes them prone to over-fitting. To tackle this issue, we adopt a recently proposed sparsity-inducing regularizer called OWL (ordered weighted ℓ1, which has proven effective in sparse linear regression with strongly correlated covariates. Unlike the conventional sparsity-inducing regularizers, OWL simultaneously eliminates unimportant variables by setting their weights to zero, while also explicitly identifying correlated groups of variables by tying the corresponding weights to a common value. We evaluate the OWL regularizer on several deep learning benchmarks, showing that it can dramatically compress the network with slight or even no loss on generalization accuracy.	algorithm;artificial neural network;benchmark (computing);column (database);computation;computer multitasking;deep learning;experiment;matrix regularization;ordered weighted averaging aggregation operator;overfitting;sparse matrix;web ontology language	Dejiao Zhang;Julian Katz-Samuels;Mário A. T. Figueiredo;Laura Balzano	2018	2018 IEEE Statistical Signal Processing Workshop (SSP)	10.1109/SSP.2018.8450819		ML	22.000152778500315	-45.57646431391158	31825
403ac8eecaf751c4a7cc2f18b1816c77e2e396f7	a priori data and a posteriori decision fusions for human action recognition		In this paper, we tackle the challenge of human action recognition using multiple data sources by mixing a priori data fusion and a posteriori decision fusion. Our strategy applied from 3 main classifiers (Dynamic Time Warping, Multi-Layer Perceptron and Siamese Neural Network) using several decision fusion methods (Voting, Stacking, Dempster-Shafer Theory and Possibility Theory) on two databases (MHAD (Ofli et al., 2013) and ChAirGest (Ruffieux et al., 2013)) outperforms state-of-the-art results with respectively 99.85%± 0.53 and 96.40%±3.37 of best average correct classification when evaluating a leave-one-subject-out protocol.	artificial neural network;database;dynamic time warping;memory-level parallelism;multilayer perceptron;possibility theory;stacking	Julien Cumin;Grégoire Lefebvre	2016		10.5220/0005680204930500	machine learning;pattern recognition;data mining	AI	17.241194305890957	-43.16272065493612	31863
d9c16e38dccbc8bc50d0e0874dbb930946405323	the univariate flagging algorithm (ufa): a fully-automated approach for identifying optimal thresholds in data		In many data classification problems, there is no linear relationship between an explanatory and the dependent variables. Instead, there may be ranges of the input variable for which the observed outcome is signficantly more or less likely. This paper describes an algorithm for automatic detection of such thresholds, called the Univariate Flagging Algorithm (UFA). The algorithm searches for a separation that optimizes the difference between separated areas while providing the maximum support. We evaluate its performance using three examples and demonstrate that thresholds identified by the algorithm align well with visual inspection and subject matter expertise. We also introduce two classification approaches that use UFA and show that the performance attained on unseen test data is equal to or better than that of more traditional classifiers. We demonstrate that the proposed algorithm is robust against missing data and noise, is scalable, and is easy to interpret and visualize. It is also well suited for problems where incidence of the target is low.	algorithm;align (company);bootstrapping (compilers);dimensionality reduction;incidence matrix;logistic regression;missing data;random forest;scalability;signature block;subject matter expert turing test;test data;unambiguous finite automaton;visual inspection	Mallory Bounds Sheth;Roy Welsch;Natasha Markuzon	2016	CoRR		econometrics;machine learning;data mining;mathematics;statistics	ML	14.908650426927275	-43.06447297472005	31942
db1ec585e16bf2236a0a79d0952f89950945c78c	a monothetic clustering method	hierarchical clustering;hierarchical clustering methods;monothetic cluster;clustering method;inertia criterion	The proposed divisive clustering method performs simultaneously a hierarchy of a set of objects and a monothetic characterization of each cluster of the hierarchy. A division is performed according to the within-cluster inertia criterion which is minimized among the bipartitions induced by a set of binary questions. In order to improve the clustering, the algorithm revises at each step the division which has induced the cluster chosen for division.	algorithm;angular defect;cluster analysis;hierarchical clustering;iris flower data set	Marie Chavent	1998	Pattern Recognition Letters	10.1016/S0167-8655(98)00087-7	complete-linkage clustering;correlation clustering;data stream clustering;k-medians clustering;fuzzy clustering;flame clustering;computer science;canopy clustering algorithm;machine learning;consensus clustering;pattern recognition;cure data clustering algorithm;data mining;mathematics;hierarchical clustering;cluster analysis;single-linkage clustering;brown clustering;statistics;hierarchical clustering of networks;clustering high-dimensional data;conceptual clustering	Vision	2.806394945028124	-40.33720369213928	31991
485c11734eccf3193392f178ff0aac41c79d0e9a	correcting bias in statistical tests for network classifier evaluation	type i error;statistical test;mathematics computing and information science;independent and identically distributed;statistical power;social network analysis;97 mathematics computing and information science;network classification	It is difficult to directly apply conventional significance tests to compare the performance of network classification models because network data instances are not independent and identically distributed. Recent work [6] has shown that paired t-tests applied to overlapping network samples will result in unacceptably high levels (e.g., up to 50%) of Type I error (i.e., the tests lead to incorrect conclusions that models are different, when they are not). Thus, we need new strategies to accurately evaluate network classifiers. In this paper, we analyze the sources of bias (e.g. dependencies among network data instances) theoretically and propose analytical corrections to standard significance tests to reduce the Type I error rate to more acceptable levels, while maintaining reasonable levels of statistical power to detect true performance differences. We validate the effectiveness of the proposed corrections empirically on both synthetic and real networks.	synthetic intelligence	Tao Wang;Jennifer Neville;Brian Gallagher;Tina Eliassi-Rad	2011		10.1007/978-3-642-23808-6_33	independent and identically distributed random variables;statistical hypothesis testing;social network analysis;type i and type ii errors;computer science;artificial intelligence;machine learning;statistical power;data mining;statistics	ML	7.453681793067875	-44.705601707968235	32046
10df580b06829a31ad86daba69a68f7771f31990	a new approach for classification: visual simulation point of view	extraction information;classification algorithm;analisis datos;information extraction;image databank;information technology;hombre;visual simulation;technologie information;intelligence artificielle;algorithm visualization;data mining;classification;data analysis;percepcion visual;fouille donnee;banco imagen;sensation;banque image;human;perception visuelle;artificial intelligence;analyse donnee;visual perception;inteligencia artificial;point of view;tecnologia informacion;busca dato;clasificacion;extraccion informacion;sensacion;homme	Classification is a fundamental problem in data mining, which is central to various applications of information technology. The existing approaches for classification have been developed mainly based on exploring the intrinsic structure of dataset itself, less or no emphasis paid on simulating human sensation and perception. Understanding data is, however, highly relevant to how one senses and perceives the data. In this talk we initiate an approach for classification based on simulating the human visual sensation and perception principle. The core idea is to treat a data set as an image, and to mine the knowledge from the data in accordance with the way we observe and perceive the image. The algorithm, visual classification algorithm (VCA), from the proposed approach is formulated. We provide a series of simulations to demonstrate that the proposed algorithm is not only effective but also efficient. In particular, we show that VCA can very often bring a significant reduction of computation effort without loss of prediction capability, as compared with the prevalently adopted SVM approach. The simulations further show that the new approach potentially is very encouraging and useful.	augmented reality;point of view (computer hardware company);simulation	Zongben Xu;Deyu Meng;Wenfeng Jing	2005		10.1007/11427445_1	sensation;computer vision;visual perception;biological classification;computer science;artificial intelligence;machine learning;data mining;data analysis;information technology;information extraction	Vision	-2.052835809329991	-32.40997481629658	32082
8d85754cb944fa95b638507cd231c1db6c823ea6	surmise relations between tests - mathematical considerations	use;software;espacio;representation;espace connaissance test;non numerical test theory;concept;curriculum development;test knowledge space;text;matrix representation;dato;aplicacion;modele mathematique;development;analisis datos;logiciel;cuerpo;propiedad;1985;body;sistema;data;connaissance;surmise relation between tests;desarrollo;software systems;68n01;espace;conocimiento;modelo matematico;texte;test;utilizacion;recherche;informacion;ensayo;utilisation;knowledge;essai;data analysis;particion;donnee;test theory;developpement;system;matriz booleana;relacion;theorie test;partition;mathematical model;corps;propriete;logicial;analyse donnee;knowledge theory;space;theorie connaissance;theorie espace connaissance;systeme;properties;application;texto;investigacion;relation;information;prerequisite relationship;matrice booleenne;boolean matrix;representacion;concepto;knowledge space theory	In 1985, Doignon and Falmagne introduced surmise relations for representing prerequisite relationships between items within a body of information for the assessment of knowledge. Often it is useful to partition such a body of information into sub-collections. As we are primarily interested in psychological applications, we refer to these sub-collections as tests. We extend the concept of surmise relations between items within tests to surmise relations between tests. Three di7erent kinds of surmise relations between tests are investigated with respect to their properties. Furthermore, the corresponding knowledge spaces for tests and their bases are introduced. The relationship of this set theoretical approach to a Boolean matrix representation is discussed. Finally, we give a short overview about the further research regarding this mathematical model. It will be the foundation for a software system that will be used for analyzing test data. Other applications in 9elds like curriculum development and structuring hyper-texts can easily be imagined. ? 2002 Elsevier Science B.V. All rights reserved.	knowledge space;mathematical model;matrix representation;software system;test data	Silke Brandt;Dietrich Albert;Cord Hockemeyer	2003	Discrete Applied Mathematics	10.1016/S0166-218X(02)00207-X	partition;combinatorics;matrix representation;information;relation;artificial intelligence;space;mathematical model;system;mathematics;knowledge;data analysis;concept;representation;test theory;algorithm;data	AI	-3.01264815810605	-31.51105869749739	32155
8dcf0808214083aa0979daa940f66aad099ca357	quantifying uncertainty in phylogenetic studies of the slavonic languages	uncertainty;bayesian inference;slavonic languages;phylogeny	We describe the application of Bayesian methods to accommodate the uncertainty problem in phylogenetic reconstruction with an example of the Slavonic languages family. Comparative studies of languages have lots in common with evolutionary biology studies. Stable linguistic characters (e.g. word forms from the basic vocabulary, grammar characters) can be used to construct DNA-like sequences that the phylogenetic reconstruction methods can then be applied to. Linguistic data is known to be a subject of noise and error of different kinds causing conflicting signals and uncertainty within a phylogeny. Bayesian methods help to quantify the uncertainty. The comparison with the Damerau-Levenshtein distance-based tree is also given.	bayesian network;damerau–levenshtein distance;image noise;levenshtein distance;phylogenesis;phylogenetics;vocabulary	Diana Nurbakova;Sergey Rusakov;Vassil N. Alexandrov	2013		10.1016/j.procs.2013.05.398	natural language processing;mathematics;algorithm	NLP	0.7509287213249332	-47.72370490859673	32245
00a7e043f371dcfb9c47ec60e9158601ed868c08	real-time anomaly detection system for time series at scale		This paper describes the design considerations and general outline of an anomaly detection system used by Anodot. We present results of the system on a large set of metrics collected from multiple companies.	algorithm;anomaly detection;data point;feedback;real-time clock;requirement;scalability;semi-supervised learning;semiconductor industry;statistical model;time series	Meir Toledano;Ira Cohen;Yonatan Ben-Simhon;Inbal Tadeski	2017			computer science;data mining;anomaly detection	ML	6.081685439194994	-35.96389481030634	32249
fb4610736e0a7ed43fd21d3caaf758369072c2f6	fast sketch-based recovery of correlation outliers		Many data sources can be interpreted as time-series, and a key problem is to identify which pairs out of a large collection of signals are highly correlated. We expect that there will be few, large, interesting correlations, while most signal pairs do not have any strong correlation. We abstract this as the problem of identifying the highly correlated pairs in a collection of n mostly pairwise uncorrelated random variables, where observations of the variables arrives as a stream. Dimensionality reduction can remove dependence on the number of observations, but further techniques are required to tame the quadratic (in n) cost of a search through all possible pairs. We develop a new algorithm for rapidly finding large correlations based on sketch techniques with an added twist: we quickly generate sketches of random combinations of signals, and use these in concert with ideas from coding theory to decode the identity of correlated pairs. We prove correctness and compare performance and effectiveness with the best LSH (locality sensitive hashing) based approach. 1998 ACM Subject Classification F.2.1 Numerical Algorithms and Problems		Graham Cormode;Jacques Dark	2018		10.4230/LIPIcs.ICDT.2018.13	mathematics;locality-sensitive hashing;outlier;correctness;machine learning;coding theory;dimensionality reduction;artificial intelligence;sketch;pairwise comparison;correlation	ML	-1.8369797726883637	-37.90444607790428	32253
ef4e983e403d2685db56c403e1c6ba627f808c87	performance analysis of a deep simple recurrent unit recurrent neural network (sru-rnn) in mems gyroscope de-noising	deep learning;inertial measurement unit;microelectromechanical systems;simple recurrent unit	Microelectromechanical System (MEMS) Inertial Measurement Unit (IMU) is popular in the community for constructing a navigation system, due to its small size and low power consumption. However, limited by the manufacturing technology, MEMS IMU experiences more complicated noises and errors. Thus, noise modeling and suppression is important for improving accuracy of the navigation system based on MEMS IMU. Motivated by this problem, in this paper, a deep learning method was introduced to MEMS gyroscope de-noising. Specifically, a recently popular Recurrent Neural Networks (RNN) variant Simple Recurrent Unit (SRU-RNN) was employed in MEMS gyroscope raw signals de-noising. A MEMS IMU MSI3200 from MT Microsystem Company was employed in the experiments for evaluating the proposed method. Following two problems were furtherly discussed and investigated: (1) the employed SRU with different training data length were compared to explore whether there was trade-off between the training data length and prediction performance; (2) Allan Variance was the most popular MEMS gyroscope analyzing method, and five basic parameters were employed to describe the performance of different grade MEMS gyroscope; among them, quantization noise, angle random walk, and bias instability were the major factors influencing the MEMS gyroscope accuracy, the compensation results of the three parameters for gyroscope were presented and compared. The results supported the following conclusions: (1) considering the computation brought from training dataset, the values of 500, 3000, and 3000 were individually sufficient for the three-axis gyroscopes to obtain a reliable and stable prediction performance; (2) among the parameters, the quantization noise, angle random walk, and bias instability performed 0.6%, 6.8%, and 12.5% improvement for X-axis gyroscope, 60.5%, 17.3%, and 34.1% improvement for Y-axis gyroscope, 11.3%, 22.7%, and 35.7% improvement for Z-axis gyroscope, and the corresponding attitude errors decreased by 19.2%, 82.1%, and 69.4%. The results surely demonstrated the effectiveness of the employed SRU in this application.		Changhui Jiang;Shuai Chen;Yuwei Chen;Yuming Bo;Lin Han;Jun Guo;Ziyi Feng;Hui Zhou	2018		10.3390/s18124471		AI	16.625849560747685	-33.42190406193313	32301
fb46b2a8d2b330aa755694bc673a8bd161881296	the lower system, the upper system and rules with stability factor in non-deterministic information systems	non deterministic information;stability factor;incomplete information;rule generation;rough sets;apriori algorithm;information system;rough set	A rule in a Deterministic Information System (DIS) is often defined by an implication ? such that both support(?) ? ? and accuracy(?) ? β hold for the threshold values ? and β. In a Non-deterministic Information System (NIS), there are derived DISs due to the information incompleteness. A rule in a DIS was extended to either a rule in the lower system or a rule in the upper system in a NIS. This paper newly introduces a criterion, i.e., stability factor, into rules in a NIS. Rules in the upper system are classified according to the stability factor.	information system	Hiroshi Sakai;Kohei Hayashi;Michinori Nakata;Dominik Slezak	2009		10.1007/978-3-642-10646-0_38	rough set;computer science;artificial intelligence;machine learning;data mining;mathematics;algorithm	ECom	-2.1713067712067216	-26.09863011442732	32313
d3cc58ab288ce5421540f24c09761c4051b3541f	incremental multiple concept learning using experiments	concept learning	The learning method presented here is a general data-driven method that learns multiple discriminant disjunctive descriptions incrementally from experiments assuming perfect classifications. New points are selected for classification by the environment based on the current concept descriptions. Unlike previous methods for acquiring concepts, attributes with finite unordered and infinite totally-ordered domains are integrated into a uniform framework in which concept descriptions are not only constrained by negative examples, but, more importantly, by the current descriptions of other the classes.	concept learning;experiment	Klaus P. Gross	1988			discrete mathematics;concept learning;computer science;machine learning;pattern recognition;mathematics	Vision	5.963903260471607	-31.62613678681912	32382
99162e20ef615b1b557a76672c86a964df8318dc	a comparative study of belief and plausibility reducís in information systems with fuzzy decisions	belief function;reducts;information systems;belief functions;rough set theory;consistent sets;fuzzy set theory;rough set theory fuzzy set theory information systems;attribute reduction;upper approximation reducts;lower approximation reducts;plausibility reducts;upper approximation reducts belief reducts plausibility reducts information systems fuzzy decisions knowledge reduction rough set theory attribute reduction lower approximation reducts;rough sets;belief reducts;information system;rough sets belief functions consistent sets information systems information systems with fuzzy decisions reducts;rough set;information systems with fuzzy decisions;fuzzy decisions;knowledge reduction	Knowledge reduction is one of the main problems in the study of rough set theory. This paper deals with attribute reduction in complete information systems with fuzzy decisions. The concepts of lower approximation reducts, upper approximation reducís, belief reducís, and plausibility reducts in information systems with fuzzy decisions are introduced and their relationships are examined. It is shown that, in a complete information system with fuzzy decisions, an attribute set is a belief reduct (a plausibility reduct, respectively) if and only if it is a lower approximation reduct (an upper approximation reduct, respectively).	approximation;fuzzy concept;information system;plausibility structure;rough set;set theory	Wei-Zhi Wu	2010	2010 International Conference on Machine Learning and Cybernetics	10.1109/ICMLC.2010.5580481	discrete mathematics;rough set;computer science;machine learning;pattern recognition;data mining;mathematics	DB	-2.1612125477302206	-26.13958790293909	32413
38d4e89473056d0a80e892cccf50267566e4b0de	a geometry-based band selection approach for hyperspectral image analysis		Band selection (BS) is a special case of the feature selection problem, and it tries to remove redundant bands and select a few informative and distinctive bands to represent the whole image cube. The maximum ellipsoid volume (MEV) method regards the band subset with the maximum volume as the optimal band combination. However, the MEV method cannot be directly applied for hyperspectral imagery due to the high dimensionality of the data sets. Therefore, we first combine MEV with the sequential forward search (SFS) and propose a new unsupervised BS method called MEV-SFS. Furthermore, a subtle relationship between the ellipsoid volume of the band set and the orthogonal projections (OPs) of the candidate bands is observed. Based on this relationship, we propose another equivalent method, namely, the OP-based BS (OPBS) method. OPBS is the fast version of MEV-SFS, and it has a better computational efficiency and the potential to determine the number of bands to be selected. We specifically explain the rationality of the MEV-based methods (MEV-SFS and OPBS) and illustrate their theoretical significance and physical meaning from different aspects. Theoretical analysis also demonstrates that OPBS can be regarded as a model or framework for BS, and thus, we further propose a third novel BS method named the OPBS-information divergence (OPBS-ID) method, which is a variant of OPBS. OPBS-ID can achieve a better classification performance than OPBS in many cases. Experimental results on different hyperspectral data sets demonstrate that the proposed methods have high computational efficiency, and the selected bands can achieve satisfactory classification performances.	caller id;clustered file system;computation;computational complexity theory;feature selection;id-wsf;image analysis;information;performance;rationality;selection algorithm	Wenqiang Zhang;Xiaorun Li;Yaxing Dou;Liaoying Zhao	2018	IEEE Transactions on Geoscience and Remote Sensing	10.1109/TGRS.2018.2811046	computer vision;mathematics;divergence;feature extraction;feature selection;ellipsoid;data set;curse of dimensionality;hyperspectral imaging;special case;artificial intelligence;pattern recognition	Vision	11.771993887897672	-43.888085830393464	32415
526a97d807a61832749cd01f583c71cd79ab2065	constructive induction for classifying time series	reconocimiento lenguaje;lenguaje por signos;sign language recognition;handwriting recognition;constructive induction;reconnaissance langage;sign language;hombre;intelligence artificielle;time series;electrocardiographie;classification;language recognition;langage gestuel;multivariate time series;induccion;reconnaissance ecriture;electrocardiography;electrocardiografia;induction;machine learning;serie temporelle;human;serie temporal;time series data;artificial intelligence;inteligencia artificial;methode induction;clasificacion;homme;metodo induccion;induction method	We present a method of constructive induction aimed at learning tasks involving multivariate time series data. Using metafeatures, the scope of attribute-value learning is expanded to domains that contain instances that have some kind of recurring substructure, such as strokes in handwriting recognition, or local maxima in time series data. These substructures are used to construct attributes. Metafeatures are applied to two real-world domains: sign language recognition and ECG classification. Using a very generic set of metafeatures we are able to generate classifiers that are either comprehensible or accurate, producing results that are comparable to hand-crafted preprocessing and comparable to human experts.	handwriting recognition;inductive reasoning;maxima and minima;megabyte;preprocessor;random search;time series	Mohammed Waleed Kadous;Claude Sammut	2004		10.1007/978-3-540-30115-8_20	speech recognition;computer science;artificial intelligence;machine learning;time series;handwriting recognition;algorithm;statistics	ML	8.699368137767546	-33.228900982608835	32424
b9f4cb83d65a7ec97cd17a44dc923fdf6bc3b7f6	efficient distribution of backpropagation models on parallel architectures	backpropagation;parallel architecture		backpropagation	Louis Ceci;Patrick Lynn;Phillip E. Gardner	1988	Neural Networks	10.1016/0893-6080(88)90451-0	computer science;backpropagation;machine learning	ML	13.247980746727409	-26.965270836965757	32478
093d77ecbeb43022fbe10f24849410a296343ed5	cakewalk sampling		Combinatorial optimization is a common theme in computer science which underlies a considerable variety of problems. In contrast to the continuous setting, combinatorial problems require special solution strategies, and it’s hard to come by generic schemes like gradient methods for continuous domains. We follow a standard construction of a parametric sampling distribution that transforms the problem to the continuous domain, allowing us to optimize the expectation of a given objective using estimates of the gradient. In spite of the apparent generality, such constructions are known to suffer from highly variable gradient estimates, and thus require careful tuning that is done in a problem specific manner. We show that a simple trick of converting the objective values to their cumulative probabilities fixes the distribution of the objective, allowing us to derive an online optimization algorithm that can be applied in a generic fashion. As an experimental benchmark we use the task of finding cliques in undirected graphs, and we show that our method, even when blindly applied, consistently outperforms related methods. Notably, on the DIMACS clique benchmark, our method approaches the performance of the best clique finding algorithms without access to the graph structure, and only through objective function evaluations, thus providing significant evidence to the generality and effectivity of our method.	algorithm;benchmark (computing);cakewalk pro audio;clique (graph theory);combinatorial optimization;computer science;convex optimization;gradient;graph (discrete mathematics);hood method;loss function;mathematical optimization;nyquist–shannon sampling theorem;online optimization;optimization problem;reinforcement learning;sampling (signal processing);stochastic gradient descent;stochastic optimization	Uri Patish;Shimon Ullman	2018	CoRR		artificial intelligence;clique;machine learning;mathematical optimization;mathematics;generality;combinatorial optimization;sampling (statistics);spite;online optimization;sampling distribution;parametric statistics	ML	23.720650980217027	-31.80386863457863	32488
f36c7fad71273ab9809e06e1b89978c132741063	neural computation for planning and/or precedence-constraint robot assembly sequences	robots assembling neural nets operations research;neural computation;connection matrix;hopfield network;neural nets;precedence constraint assembly sequences;and or precedence constraint;operations research;modified hopfield network;assembling;robots;robot assembly sequences and or precedence constraint connection matrix geometric constraints modified hopfield network neural computation planning precedence constraint assembly sequences;precedence constraint;planning;geometric constraints;robot assembly sequences	The problem of finding AND/OR precedence-constraint assembly sequences for a set of  n  parts that construct a mechanical object using neural computation is discussed. The geometric constraints of the assembled object are transformed into the elements of the connection matrix which specifies the connection strength among neurons. A modified Hopfield network is used to tackle the AND/OR precedence-constraint assembly-sequence problem. The designed algorithm can accommodate various constraints and applications. Detailed algorithms and analysis, and examples and experiments are presented	computation;robot	Charley Peter Chen	1990		10.1109/IJCNN.1990.137557	planning;robot;mathematical optimization;computer science;artificial intelligence;machine learning;hopfield network;artificial neural network;models of neural computation	Robotics	19.62347822303206	-24.788423408513204	32505
14e306cd78510fbc2f343b38ff215cd528ef9bdc	predicting drug side effects using data analytics and the integration of multiple data sources		The development of automated approaches employing computational methods using data from publicly available drugs datasets for the prediction of drug side effects has been proposed. This paper presents the use of a hybrid machine learning approach to construct side effect classifiers using an appropriate set of data features. The presented approach utilizes the perspective of data analytics to investigate the effect of drug distribution in the feature space, categorize side effects into several intervals, adopt suitable strategies for each interval, and construct data models accordingly. To verify the applicability of the presented method in side effect prediction, a series of experiments were conducted. The results showed that this approach was able to take into account the characteristics of different types of side effects, thereby achieve better predictive performance. Moreover, different feature selection schemes were coupled with the modeling methods to examine the corresponding effects. In addition, analyses were performed to investigate the task difficulty in terms of data distance and similarity. Examples of visualized networks of associations between drugs and side effects are also discussed to further evaluate the results.	categorization;data model;experiment;feature selection;feature vector;machine learning;side effect (computer science)	Wei-Po Lee;Jhih-Yuan Huang;Hsuan-Hao Chang;King-Teh Lee;Chao-Ti Lai	2017	IEEE Access	10.1109/ACCESS.2017.2755045	drug side effects;data mining;categorization;data modeling;computer science;side effect;machine learning;feature vector;artificial intelligence;feature selection;data analysis;correlation	Web+IR	11.036742963221899	-49.16136540885743	32511
7ce58704ad1820f3663e56843a90317cae4c6ea9	robust mapping learning for multi-view multi-label classification with missing labels		The multi-label classification problem has generated significant interest in recent years. Typical scenarios assume each instance can be assigned to a set of labels. Most of previous works regard the original labels as authentic label assignments which ignore missing labels in realistic applications. Meanwhile, few studies handle the data coming from multiple sources (multiple views) to enhance label correlations. In this paper, we propose a new robust method for multi-label classification problem. The proposed method incorporates multiple views into a mixed feature matrix, and augments the initial label matrix with label correlation matrix to estimate authentic label assignments. In addition, a low-rank structure and a manifold regularization are used to further exploit global label correlations and local smoothness. An alternating algorithm is designed to slove the optimization problem. Experiments on three authoritative datasets demonstrate the effectiveness and robustness of our method.	multi-label classification	Weijieying Ren;Lei Zhang;Bo Jiang;Zhefeng Wang;Guangming Guo;Guiquan Liu	2017		10.1007/978-3-319-63558-3_46	machine learning;artificial intelligence;robustness (computer science);multi-label classification;data mining;computer science;smoothness;covariance matrix;matrix (mathematics);manifold regularization;exploit;optimization problem;pattern recognition	AI	23.985262967575313	-43.6857117151173	32534
6822b932a2c557334eb1119f76ce23b8fce3603c	integrating low-rank approximation and word embedding for feature transformation in the high-dimensional text classification		Abstract With the Bag-of-Words model, a document corpus can be originally represented by a Terms-Documents matrix. However, the high-dimensional pure Terms-Documents matrix needs transforming to a lower-dimensional semantic Concepts-Documents matrix in order to not only reduce the feature space dimension but also create more meaningful features. This paper analyzes two feature transformation (FT) models on the Terms-Documents matrix, i.e. the FT model based on Low-Rank Approximation (LRA) and the FT model based on Word Embedding (WE). Both of them have their unique strength and weakness in the text transformation. The LRA-based FT only focuses on the mathematical perspective to statistically cover the original dispersed term set of the corpus as well as possible, while the WE-based FT utilizes the available word embedding vectors to enhance the contextual content of the corpus presentation. Therefore, the combinations of the LRA-based FT and the WE-based FT, named LRAintoWE-based FT and WEintoLRA-based FT, are possibly proposed to obtain comprehensive FTs capturing appropriately both the statistical information and the contextual information. The experiment results on three benchmark datasets show that the information of the WE-based FT and the LRA-based FT can be integrated, and their integration as LRAintoWE-based FT and WEintoLRA-based FT can improve the classification performance compared with that based on only either of them.	document classification;low-rank approximation;word embedding	Le Nguyen Hoai Nam;Ho Bao Quoc	2017		10.1016/j.procs.2017.08.058	word embedding;machine learning;low-rank approximation;matrix (mathematics);computer science;feature vector;artificial intelligence;pattern recognition	NLP	22.86100589318558	-43.467441672014736	32551
ce9ec57c74553f5dc8f9e68380fbe9d321da3beb	cost-sensitive learning for recurrence prediction of breast cancer	recurrence prediction;data mining;survival analysis;cost sensitive learning;breast cancer	Breast cancer is one of the top cancer-death causes and specifically accounts for 10.4% of all cancer incidences among women. The prediction of breast cancer recurrence has been a challenging research problem for many researchers. Data mining techniques have recently received considerable attention, especially when used for the construction of prognosis models from survival data. However, existing data mining techniques may not be effective to handle censored data. Censored instances are often discarded when applying classification techniques to prognosis. In this paper, we propose a cost-sensitive learning approach to involve the censored data in prognostic assessment with better recurrence prediction capability. The proposed approach employs an outcome inference mechanism to infer the possible probabilistic outcome of each censored instance and adopt the cost-proportionate rejection sampling and a committee machine strategy to take into account these instances with probabilistic outcomes during the classification model learning process. We empirically evaluate the effectiveness of our proposed approach for breast cancer recurrence prediction and include a censored-data-discarding method (i.e., building the recurrence prediction model by only using uncensored data) and the Kaplan-Meier method (a common prognosis method) as performance benchmarks. Overall, our evaluation results suggest that the proposed approach outperforms its benchmark techniques, measured by precision, recall and F1 score.	benchmark (computing);censoring (statistics);committee machine;data mining;f1 score;kaplan–meier estimator;mac os x 10.4 tiger;protein structure prediction;rejection sampling;sampling (signal processing)	Tsang-Hsiang Cheng;Ci-Wei Lan;Chih-Ping Wei;Henry Chang	2010			breast cancer;survival analysis	ML	14.59213065035659	-41.842009481603434	32553
3bdf29f44da92c85619c50172efc41623562ac7f	improving boosting performance with a local combination of learners	real adaboost ensemble classifiers;cost function;neural nets;training;gating scheme;standard linear combination;error analysis;boosting ensembles;artificial neural networks;boosting ensembles boosting performance real adaboost ensemble classifiers standard linear combination gating scheme epoch by epoch construction;boosting;training boosting cost function algorithm design and analysis error analysis artificial neural networks neurons;boosting performance;pattern classification;neurons;epoch by epoch construction;learning artificial intelligence;algorithm design and analysis;pattern classification learning artificial intelligence neural nets	This work explores the possibility of improving the performance of Real Adaboost ensemble classifiers by replacing their standard linear combination of learners by a gating scheme. This more powerful fusion method is defined following the epoch-by-epoch construction of boosting ensembles. Preliminary experimental results support the potential of this new approach.	adaboost;benchmark (computing);boosting (machine learning);computation;ensemble learning;epoch (reference date)	Efraín Mayhua-López;Vanessa Gómez-Verdejo;Aníbal R. Figueiras-Vidal	2010	The 2010 International Joint Conference on Neural Networks (IJCNN)	10.1109/IJCNN.2010.5596317	algorithm design;computer science;artificial intelligence;machine learning;pattern recognition;boosting;artificial neural network	Robotics	14.9274712393293	-32.756885878290625	32631
e8dc2dbd01b77f2b52097ddd995ba1d7f2fc7afb	efficiently finding the most parsimonious phylogenetic tree via linear programming	y chromosome;heuristic method;phylogenetic tree;linear program;computational biology;integer linear program	Reconstruction of phylogenetic trees is a fundamental problem in computational biology. While excellent heuristic methods are available for many variants of this problem, new advances in phylogeny inference will be required if we are to be able to continue to make effective use of the rapidly growing stores of variation data now being gathered. In this paper, we introduce an integer linear programming formulation to find the most parsimonious phylogenetic tree from a set of binary variation data. The method uses a flow-based formulation that could use exponential numbers of variables and constraints in the worst case. The method has, however, proved extremely efficient in practice on datasets that are well beyond the reach of the available provably efficient methods. The program solves several large mtDNA and Y-chromosome instances within a few seconds, giving provably optimal results in times competitive with fast heuristics than cannot guarantee optimality.	best, worst and average case;computational biology;heuristic (computer science);integer programming;linear programming formulation;maximum parsimony (phylogenetics);occam's razor;phylogenetic tree;phylogenetics;time complexity	Srinath Sridhar;Fumei Lam;Guy E. Blelloch;R. Ravi;Russell Schwartz	2007		10.1007/978-3-540-72031-7_4	biology;mathematical optimization;phylogenetic tree;computer science;bioinformatics;linear programming;theoretical computer science;machine learning;mathematics;algorithm	ML	1.2772021573429908	-51.08901320037598	32646
107cff1d20f56ef101877d48a9524ae46530a908	bam learning of nonlinearly separable tasks by using an asymmetrical output function and reinforcement learning	modelizacion;attracteur;teoria cognitiva;reinforcement learning bidirectional associative memory bam chaos control cusp catastrophe hybrid model nonlinearly separable tasks prior knowledge;nonlinearly separable tasks;neural networks;learning;supervised learning;neural nets;asymmetry;chaos;helium;search space;reinforcement learning;modelo hibrido;caos;vector space;chaotic wandering;catastrophe theory;punto fijo;cognitive theory;prior knowledge;attractor;psychology;theorie catastrophe;asymetrie;modele hybride;magnesium compounds;cusp catastrophe;theorie cognitive;hybrid model;fixed point;atractor;modelisation;regression analysis content addressable storage learning artificial intelligence neural nets;bam learning;algorithms artificial intelligence cognition computer simulation humans learning memory mental recall neural networks computer nonlinear dynamics regression analysis reinforcement psychology;apprentissage renforce;bidirectional associative memory networks;memoria asociativa bidireccional;general regression neural network;chaos control;bidirectional associative memory bam;point fixe;asymmetrical output function;associative memory;asimetria;genetic algorithms;regression analysis;espace vectoriel;magnesium compounds learning chaos associative memory neural networks switches genetic algorithms psychology computer science;computer science;apprentissage supervise;teoria catastrofe;learning artificial intelligence;reseau neuronal;dual fixed point behavior;switches;aprendizaje reforzado;content addressable storage;aprendizaje supervisado;modeling;cognitive model;bidirectional associative memory;espacio vectorial;memoire associative bidirectionnelle;fix point;red neuronal;cognitive modeling viewpoint;neural network;general regression neural network bam learning bidirectional associative memory networks nonlinearly separable tasks asymmetrical output function reinforcement learning dual fixed point behavior chaotic wandering cognitive modeling viewpoint	Most bidirectional associative memory (BAM) networks use a symmetrical output function for dual fixed-point behavior. In this paper, we show that by introducing an asymmetry parameter into a recently introduced chaotic BAM output function, prior knowledge can be used to momentarily disable desired attractors from memory, hence biasing the search space to improve recall performance. This property allows control of chaotic wandering, favoring given subspaces over others. In addition, reinforcement learning can then enable a dual BAM architecture to store and recall nonlinearly separable patterns. Our results allow the same BAM framework to model three different types of learning: supervised, reinforcement, and unsupervised. This ability is very promising from the cognitive modeling viewpoint. The new BAM model is also useful from an engineering perspective; our simulations results reveal a notable overall increase in BAM learning and recall performances when using a hybrid model with the general regression neural network (GRNN).	artificial neural network;behavior;biasing;bidirectional associative memory;biological neural networks;catastrophe theory;chaos theory;cognitive model;content-addressable memory;dual;exclusive or;feature extraction;fixed-point number;generalization (psychology);iteration;large;neural network simulation;nonlinear system;one-to-many (data model);pattern recognition;performance;population parameter;published comment;reln gene;rl (complexity);reinforcement learning;root-finding algorithm;supervised learning;unsupervised learning;whole earth 'lectronic link	Sylvain Chartier;Mounir Boukadoum;Mahmood Amiri	2009	IEEE Transactions on Neural Networks	10.1109/TNN.2009.2023120	cognitive model;systems modeling;genetic algorithm;vector space;network switch;computer science;artificial intelligence;catastrophe theory;machine learning;fixed point;bidirectional associative memory;helium;attractor;artificial neural network;asymmetry;regression analysis	ML	17.174982358217076	-26.879109227078025	32660
56573557018d7f42bb07c04a63dcb3b3d2d0b445	upper bound on pattern storage in feedforward networks	interpolation;support vector machines;activation function;upper bound neural networks feedforward neural networks interpolation polynomials multilayer perceptrons support vector machines nonlinear equations shape;multilayer perceptrons;hidden activations;multilayer perceptron;upper bound;conjugate gradient;nonlinear feedforward network;radial basis function network;multilayer perceptron models;support vector machines conjugate gradient methods interpolation multilayer perceptrons;support vector machines pattern storage interpolation equations multivariate polynomials upper bound nonlinear feedforward network hidden activations conjugate gradient multilayer perceptron models;pattern storage;multivariate polynomials;conjugate gradient methods;interpolation equations	Starting from the strict interpolation equations for multivariate polynomials, an upper bound is developed for the number of patterns that can be memorized by a nonlinear feedforward network. A straightforward proof by contradiction is presented for the upper bound. It is shown that the hidden activations do not have to be analytic. Networks, trained by conjugate gradient, are used to demonstrate the tightness of the bound for random patterns. Based upon the upper bound, small multilayer perceptron models are successfully demonstrated for large support vector machines.	activation function;conjugate gradient method;feed forward (control);feedforward neural network;interpolation;memory-level parallelism;multilayer perceptron;nonlinear system;polynomial;simulation;support vector machine	Pramod Lakshmi Narasimha;Michael T. Manry;Francisco Maldonado	2007	2007 International Joint Conference on Neural Networks	10.1109/IJCNN.2007.4371216	support vector machine;mathematical optimization;discrete mathematics;interpolation;computer science;machine learning;mathematics;conjugate gradient method;upper and lower bounds;multilayer perceptron;activation function;radial basis function network	ML	18.23231725405106	-29.705150625529143	32692
8bb9580566b3f0604b08fcd359c236da82a03031	naive bayes classification given probability estimation trees	bayes estimation;estimation theory;empirical study;decision tree;probability;probability estimation tree;tree induction;hybrid models;bayes methods;naive bayes;classification tree analysis positron emission tomography decision trees probability machine learning machine learning algorithms regression tree analysis predictive models frequency estimation learning systems;classification;hybrid model;bayes estimation naive bayes classification probability estimation trees tree induction decision trees hybrid models;naive bayes classifier;hybrid classification model;naive bayes classification;hybrid classification model probability estimation tree decision tree naive bayes classification;probability bayes methods decision trees estimation theory learning artificial intelligence pattern classification;pattern classification;learning artificial intelligence;decision trees;probability estimation trees	Tree induction is one of the most effective and widely used models in classification. Unfortunately, decision trees such as C4.5 have been found to provide poor probability estimates. By the empirical studies, Provost and Domingos found that probability estimation trees (PETs) give a fairly good probability estimation. However, different from normal decision trees, pruning reduces the performances of PETs. In order to get a good probability estimation, we usually need large trees which are not good in terms of the model transparency. In this paper, two hybrid models by combining the naive Bayes classifier and PETs are proposed in order to build a model with good performance without losing too much transparency. The first model use naive Bayes estimation given a PET and the second model use a group of small-sized PETs as naive Bayes estimators. Empirical studies show that the first model outperforms the PET model at shallow depth and the second model is equivalent to naive Bayes and PET	c4.5 algorithm;decision tree;estimation theory;naive bayes classifier;performance;polyethylene terephthalate;two-hybrid screening	Zengchang Qin	2006	2006 5th International Conference on Machine Learning and Applications (ICMLA'06)	10.1109/ICMLA.2006.36	bayes classifier;bayes' rule;naive bayes classifier;computer science;machine learning;decision tree;pattern recognition;statistics	ML	12.08309017794351	-38.570931872443595	32712
860314c6d2076794dfcac3c84b7e27f7ce9b1987	evidential calibration of binary svm classiers	evidence theory;theory of belief functions;dempster shafer theory;classifier calibration;support vector machine;dempstershafer theory	In machine learning problems, the availability of several classifiers trained on different data or features makes the combination of pattern classifiers of great interest. To combine distinct sources of information, it is necessary to represent the outputs of classifiers in a common space via a transformation called calibration. The most classical way is to use class membership probabilities. However, using a single probability measure may be insufficient to model the uncertainty induced by the calibration step, especially in the case of few training data. In this paper, we extend classical probabilistic calibration methods to the evidential framework. Experimental results from the calibration of SVM classifiers show the interest of using belief functions in classification problems.	algorithm;isotonic regression;logistic regression;machine learning;pattern recognition;product binning	Philippe Xu;Franck Davoine;Hongbin Zha;Thierry Denoeux	2015	Int. J. Approx. Reasoning	10.1016/j.ijar.2015.05.002	random subspace method;calibration;support vector machine;dempster–shafer theory;computer science;machine learning;pattern recognition;data mining;mathematics;statistics	AI	-0.254558459914487	-28.5377608580485	32713
f120282b7476644c8c62cb0181e5871d14d2fe3a	off-line state-dependent parameter models identification using simple fixed interval smoothing		This paper shows a detailed study about the Young's algorithm for parameter estimation on ARX-SDP models and proposes some improvements. To reduce the high entropy of the unknown parameters, data reordering according to a state ascendant ordering is used on that algorithm. After the Young's temporal reordering process, the old data do not necessarily continue so. We propose to reconsider the forgetting factor, internally used in the exponential window past, as a fixed and small value. This proposal improves the estimation results, especially in the low data density regions, and improves the algorithm velocity as experimentally shown. Other interesting improvement of our proposal is characterized by the flexibility to the changes on the state-parameter dependency. This is important in a future On-Line version. Interesting features of the SDP estimation algorithm for the case of ARX-SDP models with unitary regressors and the case with correlated state-parameter are also studied. Finally a example shows our results using the INCA toolbox we developed for our proposal.	arx;areal density (computer storage);captain (videotex);cooley–tukey fft algorithm;dependency grammar;entropy (information theory);estimation theory;experiment;kernel density estimation;offset (computer science);optimization problem;smoothing;support vector machine;time complexity;velocity (software development)	Elvis Omar Jara Alegria;Hugo Tanzarella Teixeira;Celso Pascoli Bottura	2015	2015 12th International Conference on Informatics in Control, Automation and Robotics (ICINCO)		econometrics;mathematical optimization;machine learning;mathematics;statistics	Robotics	21.729071043370688	-29.526736678304893	32717
f046c365395fb54e9e5acf18675ba88f17f4fe6e	low complexity adaptive forgetting factor for online sequential extreme learning machine (os-elm) for application to nonstationary system estimations		Huang et al. (2004) has recently proposed an on-line sequential ELM (OS-ELM) that enables the extreme learning machine (ELM) to train data one-by-one as well as chunk-by-chunk. OS-ELM is based on recursive least squares-type algorithm that uses a constant forgetting factor. In OS-ELM, the parameters of the hidden nodes are randomly selected and the output weights are determined based on the sequentially arriving data. However, OS-ELM using a constant forgetting factor cannot provide satisfactory performance in time-varying or nonstationary environments. Therefore, we propose an algorithm for the OS-ELM with an adaptive forgetting factor that maintains good performance in time-varying or nonstationary environments. The proposed algorithm has the following advantages: (1) the proposed adaptive forgetting factor requires minimal additional complexity of O(N) where N is the number of hidden neurons, and (2) the proposed algorithm with the adaptive forgetting factor is comparable with the conventional OS-ELM with an optimal forgetting factor.	algorithm;array processing;elm;interference (communication);nonlinear system;online and offline;operating system;randomness;recursion;recursive least squares filter;vector processor	Jun-Seok Lim;Seokjin Lee;Hee-Suk Pang	2012	Neural Computing and Applications	10.1007/s00521-012-0873-x	speech recognition;computer science;artificial intelligence;machine learning;statistics	ML	16.057818471534386	-30.656695693540236	32834
d9cae31be2f5f843b899e5030b1b6f0b87e31347	fast genome-wide epistasis analysis using ant colony optimization for multifactor dimensionality reduction analysis on graphics processing units	human disease;ant colony optimization;integrated circuit;large dataset;ant colony;gpu;aco;genetics;multifactor dimensionality reduction;graphic processing unit;expert knowledge;evolutionary algorithm;high throughput;computational efficiency;genome sequence;exhaustive search	Epistasis, or non-linear gene-to-gene interaction, is now thought to be at the heart of many common human diseases. A popular algorithm to detect epistasis is Multifactor Dimensionality Reduction (MDR), which exhaustively searches to determine an optimal classification. This exhaustive search is combinatorial in complexity and does not scale efficiently to large datasets. Ant Colony Opimization (ACO) is a technique to reduce this complexity by exploiting expert knowledge to spend more time looking at most likely candidates for the optimal classification. Graphics Processing Units (GPUs) are highly-parallel integrated circuits able to execute arbitrary code. The authors implemented ACO MDR on GPUs and compared it to both a Java ACO implementation and an exhaustive C++ implementation. The performance advantage of GPUs, combined with the added computational efficiency of a heuristic evolutionary algorithm such as ACO, allow larger scale problems to be tackled, something that is becoming critical with the advances in high throughput genome sequencing.	ant colony optimization algorithms;arbitrary code execution;brute-force search;c++;complexity;evolutionary algorithm;graphics processing unit;heuristic;integrated circuit;java;mathematical optimization;memory data register;multifactor dimensionality reduction;nonlinear system;scalability;throughput;whole genome sequencing	Nicholas A. Sinnott-Armstrong;Casey S. Greene;Jason H. Moore	2010		10.1145/1830483.1830523	high-throughput screening;mathematical optimization;ant colony optimization algorithms;whole genome sequencing;multifactor dimensionality reduction;computer science;bioinformatics;integrated circuit;ant colony;machine learning;evolutionary algorithm;brute-force search;data mining	HPC	2.623297703792522	-46.867679549229855	32884
0fbd4f121b20c002437e183d1ccd724f72d29877	nonstationary topological learning with bridges and convex polytopes: the g-exin neural network		Non-stationary topological representation can be addressed in two ways, according to the application: life-long modeling or by forgetting the past. Life-long learning requires neural networks equipped with a tool for judging if a neuron has to be created for tracking the input distribution. It is always implemented as an isotropic criterion (a hypersphere centered at the winner weight vector represents the domain of the neuron). Instead, the G-EXIN neural network, presented here, uses an anisotropic convex polytope, which, models the shape of the neuron neighborhood. This idea allows to consider the boundaries of the Voronoi sets of data and controls the extent of the extrapolation. It also employs a novel kind of edge, called bridge, which carries information on the extent of the distribution time change. Indeed, the analysis of bridges, mainly their density, yields a deeper insight to the kind of non-stationarity. Both artificial and real examples are given of the advantages of this approach with regard to the ESOINN neural network, which is the best existing approach to life-long modeling.	artificial life;extrapolation;information;neural networks;neuron;program lifecycle phase;sensor;software bug;stationary process;structured text	Vincenzo Randazzo;Giansalvo Cirrincione;Alpha Boubaca Barry;Eros Pasero	2018	2018 International Joint Conference on Neural Networks (IJCNN)	10.1109/IJCNN.2018.8489186	voronoi diagram;extrapolation;polytope;artificial neural network;regular polygon;convex polytope;weight;hypersphere;computer science;topology	ML	18.521408197324533	-31.909004690159623	32913
1b842139a0b436a2f7652ea1c56cd21f912b596e	better partitions of protein graphs for subsystem quantum chemistry		Determining the interaction strength between proteins and small molecules is key to analyzing their biological function. Quantummechanical calculations such as Density Functional Theory (DFT) give accurate and theoretically well-founded results. With common implementations the running time of DFT calculations increases quadratically with molecule size. Thus, numerous subsystem-based approaches have been developed to accelerate quantum-chemical calculations. These approaches partition the protein into different fragments, which are treated separately. Interactions between different fragments are approximated and introduce inaccuracies in the calculated interaction energies. To minimize these inaccuracies, we represent the amino acids and their interactions as a weighted graph in order to apply graph partitioning. None of the existing graph partitioning work can be directly used, though, due to the unique constraints in partitioning such protein graphs. We therefore present and evaluate several algorithms, partially building upon established concepts, but adapted to handle the new constraints. For the special case of partitioning a protein along the main chain, we also present an efficient dynamic programming algorithm that yields provably optimal results. In the general scenario our algorithms usually improve the previous approach significantly and take at most a few seconds.	approximation algorithm;brute-force search;density functional theory;dijkstra's algorithm;dynamic programming;emoticon;fm broadcasting;fiduccia-mattheyses algorithm;function (biology);general-purpose modeling;graph partition;greedy algorithm;interaction;liu hui's π algorithm;minimum-weight triangulation;nan;pseudocode;rate of convergence;recursion;region growing;ring counter;self-balancing binary search tree;time complexity	Moritz von Looz;Mario Wolter;Christoph R. Jacob;Henning Meyerhenke	2016		10.1007/978-3-319-38851-9_24	mathematical optimization;combinatorics;theoretical computer science;mathematics;algorithm	PL	-0.4695641373091484	-50.14052396945334	32963
27e5d4a679cce504da4c43c9e9a8f4aa482a439a	kernelized cluster validity measures and application to evaluation of different clustering algorithms	cluster algorithm;clustering algorithms chromium robustness testing kernel support vector machines fluctuations stability character generation euclidean distance;pattern clustering;covariance analysis;fuzzy covariance;support vector machines;kernel function;fuzzy set theory;kernelized cluster validity measure;nonlinear boundary;support vector machines covariance analysis fuzzy set theory pattern clustering;number of clusters;kernelized clustering algorithm evaluation;cluster validity;support vector machine;kernel function kernelized cluster validity measure kernelized clustering algorithm evaluation support vector machines fuzzy covariance nonlinear boundary	Many cluster validity measures have been proposed up to now, and it is realized that no universally best measure exists. In this paper we propose kernelized validity measures where a kernel means the kernel function used in support vector machines. Two measures are considered: one is the sum of the traces of the fuzzy covariances within clusters. Why we consider the trace instead of the determinant is that the calculation of the determinant will be ill-posed when kernelized, while the trace is sound and easily computed. The second is a kernelized Xie-Beni's measure. These two measures are applied to the determination of the number of clusters having nonlinear boundaries generated by kernelized clustering algorithms. Another application of the measures is the evaluation of robustness of different algorithms with respect to variations of initial values and changes of a parameter.	algorithm;cluster analysis;feature vector;kernel (operating system);kernel method;lazy evaluation;nonlinear system;sensitivity and specificity;support vector machine;tracing (software);well-posed problem;x image extension	Ryo Inokuchi;Tetsuya Nakamura;Sadaaki Miyamoto	2006	2006 IEEE International Conference on Fuzzy Systems	10.1109/FUZZY.2006.1681796	support vector machine;radial basis function kernel;computer science;machine learning;pattern recognition;data mining;graph kernel;mathematics;polynomial kernel	Robotics	15.778864143833493	-46.42401176774818	33025
84fa7bf01be02848fcd723a8b47276bf59e5b4ed	a simple regression based heuristic for learning model trees	regression tree;model trees;learning model;linear regression model;regression;machine learning;prediction accuracy;heuristics;experimental evaluation	The term “model trees” is commonly used for regression trees that contain some non-trivial model in their leaves. Popular implementations of model tree learners build trees with linear regression models in their leaves. They use reduction of variance as a heuristic for selecting tests during the tree construction process. In this article, we show that systems employing this heuristic may exhibit pathological behaviour in some quite simple cases. This is not visible in the predictive accuracy of the tree, but it reduces its explanatory power. We propose an alternative heuristic that yields equally accurate but simpler trees with better explanatory power, and this at little or no additional computational cost. The resulting model tree induction algorithm is experimentally evaluated and compared with simpler and more complex approaches on a variety of synthetic and real world data sets.	algorithm;algorithmic efficiency;computation;decision tree;experiment;heuristic;synthetic intelligence	Celine Vens;Hendrik Blockeel	2006	Intell. Data Anal.		econometrics;proper linear model;regression;decision tree learning;computer science;linear regression;heuristics;machine learning;decision tree;linear model;pattern recognition;mathematics;logistic model tree	AI	16.836484240478526	-36.89103494273729	33155
95dbc8d3140085f8fb01c60af62ae0281662d6e2	a systematic comparison of deep learning architectures in an autonomous vehicle		Self-driving technology is advancing rapidly — albeit with significant challenges and limitations. This progress is largely due to recent developments in deep learning algorithms. To date, however, there has been no systematic comparison of how different deep learning architectures perform at such tasks, or an attempt to determine a correlation between classification performance and performance in an actual vehicle, a potentially critical factor in developing self-driving systems. Here, we introduce the first controlled comparison of multiple deep-learning architectures in an end-to-end autonomous driving task across multiple testing conditions. We used a simple and affordable platform consisting of an off-the-shelf, remotely operated vehicle, a GPU-equipped computer, and an indoor foamrubber racetrack. We compared performance, under identical driving conditions, across seven architectures including a fully-connected network, a simple 2 layer CNN, AlexNet, VGG-16, Inception-V3, ResNet, and an LSTM by assessing the number of laps each model was able to successfully complete without crashing while traversing an indoor racetrack. We compared performance across models when the conditions exactly matched those in training as well as when the local environment and track were configured differently and objects that were not included in the training dataset were placed on the track in various positions. In addition, we considered performance using several different data types for training and testing including single grayscale and color frames, and multiple grayscale frames stacked together in sequence. With the exception of a fully-connected network, all models performed reasonably well (around or above 80%) and most very well (∼95%) on at least one input type but with considerable variation across models and inputs. Overall, AlexNet, operating on single color frames as input, achieved the best level of performance (100% success rate in phase one and 55% in phase two) while VGG-16 performed well most consistently across image types. Performance with obstacles on the track and conditions that were different than those in training was much more variable than without objects and under conditions similar to those in the training set. Analysis of the model’s driving paths found greater consistency within vs. between models. Path similarity between models did not correlate strongly with success similarity. Our novel pixelflipping method allowed us to create a heatmap for each given image to observe what features of the image were weighted most heavily by the network when making its decision. Finally, we found that the variability across models in the driving task was not fully predicted by validation performance, indicating the presence of a ‘deployment gap’ between model training and performance in a simple, real-world task. Overall, these results demonstrate the need for increased field research in self-driving. 1Center for Complex Systems and Brain Sciences, Florida Atlantic University, 777 Glades Road, Boca Raton, FL 33431, USA 2College of Computer and Information Science, Northeastern University, 360 Huntington Ave, Boston, MA 02115, USA 3Department of Ocean and Mechanical Engineering, Florida Atlantic University, 777 Glades Road, Boca Raton, FL 33431, USA † mteti@fau.edu	algorithm;artificial neural network;autonomous car;autonomous robot;complex systems;control system;deep learning;embedded system;end-to-end principle;flops;field research;graphics processing unit;grayscale;heat map;in-phase and quadrature components;information and computer science;information science;long short-term memory;machine learning;network topology;particle filter;racetrack memory;remotely operated vehicle;software deployment;spatial variability;test set	Michael Teti;Elan Barenholtz;Shawn Martin;William Edward Hahn	2018	CoRR		traverse;machine learning;artificial intelligence;deep learning;remotely operated vehicle;architecture;mathematics	ML	19.55988270545459	-51.990250352043454	33227
4c46347fbc272b21468efe3d9af34b4b2bad6684	deep learning via hessian-free optimization	large dataset;optimal method;deep learning	We develop a 2nd-order optimization method based on the “Hessian-free” approach, and apply it to training deep auto-encoders. Without using pre-training, we obtain results superior to those reported by Hinton & Salakhutdinov (2006) on the same tasks they considered. Our method is practical, easy to use, scales nicely to very large datasets, and isn’t limited in applicability to autoencoders, or any specific model class. We also discuss the issue of “pathological curvature” as a possible explanation for the difficulty of deeplearning and how 2nd-order optimization, and our method in particular, effectively deals with it.	autoencoder;deep learning;encoder;hessian;mathematical optimization;truncated newton method	James Martens	2010			computer science;machine learning;pattern recognition;data mining;deep learning	AI	21.93315961121633	-35.960589373796026	33234
4a48cd2d5878f6eee4de498015bc6a2df4b3734a	modeling with insufficient data to increase prediction stability	forecasting;small sample artificial intelligence uncertainty modeling forecasting data augmentation em algorithm;data augmentation;small sample;uncertainty modeling;artificial intelligence;maximum likelihood estimation approximation algorithms data models bayes methods robustness inference algorithms uncertainty;regression analysis bayes methods data handling expectation maximisation algorithm inference mechanisms mean square error methods;em algorithm;mean squared error prediction stability small sample regression bayesian inference regression parameters estimation data augmentation expectation maximization algorithm em algorithm maximum likelihood estimation	This article proposes a procedure for small sample regression, systematically using the concept of robust Bayesian inference and a contaminated prior. The approach explores the possible domain of population information and attempts to estimate regression parameters further. A data augmentation step included in the procedure works to enlarge the original small data set by adding new data to it. It follows that when the expectation-maximization (EM) algorithm is used to output the hypothesis, approximating the true (but unobservable) parameters based on the enlarged data set. Both the augmented data set and the maximum likelihood estimate used are generated, based on the implementation of contaminated priors. The experiments show that the proposed procedure can effectively lower the mean squared error when modeling.	convolutional neural network;expectation–maximization algorithm;experiment;mean squared error	Yao-San Lin	2016	2016 5th IIAI International Congress on Advanced Applied Informatics (IIAI-AAI)	10.1109/IIAI-AAI.2016.19	econometrics;pattern recognition;mathematics;maximum likelihood sequence estimation;statistics	ML	23.085052437767065	-27.99768226215058	33263
0a90a9f8f1084b3ce5bede83bdb909d4db7edd0c	dts: dynamic trees	dynamic tree	"""In this paper we introduce a new class of image models, which we call dynamic trees or DTs. A dynamic tree model specifies a prior over a large number of trees, each one of which is a tree-structured belief net (TSBN). Experiments show that DTs are capable of generating images that are less blocky, and the models have better translation invariance properties than a fixed, """"balanced"""" TSBN. We also show that Simulated Annealing is effective at finding trees which have high posterior probability."""	link/cut tree;simulated annealing	Christopher K. I. Williams;Nicholas J. Adams	1998			computer science;theoretical computer science;algorithm	Vision	24.52852284501689	-27.703057202826475	33269
e989683b9a2c44cf0241ae0e5a299988e80591a0	differential evolution based band selection in hyperspectral data classification	differential evolution;band selection;naive bayes;hyperspectral data;global optimization;information entropy;classification accuracy;local minima;spectral classification	Differential evolution is a new heuristic approach for global optimization method. Hyperspectral data included huge information, how to process the hyperspectral data lack of reliable and effective technique. We presented an evolutional program to select hyperspectral band, which is very fast and certainty, in order to avoid the band felling in local minima, the selected bands are contained in the entire spectral range, and have a good performance in hyperspectral data classification. The classification methods we used are very classic, which are good at the imbalance data, so that the classification accuracy are convincing, for example NBtree, Naive Bayes and J4.8. The results in classification of various kinds of minerals in uranium deposit are better than other methods, such as information entropy.	algorithm;artificial intelligence;data mining;differential evolution;entropy (information theory);global optimization;heuristic;mathematical optimization;maxima and minima;naive bayes classifier;random search	Xiaobo Liu;Chao Yu;Zhihua Cai	2010		10.1007/978-3-642-16493-4_9	machine learning;pattern recognition;data mining;mathematics	ML	10.312453054798594	-42.86897310853838	33271
55249853944d7bf52591756a210209c9fef8d0a7	a bayesian learning algorithm of discrete variables for automatically mining irregular features of pattern images	bayesian learning;feature extraction;image mining;belief network	"""Multimedia data mining often involves difficult problems where knowledge about patterns should be extracted automatically from datasets. It is also a critical task in pattern recognition systems to automatically extract highly irregular features of pattern images#1, especially when these features (e.g. structural features of unconstrained handwritten characters, video objects, etc.) can hardly be described in a quantitative way. In this paper we propose an image mining algorithm for irregular feature extraction. This algorithm is based on learning belief networks of pattern image pixels, each of which is regarded as a discrete variable with a limited number of states. The probability of belief network, i.e. Bayesian metric, is chosen to measure the associations between image pixels and the pattern image category. A heuristic algorithm is designated to learn the ψ-structure of belief network, where clusters of """"equivalent"""" pixels are regarded as the irregular features. We test the algorithm on both simulated data and real data (i.e. unconstrained handwritten characters). For simulated data, the algorithm can successfully discover the probabilistic associations implied by the ground truth mask. In the character feature extraction experiments, a hierarchy of statistically optimal feature vectors is obtained by averaging the pixel clusters over many independent experiments. The irregular features' soundness is verified with neural classifiers. Our results show that the heuristic Bayesian learning algorithm can produce significantly better features than the multi-layer perceptron, learning vector quantization network, sparse trace neural network, and simple template matching method."""		Hanchuan Peng;Fuhui Long	2001			computer vision;wake-sleep algorithm;feature extraction;computer science;machine learning;pattern recognition;bayesian network;data mining;bayesian inference;feature	ML	20.716447226379277	-45.68896819943662	33298
c8fa79401646e97da309e3dbd98cf5e52f65c91a	multi-schema matching based on web structured information sources	pattern clustering;clustering techniques multischema matching web structured information sources database applications data integration data warehouse data spaces ontology merging pair wise attribute correspondence semantic correspondence vector space partition attributes;database management systems;pattern clustering database management systems internet;internet;clustering algorithms vectors semantics vocabulary measurement educational institutions accuracy	Schema matching is widely used in many database applications, such as, data integration, data warehouse, data spaces, and ontology merging. In this paper, we propose multi-schema matching based on web structured information sources. There are two meanings at this point. Traditional matching techniques mainly address matching tasks between two attributes, namely pair wise-attribute correspondence. Thus, the first is that we will focus on find the semantic correspondence among multiple attributes, which is more difficult than pair wise-attribute correspondence. The main idea is to regard each attribute as a point in vector space and partition attributes into different set by clustering techniques. The attributes in the same cluster have the similar semantic. Second, we will use web sources that contain ample structured information to improve the quality of schema matching. We validate our approach with an experimental study, the results of which demonstrate that our approach is effective and has good performance.	algorithm;cluster analysis;dataspaces;experiment;information source;k-means clustering;ontology merging;vii;vocabulary	Guohui Ding;Yingnan Xu;Keyan Cao	2013	2013 10th Web Information System and Application Conference	10.1109/WISA.2013.23	computer science;data mining;database;information retrieval	DB	-3.8765210955938376	-43.675659425539294	33327
fefb5d04003c855a6a91398a22299892f91b0c34	proving the efficacy of complementary inputs for multilayer neural networks	complexity theory;training backpropagation complexity theory encoding equations accuracy surface treatment;multilayer perceptrons;training;backpropagation;feature space;feature vector;accuracy;surface treatment;multilayer perceptrons backpropagation;encoding;multilayer neural network;network complexity complementary inputs multilayer neural networks backpropagation based training approach decision surface training sets input feature vectors;training algorithm	This paper proposes and discusses a backpropagation-based training approach for multilayer networks that counteracts the tendency that typical backpropagation-based training algorithms have to “favor” examples that have large input feature values. This problem can occur in any real valued input space, and can create a surprising degree of skew in the learned decision surface even with relatively simple training sets. The proposed method involves modifying the original input feature vectors in the training set by appending complementary inputs, which essentially doubles the number of inputs to the network. This paper proves that this modification does not increase the network complexity, by showing that it is possible to map the network with complimentary inputs back into the original feature space.	algorithm;artificial neural network;backpropagation;decision boundary;feature vector;test set	Timothy L. Andersen	2011	The 2011 International Joint Conference on Neural Networks	10.1109/IJCNN.2011.6033480	feature vector;computer science;artificial intelligence;theoretical computer science;machine learning;multilayer perceptron	Vision	14.421214039539116	-33.441157007583634	33383
2b0afb1b62147b2767c781cf7a758a013c95ae05	learning theory of distributed regression with bias corrected regularization kernel network		Distributed learning is an effective way to analyze big data. In distributed regression, a typical approach is to divide the big data into multiple blocks, apply a base regression algorithm on each of them, and then simply average the output functions learnt from these blocks. Since the average process will decrease the variance, not the bias, bias correction is expected to improve the learning performance if the base regression algorithm is a biased one. Regularization kernel network is an effective and widely used method for nonlinear regression analysis. In this paper we will investigate a bias corrected version of regularization kernel network. We derive the error bounds when it is applied to a single data set and when it is applied as a base algorithm in distributed regression. We show that, under certain appropriate conditions, the optimal learning rates can be reached in both situations.	algorithm;big data;kernel (operating system);nonlinear system	Zheng-Chu Guo;Lei Shi;Qiang Zheng	2017	Journal of Machine Learning Research		artificial intelligence;kernel (linear algebra);machine learning;mathematics;pattern recognition;statistics;polynomial regression;regression;big data;nonlinear regression;principal component regression;regularization (mathematics);learning theory	ML	21.657819810467025	-33.72629750188019	33390
c8fc0d5c55cedc01ffab8555564c68056f50af73	effective imbalanced classification of breast thermogram features		Breast cancer is the most commonly occurring form of cancer in women, and can be diagnosed using various imaging modalities including thermography. In this paper, we present an approach to analysing breast thermograms based on statistical image features and an effective ensemble method for imbalanced classification problems. We extract a series of features from the images to arrive at indications of asymmetry between left and right breast regions. These then form the input to a classification stage for which we develop a dedicated multiple classifier system that employs neural networks or support vector machines as base classifiers, trains base classifiers on balanced subsets of the training data to address the class imbalance that is typically inherent in medical decision making problems, and fuses the decisions using a neural network combined with a fuzzy diversity measure to remove individual classifiers from the ensemble and to enhance prediction performance. Experimental results, on a large dataset of about 150 breast thermograms, confirm our approach to provide excellent classification performance and to outperform other classifier ensembles designed for imbalanced datasets.		Bartosz Krawczyk;Gerald Schaefer	2015		10.1007/978-3-319-19941-2_51	computer science;fuzzy logic;breast cancer;artificial neural network;artificial intelligence;support vector machine;pattern recognition;machine learning;feature (computer vision);training set	Vision	13.711213165741668	-44.612855380122404	33462
2512bb5b400fe4459f06303e38b0e6e169437332	an iterative block-shifting approach to retention time alignment that preserves the shape and area of gas chromatography-mass spectrometry peaks	gas chromatography mass spectrometry;high resolution;spectrum;retention time;computational biology bioinformatics;feature extraction;biopolymers;artificial intelligence;algorithms;pattern recognition automated;sequence alignment;data reduction;combinatorial libraries;data preprocessing;computer appl in life sciences;microarrays;bioinformatics;knowledge discovery	Metabolomics, petroleum and biodiesel chemistry, biomarker discovery, and other fields which rely on high-resolution profiling of complex chemical mixtures generate datasets which contain millions of detector intensity readings, each uniquely addressed along dimensions of time (e.g., retention time of chemicals on a chromatographic column), a spectral value (e.g., mass-to-charge ratio of ions derived from chemicals), and the analytical run number. They also must rely on data preprocessing techniques. In particular, inter-run variance in the retention time of chemical species poses a significant hurdle that must be cleared before feature extraction, data reduction, and knowledge discovery can ensue. Alignment methods, for calibrating retention reportedly (and in our experience) can misalign matching chemicals, falsely align distinct ones, be unduly sensitive to chosen values of input parameters, and result in distortions of peak shape and area. We present an iterative block-shifting approach for retention-time calibration that detects chromatographic features and qualifies them by retention time, spectrum, and the effect of their inclusion on the quality of alignment itself. Mass chromatograms are aligned pairwise to one selected as a reference. In tests using a 45-run GC-MS experiment, block-shifting reduced the absolute deviation of retention by greater than 30-fold. It compared favourably to COW and XCMS with respect to alignment, and was markedly superior in preservation of peak area. Iterative block-shifting is an attractive method to align GC-MS mass chromatograms that is also generalizable to other two-dimensional techniques such as HPLC-MS.	align (company);biologic preservation;biological markers;cow antigen;data pre-processing;detectors;dimensions;distortion;feature extraction;gases;image resolution;ions;iteration;iterative method;loudspeaker time alignment;mass effect trilogy;metabolomics;preprocessor;reading (activity);sample variance;spectrometry;mixture	Minho Chae;Robert J. Shmookler Reis;John J. Thaden	2008	BMC Bioinformatics	10.1186/1471-2105-9-S9-S15	spectrum;data reduction;dna microarray;gas chromatography–mass spectrometry;image resolution;feature extraction;computer science;bioinformatics;data science;sequence alignment;data pre-processing;knowledge extraction	ML	4.838856719716986	-51.38322883974119	33556
6799b073aa5e5407e2353e8f2b9446f9260b22cf	generalization error analysis: deep convolutional neural network in mammography		We conducted a study to gain understanding of the generalizability of deep convolutional neural networks (DCNNs) given their inherent capability to memorize data. We examined empirically a specific DCNN trained for classification of masses on mammograms. Using a data set of 2,454 lesions from 2,242 mammographic views, a DCNN was trained to classify masses into malignant and benign classes using transfer learning from ImageNet LSVRC-2010. We performed experiments with varying amounts of label corruption and types of pixel randomization to analyze the generalization error for the DCNN. Performance was evaluated using the area under the receiver operating characteristic curve (AUC) with an N-fold cross validation. Comparisons were made between the convergence times, the inference AUCs for both the training set and the test set of the original image patches without corruption, and the root-mean-squared difference (RMSD) in the layer weights of the DCNN trained with different amounts and methods of corruption. Our experiments observed trends which revealed that the DCNN overfitted by memorizing corrupted data. More importantly, this study improved our understanding of DCNN weight updates when learning new patterns or new labels. Although we used a specific classification task with the ImageNet as example, similar methods may be useful for analysis of the DCNN learning processes, especially those that employ transfer learning for medical image analysis where sample size is limited and overfitting risk is high.	artificial neural network;convolutional neural network;error analysis (mathematics);generalization error	Caleb D. Richter;Ravi K. Samala;Heang-Ping Chan;Lubomir M. Hadjiiski;Kenny H. Cha	2018		10.1117/12.2292921	cross-validation;convolutional neural network;overfitting;randomization;receiver operating characteristic;sample size determination;deep learning;artificial intelligence;computer science;test set;pattern recognition	NLP	20.463222726027897	-50.96909433254466	33650
f04f70deef8d3cb9cd6bad8913e5f41d52856504	choosing the best predicates for data-driven fuzzy modeling	quantization;optimisation;fuzzy set;neural networks;computer model;fuzzy set theory;fuzzy sets;ordering based predicate data driven fuzzy modeling fuzzy sets fuzzy partition fuzzy rule base;ordering based predicate;computational modeling;fuzzy rule base;shape;machine learning;optimisation fuzzy set theory knowledge based systems;data driven fuzzy modeling;fuzzy systems;knowledge based systems;fuzzy model;fuzzy partition;partitioning algorithms;fuzzy sets shape machine learning computational modeling partitioning algorithms neural networks quantization fuzzy systems	Data-driven fuzzy modeling is concerned with the induction of computational models from data. When creating fuzzy models from data, the problem arises how to choose the underlying fuzzy sets. On the one hand, the fuzzy sets should have a semantic meaning to ease interpretation, but on the other hand, their shape has a large influence on the quality of the resulting fuzzy model. In this paper, we would present an algorithm to derive fuzzy partitions from data. We would then illustrate the influence of the number and shape of fuzzy sets on the quality and the complexity of the resulting models. We show that by using ordering-based predicates, the problem of choosing the optimal number of fuzzy sets can be overcome. Finally, we would give an outlook on post optimization of fuzzy rule bases.	algorithm;computational model;fuzzy concept;fuzzy rule;fuzzy set;mathematical optimization;microsoft outlook for mac	Mario Drobics	2004	2004 IEEE International Conference on Fuzzy Systems (IEEE Cat. No.04CH37542)	10.1109/FUZZY.2004.1375727	fuzzy logic;discrete mathematics;fuzzy cognitive map;membership function;defuzzification;adaptive neuro fuzzy inference system;fuzzy transportation;type-2 fuzzy sets and systems;fuzzy mathematics;fuzzy classification;computer science;artificial intelligence;fuzzy number;neuro-fuzzy;knowledge-based systems;machine learning;fuzzy measure theory;data mining;mathematics;fuzzy set;fuzzy associative matrix;fuzzy set operations;artificial neural network;fuzzy control system	Robotics	3.896480807346452	-27.501140087213127	33667
5efd20b5dee4b6919ca699c7940a24b75726a633	beyond fine tuning: a modular approach to learning on small data		In this paper we present a technique to train neural network models on small amounts of data. Current methods for training neural networks on small amounts of rich data typically rely on strategies such as fine-tuning a pre-trained neural network or the use of domain-specific hand-engineered features. Here we take the approach of treating network layers, or entire networks, as modules and combine pre-trained modules with untrained modules, to learn the shift in distributions between data sets. The central impact of using a modular approach comes from adding new representations to a network, as opposed to replacing representations via fine-tuning. Using this technique, we are able surpass results using standard fine-tuning transfer learning approaches, and we are also able to significantly increase performance over such approaches when using smaller amounts of data.	artificial neural network;internet movie database (imdb);mnist database	Ark Anderson;Kyle Shaffer;Artëm Yankov;Courtney Corley;Nathan Oken Hodas	2016	CoRR		simulation;computer science;artificial intelligence;machine learning	ML	21.771880590368983	-50.3525515074669	33685
6cbd9faadbf67699d5ecb8eedc1c4e93749f0827	discovering a taste for the unusual: exceptional models for preference mining	subgroup discovery;exceptional model mining;label ranking;preference learning;distribution rules	Exceptional preferences mining (EPM) is a crossover between two subfields of data mining: local pattern mining and preference learning. EPM can be seen as a local pattern mining task that finds subsets of observations where some preference relations between labels significantly deviate from the norm. It is a variant of subgroup discovery, with rankings of labels as the target concept. We employ several quality measures that highlight subgroups featuring exceptional preferences, where the focus of what constitutes ‘exceptional’ varies with the quality measure: two measures look for exceptional overall ranking behavior, one measure indicates whether a particular label stands out from the rest, and a fourth measure highlights subgroups with unusual pairwise label ranking behavior. We explore a few datasets and compare with existing techniques. The results confirm that the new task EPM can deliver interesting knowledge.	data mining;electronic counter-countermeasure;preference learning	Cláudio Rebelo de Sá;Wouter Duivesteijn;Paulo J. Azevedo;Alípio Mário Jorge;Carlos Soares;Arno J. Knobbe	2018	Machine Learning	10.1007/s10994-018-5743-z	pattern recognition;artificial intelligence;machine learning;mathematics;preference learning;ranking;crossover;pairwise comparison;norm (social)	ML	15.527252385113714	-42.752470971181516	33742
2980bea598e2208b08e0996a114400415785debd	greedy layer-wise training of long short term memory networks		Recent developments in Recurrent Neural Networks (RNNs) such as Long Short Term Memory (LSTM) have shown promising potential for modeling sequential data. Nevertheless, training LSTM is not trivial when there are multiple layers in the deep architectures. This difficulty originates from the initialization method of LSTM, where gradient-based optimization often appears to converge to poor local solutions. In this paper, we explore an unsupervised pretraining mechanism for LSTM initialization, following the philosophy that the unsupervised pretraining plays the role of a regularizer to guide the subsequent supervised training. We propose a novel encoder-decoder-based learning framework to initialize a multi-layer LSTM in a greedy layer-wise manner in which each added LSTM layer is trained to retain the main information in the previous representation. A multi-layer LSTM trained with our method outperforms the one trained with random initialization, with clear advantages on several tasks. Moreover, the multi-layer LSTMs converge 4 times faster with our greedy layer-wise training method.		Kaisheng Xu;Xu Shen;Ting Yao;Xinmei Tian;Tao Mei	2018	2018 IEEE International Conference on Multimedia & Expo Workshops (ICMEW)	10.1109/ICMEW.2018.8551584	long short term memory;artificial intelligence;initialization;pattern recognition;recurrent neural network;computer science	Vision	21.97491504257357	-49.4846238580474	33759
959f0c18ca20c21719b4522c2e60c83cc8f5f24c	multi-criteria based learning of the choquet integral using goal programming	minimization;frequency modulation;sensors;training data;programming training data frequency modulation minimization sensors signal processing algorithms linear programming;monotonicity constraints multicriteria based learning aggregation operator labeled training data sets weighted goal programming multicriteria decision making mcdm fuzzy measure choquet integral data fusion information fusion;linear programming;signal processing algorithms;sensor fusion decision making fuzzy set theory integral equations learning artificial intelligence mathematical programming;programming	In this paper, we explore a new way to learn an aggregation operator for fusion based on a combination of one or more labeled training data sets and information from one or more experts. One problem with learning an aggregation from training data alone is that it often results in solutions that are overly complex and expensive to implement. It also runs the risk of over-fitting and the quality of that solution is based in large on the size and diversity of the data employed. On the other hand, learning an aggregation based on only expert opinion can be overly subjective and may not result in desired performance for some given task. In order to overcome these shortcomings, we explore a new way to combine both of these important sources. However, conflict between data sets, experts or a combination of the two, can (and often do) occur and must be addressed. Herein, weighted Goal programming, an approach from multi-criteria decision making (MCDM), is employed to learn the fuzzy measure (FM) relative to the Choquet integral (CI) for data/information fusion. This framework provides an interesting way in which we can set the priority order of any number of combination of these two sources. Furthermore, it provides a mechanism to preserve the monotonicity constraints of the FM. We demonstrate results from synthetic experiments across a range of different conflicting and combination of sources scenarios.	experiment;fm broadcasting;fuzzy measure theory;goal programming;manifold regularization;matrix regularization;overfitting;synthetic intelligence	Muhammad Aminul Islam;Derek Anderson;Timothy C. Havens	2015	2015 Annual Conference of the North American Fuzzy Information Processing Society (NAFIPS) held jointly with 2015 5th World Conference on Soft Computing (WConSC)	10.1109/NAFIPS-WConSC.2015.7284140	frequency modulation;programming;training set;mathematical optimization;computer science;sensor;linear programming;artificial intelligence;machine learning;goal programming;data mining;mathematics;inductive programming	Robotics	2.2719690475779184	-30.545729431284748	33833
434a9c417ec2336fd46e1dc6d57b2c7d1a1d7609	method for increasing the computation speed of an unsupervised learning approach for data clustering	data volume;pattern clustering;complexity theory;complexity analysis particle swarm optimization clustering statistical analysis;rce;k means;complexity analysis;euclidean distance;data dimension;rapid centroid estimation;data clustering;mpsc;statistical analysis;estimation;clustering;particle swarm optimization;fuzzy c means;fuzzy c means unsupervised learning approach data clustering data volume data dimension lightweight swarm clustering solution rapid centroid estimation rce optimization time modified particle swarm clustering mpsc k means;clustering algorithms;modified particle swarm clustering;lightweight swarm clustering solution;optimization;unsupervised learning approach;learning artificial intelligence;pattern clustering learning artificial intelligence particle swarm optimisation;particle swarm optimisation;algorithm design and analysis;conference proceeding;optimization time;complexity theory clustering algorithms optimization particle swarm optimization algorithm design and analysis estimation euclidean distance	Clustering can be especially effective where the data is irregular, noisy and/or not differentiable. A major obstacle for many clustering techniques is that they are computationally expensive, hence limited to smaller data volume and dimension. We propose a lightweight swarm clustering solution called Rapid Centroid Estimation (RCE). Based on our experiments, RCE has significantly quickened optimization time of its predecessors, Particle Swarm Clustering (PSC) and Modified Particle Swarm Clustering (mPSC). Our experimental results show that on benchmark datasets, RCE produces generally better clusters compared to PSC, mPSC, K-means and Fuzzy C-means. Compared with K-means and Fuzzy C-means which produces clusters with 62% and 55% purities on average respectively, thyroid dataset has successfully clustered on average 71% purity in 14.3 seconds.		Mitchell Yuwono;Steven W. Su;Bruce Moulton;Hung T. Nguyen	2012	2012 IEEE Congress on Evolutionary Computation	10.1109/CEC.2012.6252927	correlation clustering;mathematical optimization;data stream clustering;k-medians clustering;computer science;canopy clustering algorithm;machine learning;pattern recognition;cure data clustering algorithm;mathematics;cluster analysis	ML	-0.11792256525283686	-40.41738827613577	33868
9a67ef24bdbed0776d1bb0aa164c09cc029bbdd5	an improved algorithm for incremental induction of decision trees	decision tree	This paper presents an algorithm for incremental induction of decision trees that is able to handle both numeric and symbolic variables. In order to handle numeric variables, a new tree revision operator called`slewing' is introduced. Finally, a non-incremental method is given for nding a decision tree based on a direct metric of a candidate tree.	algorithm;decision tree;mathematical induction	Paul E. Utgoff	1994			c4.5 algorithm;decision tree learning;computer science;machine learning;decision tree;alternating decision tree;incremental decision tree;id3 algorithm;grafting;decision stump	ML	5.272130633640273	-32.231057884613186	33898
596d05fc4dec5dd230dd50c53801a6a1576aaa2a	using random forest for reliable classification and cost-sensitive learning for medical diagnosis	transductive learning;confidence level;computational biology bioinformatics;diagnostic techniques and procedures;real world application;kolmogorov complexity;machine learning;random forest;models statistical;artificial intelligence;algorithms;pattern recognition automated;cost sensitive learning;combinatorial libraries;computational biology;computer appl in life sciences;article;information storage and retrieval;prediction;medical diagnosis;microarrays;bioinformatics	Most machine-learning classifiers output label predictions for new instances without indicating how reliable the predictions are. The applicability of these classifiers is limited in critical domains where incorrect predictions have serious consequences, like medical diagnosis. Further, the default assumption of equal misclassification costs is most likely violated in medical diagnosis. In this paper, we present a modified random forest classifier which is incorporated into the conformal predictor scheme. A conformal predictor is a transductive learning scheme, using Kolmogorov complexity to test the randomness of a particular sample with respect to the training sets. Our method show well-calibrated property that the performance can be set prior to classification and the accurate rate is exactly equal to the predefined confidence level. Further, to address the cost sensitive problem, we extend our method to a label-conditional predictor which takes into account different costs for misclassifications in different class and allows different confidence level to be specified for each class. Intensive experiments on benchmark datasets and real world applications show the resultant classifier is well-calibrated and able to control the specific risk of different class. The method of using RF outlier measure to design a nonconformity measure benefits the resultant predictor. Further, a label-conditional classifier is developed and turn to be an alternative approach to the cost sensitive learning problem that relies on label-wise predefined confidence level. The target of minimizing the risk of misclassification is achieved by specifying the different confidence level for different class.	benchmark (computing);default;experiment;kerrison predictor;kolmogorov complexity;machine learning;radio frequency;random forest;randomness;resultant;transduction (machine learning);benefit	Fan Yang;Hua-zhen Wang;Hong Mi;Cheng-de Lin;Wei-wen Cai	2009	BMC Bioinformatics	10.1186/1471-2105-10-S1-S22	random forest;confidence interval;dna microarray;prediction;transduction;computer science;bioinformatics;data science;machine learning;medical diagnosis;data mining;algorithm	ML	10.505169726689527	-47.839911720639705	33911
02de2695dd00d44093a73c11240b758349189de4	rough extreme learning machine: a new classification method based on uncertainty measure		Extreme learning machine (ELM) is a new single hidden layer feedback neural network. The weights of the input layer and the biases of neurons in hidden layer are randomly generated; the weights of the output layer can be analytically determined. ELM has been achieved good results for a large number of classification tasks. In this paper, a new extreme learning machine called rough extreme learning machine (RELM) was proposed. RELM uses rough set to divide data into upper approximation set and lower approximation set, and the two approximation sets are utilized to train upper approximation neurons and lower approximation neurons. In addition, an attribute reduction is executed in this algorithm to remove redundant attributes. The experimental results showed, comparing with the comparison algorithms, RELM can get a better accuracy and repeatability in most cases; RELM can not only maintain the advantages of fast speed, but also effectively cope with the classification task for high-dimensional data.		Lin Feng;Shuliang Xu;Feilong Wang;Shenglan Liu;Hong Qiao	2019	Neurocomputing	10.1016/j.neucom.2018.09.062	machine learning;extreme learning machine;artificial intelligence;artificial neural network;rough set;mathematics;data set;pattern recognition	AI	15.008086590301232	-31.681211314391486	33917
b9c0994aa9a15dda83efc7d0910645b1e6903e32	bfl: a node and edge betweenness based fast layout algorithm for large scale networks	metabolic networks and pathways;computer graphics;network visualization;gene network;computational biology bioinformatics;large scale;graph layout;algorithms;pattern recognition automated;subcellular localization;user computer interface;network flow;combinatorial libraries;optimal algorithm;computer appl in life sciences;microarrays;bioinformatics	Network visualization would serve as a useful first step for analysis. However, current graph layout algorithms for biological pathways are insensitive to biologically important information, e.g. subcellular localization, biological node and graph attributes, or/and not available for large scale networks, e.g. more than 10000 elements. To overcome these problems, we propose the use of a biologically important graph metric, betweenness, a measure of network flow. This metric is highly correlated with many biological phenomena such as lethality and clusters. We devise a new fast parallel algorithm calculating betweenness to minimize the preprocessing cost. Using this metric, we also invent a node and edge betweenness based fast layout algorithm (BFL). BFL places the high-betweenness nodes to optimal positions and allows the low-betweenness nodes to reach suboptimal positions. Furthermore, BFL reduces the runtime by combining a sequential insertion algorim with betweenness. For a graph with n nodes, this approach reduces the expected runtime of the algorithm to O(n2) when considering edge crossings, and to O(n log n) when considering only density and edge lengths. Our BFL algorithm is compared against fast graph layout algorithms and approaches requiring intensive optimizations. For gene networks, we show that our algorithm is faster than all layout algorithms tested while providing readability on par with intensive optimization algorithms. We achieve a 1.4 second runtime for a graph with 4000 nodes and 12000 edges on a standard desktop computer.	anatomic node;betweenness;cns disorder;clinical act of insertion;computation;computer cluster;degree (graph theory);desktop computer;distance (graph theory);edge dominating set;extraction;flow network;force-directed graph drawing;gml gene;gene regulatory network;graph (discrete mathematics);graph - visual representation;here document;image scaling;imagery;insertion mutation;linc;manuscripts;mathematical optimization;medical records systems, computerized;node - plant part;parallel algorithm;preprocessor;real-time clock;silo (dataset);test scaling;usb hub;ultima online;weatherstar;zip code;citation	Tatsunori B. Hashimoto;Masao Nagasaki;Kaname Kojima;Satoru Miyano	2008	BMC Bioinformatics	10.1186/1471-2105-10-19	biology;gene regulatory network;flow network;dna microarray;computer science;bioinformatics;theoretical computer science;machine learning;graph drawing;computer graphics	Visualization	0.6219237257626952	-49.531435365331056	33945
58d07cc2b885ed444042dc82a87c95b673630783	modus ponens versus modus tollens associated with rough gradual decision rules induced from a decision table	gradual decision rule;decision table;linear regression analysis;inference pattern;fuzzy logical connective;modifier function;rough gradual decision rule;modus tollens;modus ponens;fuzzy rough set approach;linear regression;computing;decision rule;business information systems	We have proposed a fuzzy rough set approach to induce gradual decision rules from decision tables without using any fuzzy logical connectives. In this paper, we discuss the use of these gradual decision rules within modus ponens and modus tollens inference patterns. We show differences and similarities between modus ponens and modus tollens through representation theorems of modifier functions characterizing the inference patterns. Moreover, we prove that modus ponens and modus tollens are equivalent under suitable monotonicity conditions. Finally, we conclude this paper with a comparison between the linear regression analysis and the proposed approach.	decision table	Masahiro Inuiguchi;Salvatore Greco;Roman Slowinski	2005	Int. J. Hybrid Intell. Syst.		decision table;constructive dilemma;computing;modus tollens;modus ponens;deduction theorem;computer science;linear regression;artificial intelligence;modus ponendo tollens;management information systems;data mining;decision rule;algorithm	AI	-1.9501373926987613	-25.576447389778696	33952
2516209cba1a8ca422134fbd1d7c41b162b082eb	information, divergence and risk for binary experiments	statistical machine learning;divergence;journal article;proper scoring rule;keywords classification;loss functions;fisher linear discriminant;roc curve;statistical information;binary classification;support vector machine;machinery;regret bounds;statistics classification	We unify f -divergences, Bregman divergences, surrogate regret bounds, proper scoring rules, cost curves, ROC-curves and statistical information. We do this by systematically studying integral and variational representations of these various objects and in so doing identify their primitives which all are related to cost-sensitive binary classification. As well as developing relationships between generative and discriminative views of learning, the new machinery leads to tight and more general surrogate regret bounds and generalised Pinsker inequalities relating f -divergences to variational divergence. The new viewpoint also illuminates existing algorithms: it provides a new derivation of Support Vector Machines in terms of divergences and relates Maximum Mean Discrepancy to Fisher Linear Discriminants.	algorithm;binary classification;bregman divergence;calculus of variations;convex function;discrepancy function;hoare logic;jensen's inequality;pinsker's inequality;receiver operating characteristic;support vector machine;variational principle	Mark D. Reid;Robert C. Williamson	2011	Journal of Machine Learning Research		binary classification;scoring rule;support vector machine;machine;computer science;machine learning;pattern recognition;mathematics;divergence;receiver operating characteristic;statistics	ML	21.213273727859445	-35.67298325751195	34003
672f0af71ad73732dbc54235fa7f4e3c975bc75e	the gene evolution model and computing its associated probabilities	gene loss;genetique;modelizacion;molecular phylogenies;proceso lineal;biogeografia;probability;algorithmique;phylogeny;loi probabilite;duplicacion genica;maximum likelihood;genetica;ley probabilidad;tree distributions;processus naissance mort;phylogenese;efficient algorithm;echantillonnage;dna sequences;orthologs;posterior probability;biology;biologia;probabilistic approach;signed permutations;gene trees;genetics;processus lineaire;gene duplication;sampling;modelisation;kemi;natural sciences;biogeographie;proceso nacimiento muerte;biogeography;algorithmics;linear process;algoritmica;enfoque probabilista;approche probabiliste;duplication;probability distribution;theory;filogenesis;genome;probabilite a posteriori;host parasite co evolution;probabilidad a posteriori;gene;incongruence;algorithms;duplication genique;species trees;biologiska vetenskaper;genoma;birth death process;biological sciences;muestreo;reconciliation;loss;modeling;chemical sciences;inference;biologie;evolution	Phylogeny is both a fundamental tool in biology and a rich source of fascinating modeling and algorithmic problems. Today's wealth of sequenced genomes makes it increasingly important to understand evolutionary events such as duplications, losses, transpositions, inversions, lateral transfers, and domain shuffling. We focus on the gene duplication event, that constitutes a major force in the creation of genes with new function [Ohno 1970; Lynch and Force 2000] and, thereby also, of biodiversity.  We introduce the probabilistic gene evolution model, which describes how a gene tree evolves within a given species tree with respect to speciation, gene duplication, and gene loss. The actual relation between gene tree and species tree is captured by a reconciliation, a concept which we generalize for more expressiveness. The model is a canonical generalization of the classical linear birth-death process, obtained by replacing the interval where the process takes place by a tree.  For the gene evolution model, we derive efficient algorithms for some associated probability distributions: the probability of a reconciled tree, the probability of a gene tree, the maximum probability reconciliation, the posterior probability of a reconciliation, and sampling reconciliations with respect to the posterior probability. These algorithms provides the basis for several applications, including species tree construction, reconciliation analysis, orthology analysis, biogeography, and host-parasite co-evolution.	algorithm;inversion (discrete mathematics);lateral computing;lateral thinking;phylogenetics;sampling (signal processing)	Lars Arvestad;Jens Lagergren;Bengt Sennblad	2009	J. ACM	10.1145/1502793.1502796	phylogenetic tree;bioinformatics;biogeography;tree rearrangement;mathematics;algorithmics;algorithm;gene duplication;statistics	Comp.	1.5116560895947546	-50.68551797284205	34055
54c40da9e530cca1d39bcb3b4149c257e0db21ef	a fast online learning algorithm for distributed mining of bigdata	analytics;big data;algorithms;tactical environment;cloud computing	BigData analytics require that distributed mining of numerous data streams is performed in real-time. Unique challenges associated with designing such distributed mining systems are: online adaptation to incoming data characteristics, online processing of large amounts of heterogeneous data, limited data access and communication capabilities between distributed learners, etc. We propose a general framework for distributed data mining and develop an efficient online learning algorithm based on this. Our framework consists of an ensemble learner and multiple local learners, which can only access different parts of the incoming data. By exploiting the correlations of the learning models among local learners, our proposed learning algorithms can optimize the prediction accuracy while requiring significantly less information exchange and computational complexity than existing state-of-the-art learning solutions.	algorithm;big data;computational complexity theory;converge;data access;data mining;information exchange;machine learning;real-time locating system	Yu Zhang;Daby M. Sow;Deepak S. Turaga;Mihaela van der Schaar	2014	SIGMETRICS Performance Evaluation Review	10.1145/2627534.2627562	analytics;big data;cloud computing;computer science;data science;online machine learning;machine learning;data mining;data stream mining	ML	13.529509277525657	-37.562173800593406	34056
1cc370a5f9f803b5a3edef7534b958f182788293	transforming examples for multiclass boosting	decision tree;ensemble method;naive bayes;boosting;multiclass learning;ensemble methods;hamming loss;loss function;pseudoloss	AdaBoost.M2 and AdaBoost.MH are boosting algorithms for learning from multiclass datasets. They have received less attention than other boosting algorithms because they require base classifiers that can handle the pseudoloss or Hamming loss, respectively. The difficulty with these loss functions is that each example is associated with k weights, where k is the number of classes. We address this issue by transforming an m-example dataset with k weights/example into a dataset with km examples and one weight/example. Minimizing error on the transformed dataset is equivalent to minimizing loss on the original dataset. Resampling the transformed dataset can be used for time efficiency and base classifiers that cannot handle weighted examples. We empirically apply the transformation on several multiclass datasets using naive Bayes and decision trees as base classifiers. Our experiment shows that it is competitive with AdaBoost.ECC, a boosting algorithm using output coding.	adaboost;algorithm;boosting (machine learning);decision tree;hamming distance;loss function;modified huffman coding;multiclass classification;naive bayes classifier	Tom Bylander	2010	J. Exp. Theor. Artif. Intell.	10.1080/09528130902823680	naive bayes classifier;computer science;machine learning;decision tree;pattern recognition;data mining;ensemble learning;gradient boosting;boosting;loss function	ML	15.463723253053391	-41.02157358127658	34057
79baf48bd560060549998d7b61751286de062e2a	factorization tricks for lstm networks		We present two simple ways of reducing the number of parameters and accelerating the training of large Long Short-Term Memory (LSTM) networks: the first one is ”matrix factorization by design” of LSTM matrix into the product of two smaller matrices, and the second one is partitioning of LSTM matrix, its inputs and states into the independent groups. Both approaches allow us to train large LSTM networks significantly faster to the near state-of the art perplexity while using significantly less RNN parameters.	long short-term memory;perplexity;random neural network	Oleksii Kuchaiev;Boris Ginsburg	2017	CoRR		computer science;theoretical computer science;machine learning;algorithm	ML	21.105359359232427	-48.69645326670981	34067
1c3947b3d6a579ef924c42fd3335fdf8a2603692	the structural affinity method for solving the raven's progressive matrices test for intelligence		Graphical models offer techniques for capturing the structure of many problems in real-world domains and provide means for representation, interpretation, and inference. The modeling framework provides tools for discovering rules for solving problems by exploring structural relationships. We present the Structural Affinity method that uses graphical models for first learning and subsequently recognizing the pattern for solving problems on the Raven’s Progressive Matrices Test of general human intelligence. Recently there has been considerable work on computational models of addressing the Raven’s test using various representations ranging from fractals to symbolic structures. In contrast, our method uses Markov Random Fields parameterized by affinity factors to discover the structure in the geometric analogy problems and induce the rules of Carpenter et al.’s cognitive model of problem-solving on the Raven’s Progressive Matrices Test. We provide a computational account that first learns the structure of a Raven’s problem and then predicts the solution by computing the probability of the correct answer by recognizing patterns corresponding to Carpenter et al.’s rules. We demonstrate that the performance of our model on the Standard Raven Progressive Matrices is comparable with existing state of the art models.	affinity analysis;cognitive model;computation;computational model;fractal;graphical model;markov chain;markov random field;problem solving;processor affinity	Snejana Shegheva;Ashok K. Goel	2018			machine learning;artificial intelligence;raven's progressive matrices;computer science	AI	24.1969266960547	-27.243785182063043	34075
f4553716deac89e4849c40b941fcb24d0f737b56	on constructing and pruning svm ensembles	kernel;ensemble method;support vector machines;support vector machines kernel accuracy training tuning classification algorithms machine learning;training;svm ensemble;accuracy;ensemble;pruning;tuning;machine learning;pruning method svm ensemble support vector machine svm classifier kernel parameter;kernel parameter;svm classifier;classification algorithms;pattern classification;support vector machine;sampling methods;pruning support vector machine ensemble;support vector machines pattern classification;pruning method	This paper proposes an effective method for constructing and pruning support vector machine ensembles for improved classification performance. Firstly we propose a novel method for constructing SVM ensembles. Traditionally an SVM ensemble is constructed by the data sampling method; In our method, however,each individual SVM classifier is trained by using the same original training set, but with different kernel parameters.Compared to traditional SVM ensemble methods, our method need not to tune the kernel parameters for each individual SVM, thus the training of the SVM ensemble can be simplified considerably. Furthermore, we also propose several efficient method for pruning the constructed SVM ensembles. The proposed pruning methods cannot only simplify the SVM ensemble, but also improve its performance. A set of experiments were conducted to prove the efficiency and affectivity of our proposed approaches.	effective method;ensemble kalman filter;ensemble learning;experiment;kernel (operating system);neural ensemble;sampling (signal processing);statistical classification;support vector machine;test set	Bing-Yu Sun;Xiaoming Zhang;Rujing Wang	2007	2007 Third International IEEE Conference on Signal-Image Technologies and Internet-Based System	10.1109/SITIS.2007.19	statistical classification;support vector machine;computer science;machine learning;pattern recognition;data mining;ranking svm	Vision	13.081279932146078	-41.32369906837378	34114
7264697132611e9fac346efee7886342bab6bb2d	a probabilistic approach to latent cluster analysis	unsupervised learning;cluster ensemble;会议论文;latent cluster model	Facing a large number of clustering solutions, cluster ensemble method provides an effective approach to aggregating them into a better one. In this paper, we propose a novel cluster ensemble method from probabilistic perspective. It assumes that each clustering solution is generated from a latent cluster model, under the control of two probabilistic parameters. Thus, the cluster ensemble problem is reformulated into an optimization problem of maximum likelihood. An EM-style algorithm is designed to solve this problem. It can determine the number of clusters automatically. Experimenal results have shown that the proposed algorithm outperforms the state-of-the-art methods including EAC-AL, CSPA, HGPA, and MCLA. Furthermore, it has been shown that our algorithm is stable in the predicted numbers of clusters.	algorithm;cluster analysis;mathematical optimization;optimization problem	Zhipeng Xie;Rui Dong;Zhengheng Deng;Zhenying He;Weidong Yang	2013			unsupervised learning;k-medians clustering;computer science;machine learning;pattern recognition;data mining;mathematics	AI	20.580522823560333	-42.016220716922184	34145
a8af635e9b66a34daeef85af9b2c3bbf493763a1	online learning of portfolio ensembles with sector exposure regularization		We consider online learning of ensembles of portfolio selec tion algorithms and aim to regularize risk by encouraging diversification with r espect to a predefined risk-driven grouping of stocks. Our procedure uses online c onvex optimization to control capital allocation to underlying investment alg orithms while encouraging non-sparsity over the given grouping. We prove a logarit hm c regret for this procedure with respect to the best-in-hindsight ensemble. W applied the procedure with known mean-reversion portfolio selection algori thms using the standard GICS industry sector grouping. Empirical Experimental res ults showed an impressive percentage increase of risk-adjusted return (Sharpe r tio).	algorithm;data compression ratio;diversification (finance);manifold regularization;mathematical optimization;matrix regularization;newton;real life;regret (decision theory);relative change and difference;reversion (software development);sparse matrix	Guy Uziel;Ran El-Yaniv	2016	CoRR		mathematical optimization;machine learning;statistics	ML	22.528968280518225	-36.20590320698296	34167
371a1e185055dbe385ce03378efb417c316884a1	chemical boltzmann machines		How smart can a micron-sized bag of chemicals be? How can an artificial or real cell make inferences about its environment? From which kinds of probability distributions can chemical reaction networks sample? We begin tackling these questions by showing four ways in which a stochastic chemical reaction network can implement a Boltzmann machine, a stochastic neural network model that can generate a wide range of probability distributions and compute conditional probabilities. The resulting models, and the associated theorems, provide a road map for constructing chemical reaction networks that exploit their native stochasticity as a computational resource. Finally, to show the potential of our models, we simulate a chemical Boltzmann machine to classify and generate MNIST digits in-silico.	artificial neural network;boltzmann machine;chemical reaction network theory;computational resource;mnist database;network model;simulation;stochastic neural network;stochastic process	William Poole;Andrés Ortiz-Muñoz;Abhishek Behera;Nick S. Jones;Thomas E. Ouldridge;Erik Winfree;Manoj Gopalkrishnan	2017		10.1007/978-3-319-66799-7_14	boltzmann constant;machine learning;probability distribution;boltzmann machine;computational resource;stochastic neural network;conditional probability;exploit;mnist database;artificial intelligence;mathematics	ML	24.51439358415451	-29.8853480291522	34182
c71c04552a4992f4994b97306d330ca29530d125	analysis of global k-means, an incremental heuristic for minimum sum-of-squares clustering	heuristique;classification automatique statistiques;analyse multivariable;somme carre munimum;computacion informatica;multivariate analysis;analisis datos;performance;k means;minimum sum of squares;moyenne j;moyenne k;global k means;data analysis;j mean;clustering;ciencias basicas y experimentales;matematicas;sum of squares;j means;analisis multivariable;analyse donnee;k mean;moyenne k globale;rendimiento;cluster analysis statistics;grupo a;global k mean	The global k-means heuristic is a recently proposed (Likas, Vlassis and Verbeek, 2003) incremental approach for minimum sum-of-squares clustering of a set X of N points of R d  into M clusters. For k = 2,3,.... M - 1 it considers the best-known set of k - 1 centroids previously obtained, adds a new cluster center at each point of X in turn and applies k-means to each set of k centroids so-obtained, keeping the best k-partition found. We show that global k-means cannot be guaranteed to find the optimum partition for any M ≥ 2 and d > 1; moreover, the same holds for all M > 3 if the new cluster center is chosen anywhere in R d  instead of belonging to X. The empirical performance of global k-means is also evaluated by comparing the values it obtains with those obtained for three data sets with N < 150 which are solved optimally, as well as with values obtained by the recent j-means heuristic and extensions thereof for three larger data sets with N ≤ 3038.	heuristic;k-means clustering	Pierre Hansen;Eric W. T. Ngai;Bernard K.-S. Cheung;Nenad Mladenovic	2005	J. Classification	10.1007/s00357-005-0018-3	computer science;machine learning;calculus;mathematics;algorithm;statistics;k-means clustering	AI	3.5414807779402424	-37.61841926727138	34225
1531178873510075121efe26dc377f63b02b3d5d	adversarial examples for malware detection		Machine learning models are known to lack robustness against inputs crafted by an adversary. Such adversarial examples can, for instance, be derived from regular inputs by introducing minor—yet carefully selected—perturbations. In this work, we expand on existing adversarial example crafting algorithms to construct a highly-effective attack that uses adversarial examples against malware detection models.To this end, we identify and overcome key challenges that prevent existing algorithms from being applied against malware detection: our approach operates in discrete and often binary input domains, whereas previous work operated only in continuous and differentiable domains. In addition, our technique guarantees the malware functionality of the adversarially manipulated program. In our evaluation, we train a neural network for malware detection on the DREBIN data set and achieve classification performance matching stateof-the-art from the literature. Using the augmented adversarial crafting algorithm we then manage to mislead this classifier for 63% of all malware samples. We also present a detailed evaluation of defensive mechanisms previously introduced in the computer vision contexts, including distillation and adversarial training, which show promising results.	adversary (cryptography);algorithm;artificial neural network;computer vision;machine learning;malware;perturbation theory	Kathrin Grosse;Nicolas Papernot;Praveen Manoharan;Michael Backes;Patrick D. McDaniel	2017		10.1007/978-3-319-66399-9_4	computer security;robustness (computer science);malware;distributed computing;computer science;adversary;adversarial system	Security	18.902365606881116	-51.220095931807	34345
f97aaaeb70bb19b651f40b4b4c97cbe769f31d7e	remembering similitude terms in cbr	raisonnement base sur cas;razonamiento fundado sobre caso;apprentissage inductif;reutilizacion;apprentissage conceptuel;intelligence artificielle;reuse;lazy learning;aprendizaje conceptual;aprendizaje por induccion;inductive learning;concept learning;artificial intelligence;inteligencia artificial;case based reasoning;reutilisation;problem solving	In concept learning, inductive techniques perform a global approximation to the target concept. Instead, lazy learning techniques use local approximations to form an implicit global approximation of the target concept. In this paper we present C-LID, a lazy learning technique that uses LID for generating local approximations to the target concept. LID generates local approximations in the form of similitude terms (symbolic descriptions of what is shared by 2 or more cases). C-LID caches and reuses the similitude terms generated in past cases to improve the problem solving of future problems. The outcome of C-LID (and LID) is assessed with experiments on the Toxicology dataset.	approximation;case-based reasoning;concept learning;experiment;lazy evaluation;lazy learning;problem solving	Eva Armengol;Enric Plaza	2003		10.1007/3-540-45065-3_11	case-based reasoning;concept learning;computer science;artificial intelligence;machine learning;reuse;mathematics;algorithm	ML	8.210689246482653	-31.805776786016136	34350
0b2f2740d7d4b6783f7dab0b32eb49988c717cdc	a new ensemble learning methodology based on hybridization of classifier ensemble selection approaches	classifier combination;dynamic ensemble selection;multi objective optimization;static ensemble selection;classifier diversity;ensemble learning system	Proposing a new hybrid approach for ensemble learning systems that exploits the abilities of static ensemble selection (SES) and dynamic ensemble selection (DES) strategies.Presenting an SES approach based on NSGAII multi-objective genetic algorithm.Improving one of the DES approaches by utilizing the SES proposed method.Justifying the performance of the proposed methods by UCI repository and LKC datasets. Ensemble learning is a system that improves the performance and robustness of the classification problems. How to combine the outputs of base classifiers is one of the fundamental challenges in ensemble learning systems. In this paper, an optimized Static Ensemble Selection (SES) approach is first proposed on the basis of NSGA-II multi-objective genetic algorithm (called SES-NSGAII), which selects the best classifiers along with their combiner, by simultaneous optimization of error and diversity objectives. In the second phase, the Dynamic Ensemble Selection-Performance (DES-P) is improved by utilizing the first proposed method. The second proposed method is a hybrid methodology that exploits the abilities of both SES and DES approaches and is named Improved DES-P (IDES-P). Accordingly, combining static and dynamic ensemble strategies as well as utilizing NSGA-II are the main contributions of this research. Findings of the present study confirm that the proposed methods outperform the other ensemble approaches over 14 datasets in terms of classification accuracy. Furthermore, the experimental results are described from the view point of Pareto front with the aim of illustrating the relationship between diversity and the over-fitting problem.		Reza Mousavi;Mahdi Eftekhari	2015	Appl. Soft Comput.	10.1016/j.asoc.2015.09.009	mathematical optimization;computer science;multi-objective optimization;machine learning;pattern recognition;data mining;ensemble learning	ECom	10.008480359263602	-42.52628431394805	34360
c2d62cefdb1d069529f4f10399be5e8d339e6c88	a framework for similarity search of time series cliques with natural relations	databases;database management systems;information retrieval;multiple time series;time series;data analysts similarity search time series cliques natural relations time series retrieval tsc database tsc data compact representation multidimensional relation vector similarity measure;journal;natural relation;data analysis;trajectory;spatial relation;compact representation;time series analysis;time series analysis databases trajectory principal component analysis games search problems algorithm design and analysis;data structures;principal component analysis;games;similarity search time series clique natural relation compact representation;search problems;time series clique;synthetic data;similarity measure;algorithm design;algorithm design and analysis;similarity search;time series data analysis data structures database management systems information retrieval	A Time Series Clique (TSC) consists of multiple time series which are related to each other by natural relations. The natural relations that are found between the time series depend on the application domains. For example, a TSC can consist of time series which are trajectories in video that have spatial relations. In conventional time series retrieval, such natural relations between the time series are not considered. In this paper, we formalize the problem of similarity search over a TSC database. We develop a novel framework for efficient similarity search on TSC data. The framework addresses the following issues. First, it provides a compact representation for TSC data. Second, it uses a multidimensional relation vector to capture the natural relations between the multiple time series in a TSC. Lastly, the framework defines a novel similarity measure that uses the compact representation and the relation vector. We conduct an extensive performance study, using both real-life and synthetic data sets. From the performance study, we show that our proposed framework is both effective and efficient for TSC retrieval.	clique (graph theory);object-based language;real life;remote desktop services;search problem;similarity measure;similarity search;synthetic data;synthetic intelligence;time stamp counter;time series	Bin Cui;Zhe Zhao;Wee Hyong Tok	2012	IEEE Transactions on Knowledge and Data Engineering	10.1109/TKDE.2010.270	algorithm design;data structure;computer science;theoretical computer science;machine learning;time series;data mining;database;mathematics;statistics	DB	-3.9236792991468477	-41.98889945418021	34407
4f2c68282b8d26e6bfaf779f83196d4cc406e1ec	combining multiple classifiers in probabilistic neural networks	bayes estimation;reseau probabiliste;bayesian classifier;information loss;analisis estadistico;image processing;aproximacion;multiple solution;procesamiento imagen;clasificador;posterior probability;probabilistic approach;traitement image;approximation;multiple classifiers;estimacion bayes;classifier;reconnaissance caractere;red multinivel;probabilistic net;statistical analysis;enfoque probabilista;approche probabiliste;probabilite a posteriori;analyse statistique;statistical pattern recognition;probabilidad a posteriori;pattern recognition;classificateur;reconnaissance forme;multilayer network;reseau multicouche;reseau neuronal;reconocimiento patron;probabilistic neural network;character recognition;red neuronal;reconocimiento caracter;estimation bayes;neural network	We first summarize main features of a new probabilistic approach to neural networks recently developed in a series of papers in the framework of statistical pattern recognition. We consider a simplifying binary approximation of the output variables and, in order to prevent the arising information loss, we propose to combine multiple solutions. However, instead of combining different a posteriori probabilities, we make a parallel use of the binary output vectors to compute the standard Bayesian classifier.	neural networks	Jirí Grim;Josef Kittler;Pavel Pudil;Petr Somol	2000		10.1007/3-540-45014-9_15	probabilistic neural network;naive bayes classifier;classifier;image processing;computer science;machine learning;approximation;pattern recognition;posterior probability;artificial neural network;statistics	ML	11.102375506249727	-33.359228072816876	34423
56417c43a231226a4658ae5588de14caeac738f6	construction cosine radial basic function neural networks based on artificial immune networks	learning process;anomaly detection;intrusion detection;gradient descent;rbf neural network;intrusion detection algorithm;network algorithm;multiple granularities immune network;neural network	In this paper, we propose a novel Intrusion Detection algorithm utilizing both Artificial Immune Network and RBF neural network. The proposed anomaly detection method using multiple granularities artificial immune network algorithm to get the candidate hidden neurons firstly, and then, we training a cosine RBF neural network base on gradient descent learning process. The principle interest of this work is to benchmark the performance of the proposed algorithm by using KDD Cup 99 Data Set, the benchmark dataset used by IDS researchers. It is observed that the proposed approach gives better performance over some traditional approaches.	neural networks;radial (radio)	YongJin Zeng;Jiandong Zhuang	2010		10.1007/978-3-642-17313-4_13	gradient descent;intrusion detection system;anomaly detection;probabilistic neural network;computer science;artificial intelligence;machine learning;data mining;time delay neural network	ML	7.52302816286774	-36.543898722707986	34469
a518f0aa170e267206a1c1045b30a3d7be857758	latent semantic indexing with a variable number of orthogonal factors	text mining;information retrieval;singular value decomposition;number of factors;latent semantic indexing;numerical experiment;query expansion;latent semantic analysis	We seek insight into Latent Semantic Indexing by establishing a method to identify the optimal number of factors in the approximation matrix. We define some reasonable property for the approximation to hold and derive a new, un-parametric query expansion method. Extensive numerical experiments confirm the value of the new method.	approximation;experiment;numerical analysis;query expansion;singular value decomposition	Georges Dupret	2004			latent semantic indexing;latent semantic analysis;document-term matrix;pattern recognition;data mining;mathematics;probabilistic latent semantic analysis;information retrieval	DB	-4.090198327754578	-44.3888955397478	34492
8da968cfb8e41331a7385b3367c464e5706e0111	application of artificial neural networks in particle physics	feed forward;chip;function approximation;particle physics;pattern recognition;hardware implementation;artificial neural network	The application of artificial neural networks in particle physics is reviewed. The use of feed-forward nets is most common for event classification and function approximation. This network type is best suited for a hardware implementation and special VLSI chips are available which are used in fast trigger processors. Also discussed are fully connected networks of the Hopfield type for pattern recognition in tracking detectors.	approximation;artificial intelligence;artificial neural network;central processing unit;experiment;hopfield network;neural networks;parallel algorithm;parallel computing;pattern recognition;petri net;sensor;very-large-scale integration	Hermann Kolanoski	1996		10.1007/3-540-61510-5_1	chip;function approximation;computer science;artificial intelligence;theoretical computer science;machine learning;physical neural network;time delay neural network;feed forward;artificial neural network	ML	13.747860917264461	-26.775526394672486	34524
00a517d096f302cc74a5a398a349c82119fc3741	privacy-preserving mechanisms for k-modes clustering		Abstract Clustering categorical data is an important data mining task with rich applications. As an extension of k-means applied to categorical data, the k-modes algorithm became a popular clustering tool due to its simplicity and efficiency. A lot of improvements for k-modes such as better initialization techniques or more effective dissimilarity scores have been proposed recently. However, the problem of running the k-modes in private manners is rarely considered. In this paper, we address the privacy-preserving k-modes problem using differential privacy, a formal and rigorous definition of privacy for data publication. Differential privacy guarantees that the existence of any item in the input dataset is indistinguishable by looking at the computation output. We analyze the challenges of differentially private k-modes with regard to the k-means counterpart. Then we propose several schemes in both interactive and non-interactive settings. We prove that our mechanisms satisfy differential privacy and run linearly in the number of data points. Evaluation over fifteen real datasets shows that we can achieve useful privacy-preserving clustering outputs. In terms of clustering cost, the interactive approaches perform better than the non-interactive schemes and the solution adapted from k-means.		Huu Hiep Nguyen	2018	Computers & Security	10.1016/j.cose.2018.06.003	differential privacy;internet privacy;categorical variable;initialization;cluster analysis;data mining;data point;computation;computer science	Crypto	0.23180086647739176	-38.228767950733484	34608
9db5b659cfb087442f933b4fa71ea297aff1f275	collective information-theoretic competitive learning: emergency of improved performance by collectively treated neurons	competition;competitividad;living system;information content;competitive learning;collective distance;emergency;emergent properties;urgencia;collective learning;competitiveness;systeme vivant;urgence;mutual information maximization;mutual information;theorie information;reseau neuronal;sistema viviente;competitivite;information theoretic;apprentissage collectif;generalization;red neuronal;aprendizaje colectivo;information theory;neural network;teoria informacion	In this paper, we try to show that the simple collection of competitive units can show some emergent property such as improved generalization performance. We have so far defined information-theoretic competitive learning with respect to individual competitive units. As information is increased, one competitive unit tends to win the competition. This means that competitive learning can be described as a process of information maximization. However, in living systems, a large number of neurons behave collectively. Thus, it is urgently needed to introduce collective property in information-theoretic competitive learning. In this context, we try to treat several competitive units as one unit, that is, one collective unit. Then, we try to maximize information content not in individual competitive units but in collective competitive units. We applied the method to an artificial data and cabinet approval rating estimation. In all cases, we successfully demonstrated that improved generalization could be obtained.	competitive learning;information theory	Ryotaro Kamimura;Fumihiko Yoshida;Ryozo Kitajima	2006		10.1007/11893028_70	generalization;simulation;competition;self-information;information theory;emergency;computer science;artificial intelligence;machine learning;mutual information;competitive learning;artificial neural network;statistics;emergence	ML	15.53234311112054	-32.208516092489276	34612
590adf58c0df2a4b49433a3612b956cd2ed296cf	supermic: analyzing large biological datasets in bioinformatics with maximal information coefficient	microwave integrated circuits algorithm design and analysis bioinformatics biology mutual information acceleration clustering algorithms;mapreduce bioinformatics large biological datasets mic	The maximal information coefficient MIC has been proposed to discover relationships and associations between pairs of variables. It poses significant challenges for bioinformatics scientists to accelerate the MIC calculation, especially in genome sequencing and biological annotations. In this paper, we explore a parallel approach which uses MapReduce framework to improve the computing efficiency and throughput of the MIC computation. The acceleration system includes biological data storage on HDFS, preprocessing algorithms, distributed memory cache mechanism, and the partition of MapReduce jobs. Based on the acceleration approach, we extend the traditional two-variable algorithm to multiple variables algorithm. The experimental results show that our parallel solution provides a linear speedup comparing with original algorithm without affecting the correctness and sensitivity.	algorithm;apache hadoop;bioinformatics;cache;computation (action);computer data storage;correctness (computer science);distributed memory;mapreduce;maximal information coefficient;mental association;numerous;occupations;preprocessor;scalability;sensor;speedup;throughput;whole genome sequencing	Chao Wang;Dong Dai;Xi Li;Aili Wang;Xuehai Zhou	2017	IEEE/ACM Transactions on Computational Biology and Bioinformatics	10.1109/TCBB.2016.2550430	machine learning;theoretical computer science;artificial intelligence;cluster analysis;distributed memory;algorithm design;correctness;biological data;mutual information;speedup;computer science;bioinformatics;maximal information coefficient	HPC	-2.132154785169982	-51.46429193677604	34641
f41db5affbce7076a1d79f5d7812edd9df490c3b	an empirical comparison of machine learning techniques in predicting the bug severity of open and closed source projects	bug severity;bug repositories;text mining;supervised classification;10 fold cross validation;multiclass classification	Bug severity is the degree of impact that a defect has on the development or operation of a component or system, and can be classified into different levels based on their impact on the system. Identification of severity level can be useful for bug triager in allocating the bug to the concerned bug fixer. Various researchers have attempted text mining techniques in predicting the severity of bugs, detection of duplicate bug reports and assignment of bugs to suitable fixer for its fix. In this paper, an attempt has been made to compare the performance of different machine learning techniques namely Support vector machine (SVM), probability based Naïve Bayes (NB), Decision Tree based J48 (A Java implementation of C4.5), rule based Repeated Incremental Pruning to Produce Error Reduction (RIPPER) and Random Forests (RF) learners in predicting the severity level (1 to 5) of a reported bug by analyzing the summary or short description of the bug reports. The bug report data has been taken from NASA’s PITS (Projects and Issue Tracking System) datasets as closed source and components of Eclipse, Mozilla & GNOME datasets as open source projects. The analysis has been carried out in RapidMiner and STATISTICA data mining tools. The authors measured the performance of different machine learning techniques by considering (i) the value of accuracy and F-Measure for all severity level and (ii) number of best cases at different threshold level of accuracy and F-Measure. An Empirical Comparison of Machine Learning Techniques in Predicting the Bug Severity of Open and Closed Source Projects	bug tracking system;c4.5 algorithm;data mining;decision tree;eclipse;f1 score;issue tracking system;java;machine learning;naive bayes classifier;open-source software;radio frequency;random forest;rapidminer;software bug;statistica;support vector machine;text mining	K. K. Chaturvedi;V. B. Singh	2012	IJOSSP	10.4018/jossp.2012040103	text mining;computer science;machine learning;multiclass classification;pattern recognition;data mining;software regression;world wide web	SE	6.837304118207858	-40.320545932008486	34656
40415fcd4ba53edc01cd907a617c19a5923cdc43	feature extraction in protein sequences classification: a new stability measure	reliability;sensibility;classification of protein sequences;motif stability;motif extraction feature extraction;stable motif interest	Feature extraction is an unavoidable task, especially in the critical step of preprocessing biological sequences. This step consists for example in transforming the biological sequences into vectors of motifs where each motif is a subsequence that can be seen as a property (or attribute) characterizing the sequence. Hence, we obtain an object-property table where objects are sequences and properties are motifs extracted from sequences. This output can be used to apply standard machine learning tools to perform data mining tasks such as classification. Several previous works have described feature extraction methods for bio-sequence classification, but none of them discussed the robustness of these methods when perturbing the input data. In this work, we introduce the notion of stability of the generated motifs in order to study the robustness of motif extraction methods. We express this robustness in terms of the ability of the method to reveal any change occurring in the input data and also its ability to target the interesting motifs. We use these criteria to evaluate and experimentally compare four existing extraction methods for biological sequences.	british informatics olympiad;data mining;experiment;feature extraction;machine learning;motif;peptide sequence;preprocessor	Rabie Saidi;Sabeur Aridhi;Engelbert Mephu Nguifo;Mondher Maddouri	2012		10.1145/2382936.2383060	bioinformatics;pattern recognition;data mining;reliability;mathematics;statistics	ML	9.927372553882527	-51.8772994026964	34680
c75705f6a7b7b0d3328b996208a2473f8fecc8b7	on exploiting hierarchical label structure with pairwise classifiers	hierarchical class structure;training set;additional information;regular pairwise classifier;hierarchical label structure;class hierarchy	The goal of this work was to test whether the performance of a regular pairwise classifier can be improved when additional information about the hierarchical class structure is added to the training sets. Somewhat surprisingly, the additional information seems to hurt the performance. We explain this with the fact that the structure of the class hierarchy is not reflected in the distribution of the instances.	class hierarchy;naive bayes classifier	Johannes Fürnkranz;Jan Frederik Sima	2010	SIGKDD Explorations	10.1145/1964897.1964903	machine learning;pattern recognition;data mining	Theory	15.596627156889406	-40.33427586072926	34682
8e223302d0d879c3ba5cfc63e78187c76b4ef5ef	can a fuzzy rule extraction find an extremely tiny non-self region?	fuzzy rules	This paper reports one snapshot of our on-going experiments in which a common target we call a-tiny-island-in-a-huge-lakeis explored with different methods ranging from a data-mining technique to an artificial immune system. Our implicit interest is a network intrusion detection where we usually do not know what does an illegal transaction pattern look like until it completed intrusion when it was too late. Hence our first interest is (i) if it is possible to train the intrusion detection systemonly using legal patterns. From this context we assume data floating in thelakeare normal while ones found on the island is abnormal. Our second concern is then (ii) to study the limit of the size of the detectable area, that is, until what size can the detector detect it when we decrease the size of the island shrinking to zero, which is sometimes called a-needle-in-a-haystack. In this paper, a fuzzy rule extraction implemented by a neural network architecture is employed for the purpose.	artificial immune system;artificial neural network;data mining;experiment;fuzzy rule;intrusion detection system;network architecture;rule induction;snapshot (computer storage)	Akira Imada	2005			defuzzification;artificial intelligence;fuzzy number;data mining;fuzzy associative matrix;fuzzy set operations	ML	4.988344008996302	-37.079915318552814	34684
e528b54bce5134f3e304e19270851be25aa8cdd6	concurrent asynchronous learning algorithms for massively parallel recurrent neural networks	parallelisme;distributed system;systeme reparti;asynchronous learning;learning;aprendizaje;apprentissage;parallelism;sistema repartido;paralelismo;reseau neuronal recurrent;recurrent neural network;reseau neuronal;red neuronal;neural network	Abstract   Synchronism is a critical issue in the implementation of massively parallel neural networks. Typically, there is no global synchronism in a biological neural system. It is important, therefore, to develop a model for massively parallel neural networks to mimic the asynchronism of a biological neural system. In this paper, a mathematical basis for a concurrent, asynchronous relaxation method for parallel learning of recurrent neural networks is proposed. The condition for this asynchronous relaxation learning method to converge in multiprocessor systems is developed on the basis of partially asynchronous gradient descent optimization theory. We have successfully implemented this parallel asynchronous learning algorithm of recurrent neural networks on a CRAY X-MP using Macrotasking and an iPSC/2 using asynchronous communication. The recurrent neural network is trained to learn the behavior of a class of aperiodic or chaotic nonlinear delay-differential equations by Mackey and Glass. Speedup of the asynchronous algorithm vs the synchronous algorithm is achieved.	algorithm;neural network software;recurrent neural network	Chwan-Hwa John Wu;Jyun-Hwei Tsai	1992	J. Parallel Distrib. Comput.	10.1016/0743-7315(92)90073-V	parallel computing;types of artificial neural networks;computer science;recurrent neural network;theoretical computer science;machine learning;time delay neural network;distributed computing;deep learning;artificial neural network	HPC	17.298978446888256	-26.69537614777685	34712
6d09558cf522944209d091f11358cc94861adf76	fuzzy clustering based on α-divergence for spherical data and for categorical multivariate data	machine learning algorithms;atmospheric measurements;particle measurements;clustering algorithms optimization entropy clustering methods atmospheric measurements particle measurements machine learning algorithms;clustering algorithms;optimization;entropy;clustering methods	This paper presents two clustering algorithms based on α-divergence between memberships and variables that control cluster sizes: one is for spherical data and the other for categorical multivariate data. First, this paper shows that a conventional method for vectorial data can be interpreted as the regularization of another conventional method with α-divergence. Second, with this interpretation, a spherical clustering algorithm based on α-divergence is derived from an optimization problem built by regularizing a conventional method with α-divergence. Third, this paper connects the facts that the α-divergence is a generalization of Kullback-Leibler (KL)-divergence, and that three conventional co-clustering methods are based on KL-divergence. Based on these facts, a co-clustering algorithm based on α-divergence is derived from an optimization problem built by extending the KL-divergence in conventional methods to α-divergence. This paper also demonstrates some numerical examples for the proposed methods.	algorithm;biclustering;categorical variable;cluster analysis;document;emoticon;fuzzy clustering;kl-one;kernel method;kullback–leibler divergence;mathematical optimization;nonlinear system;numerical analysis;numerical method;optimization problem	Yuchi Kanzawa	2015	2015 IEEE International Conference on Fuzzy Systems (FUZZ-IEEE)	10.1109/FUZZ-IEEE.2015.7337853	correlation clustering;entropy;data stream clustering;k-medians clustering;fuzzy clustering;flame clustering;computer science;canopy clustering algorithm;machine learning;consensus clustering;pattern recognition;cure data clustering algorithm;data mining;mathematics;cluster analysis;brown clustering;biclustering;statistics;clustering high-dimensional data	Visualization	3.2580278167204373	-39.6261261035278	34753
20e2d7f8edc73b767117f844309cd433993c2213	improving anns performance on unbalanced data with an auc-based learning algorithm	unbalanced datasets;area under the roc curve;classification;parameter estimation criteria	This paper investigates the use of the Area Under the ROC Curve (AUC) as an alternative criteria for model selection in classification problems with unbalanced datasets. A novel algorithm, named here as AUCMLP, which incorporates AUC optimization into the Multi-layer Perceptron (MLPs) learning process is presented. The basic principle of AUCMLP is the solution of an optimization problem that aims at ranking quality as well as the separability of class distributions with respect to the threshold decision. Preliminary results achieved on real data, point out that our approach is promising, and can lead to better decision surfaces, specially under more severe unbalance conditions.	algorithm;unbalanced circuit	Cristiano Leite Castro;Antônio de Pádua Braga	2012		10.1007/978-3-642-33266-1_39	biological classification;computer science;machine learning;pattern recognition;data mining;statistics	ML	12.304846712436307	-41.60915884225092	34780
539a7d66c4b0765eb467406233e535cd22ed2a1b	approximation algorithms for k-modes clustering	k-modes objective function;main contribution;empirical result;deterministic algorithm;approximation factor;k-modes clustering;categorical data;distance measure;approximation algorithm;natural formulation;metric k-median	In this paper, we study clustering with respect to the k-modes objective function, a natural formulation of clustering for categorical data. One of the main contributions of this paper is to establish the connection between kmodes and k-median, i.e., the optimum of k-median is at most the twice the optimum of k-modes for the same categorical data clustering problem. Based on this observation, we derive a deterministic algorithm that achieves an approximation factor of 2. Furthermore, we prove that the distance measure in k-modes defines a metric. Hence, we are able to extend existing approximation algorithms for metric k-median to k-modes. Empirical results verify the superiority of our method.	approximation algorithm;categorical variable;cluster analysis;deterministic algorithm;loss function;optimization problem	Zengyou He	2006		10.1007/11816171_38	correlation clustering;constrained clustering;mathematical optimization;data stream clustering;categorical variable;metric;k-medians clustering;fuzzy clustering;biological classification;flame clustering;computer science;artificial intelligence;canopy clustering algorithm;machine learning;cure data clustering algorithm;mathematics;cluster analysis;approximation algorithm;algorithm;clustering high-dimensional data	ML	3.462711282862581	-37.84504142018595	34791
b1e4660c82951ba19a861afc8be5cf56cc46aaa8	cost-sensitive boosting for classification of imbalanced data	modelizacion;evaluation performance;learning algorithm;performance evaluation;learning;imbalanced data;evaluacion prestacion;weighting;class imbalance;algorithme apprentissage;ponderacion;classification;aprendizaje;modelisation;minimizacion costo;accuracy;apprentissage;boosting;precision;minimisation cout;cost minimization;doctoral thesis;signal classification;adaboost;classification signal;ponderation;cost sensitive learning;classification automatique;classification accuracy;automatic classification;algoritmo aprendizaje;modeling;clasificacion automatica;class imbalance problem	Classification of data with imbalanced class distribution has posed a significant drawback of the performance attainable by most standard classifier learning algorithms, which assume a relatively balanced class distribution and equal misclassification costs. The significant difficulty and frequent occurrence of the class imbalance problem indicate the need for extra research efforts. The objective of this paper is to investigate meta-techniques applicable to most classifier learning algorithms, with the aim to advance the classification of imbalanced data. The AdaBoost algorithm is reported as a successful meta-technique for improving classification accuracy. The insight gained from a comprehensive analysis of the AdaBoost algorithm in terms of its advantages and shortcomings in tacking the class imbalance problem leads to the exploration of three cost-sensitive boosting algorithms, which are developed by introducing cost items into the learning framework of AdaBoost. Further analysis shows that one of the proposed algorithms tallies with the stagewise additive modelling in statistics to minimize the cost exponential loss. These boosting algorithms are also studied with respect to their weighting strategies towards different types of samples, and their effectiveness in identifying rare cases through experiments on several real world medical data sets, where the class imbalance problem prevails. 2007 Pattern Recognition Society. Published by Elsevier Ltd. All rights reserved.	adaboost;algorithm;experiment;machine learning;pattern recognition;time complexity;utility functions on indivisible goods	Yanmin Sun	2007	Pattern Recognition	10.1016/j.patcog.2007.04.009	adaboost;brownboost;computer science;machine learning;pattern recognition;data mining;mathematics;accuracy and precision;lpboost;statistics	ML	10.554345457984782	-35.04211846387778	34804
a0843d22bc4dc4100862b17d8b66b292111465de	an ensemble generation method based on instance hardness		In Machine Learning, ensemble methods have been receiving a great deal of attention. Techniques such as Bagging and Boosting have been successfully applied to a variety of problems. Nevertheless, such techniques are still susceptible to the effects of noise and outliers in the training data. We propose a new method for the generation of pools of classifiers based on Bagging, in which the probability of an instance being selected during the resampling process is inversely proportional to its instance hardness, which can be understood as the likelihood of an instance being misclassified, regardless of the choice of classifier. The goal of the proposed method is to remove noisy data without sacrificing the hard instances which are likely to be found on class boundaries. We evaluate the performance of the method in nineteen public data sets, and compare it to the performance of the Bagging and Random Subspace algorithms. Our experiments show that in high noise scenarios the accuracy of our method is significantly better than that of Bagging.	algorithm;boosting (machine learning);bootstrap aggregating;ensemble learning;experiment;image noise;information privacy;machine learning;signal-to-noise ratio	Felipe N. Walmsley;George D. C. Cavalcanti;Dayvid V. R. Oliveira;Rafael M. O. Cruz;Robert Sabourin	2018	2018 International Joint Conference on Neural Networks (IJCNN)	10.1109/IJCNN.2018.8489269	artificial intelligence;boosting (machine learning);machine learning;outlier;resampling;pattern recognition;noise measurement;classifier (linguistics);ensemble learning;subspace topology;computer science;data set	AI	14.758829442003412	-41.376412832034106	34806
378edfd969e3e69ba5923aa15de007f1f2f312f9	nonlinear online classificatand michion algorithm with probability margin		Usually, it is necessary for nonlinear online learning algorithms to store a set of misclassified observed examples for computing kernel values. For large-scale problems, this is not only time consuming but leads also to an out-of-memory problem. In the paper, a nonlinear online classification algorithm is proposed with a probability margin to address the problem. In particular, the discriminant function is defined by the Gaussian mixture model with the statistical information of all the observed examples instead of data points. Then, the learnt model is used to train a nonlinear online classification algorithm with confidence such that the corresponding margin is defined by probability. When doing so, the internal memory is significantly reduced while the classification performance is kept. Also, we prove mistake bounds in terms of the generative model. Experiments carried out on one synthesis and two real large-scale data sets validate the effectiveness of the proposed approach.	algorithm;computation;computer data storage;curse of dimensionality;data point;dimensionality reduction;discriminant;experiment;generative model;kernel (operating system);kernel perceptron;mixture model;nonlinear system;online machine learning;out of memory;statistical model;winnow (algorithm)	Mingmin Chi;Huijun He	2011			nonlinear system;machine learning;mathematical optimization;artificial intelligence;computer science	ML	19.688808737685466	-38.33837779844305	34808
a31882d28982858b558cf5baab19c05800d6f10d	elblocker: predicting blocking bugs with ensemble imbalance learning	ensemble learning;blocking bug;imbalance learning	http://dx.doi.org/10.1016/j.infsof.2014.12.006 0950-5849/ 2015 Elsevier B.V. All rights reserved. ⇑ Corresponding author. E-mail addresses: xxkidd@zju.edu.cn (X. Xia), davidlo@smu.edu.sg (D. Lo), eshihab@cse.concordia.ca (E. Shihab), wangxinyu@zju.edu.cn (X. Wang), yangxh@ zju.edu.cn (X. Yang). 1 In this paper, we use the terms ‘‘bug’’ or ‘‘bug report’’ interchangeabl refer to an issue report stored in a bug tracking system that is marked as a Xin Xia , David Lo , Emad Shihab , Xinyu Wang a,⇑, Xiaohu Yang a	blocking (computing);bug tracking system;software bug;yang	Xin Xia;David Lo;Emad Shihab;Xinyu Wang;Xiaohu Yang	2015	Information & Software Technology	10.1016/j.infsof.2014.12.006	real-time computing;computer science;machine learning;data mining;ensemble learning	AI	7.49567927089985	-40.42806031374004	34853
acc97f3b12d8762a9c095c5483bf280abc0198cb	the capacity of associative memories with malfunctioning neurons	tolerancia falta;hopfield model;neurone;modele hopfield;memoire associative;neurons associative memory biological neural networks fault tolerance asymptotic stability robustness computer networks humans state space methods distributed computing;modelo hopfield;defecto;neural networks fault tolerance malfunctioning neurons hopfield associative memories exchangeable events theory asymptotic storage capacity stability attractivity;hopfield neural nets;asymptotic behavior;comportement asymptotique;capacite stockage;capacidad memoria;hopfield neural nets content addressable storage fault tolerant computing;comportamiento asintotico;neurona;fault tolerant computing;capacite memoire;memory capacity;associative storage;capacidad almacenaje;storage capacity;defect;fault tolerance;defaut;memoria asociativa;reseau neuronal;content addressable storage;red neuronal;tolerance faute;neuron;neural network	Hopfield associative memories with alphan malfunctioning neurons are considered. Using some facts from exchangeable events theory, the asymptotic storage capacity of such a network is derived as a function of the parameter alpha under stability and attractivity requirements. It is shown that the asymptotic storage capacity is (1-alpha)(2)/n(4 log n) under stability and (1-alpha)(2)(1-2rho)(2)n/(4 log n) under attractivity requirements, respectively. Comparing these capacities with their maximum values corresponding to the case when there is no malfunctioning neurons, alpha=0, shows the robustness of the retrieval mechanism of Hopfield associative memories with respect to the existence of malfunctioning neurons. This result also supports the claim that neural networks are fault tolerant.	artificial neural network;fault tolerance;hopfield network;neural network simulation;neuron;neurons;population parameter;requirement	Mahdad Nouri Shirazi;Sadao Maekawa	1993	IEEE transactions on neural networks	10.1109/72.238317	fault tolerance;asymptotic analysis;computer science;artificial intelligence;machine learning;artificial neural network;algorithm	ML	18.475517080846544	-27.62550116451414	34938
736d044a522d238b7b6f4e091670f6e837ee438d	robust clustering of large data sets with categorial attributes			categorial grammar	Vladimir Estivill-Castro;Michael E. Houle	1999			database;computer science;data mining;cluster analysis;data set;cure data clustering algorithm	ML	2.0662117818363863	-41.00526435724766	35016
7af426948ed7fb4c46cb7826437979c45df9200f	biologically inspired incremental learning for high-dimensional spaces	transfer functions;self organising feature maps computational complexity covariance matrices graphics processing units learning artificial intelligence parallel processing pattern classification regression analysis;prototypes;parallel gpu implementation biologically inspired incremental learning high dimensional spaces highly parallelizable neural learning architecture constant time complexity neural learning architecture multiclass classification projection prediction architecture pro pre architecture biological information processing prototype based layer topologically organized hidden layer self organizing map learning som learning localized neural subpopulation weight catastrophic forgetting effect mlp input statistics readout layer linear regression transfer function nonlinear decision boundaries similarity approximation topological som projection property intercluster distance input space covariance matrices mnist handwritten digit benchmark;biological system modeling;linear regression;computer architecture;robots;prototypes linear regression computer architecture biological system modeling robots transfer functions	We propose an incremental, highly parallelizable, and constant-time complexity neural learning architecture for multi-class classification (and regression) problems that remains resource-efficient even when the number of input dimensions is very high (≥ 1000). This so-called projection-prediction (PRO-PRE) architecture is strongly inspired by biological information processing in that it uses a prototype-based, topologically organized hidden layer that updates hidden layer weights whenever an error occurs. The employed self-organizing map (SOM) learning adapts only the weights of localized neural sub-populations that are similar to the input, which explicitly avoids the catastrophic forgetting effect of MLPs in case new input statistics are presented. The readout layer applies linear regression to hidden layer activities subjected to a transfer function, making the whole system capable of representing strongly non-linear decision boundaries. The resource-efficiency of the algorithm stems from approximating similarity in the input space by proximity in the SOM layer due to the topological SOM projection property. This avoids the storage of inter-cluster distances (quadratic in number of hidden layer elements) or input space covariance matrices (quadratic in input dimensions) as other incremental algorithms typically do. Tests on the popular MNIST handwritten digit benchmark show that the algorithm compares favorably to state-of-the-art results, and parallelizability is demonstrated by analyzing the efficiency of a parallel GPU implementation of the architecture.	algorithm;analysis of algorithms;autonomous robot;benchmark (computing);catastrophic interference;dynamic problem (algorithms);graphics processing unit;image scaling;information processing;mnist database;machine learning;maximal set;merge sort;multiclass classification;nonlinear system;organizing (structure);parallel computing;population;prototype;self-organization;self-organizing map;time complexity;transfer function;uncontrolled format string	Alexander Gepperth;Thomas Hecht;Mathieu Lefort;Ursula Körner	2015	2015 Joint IEEE International Conference on Development and Learning and Epigenetic Robotics (ICDL-EpiRob)	10.1109/DEVLRN.2015.7346155	computer science;artificial intelligence;theoretical computer science;machine learning	ML	14.820857483150558	-31.968879558455814	35033
3bda106dd6e01caa80c59168b75cb951e4ee7b3b	using background knowledge to construct bayesian classifiers for data-poor domains	bayesian classifier;structural complexity;machine learning;probability distribution;background knowledge;classification accuracy;article in monograph or in proceedings	The development of Bayesian classifiers is frequently accomplished by means of algorithms which are highly data-driven. Often, however, sufficient data are not available, which may be compensated for by eliciting background knowledge from experts. This paper explores the trade-offs between modelling using background knowledge from domain experts and machine learning using a small clinical dataset in the context of Bayesian classifiers. We utilized background knowledge to improve Bayesian classifier performance, both in terms of classification accuracy and in terms of modelling the structure of the underlying joint probability distribution. Relative differences between models of differing structural complexity, which were learnt using varying amounts of background knowledge, are explored. It is shown that the use of partial background knowledge may significantly improve the quality of the resulting classifiers.	algorithm;bayesian network;kullback–leibler divergence;machine learning;model-driven architecture;model-driven engineering;model-driven integration;naive bayes classifier;structural complexity (applied mathematics)	Marcel van Gerven;Peter J. F. Lucas	2004		10.1007/1-84628-102-4_20	probability distribution;structural complexity;naive bayes classifier;variable-order bayesian network;computer science;machine learning;pattern recognition;data mining;bayesian statistics	AI	16.687147507889847	-37.19803958267114	35047
fdee0ff1443f96f846406fdf92f2ff9e8f7d665b	cluster ensemble selection - using average cluster consistency		In order to combine multiple data partitions into a more robust data partition, several approaches to produce the cluster ensemble and various consensus functions have been proposed. This range of possibilities in the multiple data partitions combination raises a new problem: which of the existing approaches, to produce the cluster ensembles’ data partitions and to combine these partitions, best fits a given data set. In this paper, we address the cluster ensemble selection problem. We proposed a new measure to select the best consensus data partition, among a variety of consensus partitions, based on a notion of average cluster consistency between each data partition that belongs to the cluster ensemble and a given consensus partition. We compared the proposed measure with other measures for cluster ensemble selection, using 9 different data sets, and the experimental results shown that the consensus partitions selected by our approach usually were of better quality in comparison with the consensus partitions selected by other measures used in our experiments.	computer cluster;experiment;fits;selection algorithm	F. Jorge F. Duarte;João M. M. Duarte;Fátima Rodrigues;Ana L. N. Fred	2009			computer science;machine learning;artificial intelligence	DB	1.4515994065253526	-41.10534297271501	35057
6acb13ebc18dd966ebcbc18c60e381f884014b0f	image segmentation: a novel cluster ensemble algorithm		Cluster ensemble has testified to be a good choice for addressing cluster analysis issues, which is composed of two processes: creating a group of clustering results from a same data set and then combining these results into a final clustering results. How to integrate these results to produce a final one is a significant issue for cluster ensemble. This combination process aims to improve the quality of individual data clustering results. A novel image segmentation algorithm using the Binary k-means and the Adaptive Affinity Propagation clustering (CEBAAP) is designed in this paper. It uses a Binary k-means method to generate a set of clustering results and develops an Adaptive Affinity Propagation clustering to combine these results. The experiments results show that CEBAAP has good image partition effect.	algorithm;image segmentation	Lei Wang;Guoyin Zhang;Chen Liu;Wei Gao	2016		10.1007/978-981-10-2053-7_36	mean-shift;segmentation-based object categorization;pattern recognition;image segmentation;minimum spanning tree-based segmentation;scale-space segmentation	Vision	3.780705166759596	-41.87077258548965	35124
d45eb5975492a47ab2f968644ff8dac53f7d01e8	fairness-aware classification: criterion, convexity, and bounds		Fairness-aware classification is receiving increasing attention in the machine learning fields. Recently research proposes to formulate the fairness-aware classification as constrained optimization problems. However, several limitations exist in previous works due to the lack of a theoretical framework for guiding the formulation. In this paper, we propose a general framework for learning fair classifiers which addresses previous limitations. The framework formulates various commonlyused fairness metrics as convex constraints that can be directly incorporated into classic classification models. Within the framework, we propose a constraint-free criterion on the training data which ensures that any classifier learned from the data is fair. We also derive the constraints which ensure that the real fairness metric is satisfied when surrogate functions are used to achieve convexity. Our framework can be used to for formulating fairness-aware classification with fairness guarantee and computational efficiency. The experiments using real-world datasets demonstrate our theoretical results and show the effectiveness of proposed framework and methods.	constrained optimization;experiment;fairness measure;machine learning;mathematical optimization	Yongkai Wu;Lu Zhang;Xintao Wu	2018	CoRR		machine learning;mathematical optimization;constrained optimization;artificial intelligence;training set;mathematics;convexity	ML	19.164712083337097	-35.59128326224573	35161
529f55995c9abb70e3509f69b6315d3aa30ac4ae	cooperative coevolution of elman recurrent neural networks for chaotic time series prediction	chaotic time series prediction;evolutionary algorithms;neuro evolution;recurrent neural networks;cooperative coevolution;qa76 computer software	Cooperative coevolution decomposes a problem into subcomponents and employs evolutionary algorithms for solving them. Cooperative coevolution has been effective for evolving neural networks. Different problem decomposition methods in cooperative coevolution determine how a neural network is decomposed and encoded which affects its performance. The problem decomposition method should provide enough diversity and also group interacting variables which are the synapses in the neural network. Neural networks have shown promising results in chaotic time series prediction. This work employs two different problem decomposition methods for training Elman recurrent neural networks on chaotic time series problems. The Mackey-Glass, Lorenz and Sunspot time series are used to demonstrate the performance of the cooperative neuro-evolutionary methods. The results show improvement in performance in terms of accuracy when compared to some of the methods from literature.	cooperative coevolution;evolutionary algorithm;evolutionary computation;global optimization;gradient;interaction;local search (optimization);mathematical optimization;neural networks;recurrent neural network;time series	Rohitash Chandra;Mengjie Zhang	2012	Neurocomputing	10.1016/j.neucom.2012.01.014	simulation;computer science;artificial intelligence;recurrent neural network;machine learning;evolutionary algorithm	ML	14.841337773162584	-24.220289763846903	35307
7348b1c73fb36ac9eac5c927f4b5985dc2cac248	research for neuron classification based on support vector machine	animals;fractals;kernel;support vector machines;neural nets;training;geometry;geometry neuron classification support vector machine spatial structure fractal dimensions training samples correct classification rate;fractal geometry;spatial structure;classification;classification support vector machine fractal geometry spatial structure;neurons support vector machines fractals kernel training mathematical model animals;pattern classification;mathematical model;neurons;support vector machine;support vector machines fractals geometry neural nets pattern classification	In this paper, a new method is proposed for neurons classifying based on its spatial structure. The part of neuron is geometrically similar to the whole. Neurons can be regarded as fractal. Different types of neurons fill with different levels in space. So, their fractal dimensions are also different. First, fractal dimensions are calculated for neurons. Then the other 16 spatial structure indicators are added in the classifier. There are 44 neurons as the training samples to train Support Vector Machine and other 20 neurons as the test samples. Experiments show that the correct classification rate is almost over 70% for many cases. It provides a new method to classify neurons.	experiment;fractal dimension;neuron;support vector machine	Fengqing Han;Jie Zeng	2012	2012 Third International Conference on Digital Manufacturing & Automation	10.1109/ICDMA.2012.153	discrete mathematics;machine learning;pattern recognition;mathematics	ML	14.143216682597535	-34.186671968580406	35310
7f54bc8e71b03a857287ccc88153c79959bb3a56	design of artificial neural networks using differential evolution algorithm	differential evolution;non linear optimization;transfer function;pattern classification;artificial neural network	The design of an Artificial Neural Network (ANN) is a difficult task for it depends on the human experience. Moreover it needs a process of testing and error to select which kind of a transfer function and which algorithm should be used to adjusting the synaptic weights in order to solve a specific problem. In the last years, bio-inspired algorithms have shown their power in different nonlinear optimization problems. Due to their efficiency and adaptability, in this paper we explore a new methodology to automatically design an ANN based on the Differential Evolution (DE) algorithm. The proposed method is capable to find the topology, the synaptic weights and the transfer functions to solve a given pattern classification problems.	algorithm;artificial neural network;differential evolution;neural networks	Beatriz A. Garro;Juan Humberto Sossa Azuela;Roberto Antonio Vázquez	2010		10.1007/978-3-642-17534-3_25	differential evolution;mathematical optimization;computer science;artificial intelligence;machine learning;transfer function;artificial neural network	ML	14.054520627490048	-24.60936688284766	35351
0463e0c874b5f65499e2876ddee93ea1bd1fa5f0	a hypothalamic and piagetian fuzzy inference system: htpfis	structure learning;body temperature;learning algorithm;fuzzy neural nets;fuzzy systems temperature space technology fuzzy neural networks humans neural networks circuits inference algorithms computer networks biological system modeling;fuzzy rules;temperature sensors;piagetian fuzzy inference system;inference mechanisms;heating;data mining;cognitive development;concise fuzzy rules knowledge base piagetian fuzzy inference system hypothalamic fuzzy inference system model externalization fuzzy rules neuro fuzzy system neuronal circuitries anterior hypothalamus learning algorithm action based cognitive development;artificial neural networks;knowledge based systems fuzzy neural nets inference mechanisms;neuro fuzzy system;integrated circuit modeling;fuzzy inference system;preoptic area;concise fuzzy rules knowledge base;neurons;hypothalamic fuzzy inference system;model externalization;action based cognitive development;neuronal circuitries;fuzzy systems;knowledge based systems;anterior hypothalamus;knowledge base	This paper presents a new approach to solving model externalization by taking into consideration the imprecise nature of decision makers' judgements on the different tacit models. Knowledge in the form of fuzzy rules are created using a neuro-fuzzy system called the Hypothalamic and Piagetian Fuzzy Inference System (HtPFIS). The structure of HtPFIS is inspired from the simplified neuronal circuitries of the preoptic area and anterior hypothalamus (PO/AH) which are involved in the thermoregulation of body temperature. HtPFIS employs a novel structure learning algorithm that is inspired from the Piaget's constructivist emphasis of action-based cognitive development in human. Results from the experiments show that HtPFIS is able to represent the formulated explicit model using a set of concise fuzzy rules knowledge base, and achieve better or comparable generalization than other models.	algorithm;cognition;experiment;fuzzy control system;fuzzy rule;inference engine;knowledge base;neuro-fuzzy;piaget's theory of cognitive development;time series	Eng-Yeow Cheu;See-Kiong Ng;Hiok Chai Quek	2009	2009 IEEE International Conference on Fuzzy Systems	10.1109/FUZZY.2009.5277213	knowledge base;human body temperature;adaptive neuro fuzzy inference system;computer science;artificial intelligence;machine learning;cognitive development;fuzzy control system	Robotics	5.6288041882908075	-28.366972194844635	35466
795cd1219104a7fc413976c0e3742db11ab068ab	verification of hypotheses generated by case-based reasoning object matching		Case-based reasoning object-matching consists of the methods at choice when the objects can be identified by case models. The result of the matching process is a number of hypotheses for the true shape of the objects. These hypotheses have to be verified in a hypothesis-verification process. In this paper we review what has been done so far and present our hypothesis-verification rules. The rules are evaluated and the results are discussed and presented in images. We consider two different hypothesis-verification rules, one is based on set-theory and the other one is based on statistical measures. Finally, we describe the results achieved so far and give an outlook about further work.	case-based reasoning	Petra Perner	2017		10.1007/978-3-319-59108-7_6	computer science;computer vision;case-based reasoning;machine learning;artificial intelligence;pattern recognition;set theory	AI	0.03930362046648002	-27.060603366236265	35479
0faf63705bf6fee852ff18892d468030f13beed7	deep stochastic configuration networks: universal approximation and learning representation		This paper focuses on the development of randomized approaches for building deep neural networks. A supervisory mechanism is proposed to constrain the random assignment of the hidden parameters (i.e., all biases and weights within the hidden layers). Full-rank oriented criterion is suggested and utilized as a termination condition to determine the number of nodes for each hidden layer, and a pre-defined error tolerance is used as a global indicator to decide the depth of the learner model. The read-out weights attached with all direct links from each hidden layer to the output layer are incrementally evaluated by the least squares method. Such a class of randomized leaner models with deep architecture is termed as deep stochastic configuration networks (DeepSCNs), of which the universal approximation property is verified with rigorous proof. Given abundant samples from a continuous distribution, DeepSCNs can speedily produce a learning representation, that is, a collection of random basis functions with the cascaded inputs together with the read-out weights. Simulation results with comparisons on function approximation align with the theoretical findings.	align (company);artificial neural network;basis function;deep learning;error-tolerant design;feature learning;functional programming;gene regulatory network;least squares;machine learning;network architecture;problem solving;randomized algorithm;simulation;sparse matrix;universal approximation theorem	Dianhui Wang;Ming Li	2017	CoRR		mathematical optimization;machine learning;mathematics;algorithm;statistics	ML	17.877991654464285	-30.663375919331674	35494
bd3cdd8923cde0170bc47dee895d22e8c9e5699f	a unified batch online learning framework for click prediction		We present a unified framework for Batch Online Learning (OL) for Click Prediction in Search Advertisement. Machine Learning models once deployed, show nontrivial accuracy and calibration degradation over time due to model staleness. It is therefore necessary to regularly update models, and do so automatically. This paper presents two paradigms of Batch Online Learning, one which incrementally updates the model parameters via an early stopping mechanism, and another which does so through a proximal regularization. We argue how both these schemes naturally trade-off between old and new data. We then theoretically and empirically show that these two seemingly different schemes are closely related. Through extensive experiments, we demonstrate the utility of of our OL framework; how the two OL schemes relate to each other and how they trade-off between the new and historical data. We then compare batch OL to full model retrains, and show how online learning is more robust to data issues. We also demonstrate the long term impact of Online Learning, the role of the initial Models in OL, the impact of delays in the update, and finally conclude with some implementation details and challenges in deploying a real world online learning system in production. While this paper mostly focuses on application of click prediction for search advertisement, we hope that the lessons learned here can be carried over to other problem domains.	algorithm;baseline (configuration management);batch processing;convex function;cyclic redundancy check;early stopping;elegant degradation;emoticon;expect;experiment;gradient descent;iterative method;online machine learning;problem domain;rollback (data management);unified framework;world online	Rishabh K. Iyer;Nimit Acharya;Tanuja Bompada;Denis Charles;Eren Manavoglu	2018	CoRR		machine learning;early stopping;mathematics;artificial intelligence	ML	23.19967941125466	-35.0054589680303	35497
f08d0e9a8789efa59b6b38536c240914f0e6cd4b	hybrid pca and lda analysis of microarray gene expression data	discriminant analysis;support vector machines;gene regulatory network;covariance matrix;high throughput;cell cycle regulation;computer science;principal component analysis;microarray data;linear discriminant analysis;multiple discriminant analysis;dimension reduction;biology;gene expression;scattering matrix	Microarray technology offers a high throughput means to study expression networks and gene regulatory networks in cells. The intrinsic nature of high dimensionality and small sample size in microarray data calls for the development of effective computational methods. In this paper, we propose a novel hybrid dimension reduction technique for classification - hybrid PCA (principal component analysis) and LDA (linear discriminant analysis) analysis. This technique effectively solves the singular scatter matrix problem caused by small training samples and increases the effective dimension of the projected subspace. It offers more flexibility and a richer set of alternatives to LDA and PCA in the parametric space. In addition, generalization of hybrid analysis of other dimension reduction techniques is also proposed in this paper, such as multiple discriminant analysis (MDA) and biased discriminant analysis (BDA). Extensive experiments on the yeast cell cycle regulation data set show the superior performance of the hybrid analysis over the traditional methods such as SVM.	broadcast driver architecture;dimensionality reduction;effective dimension;experiment;gene regulatory network;linear discriminant analysis;local-density approximation;microarray;multiple discriminant analysis;principal component analysis;support vector machine;throughput	Yijuan Lu;Qi Tian;Maribel Sanchez;Yufeng Wang	2005	2005 IEEE Symposium on Computational Intelligence in Bioinformatics and Computational Biology		s-matrix;high-throughput screening;support vector machine;microarray analysis techniques;gene regulatory network;covariance matrix;gene expression;computer science;bioinformatics;cell cycle;machine learning;pattern recognition;linear discriminant analysis;multiple discriminant analysis;dimensionality reduction;principal component analysis	Comp.	8.877855344080585	-48.7802635296334	35508
85473d7bd0b73488f22d8443583165fdbd3d221d	product quantized translation for fast nearest neighbor search		This paper proposes a simple nearest neighbor search algorithm, which provides the exact solution in terms of the Euclidean distance efficiently. Especially, we present an interesting approach to improve the speed of nearest neighbor search by proper translations of data and query although the task is inherently invariant to the Euclidean transformations. The proposed algorithm aims to eliminate nearest neighbor candidates effectively using their distance lower bounds in nonlinear embedded spaces, and further improves the lower bounds by transforming data and query through product quantized translations. Although our framework is composed of simple operations only, it achieves the state-of-the-art performance compared to existing nearest neighbor search techniques, which is illustrated quantitatively using various largescale benchmark datasets in different sizes and dimensions.	autonomous robot;benchmark (computing);computation;embedded system;euclidean distance;knowledge-based systems;machine learning;master of science in information technology;nearest neighbor search;nonlinear system;precomputation;quantization (signal processing);search algorithm;shattered world	Yoonho Hwang;Mooyeol Baek;Saehoon Kim;Bohyung Han;Hee-Kap Ahn	2018			machine learning;artificial intelligence;quantization (physics);computer science;nearest neighbor search	AI	18.87520289136492	-46.99628343945101	35529
3557a5708b85a99be717307a4946454b0c402a94	fixing the convergence problems in parallel asynchronous dual coordinate descent	convergence;support vector machines;risk management;logistics;message systems;delays;instruction sets	"""Solving L2-regularized empirical risk minimization (e.g., linear SVMs and logistic regression) using multiple cores has become an important research topic. Among all the existing algorithms, Parallel ASynchronous Stochastic dual Co-Ordinate DEscent (PASSCoDe) demonstrates superior performance compared with other methods. Although PASSCoDe is fast when it converges, the algorithm has been observed to diverge on several cases especially when a relatively large number of threads are used. This is mainly due to the delayed parameter access problem — the parameters used for the current update may be delayed and are not the latest ones. In theory, the algorithm converges only when the delay is small enough, but in practice the delay depends on the underlying parallel computing environment and cannot be guaranteed. In this work, we propose a simple and computational efficient way to fix the convergence problem of PASSCoDe. Instead of allowing all worker threads to conduct asynchronous updates wildly, we add periodic check points to the procedure, where all workers need to stop and refine the current solution at each check point. The resulting """"semi-asynchronous"""" algorithm is guaranteed to converge for any problem even when PASSCoDe diverges, and for the cases where PASSCoDe converges they have almost identical speed."""	algorithm;converge;coordinate descent;empirical risk minimization;logistic regression;parallel computing;semiconductor industry	Huan Zhang;Cho-Jui Hsieh	2016	2016 IEEE 16th International Conference on Data Mining (ICDM)	10.1109/ICDM.2016.0073	logistics;support vector machine;mathematical optimization;convergence;risk management;computer science;theoretical computer science;machine learning;instruction set;data mining;mathematics;distributed computing;statistics	DB	19.71599304857888	-37.46115192644969	35559
713064fc2dccd6c4e38a2444212cb823571d5bb6	outlier analysis using lattice of contiguous subspaces		Many anomaly detection techniques consider all the data-space dimensions when looking for outliers, and some others consider only specific subspaces, in isolation from other subspaces. However, interesting information about anomalous data points is embedded in the inter-relationships of the subspaces within which the data points appear to be outliers. Important characteristics of a dataset can be revealed by looking at these inter-relationships among subspaces. We describe a methodology for searching for outliers within the context of contiguous subspaces in the subspace lattice of a domain. We demonstrate additional insights about the outliers gained from this approach compared to finding the outliers in only specific subspaces or in the complete data-space. This additional information points an analyst to peculiar sets of subspaces to investigate further the underlying structure of the data space and also of the anomalous nature of the data points.		Vineet Joshi;Raj Bhatnagar	2014		10.1007/978-3-319-09912-5_20	statistics	NLP	-1.3120250866278689	-42.68823993728836	35581
80f1ed96aefc1fa0bf0ebc14dfbcb614733ad782	a method for creating ensemble neural networks using a sampling data approach	neural network;sampling technique	Ensemble Neural Networks are a learning paradigm where many neural networks are used together to solve a particular problem. In this paper, the relationship between the ensemble and its component neural networks is analyzed with the goal of creating of a set of nets for an ensemble with the use of a sampling-technique. This technique is such that each net in the ensemble is trained on a different sub-sample of the training data.		Miguel Lopez;Patricia Melin;Oscar Castillo	2007		10.1007/978-3-540-72434-6_78	sampling;types of artificial neural networks;computer science;machine learning;pattern recognition;data mining;time delay neural network;deep learning;ensemble learning;artificial neural network	AI	13.254151142260191	-28.9267534556204	35594
b528e81c8a296899d4a980bee41fd318b438833c	binary tree of svm: a new fast multiclass training and classification algorithm	directed graphs;probabilistic output;directed acyclic graph;grafo aciclico;multiclass;classification algorithm;error correction codes;convergence;complexity theory;binary trees support vector machines support vector machine classification classification tree analysis classification algorithms testing convergence error correction codes upper bound tree graphs;support vector machines;support vector machine svm;multiclase;error correction coding;convergence complexity;graphe acyclique;testing;trees mathematics;algorithms artificial intelligence cluster analysis image interpretation computer assisted information storage and retrieval pattern recognition automated;classification;acyclic graph;binary trees;upper bound;learning systems;tree graphs;c bts;multiclass problems;cluster analysis;multiclasse;image interpretation computer assisted;arbol binario;computational complexity;trees mathematics computational complexity convergence directed graphs error correction codes learning artificial intelligence support vector machines;trees graphs;directed graph;binary tree of support vector machine bts;machine exemple support;graphe oriente;arbre binaire;classification algorithms;binary classifiers;support vector machine svm binary tree of support vector machine bts c bts multiclass classification probabilistic output;error correcting output codes binary tree support vector machine fast multiclass training classification algorithm multiclass problems binary classifiers convergence complexity log complexity directed acyclic graph svm;artificial intelligence;support vector machine classification;algorithms;grafo orientado;pattern recognition automated;classification tree analysis;support vector machine;maquina ejemplo soporte;vector support machine;learning artificial intelligence;reseau neuronal;directed acyclic graph svm;information storage and retrieval;multiclass classification;clasificacion;red neuronal;fast multiclass training;log complexity;error correcting output codes	We present a new architecture named Binary Tree of support vector machine (SVM), or BTS, in order to achieve high classification efficiency for multiclass problems. BTS and its enhanced version, c-BTS, decrease the number of binary classifiers to the greatest extent without increasing the complexity of the original problem. In the training phase, BTS has N-1 binary classifiers in the best situation (N is the number of classes), while it has log4/3((N+3)/4) binary tests on average when making a decision. At the same time the upper bound of convergence complexity is determined. The experiments in this paper indicate that maintaining comparable accuracy, BTS is much faster to be trained than other methods. Especially in classification, due to its Log complexity, it is much faster than directed acyclic graph SVM (DAGSVM) and ECOC in problems that have big class number	algorithm;binary tree;broadcast television systems inc.;class;convergence (action);directed acyclic graph;experiment;multiclass classification;name;pyruvic acid;support vector machine	B. Fei;Jinbai Liu	2006	IEEE Transactions on Neural Networks	10.1109/TNN.2006.872343	statistical classification;support vector machine;directed graph;binary tree;computer science;machine learning;multiclass classification;pattern recognition;data mining;directed acyclic graph;artificial neural network	ML	14.070257433961032	-32.885055945041344	35598
c88771b918e8e2002b9549af71ac191e3785f697	a fast multilayer neural-network training algorithm based on the layer-by-layer optimizing procedures	minimisation;optimal solution;layer by layer;learning algorithm;feedforward;etude theorique;multilayer perceptrons;nonhomogeneous media multi layer neural network neural networks convergence feedforward neural networks backpropagation algorithms system identification computer simulation robustness power system modeling;multilayer feedforward neural network;multicouche;dynamic system;algorithme apprentissage;computation time fast multilayer neural network training algorithm layer by layer optimizing procedures learning algorithm multilayer feedforward neural network weight adjustment weight matrix sum square error minimization optimal weight matrix layer output vector dynamic forgetting factors method dynamic system identification computer simulation converging speed;boucle anticipation;multiple layer;identificacion sistema;ciclo anticipacion;system identification;factorization method;capa multiple;estudio teorico;feedforward neural nets;minimisation multilayer perceptrons learning artificial intelligence feedforward neural nets;theoretical study;learning artificial intelligence;reseau neuronal;multilayer neural network;computer simulation;red neuronal;identification systeme;training algorithm;neural network	A faster new learning algorithm to adjust the weights of the multilayer feedforward neural network is proposed. In this new algorithm, the weight matrix (W(2)) of the output layer and the output vector (Y) of the previous layer are treated as two variable sets. An optimal solution pair (W(2)*,Y(P)*) is found to minimize the sum-square-error of the patterns input. Y(P)* is then used as the desired output of the previous layer. The optimal weight matrix and layer output vector of the hidden layers in the network is found with the same method as that used for the output layer. In addition, the dynamic forgetting factors method makes the proposed new algorithm even more powerful in dynamic system identification. Computer simulation shows that the new algorithm outmatches other learning algorithms both in converging speed and in computation time required.	algorithm;artificial neural network;computation;computer simulation;convergence (action);dynamical system;feedforward neural network;machine learning;multilayer perceptron;neural network simulation;system identification;time complexity;weight;anatomical layer	Gou-Jen Wang;Chih-Cheng Chen	1996	IEEE transactions on neural networks	10.1109/72.501734	computer simulation;layer by layer;minimisation;system identification;computer science;artificial intelligence;theoretical computer science;dynamical system;machine learning;feed forward;artificial neural network	ML	16.55970161203784	-27.84548530298379	35600
a5fc55d090413021db99745c5f4a66e130f75945	modifying genetic programming for artificial neural network development for data mining	genetic program;evolutionary computation;soft computing;complex structure;genetic programming;data mining;artificial neural networks;artificial neural network;evolutionary computing	The development of artificial neural networks (ANNs) is usually a slow process in which the human expert has to test several architectures until he finds the one that achieves best results to solve a certain problem. However, there are some tools that provide the ability of automatically developing ANNs, many of them using evolutionary computation (EC) tools. One of the main problems of these techniques is that ANNs have a very complex structure, which makes them very difficult to be represented and developed by these tools. This work presents a new technique that modifies genetic programming (GP) so as to correctly and efficiently work with graph structures in order to develop ANNs. This technique also allows the obtaining of simplified networks that solve the problem with a small group of neurons. In order to measure the performance of the system and to compare the results with other ANN development methods by means of evolutionary computation (EC) techniques, several tests were performed with problems based on some of the most used test databases in the Data Mining domain. These comparisons show that the system achieves good results that are not only comparable to those of the already existing techniques but, in most cases, improve them. D. Rivero (B) · J. Dorado · J. R. Rabuñal · A. Pazos Fac. Informatica, University of A Coruña, Campus Elviña, 15071 A Coruña, Spain e-mail: drivero@udc.es J. Dorado e-mail: julian@udc.es J. R. Rabuñal e-mail: juanra@udc.es A. Pazos e-mail: apazos@udc.es	artificial neural network;campus party;data mining;database;distributed computing;email;evolutionary algorithm;evolutionary computation;genetic algorithm;genetic programming;graph (discrete mathematics);network architecture;software release life cycle;time series	Daniel Rivero;Julian Dorado;Juan R. Rabuñal;Alejandro Pazos	2009	Soft Comput.	10.1007/s00500-008-0317-9	evolutionary programming;genetic programming;computer science;artificial intelligence;machine learning;genetic representation;data mining;generalized complex structure;artificial neural network;evolutionary computation	ML	13.511155453738889	-24.776818759857296	35699
57e0b2614fe0d0aed7c85a09cb17289f7e0d1bf6	conservativeness of untied auto-encoders		We discuss necessary and sufficient conditions for an auto-encoder to define a conservative vector field, in which case it is associated with an energy function akin to the unnormalized log-probability of the data. We show that the conditions for conservativeness are more general than for encoder and decoder weights to be the same (“tied weights”), and that they also depend on the form of the hidden unit activation function, but that contractive training criteria, such as denoising, will enforce these conditions locally. Based on these observations, we show how we can use auto-encoders to extract the conservative component of a vector field.	activation function;autoencoder;basis (linear algebra);encoder;log probability;mathematical optimization;noise reduction	Daniel Jiwoong Im;Mohamed Ishmael Diwan Belghazi;Roland Memisevic	2016			mathematical optimization;discrete mathematics;control theory;mathematics	AI	22.74554931585541	-48.08021561614364	35752
44dff33e028f56bd0cd1e30cd27b7875f4ba71db	building a fuzzy system from input-output data		We propose a new neural network for implementing fuzzy systems, and we prove that it can represent any continuous function over a compact set. We propose and test a method for building a fuzzy neural system from input-output data. We analyze the output data using fuzzy c-means to obtain the number of rules and to set some of the initial weights in the network. Then, we use this fuzzy neural network to identify the input variables and to determine the number of input membership functions. We show that the resulting model is simpler and yields better performance than previously proposed methods for extracting fuzzy systems and neural networks from input-output data.	fuzzy control system	Yinghua Lin;George A. Cunningham	1994	Journal of Intelligent and Fuzzy Systems	10.3233/IFS-1994-2304	discrete mathematics;membership function;defuzzification;adaptive neuro fuzzy inference system;fuzzy transportation;type-2 fuzzy sets and systems;fuzzy classification;fuzzy number;neuro-fuzzy;machine learning;fuzzy measure theory;data mining;time delay neural network;mathematics;fuzzy associative matrix;fuzzy set operations;fuzzy control system	Robotics	5.098602710140118	-27.475683757501393	35788
1430f20b54fa75fd4debbb27fbb79e93adc1e58f	evading: an evolutionary algorithm with dynamic niching for data classification.	rule induction;indexing terms;function optimization;optimization problem;dynamic clustering;machine learning;classification rules;prediction accuracy;pattern recognition;evolutionary algorithm;data classification	Multimodal optimization problems (MMOPs) have been widely studied in many fields of machine learning, including pattern recognition and data classification. Formulating the process of rule induction for the latter task as a MMOP and inspired by corresponding findings in the field of function optimization, our current work proposes an evolutionary algorithm (EVADING) capable of discovering a set of accurate and diverse classification rules. The proposed algorithm uses a dynamic clustering technique as a parallel niching method to maintain rule population diversity and converge to the optimal rules for the attribute-space defined by the target dataset. To demonstrate its applicability and potential, EVADING is applied to a series of real-life classification problems and its prediction accuracy is compared to that of other popular non-evolutionary machine learning techniques. Results are encouraging, since EVADING manages to achieve the best overall average ranking and performs significantly better (at significance level a=0.05) from three out of the eight rival algorithms used in this study. This work is concluded with some insights on the factors affecting the proposed algorithm’s performance, along with the directions of our future research.	benchmark (computing);cluster analysis;converge;decision table;evolutionary algorithm;evolutionary multimodal optimization;fuzzy logic;machine learning;mathematical optimization;multimodal interaction;niche blogging;pattern recognition;real life;rule induction	John Psaroudakis;Fani A. Tzima;Pericles A. Mitkas	2009			computer science;machine learning;pattern recognition;data mining	ML	4.51178636702549	-41.84746730096414	35841
398f9498f4340df32f1fb7409140850452bc10d9	a new temporal pattern identification method for characterization and prediction of complex time series events	identification time series data mining pattern recognition;decision tree;optimal method;time series;phase space;data mining;time delay;temporal patterns pattern identification time series analysis data mining time delay embedding optimization clustering genetic algorithms;time delay neural network;time series analysis;time delay embedding;identification;data mining time series analysis data analysis welding delay effects pattern analysis spatial databases visual databases dynamic programming optimization methods;temporal pattern;pattern recognition;and genetic algorithms;time series data;temporal pattern identification;optimization clustering	A new method for analyzing time series data is introduced in this paper. Inspired by data mining, the new method employs time-delayed embedding and identifies temporal patterns in the resulting phase spaces. An optimization method is applied to search the phase spaces for optimal heterogeneous temporal pattern clusters that reveal hidden temporal patterns, which are characteristic and predictive of time series events. The fundemantal concepts and framework of the method are explained in detail. The method is then applied to the characterization and prediction, with a high degree of accuracy, of the release of metal droplets from a welder. The results of the method are compared to those from a Time Delay Neural Network and the C4.5 decision tree algorithm.	c4.5 algorithm;cluster analysis;data mining;decision tree;list of algorithms;mathematical optimization;time delay neural network;time series	Richard J. Povinelli;Xin Feng	2003	IEEE Trans. Knowl. Data Eng.	10.1109/TKDE.2003.1185838	computer science;machine learning;time series;pattern recognition;data mining;statistics	ML	1.9654773396383625	-36.599652721876566	35893
63ef9340eeace5b4caf6a1863118f5ec967dc111	a scale-space filter approach to clustering dose-response curves of novel drug compounds	drugs;multiscale representation;scale space filtering automatic classification clustering functional high throughput screening gaussian smoothing multiscale representation;high throughput screening;scale space;filters drugs filtering throughput informatics robustness high temperature superconductors matrix converters performance analysis smoothing methods;filtering theory pharmaceutical industry drugs curve fitting pattern classification;pattern classification;dose response;curve fitting;pharmaceutical industry;screening assay scale space filter approach novel drug compounds automated dose response curve classification method;automatic classification;filtering theory	"""Automated dose-response curve classification methods need to be developed to keep up with the vast amount of data emanating from high throughput screening assays. We have devised a methodology based on scale-space filtering that allows tracking of salient features of dose-response curves at different scales. A complete and unbiased representation of dose-response data at various scale levels enables us to subsequently employ metrics that robustly classify the different functional categories of drug compounds that may exist in a novel screening assay. This powerful tool is intuitive and yet rigorous in that it distinguishes """"important"""" characteristics of """"different"""" curves. The method is non-heuristic, eliminates subjectivity, and is general enough to be readily employed in a wide variety of applications."""	cluster analysis;heuristic;persistent data structure;scale space;smoothing;throughput	S. S. Dalai;David J. Balaban	2005	2005 IEEE International Conference on Systems, Man and Cybernetics	10.1109/ICSMC.2005.1571581	high-throughput screening;computer vision;econometrics;dose–response relationship;scale space;computer science;data mining;statistics;curve fitting	Robotics	6.317596638818054	-51.21202422113147	35896
05ddd661a8df460c4dfb4842bccddf646d436032	exploring new possibilities for case based explanation of artificial neural network ensembles	emergency department;personal sanitario;medecin;analisis sensibilidad;optimisation;raisonnement base sur cas;razonamiento fundado sobre caso;teaching hospital;regle;optimizacion;physician;systeme aide decision;salud publica;recubrimiento;neural network ensemble;overlay;prise de decision;syndrome;sistema ayuda decision;electrocardiographie;sindrome;centre hospitalier universitaire;recouvrement;acute coronary syndrome;algorithme;algorithm;servicio urgencia;decision support system;electrocardiography;electrocardiografia;regla;anestesi och intensivvard;case based explanation;sensitivity analysis;medico;personnel sanitaire;utilisabilite;analyse sensibilite;sante publique;clinical decision support system;optimization;usabilidad;case based reasoning;reseau neuronal;toma decision;centro hospitalario universitario;usability;rule;health staff;red neuronal;public health;artificial neural network;electrocardiogram;neural network;algoritmo;service urgence;radiologi och bildbehandling;neural network ensembles	Artificial neural network (ANN) ensembles have long suffered from a lack of interpretability. This has severely limited the practical usability of ANNs in settings where an erroneous decision can be disastrous. Several attempts have been made to alleviate this problem. Many of them are based on decomposing the decision boundary of the ANN into a set of rules. We explore and compare a set of new methods for this explanation process on two artificial data sets (Monks 1 and 3), and one acute coronary syndrome data set consisting of 861 electrocardiograms (ECG) collected retrospectively at the emergency department at Lund University Hospital. The algorithms managed to extract good explanations in more than 84% of the cases. More to the point, the best method provided 99% and 91% good explanations in Monks data 1 and 3 respectively. Also there was a significant overlap between the algorithms. Furthermore, when explaining a given ECG, the overlap between this method and one of the physicians was the same as the one between the two physicians in this study. Still the physicians were significantly, p-value<0.001, more similar to each other than to any of the methods. The algorithms have the potential to be used as an explanatory aid when using ANN ensembles in clinical decision support systems.	acute coronary syndrome;artificial neural network;clinical decision support system;decision support systems, clinical;decision boundary;mental suffering;ninety nine;overlap–add method;rule (guideline);usability;algorithm;explanation	Michael Green;Ulf Ekelund;Lars Edenbrandt;Jonas Björk;Jakob Lundager Forberg;Mattias Ohlsson	2008	Neural networks : the official journal of the International Neural Network Society	10.1016/j.neunet.2008.09.014	case-based reasoning;usability;computer science;artificial intelligence;machine learning;overlay;operations research;sensitivity analysis;artificial neural network	ML	8.383917351751386	-30.633947813603598	35912
51718a41b836842bc3afaaf45600921bc8b48d87	method and technology of synthesis of neural network models of object control with their hardware implementation on fpga		This work presents a method and technology of synthesis of direct and inverse neural network models of object control, and their hardware implementation of programmable logic integrated circuits, that will automate the process of synthesis of such models and shorten the time of development and research.	artificial neural network;control system;field-programmable gate array;genetic algorithm;integrated circuit;intelligent control;network model;programmable logic device	Petro I. Kravets;Volodymyr M. Shymkovych;Volodymyr Samotyy	2017	2017 9th IEEE International Conference on Intelligent Data Acquisition and Advanced Computing Systems: Technology and Applications (IDAACS)	10.1109/IDAACS.2017.8095226	field-programmable gate array;computer hardware;programmable logic device;artificial neural network;data modeling;integrated circuit;computer science;control system	Robotics	13.303914012931317	-26.602461852034622	35914
0fbdcee3ed4a30f58c99bd3eace2f7219259b85e	learning algorithms for auto-associators with full storage capacity	learning algorithms;learning algorithm;neural nets;autoassociator;short bit length data;learning systems;neural nets learning systems;hebb rule;simulations hebb rule autoassociator full storage capacity learning algorithms neural network short bit length data;storage capacity;full storage capacity;neural network	Two learning algorithms for storing data in an autoassociator with full storage capacity are presented. The first algorithm can teach a neural network to store short-bit-length data with full storage capacity (as compared to the Hebb rule), and the second algorithm can do the same for long-bit-length data at a higher speed (as compared to the delta rule). The algorithms eliminate the problem of limited storage capacity associated with the Hebb rule, and their learning speeds are much faster than that of the corresponding delta rule. Simulations have been done to compare the two learning algorithms to those of the Hebb rule and the delta rule. Results show that the two algorithms are much better than the Hebb rule in terms of storage capacity and much better than the delta rule in terms of learning speed	algorithm	C. K. Lee;H. K. Kwan	1990		10.1109/IJCNN.1990.137841	delta rule;computer science;artificial intelligence;machine learning;generalized hebbian algorithm;artificial neural network;algorithm	Theory	14.994206392349748	-29.88349203396536	35933
a24352c33cfefa42096f93c4e7ee219ccdcb56ec	kernel-based hashing for content-based image retrval in large remote sensing data archive	kernel based hashing remote sensing content based image retrieval;vectors approximation theory binary codes cryptography file organisation geophysical image processing hamming codes image coding image retrieval remote sensing search problems;aerial imaging kernel based hashing function content based image retrieval large remote sensing data archive approximate nearest neighbor search algorithm high dimensional image feature vector mapping short binary code hamming distance image hash code rs image retrieval problem semantic similarity;image retrieval kernel accuracy vectors remote sensing training binary codes	This paper presents hashing based approximate nearest neighbor search algorithms that allow fast and accurate image retrieval in huge remote sensing data archives. Hashing methods aim at mapping high-dimensional image feature vectors into short binary codes based on hashing functions. Then, the image retrieval is accomplished according to Hamming distances of image hash codes. In particular, in this paper two hashing methods are adopted for RS image retrieval problems. The former aims at defining hash functions in the kernel space by using only unlabeled images. The latter leverages on the semantic similarity given in terms of annotated images to define much distinctive hash functions in the kernel space. The effectiveness of both methods is analyzed in terms of RS image retrieval accuracy as well as retrieval time. Experiments carried out on an archive of aerial images show that the presented hashing methods are one hundred times faster than those that exploit an exact nearest neighbor search while keeping a high retrieval accuracy.	aerial photography;approximation algorithm;archive;binary code;feature (computer vision);hamming distance;hash function;image retrieval;kernel (operating system);nearest neighbor search;research data archiving;search algorithm;semantic similarity;user space	Begiim Demir;Lorenzo Bruzzo	2014	2014 IEEE Geoscience and Remote Sensing Symposium	10.1109/IGARSS.2014.6947247	feature detection;visual word;computer science;theoretical computer science;pattern recognition;automatic image annotation;information retrieval	Vision	19.10071721142865	-46.99495856730174	35959
1004a1bb4a4397b22ccd47beeaa1d3275155f952	machine learning approach to rf transmitter identification		This document does not contain technology or technical data controlled under either the U.S. International Traffic in Arms Regulations or the U.S. Export Administration Regulations. With the development and widespread use of wireless devices in recent years (mobile phones, Internet of Things, Wi-Fi), the electromagnetic spectrum has become extremely crowded. In order to counter security threats posed by rogue or unknown transmitters, it is important to identify RF transmitters not by the data content of the transmissions but based on the intrinsic physical characteristics of the transmitters. RF waveforms represent a particular challenge because of the extremely high data rates involved and the potentially large number of transmitters present in a given location. These factors outline the need for rapid fingerprinting and identification methods that go beyond the traditional hand-engineered approaches. In this study, we investigate the use of machine learning (ML) strategies to the classification and identification problems, and the use of wavelets to reduce the amount of data required. Four different ML strategies are evaluated: deep neural nets (DNN), convolutional neural nets (CNN), support vector machines (SVM), and multi-stage training (MST) using accelerated Levenberg-Marquardt (A-LM) updates. The A-LM MST method preconditioned by wavelets was by far the most accurate, achieving 100% classification accuracy of transmitters, as tested using data originating from 12 different transmitters. We discuss strategies for extension of MST to a much larger number of transmitters.	artificial neural network;convolutional neural network;deep learning;fingerprint (computing);internet of things;levenberg–marquardt algorithm;machine learning;mobile phone;radio frequency;rogue;support vector machine;transmitter;wavelet	Khalid Youssef;Louis-S. Bouchard;K. Z. Haigh;H. Krovi;J. Silovsky;C. P. Vander Valk	2017	CoRR		scalability;radio transmitter design;transmitter;wireless;radio frequency;support vector machine;artificial neural network;machine learning;artificial intelligence;computer science;communication channel	HCI	4.3269394325842985	-36.01463214902652	35963
165b28ceaafcd9992f18747d9c16aa947caa22ee	decision making using hybrid rough sets and neural networks.	neural networks;diagnostic system;structure adaptation;rough sets;rough set;neural network	A methodology for using rough sets theory for preference modeling in decision problem is presented in this paper. We will introduce a new method where neural network systems and rough sets theory are completely integrated into a hybrid system and are used cooperatively for decision and classification support. At the first glance, the two methods we discuss have not much in common. But, in spite of the differences between them, it is interesting to try to incorporate both into one combined system, and apply it in the building of a decision support system.	aortic valve insufficiency;artificial neural network;base excision repair;biological neural networks;cns disorder;data pre-processing;decision problem;decision support system;emergence;experiment;fr 139317;hybrid system;nl (complexity);network model;neural network simulation;nomenclature;numerical aperture;physical object;preprocessor;problem domain;real life;rough set;set theory;silo (dataset);sodium;statistical classification;weight	Yasser Hassan;Eiichiro Tazaki;Shin Egawa;Kazuho Suyama	2002	International journal of neural systems	10.1142/S012906570200131X	rough set;computer science;artificial intelligence;machine learning;data mining;mathematics;artificial neural network;dominance-based rough set approach	Robotics	3.4818725171893457	-26.309764606115337	35966
f1dc74af360beba52c7e1a283d75d6087be4e944	sarah: a novel method for machine learning problems using stochastic recursive gradient		In this paper, we propose a StochAstic Recursive grAdient algoritHm (SARAH), as well as its practical variant SARAH+, as a novel approach to the finite-sum minimization problems. Different from the vanilla SGD and other modern stochastic methods such as SVRG, S2GD, SAG and SAGA, SARAH admits a simple recursive framework for updating stochastic gradient estimates; when comparing to SAG/SAGA, SARAH does not require a storage of past gradients. The linear convergence rate of SARAH is proven under strong convexity assumption. We also prove a linear convergence rate (in the strongly convex case) for an inner loop of SARAH, the property that SVRG does not possess. Numerical experiments demonstrate the efficiency of our algorithm.	algorithm;convex function;experiment;gradient;inner loop;machine learning;numerical method;rate of convergence;recursion (computer science);sql access group	Lam M. Nguyen;Jie Liu;Katya Scheinberg;Martin Takác	2017			mathematical optimization;artificial intelligence;machine learning;mathematics;algorithm;statistics	ML	24.050051346417312	-33.62428455657343	35999
749c328e9ef247b073f065837ffa8a79c8a9cce6	producing accurate interpretable clusters from high-dimensional data	base dato multidimensional;analyse amas;text;base donnee;grouping;analisis datos;database;base dato;texte;multidimensional database;classification;data analysis;cluster analysis;modele spectral;decouverte connaissance;high dimensional data;text clustering;descubrimiento conocimiento;analyse donnee;analisis cluster;base donnee multidimensionnelle;technical report;agrupamiento;computer science;cluster model;texto;clasificacion;groupage;modelo espectral;spectral model;knowledge discovery	The primary goal of cluster analysis is to produce clusters that accurately reflect the natural groupings in the data. A second objective that is important for high-dimensional data is to identify features that are descriptive of the clusters. In addition to these requirements, we often wish to allow objects to be associated with more than one cluster. In this paper we present a technique, based on the spectral co-clustering model, that is effective in meeting these objectives. Our evaluation on a range of text clustering problems shows that the proposed method yields accuracy superior to that afforded by existing techniques, while producing cluster descriptions that are amenable to human interpretation.	biclustering;cluster analysis;requirement	Derek Greene;Padraig Cunningham	2005		10.1007/11564126_49	document clustering;biological classification;computer science;technical report;data science;machine learning;data mining;knowledge extraction;cluster analysis;data analysis;clustering high-dimensional data	SE	-2.66880088616696	-32.57009716060107	36025
4f464c4da14411c3c9b08b43ea8efe179b512f83	model-based oversampling for imbalanced sequence classification	oversampling;model space;sequence classification;imbalanced learning	Sequence classification is critical in the data mining communities. It becomes more challenging when the class distribution is imbalanced, which occurs in many real-world applications. Oversampling algorithms try to re-balance the skewed class by generating synthetic data for minority classes, but most of existing oversampling approaches could not consider the temporal structure of sequences, or handle multivariate and long sequences. To address these problems, this paper proposes a novel oversampling algorithm based on the 'generative' models of sequences. In particular, a recurrent neural network was employed to learn the generative mechanics for sequences as representations for the corresponding sequences. These generative models are then utilized to form a kernel to capture the similarity between different sequences. Finally, oversampling is performed in the kernel feature space to generate synthetic data. The proposed approach can handle highly imbalanced sequential data and is robust to noise. The competitiveness of the proposed approach is demonstrated by experiments on both synthetic data and benchmark data, including univariate and multivariate sequences.	algorithm;artificial neural network;benchmark (computing);data mining;experiment;feature vector;generative model;kernel (operating system);oversampling;recurrent neural network;synthetic data	Zhichen Gong;Bingbing Jiang	2016		10.1145/2983323.2983784	oversampling;computer science;machine learning;pattern recognition;data mining	ML	17.796141526548222	-42.33536487753307	36081
f353e278c7277ec0780773f980d5f26be6982623	on the application of the fuzzy sets separation theorem for automatic classification in information retrieval systems	fuzzy set;information retrieval system;automatic classification	Abstract   This paper deals with a new clustering technique using the concept of fuzzy set introduced by Zadeh. A cluster is defined as a subset characterized by a membership function which associates with each element a real number in the unit interval. A membership function is proposed and a method to select the cluster elements is derived using the separation theorem of the fuzzy sets. The clusters obtained by this way are controlled overlapping groupings.	fuzzy set;gabbay's separation theorem;information retrieval	Constantin Virgil Negoita	1973	Inf. Sci.	10.1016/0020-0255(73)90019-4	fuzzy logic;membership function;defuzzification;type-2 fuzzy sets and systems;fuzzy mathematics;fuzzy classification;computer science;artificial intelligence;fuzzy number;neuro-fuzzy;machine learning;pattern recognition;data mining;mathematics;fuzzy set;fuzzy set operations	AI	-0.7433743510615988	-24.7477319714466	36190
6412ffb5c70758e649da0629003b6566e93900ac	dimensional reduction of web traffic data	unsupervised learning;ruido aleatorio;log likelihood;information loss;red www;data compression;dimension reduction;bruit aleatoire;resistance;reseau web;donnee trafic web;apprentissage non supervise;clustering base distance;distance based clustering;reduction donnee;reduction dimension;random noise;matrices;internet;machine learning;perdida informacion;web traffic data;world wide web;reduccion datos;data reduction;compresion dato;perte information;compression donnee	Dimensional reduction may be effective in order to compress data without loss of essential information. Also, it may be useful in order to smooth data and reduce random noise. The model presented in this paper was motivated by the structure of the msweb web-traffic dataset from the UCI archive. It is proposed to reduce dimension (number of the used web-areas or vroots) as a result of the unsupervised learning process maximizing specially defined average loglikelihood divergence. Two different web-areas will be merged in the case if these areas appear together frequently during the same sessions. Essentially, roles of the web-areas are not symmetrical in the merging process. The webarea or cluster with bigger weight will act as an attractor and will stimulate merging. In difference, the smaller cluster will try to keep independence. In both cases the powers of attraction or resistance will depend on the weights of the corresponding clusters. Above strategy will prevent creation of one super-big cluster, and will help to reduce number of non-significant clusters. The proposed method was illustrated using two synthetic examples. The first example is based on an ideal vlink matrix which characterizes weights of the vroots and relations between them. The vlink matrix for the second example was generated using specially designed web-traffic simulator.	archive;kullback–leibler divergence;noise (electronics);simulation;synthetic intelligence;unsupervised learning;web traffic	Vladimir Nikulin	2006		10.1117/12.664767	data compression;unsupervised learning;data reduction;the internet;telecommunications;likelihood-ratio test;computer science;artificial intelligence;machine learning;data mining;resistance;matrix;dimensionality reduction	ML	8.00409587376101	-35.00464352712259	36201
a4cbe0bb20bf65b66f12063f0cd47b97896f61ec	learning and transferring convolutional neural network knowledge to ocean front recognition	knowledge learning knowledge transferring convolutional neural network knowledge ocean front recognition deep learning method fine tuning limited remote sensing images colorful data gray level data noaa handcraft descriptor bag of visual words last layer fine tuned cnn model;oceans;neural networks;data mining;convolutional neural networks cnns fine tuning ocean front recognition transfer learning;training data;computer architecture;machine learning;feature extraction;remote sensing geophysical image processing image recognition knowledge acquisition learning artificial intelligence neural nets oceanographic techniques;last layer fine tuned cnn model knowledge learning knowledge transferring convolutional neural network knowledge ocean front recognition deep learning method fine tuning limited remote sensing images colorful data gray level data noaa handcraft descriptor bag of visual words;oceans feature extraction computer architecture machine learning training data neural networks data mining;geophysical image processing image recognition knowledge acquisition learning artificial intelligence neural nets oceanographic techniques remote sensing;transfer learning convolutional neural networks cnns fine tuning ocean front recognition	In this letter, we investigated how to apply a deep learning method, in particular convolutional neural networks (CNNs), to an ocean front recognition task. Exploring deep CNNs knowledge to ocean front recognition is a challenging task, because the training data is very scarce. This letter overcomes this challenge using a sequence of transfer learning steps via fine-tuning. The core idea is to extract deep knowledge of the CNN model from a large data set and then transfer the knowledge to our ocean front recognition task on limited remote sensing (RS) images. We conducted experiments on two different RS image data sets, with different visual properties, i.e., colorful and gray-level data, which were both downloaded from the National Oceanic and Atmospheric Administration (NOAA). The proposed method was compared with the conventional handcraft descriptor with bag-of-visual-words, original CNN model, and last-layer fine-tuned CNN model. Our method showed a significantly higher accuracy than other methods in both datasets.	artificial neural network;bag-of-words model in computer vision;convolutional neural network;deep learning;experiment;imagenet;reed–solomon error correction	Estanislau Lima;Xin Sun;Junyu Dong;Hui Wang;Yuting Yang;Lipeng Liu	2017	IEEE Geoscience and Remote Sensing Letters	10.1109/LGRS.2016.2643000	computer vision;training set;feature extraction;computer science;artificial intelligence;machine learning;deep learning;artificial neural network	Vision	22.7547392697714	-51.36104006727721	36202
ddfa23481a0557de41cb23630a399cc54983eb53	local search optimized hashing for fast image copy detection	training;semantics;search problems feature extraction;feature extraction;transforms;linear programming;robustness;feature extraction linear programming semantics optimization training robustness transforms;optimization;mapping error local search optimized hashing method content based image copy detection robust feature extraction huge semantic loss neighborhood structure feature data	Recently, researches on content based image copy detection mainly focus on robust feature extraction. However, due to the exponential growth of online images, it is time-consuming and unscalable to search among large scale images. Although many hashing methods has been proposed to improve the efficiency of image copy detection, they confront semantic loss issue. In this paper, we propose a new hashing based method for fast image copy detection. It first generates compact fingerprint which combine the influence of both the neighborhood structure of feature data and mapping error to prevent huge semantic loss during the process of hashing. Then optimize the solution through Local Search to further decrease semantic loss. Experimental results show that our approach significantly outperforms state-of-art methods.	cryptographic hash function;exclusive or;experiment;feature data;feature extraction;fingerprint;hamming space;iterated local search;iteration;local search (constraint satisfaction);local search (optimization);locality of reference;machine learning;time complexity	Lingyu Yan;Xinyu Ou;Hefei Ling	2014	Signal and Information Processing Association Annual Summit and Conference (APSIPA), 2014 Asia-Pacific	10.1109/APSIPA.2014.7041566	feature detection;computer science;machine learning;pattern recognition;data mining;feature	AI	20.387220662884427	-47.38953015046792	36209
534e73d53bd8ad5690cb7650bc6c8f2762dcde71	rough set approach to spam filter learning	spam filtering;intelligent agent;data modelling;rough set;decision table;spam detection	This article presents an elementary overview of techniques employed for spam detection via probabilistic decision table-based predictive data modelling. The focus here is to present a solution that combines simple algorithms together with some heuristics to construct generalized rough approximations of spam and legitimate e-mails using the variable precision rough set (VPRSM) approach. Experiments were conducted to explore the application of VPRSM for designing an intelligent agent for spam filtering.	email filtering;rough set	Mawuena Glymin;Wojciech Ziarko	2007		10.1007/978-3-540-73451-2_37	computer science;theoretical computer science;machine learning;data mining	ML	7.2026839089176935	-36.46351963037844	36229
bf4ed3545200937a40dd600000657df9eee03f37	an ensemble approach to instance-based regression using stretched neighborhoods		Instance-based regression methods generate solutions from prior solutions within a neighborhood of the input query. Their performance depends on both neighborhood selection criteria and on the method for generating new solutions from the values of prior instances. This paper proposes a new approach to addressing both problems, in which solutions are generated by an ensemble of solutions of local linear regression models built for a collection of “stretched” neighborhoods of the query. Each neighborhood is generated by relaxing a different dimension of the problem space. The rationale is to enable major change trends along that dimension to have increased influence on the corresponding model. The approach is evaluated for two candidate relaxation approaches, gradient-based and based on fixed profiles, and compared to baselines of k-NN and using a radiusbased spherical neighborhood in n-dimensional space. Results in four test domains show up to 15 percent improvement over baselines, and suggest that the approach could be particularly useful in domains for which the space of prior instances is sparse. Introduction Lazy learning methods postpone building a model or making an estimation for the target function until a query is submitted, generating local estimates tailored the specific input problems. Lazy learning can be especially beneficial for complex and incomplete domains in which a set of (possibly relatively simpler) local models may provide higher quality results than a single global model. The notion of locality in lazy learning is often defined based on a distance function that is used for finding a set of nearest neighbors for the input query, from whose values a value is computed for the input query. Normally the neighborhood is determined by the distance function and a predefined number of nearby instances to consider: k-NN considers the k nearest neighbors. However, other neighborhood selection schemes and combination functions may sometimes be more appropriate. In this paper, we explore an approach using new neighborhood selection functions for choosing points from which to calculate Copyright c © 2013, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved. a target value, using linear regression to develop local models, and then combining the values of those models to produce a value. From the perspective of case-based reasoning, this corresponds to a new approach to adapting the solutions of prior cases for regression tasks. The method trains linear regression models for local neighborhoods of the input query, in which the nearest neighbor calculation is adapted to “stretch” one dimension. More specifically, for an n-dimensional space, distances are computed by a normal domain similarity metric in n-1 dimensions, and distances in one dimension are relaxed according to either a gradient-based strategy or a strategy based on a fixed “shape” profile. By generating a model for a set neighborhoods, each relaxing of one of the n possible dimensions, n different linear regression models are generated for the specific query. The final value is generated by averaging the estimate returned by each of the models. We first present the approach and then evaluate its performance for four sample domains, showing encouraging results. We close with observations and topics for future research. Related Work Many instance-based learning approaches use k-NN, selecting neighborhoods composed of the k nearest instances. The effects of neighborhood shape have received little study. Outside of instance-based learning, numerous approaches have been explored for regression tasks. For example, Kwok and Yeung (yau Kwok and Yeung 1997) apply feed-forward neural networks, Orr (Orr 1996) applies radial basis function networks, and Scholkopf and Smola (Scholkopf and Smola 2001) apply Support Vector Machines by transforming the regression problem into a constrained optimization problem. These methods differ from our work both in the utilized models and the non-lazy nature of the model generation. Within case-based reasoning, McSherry (McSherry 1998) proposes a case-based reasoning regression approach based on pair-wise comparisons between cases in a case-base and using those pairs for adapting the solution from a retrieved case for an input query. Most relevant to our approach, Patterson et. al. (Patterson, Rooney, and Galushka 2002) train a locally weighted regression model for predicting the difference in the target value of two cases. They use a distance weighted average for creating a generalized case from the top k nearest neighbors to the input query, and adapt the soProceedings of the Twenty-Sixth International Florida Artificial Intelligence Research Society Conference	artificial intelligence;artificial neural network;baseline (configuration management);case-based reasoning;constrained optimization;constraint (mathematics);design rationale;feedforward neural network;gradient;instance-based learning;k-nearest neighbors algorithm;ken orr;lazy evaluation;lazy learning;linear programming relaxation;locality of reference;mathematical optimization;optimization problem;problem domain;radial (radio);radial basis function;sparse matrix;support vector machine	Vahid Jalali;David B. Leake	2013			mathematical optimization;machine learning;data mining;statistics	AI	21.50187168711695	-40.7454087666136	36237
6500e3512c8c266561d016902a3904f66d453624	comparing machine learning classifiers for object-based land cover classification using very high resolution imagery	tuning parameters;machine learning classifiers;very high resolution image;urban area;object based classification	This study evaluates and compares the performance of four machine learning classifiers—support vector machine (SVM), normal Bayes (NB), classification and regression tree (CART) and K nearest neighbor (KNN)—to classify very high resolution images, using an object-based classification procedure. In particular, we investigated how tuning parameters affect the classification accuracy with different training sample sizes. We found that: (1) SVM and NB were superior to CART and KNN, and both could achieve high classification accuracy (>90%); (2) the setting of tuning parameters greatly affected classification accuracy, particularly for the most commonly-used SVM classifier; the optimal values of tuning parameters might vary slightly with the size of training samples; (3) the size of training sample also greatly affected the classification accuracy, when the size of training sample was less than 125. Increasing the size of training samples generally led to the increase of classification accuracies for all four classifiers. In addition, NB and KNN were more sensitive to the sample sizes. This research provides insights into the selection of classifiers and the size of training samples. It also highlights the importance of the appropriate setting of tuning parameters for different machine learning classifiers and provides useful information for optimizing these parameters.	decision tree learning;image resolution;k-nearest neighbors algorithm;machine learning;naive bayes classifier;object-based language;support vector machine	Yuguo Qian;Weiqi Zhou;Jingli Yan;Weifeng Li;Lijian Han	2015	Remote Sensing	10.3390/rs70100153	computer science;machine learning;linear classifier;pattern recognition;data mining;structured support vector machine	ML	13.93213321947391	-42.58217576186881	36255
204ecae4b84e6aabc9bf969ab4358a3d1e5c2631	flow-sne: a new approach for flow cytometry clustering and visualization	manuals;kernel;biology;flow cytometry dataset flow sne flow cytometry clustering flow cytometry visualization multiple cellular marker expression cell type identification infectious disease immune system reflex automatic clustering technique;estimation;phenotypic signature;clustering;data visualization;2d visualization;clustering algorithms;pattern clustering cellular biophysics diseases laser applications in medicine;phenotypic signature 2d visualization clustering flow cytometry;sociology;flow cytometry;kernel estimation data visualization biology manuals clustering algorithms sociology	Flow cytometry is a technology by which the expression of multiple cellular markers are measured simultaneously for each cell. Analysis of the extracted cytometry dataset is invaluable for biologists in many applications such as identification of various cell types with specific phenotypic properties. Specifically, identification of rare subpopulation in presence of infectious diseases can reveal the effects of that disease on immune system reflex. In this paper, we propose a new automatic clustering technique to extract meaningful cell subtypes from the flow cytometry datasets. In contrast with other methods, our approach is able to visualize the dataset in 2D. Also, it is designed to easily handle very large flow cytometry datasets. We compared our method against others using three famous publicly available flow cytometry datasets. The results indicate a much better performance and an effective visualization.	cluster analysis;effective method;graphical model;interconnection;t-distributed stochastic neighbor embedding	Maziyar Baran Pouyan;Mehrdad Nourani	2015	2015 International Conference on Healthcare Informatics	10.1109/ICHI.2015.28	computer science;bioinformatics;data science;data mining	Visualization	4.794256247076524	-50.35855844596055	36261
2cb850d3965523f66f3fb9f9098b435beedd2692	lossless online bayesian bagging	online algorithm;dirichlet distribution;learning algorithm;classification tree;bayesian bootstrap;journal article	Bagging frequently improves the predictive performance of a model. An online version has recently been introduced, which attempts to gain the benefits of an online algorithm while approximating regular bagging. However, regular online bagging is an approximation to its batch counterpart and so is not lossless with respect to the bagging operation. By operating under the Bayesian paradigm, we introduce an online Bayesian version of bagging which is exactly equivalent to the batch Bayesian version, and thus when combined with a lossless learning algorithm gives a completely lossless online bagging algorithm. We also note that the Bayesian formulation resolves a theoretical problem with bagging, produces less variability in its estimates, and can improve predictive performance for smaller data sets.	approximation;bootstrap aggregating;lossless compression;online algorithm;programming paradigm;spatial variability	Herbert K. H. Lee;Merlise A. Clyde	2004	Journal of Machine Learning Research		dirichlet distribution;online algorithm;decision tree learning;computer science;machine learning;pattern recognition;data mining;mathematics	ML	17.26291243982803	-38.132141833697986	36267
da4e4f96cbee75385bbd3492dec57a668362980d	online consensus and agreement of phylogenetic trees	online algorithm;arbre phylogenetique;optimisation;consensus;long period;optimizacion;large dataset;heuristic method;bioinformatique;metodo heuristico;temps minimal;arbol filogenetico;simulation experiment;large scale;phylogenetic tree;consenso;optimality criteria;minimum time;optimization;methode heuristique;bioinformatica;biological data;tiempo minimo;bioinformatics	Computational heuristics are the primary methods for reconstruction of phylogenetic trees on large datasets. Most large-scale phylogenetic analyses produce numerous trees that are equivalent for some optimization criteria. Even using the best heuristics, it takes significant amount of time to obtain optimal trees in simulation experiments. When biological data are used, the score of the optimal tree is not known. As a result, the heuristics are either run for a fixed (long) period of time, or until some measure of a lack of improvement is achieved. It is unclear, though, what is a good criterion for measuring this lack of improvement. However, often it is useful to represent the collection of best trees so far in a compact way to allow scientists to monitor the reconstruction progress. Consensus and agreement trees are common such representations. Using existing static algorithms to produce these trees increases an already lengthy computational time substantially. In this paper we present efficient online algorithms for computing strict and majority consensi and the maximum agreement subtree.	computation;experiment;heuristic (computer science);mathematical optimization;online algorithm;online and offline;phylogenesis;phylogenetic tree;phylogenetics;simulation;time complexity;tree (data structure)	Tanya Y. Berger-Wolf	2004		10.1007/978-3-540-30219-3_30	biology;online algorithm;mathematical optimization;phylogenetic tree;consensus;biological data;computer science;bioinformatics;machine learning;tree rearrangement;data mining;mathematics;algorithm;statistics	Comp.	0.6310826855040932	-50.1097048334595	36286
d855082100eb913b01f3a335bf31117ff9bba52a	mining multiple satellite sensor data using collaborative clustering	libraries;groupware;pattern clustering;remote sensing data collaborative clustering satellite sensor data data mining multisource data;earth;sensor fusion data mining geophysics computing groupware pattern clustering remote sensing;collaborative clustering;collaboration;data mining;satellites collaboration hyperspectral sensors sensor phenomena and characterization data mining collaborative work earth remote sensing hyperspectral imaging minerals;satellite sensor data;geophysics computing;remote sensing data;remote sensing;satellites;earth observation;sensor fusion;multisource data;data models	In recent years, satellite sensor data have become easier to acquire. Several different satellite systems are now available and produce a large amount of data used for Earth observation. To better grasp the complexity of the Earth surface, it became usual to use different images from different satellites. However, it is generally difficult to predict the potential gain of using multisource satellite sensor data before actually acquiring the data. In this paper, we present a simulation approach to create different views of remote sensing sensor data according to different satellite characteristics. These different views are then used in a collaborative clustering approach to assess the interest of using these multisource data together. Experiments provide some insights on couple of satellite systems able to leverage the complementary of the sources.	cluster analysis;pixel;sensor;simulation	Germain Forestier;Cédric Wemmert;Pierre Gançarski;Jordi Inglada	2009	2009 IEEE International Conference on Data Mining Workshops	10.1109/ICDMW.2009.42	earth observation;data modeling;computer science;data science;data mining;sensor fusion;earth;satellite;collaboration	Robotics	0.4770175497300898	-37.172880669962026	36335
77f4896c3a67dea350ed79864068ea4d2e8cf187	prefixtreeespan: a pattern growth algorithm for mining embedded subtrees	extraction information;methode diviser pour regner;frequent pattern;analisis datos;information extraction;database;metodo dividir para vencer;base dato;data mining;pattern mining;data analysis;internet;fouille donnee;divide and conquer method;base de donnees;analyse donnee;information system;busca dato;divide and conquer;extraccion informacion;systeme information;sistema informacion	Frequent embedded subtree pattern mining is an important data mining problem with broad applications. In this paper, we propose a novel embedded subtree mining algorithm, called PrefixTreeESpan (i.e. Prefix-Treeprojected Embedded-Subtree pattern), which finds a subtree pattern by growing a frequent prefix-tree. Thus, using divide and conquer, mining local length-1 frequent subtree patterns in Prefix-Tree-Projected database recursively will lead to the complete set of frequent patterns. Different from Chopper and XSpanner [4], PrefixTreeESpan does not need a checking process. Our performance study shows that PrefixTreeESpan outperforms Apriori-like algorithm: TreeMiner [6], and pattern-growth algorithms :Chopper , XSpanner .	apriori algorithm;chopper (electronics);data mining;embedded system;hierarchical database model;recursion;tree (data structure);trie	Lei Zou;Yansheng Lu;Huaming Zhang;Rong Hu	2006		10.1007/11912873_51	divide and conquer algorithms;the internet;computer science;artificial intelligence;data mining;data analysis;information extraction;information system;algorithm	ML	-3.4046593365036704	-33.13747627647682	36343
025c5c7e2eb28807d2b1bde6ff02c294f7f949db	a new approach to classification with the least number of features	minimisation;pattern classification learning artificial intelligence minimisation;minimization;support vector machines;input variables;classification support feature machine feature selection zero norm minimisation;support feature machine;training;separating hyper plane;classification;sfm;machine learning;pattern classification;feature selection;learning artificial intelligence;linearly nonseparable datasets;zero norm minimisation;training support vector machines noise minimization machine learning input variables bioinformatics;noise;linearly nonseparable datasets classification support feature machine sfm feature selection zero norm minimisation separating hyper plane;bioinformatics	Recently, the so-called Support Feature Machine (SFM) was proposed as a novel approach to feature selection for classification, based on minimisation of the zero norm of a separating hyper plane. We propose an extension for linearly non-separable datasets that allows a direct trade-off between the number of misclassified data points and the number of dimensions. Results on toy examples as well as real-world datasets demonstrate that this method is able to identify relevant features very effectively.	data point;experiment;feature selection;iterative method;linear classifier;linear programming;linear separability;mathematical optimization;microarray;nonlinear system;randomness;relevance;statistical classification	Sascha Klement;Thomas Martinetz	2010	2010 Ninth International Conference on Machine Learning and Applications	10.1109/ICMLA.2010.28	support vector machine;minimisation;biological classification;computer science;noise;machine learning;pattern recognition;data mining;mathematics;feature selection	ML	21.483185826086547	-40.0992900129411	36408
737256b1e026ac0717d24dc13b363b993fe5748d	the genetic code as a function of multiple-valued logic over the field of complex numbers and its learning using multilayer neural network based on multi-valued neurons		"""It is shown in this paper that a model of multiplevalued logic over the field of complex numbers is the most appropriate for the representation of the genetic code as a multiple-valued function. The genetic code is considered as a partially defined multiple-valued function of three variables. The genetic code is the four-letter nucleic acid code, and it is translated into a 20-letter amino acid code from proteins (each of 20 amino acids is coded by the triplet of four nucleic acids). Thus, it is possible to consider the genetic code as a partially defined multiple-valued function of a 20-valued logic. Consideration of the genetic code within the proposed mathematical model makes it possible to learn the code using a multilayer neural network based on multi-valued neurons (MLMVN). MLMVN is a neural network with traditional feedforward architecture, but with a highly efficient derivativefree learning algorithm and higher functionality than the one of the traditional feedforward neural networks and a variety of kernel-based networks. It is shown that the genetic code multiple-valued function can be easily trained by a significantly * Based on """"The Genetic Code as a Multiple-Valued Function and its Implementation Using Multilayer Neural Network based on Multi-Valued Neurons """", by Igor Aizenberg and Claudio Moraga which appeared in The Proceedings of 37 International Symposium on MultipleValued Logic (ISMVL-2007), © 2007 IEEE IGOR AIZENBERG AND CLAUDIO MORAGA, JOURNAL OF MULTIPLE-VALUED LOGIC AND SOFT COMPUTING, NO 4-6, NOVEMBER 2007, PP. 605-618 smaller MLMVN in comparison with a classical feedforward neural network."""	artificial neural network;feedforward neural network;genetic algorithm;mathematical model;neuron;soft computing;triplet state	Igor N. Aizenberg;Claudio Moraga	2007	Multiple-Valued Logic and Soft Computing			ML	14.024697973842992	-27.38399563159749	36464
91d0e06c8c0d7219e9172e070b5f50ac7e1e747d	discovery of significant classification rules from incrementally inducted decision tree ensemble for diagnosis of disease	decision tree;ensemble method;classification rules;decision tree induction;incremental tree induction;cascading and sharing	Previous studies show that using significant classification rules to accomplish the classification task is suitable for bio-medical research. Discovery of many significant rules could be performed by using ensemble methods in decision tree induction. However, those traditional approaches are not useful for incremental task. In this paper, we use an ensemble method named Cascading and Sharing to derive many significant classification rules from incrementally inducted decision tree and improve the classifiers accuracy.	decision tree	Minghao Piao;Jong Bum Lee;Khalid E. K. Saeed;Keun Ho Ryu	2009		10.1007/978-3-642-03348-3_60	decision tree learning;computer science;machine learning;decision tree;pattern recognition;incremental decision tree;data mining;decision stump	ML	9.197697259084851	-39.478710112541165	36480
a57714f6df1f48773331d8509b6c44c2e5dfe370	swarm intelligence in semi-supervised classification		This Paper represents a literature review of Swarm intelligence algorithm in the area of semi-supervised classification. There are many research papers for applying swarm intelligence algorithms in the area of machine learning. Some algorithms of SI are applied in the area of ML either solely or hybrid with other ML algorithms. SI algorithms are also used for tuning parameters of ML algorithm, or as a backbone for ML algorithms. This paper introduces a brief literature review for applying swarm intelligence algorithms in the field of semi-supervised learning	algorithm;internet backbone;machine learning;semi-supervised learning;semiconductor industry;supervised learning;swarm intelligence	Shahira Shaaban Azab;Hesham Ahmed Hefny	2017	CoRR		supervised learning;swarm intelligence;unsupervised learning;machine learning;particle swarm optimization;pattern recognition;computer science;artificial intelligence	AI	8.525439234573854	-37.561448593375545	36492
5c68414f2ed7c91fc61c1b6bfc929d66536c124f	an evolutionary algorithm for column family schema optimization in hbase	statistical significance evolutionary algorithm column family schema optimization apache hbase column oriented nosql key value store hadoop distributed file system user queries zanox ag user queries;evolutionary computation;column family;layout;big data;column layout;hbase;statistical analysis data handling evolutionary computation parallel processing query processing sql;optimization layout conferences big data evolutionary computation genetic algorithms algorithm design and analysis;genetic algorithms;optimization;evolutionary algorithm;schema optimization;evolutionary algorithm hbase nosql column family column layout schema optimization;algorithm design and analysis;nosql;conferences	Apache HBase is a column-oriented NoSQL key-value store built on top of the Hadoop distributed file-system. Logically, columns in HBase are grouped into column families. Physically, all columns in one column family are stored in the same set of files. Therefore the division of column families is closely related to the response time for a specific row query. In this paper, one new Evolutionary Algorithm is designed and applied to find the optimum column family schema for the given user queries. The reading performance of the optimized column family schema is evaluated on a real dataset provided by ZANOX AG, which contains 2.6 million rows of aggregated tracking data and 1.3 million user queries. It is shown that by using the found optimized column family schema, the reading performance of HBase is improved with a statistical significance. User queries from a testing set show that the average response time is reduced by up to 72% compared to un-optimized column family schemas.	apache hbase;apache hadoop;attribute–value pair;column (database);column-oriented dbms;evolutionary algorithm;key-value database;nosql;response time (technology)	Fangzhou Yang;Dragan Milosevic;Jian Cao	2015	2015 IEEE First International Conference on Big Data Computing Service and Applications	10.1109/BigDataService.2015.20	computer science;theoretical computer science;column;data mining;database	DB	-3.9744629564795204	-37.72151384821238	36541
c5731e5653935e9eb0de51f6195aacdc10905ed5	attractor memory with self-organizing input	unsupervised learning;attracteur;distributed system;evaluation performance;hebbian learning;systeme reparti;memoire associative;procesamiento informacion;performance evaluation;neural networks;software prototyping;competitividad;technology;evaluacion prestacion;computer and information science;data processing;teknikvetenskap;intelligence artificielle;apprentissage non supervise;attractor;noise abatement;competitive learning;reduccion ruido;atractor;learning systems;computer architecture;natural sciences;sistema repartido;biomimetique;noise reduction;information processing;reduction bruit;competitiveness;datavetenskap datalogi;memory systems;autoorganizacion;associative memory;memoria asociativa;attractor neural network;artificial intelligence;completitud;self organization;receptive field;inteligencia artificial;computer science;completeness;reseau neuronal;traitement information;completude;competitivite;red neuronal;autoorganisation;apprentissage hebbien;biomimetics;neural network	We propose a neural network based autoassociative memory system for unsupervised learning. This system is intended to be an example of how a general information processing architecture, similar to that of neocortex, could be organized. The neural network has its units arranged into two separate groups called populations, one input and one hidden population. The units in the input population form receptive fields that sparsely projects onto the units of the hidden population. Competitive learning is used to train these forward projections. The hidden population implements an attractor memory. A back projection from the hidden to the input population is trained with a Hebbian learning rule. This system is capable of processing correlated and densely coded patterns, which regular attractor neural networks are very poor at. The system shows good performance on a number of typical attractor neural network tasks such as pattern completion, noise reduction, and prototype extraction.	artificial neural network;autoassociative memory;competitive learning;decorrelation;hebbian theory;information processing;learning rule;noise reduction;organizing (structure);population;preprocessor;prototype;unsupervised learning	Christopher Johansson;Anders Lansner	2006		10.1007/11613022_22	biomimetics;simulation;completeness;computer science;artificial intelligence;machine learning;noise reduction;competitive learning;receptive field;attractor;artificial neural network;technology	ML	11.186045535163215	-30.791141770208693	36554
bcad3bb1a23706c61f4b9999676b7b86a11538bc	transfer learning algorithms for image classification	electrical engineering and computer science;thesis	An ideal image classifier should be able to exploit complex high dimensional feature representations even when only a few labeled examples are available for training. To achieve this goal we develop transfer learning algorithms that: 1) Leverage unlabeled data annotated with meta-data and 2) Exploit labeled data from related categories. In the first part of this thesis we show how to use the structure learning framework (Ando and Zhang, 2005) to learn efficient image representations from unlabeled images annotated with meta-data. In the second part we present a joint sparsity transfer algorithm for image classification. Our algorithm is based on the observation that related categories might be learnable using only a small subset of shared relevant features. To find these features we propose to train classifiers jointly with a shared regularization penalty that minimizes the total number of features involved in the approximation. To solve the joint sparse approximation problem we develop an optimization algorithm whose time and memory complexity is O(n log n) with n being the number of parameters of the joint model. We conduct experiments on news-topic and keyword prediction image classification tasks. We test our method in two settings: a transfer learning and multitask learning setting and show that in both cases leveraging knowledge from related categories can improve performance when training data per category is scarce. Furthermore, our results demonstrate that our model can successfully recover jointly sparse solutions. Thesis Supervisor: Michael Collins Title: Associate Professor Thesis Supervisor: Trevor Darrell Title: Associate Professor	algorithm;computer vision;machine learning	Ariadna Quattoni	2009			semi-supervised learning;computer science;artificial intelligence;machine learning;pattern recognition	ML	23.774256814779683	-45.53241156619502	36601
25fc42760413478a1d6c8396a0f3327d1e97f59b	bayesian convolutional neural networks		We introduce Bayesian Convolutional Neural Networks (BayesCNNs), a variant of Convolutional Neural Networks (CNNs) which is built upon Bayes by Backprop. We demonstrate how this novel reliable variational inference method can serve as a fundamental construct for various network architectures. On multiple datasets in supervised learning settings (MNIST, CIFAR-10, CIFAR-100, and STL-10), our proposed variational inference method achieves performances equivalent to frequentist inference in identical architectures, while a measurement for uncertainties and a regularisation are incorporated naturally. In the past, Bayes by Backprop has been successfully implemented in feedforward and recurrent neural networks, but not in convolutional ones. This work symbolises the extension of Bayesian neural networks which encompasses all three aforementioned types of network architectures now.	artificial neural network;backpropagation;bayesian network;convolutional neural network;feedforward neural network;mnist database;neural networks;performance;recurrent neural network;supervised learning;variational principle	Felix Laumann;Kumar Shridhar;Adrian Llopart Maurin	2018	CoRR		machine learning;supervised learning;convolutional neural network;artificial neural network;mathematics;recurrent neural network;bayes' theorem;inference;mnist database;frequentist inference;artificial intelligence	ML	21.338798216208207	-34.537846423926794	36625
fc22314d3cfdbb15e64bca0e854083f4b9246882	sample subset optimization for classifying imbalanced biological data	data;biology;sampling;optimization	Data in many biological problems are often compounded by imbalanced class distribution. That is, the positive examples may largely outnumbered by the negative examples. Many classification algorithms such as support vector machine (SVM) are sensitive to data with imbalanced class distribution, and result in a suboptimal classification. It is desirable to compensate the imbalance effect in model training for more accurate classification. In this study, we propose a sample subset optimization technique for classifying biological data with moderate and extremely high imbalanced class distributions. By using this optimization technique with an ensemble of SVMs, we build multiple roughly balanced SVM base classifiers, each trained on an optimized sample subset. The experimental results demonstrate that the ensemble of SVMs created by our sample subset optimization technique can achieve higher area under the ROC curve (AUC) value than popular sampling approaches such as random over-/under-sampling; SMOTE sampling, and those in widely used ensemble approaches such as bagging and boosting.	algorithm;bioinformatics;ensemble learning;mathematical optimization;receiver operating characteristic;sampling (signal processing);support vector machine	Pengyi Yang;Zili Zhang;Bing Bing Zhou;Albert Y. Zomaya	2011		10.1007/978-3-642-20847-8_28	sampling;computer science;machine learning;pattern recognition;data mining;mathematics;statistics;data	ML	13.597232616217866	-42.03844647615742	36630
1439d945f1d4f154e28bb611b7858fbe034460e3	introducing roc curves as error measure functions: a new approach to train ann-based biomedical data classifiers	receiver operator characteristic;root mean square error;machine learning classifiers;simulated annealing;roc curves;data analysis;artificial neural networks;machine learning;roc curve;biomedical data;training algorithm;artificial neural network	This paper explores the usage of the area (Az) under the Receiver Operating Characteristic (ROC) curve as error measure to guide the training process to build machine learning ANN-based classifiers for biomedical data analysis. Error measures (like root mean square error, RMS) are used to guide training algorithms measuring how far solutions are from the ideal classification, whereas it is well known that optimal classification rates do not necessarily yield to optimal Az’s. Our hypothesis is that Az error measures can guide existing training algorithms to obtain better Az’s than other error measures. This was tested after training 280 different configurations of ANNbased classifiers, with simulated annealing, using five biomedical binary datasets from the UCI machine learning repository with different test/train data splits. Each ANN configuration was trained both using the Az and RMS based error measures. In average Az was improved in 7.98% in testing data (9.32% for training data) when using 70% of the datasets elements for training. Further analysis reveals interesting patterns (Az improvement is greater when Az are lower). These results encourage us to further explore the usage of Az based error measures in training methods for classifiers in a more generalized manner.	algorithm;artificial neural network;audio power;biological anthropology;experiment;machine learning;mean squared error;real computation;receiver operating characteristic;simulated annealing	Raúl Ramos-Pollán;Miguel Ángel Guevara-López;Eugénio C. Oliveira	2010		10.1007/978-3-642-16687-7_68	computer science;machine learning;pattern recognition;data mining;receiver operating characteristic;artificial neural network;statistics	ML	11.35407271988799	-38.91568663152517	36631
b1abdbae832f11000f0ee7ee3846870ec898a8b7	rethinking the learning of belief network probabilities	learning algorithm;probabilistic estimation;probability;learning;informing science;prior knowledge;statistical models;statistical model;artificial intelligent;probabilistic model;model error;probability theory;statistics;artificial intelligence;99 mathematics computers information science management law miscellaneous;conditional probability;belief network;neural network;knowledge base;knowledge discovery;mathematics computers information science management law miscellaneous	Belief networks are a powerful tool for knowledge discovery that provide concise, understandable probabilistic models of data. There are methods grounded in probability theory to incrementally update the relationships described by the belief network when new information is seen, to perform complex inferences over any set of variables in the data, to incorporate domain expertise and prior knowledge into the model, and to automatically learn the model from data. This paper concentrates on part of the belief network induction problem, that of learning the quantitative structure (the conditional probabilities), given the qualitative structure. In particular, the current practice of rote learning the probabilities in belief networks can be significantly improved upon. We advance the idea of applying any learning algorithm to the task of conditional probability learning in belief networks, discuss potential benefits, and show results of applying neural networks and other algorithms to a medium sized car insurance belief network. The results demonstrate from 10 to 100% improvements in model error rates over the current approaches.	algorithm;artificial neural network;bayesian network	Ron Musick	1996			statistical model;knowledge base;computer science;belief structure;artificial intelligence;machine learning;data mining;knowledge extraction;statistics	ML	23.100672793581438	-27.53188940983638	36641
209c0f0799c54ac843857255ffc5c6b9154fe07b	rule-based back propagation neural networks for various precision rough set presented kansei knowledge prediction: a case study on shoe product form features extraction		Nonlinear operators for KANSEI evaluation dataset were significantly developed such as uncertainty reason techniques including rough set, fuzzy set and neural networks. In order to extract more accurate KANSEI knowledge, rule-based presentation was concluded a promising way in KANSEI engineering research. In the present work, variable precision rough set was applied in rule-based system to reduce the complexity of the knowledge database from normal item dataset to high frequent rule set. In addition, evidence theory’s reliability indices, namely the support and confidence for rule-based knowledge presentation, were proposed by using back propagation neural network with Bayesian regularization algorithm. The proposed method was applied in shoes KANSEI evaluation system; for a certain KANSEI adjective, the key form features of products were predicted. Some similar algorithms such as Levenberg–Marquardt and scaled conjugate gradient were also discussed and compared to establish the effectiveness of the proposed approach. The experimental results established the effectiveness and feasibility of the proposed algorithms customized for shoe industry, where the proposed back propagation neural network/Bayesian regularization approach achieved superior performance compared to the other algorithms in terms of the performance, gradient, Mu, Effective number of parameter, and the sum square parameter in KANSEI support and confidence time series prediction.	artificial neural network;backpropagation;bayesian network;bayesian programming;conjugate gradient method;fuzzy set;image scaling;inference engine;levenberg–marquardt algorithm;linear programming;logic programming;mathematical optimization;nonlinear system;rough set;rule-based system;shoes;software propagation;time series	Zairan Li;Kai Shi;Nilanjan Dey;Amira S. Ashour;Dan Wang;Valentina Emilia Balas;Pamela McCauley;Fuqian Shi	2016	Neural Computing and Applications	10.1007/s00521-016-2707-8	artificial intelligence;machine learning;data mining	AI	2.8359672112460834	-25.817837309050557	36655
9bc912be281e2e9b6a31b166651c551381fdc624	escaping plato's cave using adversarial training: 3d shape from unstructured 2d image collections		We develop PLATONICGAN to discover 3D structure of an object class from an unstructured collection of 2D images. The key idea is to learn a deep neural network that generates 3D shapes that are never objectionable to a discriminator looking only at its 2D projections, i. e., renderings of the generated volumes. Using such a 2D instead of a 3D discriminator allows tapping into massive 2D image collections instead of relying on much smaller 3D data sets. To establish constraints between 2D image observation and their 3D interpretation we suggest a family of rendering layers that are effectively back-propagatable. This family includes visual hull, absorption-only (akin to x-ray), and emission-absorption (that can resolve occlusion if multiple 3D points project to the same 2D pixel). These layers are studied both on synthetic and real data in an application to reconstruct of 3D shape from 2D images.	2d computer graphics;3d reconstruction;artificial neural network;deep learning;discriminator;filter (signal processing);gradient;graphics processing unit;map;pixel;robotics;shading;synthetic data;tomography;variable shadowing;visual hull;volume rendering	Philipp Henzler;Niloy Jyoti Mitra;Tobias Ritschel	2018	CoRR			ML	24.527552225111005	-49.33336730227961	36691
91810774ecebf1475b433727693a7f9dbc027d86	incorporating domain knowledge into a min-max modular support vector machine for protein subcellular localization	domain knowledge;decomposition method;learning methods;protein subcellular localization;support vector machine	As biological sequences and various annotation data grow rapidly in public databases, the classification problems become larger and more complicated. New classifier designs are necessitated. Besides, how to incorporate some explicit domain knowledge into learning methods is also a big issue. In this paper, we adopt a modular classifier, min-max modular support vector machine (M3-SVM) to solve protein subcellular localization problem, and use the domain knowledge of taxonomy information to guide the task decomposition. Experimental results show that M3-SVM can maintain the overall accuracy and improve location average accuracy compared with traditional SVMs. The taxonomy decomposition is superior to other decomposition methods on a majority of the classes. The results also demonstrate a speedup on training time of M3-SVM compared with traditional SVMs.	protein subcellular localization prediction;support vector machine	Yang Yang;Bao-Liang Lu	2007		10.1007/978-3-540-69162-4_86	support vector machine;decomposition method;computer science;artificial intelligence;machine learning;pattern recognition;data mining;domain knowledge	ML	11.616455882139775	-40.18512455790706	36724
d38c9eac1b7df3b1a79271a7e71fdaae40cae842	active learning for level set estimation	level set estimation;autonomous monitoring;algal population;sample complexity;threshold level;gaussian process;gp-derived confidence bound;target function;active learning;geolocating network latency;classification problem;unknown function	Many information gathering problems require determining the set of points, for which an unknown function takes value above or below some given threshold level. As a concrete example, in the context of environmental monitoring of Lake Zurich we would like to estimate the regions of the lake where the concentration of chlorophyll or algae is greater than some critical value, which would serve as an indicator of algal bloom phenomena. A critical factor in such applications is the high cost in terms of time, baery power, etc. that is associated with each measurement, therefore it is important to be careful about selecting “informative” locations to sample, in order to reduce the total sampling effort required. We formalize the task of level set estimation as a classification problem with sequential measurements, where the unknown function is modeled as a sample from a Gaussian process (GP). We propose LSE, an active learning algorithm that guides both sampling and classification based on GP-derived confidence bounds, and provide theoretical guarantees about its sample complexity. Furthermore, we extend LSE and its theory to two more natural seings: (1) where the threshold level is implicitly defined as a percentage of the (unknown) maximum of the target function and (2) where samples are selected in batches. Based on the laer extension we also propose a simple path planning algorithm. We evaluate the effectiveness of our proposed methods on two problems of practical interest, namely the aforementioned autonomous monitoring of algal populations in Lake Zurich and geolocating network latency.	algorithm;autonomous robot;gaussian process;integrated circuit layout design protection;international joint conference on artificial intelligence;population;regular expression;sample complexity;sampling (signal processing)	Alkis Gotovos;Nathalie Casati;Gregory Hitz;Andreas Krause	2013			mathematical optimization;artificial intelligence;machine learning;data mining;mathematics;statistics	AI	22.508038744206104	-28.577613752092034	36758
a98e91f05cacc58feaa96fffae59dec197d75c39	genetic algorithms and sensitivity analysis applied to select inputs of a multi-layer perceptron for the prediction of air pollutant time-series	time series forecasting;analisis sensibilidad;optimisation;modelo prevision;pollutant;algorithm analysis;optimizacion;multilayer perceptrons;contaminante;intelligence artificielle;polluant;time series;algoritmo genetico;forecast model;perceptron multicouche;red multinivel;sensitivity analysis;serie temporelle;serie temporal;algorithme genetique;utilisabilite;analyse sensibilite;input selection;artificial intelligence;genetic algorithm;genetic algorithms;multi layer perceptron;optimization;analyse algorithme;inteligencia artificial;multilayer network;usabilidad;reseau multicouche;reseau neuronal;usability;air pollutants;red neuronal;analisis algoritmo;neural network;modele prevision	The aim of this paper was to evaluate genetic algorithms (GA) and sensitivity analysis (SA) for selecting inputs of a multi-layer perceptron model (MLP) applied to forecast time-series of urban air pollutant. The main objective was to compare usability and efficiency of the methods. The results in general showed that the methods based on the SA and GA can be used efficiently to select relevant variables and thus, to enhance the performance of MLP.	feature selection;finnish meteorological institute;genetic algorithm;memory-level parallelism;multilayer perceptron;numerical analysis;numerical weather prediction;performance;powera;quad flat no-leads package;software release life cycle;time series;usability	Harri Niska;Mikko Heikkinen;Mikko Kolehmainen	2006		10.1007/11875581_27	genetic algorithm;computer science;artificial intelligence;machine learning;time series;operations research;artificial neural network;statistics	AI	9.662733078687372	-24.417748143308813	36761
259c2a70ea62a348dcb56682f4287713a8dfde85	argument-based machine learning.	knowledge intensive learning;argumentacion;argumentation;sistema experto;learning algorithm;intelligence artificielle;algorithme apprentissage;aprendizaje por ejemplos;rule learning;learning by example;machine learning;background knowledge;learning through arguments;artificial intelligence;inteligencia artificial;systeme expert;algoritmo aprendizaje;apprentissage a partir d exemple;expert system	The Thesis presents a novel approach to machine learning, called ABML (argument based machine learning). This approach combines machine learning from examples with some concepts from the field of defeasible argumentation, where arguments are used together with learning examples by learning methods in the induction of a hypothesis. An argument represents a relation between the class value of a particular learning example and its attributes and can be regarded as a partial explanation of this example. We require that the theory induced from the examples explains the examples in terms of the given arguments. Thus arguments constrain the combinatorial search among possible hypotheses, and also direct the search towards hypotheses that are more comprehensible in the light of expert’s background knowledge. Arguments are usually provided by domain experts. One of the main differences between ABML and other knowledge-intensive learning methods is in the way the knowledge is elicited from these experts. Other methods require general domain knowledge, that is knowledge valid for the entire domain. The problem with this is the difficulty that experts face when they try to articulate their global domain knowledge. On the other hand, as arguments contain knowledge specific only to certain situations, they need to provide only local knowledge for the specific examples. Experiments with ABML and other empirical observations show that experts have significantly less problems while expressing such local knowledge. Furthermore, we define the ABML loop that iteratively selects critical learning examples, namely examples that could not be explained by the current hypothesis, which are then shown to domain experts. Using this loop, the burden that lies on experts is further reduced (only some examples need to be explained) and only relevant knowledge is obtained (difficult examples). We implemented the ABCN2 algorithm, an argument-based extension of the rule learning algorithm CN2. The basic version of ABCN2 ensures that rules classifying argumented examples will contain the reasons of the given arguments in their condition part. We furthermore improved the basic algorithm with a new method for evaluation of rules, called extreme value correction (EVC), that reduces the optimism of evaluation measures due to the large number of rules tested and evaluated during the learning process (known as the multiple comparison procedures problem). This feature is critical for ABCN2, since arguments given to different examples have different number of reasons and therefore differently constrain the space for different rules. Moreover, as shown in the dissertation, using this method in CN2 (without arguments) results in significantly more accurate models as compared to the original	algorithmic efficiency;cn2 algorithm;combinatorial search;experiment;inductive reasoning;machine learning;maxima and minima;norm (social);selection (genetic algorithm);theory	Martin Mozina;Jure Zabkar;Ivan Bratko	2007	Artif. Intell.	10.1016/j.artint.2007.04.007	computer science;artificial intelligence;machine learning;argumentation theory;stability;expert system;active learning;algorithm	AI	8.10074386480271	-31.858400649595396	36762
df942aac9c080da61fbfe7ca045addead6776874	effect of pre-processing methods on microarray-based svm classifiers in affymetrix genechips	cancer microarray datasets;kernel support vector machines cancer polynomials tumors probes gene expression;biology computing;kernel;support vector machine preprocessing methods microarray based svm classifiers affymetrix genechips affymetrix high oligonucleotide expression arrays high throughput assessment gene expression microarray preprocessing procedures expression based phenotype classification cancer microarray datasets;support vector machines;cancer;affymetrix high oligonucleotide expression arrays;probes;polynomials;genetics;gene expression;radial basis function;support vector machines biology computing genetics pattern classification;pattern classification;tumors;preprocessing methods;differentially expressed gene;support vector machine;microarray based svm classifiers;high throughput;expression based phenotype classification;microarray preprocessing procedures;high throughput assessment;affymetrix genechips	Affymetrix High Oligonucleotide expression arrays are widely used for the high-throughput assessment of gene expression of thousands of genes simultaneously. Although disputed by several authors, there are non-biological variations and systematic biases that must be removed as much as possible through the pre-processing step before an absolute expression level for every gene is assessed. It is important to evaluate microarray pre-processing procedures not only to the detection of differentially expressed genes, but also to classification, since a major use of microarrays is the expression-based phenotype classification. Thus, in this paper, we use several cancer microarray datasets to assess the influence of five different pre-processing methods in Support Vector Machine-based classification methodologies with different kernels: linear, Radial Basis Functions (RBFs) and polynomial.	dna microarray;high-throughput computing;polynomial;preprocessor;radial (radio);radial basis function;support vector machine;throughput	J. P. Florido;Héctor Pomares;Ignacio Rojas;José Miguel Urquiza Ortiz;Luis Javier Herrera;M. Gonzalo Claros	2010	The 2010 International Joint Conference on Neural Networks (IJCNN)	10.1109/IJCNN.2010.5596308	support vector machine;computer science;bioinformatics;machine learning;pattern recognition;data mining;microarray databases	Comp.	8.205034095941855	-50.4426472805629	36784
e7c568546ffb7b24255f8311c99e635f0f2829fd	a symbolic interpretation for back-propagation networks	evaluation performance;sistema experto;architecture systeme;performance evaluation;connectionism;conexionismo;evaluacion prestacion;intelligence artificielle;backpropagation;connexionnisme;retropropagation;back propagation network;artificial intelligence;arquitectura sistema;inteligencia artificial;systeme expert;reseau neuronal;system architecture;red neuronal;neural network;expert system	Abstract#R##N##R##N#Two main problems for the neural network (NN) paradigm are discussed: the output value interpretation and the symbolic content of the connection matrix. In this article, we construct a solution for a very common architecture of pattern associators: the backpropagation networks. First, we show how Zadeh's possibility theory brings a formal structure to the output interpretation. Properties and practical applications of this theory are developed. Second, a symbolic interpretation for the connection matrix is proposed by designing of an algorithm. By accepting the NN training examples as input this algorithm produces a set of implication rules. These rules accurately model the NN behavior. Moreover, they allow to understand it, especially in the cases of generalization or interference.	backpropagation;software propagation	P. Magrez;A. Rousseau	1992	Int. J. Intell. Syst.	10.1002/int.4550070404	connectionism;computer science;artificial intelligence;backpropagation;machine learning;expert system;algorithm	ML	8.596623100760539	-29.734460762928425	36799
cef9e528ff7fc8b3c7ed6fc0147c4db207bbe6df	robust quantization for general similarity search		"""The recent years have witnessed the emerging of vector quantization (VQ) techniques for efficient similarity search. VQ partitions the feature space into a set of codewords and encodes data points as integer indices using the codewords. Then the distance between data points can be efficiently approximated by simple memory lookup operations. By the compact quantization, the storage cost, and searching complexity are significantly reduced, thereby facilitating efficient large-scale similarity search. However, the performance of several celebrated VQ approaches degrades significantly when dealing with noisy data. In addition, it can barely facilitate a wide range of applications as the distortion measurement only limits to <inline-formula> <tex-math notation=""""LaTeX"""">$\ell _{2}$ </tex-math></inline-formula> <italic>norm</italic>. To address the shortcomings of the squared Euclidean (<inline-formula> <tex-math notation=""""LaTeX"""">$\ell _{2,2}$ </tex-math></inline-formula> norm) loss function employed by the VQ approaches, in this paper, we propose a novel robust and general VQ framework, named RGVQ, to enhance both robustness and generalization of VQ approaches. Specifically, a <inline-formula> <tex-math notation=""""LaTeX"""">$\ell _{p,q}$ </tex-math></inline-formula>-norm loss function is proposed to conduct the <inline-formula> <tex-math notation=""""LaTeX"""">$\ell _{p}$ </tex-math></inline-formula>-norm similarity search, rather than the <inline-formula> <tex-math notation=""""LaTeX"""">$\ell _{2}$ </tex-math></inline-formula> norm search, and the <inline-formula> <tex-math notation=""""LaTeX"""">$q$ </tex-math></inline-formula>-th order loss is used to enhance the robustness. Despite the fact that changing the loss function to <inline-formula> <tex-math notation=""""LaTeX"""">$\ell _{p,q}$ </tex-math></inline-formula> norm makes VQ approaches more robust and generic, it brings us a challenge that a non-smooth and non-convex <italic>orthogonality constrained</italic> <inline-formula> <tex-math notation=""""LaTeX"""">$\ell _{p,q}$ </tex-math></inline-formula>-<italic>norm function</italic> has to be minimized. To solve this problem, we propose a novel and efficient optimization scheme and specify it to VQ approaches and theoretically prove its convergence. Extensive experiments on benchmark data sets demonstrate that the proposed RGVQ is better than the original VQ for several approaches, especially when searching similarity in noisy data."""	approximation algorithm;benchmark (computing);code word;convergence (action);convex optimization;data point;distortion;experiment;feature vector;generalization (psychology);generic drugs;hl7publishingsubsection <operations>;hearing loss, high-frequency;image retrieval;integer (number);lookup table;loss function;mathematical optimization;maxima and minima;name;optimization problem;promotion (action);request - action;sensorineural hearing loss (disorder);signal-to-noise ratio;similarity search;vector quantization;benefit	Yuchen Guo;Guiguang Ding;Jungong Han	2018	IEEE Transactions on Image Processing	10.1109/TIP.2017.2766445	robustness (computer science);square (algebra);quantization (signal processing);vector quantization;mathematics;mathematical optimization;feature vector;integer;nearest neighbor search;orthogonality	ML	19.714148844778894	-46.3347337535909	36839
bea3694118ec72c47f3b6f890ff7c7a553298a28	data-driven models for fault detection using kernel pca: a water distribution system case study	kernel pca;fault detection;machine learning	Kernel Principal Component Analysis (KPCA), an example of machine learning, can be considered a non-linear extension of the PCA method. While various applications of KPCA are known, this paper explores the possibility to use it for building a data-driven model of a non-linear system—the water distribution system of the Chojnice town (Poland). This model is utilised for fault detection with the emphasis on water leakage detection. A systematic description of the system’s framework is followed by evaluation of its performance. Simulations prove that the presented approach is both flexible and efficient.	computer simulation;decision boundary;experiment;fault detection and isolation;kernel principal component analysis;linear system;machine learning;nonlinear system;novelty detection;sensitivity and specificity;spectral leakage	Adam Nowicki;Michal Grochowski;Kazimierz Duzinkiewicz	2012	Applied Mathematics and Computer Science		kernel principal component analysis;computer science;engineering;machine learning;pattern recognition;data mining;fault detection and isolation	ML	23.411881930765677	-24.629218281601055	36848
e3c608c5ebf316d56fbea2eb5af3c635f13de708	association analysis techniques for analyzing complex biological data sets	preprocessing protein interaction networks association analysis techniques biological data sets data mining bioinformatics;genomics;itemsets;data mining;proteins bioinformatics data mining;data analysis itemsets pattern analysis bioinformatics data mining proteins biology computer science data engineering application software;proteins;biological data;association analysis techniques;association analysis;biological data sets;algorithm design and analysis;preprocessing protein interaction networks;protein interaction network;bioinformatics	Association analysis is one of the most popular analysis paradigms in data mining. In this paper, we present different types of association patterns and discuss some of their applications in bioinformatics. We present a case study showing the usefulness of association analysis-based techniques for pre-processing protein interaction networks. Finally, we discuss some of the challenges that need to be addressed to make association analysis-based techniques more applicable for bioinformatics.	bioinformatics;data mining;preprocessor	Gaurav Pandey;Gowtham Atluri;Gang Fang;Rohit Gupta;Michael Steinbach;Vipin Kumar	2009	2009 IEEE International Workshop on Genomic Signal Processing and Statistics	10.1109/GENSIPS.2009.5174378	biology;algorithm design;genomics;biological data;computer science;bioinformatics;data science;genetic association;data mining	Visualization	4.972597821540952	-48.42958438211474	36861
147f60a20552024c2c3c93eed1645864bec4f896	som-based novelty detection using novel data	unsupervised learning;tabla codificacion;supervised learning;nouveaute;incertidumbre;uncertainty;classification supervisee;supervised classification;novelty;novedad;novelty detection;intelligence artificielle;apprentissage non supervise;cuantificacion vectorial;vector quantization;codebook;table codage;clasificacion supervisada;autoorganizacion;artificial intelligence;self organization;self organized map;incertitude;inteligencia artificial;classification accuracy;autoorganisation;learning vector quantization;quantification vectorielle	Novelty detection involves identifying novel patterns. They are not usually available during training. Even if they are, the data quantity imbalance leads to a low classification accuracy when a supervised learning scheme is employed. Thus, an unsupervised learning scheme is often employed ignoring those few novel patterns. In this paper, we propose two ways to make use of the few available novel patterns. First, a scheme to determine local thresholds for the Self Organizing Map boundary is proposed. Second, a modification of the Learning Vector Quantization learning rule is proposed so that allows one to keep codebook vectors as far from novel patterns as possible. Experimental results are	codebook;learning rule;learning vector quantization;novelty detection;self-organizing map;supervised learning;unsupervised learning	Hyoungjoo Lee;Sungzoon Cho	2005		10.1007/11508069_47	semi-supervised learning;unsupervised learning;self-organization;uncertainty;learning vector quantization;computer science;artificial intelligence;machine learning;codebook;pattern recognition;supervised learning;vector quantization	ML	10.095058489814667	-32.55745984532934	36869
9b14a35ab653d550203081950d3077ca251890ab	robust similarity measures for mobile object trajectories	time warp;distance function;robustness mobile computing degradation space technology spatiotemporal phenomena databases engineering profession indexing global positioning system data analysis;mobile object;matching function;temporal databases;synthetic data;noise robust similarity measures mobile object trajectories similarity analysis spatio temporal trajectories outliers euclidean distance time warping distance nonmetric distance functions longest common subsequence sigmoidal matching function l sub p norms;similarity measure;temporal databases visual databases;visual databases	We investigate techniques for similarity analysis of spatio-temporal trajectories for mobile objects. Such kind of data may contain a great amount of outliers, which degrades the performance of Euclidean and Time Warping Distance. Therefore, here we propose the use of non-metric distance functions based on the Longest Common Subsequence (LCSS), in conjunction with a sigmoidal matching function. Finally, we compare these new methods to various Lp Norms and also to Time Warping distance (for real and synthetic data) and we present experimental results that validate the accuracy and efficiency of our approach, especially under the strong presence of noise.	cluster analysis;experiment;image noise;longest common subsequence problem;sigmoid function;similarity measure;social inequality;synthetic data	Michail Vlachos;Dimitrios Gunopulos;George Kollios	2002		10.1109/DEXA.2002.1045983	metric;machine learning;pattern recognition;data mining;database;temporal database;synthetic data	DB	-3.4981968287944984	-42.009905279943005	36882
eea37bd18b0dee4fcf5967039afd2a1a6da2cab3	the speech recogniton system based on structure equivalent fuzzy rbf neural network	gradient descent method;fuzzy theory;fuzzy neural nets;fuzzy reasoning;fuzzy rules;training;vocabulary;speech;speech recognition fuzzy neural nets fuzzy reasoning fuzzy set theory gradient methods learning artificial intelligence radial basis function networks signal classification;structure equivalent fuzzy rbf neural network;fuzzy set theory;structure equivalence;radial basis function networks;speech recognition fuzzy rbf neural network structure equivalence;classification information;artificial neural networks;radial basis function;speech recognition system;rbf neural network;signal classification;classification algorithms;membership function;fuzzy rbf neural network;gradient methods;speech recognition;network parameter learning;network reasoning;fuzzy theory speech recognition system structure equivalent fuzzy rbf neural network radial basis function network parameter learning gradient descent method network reasoning fuzzy rule number classification information;learning artificial intelligence;speech recognition fuzzy neural networks fuzzy systems neural networks clustering algorithms vocabulary robustness educational institutions inference algorithms clustering methods;fuzzy systems;fuzzy system;fuzzy rule number;neural network	A structure equivalent fuzzy radial basis function (FRBF) neural network with five layers is proposed in this paper. A two stage algorithm for the parameters learning of the network is presented, which first determine the center value and width of the membership function according to the classification information of training samples, and then adjusts the weights between the fourth layer and the fifth layer by the gradient descent method. When the input data dimension number is large, the reasoning of conventional fuzzy system often cannot correctly work because the degree of each rule become too small and sometimes they cause underflow. The network reasoning can correctly work by adding a compensated factor on membership function. The structure equivalent FRBF neural network was used in speech recognition system. It is able to determine the fuzzy rule numbers according to the vocabulary to be recognized. The experimental results showed that the proposed structure equivalent FRBF neural network has demonstrated superior performance compared to radial basis function (RBF) neural network, such as higher recognition and better robustness.	algorithm;arithmetic underflow;artificial neural network;fuzzy control system;fuzzy rule;gradient descent;radial (radio);radial basis function;speech recognition;vocabulary	Xueying Zhang;Gaoyun Li	2009	2009 IEEE International Symposium on Circuits and Systems	10.1109/ISCAS.2009.5118450	gradient descent;radial basis function;membership function;computer science;speech;artificial intelligence;neuro-fuzzy;machine learning;pattern recognition;time delay neural network;mathematics;fuzzy set;artificial neural network;fuzzy control system	Vision	5.928321645181463	-27.799351732746917	36911
556fc1142c755911327e58ad8c24949e5e8883eb	logit pairing methods can fool gradient-based attacks		Recently, Kannan et al. [2018] proposed several logit regularization methods to improve the adversarial robustness of classifiers. We show that the computationally fast methods they propose – Clean Logit Pairing (CLP) and Logit Squeezing (LSQ) – just make the gradient-based optimization problem of crafting adversarial examples harder without providing actual robustness. We find that Adversarial Logit Pairing (ALP) may indeed provide robustness against adversarial examples, especially when combined with adversarial training, and we examine it in a variety of settings. However, the increase in adversarial accuracy is much smaller than previously claimed. Finally, our results suggest that the evaluation against an iterative PGD attack relies heavily on the parameters used and may result in false conclusions regarding robustness of a model.	adversary (cryptography);gradient;iterative method;manifold regularization;mathematical optimization;multinomial logistic regression;optimization problem	Seifeldin T Sadek;Maksym Andriushchenko;Thomas Alexander Trost;Matthias Hein;Dietrich Klakow	2018	CoRR		logit;machine learning;robustness (computer science);mathematical optimization;adversarial system;regularization (mathematics);artificial intelligence;mathematics;optimization problem;pairing	AI	18.977866505230974	-50.70347127622231	36932
28519b82ee3dcadb88cbcf4f3f149a7b683e623b	a convergence rate analysis for logitboost, mart and their variant		LogitBoost, MART and their variant can be viewed as additive tree regression using logistic loss and boosting style optimization. We analyze their convergence rates based on a new weak learnability formulation. We show that it has O( 1 T ) rate when using gradient descent only, while a linear rate is achieved when using Newton descent. Moreover, introducing Newton descent when growing the trees, as LogitBoost does, leads to a faster linear rate. Empirical results on UCI datasets support our analysis.	flat rate;gradient descent;learnability;logitboost;loss functions for classification;mathematical optimization;newton;newton's method;utility functions on indivisible goods	Peter P Sun;Tong Zhang;Jie Zhou	2014			artificial intelligence;machine learning;learnability;rate of convergence;boosting (machine learning);pattern recognition;gradient descent;logitboost;mathematical optimization;mathematics	ML	22.084374266531718	-34.70074389452045	36990
03e2f687f9c02a8bad1a17caf1ce7d4acc18b7ba	the cart decision tree for mining data streams	data steam;cart;decision tree;gini index;kik;iisi;gaussian approximation	One of the most popular tools for mining data streams are decision trees. In this paper we propose a new algorithm, which is based on the commonly known CART algorithm. The most important task in constructing decision trees for data streams is to determine the best attribute to make a split in the considered node. To solve this problem we apply the Gaussian approximation. The presented algorithm allows to obtain high accuracy of classification, with a short processing time. The main result of this paper is the theorem showing that the best attribute computed in considered node according to the available data sample is the same, with some high probability, as the attribute derived from the whole data stream.	algorithm;decision tree learning;polynomial-time approximation scheme	Leszek Rutkowski;Maciej Jaworski;Lena Pietruczuk;Piotr Duda	2014	Inf. Sci.	10.1016/j.ins.2013.12.060	mathematical optimization;decision tree learning;computer science;machine learning;decision tree;pattern recognition;incremental decision tree;data mining;statistics	DB	-1.7195931186997555	-36.546824021044934	37047
9061bd138ba0d33972b9ae25a0d1237bb82b4648	learning with hierarchical gaussian kernels		We investigate iterated compositions of weighted sums of Gaussian kernels and provide an interpretation of the construction that shows some similarities with the architectures of deep neural networks. On the theoretical side, we show that these kernels are universal and that SVMs using these kernels are universally consistent. We further describe a parameter optimization method for the kernel parameters and empirically compare this method to SVMs, random forests, a multiple kernel learning approach, and to some deep neural networks.	artificial neural network;deep learning;iteration;kernel (operating system);mathematical optimization;multiple kernel learning;random forest;support vector machine	Ingo Steinwart;Philipp Thomann;Nico Schmid	2016	CoRR		mathematical optimization;machine learning;pattern recognition;mathematics	ML	20.689298914016096	-36.64743157422889	37057
35c7cb4786ae0f21df6f31b66b340b8886a968f0	pareto depth sampling distributions for gene ranking	pareto optimization;molecular biophysics;aging;pareto distribution;sampling methods;biomedical imaging;stability;genetics;filtering	In this paper we propose a method for gene ranking from microarray experiments using multiple discriminants. The novelty of our approach is that a gene's relative rank is determined according to the ordinal theory of multiple objective optimization. Furthermore, the distribution of each gene's rank, called Pareto depth, is determined by resampling over the microarray replicates. This distribution is called the Pareto depth sampling distribution (PDSD) and it is used to assess the stability of each ranking. Graphical representation of the PDSD as an image communicates information about the stability of each gene's rank. We illustrate on data from a mouse retina microarray experiment.	experiment;graphical user interface;mathematical optimization;microarray;multi-objective optimization;ordinal data;pareto efficiency;sampling (signal processing)	Alfred O. Hero;Sepidarseh Zareparsi;Anand Swaroop;Gilles Fleury	2004	2004 2nd IEEE International Symposium on Biomedical Imaging: Nano to Macro (IEEE Cat No. 04EX821)		filter;sampling;mathematical optimization;medicine;stability;bioinformatics;pareto distribution;mathematics;statistics;molecular biophysics	Vision	5.904224165453664	-51.512049284631665	37059
86bdeea4f9387cf5d6f0318021a95d8ab4b52d9b	a neural algorithm incorporating winner‐take‐all subnets for combinatorial optimization	aproximacion;performance;maximum cut problem;approximation;algorithme;optimisation combinatoire;algorithm;neural combinatorial optimization;evaluation;partitionnement;evaluacion;rendimiento;reseau neuronal;combinatorial optimization;reseau winner take all;winner take all;red neuronal;neural network;optimizacion combinatoria;algoritmo;wta net	Using a neural net composed of subnets with a winner-take-all (WTA) mode of operations, the constraint that the variables must form a probability vector or a probability matrix can automatically be satisfied. Taking advantage of this property, this paper proposes a neural algorithm than can derive the approximate solution for a combinatorial optimization problem such as set partitioning. As a simple example, the 3-partition maximum-cut problem is considered.	3-partition problem;approximation algorithm;artificial neural network;combinatorial optimization;mathematical optimization;maximum cut;optimization problem;stochastic matrix;subnetwork;weapon target assignment problem;winner-take-all (computing)	Kiichi Urahama	1993	Systems and Computers in Japan	10.1002/scj.4690240609	winner-take-all;mathematical optimization;performance;combinatorial optimization;computer science;artificial intelligence;evaluation;machine learning;approximation;mathematics;algorithm	ML	18.274960263460812	-27.450819099792447	37121
9e88e42a23577b21dde5749ed552027780ac9e89	multi-objective evolutionary algorithm for mining 3d clusters in gene-sample-time microarray data	microarray data;cluster algorithm;evolutionary computation;multi objective modeling;three dimensional cluster mining;biomedical applications;multi objective evolutionary algorithm;data mining;three dimensional;medical computing;multi objective evolutionary 3d clustering algorithm multi objective evolutionary algorithm 3d cluster mining gene sample time microarray data three dimensional cluster mining gst datasets bioinformatics research biomedical applications multi objective modeling;multi objective evolutionary 3d clustering algorithm;three dimensional displays;clustering algorithms;bioinformatics research;3d cluster mining;gene sample time microarray data;encoding;three dimensional displays clustering algorithms data mining educational institutions algorithm design and analysis encoding bioinformatics;biomedical application;algorithm design and analysis;gst datasets;object model;bioinformatics;medical computing bioinformatics data mining evolutionary computation	Latest microarray technique can measure the expression levels of a set of genes under a set of samples during a series of time points, and generates new datasets which are called gene-sample-time (simply GST) microarray data. Mining three-dimensional (3D) clusters from GST datasets is important in bioinformatics research and biomedical applications. Several objectives in conflict with each other have to be optimized simultaneously during mining 3D clusters, so multi-objective modeling is suitable for solving 3D clustering. This paper proposes a novel multi-objective evolutionary 3D clustering algorithm to mine 3D cluster in 3D microarray data. Experimental results on real dataset show that our approach can find significant 3D clusters of high quality.	bioinformatics;cluster analysis;display resolution;evolutionary algorithm;experiment;fitness function;local search (optimization);moea framework;microarray;qualitative comparative analysis	Junwan Liu;Zhoujun Li;Xiaohua Hu;Yiming Chen	2008	2008 IEEE International Conference on Granular Computing	10.1109/GRC.2008.4664735	three-dimensional space;algorithm design;microarray analysis techniques;gene chip analysis;object model;computer science;bioinformatics;data science;machine learning;data mining;cluster analysis;affinity propagation;encoding;evolutionary computation	HPC	3.6309943287519584	-48.14827894288887	37144
b3de0f53b526da8f265405e5370291607137f285	extracting interestingness dimensions for search time in visual cluttered scenes	subtractive clustering subclust;multivariate based data reduction;factor analysis;neuro fuzzy system			Deok Hee Nam;Harpreet Singh;Thomas Meitzler	2006			computer vision;machine learning;data mining;factor analysis;statistics	Vision	6.012266196389177	-39.90327729330426	37176
f50c24bb904d0f931e9ae04ccc0dbdfb7f3e1176	subcoid: an attempt to explore cluster-outlier iterative detection approach to multi-dimensional data analysis in subspace	watermarking;information systems;high dimensionality;noisy data;data processing;relational database;outlier detection;data clustering;multi dimensional;data analysis;clustering;signal processing;clustering method;data mining algorithm;pattern recognition;database applications;information search and retrieval;iterative detection	Many data mining algorithms focus on clustering methods. There are also a lot of approaches designed for outlier detection. We observe that, in many situations, clusters and outliers are concepts whose meanings are inseparable to each other, especially for those data sets with noise. Clusters and outliers should be treated as the concepts of the same importance in data analysis. In our previous work [22] we proposed a cluster-outlier iterative detection algorithm in full data space. However, in high dimensional spaces, for a given cluster or outlier, not all dimensions may be relevant to it. In this paper we extend our work in subspace area, tending to detect the clusters and outliers in another perspective for noisy data. Each cluster is associated with its own subset of dimensions, so is each outlier. The partition, subsets of dimensions and qualities of clusters are detected and adjusted according to the intra-relationship within clusters and the inter-relationship between clusters and outliers, and vice versa. This process is performed iteratively until a certain termination condition is reached. This data processing algorithm can be applied in many fields such as pattern recognition, data clustering and signal processing.	algorithm;anomaly detection;cluster analysis;computer cluster;data mining;dataspaces;iterative method;pattern recognition;separable polynomial;signal processing;signal-to-noise ratio	Yong Shi	2008		10.1145/1593105.1593139	computer science;machine learning;pattern recognition;cure data clustering algorithm;data mining	DB	-0.4939201479936809	-41.362766476236246	37181
c059756825b1744175311583c331d0375043f2cc	controlling the parallel layer perceptron complexity using a multiobjective learning algorithm	learning algorithms;learning algorithm;neural networks;parallel layer perceptron;machine learning;multiobjective training algorithm;training algorithm;neural network	This paper deals with the parallel layer perceptron (PLP) complexity control, bias and variance dilemma, using a multiobjective (MOBJ) training algorithm. To control the bias and variance the training process is rewritten as a bi-objective problem, considering the minimization of both training error and norm of the weight vector, which is a measure of the network complexity. This method is applied to regression and classification problems and compared with several other training procedures and topologies. The results show that the PLP MOBJ training algorithm presents good generalization results, outperforming traditional methods in the tested examples.	algorithm;pl/p;perceptron;statistical classification	Douglas A. G. Vieira;João A. Vasconcelos;Walmir M. Caminhas	2006	Neural Computing and Applications	10.1007/s00521-006-0052-z	computer science;artificial intelligence;theoretical computer science;machine learning;supervised learning;stability;artificial neural network	AI	15.752189274143364	-31.10334545103359	37312
14edd2b96733e84bae611782a2aebf2fc0732382	the third anniversary of neural networks	neural network		neural networks	Stephen Grossberg	1991	Neural Networks	10.1016/0893-6080(91)90025-Z	computer science;machine learning;artificial neural network	ML	12.090588184116816	-26.79138357483997	37354
5c44f5f6069bd287229bdc08e2344508c8b6c33e	a uml approximation of three chidamber-kemerer metrics and their ability to predict faulty code across software projects	logistic regression	Design-complexity metrics, while measured from the code, have shown to be good predictors of fault-prone object-oriented programs. Some of the most often used metrics are the Chidamber and Kemerer metrics (CK). This paper discusses how to make early predictions of fault-prone object-oriented classes, using a UML approximation of three CK metrics. First, we present a simple approach to approximate Weighted Methods per Class (WMC), Response For Class (RFC) and Coupling Between Objects (CBO) CK metrics using UML collaboration diagrams. Then, we study the application of two data normalization techniques. Such study has a twofold purpose: to decrease the error approximation in measuring the mentioned CK metrics from UML diagrams, and to obtain a more similar data distribution of these metrics among software projects so that better prediction results are obtained when using the same prediction model across different software projects. Finally, we construct three prediction models with the source code of a package of an open source software project (Mylyn from Eclipse), and we test them with several other packages and three different small size software projects, using their UML and code metrics for comparison. The results of our empirical study lead us to conclude that the proposed UML RFC and UML CBO metrics can predict fault-proneness of code almost with the same accuracy as their respective code metrics do. The elimination of outliers and the normalization procedure used were of great utility, not only for enabling our UML metrics to predict fault-proneness of code using a code-based prediction model but also for improving the prediction results of our models across different software packages and projects. key words: UML metrics, CK metrics, fault-proneness of code, logistic regression	approximation algorithm;diagram;eclipse;logistic regression;open-source software;software metric;software project management;uml state machine;unified modeling language	Ana Erika Camargo Cruz;Koichiro Ochimizu	2010	IEICE Transactions		computer science;machine learning;data mining;logistic regression	SE	4.047311340728863	-33.928119203602016	37361
9078689ade915e22056d56e9e4060a8b2889c266	extraction of voltage harmonics using multi-layer perceptron neural network	calcul neuronal;feed forward;neural computation;learning rate;62p20;aplicacion;error back propagation;neural networks;superviseur;learning;harmonic extraction;programming environment;62m45;dynamique reseau;algorithme;aprendizaje;algorithm;structure reseau;apprentissage;mlp neural network;estimation erreur;red multinivel;supervisor;propagacion;dynamic voltage restorer;error estimation;estimacion error;couche cachee;multi layer perceptron;vitesse apprentissage;multilayer network;network structure;reseau multicouche;perceptron;reseau neuronal;62p12;application;taux apprentissage;red neuronal;computacion neuronal;reseau neuronal artificiel;propagation;artificial neural network;neural network;algoritmo	This paper presents a harmonic extraction algorithm using artificial neural networks for Dynamic Voltage Restorers (DVRs). The suggested algorithm employs a feed forward Multi Layer Perceptron (MLP) Neural Network with error back propagation learning to effectively track and extract the 3rd and 5th voltage harmonics. For this purpose, two different MLP neural network structures are constructed and their performances compared. The effects of hidden layer, supervisors and learning rate are also presented. The proposed MLP Neural Network algorithm is trained and tested in MATLAB program environment. The results show that MLP neural network enable to extract each harmonic effectively.	algorithm;artificial neural network;backpropagation;effective method;layer (electronics);matlab;memory-level parallelism;multilayer perceptron;performance;quad flat no-leads package;quantum harmonic oscillator;software propagation	Mehmet Tümay;M. Emin Meral;K. Çagatay Bayindir	2007	Neural Computing and Applications	10.1007/s00521-007-0154-2	probabilistic neural network;computer science;artificial intelligence;backpropagation;perceptron;machine learning;time delay neural network;multilayer perceptron;feed forward;artificial neural network;algorithm;models of neural computation	ML	11.366180291716777	-29.262045198824353	37390
0639bde25c6ab661413a14c661cda15ea42baae9	the role of weight shrinking in large margin perceptron learning		We introduce into the classical perceptron algorithm with margin a mechanism that shrinks the current weight vector as a first step of the update. If the shrinking factor is constant the resulting algorithm may be regarded as a margin-error-driven version of NORMA with constant learning rate. In this case we show that the allowed strength of shrinking depends on the value of the maximum margin. We also consider variable shrinking factors for which there is no such dependence. In both cases we obtain new generalizations of the perceptron with margin able to provably attain in a finite number of steps any desirable approximation of the maximal margin hyperplane. The new approximate maximum margin classifiers appear experimentally to be very competitive in 2-norm soft margin tasks involving linear kernels.	approximation algorithm;experiment;margin classifier;maximal set;perceptron	Constantinos Panagiotakopoulos;Petroula Tsampouka	2012	CoRR		margin classifier;mathematical optimization;margin;machine learning;mathematics;algorithm	ML	20.748640777476737	-33.40420030499853	37474
463423a02205d500ba28b67190a640a50fadd1ec	merging of distance matrices and classification by dynamic clustering	microordenador;software;arbre phylogenetique;basic;representation graphique;cluster;matrice distance;logiciel;amas;representacion grafica;arbol filogenetico;ibm pc;microordinateur;microcomputer;algorithme;dynamic clustering;algorithm;methode matricielle;phylogenetic tree;matrix method;distancia;metodo matriz;logicial;monton;graphics;distance;algoritmo	The graphical representation of distance matrices in a Euclidean space allows the merging of two distance matrices since the two matrices have shared elements. The graphical representation of the merging of the two distance matrices is associated with a robust method of classification that allows one to distinguish species for which membership to a cluster cannot be established with certainty. These possibilities are exploited to test the consistency of phylogenetic trees, and to establish exact relations between species for which one possesses different independent distance measurements (distance matrices established from several types of sequences for instance). The whole set of programs is written in BASIC and runs on microcomputers.	basic;cluster analysis;distance matrix;microcomputer;microcomputers;phylogenetic tree;phylogenetics;trees (plant);statistical cluster	Marie-Odile Delorme;Alain Hénaut	1988	Computer applications in the biosciences : CABIOS	10.1093/bioinformatics/4.4.453	complete-linkage clustering;matrix method;correlation clustering;parallel computing;phylogenetic tree;k-medians clustering;fuzzy clustering;computer science;graphics;theoretical computer science;consensus clustering;microcomputer;hierarchical clustering;cluster analysis;single-linkage clustering;ibm pc compatible;distance;algorithm;cluster	ML	0.6261519426918927	-45.03453341068918	37489
ea279e7111febd5bdbbbfce7ac1945f7bd15d822	the solution space of genome sequence alignment and lis graph decomposition	optimal solution;genome alignment;longest increasing subsequence;decomposition algorithm;sequence alignment;graph decomposition;genome sequence;multiple alignment	In this paper we present an algorithm to discover the optimal solution space of genome sequence alignment. The solution space is an LIS (longest increasing subsequence) graph, which can be constructed in O(n2) time, where n is the number of MUMs in given genome sequences. The LIS graph has many unique properties that lead to the development of efficient decomposition algorithms. With the availability of the solution space, users can examine all possible solutions and pick the one that best meet their needs. We provide the decomposition tree traversal algorithm, which outputs the solution in an elegant and compact clustered form. Moreover, the solution space can also be used to study the homology of genome sequences.	algorithm;feasible region;homology (biology);longest increasing subsequence;sequence alignment;tree traversal	Fangrui Ma;Jitender S. Deogun	2010		10.1145/1854776.1854818	biology;combinatorics;whole genome sequencing;longest increasing subsequence;multiple sequence alignment;computer science;bioinformatics;theoretical computer science;sequence alignment;mathematics;alignment-free sequence analysis	Theory	-0.9501985217779615	-50.948216330124836	37493
c787b5e616287c081813a0bbbd01c9633f768693	a framework for fuzzy rule-based cognitive maps	cognitive map;carte cognitive;logique floue;base connaissance;logica difusa;linear functionals;fuzzy logic;fuzzy rule base;aggregation operator;mapa cognitiva;causalite;transfer function;fonction appartenance;membership function;base conocimiento;fuzzy cognitive map;funcion pertenencia;fuzzy rule;regle floue;carte cognitive floue;causality;causalidad;knowledge base	Fuzzy Cognitive Maps (FCM), as defined originally, are limited in their capacity to model real-world scenarios, due to the rather simple representation of causal relationships between interrelated concepts. They can model a world that has only monotonic cause-effect relationships. Unlike this traditional FCM, which uses a linear function to represent the strength of relationship between two concepts, and a non-linear transfer function, to update the value of a concept during simulation, the FCM proposed by us uses fuzzy rules based on membership functions, and an aggregation operator respectively to serve these two purposes. This allows representation of non-monotonic causality, which is typical of many scenarios.	cognitive map;fuzzy rule	M. Shamim Khan;Sebastian W. Khor	2004		10.1007/978-3-540-28633-2_49	fuzzy logic;knowledge base;fuzzy cognitive map;causality;membership function;cognitive map;computer science;artificial intelligence;machine learning;mathematics;transfer function;algorithm	HCI	1.6300000321293908	-26.044934432636623	37529
a126c320d0ed35bb11a43e29cacc5f8ea724a0c8	automatic learning control using fuzzy logic			fuzzy logic;machine learning	N. Baaklini	1976				Robotics	3.899459248355733	-25.309459853567034	37532
277cfee6805abc5cd2ca440231c6a083c1991cef	automatic recommendation of classification algorithms based on data set characteristics	k nearest neighbors;algorithm performance;classification algorithm automatic recommendation;classification;data set characteristics extraction	Choosing appropriate classification algorithms for a given data set is very important and useful in practice but also is full of challenges. In this paper, a method of recommending classification algorithms is proposed. Firstly the feature vectors of data sets are extracted using a novel method and the performance of classification algorithms on the data sets is evaluated. Then the feature vector of a new data set is extracted, and its k nearest data sets are identified. Afterwards, the classification algorithms of the nearest data sets are recommended to the new data set. The proposed data set feature extraction method uses structural and statistical information to characterize data sets, which is quite different from the existing methods. To evaluate the performance of the proposed classification algorithm recommendation method and the data set feature extraction method, extensive experiments with the 17 different types of classification algorithms, the three different types of data set characterization methods and all possible numbers of the nearest data sets are conducted upon the 84 publicly available UCI data sets. The results indicate that the proposed method is effective and can be used in practice. & 2012 Elsevier Ltd. All rights reserved.	algorithm;data mining;experiment;feature extraction;feature vector;statistical classification	Qinbao Song;Guangtao Wang;Chao Wang	2012	Pattern Recognition	10.1016/j.patcog.2011.12.025	biological classification;computer science;machine learning;pattern recognition;data mining;k-nearest neighbors algorithm;information retrieval	ML	11.902577047117221	-46.23224313052575	37539
cb48a7a46f9bc3ba74ecd728e91866d259a7982f	the parallel transfer of task knowledge using dynamic learning rates based on a measure of relatedness	algoritmo paralelo;learning rate;learning algorithm;parallel algorithm;parallel learning;base connaissance;algorithme apprentissage;learning to learn;task relatedness;algorithme parallele;artificial neural networks;knowledge based inductive bias;knowledge transfer;base conocimiento;task knowledge transfer;reseau neuronal;algoritmo aprendizaje;red neuronal;neural network;knowledge base	With a distinction made between two forms of task knowledge transfer, representational and functional, MTL, a modi ed version of the MTL method of functional (parallel) transfer, is introduced. The MTL method employs a separate learning rate, k, for each task output node k. k varies as a function of a measure of relatedness, Rk, between the kth task and the primary task of interest. Results of experiments demonstrate the ability of MTL to dynamically select the most related source task(s) for the functional transfer of prior domain knowledge. The MTL method of learning is nearly equivalent to standard MTL when all parallel tasks are su ciently related to the primary task, and is similar to single task learning when none of the parallel tasks are related to the primary task. 2	experiment;monoidal t-norm logic	Daniel L. Silver	1996	Connect. Sci.	10.1080/095400996116929	computer science;artificial intelligence;machine learning;parallel algorithm;artificial neural network;algorithm	ML	10.664237815283453	-30.59223792105026	37555
ef1ab1d21c0239b18cd27ed96995e218a0bd20e0	a fuzzy set theoretic approach to validate simulation models	fuzzy set;computacion informatica;validity grades;fuzzy set theory;input output;model validation;machine learning;ciencias basicas y experimentales;matematicas;fuzzy inference;nefprox;airline industry;grupo a;simulation model;resemblance relations	We develop a new approach to the validation of simulation models by exploiting elements from fuzzy set theory and machine learning. A fuzzy resemblance relation concept is used to set up a mathematical framework for measuring the degree of similarity between the input-output behavior of a simulation model and the corresponding behavior of the real system. A neuro-fuzzy inference algorithm is employed to automatically learn the required resemblance relation from real and simulated data. Ultimately, defuzzification strategies are applied to obtain a coefficient on the unit interval that characterizes the degree of model validity. An example in the airline industry illustrates the practical application of this methodology.	algorithm;coefficient;defuzzification;fuzzy set;machine learning;neuro-fuzzy;set theory;simulation	Jurgen Martens;Ferdi Put;Etienne E. Kerre	2006	ACM Trans. Model. Comput. Simul.	10.1145/1176249.1176253	fuzzy logic;simulation;defuzzification;adaptive neuro fuzzy inference system;type-2 fuzzy sets and systems;fuzzy classification;computer science;artificial intelligence;fuzzy number;neuro-fuzzy;machine learning;data mining;mathematics;fuzzy set;fuzzy set operations;statistics	Graphics	1.3650718019955326	-25.282957153727967	37561
8eceed07b2fa847ea86c7113ea1703c0deb46f25	constructing canonical regions for fast and effective view selection		In view selection, little work has been done for optimizing the search process, views must be densely distributed and checked individually. Thus, evaluating poor views wastes much time, and a poor view may even be misidentified as a best one. In this paper, we propose a search strategy by identifying the regions that are very likely to contain best views, referred to as canonical regions. It is by decomposing the model under investigation into meaningful parts, and using the canonical views of these parts to generate canonical regions. Applying existing view selection methods in the canonical regions can not only accelerate the search process but also guarantee the quality of obtained views. As a result, when our canonical regions are used for searching N-best views during comprehensive model analysis, we can attain greater search speed and reduce the number of views required. Experimental results show the effectiveness of our method.	approximation algorithm;best practice;brute-force attack;display resolution	Wencheng Wang;Tianhao Gao	2016	2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)	10.1109/CVPR.2016.446	mathematical optimization;machine learning;data mining;canonical model;mathematics	Vision	13.024585149554085	-46.981777426250595	37582
4d4bd51a6e3ebc257e4200ebeee1fa71b93de705	constructing and mapping fuzzy thematic clusters to higher ranks in a taxonomy	computer science and information systems;fuzzy clustering;classification system;recursive algorithm;penalty function	We present a method for mapping a structure such as a research department to a related taxonomy in a thematically consistent way. The components of the structure are supplied with fuzzy membership profiles over the taxonomy. The profiles are then generalized in two steps: first, by fuzzy clustering, and then by mapping the clusters to higher ranks of the taxonomy. To be specific, we concentrate on the Computer Sciences area represented by the taxonomy of ACM Computing Classification System (ACM-CCS). We build fuzzy clusters of the taxonomy leaves according to the similarity between individual profiles. Clusters are extracted using an original additive spectral clustering method involving a number of model-based stopping conditions. The clusters are not necessarily consistent with the taxonomy. This is formalized by parsimoniously lifting them to higher ranks of the taxonomy using an original recursive algorithm for minimizing a penalty function that involves “head subjects” on the higher ranks of the taxonomy along with their “gaps” and “offshoots”. An example is given illustrating the method applied to real-world data.	acm computing classification system;algorithm;cluster analysis;entity;evolutionary taxonomy;fuzzy clustering;fuzzy logic;occam's razor;penalty method;recursion (computer science);taxonomy (general);utility functions on indivisible goods	Boris G. Mirkin;Susana Nascimento;Trevor I. Fenner;Luís Moniz Pereira	2010		10.1007/978-3-642-15280-1_31	fuzzy clustering;fuzzy classification;computer science;artificial intelligence;theoretical computer science;machine learning;penalty method;data mining;recursion	ML	-1.369218695002138	-29.764137261585383	37608
96914cb1c1ad3896303f54f67d7d43d86c128d9a	assessments metrics for multi-class imbalance learning: a preliminary study		In this paper we study some of the most common global measures employed to measure the classifier performance on the multi-class imbalanced problems. The aim of this work consists of showing the relationship between global classifier performance (measure by global measures) and partial classifier performance, i.e., to determine if the results of global metrics match with the improved classifier performance over the minority classes. We have used five strategies to deal with the class imbalance problem over five real multi-class datasets on neural networks context.		Roberto Alejo;J. A. Antonio;Rosa Maria Valdovinos;J. Horacio Pacheco-Sánchez	2013		10.1007/978-3-642-38989-4_34	artificial intelligence;computer science;machine learning;artificial neural network;classifier (linguistics)	Theory	12.537353611576986	-41.45679701749546	37712
f90b0db4808224ee0a2807c30dcb564dd13fb0ef	relative strength of knowledge granules.				Thomas Whalen	2000	International Journal on Artificial Intelligence Tools	10.1142/S0218213000000288	machine learning;relative strength;artificial intelligence;pattern recognition;computer science;granule (cell biology)	DB	10.671633094285104	-27.628548672017086	37748
3942dfe724d5f7917c00fa579eb67abfa0573214	a new kernelized associative memory and some of its applications			content-addressable memory;kernel method	Matthew Saltz;Lluís A. Belanche Muñoz	2016		10.3233/978-1-61499-672-9-311	machine learning;content-addressable memory;artificial intelligence;computer science	HPC	13.338369473157586	-29.266472424807947	37804
cfa58bcfecf9a186743475307ba7b73226961290	back-propagation is not efficient	cargamento;non linear programming;learning algorithm;learning;nonlinear programming;probleme np complet;efficient algorithm;programacion no lineal;loading;programmation non lineaire;chargement;backpropagation;standard sigmoid function;algorithme;aprendizaje;algorithm;retropropagation;apprentissage;np hardness;loading problem;problema np completo;network architecture;reseau neuronal;learning theory;retropropagacion;back propagation;red neuronal;np complete problem;neural network;algoritmo	The back-propagation learning algorithm for multi-layered neural networks, which is often successfully used in practice, appears very time consuming even for small network architectures or training tasks. However, no results are yet known concerning the complexity of this algorithm. Blum and Rivest proved that training even a three-node network is NP-complete for the case when a neuron computes the discrete linear threshold function. We generalize the technique from their NP-hardness proof for a continuous sigmoidal function used in back-propagation. We show that training a three-node sigmoid network with an additional constraint on the output neuron function (e.g., zero threshold) is NP-hard. As a consequence of this, we find training sigmoid feedforward networks, with a single hidden layer and with zero threshold of output neuron, to be intractable. This implies that back-propagation is generally not an efficient algorithm, unless at least P = NP. We take advantage of these results by showing the NP-hardness of a special nonlinear programming problem. Copyright 1996 Elsevier Science Ltd.	algorithm;anatomic node;arabic numeral 0;architecture as topic;artificial neural network;backpropagation;blum axioms;complexity;copyright;feedforward neural network;np-completeness;np-hardness;neural network simulation;node - plant part;nonlinear programming;nonlinear system;numerous;p versus np problem;sigmoid colon;sigmoid function;software propagation;anatomical layer;neuron projection extension involved in neuron projection guidance	Jirí Síma	1996	Neural networks : the official journal of the International Neural Network Society	10.1016/0893-6080(95)00135-2	nonlinear programming;computer science;artificial intelligence;backpropagation;machine learning;mathematics;algorithm	ML	17.77394872115448	-28.014620075931795	37911
940b6391610dcc09affe6155f0f187068561efa6	a transfer learning based classifier ensemble model for customer credit scoring	customer credit scoring;transfer ensemble model;eliminate noise;support vector machines;training;multiple classifier ensemble;selectively transfer learning;cste model transfer learning based classifier ensemble model customer credit scoring domestic industries global industries ensemble learning clustering based dynamic transfer ensemble model selecting based dynamic transfer ensemble model;computational modeling;mathematical model;pattern classification credit transactions learning artificial intelligence;multiple classifier ensemble customer credit scoring transfer ensemble model selectively transfer learning eliminate noise;mathematical model training data models educational institutions support vector machines computational modeling noise;noise;data models	Customer credit scoring is an important concern for numerous domestic and global industries. It is difficult to achieve satisfactory performance by traditional models constructed on the assumption that the training and test data are subject to the same distribution, because the customers usually come from different districts and may be subject to different distributions in reality. This study combines ensemble learning and transfer learning, and proposes a clustering and selecting based dynamic transfer ensemble (CSTE) model to transfer the related source domains to target domain for assisting in modeling. The experimental results in a large customer credit scoring dataset show that CSTE model outperforms two traditional credit scoring models, as well as three existing transfer learning models.	certified senior broadcast television engineer;cluster analysis;customer relationship management;ensemble learning;programming paradigm;test data	Jin Xiao;Runzhe Wang;Ge-Er Teng;Yi Hu	2014	2014 Seventh International Joint Conference on Computational Sciences and Optimization	10.1109/CSO.2014.21	data modeling;support vector machine;computer science;noise;machine learning;pattern recognition;mathematical model;data mining;ensemble learning;computational model;statistics	AI	8.639447254085281	-38.58146624352573	37917
eee5c0f0e5f27604bc5ee45579860bd3a71172e6	nonparametric stochastic contextual bandits		We analyze the $K$-armed bandit problem where the reward for each arm is a noisy realization based on an observed context under mild nonparametric assumptions. We attain tight results for top-arm identification and a sublinear regret of $widetilde{O}Big(T^{frac{1+D}{2+D}}Big)$, where $D$ is the context dimension, for a modified UCB algorithm that is simple to implement ($k$NN-UCB). We then give global intrinsic dimension dependent and ambient dimension independent regret bounds. We also discuss recovering topological structures within the context space based on expected bandit performance and provide an extension to infinite-armed contextual bandits. Finally, we experimentally show the improvement of our algorithm over existing multi-armed bandit approaches for both simulated tasks and MNIST image classification.	algorithm;experiment;intrinsic dimension;mnist database;maximal set;multi-armed bandit;rss bandit;regret (decision theory);simulation	Melody Y. Guan;Heinrich Jiang	2018			discrete mathematics;mathematical optimization;mnist database;regret;computer science;intrinsic dimension;nonparametric statistics;contextual image classification;sublinear function	ML	22.123280653762258	-31.145783913781035	37919
8058abd2631ddb384720a588055cd349093777ff	on the use of normalized edit distances and an efficient k-nn search technique (k-aesa) for fast and accurate string classification	medical computing pattern classification cellular biophysics string matching search problems;pattern classification normalised edit distances string classification pattern recognition nearest neighbour search dissimilarity computational cost chromosomes;dissimilarity measure;edit distance;medical computing;pattern classification;pattern recognition;nearest neighbour;search problems;string matching;cellular biophysics;prototypes neural networks humans biological cells computational efficiency integrated circuit testing pattern recognition costs extraterrestrial measurements data preprocessing	Classification based on Nearest Neighbours (NN) is a uniformly good approach to many Pattern Recognition (PR) tasks. However, two important aspects need to be taken into account to actually achieve good performance in practice. The first one is the metric or dissimilarity measure adopted to compare the considered patterns. The second is the computational cost incurred by the NN searching operation. As it is shown in this paper, by using the adequate techniques to cope with these two issues, NN-based classification leads to better results than those obtained by other approaches that have been applied to a task of human banded chromosomes classification.	algorithmic efficiency;computation;data pre-processing;k-nearest neighbors algorithm;pattern recognition	Alfons Juan-Císcar;Enrique Vidal	2000		10.1109/ICPR.2000.906165	edit distance;computer science;machine learning;pattern recognition;data mining;mathematics;string searching algorithm	ML	7.852445071032109	-46.011769821094084	37923
3855941d5692ea889964e23c3e073e795b2bf976	two classes of algorithms for data clustering	kernel functions;constrained clustering;agglomerative hierarchical clustering;k means clustering	The two classes of agglomerative hierarchical clustering algorithms and K-means algorithms are overviewed. Moreover recent topics of kernel functions and semi-supervised clustering in the two classes are discussed. This paper reviews traditional methods as well as new techniques.	cluster analysis;computer cluster	Sadaaki Miyamoto	2011		10.1007/978-3-642-24918-1_5	correlation clustering;data stream clustering;k-medians clustering;fuzzy clustering;flame clustering;canopy clustering algorithm;machine learning;consensus clustering;pattern recognition;cure data clustering algorithm;data mining;hierarchical clustering;cluster analysis;single-linkage clustering;brown clustering;dbscan;biclustering;dendrogram;hierarchical clustering of networks;clustering high-dimensional data;conceptual clustering	DB	2.487929551135982	-41.29656219114977	37949
c76695037f6decfccc6812d31e11000eef2dbf7d	a mixture model based defense for data poisoning attacks against naive bayes spam filters		Naive Bayes spam filters are highly susceptible to data poisoning attacks. Here, known spam sources/blacklisted IPs exploit the fact that their received emails will be treated as (ground truth) labeled spam examples, and used for classifier training (or re-training). The attacking source thus generates emails that will skew the spam model, potentially resulting in great degradation in classifier accuracy. Such attacks are successful mainly because of the poor representation power of the naive Bayes (NB) model, with only a single (component) density to represent spam (plus a possible attack). We propose a defense based on the use of a mixture of NB models. We demonstrate that the learned mixture almost completely isolates the attack in a second NB component, with the original spam component essentially unchanged by the attack. Our approach addresses both the scenario where the classifier is being re-trained in light of new data and, significantly, the more challenging scenario where the attack is embedded in the original spam training set. Even for weak attack strengths, BIC-based model order selection chooses a two-component solution, which invokes the mixture-based defense. Promising results are presented on the TREC 2005 spam corpus.	artificial neural network;bayesian information criterion;deep learning;elegant degradation;email filtering;embedded system;generative modelling language;ground truth;mixture model;naive bayes classifier;spamming;statistical classification;support vector machine;test set	David J. Miller;Xinyi Hu;Zhen Xiang;George Kesidis	2018	CoRR			Security	19.250178490388507	-50.914483672866744	37984
292ed47681e31fef29858df6c80e35cd369f0862	estimating the generalization performance of an svm efficiently	generalization performance;svm efficiently;cross validation;support vector machine;error rate	This paper proposes and analyzes an e cient and e ective approach for estimating the generalization performance of a support vector machine (SVM) for text classi cation. Without any computation-intensive resampling, the new estimators are computationally much more e cient than cross-validation or bootstrapping. They can be computed at essentially no extra cost immediately after training a single SVM. Moreover, the estimators developed here address the special performancemeasures needed for evaluating text classi ers. They can be used not only to estimate the error rate, but also to estimate recall, precision, and F1. A theoretical analysis and experiments show that the new method can e ectively estimate the performance of SVM text classi ers in an e cient way.	bit error rate;computation;cross-validation (statistics);experiment;support vector machine	Thorsten Joachims	2000			support vector machine;word error rate;computer science;machine learning;pattern recognition;data mining;structured support vector machine;cross-validation	ML	15.412155518993975	-36.138657784876905	38017
498faba9efdc0283cef5d5e8a83fd949fad8d7e5	dynamic behaviors of an integrated circuit for recurrent neural networks	multiprocessor interconnection networks;nearest neighbor searches;cmos integrated circuits;connection matrix;cmos technology;self coupling;4 mm;limit cycles neurons recurrent neural networks cmos technology multiprocessor interconnection networks neural network hardware neural networks integrated circuit technology nearest neighbor searches associative memory;ic;neural networks;integrated circuit;synaptic weight construction;spice recurrent neural nets neural chips cmos integrated circuits limit cycles content addressable storage integrated circuit design;basin of attraction;spice simulation;nearest neighbor connections;neuro chips;interconnection network;chip;design rules;integrated circuit design;neural chips;limit cycle;limit cycles;integrated circuit technology;nearest neighbor;asymmetric interconnection networks;associative memory;neural network hardware;2 2 mm dynamic behavior integrated circuit ic recurrent neural networks asymmetric interconnection networks neuro chips programmable synaptic weights cmos technology self coupling limit cycles nearest neighbor connections attraction basins associative memory dynamical cyclic patterns spice simulation synaptic weight construction connection matrix 4 mm;attraction basins;2 2 mm;recurrent neural nets;neurons;recurrent neural networks;recurrent neural network;content addressable storage;dynamical cyclic patterns;programmable synaptic weights;spice;hardware implementation;neural network;dynamic behavior	In order to investigate dynamic behaviors of recurrent neural networks or asymmetric interconnection networks on neuro-chips, we design a hardware neural network with programmable synaptic weights according to the design rule of a CMOS technology. The full connections between neurons and the self-coupling can be performed. Some types of connections can produce many limit cycles on the network. The number of limit cycles increases sharply with increasing the number of neurons in case of nearest neighbor connections. As an example, there are at least 1.14/spl times/10/sup 7/ limit cycles in the case of 40 neurons. The limit cycles have basins of attraction, and hence, we may utilize the network as associative memory to retrieve dynamical cyclic patterns. After the SPICE simulation for the network, we fabricate the integrated circuit. The chip size is 4 mm/spl times/4 mm or 2.2 mm/spl times/2.2 mm. The main part of the chip has 49 synapses and 98 SRAM cells each two of which belongs to each synapse to store its weight. We present a procedure to construct the synaptic weights to produce particular limit cycles in a network. The procedure to make up a connection matrix is useful for hardware implementation in terms of the simple synaptic weights and its accuracy.	artificial neural network;integrated circuit;recurrent neural network	K. Nakajima	1998		10.1109/KES.1998.725981	electronic engineering;computer science;theoretical computer science;machine learning	EDA	15.932577932570059	-26.537309972072975	38032
290e17f24e3707780e5d29598cf614b9da416eeb	algorithmic randomness based feature selection for traditional chinese chronic gastritis diagnosis	support vector machines;discovery;chronic gastritis;classification;random forests;feature importance;conformal predictor;medicine;feature selection;algorithmic randomness;gene selection;article	Machine learning methods involving multivariate interacting effects have become mainstream in feature selection. However, the feature importance score generated by machine learning methods is not statistically interpretable, which hampers its application in practice like medical diagnosis. In this study, a framework of Algorithmic Randomness based Feature Selection (ARFS) is proposed to measure the feature importance score using the p-value which derives from the combination of algorithmic randomness test and machine learning methods. In ARFS, a machine learning algorithm, such as random forest (RF), support vector machine (SVM) and naïve Bayes classifier (NB) is used to compute the nonconformity score of each example belonging to data distribution, and then the p-value from algorithmic randomness test is obtained from nonconformity scores. ARFS evaluates the importance of each feature with the reduction of p-value on the datasets before and after random permutation of that feature, which makes it statistically interpretable. To demonstrate its efficiency, three ARFS models, i.e. ARFS-RF, ARFS-SVM and ARFS-NB were used to compare with some feature selection approaches, i.e. RF-ACC, RF-Gini, KNNpermute, SMFS, ANOVA and SNR. The results showed that ARFS-RF obtained better performances both on the synthetic and benchmark datasets. Further study on chronic gastritis dataset in Traditional Chinese Medicine (TCM) showed that the symptom sets given by ARFS-RF performs substantially better than that of TCM experts with the same size. The symptom ranking list generated by ARFS-RF can offer counselling for the physician to design, select, and interpret the symptoms in chronic gastritis diagnosis. & 2014 Elsevier B.V. All rights reserved.	algorithm;algorithmically random sequence;benchmark (computing);dhrystone;feature selection;interaction;machine learning;naive bayes classifier;naivety;performance;rf modulator;radio frequency;random forest;random permutation;randomness tests;signal-to-noise ratio;support vector machine;toolkit for conceptual modeling	Hua-zhen Wang;Bing Lv;Fan Yang;Kai Zheng;Xuan Li;Xueqin Hu	2014	Neurocomputing	10.1016/j.neucom.2014.03.016	gene-centered view of evolution;random forest;support vector machine;biological classification;computer science;artificial intelligence;machine learning;data mining;feature selection	AI	9.521032755830268	-46.88031351677801	38081
12221847bed5b8f82607d59d07c999a5dc6f95e7	a safe screening rule for sparse logistic regression		The `1-regularized logistic regression (or sparse logistic regression) is a widely used method for simultaneous classification and feature selection. Although many recent efforts have been devoted to its efficient implementation, its application to high dimensional data still poses significant challenges. In this paper, we present a fast and effective sparse logistic regression screening rule (Slores) to identify the “0” components in the solution vector, which may lead to a substantial reduction in the number of features to be entered to the optimization. An appealing feature of Slores is that the data set needs to be scanned only once to run the screening and its computational cost is negligible compared to that of solving the sparse logistic regression problem. Moreover, Slores is independent of solvers for sparse logistic regression, thus Slores can be integrated with any existing solver to improve the efficiency. We have evaluated Slores using high-dimensional data sets from different applications. Experiments demonstrate that Slores outperforms the existing state-of-the-art screening rules and the efficiency of solving sparse logistic regression can be improved by one magnitude.	algorithmic efficiency;computation;experiment;feature selection;lr parser;lasso;logistic regression;mathematical optimization;numerical analysis;solver;sparse matrix	Jie Jin Wang;Jiayu Zhou;Jun Liu;Peter Wonka;Jieping Ye	2014			computer science;machine learning;pattern recognition;logistic model tree;multinomial logistic regression;statistics	ML	20.932977080574627	-38.079129918652356	38083
6a15d0dd24a0a81795f6d7b5fc24b2d0146d9787	neuromorphic computing's yesterday, today, and tomorrow - an evolutional view		Neuromorphic computing was originally referred to as the hardware that mimics neuro-biological architectures to implement models of neural systems. The concept was then extended to the computing systems that can run bio-inspired computing models, e.g., neural networks and deep learning networks. In recent years, the rapid growth of cognitive applications and the limited processing capability of conventional von Neumann architecture on these applications motivated worldwide research on neuromorphic computing systems. In this paper, we review the evolution of neuromorphic computing technique in both computing model and hardware implementation from a historical perspective. Various implementation methods and practices are also discussed. Finally, we present some emerging technologies that may potentially change the landscape of neuromorphic computing in the future, e.g., new devices and interdisciplinary computing architectures.	neuromorphic engineering	Yiran Chen;Hai Li;Chunpeng Wu;Chang Song;Sicheng Li;Chuhan Min;Hsin-Pai Cheng;Wei Wen;Xiaoxiao Liu	2018	Integration	10.1016/j.vlsi.2017.11.001	computer science;von neumann architecture;real-time computing;artificial neural network;computer engineering;emerging technologies;deep learning;yesterday;cognition;neuromorphic engineering;artificial intelligence	DB	7.730054133212651	-24.847897349452058	38109
4e8269021b3c4a9f2050f20bafaf341b90edf9f5	towards neural network model for insulin/glucose in diabetics-ii	levenberg marquardt;lms algorithm;feed forward neural network;linear regression;dynamic system;neural network model;training algorithm;neural network	In this work we extending our investigations for a general neural network model that resembles the interactions between glucose concentration levels and amount of insulin injected in the bodies of diabetics. We use real data for 70 different patients of diabetics and build on it our model. Two types of neural networks (NN’s) are experimented in building that model; the first type is called the LevenbergMarquardt (LM) training algorithm of multilayer feed forward neural network (NN), the other one is based on Polynomial Network (PN’s). We do comparisons between the two models based on their performance. The design stages mainly consist of training, testing, and validation. A linear regression between the output of the multi-layer feed forward neural network trained by LM algorithm (abbreviated by LM NN) and the actual outputs shows that the LM NN is a better model. The PN’s have proved to be good static “mappers”, but their performance is degraded when used in modelling a dynamical system. The LM NN based model still proved that it can potentially be used to build a theoretical general regulator controller for insulin injections and, hence, can reflect an idea about the types and amounts of insulin required for patients. Povzetek: Na osnovi podatkov o 70 pacientih je razvit nevronski model za razmerna med insulinom in glukozo.	algorithm;artificial neural network;dynamical system;interaction;layer (electronics);network model;numerical aperture;polynomial;software testing	Raed Abu Zitar;Abdulkareem Al-Jabali	2005	Informatica (Slovenia)		feedforward neural network;simulation;levenberg–marquardt algorithm;least mean squares filter;computer science;linear regression;artificial intelligence;dynamical system;machine learning;time delay neural network;artificial neural network	ML	12.588789115917173	-25.209902591569257	38165
8541e5736df409a4183750f56030d421d9b3a732	language modeling with generative adversarialnetworks		Generative Adversarial Networks (GANs) have been promising in the field of image generation, however, they have been hard to train for language generation. GANs were originally designed to output differentiable values, so discrete language generation is challenging for them which causes high levels of instability in training GANs. Consequently, past work has resorted to pre-training with maximum-likelihood or training GANs without pretraining[3] with a WGAN[10] objective with a gradient penalty. In this study, we present a comparison of those approaches. Furthermore, we present the results of some experiments that indicate better training and convergence of Wasserstein GANs (WGANs) when a weaker regularization term is enforcing the Lipschitz constraint.	experiment;generative adversarial networks;generative grammar;glossary of computer graphics;gradient;instability;language model;natural language generation	Mehrad Moradshahi;Utkarsh Contractor	2018	CoRR		differentiable function;machine learning;generative grammar;mathematical optimization;artificial intelligence;lipschitz continuity;language model;regularization (mathematics);instability;mathematics;convergence (routing)	ML	24.23019442768744	-31.18451638261412	38170
f727d3d941be61ae9a65bbb7e2091c283cb549a2	an efficient construction and application usefulness of rectangle greedy covers	data mining;classification;greedy cover;axis parallel hyperrectangle	We develop efficient construction methods of a rectangle greedy cover (RGC), and evaluate its usefulness in applications. An RGC is a greedy cover of the set of given positive instances by exclusive axis-parallel hyperrectangles, namely, axis-parallel hyperrectangles that exclude all the given negative instances. An RGC is expected to be a compact classification rule with high readability because the number of its component rectangles is expected to be small and it can be seen as a disjunctive normal form, which is one of the most readable representations for us. We propose two approaches of RGC construction: enumeration approach and direct approach. In enumeration approach, the maximal exclusive positive subsets (MEPSs) are enumerated first and then an ordinary greedy set covering is done using the enumerated MEPSs. We make clear the relation between enumeration of the maximal frequent itemsets and enumeration of the MEPSs, and convert an efficient enumeration algorithm LCMmax [1] of maximal frequent itemsets to an enumeration algorithm LCMmax.Rnaive of MEPSs. We also develop a more efficient version of LCMmax.Rnaive, or LCMmax.R, by incorporating effective dynamic reordering of instances using excluded frequency and bit-parallel exclusiveness check. In direct approach, each component MEPS of an RGC is searched not from enumerated MEPSs but directly from the dataset that consists of the remaining uncovered positive instances and the whole negative instances. We developed an algorithm called MRF that efficiently finds an maximum-sized MEPS for given positive and negative instances. MRF is made from LCMmax.R by modifying it so as to find a maximum-sized MEPS only. An RGC is constructed by MRF repetition, that is, by repeatedly executing MRF using the remaining uncovered positive instances. According to our experimental evaluation using UCI-repository datasets, LCMmax.R was about 5-11 times faster than LCMmax.Rnaive, which indicates effectiveness of the introduced two improvements. MRF repetition, however, was significantly faster than LCMmax.R, and it was enough fast to use practically for small datasets. The experimental results using UCI-repository datasets also showed that accuracy of a nearest rectangle classifier using an RGC is close to that using the hyperrectangles output by the randomized subclass method (RSM) [2] though the number of component rectangles of an RGC is significantly smaller than the number of the hyperrectangles output by RSM. The performance of RGC was also shown to be comparable to that of the six popular classifiers including logistic regression and support vector machine. The disjunctive normal form representation of the classification rules obtained by RGC was demonstrated to be simpler and more readable for us than that obtained by RSM and C4.5.		Koji Ouchi;Atsuyoshi Nakamura;Mineichi Kudo	2014	Pattern Recognition	10.1016/j.patcog.2013.09.008	combinatorics;biological classification;computer science;machine learning;pattern recognition;mathematics;algorithm;statistics	ML	13.619815374400751	-39.07342058102479	38199
38c1c0b223eea8243ffbeb0e4f2a9e2fb500a8b6	adaptive sparseness using jeffreys prior	supervised learning;error rate;support vector machine;jeffreys prior	In this paper we introduce a new sparseness inducing prior which does not involve any (hyper)parameters that need to be adjusted or estimated. Although other applications are possible, we focus here on supervised learning problems: regression and classification. Experiments with several publicly available benchmark data sets show that the proposed approach yields state-of-the-art performance. In particular, our method outperforms support vector machines and performs competitively with the best alternative techniques, both in terms of error rates and sparseness, although it involves no tuning or adjusting of sparsenesscontrolling hyper-parameters.	adaptive grammar;benchmark (computing);hyper-heuristic;neural coding;supervised learning;support vector machine	Mário A. T. Figueiredo	2001			support vector machine;word error rate;computer science;machine learning;pattern recognition;mathematics;supervised learning;statistics	ML	18.490971521541756	-40.238309629886686	38267
038f2b498be7bd71fae9c235facf270a5002bbc0	trust region newton methods for large-scale logistic regression	approximation algorithms;quasi newton;convergence of numerical methods;regression model;newton raphson method;logistic regression;classification of information;large scale;trust region;mathematical models;natural language processing systems;regression analysis;newton method;document classification;quasi newton approach;natural language processing	Large-scale logistic regression arises in many applications such as document classification and natural language processing. In this paper, we apply a trust region Newton method to maximize the log-likelihood of the logistic regression model. The proposed method uses only approximate Newton steps in the beginning, but achieves fast convergence in the end. Experiments show that it is faster than the commonly used quasi Newton approach for logistic regression. We also compare it with linear SVM implementations.	approximation algorithm;document classification;in the beginning... was the command line;logistic regression;natural language processing;newton;newton's method;trust region	Chih-Jen Lin;Ruby C. Weng;S. Sathiya Keerthi	2007		10.1145/1273496.1273567	econometrics;mathematical optimization;computer science;machine learning;mathematics;newton's method;logistic regression;logistic model tree;approximation algorithm;regression analysis;multinomial logistic regression;statistics	ML	23.128092997544925	-35.645163721875626	38275
9a6fca8283b699df82502de3184960837eb3a843	a formal concept analysis approach to consensus clustering of multi-experiment expression data	microarray data;computational biology bioinformatics;ibcn;cluster analysis;technology and engineering;integration analysis;particle swarm optimization;algorithms;validation;combinatorial libraries;computer appl in life sciences;consensus clustering;gene expression profiling;oligonucleotide array sequence analysis;formal concept analysis;multi experiment expression data;microarrays;bioinformatics	Presently, with the increasing number and complexity of available gene expression datasets, the combination of data from multiple microarray studies addressing a similar biological question is gaining importance. The analysis and integration of multiple datasets are expected to yield more reliable and robust results since they are based on a larger number of samples and the effects of the individual study-specific biases are diminished. This is supported by recent studies suggesting that important biological signals are often preserved or enhanced by multiple experiments. An approach to combining data from different experiments is the aggregation of their clusterings into a consensus or representative clustering solution which increases the confidence in the common features of all the datasets and reveals the important differences among them. We propose a novel generic consensus clustering technique that applies Formal Concept Analysis (FCA) approach for the consolidation and analysis of clustering solutions derived from several microarray datasets. These datasets are initially divided into groups of related experiments with respect to a predefined criterion. Subsequently, a consensus clustering algorithm is applied to each group resulting in a clustering solution per group. These solutions are pooled together and further analysed by employing FCA which allows extracting valuable insights from the data and generating a gene partition over all the experiments. In order to validate the FCA-enhanced approach two consensus clustering algorithms are adapted to incorporate the FCA analysis. Their performance is evaluated on gene expression data from multi-experiment study examining the global cell-cycle control of fission yeast. The FCA results derived from both methods demonstrate that, although both algorithms optimize different clustering characteristics, FCA is able to overcome and diminish these differences and preserve some relevant biological signals. The proposed FCA-enhanced consensus clustering technique is a general approach to the combination of clustering algorithms with FCA for deriving clustering solutions from multiple gene expression matrices. The experimental results presented herein demonstrate that it is a robust data integration technique able to produce good quality clustering solution that is representative for the whole set of expression matrices.	biologic preservation;cluster analysis;consensus clustering;experiment;formal concept analysis;gene expression;generic drugs;large;lung consolidation;microarray;numerous;pooled sample;schizosaccharomyces pombe;semiconductor consolidation;singlet fission;solutions;algorithm;statistical cluster	Anna Hristoskova;Veselka Boeva;Elena Tsiporkova	2014		10.1186/1471-2105-15-151	microarray analysis techniques;dna microarray;computer science;bioinformatics;formal concept analysis;data science;consensus clustering;data mining;gene expression profiling;cluster analysis;particle swarm optimization	Comp.	5.840974688276643	-50.07421269987069	38343
3337851dfba7706ccd1bf4a89aed06a7f4298a35	supervised classification using balanced training	113 computer and information sciences;a4 article in conference publication refereed	We examine supervised learning for multi-class, multi-label text classification. We are interested in exploring classification in a realworld setting, where the distribution of labels may change dynamically over time. First, we compare the performance of an array of binary classifiers trained on the label distribution found in the original corpus against classifiers trained on balanced data, where we try to make the label distribution as nearly uniform as possible. We discuss the performance tradeoffs between balanced vs. unbalanced training, and highlight the advantages of balancing the training set. Second, we compare the performance of two classifiers, Naive Bayes and SVM, with several feature-selection methods, using balanced training. We combine a Named-Entity-based rote classifier with the statistical classifiers to obtain better performance than either method alone.	algorithm;binary classification;document classification;feature selection;linear classifier;machine learning;multi-label classification;naive bayes classifier;statistical classification;statistical model;supervised learning;test set;unbalanced circuit	Mian Du;Matthew Pierce;Lidia Pivovarova;Roman Yangarber	2014		10.1007/978-3-319-11397-5_11	computer science;artificial intelligence;machine learning;data mining	ML	14.765673112079506	-41.37102497482605	38374
718c888ced7052a45f80726b9e45228d091072e4	class-wise deep dictionaries for eeg classification	eeg dictionary learning deep learning;cdbn eeg classification class wise deep dictionary learning cwddl cascaded dictionaries sparse representation based classification deep learning datasets mnist cifar svhn stacked autoencoder convolutional neural net cnn label consistent ksvd brain computer interface classification problems eeg signals convolutional deep belief network;dictionaries training machine learning benchmark testing sparse matrices neural networks minimization;signal representation belief networks brain computer interfaces electroencephalography feedforward neural nets learning artificial intelligence medical signal processing signal classification	In this work we propose a classification framework called class-wise deep dictionary learning (CWDDL). For each class, multiple levels of dictionaries are learnt using features from the previous level as inputs (for first level the input is the raw training sample). It is assumed that the cascaded dictionaries form a basis for expressing test samples for that class. Based on this assumption sparse representation based classification is employed. Benchmarking experiments have been carried out on some deep learning datasets (MNIST and its variations, CIFAR and SVHN); our proposed method has been compared with Deep Belief Network (DBN), Stacked Autoencoder, Convolutional Neural Net (CNN) and Label Consistent KSVD (dictionary learning). We find that our proposed method yields better results than these techniques and requires much smaller run-times. The technique is applied for Brain Computer Interface (BCI) classification problems using EEG signals. For this problem our method performs significantly better than Convolutional Deep Belief Network(CDBN).	aggregate data;artificial neural network;autoencoder;benchmark (computing);biometrics;brain–computer interface;convolutional neural network;deep belief network;deep learning;dictionary;electroencephalography;experiment;feature extraction;formal verification;k-svd;mnist database;machine learning;multiclass classification;naivety;sample rate conversion;software framework;sparse approximation;sparse language;sparse matrix;test data	Prerna Khurana;Angshul Majumdar;Rabab Kreidieh Ward	2016	2016 International Joint Conference on Neural Networks (IJCNN)	10.1109/IJCNN.2016.7727656	speech recognition;computer science;machine learning;pattern recognition;deep learning;deep belief network	AI	22.49048182521144	-46.53784755679462	38378
46d183272ce49a422ff1d760312b952dcc6647c8	fault diagnosis for industrial images using a min-max modular neural network	transformation ondelette;distributed system;systeme reparti;image processing;metodo minimax;extraction forme;fonction base radiale;minimax method;procesamiento imagen;traitement image;sistema repartido;radial basis function;diagnostic panne;extraccion forma;radial basis function network;fault diagnostic;machine exemple support;image industrielle;methode minimax;diagnostico pana;transformacion ondita;support vector machine;maquina ejemplo soporte;vector support machine;reseau neuronal;funcion radial base;pattern extraction;modular neural network;red neuronal;wavelet transformation;fault diagnosis;neural network	This paper presents a new fault diagnosis method for indus- trial images based on a Min-Max Modular (M 3 ) neural network and a Gaussian Zero-Crossing (GZC) function. The most important advantage of the proposed method over existing approaches such as radial-basis function network and support vector machines is that our classifier has locally tuned response characteristics and the misclassification rate of faulty product images can be controlled as small as needed by turning two parameters of the GZC function while the correct rate can be in- fluenced to some extend. The experimental results on a real-world fault diagnosis problem of industrial images indicate that the effectiveness of the proposed method.	modular neural network	Bin Huang;Bao-Liang Lu	2004		10.1007/978-3-540-30499-9_129	support vector machine;radial basis function;image processing;computer science;artificial intelligence;machine learning;radial basis function network;artificial neural network;algorithm	Robotics	10.233485255566398	-30.75301040226965	38403
f87f800e0dd9f470171c1ca7e8410d94d67ae2a4	multi-view predictive partitioning in high dimensions	subspace learning;partial least squares;multi view clustering;web data mining;press statistic;predictive partitioning	Abstract#R##N##R##N#Many modern data mining applications are concerned with the analysis of datasets in which the observations are described by paired high-dimensional vectorial representations or ‘views’. Some typical examples can be found in web mining and genomics applications. In this article we present an algorithm for data clustering with multiple views, multi-view predictive partitioning (MVPP), which relies on a novel criterion of predictive similarity between data points. We assume that, within each cluster, the dependence between multivariate views can be modeled by using a two-block partial least squares (TB-PLS) regression model, which performs dimensionality reduction and is particularly suitable for high-dimensional settings. The proposed MVPP algorithm partitions the data such that the within-cluster predictive ability between views is maximized. The proposed objective function depends on a measure of predictive influence of points under the TB-PLS model which has been derived as an extension of the predicted residual sums of squares (PRESS) statistic commonly used in ordinary least squares regression. Using simulated data, we compare the performance of MVPP to that of competing multi-view clustering methods which rely upon geometric structures of points, but ignore the predictive relationship between the two views. State-of-art results are obtained on benchmark web mining datasets. © 2012 Wiley Periodicals, Inc. Statistical Analysis and Data Mining, 2012		Brian McWilliams;Giovanni Montana	2012	Statistical Analysis and Data Mining	10.1002/sam.11144	press statistic;computer science;machine learning;data mining;partial least squares regression;statistics	ML	-1.113471242714573	-42.366915181224094	38417
751aeeddda109567d4911d6baa906e9c9c4472c4	utilization of stochastic automata and genetic algorithms for neural network learning.	neural network			Norio Baba	1992			stochastic neural network;nervous system network models;cellular neural network;probabilistic neural network;types of artificial neural networks;computer science;artificial intelligence;recurrent neural network;theoretical computer science;machine learning;time delay neural network;deep learning;artificial neural network	AI	13.26008245785416	-27.082555738966946	38419
04f13d6977899806b145fd8310a4172ed115f8d7	reconstruction of cylinder pressure for si engine using recurrent neural network	systeme commande;sistema control;calcul neuronal;neural computation;engine control;vehiculo caminero;vehicule routier;cylinder pressure;reconstruction;ley gran numero;loi grand nombre;punto limite;experimental result;law of large numbers;captador medida;point limite;control system;feedback;measurement sensor;capteur mesure;monitoring;model matching;limit point;spark ignition engine;resultado experimental;reseau neuronal recurrent;recurrent neural nets;monitorage;recurrent neural network;reseau neuronal;boucle reaction;resultat experimental;pressure reconstruction;monitoreo;retroalimentacion;road vehicle;data validation;red neuronal;computacion neuronal;reconstruccion;neural network	Cylinder pressure based engine control systems use variables deduced from cylinder pressure as a feedback input. Monitoring of cylinder pressure is possible through various intrusive and nonintrusive sensors but cost of these sensors limits their use in the engines of on-road vehicles. In the present work, a recurrent neural network (RNN) is proposed which can reconstruct cylinder pressure of spark ignition engine. The network uses instantaneous crankshaft speed and motored pressure as inputs. Initially, parameters of two-zone model are tuned at limited number of experimental points, so that cylinder pressure predicted by model matches to that of experimental results. Further, the tuned model is used to generate large number of training data. Validation has been carried out using experimental as well as simulated pressure trace. It has been found that RNN can reconstruct cylinder pressure with reasonably good accuracy.	algorithmic efficiency;artificial neural network;control system;cylinder seal;cylinder-head-sector;embedded system;engine control unit;recurrent neural network;sensor	Samir Saraswati;Satish Chand	2010	Neural Computing and Applications	10.1007/s00521-010-0420-6	limit point;simulation;law of large numbers;computer science;control system;recurrent neural network;machine learning;data validation;control theory;feedback;artificial neural network;models of neural computation	Robotics	10.006926709817575	-24.451057950876294	38432
8fdd43edc51d40d41c54f5a748b36476a329f8b9	a new comparison theorem on conditional quantiles	comparison theorem;generalization error;learning theory;pinball loss;quantile regression	Abstract This paper studies the conditional quantile regression problem involving the pinball loss. We introduce a concept of τ -quantile of p -average logarithmic type q to complement the previous study by Steinwart and Christman (2008, 2011)  [1] , [2] . A new comparison theorem is provided which can be used for further error analysis of some learning algorithms.		Dao-Hong Xiang	2012	Appl. Math. Lett.	10.1016/j.aml.2011.05.048	econometrics;discrete mathematics;quantile regression;mathematics;statistics	Logic	20.857215613728894	-31.419842895353955	38444
ce3832eaa3817fe2fc4053d8207422fa637b0075	logistic label propagation	label propagation;semi supervised learning;gradient descent;similarity;logistic function	In this paper, we propose a novel method for semi-supervised learning, called logistic label propagation (LLP). The proposed method employs the logistic function to classify input pattern vectors, similarly to logistic regression. To cope with unlabeled samples as well as labeled ones in the semi-supervised learning framework, the logistic functions are learnt by using similarities between samples in a manner similar to label propagation. In the proposed method, these two methods of logistic regression and label propagation are effectively incorporated in terms of posterior probabilities. LLP estimates the labels of input samples by using the learnt logistic function, whereas the method of label propagation has to optimize the whole labels whenever an input sample comes. In addition, we suggest the way to provide proper parameter setting and initialization, which frees the users from determining a parameter value in trial and error. In experiments on classification (estimating labels) in the semi-supervised learning framework, the proposed method exhibits favorable performances compared to the other methods.	software propagation	Takumi Kobayashi;Kenji Watanabe;Nobuyuki Otsu	2012	Pattern Recognition Letters	10.1016/j.patrec.2011.12.005	semi-supervised learning;gradient descent;logistic function;similarity;computer science;machine learning;pattern recognition;mathematics;logistic model tree;multinomial logistic regression;statistics	Vision	19.14379534996141	-40.74898055211053	38475
5a4f4389d8baa222acfc259d702ac5bde8aeff76	a stochastic search algorithm to optimize an n-tuple classifier by selecting its inputs	statistical pattern recognition;pattern recognition;error rate;stochastic search;class group	  The N-tuple method [4] is a statistical pattern recognition method, which decomposes a given pattern into several sets of  n points, termed “N tuples”. The input connection mapping of the N-tuple classifier determines the sampling and defines the  locations of the pattern matrix. Realizing the fact that the classification performance of the N-tuple classifier is highly  dependant on the actual subset of the input bits probed [3][7], we have introduced an approach based on a Reward and Punishment  (RnP) scheme to select input mappings of the classifier. We termed the classes with high error rates as critical classes.  Different groups of tuples have been formed for different classes. The strategy was to employ more number of tuples to a critical  class-group than an easily distinguishable class. In order to illustrate the capabilities of the RnP based measure the task  of recognizing hand-written digits from NIST [10] database has been chosen.    	search algorithm;stochastic optimization	M. A. Hannan Bin Azhar;Keith R. Dimond	2004		10.1007/978-3-540-30125-7_69	feature;word error rate;computer science;machine learning;pattern recognition;data mining	AI	10.280072232252527	-42.1581260540082	38480
d431224fb9b010bfd00917a89a1c8856e65dfd61	an efficient algorithm for pawlak reduction based on simplified discernibility matrix	attribute reduction;complexity.;discernibility matrix;rough set;simplified discernibility matrix;equivalence relation	Since the definition of attribute reduction based on classic discernibility matrix is different from the definition of attribute  reduction based on positive region, simplified discernibility matrix and the corresponding definition of attribute reduction  are proposed. At the same time, it is proved that the proposed definition of attribute reduction is identical to the definition  of attribution reduction based on positive region. For computing simplified discernibility matrix, IND(C) should usually be calculated at first, so a new algorithm for computing IND(C) is designed, whose temporal complexity is cut down to O(|C||U|). Furthermore, an efficient attribute reduction algorithm is proposed, whose temporal complexity and spatial complexity  are cut down to max(O(|</font >C|</font >2|</font >U¢</font >pos|</font >|</font >U¢</font >|</font >, O(|</font >U|</font >|</font >C|</font >))\max(O(|C|^2|U'_{pos}||U'|, O(|U||C|)) and max (O(|C||U′  pos  ||U′|, O(|U|)) respectively. At last, an example is used to illustrate the efficiency of the new algorithms.  	algorithm	Zhangyan Xu;Bingru Yang	2008		10.1007/978-3-540-88914-4_75	combinatorics;discrete mathematics;complexity;rough set;computer science;machine learning;mathematics;equivalence relation;algorithm	EDA	-3.0729072518326728	-25.9529422970777	38507
36b5dbf204997ac961dd1e2002b536a6dd05a9e7	ergp: a combined entity resolution approach with genetic programming	erbium;data integration entity resolution genetic programming;genetic programming;erbium classification algorithms sociology statistics genetic programming training data;pattern classification data integration genetic algorithms;training data;classification algorithms;statistics;entity resolution;attribute pair ergp combined entity resolution approach with genetic programming data sources data integration data cleaning effective entity resolution classifier;sociology;data integration	Entities often hold more than one representation with some expressive errors in different data sources in the real world. Different representations and a few possible expressive errors make entities identifying a crucial task in data integration and data cleaning, which is known as entity resolution. We propose a novel approach for entity resolution using genetic programming named Entity Resolution with Genetic Programming (ERGP). ERGP is able to learn to get an effective entity resolution classifier by combining several different properties' comparisons. The evaluation shows that ERGP outperforms the state-of-the-art entity resolution algorithms. Above all the ERGP approach is capable of setting the threshold for each single comparison of an attributes' pair, leaving no burden of setting thresholds to the user.	algorithm;erdős–rényi model;genetic programming;named entity;plasma cleaning	Chenchen Sun;Derong Shen;Yue Kou;Tiezheng Nie;Ge Yu	2014	2014 11th Web Information System and Application Conference	10.1109/WISA.2014.46	computer science;machine learning;genetic representation;pattern recognition;data mining	AI	14.429213598142175	-42.93449842192294	38524
87f32c2cb528c1c82d508ecb68cfdf03add4b62e	using genetic programming for the induction of oblique decision trees	model selection;computational intelligence computational modeling data mining machine learning artificial intelligence impedance matching application software user interfaces heart recommender systems;knowledge based system;learning artificial intelligence data mining;computational intelligence;data mining;computational intelligence model;knowledge based system computational intelligence model ai systems data mining recommender system;recommender system;ai systems;learning artificial intelligence;knowledge base	In this paper, we present a genetically induced oblique decision tree algorithm. In traditional decision tree, each internal node has a testing criterion involving a single attribute. Oblique decision tree allows testing criterion to consist of more than one attribute. Here we use genetic programming to evolve and find an optimal testing criterion in each internal node for the set of samples at that node. This testing criterion is the characteristic function of a relation over existing attributes. We present the algorithm for construction of the oblique decision tree. We also compare the results of our proposed oblique decision tree with the one of C4.5 algorithm.	c++;c4.5 algorithm;characteristic function (convex analysis);computation;decision tree;experiment;fitness function;genetic programming;interpreted language;java;list of algorithms;machine learning;oblique projection;time complexity;tree (data structure);weka	Amin Shali;Mohammad Reza Kangavari;Bahareh Bina	2007	Sixth International Conference on Machine Learning and Applications (ICMLA 2007)	10.1109/ICMLA.2007.66	knowledge base;computer science;artificial intelligence;data science;machine learning;computational intelligence;ai-complete;artificial intelligence, situated approach;model selection;recommender system	ML	5.03317740309227	-30.078387706887998	38530
533a54c5814bfb4fcf13bdf261446bd2552ca84e	optimal allocation of information granularity in system modeling through the maximization of information specificity: a development of granular input space	fuzzy models;granular input space;information granules;global sensitivity;interval arithmetic	A concept of a granular input space in system modeling is introduced.We construct granular input variables maximizing a level of specificity of results.The idea treats information granularity as an essential design asset.Comparative studies based on global sensitivity analysis are completed. In this study, we introduce a concept of a granular input space in system modeling, in particular in fuzzy rule-based modeling. The underlying problem can be succinctly formulated in the following way: given is a numeric model, develop an efficient way of forming granular input variables so that the corresponding granular outputs of the model achieve the highest level of specificity. The rationale behind the formulation of the problem is offered along with several illustrative examples. In conjunction with the underlying idea, developed is an algorithmic framework supporting an optimization of the specificity of the model exposed to granular inputs (data). It is dwelled upon one of the principles of Granular Computing, namely an optimal allocation of information granularity. For illustrative purposes, the study is focused on information granules formalized in terms of intervals (however the proposed approach becomes equally relevant for other formalism of information granules). Some comparative analysis with the existing idea of global sensitivity analysis is also carried out by contrasting the essential differences among the two approaches and analyzing the results of computational experiments.	expectation–maximization algorithm;mathematical optimization;sensitivity and specificity;systems modeling	Xingchen Hu;Witold Pedrycz;Xianmin Wang	2016	Appl. Soft Comput.	10.1016/j.asoc.2016.02.001	mathematical optimization;artificial intelligence;theoretical computer science;machine learning;mathematics;interval arithmetic	Robotics	1.4848511251255385	-26.842267569210506	38585
00f6a50adc8ff51ae134b6abbe56d5b9289ab3ad	multi-segments naïve bayes classifier in likelihood space			naive bayes classifier	Zhenchong Zhao;Xiaodan Wang	2018	IET Computer Vision	10.1049/iet-cvi.2017.0546	naive bayes classifier;artificial intelligence;pattern recognition;mathematics	Vision	9.354157046766872	-36.760763493733414	38600
d367424329e468dea4f5b8a9c8e2d07eeaacea45	multi-dimensional classification with super-classes	bayes methods;integrated circuit modeling accuracy training vectors bayes methods context;training;problem transformation;classification;multi dimensional classification;multi dimensional;accuracy;vectors;tractable running time super classes multidimensional classification problem recently popularized task multilabel classification data instance multiple class variables core goals multilabel research conditional dependence super class partitions multidimensional learners ordinary class modeling class dependencies multidimensional datasets evaluation metrics;matematicas;integrated circuit modeling;pattern classification;context	The multi-dimensional classification problem is a generalization of the recently-popularized task of multi-label classification, where each data instance is associated with multiple class variables. There has been relatively little research carried out specific to multi-dimensional classification and, although one of the core goals is similar (modeling dependencies among classes), there are important differences; namely a higher number of possible classifications. In this paper we present method for multi-dimensional classification, drawing from the most relevant multi-label research, and combining it with important novel developments. Using a fast method to model the conditional dependence between class variables, we form super-class partitions and use them to build multi-dimensional learners, learning each super-class as an ordinary class, and thus explicitly modeling class dependencies. Additionally, we present a mechanism to deal with the many class values inherent to super-classes, and thus make learning efficient. To investigate the effectiveness of this approach we carry out an empirical evaluation on a range of multi-dimensional datasets, under different evaluation metrics, and in comparison with high-performing existing multi-dimensional approaches from the literature. Analysis of results shows that our approach offers important performance gains over competing methods, while also exhibiting tractable running time.	cobham's thesis;conditional entropy;evaluation function;multi-label classification;test set;time complexity	Jesse Read;Concha Bielza;Pedro Larrañaga	2014	IEEE Transactions on Knowledge and Data Engineering	10.1109/TKDE.2013.167	biological classification;artificial intelligence;machine learning;classification rule;pattern recognition;data mining;mathematics;accuracy and precision;soft independent modelling of class analogies;one-class classification;statistics	DB	18.604326348967138	-41.233335095281255	38667
8e563e76083a98dfbc9175998a47cf59097e8c65	dependence guided unsupervised feature selection		In the past decade, various sparse learning based unsupervised feature selection methods have been developed. However, most existing studies adopt a two-step strategy. i.e., selecting the top-m features according to a calculated descending order and then performing K-means clustering, resulting in a group of sub-optimal features. To address this problem, we propose a Dependence Guided Unsupervised Feature Selection (DGUFS) method to select features and partition data in a joint manner. Our proposed method enhances the interdependence among original data, cluster labels, and selected features. In particular, a projection-free feature selection model is proposed based on l2,0-norm equality constraints. We utilize the learned cluster labels to fill in the information gap between original data and selected features. Two dependence guided terms are consequently proposed for our model. More specifically, one term increases the dependence of desired cluster labels on original data, while the other term maximizes the dependence of selected features on cluster labels to guide the process of feature selection. Last but not least, an iterative algorithm based on Alternating Direction Method of Multipliers (ADMM) is designed to solve the constrained minimization problem efficiently. Extensive experiments on different datasets consistently demonstrate that our proposed method significantly outperforms state-of-the-art baselines.	algorithm;augmented lagrangian method;baseline (configuration management);cluster analysis;experiment;feature selection;interdependence;iterative method;k-means clustering;mathematical optimization;sorting;sparse matrix	Jun Guo;Wenwu Zhu	2018			artificial intelligence;machine learning;feature selection;computer science	AI	22.654235078936384	-42.95308314889386	38701
aacfa8b1a2c7d585c175e3a7edc280bc0aad4ef4	dnq: dynamic network quantization		Network quantization is an effective method for the deployment of neural networks on memory and energy constrained mobile devices. In this paper, we propose a Dynamic Network Quantization (DNQ) framework which is composed of two modules: a bit-width controller and a quantizer. Unlike most existing quantization methods that use a universal quantization bit-width for the whole network, we utilize policy gradient to train an agent to learn the bit-width of each layer by the bit-width controller. This controller can make a trade-off between accuracy and compression ratio. Given the quantization bit-width sequence, the quantizer adopts the quantization distance as the criterion of the weights importance during quantization. We extensively validate the proposed approach on various main-stream neural networks and obtain impressive results.		Yuhui Xu;Shuai Zhang;Yingyong Qi;Jiaxian Guo;Weiyao Lin;Hongkai Xiong	2018	CoRR		compression ratio;computer engineering;control theory;theoretical computer science;software deployment;quantization (signal processing);artificial neural network;computer science;dynamic network analysis;effective method;mobile device	AI	23.546871016026028	-50.20853981533642	38722
be3b1950fe062a3f5d39de02198486f422f7258c	extension and use of kmrcrelat algorithm for biological problems	biological sequences;sequences;word train;words;relational patterns;microsatellite identification;locus identification;repetitions;pattern recognition;patterns	The main goal of this paper is to present a new extension of KMRCRelat algorithm allowing Word Train searches. First, we recall the fundamental lemma of our KMRCRelat algorithm and we focus on the concept of flexible relational repeated words. Then, we introduce the concept of Word Trains and we show, in deep, the needed modification and extension to include such features in this algorithm. To illustrate Word Train searches, we present all details about KMRCRelat extension computation steps. We also show how this new extension is applicable to the characterization of short tandem repeat in DNA sequence providing an alternative way to solve originally this known problem in sequence analysis. Before concluding by introducing other possible KMRCRelat applications, the paper expands a set of experimental results obtained when applied to locus identification problem.	algorithm	Nahla El Zant El Kadhi;Nabil El-Kadhi;Pierre-Antoine Gourraud	2006	J. Comput. Meth. in Science and Engineering		artificial intelligence;machine learning;sequence;mathematics;pattern;algorithm	Theory	1.1516145709425207	-47.13842262568943	38723
16da39ed18a8dac06924edd852e61902eb93d37a	a new approach for testing artificial neural networks	interconnection deletion faults;activation function gains;activation function;automatic testing;activation function gains testing artificial neural networks interconnection deletion faults transient behavior faulted ann;testing;neural chips;artificial neural networks;built in self test;automatic testing neural chips integrated circuit testing vlsi built in self test;integrated circuit testing;vlsi;faulted ann;artificial neural network;transient behavior;artificial neural networks circuit testing circuit faults neurons electronic equipment testing electrical fault detection integrated circuit interconnections automatic testing manufacturing circuit simulation	This paper presents progress on a new and novel testing approach for detecting interconnection deletion faults in electronic implementations of art$cial neural networks (ANNs). The testing approach is based on an unusual transient behavior manifested by faulted ANNs showing better apparent performance than fault-free ANNs, when neurons are operated with low activation function gains. The result presented in this paper improves on prior results by requiring fewer test patterns.	activation function;artificial neural network;interconnection;sensor;test card	C. A. Fleischer;Lee A. Belfore	1997		10.1109/VTEST.1997.600282	electronic engineering;computer science;engineering;artificial intelligence;machine learning;software testing;very-large-scale integration;activation function;artificial neural network	ML	15.633215650259753	-26.351549012272923	38724
2af733d1a779e69c62b0b2b4b40d8667702cff4d	regularizing face verification nets for pain intensity regression		Limited labeled data are available for the research of estimating facial expression intensities. For instance, the ability to train deep networks for automated pain assessment is limited by small datasets with labels of patient-reported pain intensities. Fortunately, fine-tuning from a data-extensive pre-trained domain, such as face verification, can alleviate this problem. In this paper, we propose a network that fine-tunes a state-of-the-art face verification network using a regularized regression loss and additional data with expression labels. In this way, the expression intensity regression task can benefit from the rich feature representations trained on a huge amount of data for face verification. The proposed regularized deep regressor is applied to estimate the pain expression intensity and verified on the widely-used UNBC-McMaster Shoulder-Pain dataset, achieving the state-of-the-art performance. A weighted evaluation metric is also proposed to address the imbalance issue of different pain intensities.		Feng Wang;Xiang Xiang;Chang Liu;Trac D. Tran;Austin Reiter;Gregory D. Hager;Harry Quon;Jian Cheng;Alan L. Yuille	2017	2017 IEEE International Conference on Image Processing (ICIP)	10.1109/ICIP.2017.8296449	fine-tuning;artificial intelligence;computer vision;labeled data;pain assessment;pattern recognition;computer science;convolution;facial expression;machine learning	Vision	22.617593014583385	-49.85635827607882	38746
21e4a2fcae340b8fb4d41fb9f07c5a22ee657a19	indiscernibility degree of objects for evaluating simplicity of knowledge in the clustering procedure	iterative refinement;pattern clustering;rough set theory;very large databases pattern clustering equivalence classes rough set theory data mining;data mining;equivalence relation;clustering method;coarse clusters indiscernibility degree clustering procedure rough set based clustering method classification knowledge simplicity evaluation iterative refinement equivalence relations coarse classification equivalence class threshold level simple clusters artificial data equivalence relation;equivalence classes;very large databases;rough set;databases data analysis clustering methods rough sets biomedical informatics scalability clustering algorithms algorithm design and analysis set theory sections	The paper presents a novel, rough set-based clustering method that enables the evaluation of classification knowledge simplicity during the clustering procedure. The method iteratively refines equivalence relations so that they become a more simple set of relations that give adequate coarse classification to the objects. At each step of the iteration, the importance of the equivalence relation is evaluated on the basis of the newly introduced measure, indiscernibility degree. An indiscernibility degree is defined as a ratio of equivalence relations that classify the two objects into the same equivalence class. If an equivalence relation has the ability to discern two objects that have a high indiscernibility degree, a very fine classification is performed and then modified to regard them as indiscernible objects. The refinement is repeated, decreasing the threshold level of indiscernibility degree, and finally simple clusters can be obtained. Experimental results on the artificial data shows that iterative refinement of equivalence relation leads to successful generation of coarse clusters that can be represented by simple knowledge.	computer cluster	Shoji Hirano;Shusaku Tsumoto	2001		10.1109/ICDM.2001.989521	correlation clustering;combinatorics;discrete mathematics;rough set;fuzzy clustering;computer science;equivalence partitioning;machine learning;data mining;mathematics;cluster analysis	ML	-3.649188616186564	-36.20558862592446	38750
3b517e3da39970c6e1b183577873a6295a3b2212	efficient lazy elimination for averaged one-dependence estimators	time complexity;naive bayes	Semi-naive Bayesian classifiers seek to retain the numerous strengths of naive Bayes while reducing error by relaxing the attribute independence assumption. Backwards Sequential Elimination (BSE) is a wrapper technique for attribute elimination that has proved effective at this task. We explore a new technique, Lazy Elimination (LE), which eliminates highly related attribute-values at classification time without the computational overheads inherent in wrapper techniques. We analyze the effect of LE and BSE on a state-of-the-art semi-naive Bayesian algorithm Averaged One-Dependence Estimators (AODE). Our experiments show that LE significantly reduces bias and error without undue computation, while BSE significantly reduces bias but not error, with high training time complexity. In the context of AODE, LE has a significant advantage over BSE in both computational efficiency and error.	algorithm;averaged one-dependence estimators;bayesian network;biological systems engineering;computation;experiment;lazy evaluation;naive bayes classifier;semiconductor industry;time complexity	Fei Zheng;Geoffrey I. Webb	2006		10.1145/1143844.1143984	time complexity;naive bayes classifier;computer science;machine learning;data mining;statistics	ML	16.294464111385622	-36.89121688705098	38752
54f6d8cdc97ec2cf710b277354439eea51e3f6cc	parallelizing clustering of geoscientific data sets using data streams	data mining pattern clustering geophysics computing scientific information systems;histograms;grid cell clustering parallelization geoscientific data sets data mining algorithms data set clustering massive geospatial data sets data stream paradigm partial merge k means algorithm volatile memory processing power partial data stream operator ram weighted k means data subset performance evaluation one step algorithm computation time data density;pattern clustering;grid cell;instruments;image coding;ram;performance evaluation;earth;data stream;data density;k means;clustering algorithms grid computing histograms scalability instruments data mining algorithm design and analysis earth satellites image coding;data mining;data stream paradigm;one step algorithm;geophysics computing;data set clustering;geoscientific data sets;partial merge k means algorithm;satellites;data mining algorithm;clustering parallelization;weighted k means;volatile memory;partial data stream operator;data mining algorithms;clustering algorithms;k means algorithm;scalability;computation time;processing power;data subset;grid computing;massive geospatial data sets;geospatial data;algorithm design and analysis;scientific information systems	Computing data mining algorithms such as clustering on massive geospatial data sets is still not feasible nor efficient today. In this paper, we introduce a k-means algorithm that is based on the data stream paradigm. The so-called partial/merge k-means algorithm is implemented as a set of data stream operators which are adaptable to available computing resources such as volatile memory and processing power. The partial data stream operator consumes as much data as can befit into RAM, and performs a weighted k-means on the data subset. Subsequently, the weighted partial results are merged by a second data stream operator. All operators can be cloned, and parallelized. In our analytical and experimental performance evaluation, we demonstrate that the partial/merge k-means can outperform a one-step algorithm by a large margin with regard to overall computation time and clustering quality with increasing data density per grid cell.	algorithm;areal density (computer storage);automatic parallelization;central processing unit;cluster analysis;computation;data mining;grid (spatial index);ibm notes;k-means clustering;parallel computing;performance evaluation;programming paradigm;random-access memory;scalability;spatial analysis;test case;time complexity;volatile memory	Silvia Nittel;Kelvin T. Leung	2004	Proceedings. 16th International Conference on Scientific and Statistical Database Management, 2004.	10.1109/SSDBM.2004.58	data stream clustering;computer science;theoretical computer science;geospatial analysis;data mining;database;data stream mining;k-means clustering	DB	-2.6595379024529393	-40.402904899563026	38774
92b17fa69dc5e31d3f0c0dc8e26278f24adfc233	using unsupervised machine learning methods in high-throughput screening	unsupervised machine learning;high throughput screening		machine learning;throughput	Chérif Mballo;Vladimir Makarenkov	2010			high-throughput screening;machine learning;unsupervised learning;artificial intelligence;pattern recognition;computer science	ML	7.034610163270744	-45.894754246599604	38782
99bbbfc449f4ce9615b9577085e09cb4c4e5c152	a soft sensor based on multiple neural networks combined with two information fusion methods	pattern clustering;fuzzy c mean;neural nets;advanced process control;sensor model;bayes methods;soft sensing;pulp kappa number;pulp kappa number soft sensing multiple neural networks fuzzy c means clustering bayesian method;sensor fusion bayes methods fuzzy set theory neural nets pattern clustering process control;information fusion methods;fuzzy set theory;bayesian method;multiple networks;pulp kappa number soft sensor multiple neural networks information fusion methods process control applications industrial processes generalization capability multiple networks bayesian method fuzzy c means clustering;soft sensor;process control applications;process control;multiple neural networks;information fusion;sensor fusion;fuzzy c means clustering;sensor fusion neural networks multi layer neural network artificial neural networks robustness process control bayesian methods electrical equipment industry artificial intelligence predictive models;industrial processes;neural network;generalization capability	Soft sensors are especially required in lots of advanced process control applications. The ANN based soft sensor are widely studied recently. But the ANN is an uncertain method in nature. In view of the complexity of the industrial processes, the robustness is an important criterion to evaluate a model. The generalization capability is another factor to affect the applicability of a model. Aiming at improving the robustness and generalization capability of a system, a two-level architecture MNN model is proposed for soft sensor modeling. In our model, multiple networks are combined with the Bayesian and fuzzy C-means (FCM) clustering combination methods at different levels. Two experiments are conducted to validate the effectiveness of our model. The results reveal that the proposed model exceeds other three models indeed	advanced process control;artificial neural network;benchmark (computing);cluster analysis;computation;experiment;fuzzy clustering;fuzzy cognitive map;memory-level parallelism;parallel computing;quad flat no-leads package;robustness (computer science);sensor;time complexity	Tao Ye;Xuefeng Zhu;Xiangyang Li;Yan Li;Jun Zeng	2006	2006 9th International Conference on Control, Automation, Robotics and Vision	10.1109/ICARCV.2006.345270	advanced process control;bayesian probability;soft sensor;computer science;engineering;artificial intelligence;machine learning;data mining;sensor fusion;fuzzy set;artificial neural network	Robotics	7.831208332626076	-26.90272431339747	38804
e4eaf3eed659a161331e455e5fe9b2e4c3224c1f	learning from label proportions by optimizing cluster model selection	conditional exponential model;better prediction performance;supervised learning scenario;label proportion;particular label;optimizing cluster model selection;quality control;output value;method empirically;kernel k-means;final production station	In a supervised learning scenario, we learn a mapping from input to output values, based on labeled examples. Can we learn such a mapping also from groups of unlabeled observations, only knowing, for each group, the proportion of observations with a particular label? Solutions have real world applications. Here, we consider groups of steel sticks as samples in quality control. Since the steel sticks cannot be marked individually, for each group of sticks it is only known how many sticks of high (low) quality it contains. We want to predict the achieved quality for each stick before it reaches the final production station and quality control, in order to save resources. We define the problem of learning from label proportions and present a solution based on clustering. Our method empirically shows a better prediction performance than recent approaches based on probabilistic SVMs, Kernel k-Means or conditional exponential models.	algorithm;best, worst and average case;cluster analysis;k-means clustering;model selection;optimizing compiler;supervised learning;time complexity	Marco Stolpe;Katharina Morik	2011		10.1007/978-3-642-23808-6_23	computer science;artificial intelligence;machine learning;data mining	ML	15.805619088513348	-39.35091335493757	38841
34b8e675d4651db45e484da34f3c415c60ef3ea2	darkrank: accelerating deep metric learning via cross sample similarities transfer		We have witnessed rapid evolution of deep neural network architecture design in the past years. These latest progresses greatly facilitate the developments in various areas such as computer vision and natural language processing. However, along with the extraordinary performance, these state-of-theart models also bring in expensive computational cost. Directly deploying these models into applications with real-time requirement is still infeasible. Recently, Hinton et al. (?) have shown that the dark knowledge within a powerful teacher model can significantly help the training of a smaller and faster student network. These knowledge are vastly beneficial to improve the generalization ability of the student model. Inspired by their work, we introduce a new type of knowledge – cross sample similarities for model compression and acceleration. This knowledge can be naturally derived from deep metric learning model. To transfer them, we bring the “learning to rank” technique into deep metric learning formulation. We test our proposed DarkRank method on various metric learning tasks including pedestrian re-identification, image retrieval and image clustering. The results are quite encouraging. Our method can improve over the baseline method by a large margin. Moreover, it is fully compatible with other existing methods. When combined, the performance can be further boosted.	algorithmic efficiency;artificial neural network;baseline (configuration management);cluster analysis;computer vision;deep learning;image retrieval;learning to rank;margin (machine learning);natural language processing;network architecture;real-time clock;real-time computing	Yuntao Chen;Naiyan Wang;Zhaoxiang Zhang	2018			computer science;architecture;theoretical computer science;machine learning;artificial intelligence;learning to rank;artificial neural network	AI	24.085448388103007	-51.091458159434985	38867
1ef9ea5c2680fa743a495545a493ef1f5cf69b0c	using evolutionary learning classifiers to do mobilespam (sms) filtering	system exploits;network security;short message service;classifier system;evolutionary classifiers;false alarm rate;mobile phone;spam filtering;short messaging service;security and privacy;detection rate;evolutionary learning;spam sms	In recent years, we have witnessed the dramatic increase in the volume of mobile SMS (Short Messaging Service) spam. The reason is that operators - owing to fierce market competition - have introduced packages that allow their customers to send unlimited SMS in less than $1 a month. It not only degrades the service of cellular operators but also compromises security and privacy of users. In this paper, we analyze SMS spam to identify novel features that distinguishes it from benign SMS (ham). The novelty of our approach is that we intercept the SMS at the access layer of a mobile phone - in hexadecimal format - and extract two features: (1) octet bigrams, and (2) frequency distribution of octets. Later, we provide these features to a number of evolutionary and non-evolutionary classifiers to identify the best classifier for our mobile spam filtering system. We evaluate the detection rate and false alarm rate of our system - using different classifiers - on a real world dataset. The results of our experiments show that sUpervised Classifier System (UCS), by operating on the the above-mentioned features'set, achieves more than 89% detection rate and 0% false alarm rate.	bigram;email filtering;experiment;hexadecimal;learning classifier system;machine learning;mobile phone;octet (computing);spamming;visual intercept	Muhammad Bilal Junaid;Muddassar Farooq	2011		10.1145/2001576.2001817	concatenated sms;computer science;network security;machine learning;constant false alarm rate;internet privacy;world wide web;computer security;short message service	Security	4.8946278188187655	-36.94169702541769	38919
b1d2b5114e450052dbcfa8ad5c72847cb558f117	a semantic subspace learning method to exploit relevance feedback log data for image retrieval	relevance feedback content based retrieval image retrieval learning artificial intelligence;real world image database semantic subspace learning method relevance feedback log data content based image retrieval cbir systems euclidean distance metric high dimensional visual feature space cbir performance rf log data ssl method contextual information image retrieval task low dimensional semantic concept subspace;semantics radio frequency image retrieval visualization euclidean distance;learning artificial intelligence;relevance feedback;content based retrieval;image retrieval	Conventional content-based image retrieval (CBIR) systems with the Euclidean distance metric in a high-dimensional visual feature space usually cannot achieve satisfactory performance due to the semantic gap. Relevance feedback (RF) has been introduced as a powerful tool to involve the user in the system to improve the performance of CBIR. Despite the success, an on-line learning task can be tedious and boring for the user. Various schemes have been proposed to exploit the RF log data to further enhance the performance of CBIR. In this paper, we propose a semantic subspace learning (SSL) method to exploit the RF log data with contextual information for an image retrieval task. Different from conventional subspace learning approaches, our method can directly learn a semantic concept subspace from the RF log data with contextual information without using any class label information. We show that the performance of the image retrieval task can be significantly improved in the low-dimensional semantic concept subspace. Extensive experiments on a real-world image database demonstrate the effectiveness of the proposed scheme in improving the performance of CBIR by exploiting the RF log data.	computational intelligence;computer vision;content-based image retrieval;data mining;euclidean distance;experiment;feature vector;online and offline;online machine learning;radio frequency;relevance feedback;world file	Lining Zhang;Lipo Wang;Weisi Lin	2013	2013 IEEE Symposium on Computational Intelligence and Data Mining (CIDM)	10.1109/CIDM.2013.6597234	computer vision;visual word;image retrieval;computer science;machine learning;pattern recognition;information retrieval	Vision	19.469546898290936	-44.78977991770985	38986
2f54df520bf551c107d8794a636f1888e11f70ce	cluster-based congestion outlier detection method on trajectory data	moving object;trajectory clustering;detection algorithms;congestion outlier;minimal bounding boxes trajectory clustering congestion outlier;data mining;cluster based congestion outlier detection;outlier detection;trajectory data;trajectory;moving object data;super dense clusters cluster based congestion outlier detection trajectory data moving object data event based outlier detection data mining spatial information temporal factors spatial factors minimal bounding boxes;spatial factors;clustering method;spatial databases;temporal factors;clustering algorithms;telecommunication congestion control object detection educational institutions computer science detection algorithms intelligent transportation systems fuzzy systems information science electronic mail data mining;minimal bounding boxes;super dense clusters;cameras;spatial information;event based outlier detection;partitioning algorithms	As the collection of moving object data become much easier, event-based outlier detection such as congestion in trajectory data are becoming increasingly attractive to data mining community. Most of the existing methods only perform the trajectory outlier detection on the spatial information. In this paper, a framework for congestion outlier detection with clustering method was proposed. Trajectory data are analyzed according to both temporal and spatial factors by introducing the concept of minimal bounding boxes (MBBs), and super dense clusters are regarded as congestion outliers. Experiments show the capability and efficiency of the proposed approach.	algorithm;anomaly detection;cluster analysis;data mining;experiment;network congestion;sensor	Xia Ying;Zhang Xu;Wang Guo Yin	2009	2009 Sixth International Conference on Fuzzy Systems and Knowledge Discovery	10.1109/FSKD.2009.504	anomaly detection;computer science;trajectory;machine learning;pattern recognition;data mining;spatial analysis;cluster analysis	DB	-0.7952259081577778	-38.174431718560584	38990
4f17c058ea0287972c6edfa7130df1c831b628de	clustering time series from arma models with clipped data	binary sequence;k means;arma model;euclidean distance;time series;moving average;clustering;distance metric;arma;clustered data	Clustering time series is a problem that has applications in a wide variety of fields, and has recently attracted a large amount of research. In this paper we focus on clustering data derived from Autoregressive Moving Average (ARMA) models using k-means and k-medoids algorithms with the Euclidean distance between estimated model parameters. We justify our choice of clustering technique and distance metric by reproducing results obtained in related research. Our research aim is to assess the affects of discretising data into binary sequences of above and below the median, a process known as clipping, on the clustering of time series. It is known that the fitted AR parameters of clipped data tend asymptotically to the parameters for unclipped data. We exploit this result to demonstrate that for long series the clustering accuracy when using clipped data from the class of ARMA models is not significantly different to that achieved with unclipped data. Next we show that if the data contains outliers then using clipped data produces significantly better clusterings. We then demonstrate that using clipped series requires much less memory and operations such as distance calculations can be much faster. Finally, we demonstrate these advantages on three real world data sets.	algorithm;autoregressive model;clipping (computer graphics);cluster analysis;euclidean distance;k-means clustering;k-medoids;medoid;time series	Anthony J. Bagnall;Gareth J. Janacek	2004		10.1145/1014052.1014061	autoregressive–moving-average model;data stream clustering;metric;surrogate data;k-medians clustering;fuzzy clustering;machine learning;time series;pattern recognition;cure data clustering algorithm;data mining;euclidean distance;pseudorandom binary sequence;mathematics;cluster analysis;moving average;statistics;k-means clustering	ML	-1.3998002329448307	-38.08743672820458	39209
94ef778870db766d9346f1b7857dea8834982c3a	a new technique for classification of digital signal types	classification of signal types;higher order statistics;particle swarm optimization;radial basis function neural network;cross validation	Classification of the communication signals has seen under increasing demands. In this paper, we present a new technique that identifies a variety of digital communication signal types. This technique utilizes a radial basis function neural network (RBFN) as the classifier. Swarm intelligence, as an evolutionary algorithm, is used to construct RBFN. A combination of the higher-order moments and the higher-order cumulants up to eight are selected as the features of the considered digital signal types. In conjunction with RBFN, we have used k-fold cross-validation to improve the generalization potentiality. Simulation results show that the proposed technique has high performance for classification of different communication signals even at very low signal-to-noise ratios.	artificial neural network;cross-validation (statistics);evolutionary algorithm;higher-order function;nl (complexity);numerical aperture;phase-shift oscillator;radial (radio);radial basis function;signal-to-noise ratio;simulation;statistical classification;swarm intelligence	Ataollah Ebrahimzadeh;Abolfazl Ranjbar;Mehrdad Ardebilipour	2008	Journal of Circuits, Systems, and Computers	10.1142/S0218126608004617	computer science;engineering;artificial intelligence;machine learning;pattern recognition;particle swarm optimization;cross-validation	PL	11.000512531912824	-35.9120278691518	39213
e48be30076281ce3f25df3e6683ef1c73f734e9b	fault diagnosis based on orthogonal semi-supervised lltsa for feature extraction and transductive svm for fault identification			feature extraction;semiconductor industry	Jiufei Luo;Haitao Xu;Zuqiang Su;Hong Xiao;Kai Zheng;Yi Zhang	2018	Journal of Intelligent and Fuzzy Systems	10.3233/JIFS-169529	support vector machine;machine learning;mathematics;feature extraction;artificial intelligence;transduction (machine learning)	ML	9.231628805982085	-36.88325215370003	39227
39a24f721566d19cd1e3d348c090d6added866e8	nonlinear mapping algorithm and applications for multidimensional data analysis	nonlinear mapping;multidimensional data	A new algorithm to assist in the analysis of data sets of very high dimensionality (from 10 to over 1000 dimensions) is described. The algorithm is based on a nonlinear mapping (NLM) algorithm developed by Sammon winch maps a configuration of points in one space to a configuration in another such that the distances between points in the two spaces are approximately preserved. Sammon's algorithm is initially used to analyze multidimensional data from a brain mapping experiment. Because the complexity of his algorithm grows quadratically with the number of points, it is limited to relatively small data sets. An extended NLM algorithm is then described that is capable of handling large data sets (e.g., images) by using a multidimensional interpolation approach. A method for interpreting hyperspectral imagery data based on this extended algorithm is illustrated. Finally, the analysis of the structure and content of a collection of text documents using NLM is considered that involves the use of alternative distance measures and binary vectors of extremely high dimensionality (>1000).	algorithm	Mark J. Carlotto	1994	J. Visual Communication and Image Representation	10.1006/jvci.1994.1012	mathematical optimization;ramer–douglas–peucker algorithm;computer science;machine learning;sammon mapping;data mining;mathematics;nonlinear dimensionality reduction;difference-map algorithm	Visualization	-4.065113834190584	-42.70327120643203	39292
74a990b1fefc675c6f043bfe95bd537c98e8cffb	polishing the right apple: anytime classification also benefits data streams with constant arrival times	streaming data;nearest neighbor searches;optimisation;probability;processor scheduling;resource allocation;data stream;training;individual object;probability optimization;overall classification performance data stream classification constant arrival time time sensitive computationally constrained environment satisfactory performance variable response time anytime algorithm probability optimization individual object batch optimization;classification;anytime algorithm;classification algorithms nearest neighbor searches processor scheduling training heuristic algorithms accuracy schedules;accuracy;overall classification performance;heuristic algorithms;resource allocation optimisation pattern classification probability;nearest neighbor;classification algorithms;pattern classification;schedules;batch optimization;time sensitive;variable response time;experimental evaluation;anytime algorithms;constant arrival time;satisfactory performance;computationally constrained environment;data stream classification;streaming data anytime algorithms classification nearest neighbor	Classification of items taken from data streams requires algorithms that operate in time sensitive and computationally constrained environments. Often, the available time for classification is not known a priori and may change as a consequence of external circumstances. Many traditional algorithms are unable to provide satisfactory performance while supporting the highly variable response times that exemplify such applications. In such contexts, anytime algorithms, which are amenable to trading time for accuracy, have been found to be exceptionally useful and constitute an area of increasing research activity. Previous techniques for improving anytime classification have generally been concerned with optimizing the probability of correctly classifying individual objects. However, as we shall see, serially optimizing the probability of correctly classifying individual objects K times, generally gives inferior results to batch optimizing the probability of correctly classifying K objects. In this work, we show that this simple observation can be exploited to improve overall classification performance by using an anytime framework to allocate resources among a set of objects buffered from a fast arriving stream. Our ideas are independent of object arrival behavior, and, perhaps unintuitively, even in data streams with constant arrival rates our technique exhibits a marked improvement in performance. The utility of our approach is demonstrated with extensive experimental evaluations conducted on a wide range of diverse datasets.	anytime algorithm;computation;computational resource;computer performance;concurrency (computer science);exemplification;scheduling (computing);scoring functions for docking;spatial variability;time complexity	Jin Shieh;Eamonn J. Keogh	2010	2010 IEEE International Conference on Data Mining	10.1109/ICDM.2010.120	statistical classification;biological classification;schedule;resource allocation;computer science;machine learning;pattern recognition;probability;data mining;mathematics;accuracy and precision;k-nearest neighbors algorithm;statistics	DB	14.324088550599356	-38.07275742390164	39348
b8d1dfe8b6b563708e540d42d94c4ca712f57fad	online multi-label classification with adaptive model rules		The interest on online classification has been increasing due to data streams systems growth and the need for Multi-label Classification applications have followed the same trend. However, most of classification methods are not performed on-line. Moreover, data streams produce huge amounts of data and the available processing resources may not be sufficient. This work-in-progress paper proposes an algorithm for Multi-label Classification applications in data streams scenarios. The proposed method is derived from multi-target structured regressor AMRules that produces models using subsets of output attributes (output specialization strategy). Performance tests were conducted where the operation modes global, local and subset approaches of the proposed method were compared to each other and to others online multi-label classifiers described in the literature. Three datasets of real scenarios were used for evaluation. The results indicate that the subset specialization mode is competitive in comparison to local and global approaches and to other online multi-label classifiers.	multi-label classification	Ricardo Sousa;João Gama	2016		10.1007/978-3-319-44636-3_6	machine learning;pattern recognition;data mining	Vision	13.857115554422412	-38.24687019517621	39359
03a25a1589bf6c887527c494e7579f9c428cc5bf	minimal cost complexity pruning of meta-classifiers	decision tree;e commerce;real time;intrusion detection;run time system;minimum description length;inductive learning	Integrating multiple learned classification models (classifiers) computed over large and (physically) distributed data sets has been demonstrated as an effective approach to scaling inductive learning techniques, while also boosting the accuracy of individual classifiers. These gains, however, come at the expense of an increased demand for run-time system resources. The final ensemble meta-classifier may consist of a large collection of base classifiers that require increased memory resources while also slowing down classification throughput. To classify unlabeled instances, predictions need to be generated from all base-classifiers before the meta-classifier can produce its final classification. The throughput (prediction rate) of a metaclassifier is of significant importance in real-time systems, such as in e-commerce or intrusion detection. This extended abstract describes a pruning algorithm that is independent of the combining scheme and is used for discarding redundant classifiers without degrading the overall predictive performance of the pruned metaclassifier. To determine the most effective base classifiers, the algorithm takes advantage of the minimal costcomplexity pruning method of the CART learning algorithm (Breiman et al. 1984) which guarantees to find the best (with respect to misclassification cost) pruned tree of a specific size (number of terminal nodes) of an initial unpruned decision tree. An alternative pruning method using Rissanen’s minimum description length is described in (Quinlan & Rivest 1989). Minimal cost complexity pruning associates a complexity parameter with the number of terminal nodes of a decision tree. It prunes decision trees by minimizing the linear combination of the complexity (size) of the tree and its misclassification cost estimate (error rate). The degree of pruning is controlled by adjusting the weight of the complexity parameter, i.e. an increase of this weight parameter results in heavier pruning. Pruning an arbitrary meta-classifier consists of three stages. First we construct a decision tree model (e.g. CART) of the original meta-classifier, by learning its input/output behavior. This new model (a decision	algorithm;alpha–beta pruning;complexity;decision tree learning;decision tree model;e-commerce;image scaling;input/output;intrusion detection system;minimum description length;real-time computing;real-time locating system;ross quinlan;runtime system;tree-meta;throughput;tree (descriptive set theory);word lists by frequency	Andreas L. Prodromidis;Salvatore J. Stolfo	1999			e-commerce;intrusion detection system;minimum description length;computer science;artificial intelligence;theoretical computer science;machine learning;decision tree;data mining	ML	12.941977294061285	-38.615245259053346	39402
7e2b74619b341cad1c019fd884a5a734f68f9797	a learning algorithm and simulations for dendritic neural nets	neural net		algorithm;artificial neural network	Tzusheng Pei	2007			computer science;time delay neural network;competitive learning;artificial neural network;deep learning;rprop;types of artificial neural networks;wake-sleep algorithm;machine learning;leabra;artificial intelligence;pattern recognition	ML	13.303690491363138	-27.64670184611426	39508
8933e983d21c8faf6b46822b25fde3e5663003fe	ac2: a policy gradient actor with primary and secondary critics		We propose AC2, a policy gradient algorithm that employs a primary and a secondary critic to manage both bias and variance in policy gradients. We present through analyses and experiments that performance becomes more stable if a secondary critic concentrates on few problematic states (upper 95-percentile) that cause extreme changes in value estimates. This scheme can keep biases tolerable while lowering variances. We relate our algorithm with critic ensembles that have more components and show that ensemble averaging may not significantly reduce gradient variances in more difficult environments. We test our algorithm in a series of high-dimensional experiments and report better performance than ensembles with more critic components especially in harder environments. In addition, performance is more stable if the secondary critic trains on a few problematic states than by random sampling. Our algorithm reports better reward performance than single critic and other RL models.	algorithm;ensemble averaging (machine learning);experiment;gradient;monte carlo method;randomness;sampling (signal processing);teaching method;variance reduction	Alfonso B. Labao;Prospero C. Naval	2018	2018 International Joint Conference on Neural Networks (IJCNN)	10.1109/IJCNN.2018.8489747	machine learning;pattern recognition;approximation algorithm;ensemble averaging;sampling (statistics);function approximation;computer science;backpropagation;artificial intelligence	ML	18.564516577714347	-32.733869119306206	39531
694a530069cdde5442405d9de3b8173456088424	multi-core based parallel n-path labeling hkm clustering algorithm	pattern clustering;pattern clustering image retrieval multiprocessing systems parallel algorithms;video retrieval parallel algorithm clustering algorithm;clustering algorithms algorithm design and analysis labeling program processors partitioning algorithms entropy multicore processing;multiprocessing systems;multicore processors multicore based parallel n path labeling large dataset patterns hierarchical k means clustering algorithm large scale data analysis visual vocabulary large scale image retrieval large scale video retrieval parallel n path labeling hkm clustering algorithm pnhkm greedy n best paths labeling method gnpl method parallel clustering algorithm;parallel algorithms;image retrieval	The detection of useful patterns in large datasets has attracted considerable interest recently. The hierarchical K-means clustering algorithm (HKM) is very efficient in large scale data analysis. It has been extensively used for building visual vocabulary in large scale image/video retrieval. However, the accuracy and speed of HKM still have room for improvement. In this paper, we propose a Parallel N-path labeling HKM clustering algorithm (PNHKM) which improves on the HKM clustering algorithm in the following ways. Firstly, we adopt a Greedy N-best Paths Labeling (GNPL) method to improve the clustering accuracy. Secondly, we focus on developing a parallel clustering algorithm for multicore processors. Our results confirm that the PNHKM is much faster and more effective.	central processing unit;cluster analysis;greedy algorithm;human killing machine;k-means clustering;multi-core processor;vocabulary	Kaiyang Liao;Guizhong Liu;Zhen Qiao;Chaoteng Liu	2013	2013 IEEE International Conference on Multimedia and Expo Workshops (ICMEW)	10.1109/ICMEW.2013.6618327	correlation clustering;data stream clustering;image retrieval;computer science;theoretical computer science;canopy clustering algorithm;machine learning;pattern recognition;cure data clustering algorithm;parallel algorithm;cluster analysis;brown clustering;clustering high-dimensional data	Robotics	-3.0283382501800764	-40.84824229008301	39603
d65571f0d6f306cb98b4c24a98f0425bb83cc74b	incremental learning of probabilistic rules from clinical databases based on rough set theory	logic;classification;probability;artificial intelligence;algorithms	Several rule induction methods have been introduced in order to discover meaningful knowledge from databases, including medical domain. However, most of the approaches induce rules from all the data in databases and cannot induce incrementally when new samples are derived. In this paper, a new approach to knowledge acquisition, which induce probabilistic rules incrementally by using rough set technique, is introduced and was evaluated on two clinical databases. The results show that this method induces the same rules as those induced by ordinary non-incremental learning methods, which extract rules from all the datasets, but that the former method requires more computational resources than the latter approach.		Shusaku Tsumoto;Hiroshi Tanaka	1997	Proceedings : a conference of the American Medical Informatics Association. AMIA Fall Symposium		knowledge acquisition;incremental learning;rule induction;mathematical computing;database;probabilistic logic;machine learning;rough set;databases as topic;artificial intelligence;computer science	ML	2.791399116836827	-30.60397031080038	39620
1eb409034bffedd522f983cf68e58a695d1b36db	gaussian process approach to remote sensing image classification	hyperspectral imagery;remote sensing image;teledetection;informative vector machine;expectation propagation ep method;gaussian process classification;bayesian classification;expectation propagation method;approximation laplace;theoretical framework;neural networks;support vector machine svm expectation propagation ep method gaussian process gp hyperspectral imagery laplace approximation sparse classification;laplace approximation;support vector machines;analytical approximation methods;neural nets;gaussian processes;approximation method;support vector machine svm;bayes methods;multisource remote sensing image classification;systeme gps;hyperspectral remote sensing image classification;maquina vector soporte;bayesian methods;imagerie;image classification;hyperspectral sensors;curse of dimensionality;covariance;testing;sparse approximation;classification;deteccion a distancia;laplace method;machine vecteur support;imagery;support vector machine classifier;propagacion;global positioning system;geophysical signal processing;fast sparse approximation method;expectation propagation;gaussian process gp;remote sensing;gaussian processes remote sensing image classification bayesian methods hyperspectral sensors hyperspectral imaging approximation methods testing support vector machines support vector machine classification;hyperspectral remote sensing;squared exponential covariance function;gp classifier computational burden;support vector machine classification;approximation methods;imagineria;gaussian process;support vector machine;support vector machine classifier gaussian process classification bayesian classification multisource remote sensing image classification hyperspectral remote sensing image classification analytical approximation methods laplace method expectation propagation method squared exponential covariance function neural network covariance functions gp classifier computational burden fast sparse approximation method informative vector machine	Gaussian processes (GPs) represent a powerful and interesting theoretical framework for Bayesian classification. Despite having gained prominence in recent years, they remain an approach whose potentialities are not yet sufficiently known. In this paper, we propose a thorough investigation of the GP approach for classifying multisource and hyperspectral remote sensing images. To this end, we explore two analytical approximation methods for GP classification, namely, the Laplace and expectation-propagation methods, which are implemented with two different covariance functions, i.e., the squared exponential and neural-network covariance functions. Moreover, we analyze how the computational burden of GP classifiers (GPCs) can be drastically reduced without significant losses in terms of discrimination power through a fast sparse-approximation method like the informative vector machine. Experiments were designed aiming also at testing the sensitivity of GPCs to the number of training samples and to the curse of dimensionality. In general, the obtained classification results show clearly that the GPC can compete seriously with the state-of-the-art support vector machine classifier.	artificial neural network;bayesian network;computer;curse of dimensionality;expectation propagation;gaussian process;information;linear discriminant analysis;software propagation;sparse approximation;sparse matrix;support vector machine;time complexity	Yakoub Bazi;Farid Melgani	2010	IEEE Transactions on Geoscience and Remote Sensing	10.1109/TGRS.2009.2023983	hyperspectral imaging;machine learning;pattern recognition;data mining;mathematics;artificial neural network	ML	24.094437811248966	-38.602417982775606	39654
2c6734baafff31930de169a8780e72c3591fc1bf	kinome-wide activity modeling from diverse public high-quality data sets	genomics;genome human;models statistical;artificial intelligence;regression analysis;humans;protein kinases;databases protein	Large corpora of kinase small molecule inhibitor data are accessible to public sector research from thousands of journal article and patent publications. These data have been generated employing a wide variety of assay methodologies and experimental procedures by numerous laboratories. Here we ask the question how applicable these heterogeneous data sets are to predict kinase activities and which characteristics of the data sets contribute to their utility. We accessed almost 500,000 molecules from the Kinase Knowledge Base (KKB) and after rigorous aggregation and standardization generated over 180 distinct data sets covering all major groups of the human kinome. To assess the value of the data sets, we generated hundreds of classification and regression models. Their rigorous cross-validation and characterization demonstrated highly predictive classification and quantitative models for the majority of kinase targets if a minimum required number of active compounds or structure-activity data points were available. We then applied the best classifiers to compounds most recently profiled in the NIH Library of Integrated Network-based Cellular Signatures (LINCS) program and found good agreement of profiling results with predicted activities. Our results indicate that, although heterogeneous in nature, the publically accessible data sets are exceedingly valuable and well suited to develop highly accurate predictors for practical Kinome-wide virtual screening applications and to complement experimental kinase profiling.	complement system proteins;cross-validation (statistics);data point;genetic heterogeneity;journal article;kinome;knowledge base;laboratory;text corpus;virtual screening;triangulation	Stephan C. Schürer;Steven M. Muskal	2013	Journal of chemical information and modeling	10.1021/ci300403k	genomics;computer science;bioinformatics;data science;data mining;regression analysis	ML	5.308066708426873	-51.48784481651861	39708
20e782184a0769f2423739ba19440f0b9ff8be8d	an algorithm for automatic rule induction	sistema experto;rule induction;learning;connaissance;base connaissance;conocimiento;aprendizaje;identificacion sistema;knowledge;apprentissage;system identification;acquisition;base conocimiento;systeme expert;identification systeme;adquisicion;knowledge base;expert system	This paper presents an improved version of a simple rule induction algorithm known as RULES (‘RULe Extraction System’). Compared to RULES, the new algorithm generally is faster as it requires fewer rule searching operations in its induction process. Furthermore, it allows the user to specify the number of rules to be extracted, is able to deal with incomplete examples and can handle attributes with numerical as well as nominal values. The algorithm has been tested on several applications. Two of these applications, including the identification of a dynamic system, are described in the paper. The results obtained have demonstrated the strong performance of the algorithm.		Duc Truong Pham;M. S. Aksoy	1993	AI in Engineering	10.1016/0954-1810(93)90011-4	knowledge base;system identification;computer science;artificial intelligence;machine learning;fsa-red algorithm;knowledge;expert system;algorithm	AI	7.931521465936074	-29.261385045544145	39757
8331a0fe5d79e50360ef98cf8381113b6fb0fe3e	concept drift learning with alternating learners		Data-driven predictive analytics are in use today across a number of industrial applications, but further integration is hindered by the requirement of similarity among model training and test data distributions. This paper addresses the need of learning from possibly nonstationary data streams, or under concept drift, a commonly seen phenomenon in practical applications. A simple dual-learner ensemble strategy, alternating learners framework, is proposed. A long-memory model learns stable concepts from a long relevant time window, while a short-memory model learns transient concepts from a small recent window. The difference in prediction performance of these two models is monitored and induces an alternating policy to select, update and reset the two models. The method features an online updating mechanism to maintain the ensemble accuracy, and a concept-dependent trigger to focus on relevant data. Through empirical studies the method demonstrates effective tracking and prediction when the steaming data carry abrupt and/or gradual changes.	baseline (configuration management);benchmark (computing);concept drift;google analytics;memory model (programming);numerical analysis;online algorithm;online machine learning;performance prediction;test data	Yunwen Xu;Rui Xu;Weizhong Yan;Paul Ardis	2017	2017 International Joint Conference on Neural Networks (IJCNN)	10.1109/IJCNN.2017.7966109	artificial intelligence;machine learning;empirical research;predictive analytics;data stream mining;concept drift;computer science;pattern recognition;data modeling;test data;training set;phenomenon	ML	14.739072806388483	-37.574013557237116	39773
b892ddf65792f20f2195ddb6e52edef673e75a83	un-normalized hypergraph p-laplacian based semi-supervised learning methods		Most network-based machine learning methods assume that the labels of two adjacent samples in the network are likely to be the same. However, assuming the pairwise relationship between samples is not complete. The information a group of samples that shows very similar pattern and tends to have similar labels is missed. The natural way overcoming the information loss of the above assumption is to represent the feature dataset of samples as the hypergraph. Thus, in this paper, we will present the un-normalized hypergraph p-Laplacian semi-supervised learning methods. These methods will be applied to the zoo dataset and the tiny version of 20 newsgroups dataset. Experiment results show that the accuracy performance measures of these un-normalized hypergraph p-Laplacian based semisupervised learning methods are significantly greater than the accuracy performance measure of the un-normalized hypergraph Laplacian based semi-supervised learning method (the current state of the art method hypergraph Laplacian based semi-supervised learning method for classification problem with p=2).	algorithm;cluster analysis;experiment;laplacian matrix;machine learning;nonlinear dimensionality reduction;semi-supervised learning;semiconductor industry;supervised learning	Loc Hoang Tran;Linh Hoang Tran	2018	CoRR			ML	16.781240676925204	-42.2251218578205	39820
55cb80e7dd7343c245b0625e74f45b2f056180ac	independent subspace analysis using k-nearest neighborhood distances	algorithm analysis;metodo formal;methode formelle;vector space;intelligence artificielle;formal method;multi dimensional;vecino mas cercano;independent subspace analysis;plus proche voisin;artificial intelligence;nearest neighbour;k nearest neighbor;analyse algorithme;inteligencia artificial;espace vectoriel;espacio vectorial;analisis algoritmo;numerical simulation	A novel algorithm called independent subspace analysis (ISA) is introduced to estimate independent subspaces. The algorithm solves the ISA problem by estimating multi-dimensional di erential entropies. Two variants are examined, both of them utilize distances between the k-nearest neighbors of the sample points. Numerical simulations demonstrate the usefulness of the algorithms.	independent computing architecture;jacobi method;k-nearest neighbors algorithm;mathematical optimization;numerical linear algebra;preprocessor;simulation	Barnabás Póczos;András Lörincz	2005		10.1007/11550907_27	computer simulation;formal methods;vector space;computer science;artificial intelligence;machine learning;mathematics;k-nearest neighbors algorithm;algorithm	ML	23.761859878000482	-38.83046889832364	39879
349a3b7b311989418e8c19fab30bc0b00d269c9e	towards an unsupervised method for network anomaly detection in large datasets	cluster;anomaly detection;unsupervised;ensemble;cluster stability	In this paper, we present an e↵ective tree based subspace clustering technique (TreeCLUS) for finding clusters in network intrusion data and for detecting known as well as unknown attacks without using any labelled tra c or signatures or training. To establish its e↵ectiveness in finding appropriate number of clusters, we perform a cluster stability analysis. We also introduce an e↵ective cluster labelling technique (CLUSLab) to label each cluster based on the stable cluster set obtained from TreeCLUS. CLUSLab is a multi-objective technique that employs an ensemble approach for labelling each stable cluster generated by TreeCLUS to achieve high detection rate. We also introduce an e↵ective unsupervised feature clustering technique to identify the dominating feature set from each cluster. We evaluate the performance of both TreeCLUS and CLUSLab in terms of several real world intrusion datasets to identify known as well as unknown attacks and find that results are excellent. 2 M. H. Bhuyan, D. K. Bhattacharyya, J. K. Kalita	anomaly detection;antivirus software;approximation algorithm;cluster analysis;clustering high-dimensional data;data breach;sensor	Monowar H. Bhuyan;Dhruba Kumar Bhattacharyya;Jugal K. Kalita	2014	Computing and Informatics		ensembl;anomaly detection;computer science;machine learning;pattern recognition;data mining;programming language;cluster	ML	5.579295723923743	-37.558211533273074	39915
429ddae43acb53686caf642b3cee6d38461e1ad6	alternating projections for learning with expectation constraints	selected works;bepress	We present an objective function for learning with unlabeled data that utilizes auxiliary expectation constraints. We optimize this objective function using a procedure that alternates between information and moment projections. Our method provides an alternate interpretation of the posterior regularization framework (Graca et al., 2008), maintains uncertainty during optimization unlike constraint-driven learning (Chang et al., 2007), and is more efficient than generalized expectation criteria (Mann & McCallum, 2008). Applications of this framework include minimally supervised learning, semisupervised learning, and learning with constraints that are more expressive than the underlying model. In experiments, we demonstrate comparable accuracy to generalized expectation criteria for minimally supervised learning, and use expressive structural constraints to guide semi-supervised learning, providing a 3%-6% improvement over stateof-the-art constraint-driven learning.	common criteria;computational complexity theory;domain adaptation;experiment;loss function;mathematical optimization;matrix regularization;natural language;optimization problem;semi-supervised learning;semiconductor industry;supervised learning	Kedar Bellare;Gregory Druck;Andrew McCallum	2009			semi-supervised learning;unsupervised learning;instance-based learning;algorithmic learning theory;empirical risk minimization;computer science;artificial intelligence;machine learning;pattern recognition;mathematics;active learning;statistics;generalization error	ML	21.732120267829973	-34.91648625818434	39954
1876a3420ccf5f786b933e604fd3117cb55f4f23	complex functional network hebbian-type learning algorithm and convergence	learning algorithm	In this paper, functional network have been extension complex value situations, a complex value functional network Hebbian-type learning algorithm for training a complex neural network whose inputs, outputs and functional parameter are all complex was proposed, this algorithm based on the TLS criterion, rather than common LS or LMS. Finally, the complex functional network Hebbian neuron learning algorithm of convergence is proved that the purpose of complex functional network application provides theory basis.	algorithm;algorithmic learning theory;convergence;hebbian theory	Yongquan Zhou;Yanlian Du;Zhengxin Huang	2010		10.1007/978-3-642-14831-6_1	semi-supervised learning;unsupervised learning;instance-based learning;mathematical optimization;wake-sleep algorithm;computer science;online machine learning;machine learning;pattern recognition;leabra;learning classifier system;stability;competitive learning;computational learning theory;id3 algorithm;active learning;population-based incremental learning;generalization error	ML	15.685311424732923	-29.28323297647696	39964
2f2e2b8322b00b9c9ac9e7531030c484aebea042	wavelet sampling and generalization in neural networks		A new approach based on wavelet sampling is proposed to overcome overfitting in neural networks. Our approach optimizes input weights and network structure according to the empirical distribution of input training data. Thus only output weights are adjusted from training data errors. Using the fact that our algorithm trains input and output weights in independent procedures, our theorems demonstrate that it has rapid and global convergence. More importantly, we redefine a norm on l2 space, corresponding to a useful new cost function. Using this cost function, the algorithm improves the ability of our networks to distinguish target functions from noise. In fact, we prove that this algorithm allows neural networks to act as wavelet filters, yielding good generalization, approximation and anti-noise capacities. Our simulations verify these theoretical results and simultaneously show the algorithm is robust to noise.	artificial neural network;sampling (signal processing);wavelet	Zhiguo Zhang;Mark A. Kon	2017	Neurocomputing	10.1016/j.neucom.2017.04.054	types of artificial neural networks;machine learning;pattern recognition;cascade algorithm	ML	16.83125334084787	-30.423569612932596	39994
760e66b68d3387032c16a9f201b167168fc11b22	markovian spatial properties of a random field describing a stochastic neural network: sequential of parallel implementation?	parallel implementation;neural network;random field	Without Abstract	stochastic neural network	Thierry Hervé;Olivier François;Jacques Demongeot	1990		10.1007/3-540-52255-7_29	stochastic neural network;random field;computer science;theoretical computer science;machine learning;distributed computing;artificial neural network;statistics	ML	20.795693474512014	-25.44783730522224	40106
66069a63ef3b5b6ffe9365b74c714b8ef960e7d7	distance based clustering for categorical data	categorical data	Learning distances from categorical attributes is a very useful data mining task that allows to perform distance-based techniques, such as clustering and classification by similarity. In this article we propose a new context-based similarity measure that learns distances between the values of a categorical attribute (DILCA DIstance Learning of Categorical Attributes). We couple our similarity measure with a famous hierarchical distance-based clustering algorithm (Ward’s hierarchical clustering) and compare the results with the results obtained from methods of the state of the art for this research field.	algorithm;anomaly detection;categorical variable;cluster analysis;computation;data mining;hierarchical clustering;level of measurement;similarity measure;statistical classification	Dino Ienco;Rosa Meo	2009			consensus clustering;fuzzy clustering;categorical variable;cluster analysis;similarity measure;correlation clustering;mathematics;single-linkage clustering;artificial intelligence;hierarchical clustering;pattern recognition	ML	2.2255198928497477	-42.05005524285896	40179
36f0e8c505e572706775adc2d4dc1a0d6df47f47	order based genetic algorithms for the search of approximate entropy reducts	entropia;algoritmo busqueda;analisis datos;algorithme recherche;search algorithm;algoritmo genetico;data analysis;entropie;algorithme genetique;analyse donnee;genetic algorithm;entropy;theorie information;rough set;ensemble approximatif;information theory;teoria informacion	We use entropy to extend the rough set based notion of a reduct. We show that the order based genetic algorithms, applied to the search of classical decision reducts, can be used in exactly the same way in case of extracting optimal approximate entropy reducts from data.	approximate entropy;genetic algorithm;linear temporal logic to büchi automaton;rough set	Dominik Slezak;Jakub Wroblewski	2003		10.1007/3-540-39205-X_45	entropy;information theory;computer science;artificial intelligence;machine learning;mathematics;algorithm;statistics	AI	7.2994332577378005	-32.49543887693047	40217
fe5329dcabcc84497dc5573af36047ee9bf81965	a dental application of neural network computing: classification of complex electrical impedance measurements to aid root canal treatment	equivalent circuit;root canal treatment;nonlinear least squares;impedance electrique;impedancia electrica;dental root canal length;diagnostico;calculo automatico;classification;computing;calcul automatique;dental root cyst;quiste radiculodental;computational complexity;backpropagation algorithm;kyste radiculodentaire;electrical circuit;reseau neuronal;diagnosis;electrical impedance;clasificacion;red neuronal;root canal;neural network;diagnostic	Electrical impedance measurements provide an alternative diagnostic technique to the use of radiographs for aiding dental root canal treatment. Analysis of impedance data was based on Complex NonLinear Least Squares (CNLS) regression with electrical circuits as models. Different equivalent circuits were required to model the data at various depths within root canals. Therefore, it was not valid to compare directly the parameter values obtained for the same electrical components when different circuits were used. This problem was solved with a neural computing approach based on supervised training of the backpropagation algorithm to classify the data. Two strategies were investigated. The first produced a network output which indicated the electrode depth within the canal. The second approach employed the neural network as a preprocessor to establish which equivalent circuit was appropriate for the CNLS. Tests were also carried out to determine the minimum number of input nodes required by a neural network for this dental application.	algorithm;artificial neural network;backpropagation;characteristic impedance;electronic circuit;electronic component;equivalent circuit;non-linear least squares;preprocessor;radiography	Malcolm Levinkind	1994	Neural Computing & Applications	10.1007/BF01414809	equivalent circuit;computing;computer science;machine learning;electrical impedance;artificial neural network	ML	10.01995779139421	-28.8755469963032	40258
fc31f1f62e4f44a125cbe866ae2fa2472ea84c28	a kernel-based two-stage one-class support vector machines algorithm	cluster algorithm;feature space;data clustering;support vector machine;synthetic data;clustered data	One-class SVM is a kernel-based method that utilizes the kernel trick for data clustering. However it is only able to detect one cluster of non-convex shape in the input space. In this study, we propose an iterative two-stage one-class SVM to cluster data into several groups. In the first stage, one-class SVM is used to find an optimal weight vector for each cluster in the feature space, while in the second stage the weight vector is used to refine the clustering result. A mechanism is provided to control the optimal hyperplane to work against outliers. Experimental results have shown that our method compares favorably with other kernel based clustering algorithms, such as KKM and KFCM on several synthetic data sets and UCI real data sets.	algorithm;kernel (operating system);support vector machine	Chi-Yuan Yeh;Shie-Jue Lee	2007		10.1007/978-3-540-72395-0_65	correlation clustering;constrained clustering;support vector machine;kernel method;data stream clustering;feature vector;radial basis function kernel;k-medians clustering;fuzzy clustering;flame clustering;computer science;canopy clustering algorithm;machine learning;pattern recognition;cure data clustering algorithm;data mining;mathematics;cluster analysis;single-linkage clustering;synthetic data;clustering high-dimensional data	ML	21.30816707844077	-40.56309558022846	40300
c1f1b6434250a7110979b7cf69da802bb8c56542	selfless sequential learning		Sequential learning, also called lifelong learning, studies the problem of learning tasks in a sequence with access restricted to only the data of the current task. In this paper we look at a scenario with fixed model capacity, and postulate that the learning process should not be selfish, i.e. it should account for future tasks to be added and thus leave enough capacity for them. To achieve Selfless Sequential Learning we study different regularization strategies and activation functions. We find that imposing sparsity at the level of the representation (i.e. neuron activations) is more beneficial for sequential learning than encouraging parameter sparsity. In particular, we propose a novel regularizer, that encourages representation sparsity by means of neural inhibition. It results in few active neurons which in turn leaves more free neurons to be utilized by upcoming tasks. As neural inhibition over an entire layer can be too drastic, especially for complex tasks requiring strong representations, our regularizer only inhibits other neurons in a local neighbourhood, inspired by lateral inhibition processes in the brain. We combine our novel regularizer with state-of-the-art lifelong learning methods that penalize changes to important previously learned parts of the network. We show that our new regularizer leads to increased sparsity which translates in consistent performance improvement on diverse datasets.		Rahaf Aljundi;Marcus Rohrbach;Tinne Tuytelaars	2018	CoRR		machine learning;neural inhibition;artificial intelligence;performance improvement;interference (wave propagation);sparse approximation;sequence learning;regularization (mathematics);computer science;lifelong learning	ML	21.832299083152826	-49.30842293208604	40329
1f5713a2dfa947f71d64576318842767be08d6ac	finding relevant features for identifying subtypes of guillain-barré syndrome using quenching simulated annealing and partitions around medoids	hy brid methods for clustering;feature selection for clustering;search op timization	We present a novel approach to find relevant features for identifying four subtypes of GuillainBarré Syndrome (GBS). Our method consists of a combination of Quenching Simulated Annealing (QSA) and Partitions Around Medoids (PAM), named QSA-PAM method. A 156-feature real dataset containing clinical, serological and nerve conduction test data from GBS patients was used for experiments. Different feature subsets were randomly selected from the dataset using QSA. New datasets created using these feature subsets were used as input for PAM to build four clusters, corresponding to a specific GBS subtype each. Finally, purity of clusters was measured. Sixteen features from the original dataset were encountered relevant for identifying GBS subtypes with a purity of 0.8992. This work represents the first effort to find relevant features for identifying GBS subtypes using computational techniques. The results of this work may help specialists to broaden the understanding of the differences among subtypes of GBS.	algorithm;brute-force search;cluster analysis;computation;experiment;leaning toothpick syndrome;linux pam;medoid;metaheuristic;pure function;qtscript;qualified security assessor;randomness;resultant;simulated annealing;test data	Juana Canul-Reich;José Hernández-Torruco;Juan Frausto Solís;Juan José Méndez-Castillo	2015	IJCOPI		machine learning;pattern recognition;data mining;mathematics	NLP	8.301018115517847	-47.21704634273642	40330
39ed60684338b684489f26a42395a76e52101ccc	convolutional neural networks in combination with support vector machines for complex sequential data classification		Trying to extract features from complex sequential data for classification and prediction problems is an extremely difficult task. Deep Machine Learning techniques, such as Convolutional Neural Networks (CNNs), have been exclusively designed to face this class of problems. Support Vector Machines (SVMs) are a powerful technique for general classification problems, regression, and outlier detection. In this paper we present the development and implementation of an innovative by design combination of CNNs with SVMs as a solution to the Protein Secondary Structure Prediction problem, with a novel two dimensional (2D) input representation method, where Multiple Sequence Alignment profile vectors are placed one under another. This 2D input is used to train the CNNs achieving preliminary results of 80.40% per residue accuracy (Q3), which are expected to increase with the use of larger training datasets and more sophisticated ensemble methods.	convolutional neural network;support vector machine	Antreas Dionysiou;Michalis Agathocleous;Chris Christodoulou;Vasilis J. Promponas	2018		10.1007/978-3-030-01421-6_43	data classification;anomaly detection;machine learning;support vector machine;pattern recognition;convolutional neural network;artificial intelligence;deep learning;multiple sequence alignment;ensemble learning;computer science	ML	18.619130030384767	-49.0041157129706	40332
925f891f0e89002c42cc5b3da732e5d541cef55b	hybrid evolutionary algorithms for data classification in intrusion detection systems	intrusion detection systems genetic algorithm genetic programming data classification;intrusion detection accuracy genetic algorithms search problems acceleration genetic programming set theory;intrusion detection;genetic programming;set theory;acceleration;accuracy;nsl kdd dataset hybrid evolutionary algorithms data classification ids malicious behaviors attack behaviors hybrid intrusion detection system accelerated genetic algorithm and rough set theory agaar data feature reduction genetic programming with local search gpls intrusion detection dataset genetic programming operators;intrusion detection systems;genetic algorithm;genetic algorithms;security of data evolutionary computation pattern classification rough set theory;search problems;data classification	Intrusion detection systems (IDS) are important to protect our systems and networks from attacks and malicious behaviors. In this paper, we propose a new hybrid intrusion detection system by using accelerated genetic algorithm and rough set theory (AGAAR) for data feature reduction, and genetic programming with local search (GPLS) for data classification. The AGAAR method is used to select the most relevant attributes that can represent an intrusion detection dataset. In order to improve the performance of GPLS classifier, a new local search strategy is used with genetic programming operators. The main target of using local search strategy is to discover the better solution from the current. The results shown later indicate that classification accuracy improved from 75.98% to 81.44% after using AGAAR attribute reduction for the NSL-KDD dataset. The classification accuracies have been compared with others algorithms and shown that the proposed method can be one of the competitive classifiers for IDS.	central processing unit;computation;evolutionary algorithm;genetic algorithm;genetic programming;intrusion detection system;local search (optimization);malware;relevance;rough set;set theory;statistical classification	Abdel-Rahman Hedar;Mohamed A. Omer;Ahmed F. Al-Sadek;Adel A. Sewisy	2015	2015 IEEE/ACIS 16th International Conference on Software Engineering, Artificial Intelligence, Networking and Parallel/Distributed Computing (SNPD)	10.1109/SNPD.2015.7176208	anomaly-based intrusion detection system;intrusion detection system;genetic algorithm;computer science;artificial intelligence;machine learning;genetic representation;pattern recognition;data mining;computer security	SE	6.882458781357335	-37.80902471594558	40338
06c06885fd53b2cbd407704cf14f658842ed48e5	deeply-recursive convolutional network for image super-resolution	skip connection deeply recursive convolutional network image super resolution method sr drcn standard gradient descent method recursive supervision;neural nets gradient methods image resolution;image reconstruction image resolution high definition video training computational modeling neural networks computer vision	We propose an image super-resolution method (SR) using a deeply-recursive convolutional network (DRCN). Our network has a very deep recursive layer (up to 16 recursions). Increasing recursion depth can improve performance without introducing new parameters for additional convolutions. Albeit advantages, learning a DRCN is very hard with a standard gradient descent method due to exploding/ vanishing gradients. To ease the difficulty of training, we propose two extensions: recursive-supervision and skip-connection. Our method outperforms previous methods by a large margin.	benchmark (computing);circuit restoration;compression artifact;convolution;gradient descent;image restoration;margin (machine learning);noise reduction;recursion (computer science);super-resolution imaging	Jiwon Kim;Jung Kwon Lee;Kyoung Mu Lee	2016	2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)	10.1109/CVPR.2016.181	computer vision;computer science;theoretical computer science;machine learning	Vision	23.355308030511367	-50.56868984470847	40363
04cbc65dd178adf45feaf53b4166a8880cd0cf35	pre-processing structured data for standard machine learning algorithms by supervised graph propositionalization - a case study with medicinal chemistry datasets	graph theory;relational data;computer and systems sciences;learning algorithm;moss structured data preprocessing standard machine learning algorithms supervised graph propositionalization method medicinal chemistry datasets fixed length feature vectors random forests support vector machines nearest neighbor classifiers subdue;medicinal chemistry;support vector machines;information science;chemistry computing;systemvetenskap;random forests;itemsets classification algorithms machine learning machine learning algorithms data mining chemistry kernel;feature vector;learning methods;data och systemvetenskap;machine learning;random forest;pattern classification;k nearest neighbor;prediction model;support vector machine;learning artificial intelligence;medicinal chemistry structured data graph propositionalization random forests support vector machines k nearest neighbor;nearest neighbor classifier;graph propositionalization;support vector machines chemistry computing graph theory learning artificial intelligence pattern classification;structured data	Graph propositionalization methods can be used to transform structured and relational data into fixed-length feature vectors, enabling standard machine learning algorithms to be used for generating predictive models. It is however not clear how well different propositionalization methods work in conjunction with different standard machine learning algorithms. Three different graph propositionalization methods are investigated in conjunction with three standard learning algorithms: random forests, support vector machines and nearest neighbor classifiers. An experiment on 21 datasets from the domain of medicinal chemistry shows that the choice of propositionalization method may have a significant impact on the resulting accuracy. The empirical investigation further shows that for datasets from this domain, the use of the maximal frequent item set approach for propositionalization results in the most accurate classifiers, significantly outperforming the two other graph propositionalization methods considered in this study, SUBDUE and MOSS, for all three learning methods.	algorithm;feature vector;machine learning;map overlay and statistical system;maximal set;medicinal chemistry;predictive modelling;random forest;support vector machine	Thashmee Karunaratne;Henrik Boström;Ulf Norinder	2010	2010 Ninth International Conference on Machine Learning and Applications	10.1109/ICMLA.2010.128	random forest;support vector machine;information science;computer science;graph theory;machine learning;pattern recognition;data mining	ML	13.107932493049756	-46.46688490673344	40432
51215c71fbfaa82e935db84271a1b95706ac2898	mlps (mono-layer polynomials and multi-layer perceptrons) for nonlinear modeling		This paper presents a model selection procedure which stresses the importance of the classic polynomial models as tools for evaluating the complexity of a given modeling problem, and for removing non-significant input variables. If the complexity of the problem makes a neural network necessary, the selection among neural candidates can be performed in two phases. In an additive phase, the most important one, candidate neural networks with an increasing number of hidden neurons are trained. The addition of hidden neurons is stopped when the effect of the round-off errors becomes significant, so that, for instance, confidence intervals cannot be accurately estimated. This phase leads to a set of approved candidate networks. In a subsequent subtractive phase, a selection among approved networks is performed using statistical Fisher tests. The series of tests starts from a possibly too large unbiased network (the full network), and ends with the smallest unbiased network whose input variables and hidden neurons all have a significant contribution to the regression estimate. This method was successfully tested against the real-world regression problems proposed at the NIPS2000 Unlabeled Data Supervised Learning Competition; two of them are included here as illustrative examples.	algorithmic efficiency;artificial neural network;characterization test;computation;computational complexity theory;condition number;jacobian matrix and determinant;model selection;multilayer perceptron;nips;neuron;optical burst switching;overfitting;polynomial;polynomial hierarchy;recursion;round-off error;supervised learning;test set;unit testing;utility functions on indivisible goods	Isabelle Rivals;Léon Personnaz	2003	Journal of Machine Learning Research			ML	22.516081364657754	-33.95209687017284	40443
f968cbd434a7db2e6334f3e4084243edc142333b	a dimension reduction technique for two-mode non-convex fuzzy data	non convex fuzzy data;fuzzy component analysis;fuzzy statistics;fuzzy rating scales;data mining	Fuzzy modeling and fuzzy statistics provide useful tools for handling empirical situations affected by vagueness and imprecision in the data. Several fuzzy statistical models and methods (e.g., fuzzy regression, fuzzy principal component analysis, fuzzy clustering) have been developed over the years. Generally the standard LR-fuzzy data representation has been used in these methods. However, several empirical contexts, such as human ratings and decision making, may show more complex fuzzy structures which cannot be successfully modeled by the LR representation. In all these cases another type of fuzzy data representation, the so-called LHIR representation, should be preferred instead. In particular, this novel representation allows to handle with fuzzy data which are characterized by non-convex membership functions. In this paper, we address the problem of summarizing large datasets characterized by two-mode non-convex fuzzy data. We introduce a novel dimension reduction technique (NCFCA) based on the framework of Component Analysis and Least squares programming. Finally, to better highlight some important characteristics of the proposed model, we Communicated by V. Loia. Electronic supplementary material The online version of this article (doi:10.1007/s00500-014-1538-8) contains supplementary material, which is available to authorized users. A. Calcagnì (B) · L. Lombardi Department of Psychology and Cognitive Science, University of Trento, 38068 Rovereto, TN, Italy e-mail: antonio.calcagni@unitn.it L. Lombardi e-mail: luigi.lombardi@unitn.it E. Pascali Department of Mathematics and Physics ‘E. De Giorgi’, University of Salento, 73100 Lecce, Italy e-mail: eduardo.pascali@unisalento.it apply NCFCA to three empirical datasets concerning behavioral and socio-economic issues.	algorithm;authorization;cluster analysis;cognitive science;cubic function;data (computing);dimensionality reduction;email;fuzzy clustering;fuzzy concept;fuzzy logic;fuzzy number;graphical user interface;lr parser;least squares;membership function (mathematics);missing data;principal component analysis;randomness;semiconductor industry;statistical model;twisted nematic field effect;vagueness;venue (sound system)	Antonio Calcagnì;L. Lombardi;E. Pascali	2016	Soft Comput.	10.1007/s00500-014-1538-8	fuzzy logic;fuzzy cognitive map;membership function;defuzzification;fuzzy clustering;adaptive neuro fuzzy inference system;type-2 fuzzy sets and systems;fuzzy mathematics;fuzzy classification;computer science;fuzzy number;neuro-fuzzy;machine learning;pattern recognition;fuzzy measure theory;data mining;mathematics;fuzzy set;fuzzy associative matrix;fuzzy set operations;fuzzy control system;statistics	ML	-4.16437793430265	-24.21985512074428	40464
93218161e8a5fa7981667cd31ab1cee3d09999d5	time-varying prototype reduction schemes applicable for non-stationary data sets	modelizacion;nonstatinoary environments;time varying;intelligence artificielle;classification;time varying system;prototype reduction schemes prs;modelisation;vecino mas cercano;systeme parametre variable;nearest neighbor;non stationary condition;invariante;plus proche voisin;artificial intelligence;nearest neighbour;condition non stationnaire;inteligencia artificial;sistema parametro variable;condicion no estacionaria;hybrid type prototype reduction;modeling;clasificacion;invariant;time varying samples tvs	All of the Prototype Reduction Schemes (PRS) which have been reported in the literature, process time-invariant data to yield a subset of prototypes that are useful in nearest-neighbor-like classification. In this paper, we suggest two time-varying PRS mechanisms which, in turn, are suitable for two distinct models of non-stationarity. In both of these models, rather than process all the data as a whole set using a PRS, we propose that the information gleaned from a previous PRS computation be enhanced to yield the prototypes for the current data set, and this enhancement is accomplished using a LVQ3-type “fine tuning”. The experimental results, which to our knowledge are the first reported results applicable for PRS schemes suitable for non-stationary data, are, in our opinion, very impressive.	prototype;stationary process	Sang-Woon Kim;B. John Oommen	2005		10.1007/11589990_64	simulation;systems modeling;biological classification;computer science;artificial intelligence;invariant;data mining;k-nearest neighbors algorithm	HPC	9.767424895320623	-32.14272199909412	40467
8cfda143afa42232403b77ee9e893a4d82564305	neuro-fuzzy modeling and fuzzy rule extraction applied to conflict management	modelizacion;forecasting;modelo prevision;prevision;takagi sugeno fuzzy model;takagi sugeno;resolucion conflicto;transparence;fuzzy rules;logique floue;knowledge extraction;logica difusa;computational method;transparencia;forecast model;fuzzy logic;conflict management;modelisation;resolution conflit;neuro fuzzy;extraction connaissances;extraccion conocimiento;transparency;reseau neuronal;conflict resolution;modeling;red neuronal;fuzzy model;neural network;modele prevision	This paper outlines all the computational methods which have been applied to the conflict management. A survey of all the pertinent literature relating to conflict management is also presented. The paper then introduces the Takagi-Sugeno fuzzy model for the analysis of interstate conflict. It is found that using interstate variables as inputs, the Takagi-Sugeno fuzzy model is able to forecast conflict cases with an accuracy of 80.36%. Furthermore, it found that the fuzzy model offers high levels of transparency in the form of fuzzy rules. It is then shown how these rules can be translated in order to validate the fuzzy model. The Takagi-Sugeno model is found to be suitable for interstate modeling as it demonstrates good forecasting ability while offering a transparent interpretation of the modeled rules.	computation;fuzzy rule;neuro-fuzzy;relevance;rule induction	Thando Tettey;Tshilidzi Marwala	2006		10.1007/11893295_120	fuzzy logic;systems modeling;defuzzification;forecasting;type-2 fuzzy sets and systems;computer science;artificial intelligence;fuzzy number;neuro-fuzzy;machine learning;conflict resolution;data mining;knowledge extraction;fuzzy associative matrix;transparency;operations research;fuzzy set operations;artificial neural network	SE	8.442003722303589	-28.623400184163096	40500
4d2c71e7ccc26b69ce6163cafb019d1269dbbdaa	gaussian mixture reduction based on fuzzy art for extended target tracking	global clustering algorithm;normalized integrated squared distance measure;extended target tracking;weighted kullback leibler difference;gaussian mixture reduction	This paper presents a global Gaussian mixture (GM) reduction algorithm via clustering for extended target tracking in clutter. The proposed global clustering algorithm is obtained by combining a fuzzy Adaptive Resonance Theory (ART) neural network architecture with the weighted Kullback-Leibler (KL) difference which describes discrimination of one component from another. Therefore, we call the proposed algorithm as ART-KL clustering (ART-KL-C) in the paper. The weighted KL difference is used as a category choice function of ART-KL-C, derived by considering both the KL divergence between two components and their weights. The performance of ART-KL-C is evaluated by the normalized integrated squared distance (NISD) measure, which describes the deviation between the original and reduced GM. The proposed algorithm is tested on both one-dimensional and four-dimensional simulation examples, and the results show that the proposed algorithm can more accurately approximate the original mixture and is useful in extended target tracking. The paper presents a global GM reduction algorithm, ART-KL-C, via clustering.The authors propose a weighted KL difference as category choice function.The merging criterion is used as learning of category parameters.		Yongquan Zhang;Hongbing Ji	2014	Signal Processing	10.1016/j.sigpro.2013.11.004	machine learning;pattern recognition;mathematics;statistics	EDA	2.646220922294492	-39.749345237463494	40541
304d1661706236fd50bd273858f41529b1001ef6	robust interval regression analysis using neural networks	rate of convergence;fuzzy regression;regression non lineaire;estimator robustness;learning algorithm;neural networks;cost function;analisis datos;fuzzy data;non linear regression;outlier;regression model;regresion no lineal;algorithme apprentissage;observacion aberrante;data analysis;robustez estimador;analisis regresion;backpropagation algorithm;robust learning algorithms;back propagation algorithm;interval regression;algorithme retropropagation;analyse regression;observation aberrante;analyse donnee;regression analysis;reseau neuronal;algoritmo aprendizaje;back propagation;red neuronal;neural network;robustesse estimateur;algoritmo retropropagacion	"""As a very important tool for dealing with both crisp data and fuzzy data, fuzzy regression analysis based on interval regression analysis has become an active area of research. Some neural network related methods for nonlinear interval regression analysis have been proposed on the assumption that given training data are totally """"good"""" data. The performance of these methods will significantly worsen when the training data are spoiled by outliers. In this paper, we introduce the concepts of polarity and quality of the training data, on the basis of which we propose two robust learning algorithms for determining a robust nonlinear interval regression model, which makes a feature of a new cost function for reflecting not only the polarity of the training data but also the estimated knowledge about the quality of the training data. The two robust algorithms are derived in a manner similar to the back-propagation (BP) algorithm. Simulation results show that our robust algorithms outperform the existing methods remarkably in two aspects when outliers are present: (1) They are robust against outliers; (2) Their rates of convergence are improved to some extent. (~) 1998 Elsevier Science B.V. All rights reserved."""	approximation algorithm;artificial neural network;backpropagation;fuzzy logic;loss function;machine learning;nonlinear system;simulation;software propagation	Lei Huang;Bai-Ling Zhang;Qian Huang	1998	Fuzzy Sets and Systems	10.1016/S0165-0114(96)00325-9	robust statistics;econometrics;computer science;backpropagation;machine learning;mathematics;robust regression;artificial neural network;regression analysis;statistics	ML	11.850395873874259	-30.388766121547505	40580
533f860ef2c849a4b0832fd19009430bdfdb60aa	feature selection for clustering - a filter solution	unsupervised learning;histograms;cluster algorithm;pattern clustering;degradation;performance evaluation;knowledge discovery in databases;point to point;filters;data mining;real world application;clustering;dimensionality reduction technique;feature extraction;point to point distance histogram;noise reduction;number of clusters;entropy measure feature selection knowledge discovery in databases clustering dimensionality reduction technique pre processing method noisy feature removal filter method point to point distance histogram;clustering algorithms;feature selection;entropy;pre processing method;entropy measure;filters clustering algorithms entropy histograms noise reduction degradation unsupervised learning;filter method;pattern clustering entropy data mining feature extraction;dimensional reduction;noisy feature removal	Processing applications with a large number of dimensions has been a challenge to the KDD community. Feature selection, an effective dimensionality reduction technique, is an essential pre-processing method to remove noisy features. In the literature there are only a few methods proposed for feature selection for clustering. And, almost all of those methods are ‘wrapper’ techniques that require a clustering algorithm to evaluate the candidate feature subsets. The wrapper approach is largely unsuitable in real-world applications due to its heavy reliance on clustering algorithms that require parameters such as number of clusters, and due to lack of suitable clustering criteria to evaluate clustering in different subspaces. In this paper we propose a ‘filter’ method that is independent of any clustering algorithm. The proposed method is based on the observation that data with clusters has very different point-to-point distance histogram than that of data without clusters. Using this we propose an entropy measure that is low if data has distinct clusters and high otherwise. The entropy measure is suitable for selecting the most important subset of features because it is invariant with number of dimensions, and is affected only by the quality of clustering. Extensive performance evaluation over synthetic, benchmark, and real datasets shows its effectiveness.	algorithm;benchmark (computing);cluster analysis;dhrystone;dimensionality reduction;feature selection;performance evaluation;point-to-point protocol;preprocessor	Manoranjan Dash;Kiseok Choi;Peter Scheuermann;Huan Liu	2002		10.1109/ICDM.2002.1183893	unsupervised learning;correlation clustering;constrained clustering;determining the number of clusters in a data set;data stream clustering;k-medians clustering;fuzzy clustering;flame clustering;computer science;canopy clustering algorithm;machine learning;consensus clustering;pattern recognition;cure data clustering algorithm;data mining;mathematics;cluster analysis;brown clustering;feature selection;dbscan;biclustering;affinity propagation;clustering high-dimensional data	ML	0.3886703044763174	-41.45675129123874	40637
bf2d333a4b9c6fd70d3ac26a81f1638030b85e32	from predictions to data-driven decisions using machine learning			machine learning	Nathan Kallus	2014	CoRR		machine learning;pattern recognition	NLP	10.557764348194603	-26.288550126746554	40657
5d9b82b07e9d78c44c7db35f3bc05caa71e2267a	a study of the generalization capabilities of xcs		We analyze the generalization behavior of the XCS classi er system in environments in which only a few generalizations can be done. Experimental results presented in the paper evidence that the generalization mechanism of XCS can prevent it from learning even simple tasks in such environments. We present a new operator, named Specify, which contributes to the solution of this problem. XCS with the Specify operator, named XCSS, is compared to XCS in terms of performance and generalization capabilities in di erent types of environments. Experimental results show that XCSS can deal with a greater variety of environments and that it is more robust than XCS with respect to population size.	control theory;don't-care term;entity–relationship model;genetic operator	Pier Luca Lanzi	1997			operator (computer programming);machine learning;generalization;computer science;artificial intelligence	AI	4.862401715625906	-30.50325840506233	40696
d3c37e24ec1319d3b791e22dd8ab08bdf3139f74	accelerated parallel algorithm for gene network reverse engineering	cuda;gpu-aracne;gene expression dataset;mutual information;parallel computing;regulatory networks	The Algorithm for the Reconstruction of Accurate Cellular Networks (ARACNE) represents one of the most effective tools to reconstruct gene regulatory networks from large-scale molecular profile datasets. However, previous implementations require intensive computing resources and, in some cases, restrict the number of samples that can be used. These issues can be addressed elegantly in a GPU computing framework, where repeated mathematical computation can be done efficiently, but requires extensive redesign to apply parallel computing techniques to the original serial algorithm, involving detailed optimization efforts based on a deep understanding of both hardware and software architecture. Here, we present an accelerated parallel implementation of ARACNE (GPU-ARACNE). By taking advantage of multi-level parallelism and the Compute Unified Device Architecture (CUDA) parallel kernel-call library, GPU-ARACNE successfully parallelizes a serial algorithm and simplifies the user experience from multi-step operations to one step. Using public datasets on comparable hardware configurations, we showed that GPU-ARACNE is faster than previous implementations and is able to reconstruct equally valid gene regulatory networks. Given that previous versions of ARACNE are extremely resource demanding, either in computational time or in hardware investment, GPU-ARACNE is remarkably valuable for researchers who need to build complex regulatory networks from large expression datasets, but with limited budget on computational resources. In addition, our GPU-centered optimization of adaptive partitioning for Mutual Information (MI) estimation provides lessons that are applicable to other domains.	aracne algorithm;cuda;computation (action);computational resource;gene regulatory network;general-purpose computing on graphics processing units;graphics processing unit;hl7publishingsubsection <operations>;kernel;mathematical optimization;mathematics;mutual information;numerous;parallel algorithm;parallel computing;reverse engineering;sequential algorithm;software architecture;time complexity;user experience;version	Jing He;Zhou Zhou;Michael Reed;Andrea Califano	2017		10.1186/s12918-017-0458-5	bioinformatics;implementation;computation;reverse engineering;software architecture;parallel algorithm;cuda;general-purpose computing on graphics processing units;cellular network;computer science	HPC	-4.020674731913665	-51.105515536110715	40754
87c9c30ee93337cd751d940ae070eb4c39691c97	statistical extension of rough set rule induction	databases;ji cuadrado;regle inference;base donnee;sistema experto;rule induction;analisis estadistico;probabilidad condicional;tabla contingencia;probabilite conditionnelle;database;base dato;base connaissance;khi deux;statistical evaluation;inference rule;chi square;statistical analysis;decouverte connaissance;analyse statistique;base conocimiento;knowledge discovery in database;contingency table;systeme expert;rough set;table contingence;conditional probability;quantitative evaluation;regla inferencia;knowledge base;knowledge discovery;expert system	Rough set based rule induction methods have been applied to knowledge discovery in databases. The empirical results obtained show that they are very powerful and that some important knowledge has been extracted from datasets. However, quantitative evaluation of induced rules are based not on statistical evidence but on rather naive indices, such as conditional probabilities and functions of conditional probabilities. In this paper, we introduce a new approach to induced rules for quantitative evaluation, which can be viewed as a statistical extension of rough set methods. For this extension, chi-square distribution and F- distribution play an important role in statistical evaluation.© (2001) COPYRIGHT SPIE--The International Society for Optical Engineering. Downloading of the abstract is permitted for personal use only.	rough set;rule induction	Shusaku Tsumoto	2001		10.1117/12.421072	knowledge base;rough set;conditional probability;chi-square test;contingency table;computer science;artificial intelligence;data mining;chain rule;expert system;algorithm;rule of inference	NLP	0.038498791942617454	-30.04405788418723	40769
319f72197bee06a8431efd8457afcc8a6e7e13ae	"""comments on """"a possibilistic approach to clustering"""""""	fuzzy set theory;iterative methods;fuzzy clustering;pattern classification;possibility theory	In this comment, we report a difficulty with the-application of the possibilistic approach to fuzzy clustering (PCM) proposed by Keller and Krishnapuram (1993). In applying this algorithm we found that it has the undesirable tendency to produce coincidental clusters. Results illustrating this tendency are reported and a possible explanation for the PCM behavior is suggested.	cluster analysis	Mauro Barni;Vito Cappellini;Alessandro Mecocci	1996	IEEE Trans. Fuzzy Systems	10.1109/91.531780	possibility theory;fuzzy clustering;computer science;artificial intelligence;machine learning;data mining;mathematics;iterative method;fuzzy set	Embedded	-1.0072764816878033	-26.989088626613945	40770
e9426b4f0cd69d3d60e8ac69c77af893caef1384	find key m/z values in predication of mass spectrometry cancer data	wavelet analysis;high dimensionality;mass spectra;mass spectrometry;genetic algorithm	To find the significant biomarker is very important in detecting protein patterns associated with diseases. In this study multilevel wavelet analysis is performed on high dimensional mass spectrometry data to extract the detail coefficients, which are used to detect the difference between cancer tissue and normal tissue. In order to find the key m/z values of mass spectra, wavelet detail information is reconstructed based on orthogonal wavelet detail coefficients, and genetic algorithm is further employed to select best features from the reconstructed detail information. Finally the corresponding significant m/z values of mass spectra are identified using the optimized detail features.		Yihui Liu;Li Bai	2008		10.1007/978-3-540-87442-3_25	wavelet;genetic algorithm;mass spectrum;mass spectrometry;computer science;bioinformatics;data mining;statistics	Crypto	8.378282030442	-48.34672792269904	40774
9184c89aa2775e7fe6744ff8c0d8b8662a225a29	behavior and performance of the deep belief networks on image classification	image classification;pattern recognition;boltzmann machine;support vector machine;bag of words;belief network;evolutionary computing	We apply deep belief networks of restricted Boltzmann machines to bags of words of sift features obtained from databases of 13 Scenes, 15 Scenes and Caltech 256 and study experimentally their behavior and performance. We find that the final performance in the supervised phase is reached much faster if the system is pre-trained. Pre-training the system on a larger dataset keeping the supervised dataset fixed improves the performance (for the 13 Scenes case). After the unsupervised pre-training, neurons arise that form approximate explicit representations for several categories (meaning they are mostly active for this category). The last three facts suggest that unsupervised training really discovers structure in these data. Pre-training can be done on a completely different dataset (we use Corel dataset) and we find that the supervised phase performs just as good (on the 15 Scenes dataset). This leads us to conjecture that one can pre-train the system once (e.g. in a factory) and subsequently apply it to many supervised problems which then learn much faster. The best performance is obtained with single hidden layer system suggesting that the histogram of sift features doesn't have much high level structure. The overall performance is almost equal, but slightly worse then that of the support vector machine and the spatial pyramidal matching.	apply;approximation algorithm;bayesian network;computer vision;corel linux;database;deep belief network;emergence;experiment;high-level programming language;level structure;quantization (signal processing);restricted boltzmann machine;super paper mario;supervised learning;support vector machine;unsupervised learning	Karol Gregor;Gregory Griffin	2009	CoRR		boltzmann machine;support vector machine;contextual image classification;computer science;artificial intelligence;bag-of-words model;machine learning;pattern recognition;bayesian network;data mining;evolutionary computation	AI	20.893341226085585	-51.135267271458474	40777
5876dbd26f105cf1e04794a3e9d22958f2985a8f	separation index and partial membership for clustering	proyeccion;classification automatique statistiques;computacion informatica;analisis datos;separation index;data analysis;particion;62h30;ciencias basicas y experimentales;clustering method;projection;matematicas;indexation;statistical computation;calculo estadistico;fuzzy membership;partition;analyse donnee;calcul statistique;cluster analysis statistics;grupo a;separating hyperplane	We propose a new separation index that measures the magnitude of gaps between any two clusters in a partition, by projecting the data in a pair of clusters into a one-dimensional space in which they have the maximum separation. The resulting projections can also be used to determine partial membership for points near the boundaries between two or more clusters. The matrix of separation indexes is helpful in deciding whether too many or too few clusters are specified in the clustering method.	cluster analysis	Weiliang Qiu;Harry Joe	2006	Computational Statistics & Data Analysis	10.1016/j.csda.2004.09.009	partition;complete-linkage clustering;econometrics;projection;pattern recognition;mathematics;data analysis;statistics	Theory	3.3647715844120842	-37.6946101047206	40803
0ab6141c4d13ed1ae0ade661a987a7784c412d27	examining locally varying weights for nearest neighbor algorithms	raisonnement base sur cas;razonamiento fundado sobre caso;learning algorithm;intelligence artificielle;algorithme apprentissage;nearest neighbor;feature weighting;artificial intelligence;inteligencia artificial;case based reasoning;algoritmo aprendizaje	Previous work on feature weighting for case-based learning algorithms has tended to use either global weights or weights that vary over extremely local regions of the case space. This paper examines the use of coarsely local weighting schemes, where feature weights are allowed to vary but are identical for groups or clusters of cases. We present a new technique, called class distribution weighting (CDW), that allows weights to vary at the class level. We further extend CDW into a family of related techniques that exhibit varying degrees of locality, from global to local. The class distribution techniques are then applied to a set of eleven concept learning tasks. We nd that one or more of the CDW variants signi cantly improves classi cation accuracy for nine of the eleven tasks. In addition, we nd that the relative importance of classes, features, and feature values in a particular domain determines which variant is most successful.	algorithm;benchmark (computing);concept learning;cross-validation (statistics);feature extraction;ibm notes;locality of reference;machine learning;programming paradigm;test set	Nicholas Howe;Claire Cardie	1997		10.1007/3-540-63233-6_515	case-based reasoning;computer science;artificial intelligence;machine learning;mathematics;k-nearest neighbors algorithm;algorithm	ML	10.67441070079404	-32.7312501151615	40820
92fd219351f66b4182eb79ed69866b05c3bbac47	weakly supervised deep metric learning for community-contributed image retrieval	real world social image datasets weakly supervised deep metric learning community contributed image retrieval rich context information distance metric learning algorithm wdml progressive learning manner knowledge discovery heterogeneous data structures transformation matrix optimization problem iterative algorithm;optimisation data mining image retrieval iterative methods learning artificial intelligence matrix algebra;semantics;noise measurement;learning systems;visualization;weakly supervised deep image retrieval metric learning;data structures;visualization semantics image retrieval noise measurement learning systems data structures;image retrieval	Recent years have witnessed the explosive growth of community-contributed images with rich context information, which is beneficial to the task of image retrieval. It can help us to learn a suitable metric to alleviate the semantic gap. In this paper, we propose a new distance metric learning algorithm, namely weakly-supervised deep metric learning (WDML), under the deep learning framework. It utilizes a progressive learning manner to discover knowledge by jointly exploiting the heterogeneous data structures from visual contents and user-provided tags of social images. The semantic structure in the textual space is expected to be well preserved while the problem of the noisy, incomplete or subjective tags is addressed by leveraging the visual structure in the original visual space. Besides, a sparse model with the l2,1 mixed norm is imposed on the transformation matrix of the first layer in the deep architecture to compress the noisy or redundant visual features. The proposed problem is formulated as an optimization problem with a well-defined objective function and a simple yet efficient iterative algorithm is proposed to solve it. Extensive experiments on real-world social image datasets are conducted to verify the effectiveness of the proposed method for image retrieval. Encouraging experimental results are achieved compared with several representative metric learning methods.	algorithm;automatic image annotation;content-based image retrieval;data structure;deep learning;experiment;iterative method;mathematical optimization;optimization problem;sparse matrix;transformation matrix	Zechao Li;Jinhui Tang	2015	IEEE Transactions on Multimedia	10.1109/TMM.2015.2477035	semi-supervised learning;unsupervised learning;computer vision;visual word;visualization;image retrieval;computer science;noise measurement;machine learning;pattern recognition;semantics;world wide web;information retrieval;generalization error	Vision	23.614572006960806	-44.249970578174896	40916
6c35b7af5630c113752e9d7b1407e32afcdab1f5	an ordering algorithm for pattern presentation in fuzzy artmap that tends to improve generalization performance	maps;generalizacion;pattern clustering;cluster;fuzzy neural nets;fuzzy artmap;mapa;learning;amas;etude experimentale;analisis forma;indexing terms;systeme adaptatif;carte;aprendizaje;apprentissage;generalisation;clustering method;adaptive system;sistema adaptativo;sistema difuso;pattern analysis;monton;generalisation artificial intelligence;systeme flou;art neural nets;learning artificial intelligence;reseau neuronal;resonance clustering algorithms clustering methods sonar applications radar applications control systems radar tracking fuzzy logic computer science subspace constraints;estudio experimental;pattern clustering art neural nets fuzzy neural nets generalisation artificial intelligence learning artificial intelligence;generalization;red neuronal;fuzzy system;analyse forme;training pattern presentation ordering algorithm pattern presentation fuzzy artmap generalization performance max min clustering method;neural network	In this paper we introduce a procedure, based on the max-min clustering method, that identifies a fixed order of training pattern presentation for fuzzy adaptive resonance theory mapping (ARTMAP). This procedure is referred to as the ordering algorithm, and the combination of this procedure with fuzzy ARTMAP is referred to as ordered fuzzy ARTMAP. Experimental results demonstrate that ordered fuzzy ARTMAP exhibits a generalization performance that is better than the average generalization performance of fuzzy ARTMAP, and in certain cases as good as, or better than the best fuzzy ARTMAP generalization performance. We also calculate the number of operations required by the ordering algorithm and compare it to the number of operations required by the training phase of fuzzy ARTMAP. We show that, under mild assumptions, the number of operations required by the ordering algorithm is a fraction of the number of operations required by fuzzy ARTMAP.	adaptive resonance theory;cluster analysis;exhibits as topic;generalization (psychology);hl7publishingsubsection <operations>;maxima and minima;order (action);algorithm;statistical cluster	Issam Dagher;Michael Georgiopoulos;Gregory L. Heileman;George Bebis	1999	IEEE transactions on neural networks	10.1109/72.774217	generalization;computer science;artificial intelligence;fuzzy number;adaptive system;machine learning;fuzzy set operations;artificial neural network;algorithm	DB	10.649976152580786	-32.37375825284802	40932
24a67c5bed10b670ee36bf1919b5ff0d00981fb6	a comparative study of outlier detection algorithms	anomaly;robustness analysis;algorithm analysis;time complexity;anomaly detection;outlier;intrusion detection;detection;data mining;outlier detection;markov model;ozone;fraud detection	Data Mining is the process of extracting interesting information from large sets of data. Outliers are defined as events that occur very infrequently. Detecting outliers before they escalate with potentially catastrophic consequences is very important for various real life applications such as in the field of fraud detection, network robustness analysis, and intrusion detection. This paper presents a comprehensive analysis of three outlier detection methods Extensible Markov Model (EMM), Local Outlier Factor (LOF) and LCS-Mine, where algorithm analysis shows the time complexity analysis and outlier detection accuracy. The experiments conducted with Ozone level Detection, IR video trajectories, and 1999 and 2000 DARPA DDoS datasets demonstrate that EMM outperforms both LOF and LSC-Mine in both time and outlier detection accuracy.	algorithm;anomaly detection	Charlie Isaksson;Margaret H. Dunham	2009		10.1007/978-3-642-03070-3_33	intrusion detection system;time complexity;ozone;anomaly detection;outlier;anomaly;computer science;machine learning;pattern recognition;data mining;markov model;statistics	ML	5.610628563741449	-36.65856165872478	40936
4a349e11550c439fe81fe339f9d5dcbf8a5194e0	dense associative memory for pattern recognition		A model of associative memory is studied, which stores and reliably retrieves many more patterns than the number of neurons in the network. We propose a simple duality between this dense associative memory and neural networks commonly used in deep learning. On the associative memory side of this duality, a family of models that smoothly interpolates between two limiting cases can be constructed. One limit is referred to as the feature-matching mode of pattern recognition, and the other one as the prototype regime. On the deep learning side of the duality, this family corresponds to feedforward neural networks with one hidden layer and various activation functions, which transmit the activities of the visible neurons to the hidden layer. This family of activation functions includes logistics, rectified linear units, and rectified polynomials of higher degrees. The proposed duality makes it possible to apply energy-based intuition from associative memory to analyze computational properties of neural networks with unusual activation functions – the higher rectified polynomials which until now have not been used in deep learning. The utility of the dense memories is illustrated for two test cases: the logical gate XOR and the recognition of handwritten digits from the MNIST data set.	activation function;artificial neural network;bidirectional associative memory;content-addressable memory;deep learning;exclusive or;feedforward neural network;interpolation;logic gate;logistics;mnist database;pattern recognition;polynomial;prototype;smoothing;test case	Dmitry Krotov;John J. Hopfield	2016			artificial intelligence;machine learning;bidirectional associative memory	ML	18.47609123838366	-30.609718924211826	40939
d6a33a7e33d6f33dc1c805bdcaa0e2c12fbc20cf	on the optimality of the dayhoff matrix for computing the similarity score between fragments of biological sequences				Andrey M. Leontovich	1992			machine learning;matrix (mathematics);computer science;artificial intelligence	Theory	-0.3194336589514821	-48.60949196233066	40940
b9c0a0e451b9fbd87e25c5184bc3ebb7087f848c	building sparse twin support vector machine classifiers in primal space	sparse control;support vector;empirical risk minimization;stopping criterion;twin support vector machine;back fitting strategy;support vector machine;primal space;linear equations	Twin support vector machines (TSVM) obtain faster training speeds than classical support vector machines (SVM). However, TSVM augmented vectors lose sparsity. In this paper, a rapid sparse twin support vector machine (STSVM) classifier in primal space is proposed to improve the sparsity and robustness of TSVM. Based on a simple back-fitting strategy, the STSVM iteratively builds each nonparallel hyperplanes by adding one support vector (SV) from the corresponding class at one time. This process is terminated using an adaptive and stable stopping criterion. STSVM learning is implemented by linear equation computing systems through introducing a quadratic function to approximate the empirical risk. The computational results on several synthetic and benchmark datasets indicate that the STSVM obtains a sparse separating hyperplane at a low cost without sacrificing its generalization performance.	sparse matrix;support vector machine	Xinjun Peng	2011	Inf. Sci.	10.1016/j.ins.2011.05.004	margin classifier;support vector machine;least squares support vector machine;mathematical optimization;computer science;machine learning;pattern recognition;mathematics;relevance vector machine;structured support vector machine	ML	21.24039813032406	-37.64385267298147	40981
b17970a05a19d7a2fef979f3532e27a0c1cad026	combining active learning and dynamic dimensionality reduction	dimensionality reduction;active learning	To date, many active learning techniques have been developed for acquiring labels when training data is limited. However, an important aspect of the problem has often been neglected or just mentioned in passing: the curse of dimensionality. Yet, the curse of dimensionality poses even greater challenges in the case of limited data, which is precisely the setup for active learning. Reducing the dimensions is not a trivial task, however, as the correct number of dimensions depends on a number of factors including the training data size, the number of classes, the discriminative power of the features, and the underlying classification model. Moreover, active learning is typically applied in an iterative manner where the number of labels is smaller in the earlier iterations compared to the later ones. We propose an adaptive dimensionality reduction technique that determines the appropriate number of dimensions for each active learning iteration, utilizing the labeled and unlabeled data effectively to learn more accurate models. Extensive experiments comparing various approaches and parameter settings show that the proposed method improves performance drastically on three real-world text classification tasks.	active learning (machine learning);algorithm;baseline (configuration management);curse of dimensionality;dimensionality reduction;document classification;experiment;iteration;machine learning;monte carlo method;sampling (signal processing)	Mustafa Bilgic	2012		10.1137/1.9781611972825.60	dimensionality reduction	AI	17.432716209126372	-39.78062252308512	41043
e864ac81c2862acb2e563b25b3ff787ef64a428c	on the use of fuzzy rule interpolation techniques for monotonic multi-input fuzzy rule base models	interpolation;interpolation techniques;fuzzy set;interpolation process;fuzzy reasoning;interpolation fuzzy sets fuzzy systems function approximation sufficient conditions genetic algorithms curve fitting linearity stress equations;search algorithm;biological system modeling;fuzzy inference systems;search problems fuzzy reasoning fuzzy set theory fuzzy systems interpolation knowledge based systems;data mining;fuzzy set theory;fuzzy sets;mathematical derivation;fuzzy rule interpolation;fuzzy rule base;ordering criterion;multiinput;brute force;monotonicity;fuzzy inference system;mathematical model;rule selection;genetic algorithm;engineering problems;search problems;monotonic multiinput fuzzy rule base model;fis;genetic algorithm fuzzy rule interpolation technique monotonic multiinput fuzzy rule base model fuzzy inference system fis fuzzy set ordering criterion rule selection search algorithm brute force;fuzzy rule interpolation technique;fuzzy systems;knowledge based systems;ordering criteria;search algorithms;fuzzy rule base models	Constructing a monotonicity relating function is important, as many engineering problems revolve around a monotonicity relationship between input(s) and output(s). In this paper, we investigate the use of fuzzy rule interpolation techniques for monotonicity relating fuzzy inference system (FIS). A mathematical derivation on the conditions of an FIS to be monotone is provided. From the derivation, two conditions are necessary. The derivation suggests that the mapped consequence fuzzy set of an FIS to be of a monotonicity order. We further evaluate the use of fuzzy rule interpolation techniques in predicting a consequent associated with an observation according to the monotonicity order. There are several findings in this article. We point out the importance of an ordering criterion in rule selection for a multi-input FIS before the interpolation process; and hence, the practice of choosing the nearest rules may not be true in this case. To fulfill the monotonicity order, we argue with an example that conventional fuzzy rule interpolation techniques that predict each consequence separately is not suitable in this case. We further suggest another class of interpolation techniques that predicts the consequence of a set of observations simultaneously, instead of separately. This can be accomplished with the use of a search algorithm, such as the brute force, genetic algorithm or etc.	brute-force search;fuzzy rule;fuzzy set;genetic algorithm;inference engine;interpolation;rule-based system;search algorithm;serial ata;monotone	Chee Peng Lim	2009	2009 IEEE International Conference on Fuzzy Systems	10.1109/FUZZY.2009.5277387	mathematical optimization;discrete mathematics;computer science;artificial intelligence;knowledge-based systems;machine learning;mathematics;fuzzy set;fuzzy control system	Robotics	4.099826802734159	-27.229821178598918	41086
633ee7fbf324e27032bad2c8fe3ee2224db7053e	building a family of neural networks using symmetry as a foundation	engineering;graph theory;graph theory neural networks training vector training regime input output function mapping task weight transformations euclidian distance function ann systemic information reuse matrix equation;distance function;neural networks;computer science artificial intelligence;matrix algebra;ann systemic information reuse;input output;matrix algebra graph theory learning artificial intelligence;euclidian distance function;matrix equation;input output function mapping task;weight transformations;neural networks neurons feedforward neural networks computer science usa councils discrete transforms data mining equations probability distribution network topology;learning artificial intelligence;training regime;training vector;neural network;computer science software	In order to perform a function mapping task, a neural network needs two supporting mechanisms: an input and an output training vector, and a training regime. A new approach is proposed to generating a family of neural networks for performing a set of related functions. Within a family, only one network needs to be trained to perform an input-output function mapping task and other networks can be derived from this trained base network without training. The base net thus acts as a generator of the derived nets. The proposed approach builds on three mathematical foundations: (1) symmetry for defining the relationship between functions; (2) weight transformations for generating a family of networks; (3) Euclidian distance function for measuring the symmetric relationships between the related functions. The proposed approach provides a formal foundation for systemic information reuse in ANNs.	euclidean distance;neural networks	Richard Neville;Liping Zhao	2007	2007 International Joint Conference on Neural Networks	10.1109/IJCNN.2007.4370922	input/output;metric;computer science;artificial intelligence;theoretical computer science;machine learning;mathematics;artificial neural network;matrix	AI	17.824326083711203	-29.40874881272239	41089
99f91b786e83497a100b059cbb58917406459ebd	neural network studies, 1. comparison of overfitting and overtraining	neural network	The application of feed forward back propagation artificial neural networks with one hidden layer (ANN) to perform the equivalent of multiple linear regression (MLR) has been examined using artificial structured data sets and real literature data. The predictive ability of the networks has been estimated using a training/ test set protocol. The results have shown advantages of ANN over MLR analysis. The ANNs do not require high order terms or indicator variables to establish complex structure-activity relationships. Overfitting does not have any influence on network prediction ability when overtraining is avoided by cross-validation. Application of ANN ensembles has allowed the avoidance of chance correlations and satisfactory predictions of new data have been obtained for a wide range of numbers of neurons in the hidden layer.	artificial neural network;backpropagation;cross-validation (statistics);learning to rank;neural ensemble;overfitting;software propagation;test set	Igor V. Tetko;David J. Livingstone;Alexander I. Luik	1995	Journal of Chemical Information and Computer Sciences	10.1021/ci00027a006	chemistry;computer science;artificial intelligence;machine learning;pattern recognition;artificial neural network	ML	11.446871877074038	-24.272875199684904	41125
0e94303408ce253c3bf1ebd39bd6c523d7545ac2	an analysis of the furia algorithm for fuzzy rule induction	rule induction;fuzzy rules;fuzzy rule base;classification accuracy	This paper elaborates on a novel fuzzy rule-based classification method called FURIA, which is short for “Fuzzy Unordered  Rule Induction Algorithm”. FURIA has recently been developed as an extension of the well-known RIPPER algorithm. It learns  fuzzy rules instead of conventional rules and unordered rule sets instead of rule lists. Moreover, to deal with uncovered  examples, it makes use of an efficient rule stretching method. First experimental results have shown that FURIA significantly  outperforms the original RIPPER in terms of classification accuracy. Elaborating on the advantages of a fuzzy approach, this  paper makes an attempt to distill and quantify the influence of rule fuzzification on the performance of the algorithm. Moreover,  going beyond the conventional classification problem, we investigate the performance of FURIA in the context of bipartite  ranking, in which a fuzzy approach appears to be even more appealing.  	algorithm;fuzzy rule;rule 90;rule induction	Jens Christian Hühn;Eyke Hüllermeier	2010		10.1007/978-3-642-05177-7_16	defuzzification;fuzzy classification;neuro-fuzzy;fuzzy associative matrix;fuzzy set operations	ML	-1.7262483343359964	-29.21168976184506	41215
36eba312eaa0d7c1a8e96d5fa5ac1a5b70ff853d	neural network algorithm for the simultaneous extraction of all roots of algebraic polynomial	learning rate;convergence;algebraic polynomial;neural nets;approximation algorithms;data mining;polynomials;convergence neural network roots of algebraic polynomial algorithm;iterative methods;algorithm;artificial neural networks;convergence algebraic polynomial neural network iteration method;neural networks polynomials convergence data mining rail transportation educational institutions iterative methods computational intelligence information security telecommunication traffic;neural network iteration method;approximation methods;roots of algebraic polynomial;iteration method;polynomials convergence iterative methods neural nets;neural network	In this paper, we construct a neural network iteration method for simultaneous extraction of all roots of algebraic polynomial with variable learning rate. Its convergence was researched. The specific examples showed that the proposed method can simultaneously find all roots of algebraic polynomial at a very rapid convergence and very high accuracy with less computation.	algebraic equation;algorithm;artificial neural network;computation;iteration;linear algebra;polynomial;roots	Zhe-zhao Zeng	2009	2009 International Conference on Computational Intelligence and Security	10.1109/CIS.2009.78	mathematical optimization;discrete mathematics;computer science;gröbner basis;theoretical computer science;machine learning;wilkinson's polynomial;mathematics;iterative method;matrix polynomial;algebraic function;square-free polynomial;artificial neural network;polynomial	Robotics	18.063998295924517	-29.03976837279087	41268
927243e1999e11d409cc0e8c3efbf66ce488abd1	a recurrent neural network using tri-state hidden neurons to orthogonalize the memory space	recurrent neural network	"""This paper describes a process for adding hidden neurons to a fully recurrent Hopfield neural network in such a way as to optimize the orthogonality of the memory space. The process uses the network itself, operating with a """"reverse update rule"""" to assign optimal values to the hidden neurons for each memory. The outer product rule is used to modify synaptic strengths as each new memory is added. As in a standard Hopfield network this is a fast process because it is noniterative. Tri-state hidden neurons, initially set to zero, are used in the recovery of memories. Simulations indicate that the storage capacity of the network for uncorrelated memories, and the radius of attraction of each memory, are significantly better than those of the standard Hopfield network. The use of hidden neurons permits flexibility in the network capacity for memories of a given length. The network is able to solve second-order hetero-associative problems, as illustrated with solutions to the XOR set of associations."""	computational resource;recurrent neural network	Michael R. Davenport;Geoffrey W. Hoffmann	1989	Int. J. Neural Syst.	10.1142/S0129065789000049	computer science;artificial intelligence;recurrent neural network;theoretical computer science;machine learning;bidirectional associative memory;echo state network;hopfield network	ML	17.232703648729917	-29.445384276393014	41274
b19c30a29fbba76d4927b827e55073149a22698f	hybrid artificial intelligent systems		Multi-label classification (MLC) problems abound in many areas, including text categorization, protein function classification, and semantic annotation of multimedia. Issues that severely limit the applicability of many current machine learning approaches to MLC are the large-scale problem and the high dimensionality of the label space, which have a strong impact on the computational complexity of learning. These problems are especially pronounced for approaches that transform MLC problems into a set of binary classification problems for which SVMs are used. On the other hand, the most efficient approaches to MLC, based on decision trees, have clearly lower predictive performance. We propose a hybrid decision tree architecture that utilizes local SVMs for efficient multi-label classification. We build decision trees for MLC, where the leaves do not give multi-label predictions directly, but rather contain SVM-based classifiers giving multi-label predictions. A binary relevance architecture is employed in each leaf, where a binary SVM classifier is built for each of the labels relevant to that particular leaf. We use several real-world datasets to evaluate the proposed method and its competition. Our hybrid approach on almost every classification problem outperforms the predictive performances of SVM-based approaches while its computational efficiency is significantly improved as a result of the integrated decision tree.	artificial intelligence;binary classification;categorization;computation;computational complexity theory;decision tree;document classification;machine learning;multi-label classification;multi-level cell;multiclass classification;performance;relevance	Randy Goebel;Yuzuru Tanaka;Emilio Corchado;Václav Snásel;Ajith Abraham;Michał Woźniak;Manuel Graña;Sung-Bae Cho Eds	2012		10.1007/978-3-642-28931-6		ML	14.480051692947843	-48.658171511305284	41323
351e8e5e9c74b768402069461f101d20f6d3f49c	multivariate time series representation and similarity search using pca		Multivariate time series (MTS) data mining has attracted much interest in recent years due to the increasing number of fields requiring the capability to manage and process large collections of MTS. In those frameworks, carrying out pattern recognition tasks such as similarity search, clustering or classification can be challenging due to the high dimensionality, noise, redundancy and feature correlated characteristics of the data. Dimensionality reduction is consequently often used as a preprocessing step to render the data more manageable. We propose in this paper a novel MTS similarity search approach that addresses these problems through dimensionality reduction and correlation analysis. An important contribution of the proposed technique is a representation allowing to transform the MTS with large number of variables to a univariate signal prior to seeking correlations within the set. The technique relies on unsupervised learning through Principal Component Analysis (PCA) to uncover and use, weights associated with the original input variables, in the univariate derivation. We conduct numerous experiments using various benchmark datasets to study the performance of the proposed technique. Compared to major existing techniques, our results indicate increased accuracy and efficiency. We also show that our technique yields improved similarity search accuracy.	application framework;benchmark (computing);cluster analysis;data mining;dimensionality reduction;experiment;pattern recognition;preprocessor;principal component analysis;similarity search;time series;unsupervised learning	Aminata Kane;Nematollaah Shiri	2017		10.1007/978-3-319-62701-4_10	dimensionality reduction;curse of dimensionality;principal component analysis;cluster analysis;unsupervised learning;machine learning;multivariate statistics;nearest neighbor search;computer science;pattern recognition;artificial intelligence;univariate	ML	11.200618279418071	-46.14312270410009	41353
241c89d3aa5cf0714ba03a371dcf73ec87e6ff31	properties of rough approximations	ordered sets and lattices;indiscernibility relation;rough approximation operators	Rough set theory, introduced by Pawlak [10], is a mathematical formalism dealing with uncertainty and to some extent overlapping fuzzy set theory introduced by Zadeh [12]. In fuzzy set theory vagueness is expressed by a membership function. The rough set theory approach is based on indiscernibility relations and approximations. A major advantage of rough set theory is that it needs no preliminary or additional information about data, such as membership functions in fuzzy set theory. The basic idea of rough set theory is that knowledge about objects is represented by indiscernibility relations. Indiscernibility relations are usually assumed to be equivalences—reflexive, symmetric, and transitive binary relations—interpreted so that two objects are equivalent if we cannot distinguish them by their properties. This means that if we observe objects through knowledge given by an indiscernibility relation, our ability to distinguish objects is blurred—we cannot distinguish individual objects, only their equivalence classes. Let us consider the situation in Fig.1. Let X be a subset of a given universe of discourse U and let be an indiscernibility relation on U . Since the equivalence induces the partition U whose blocks are the equivalence classes of , the objects of the universe U are classified by in three classes for any subset X U :	approximation;domain of discourse;fuzzy set;rough set;semantics (computer science);set theory;turing completeness;vagueness	Jouni Järvinen	2005	JACIII	10.20965/jaciii.2005.p0502	dominance-based rough set approach	Theory	-1.884677296128925	-25.079113286402816	41378
0d6889c98d4e3e771428d686286689b5fa628167	large-scale linear support vector regression	support vector regression;newton methods;coordinate descent methods	Support vector regression (SVR) and support vector classification (SVC) are popular learning techniques, but their use with kernels is often time consuming. Recently, linear SVC without kernels has been shown to give competitive accuracy for some applications, but enjoys much faster training/testing. However, few studies have focused on linear SVR. In this paper, we extend state-of-theart training methods for linear SVC to linear SVR. We show that the extension is straightforward for some methods, but is not trivial for some others. Our experiments demonstrate that for some problems, the proposed linear-SVR training methods can very efficiently produce models that are as good as kernel SVR.	experiment;linear logic;support vector machine	Chia-Hua Ho;Chih-Jen Lin	2012	Journal of Machine Learning Research		support vector machine;econometrics;mathematical optimization;computer science;machine learning;mathematics	ML	21.72357590847359	-37.19485219240717	41420
12ee79745f1665cd44dde7a40e73ef98e85e7b3e	generating fixed-size training sets for large and streaming datasets		The k Nearest Neighbor is a popular and versatile classifier but requires a relatively small training set in order to perform adequately, a prerequisite not satisfiable with the large volumes of training data that are nowadays available from streaming environments. Conventional Data Reduction Techniques that select or generate training prototypes are also inappropriate in such environments. Dynamic RHC (dRHC) is a prototype generation algorithm that can update its condensing set when new training data arrives. However, after repetitive updates, the size of the condensing set may become unpredictably large. This paper proposes dRHC2, a new variation of dRHC, which remedies the aforementioned drawback. dRHC2 keeps the size of the condensing set in a convenient, manageable by the classifier, level by ranking the prototypes and removing the least important ones. dRHC2 is tested on several datasets and the experimental results reveal that it is more efficient and noise tolerant than dRHC and is comparable to dRHC in terms of accuracy.		Stefanos Ougiaroglou;Georgios Arampatzis;Dimitris A. Dervos;Georgios Evangelidis	2017		10.1007/978-3-319-66917-5_7	computer science;data mining;data reduction;data stream mining;training set;cluster analysis;artificial intelligence;k-nearest neighbors algorithm;pattern recognition;ranking	Vision	12.979218456652573	-40.524522455169816	41430
83da51b3e2045d3ba011fe14e9853694cd7373b7	the application of a double cusum algorithm in industrial data stream anomaly detection		The effect of the application of machine learning on data streams is influenced by concept drift, drift deviation, and noise interference. This paper proposes a data stream anomaly detection algorithm combined with control chart and sliding window methods. This algorithm is named DCUSUM-DS (Double CUSUM Based on Data Stream), because it uses a dual mean value cumulative sum. The DCUSUM-DS algorithm based on nested sliding windows is proposed to satisfy the concept drift problem; it calculates the average value of the data within the window twice, extracts new features, and then calculates accumulated and controlled graphs to avoid misleading by interference points. The new algorithm is simulated using drilling engineering industrial data. Compared with automatic outlier detection for data streams (A-ODDS) and with sliding nest window chart anomaly detection based on data streams (SNWCAD-DS), the DCUSUM-DS can account for concept drift and shield a small amount of interference deviating from the overall data. Although the algorithm complexity increased from 0.1 second to 0.19 second, the classification accuracy receiver operating characteristic (ROC) increased from 0.89 to 0.95. This meets the needs of the oil drilling industry data stream with a sampling frequency of 1 Hz, and it improves the classification accuracy.	algorithm;anomaly detection;computational complexity theory;concept drift;experiment;interference (communication);machine learning;microsoft windows;nintendo ds and 3ds storage devices;receiver operating characteristic;requirement;robustness (computer science);sampling (signal processing)	Guang Li;Jie Wang;Jing Liang;Caitong Yue	2018	Symmetry	10.3390/sym10070264	combinatorics;mathematics;anomaly detection;data stream;artificial intelligence;pattern recognition;cusum	ML	0.4477395013221103	-34.727684084678124	41441
e2cfbfac74fea9df70b832d6578a99dfc5c4e6eb	nfi: a neuro-fuzzy inference method for transductive reasoning	fuzzy neural nets;neuro fuzzy inference system;transductive reasoning;medical decision support problem neurofuzzy inference method transductive reasoning systems inductive reasoning mackey glass time series iris data classification renal function evaluation;inference mechanisms;time series;medical computing;renal function;inductive reasoning;predictive models fuzzy systems fuzzy reasoning deductive databases induction generators glass iris medical treatment testing multilayer perceptrons;adaptive systems;fuzzy inference;neural fuzzy inference nfi;transductive reasoning adaptive systems neural fuzzy inference nfi renal function evaluation time series prediction;adaptive system;renal function evaluation;vector data;medical decision support;time series prediction;medical computing inference mechanisms fuzzy neural nets	This paper introduces a novel neural fuzzy inference method-NFI for transductive reasoning systems. NFI develops further some ideas from DENFIS-dynamic neuro-fuzzy inference systems for both online and offline time series prediction tasks. While inductive reasoning is concerned with the development of a model (a function) to approximate data in the whole problem space (induction), and consecutively-using this model to predict output values for a new input vector (deduction), in transductive reasoning systems a local model is developed for every new input vector, based on some closest to this vector data from an existing database (also generated from an existing model). NFI is compared with both inductive connectionist systems (e.g., MLP, DENFIS) and transductive reasoning systems (e.g., K-NN) on three case study prediction/identification problems. The first one is a prediction task on Mackey Glass time series; the second one is a classification on Iris data; and the last one is a real medical decision support problem of estimating the level of renal function of a patient, based on measured clinical parameters for the purpose of their personalised treatment. The case studies have demonstrated better accuracy obtained with the use of the NFI transductive reasoning in comparison with the inductive reasoning systems.	approximation algorithm;connectionism;decision support system;fuzzy logic;inductive reasoning;k-nearest neighbors algorithm;memory-level parallelism;natural deduction;neuro-fuzzy;online and offline;problem domain;time series	Qun Song;Nikola K. Kasabov	2005	IEEE Transactions on Fuzzy Systems	10.1109/TFUZZ.2005.859311	transduction;computer science;artificial intelligence;adaptive system;machine learning;time series;pattern recognition;data mining;mathematics;reasoning system;statistics	ML	3.8937816490769044	-28.554635417180773	41442
1f4e159fc6411033f79304590e9d58444879916a	extending kernel fisher discriminant analysis with the weighted pairwise chernoff criterion	reconnaissance visage;vision ordenador;sample size;distribution donnee;image processing;small sample size;fonction poids;facies;methode noyau;dimension reduction;tamano muestra;procesamiento imagen;taille echantillon;linear discriminate analysis;classification;traitement image;data distribution;computer vision;reduction dimension;discriminant analysis;analyse discriminante;analisis discriminante;real world application;face recognition;kernel fisher discriminant analysis;nonlinear dimensionality reduction;metodo nucleo;funcion peso;pattern recognition;reduccion dimension;kernel method;vision ordinateur;reconnaissance forme;weight function;reconocimiento patron;classification accuracy;distribucion dato;clasificacion	Many linear discriminant analysis (LDA) and kernel Fisher discriminant analysis (KFD) methods are based on the restrictive assumption that the data are homoscedastic. In this paper, we propose a new KFD method called heteroscedastic kernel weighted discriminant analysis (HKWDA) which has several appealing characteristics. First, like all kernel methods, it can handle nonlinearity efficiently in a disciplined manner. Second, by incorporating a weighting function that can capture heteroscedastic data distributions into the discriminant criterion, it can work under more realistic situations and hence can further enhance the classification accuracy in many real-world applications. Moreover, it can effectively deal with the small sample size problem. We have performed some face recognition experiments to compare HKWDA with several linear and nonlinear dimensionality reduction methods, showing that HKWDA consistently gives the best results.	algorithm;chernoff bound;experiment;facial recognition system;feature extraction;kernel (operating system);kernel method;linear discriminant analysis;nonlinear dimensionality reduction;nonlinear system;norm (social);weight function	Guang Dai;Dit-Yan Yeung;Hong Chang	2006		10.1007/11744085_24	sample size determination;kernel method;econometrics;kernel fisher discriminant analysis;weight function;facies;image processing;biological classification;computer science;machine learning;pattern recognition;optimal discriminant analysis;mathematics;nonlinear dimensionality reduction;linear discriminant analysis;multiple discriminant analysis;statistics;dimensionality reduction	Vision	23.729537510796945	-39.25052936243534	41505
fb47931a7abee04fb615aca7fabeab0b6af328ab	multi-label classification with bayesian network-based chain classifiers	multi label classification;chain classifier;bayesian networks	We introduce a novel method for chaining Bayesian classifiers.We provide a detailed analysis of the proposed method.We perform an extensive empirical evaluation.We show very competitive results against related approaches. In multi-label classification the goal is to assign an instance to a set of different classes. This task is normally addressed either by defining a compound class variable with all the possible combinations of labels (label power-set methods) or by building independent classifiers for each class (binary relevance methods). The first approach suffers from high computationally complexity, while the second approach ignores possible dependencies among classes. Chain classifiers have been recently proposed to address these problems, where each classifier in the chain learns and predicts the label of one class given the attributes and all the predictions of the previous classifiers in the chain. In this paper we introduce a method for chaining Bayesian classifiers that combines the strengths of classifier chains and Bayesian networks for multi-label classification. A Bayesian network is induced from data to: (i) represent the probabilistic dependency relationships between classes, (ii) constrain the number of class variables used in the chain classifier by considering conditional independence conditions, and (iii) reduce the number of possible chain orders. The effects in the Bayesian chain classifier performance of considering different chain orders, training strategies, number of class variables added in the base classifiers, and different base classifiers, are experimentally assessed. In particular, it is shown that a random chain order considering the constraints imposed by a Bayesian network with a simple tree-based structure can have very competitive results in terms of predictive performance and time complexity against related state-of-the-art approaches.	bayesian network;multi-label classification	Luis Enrique Sucar;Concha Bielza;Eduardo F. Morales;Pablo Hernandez-Leal;Julio H. Zaragoza;Pedro Larrañaga	2014	Pattern Recognition Letters	10.1016/j.patrec.2013.11.007	random subspace method;computer science;machine learning;pattern recognition;bayesian network;data mining;mathematics	Vision	17.4006123591245	-37.63760773167262	41627
cc1cad4533ceb320e947ce0accac024963ddf7b2	determination of optimal recognition algorithms in the two-level system	optimisation;sistema 2 niveles;linearity;optimizacion;decision function;linearite;decision bayes;fonction decision;electrocardiographie;bayes decision;linearidad;electrocardiography;electrocardiografia;funcion decision;two level system;pattern recognition;optimization;reconnaissance forme;reconocimiento patron;algoritmo optimo;algorithme optimal;optimal algorithm;systeme 2 niveaux	Abstract   In this paper the problem of pattern recognition in the two-level system is investigated. The application of linear decision functions to the determination of the optimal recognition algorithms is presented. The results are obtained in a numerical way using a random method of optimization.	algorithm	Jerzy Józefczyk	1986	Pattern Recognition Letters	10.1016/0167-8655(86)90038-3	computer science;artificial intelligence;pattern recognition;mathematics;linearity;operations research;algorithm	Vision	11.26283310629275	-34.10430296076956	41670
e22af5f89ca657f715cf409ee60d2fed8cf1e0ad	random fourier feature kernel recursive least squares		In this paper, we investigate the nonlinear, finite dimensional and data independent random Fourier feature expansions that can approximate the popular Gaussian kernel. With recursive least squares algorithm, we develop the Random Fourier Feature Recursive Least Squares algorithm (RFF-RLS), which shows significant performance improvements in simulations when compared with several other online kernel learning algorithms such as Kernel Least Mean Square (KLMS) and Kerne Recursive Least Squares (KRLS). Our results confirm that the RFF-RLS can achieve desirable performance with low computational cost. As for the random Fourier features, the randomization generally results in redundancy. We use an algorithm, namely, Vector Quantization with Information Theoretic Learning (VQIT) to decrease the dictionary size. The resulting sparse dictionary can match the original data distribution well. The RFF-RLS with VQIT can outperform the RFF-RLS without VQIT.	algorithmic efficiency;approximation algorithm;computational complexity theory;data dictionary;kernel (operating system);machine learning;nonlinear system;online machine learning;procedural generation;randomized algorithm;randomness;recursion (computer science);recursive least squares filter;redundancy (engineering);simulation;sparse matrix;vector quantization	Zhengda Qin;Badong Chen;Nanning Zheng	2017	2017 International Joint Conference on Neural Networks (IJCNN)	10.1109/IJCNN.2017.7966212	machine learning;gaussian function;kernel embedding of distributions;artificial intelligence;least squares support vector machine;kernel method;recursive least squares filter;pattern recognition;least mean squares filter;mathematical optimization;variable kernel density estimation;mathematics;radial basis function kernel	ML	23.66012267859853	-36.2103058495829	41760
ea160ca21b2a8c4402b077d6338e6a679aa9d7b9	less-forgetting learning in deep neural networks		A catastrophic forgetting problem makes deep neural networks forget the previously learned information, when learning data collected in new environments, such as by different sensors or in different light conditions. This paper presents a new method for alleviating the catastrophic forgetting problem. Unlike previous research, our method does not use any information from the source domain. Surprisingly, our method is very effective to forget less of the information in the source domain, and we show the effectiveness of our method using several experiments. Furthermore, we observed that the forgetting problem occurs between mini-batches when performing general training processes using stochastic gradient descent methods, and this problem is one of the factors that degrades generalization performance of the network. We also try to solve this problem using the proposed method. Finally, we show our less-forgetting learning method is also helpful to improve the performance of deep neural networks in terms of recognition rates.	artificial neural network;catastrophic interference;deep learning;experiment;neural networks;sensor;stochastic gradient descent	Heechul Jung;Jeongwoo Ju;Minju Jung;Junmo Kim	2016	CoRR		catastrophic interference;simulation;computer science;artificial intelligence;machine learning	AI	20.504009820863015	-49.634066384167674	41789
198927f049a33e16523db3db0cd35fce67ad657d	neural networks with activation networks		This work presents an adaptive activation method for neural networks that exploits the interdependency of features. Each pixel, node, and layer is assigned with a polynomial activation function, whose coefficients are provided by an auxiliary activation network. The activation of a feature depends on the features of neighboring pixels in a convolutional layer and other nodes in a dense layer. The dependency is learned from data by the activation networks. In our experiments, networks with activation networks provide significant performance improvement compared to the baseline networks on which they are built. The proposed method can be used to improve the network performance as an alternative to increasing the number of nodes and layers.	activation function;artificial neural network;baseline (configuration management);coefficient;computation;computational complexity theory;experiment;interdependence;network performance;neural network software;pixel;polynomial	Jinhyeok Jang;Jaehong Kim;Jaeyeon Lee;Seungjoon Yang	2018	CoRR			ML	23.191654606852463	-51.40293854383096	41818
86b0949d365418a7bd88cc916c9bd5bb5fd0e9ae	exploiting strong convexity from data with primal-dual first-order algorithms		We consider empirical risk minimization of linear predictors with convex loss functions. Such problems can be reformulated as convex-concave saddle point problems, and thus are well suitable for primal-dual first-order algorithms. However, primal-dual algorithms often require explicit strongly convex regularization in order to obtain fast linear convergence, and the required dual proximal mapping may not admit closedform or efficient solution. In this paper, we develop both batch and randomized primal-dual algorithms that can exploit strong convexity from data adaptively and are capable of achieving linear convergence even without regularization. We also present dual-free variants of the adaptive primal-dual algorithms that do not require computing the dual proximal mapping, which are especially suitable for logistic regression.	concave function;convex function;empirical risk minimization;first-order predicate;logistic regression;loss function;randomized algorithm;rate of convergence;strong duality	Jialei Wang;Lin Xiao	2017			mathematical optimization;proximal gradient methods for learning;combinatorics;discrete mathematics;mathematics	ML	23.869751017843992	-33.614729663305475	41832
f6c14f8c9a229700baa78fef7be96aa842b7601a	learning of geometric mean neuron model using resilient propagation algorithm	learning algorithm;aggregation function;multilayer perceptron;functional approximation;function approximation;resilient propagation;geometric mean;back propagation;neuron model	The paper proposes a new neuron model (geometric mean neuron model) with an aggregation function based on geometric mean of all inputs. Performance of the geometric mean neuron model was evaluated using various learning algorithms like the back-propagation and resilient propagation on various real life data sets. Comparison of the performance of this model was made with the performance of multilayer perceptron. It has been shown that the geometric mean based aggregation function with resilient propagation (RPROP) performs the best both in terms of accuracy and speed.	algorithm;biological neuron model;rprop;software propagation	Md. Shiblee;Bala Chandra;Prem Kumar Kalra	2010	Expert Syst. Appl.	10.1016/j.eswa.2010.04.018	geometric mean;function approximation;computer science;artificial intelligence;backpropagation;theoretical computer science;biological neuron model;machine learning;multilayer perceptron	ML	14.241140831536612	-27.395418566564878	41844
cab347d4b21437f3bf8d2b16589c73c33f958c19	dcf: a dataflow-based collaborative filtering training algorithm		Emerging recommender systems often adopt collaborative filtering techniques to improve the recommending accuracy. Existing collaborative filtering techniques are implemented with either alternating least square algorithm or gradient descent (GD) algorithm. However, both of the two algorithms are not scalable because ALS suffers from high computation complexity and GD suffers from severe synchronization problem and tremendous data movement. To solve the above problems, we proposed a Dataflow-based Collaborative Filtering (DCF) algorithm. More specifically, DCF exploits fine-grain asynchronous feature of dataflow model to minimize synchronization overhead; leverages mini-batch technique to reduce computation and communication complexities; uses dummy edge and multicasting techniques to avoid fine-grain overhead of dependency checking and reduce data movement. By utilizing all the above techniques, DCF is able to significantly improve the performance of collaborative filtering. Our experiment on a cluster with one master node and ten slave nodes show that DCF achieves 23$$\times $$ × speedup over ALS on Spark and 18$$\times $$ × speedup over GD on Graphlab in public datasets.	algorithm;collaborative filtering;computation;data dependency;dataflow;design rule for camera file system;distributed computing;dummy variable (statistics);feedback;gradient descent;multicast;overhead (computing);parallel computing;recommender system;scalability;speedup	Xiangyu Ju;Quan Chen;Zhenning Wang;Minyi Guo;Guang R. Gao	2017	International Journal of Parallel Programming	10.1007/s10766-017-0525-y	recommender system;collaborative filtering;parallel computing;computer science;synchronization;dataflow;scalability;speedup;algorithm;asynchronous communication;gradient descent;distributed computing	HPC	-3.653891265049073	-40.647295849191444	41848
3a70524a98cd0c8e1f9dd160cacf56d613c3832c	learning distributed representations by mapping concepts and relations into a linear space	distributed representation;binary relation;data consistency;linear space	Linear Relational Embedding is a method of learning a distributed representation of concepts from data consisting of binary relations between concepts. Concepts are represented as vectors, binary relations as matrices, and the operation of applying a relation to a concept as a matrix-vector multiplication that produces an approximation to the related concept. A representation for concepts and relations is learned by maximizing an appropriate discriminative goodness function using gradient ascent. On a task involving family relationships, learning is fast and leads to good generalization.	approximation;array data structure;artificial neural network;gradient descent;matrix multiplication;times ascent	Alberto Paccanaro;Geoffrey E. Hinton	2000			combinatorics;discrete mathematics;theoretical computer science;binary relation;mathematics;data consistency;linear space	ML	23.177486966773476	-42.12726952025749	41871
4703af578e4ee7df21d5f705cc95ce286da76be2	efficient classification from multiple heterogeneous databases	extraction information;distributed system;informe costo beneficio;base donnee repartie;base donnee;lien hypertexte;systeme reparti;distributed database;analisis datos;information extraction;enlace hipertexto;heterogeneous databases;database;base repartida dato;base dato;hyperlink;high precision;rapport cout benefice;data mining;classification;data analysis;information transfer;base dato multiple;cost benefit ratio;sistema repartido;federated database;automatic detection;fouille donnee;base donnee federee;precision elevee;decouverte connaissance;multiple database;precision elevada;descubrimiento conocimiento;analyse donnee;base dato federada;information system;busca dato;multibase;clasificacion;extraccion informacion;systeme information;sistema informacion;knowledge discovery	With the fast expansion of computer networks, it is inevitable to study data mining on heterogeneous databases. In this paper we proposeMDBM, an accurate and efficient approach for classification on multiple heterogeneous databases. We propose a regression-based method for predicting the usefulness of inter-database links that serve as bridges for information transfer, because such links are automatically detected and may or may not be useful or even valid. Because of the high cost of inter-database communication, MDBM employs a new strategy for cross-database classification, which finds and performs actions with high benefit-to-cost ratios. The experiments show that MDBM achieves high accuracy in cross-database classification, with much higher efficiency than previous approaches.	data mining;database;experiment;inter-process communication;structure mining;synthetic intelligence	Xiaoxin Yin;Jiawei Han	2005		10.1007/11564126_40	information transfer;biological classification;computer science;cost–benefit analysis;data mining;database;hyperlink;knowledge extraction;data analysis;world wide web;distributed database;information extraction;information system	DB	-3.645808167633439	-33.27604917780199	41919
80e1ea77ed28a46a6be22777af3e57c181cd65b2	badnets: identifying vulnerabilities in the machine learning model supply chain		Deep learning-based techniques have achieved stateof-the-art performance on a wide variety of recognition and classification tasks. However, these networks are typically computationally expensive to train, requiring weeks of computation on many GPUs; as a result, many users outsource the training procedure to the cloud or rely on pre-trained models that are then fine-tuned for a specific task. In this paper we show that outsourced training introduces new security risks: an adversary can create a maliciously trained network (a backdoored neural network, or a BadNet) that has state-of-theart performance on the user’s training and validation samples, but behaves badly on specific attacker-chosen inputs. We first explore the properties of BadNets in a toy example, by creating a backdoored handwritten digit classifier. Next, we demonstrate backdoors in a more realistic scenario by creating a U.S. street sign classifier that identifies stop signs as speed limits when a special sticker is added to the stop sign; we then show in addition that the backdoor in our US street sign detector can persist even if the network is later retrained for another task and cause a drop in accuracy of 25% on average when the backdoor trigger is present. These results demonstrate that backdoors in neural networks are both powerful and—because the behavior of neural networks is difficult to explicate— stealthy. This work provides motivation for further research into techniques for verifying and inspecting neural networks, just as we have developed tools for verifying and debugging	adversary (cryptography);analysis of algorithms;artificial neural network;backdoor (computing);baseline (configuration management);computation;convolutional neural network;debugging;deep learning;graphics processing unit;mnist database;machine learning;outsourcing;verification and validation	Tianyu Gu;Brendan Dolan-Gavitt;Siddharth Garg	2017	CoRR		debugging;artificial neural network;computer security;computer science;adversary;cloud computing;computation;software;deep learning;backdoor;machine learning;artificial intelligence	ML	19.02040763003688	-51.32655502351072	41920
90515d7820f4b4db8aa5ccd5a1abb85d11f3cd8c	map learning and clustering in autonomous systems	heuristic;grouping;clustering algorithm;learning;autonomous system;map exploration;heuristic programming;map clustering;self adjusting systems heuristic programming learning systems pattern recognition;self adjusting systems;discovery;sistema autonomo;map learning;navigation scattering neural networks councils intelligent sensors intelligent actuators battery charge measurement sonar detection random number generation robustness;autonomic system;aprendizaje;learning systems;apprentissage;navigational tasks;systeme autonome;pattern recognition;exploration;self learning systems;agrupamiento;reconnaissance forme;algorithme groupage;heuristic map learning map clustering autonomous systems self learning systems discovery exploration navigational tasks;reconocimiento patron;autonomous systems;exploration carte;groupage	AbstructBuilding autonomous systems, self-learning while moving in an unknown environment, finds a variety of challenging applications. This paper presents a new approach, called clustering by discovery, for identification of clusters in a map which is being learned by exploration. The concomitance of exploration and clustering, we argue, is a mandatory feature for an autonomous system, hence the clustering technique we propose is an incremental process performed while the system is learning the map. Clusters supply an abstract description of the environment and can be used to decrease the complexity of the navigational tasks. The environment is viewed as a map of distinctive places which we assume to be sensed and recognized by the system. The presence of distinctive places and the environment scale are the only facts which we assume known apriori to the system. Clustering by discovery is based on a heuristic indicator called scattering, whose increment is minimized at each exploration step compatibly with a connectivity constraint imposed on clusters. Scattering is defined according to a number of functional and structural requirements. ’ h o variants are presented, and their performance is discussed on a sample of maps including a real urban map and some randomly generated ones. In particular, one of the variants shows robust behaviour in terms of independence of the exploration strategy adopted.	apriori algorithm;autonomous robot;autonomous system (internet);cluster analysis;functional programming;heuristic;map;procedural generation;randomness;requirement	Dario Maio;Stefano Rizzi	1993	IEEE Trans. Pattern Anal. Mach. Intell.	10.1109/34.250846	correlation clustering;constrained clustering;computer vision;simulation;heuristic;autonomous system;exploration;fuzzy clustering;computer science;autonomous system;artificial intelligence;machine learning;pattern recognition;cluster analysis	ML	11.428089446357745	-32.336206184673884	41949
f85c3f8d570bc8408f9bb298e546c0ceff91e741	regularization strategies for hyperplane classifiers: application to cancer classification with gene expression data	diagnostic tool;singular value decomposition;gene expression data;regularization;gene expression;least squares;regression;least square;numerical linear algebra;cancer classification;linear equations;point of view	Linear discrimination, from the point of view of numerical linear algebra, can be treated as solving an ill-posed system of linear equations. In order to generate a solution that is robust in the presence of noise, these problems require regularization. Here, we examine the ill-posedness involved in the linear discrimination of cancer gene expression data with respect to outcome and tumor subclasses. We show that a filter factor representation, based upon Singular Value Decomposition, yields insight into the numerical ill-posedness of the hyperplane-based separation when applied to gene expression data. We also show that this representation yields useful diagnostic tools for guiding the selection of classifier parameters, thus leading to improved performance.	acute lymphocytic leukemia;angular defect;coefficient;dna microarray;detection theory;gene expression;genetic heterogeneity;least squares;least-squares analysis;leukemia, b-cell;linear discriminant analysis;linear equation;matrix regularization;neoplasms;numerical analysis;numerical linear algebra;occam's razor;patients;precursor t-cell lymphoblastic leukemia-lymphoma;simulation;singular value decomposition;statistical classification;subtype (attribute);system of linear equations;well-posed problem;lymphoblast;occam;subclass	Erik Andries;Thomas Hagstrom;Susan R. Atlas;Cheryl Willman	2007	Journal of bioinformatics and computational biology	10.1142/S0219720007002539	system of linear equations;mathematical optimization;combinatorics;machine learning;mathematics;least squares	Comp.	10.682887356982562	-51.279348085982384	41952
f264d343e221e8b11ea8b86dc26bdacced0fef03	discovering critical cases in case-based reasoning	case base reasoning	In this paper, we discuss a method to nd a critical casebase to classify boolean concepts. By a critical casebase we mean that any subset of the casebase cannot represent a concept correctly. This notion is important for reduction of not only the size of casebase but also classi cation speed. In this paper, we consider set-inclusion based similarity which is originated from a legal reasoning system, HYPO [Ashley90, Ashley94]. In HYPO, a case c is more similar to c 1 than c 2 if the set of di erent attributes between c and c 1 is included by the set of di erent attributes between c and c 2 . A case c is regarded as a positive case if there is a positive case such that no negative case is more similar to c than the positive case. In [Satoh98], by using relationship between the above case-based reasoning and monotone theory [Bshouty93, Khardon96], we have shown that we can represent any boolean function f in a casebase which consists of at most jDNF (f )j (1 + jCNF (f)j) cases where jDNF (f)j(jCNF (f )j, respectively) is the size of a minimal DNF(CNF respectively) representation of f . Speci cally, we have shown that a boolean function de ned by a casebase with our similarity measure is a complement of a monotone extension [Bshouty93] such that a set of positive cases in the casebase is called basis in [Bshouty93] and negative cases are assignments in the monotone extension. In this paper, by extending the above results, we rstly give a construction method of a critical casebase if a boolean function is known. Then, we propose an approximation method of nding a critical casebase if a boolean function is unknown and analyze the approximation method in PAC (probably approximately correct) learning framework. In the approximation method, we use not only cases obtained from the domain, but also a membership query which asks the classi cation	approximation algorithm;case-based reasoning;numerical analysis;probably approximately correct learning;reasoning system;similarity measure;station hypo;monotone	Ken Satoh;Ryuichi Nakagawa	2000			knowledge representation and reasoning;opportunistic reasoning;case-based reasoning;abductive reasoning;qualitative reasoning;computer science;artificial intelligence;model-based reasoning;psychology of reasoning;reasoning system;deductive reasoning	AI	-2.024366745428788	-27.801878516698977	41979
4e674e1c3ab333e456cd42ef3318d3b1872f9953	advances in the quotient space theory and its applications	granule computing;fuzzy set;decision tree;data mining;quotient space;rough set	The quotient space theory uses a triplet, including the universe, its structure and attributes, to describe a problem space  or simply a space. This paper improves the quotient space’s model so as to absorb the methods of rough set. It also generalizes  the false-preserving principle and true-preserving principle to the case of probability. Some basic operations on quotient  space are introduced. The significant properties of the fuzzy quotient space family are elaborated. The main applications  of quotient space theory are discussed.  		Li-Quan Zhao;Ling Zhang	2009	IJCINI	10.4018/jcini.2009070104	rough set;quotient space;computer science;machine learning;decision tree;fuzzy set	Theory	-1.2458821020490924	-24.04325849984773	41984
6c41f60ac89ddff36c3213292010340cc01a1d70	theory and application of equal length cycle cellular automata (elcca) for enzyme classification	classification algorithm;elcca equal length cycle cellular automata;enzyme;feature extraction;necessary and sufficient condition;cellular automata;enzyme classification;symbol string analysis	A special class of n cell null boundary invertible three neighborhood CA referred to as Equal Length Cycle CA (ELCCA) is proposed in this paper to represent the features of n bit symbol strings. Necessary and sufficient conditions for generation of ELCCA has been reported. A specific set of ELCCA cycles are selected by employing the mRMR algorithm [2] popularly used for feature extraction of symbol strings. An algorithm is next developed to classify the symbol strings based on the feature set extracted. The proposed CA model has been validated for analyzing symbol string of biomolecules referred to as Enzymes. These biomolecules are classified on the basis of the catalytic reaction they participate. The symbol string classification algorithm predicts the class of any input enzyme with accuracy varying from 90.4% to 98.6%. Experimental results have been reported for 22800 enzymes with wide variation in species.	cellular automaton;enzyme commission number	Soumyabrata Ghosh;Tirthankar Bachhar;Nirmalya Sundar Maiti;Indrajit Mitra;Parimal Pal Chaudhuri	2010		10.1007/978-3-642-15979-4_5	cellular automaton;enzyme;combinatorics;discrete mathematics;feature extraction;computer science;mathematics;algorithm	NLP	10.063048266024657	-52.059168173367354	41989
b71a4d3ab453540cac7a7fac21d807989965bb1b	software defect detection with rocus	姜远 黎铭 周志华 软件缺陷 缺陷检测 机器学习方法 软件模块 软件系统 不平衡 软件测试 自动识别 software defect detection with rocus	Software defect detection aims to automatically identify defective software modules for efficient software test in order to improve the quality of a software system. Although many machine learning methods have been successfully applied to the task, most of them fail to consider two practical yet important issues in software defect detection. First, it is rather difficult to collect a large amount of labeled training data for learning a well-performing model; second, in a software system there are usually much fewer defective modules than defect-free modules, so learning would have to be conducted over an imbalanced data set. In this paper, we address these two practical issues simultaneously by proposing a novel semi-supervised learning approach named Rocus. This method exploits the abundant unlabeled examples to improve the detection accuracy, as well as employs under-sampling to tackle the class-imbalance problem in the learning process. Experimental results of real-world software defect detection tasks show that Rocus is effective for software defect detection. Its performance is better than a semi-supervised learning method that ignores the class-imbalance nature of the task and a class-imbalance learning method that does not make effective use of unlabeled data.	feature vector;iterative method;machine learning;modular programming;randomness;sampling (signal processing);semi-supervised learning;semiconductor industry;software bug;software engineering;software system;software testing;supervised learning	Yuan Jiang;Ming Li;Zhi-Hua Zhou	2011	Journal of Computer Science and Technology	10.1007/s11390-011-9439-0	semi-supervised learning;unsupervised learning;test data generation;computer science;theoretical computer science;online machine learning;machine learning;data mining;database;software testing;active learning;software metric;software system;generalization error	SE	14.920365821915075	-43.92654647904189	41995
a909f33a868867267951ca91db485c731ab5043b	finding boundary shape matching relationships in spatial data	tratamiento datos;methode element frontiere;utilisation information;evaluation performance;base donnee;system approach;representacion espacial;adquisicion del conocimiento;systeme information geographique;boundary element method;performance evaluation;geographic information system;spatial data;metodo elemento frontera;information use;information retrieval;evaluacion prestacion;information technology;donnee spatiale;database;base dato;data processing;traitement donnee;technologie information;acquisition connaissance;algorithme;approche systeme;algorithm;recherche information;shape matching;pattern matching;knowledge acquisition;spatial representation;representation spatiale;recuperacion informacion;concordance forme;enfoque sistemico;tecnologia informacion;utilizacion informacion;sistema informacion geografica;algoritmo;knowledge discovery	This paper considers a new kind of knowledge discovery among spatial objects|namely that of partial boundary shape matching. Our focus is on mining spatial data, whereby many objects called features (represented as polygons) are compared with one or more point sets called clusters. The research described has practical application in such domains as Geographic Information Systems, in which a cluster of points (possibly created by an SQL query) is compared to many natural or man-made features to detect partial or total matches of the facing boundaries of the cluster and feature. We begin by using an alpha-shape to characterize the shape of an arbitrary cluster of points, thus producing a set of edges denoting the cluster's boundary. We then provide an approach for detecting a boundary shape match between the facing curves of the cluster and feature, and show how to quantify the value of the match. Optimizations and experimental results are also provided. We also describe several orientation strategies yielding signiicant performance enhancements. Finally, we show how top-k matches can be computed eeciently.	alpha shape;boundary representation;computer cluster;experiment;geographic information system;openbsm;sql;select (sql);sensor	Edwin M. Knorr;Raymond T. Ng;David L. Shilvock	1997		10.1007/3-540-63238-7_23	boundary element method;data processing;computer science;artificial intelligence;pattern matching;database;spatial analysis;geographic information system;information technology;algorithm	DB	-4.356450796313138	-32.81304130164421	42024
14bdd0ce8bc490757899fa8353b6576b87c9f3e2	multiview feature analysis via structured sparsity and shared subspace discovery		Since combining features from heterogeneous data sources can significantly boost classification performance in many applications, it has attracted much research attention over the past few years. Most of the existing multiview feature analysis approaches separately learn features in each view, ignoring knowledge shared by multiple views. Different views of features may have some intrinsic correlations that might be beneficial to feature learning. Therefore, it is assumed that multiviews share subspaces from which common knowledge can be discovered. In this letter, we propose a new multiview feature learning algorithm, aiming to exploit common features shared by different views. To achieve this goal, we propose a feature learning algorithm in a batch mode, by which the correlations among different views are taken into account. Multiple transformation matrices for different views are simultaneously learned in a joint framework. In this way, our algorithm can exploit potential correlations among views as supplementary information that further improves the performance result. Since the proposed objective function is nonsmooth and difficult to solve directly, we propose an iterative algorithm for effective optimization. Extensive experiments have been conducted on a number of real-world data sets. Experimental results demonstrate superior performance in terms of classification against all the compared approaches. Also, the convergence guarantee has been validated in the experiment.	algorithm;assumed;batch processing;convergence (action);data sources;electronic supplementary materials;experiment;feature learning;genetic heterogeneity;intermediate representation;iterative method;loss function;mathematical optimization;optimization problem;sparse matrix;statistical classification;transformation matrix	Yan-shuo Chang;Feiping Nie;Ming-Yu Wang	2017	Neural Computation	10.1162/NECO_a_00977	artificial intelligence;batch processing;machine learning;linear subspace;pattern recognition (psychology);exploit;subspace topology;common knowledge;pattern recognition;computer science;feature learning	AI	23.68472643525337	-43.756563283807196	42184
d1c305d539310f28e828d1e9bc8dc2433d885dbd	dealing with imbalanced dataset: a re-sampling method based on the improved smote algorithm	imbalanced dataset;secondary 97k80;classification;smote algorithm;re sampling;primary 97;imbalanced data set;mathematical subject classification	Most classification models have presented an imbalanced learning state when dealing with the imbalanced datasets. This article proposes a novel approach for learning from imbalanced datasets, which based on an improved SMOTE (synthetic Minority Over-sampling technique) algorithm. By organically combining the over-sampling and the under-sampling method, this approach aims to choose neighbors targetedly and synthesize samples with different strategy. Experiments show that most classifiers have achieved an ideal performance on the classification problem of the positive and negative class after dealing imbalanced datasets with our algorithm.	algorithm;sampling (signal processing)	Wei Xue;Jing Zhang	2016	Communications in Statistics - Simulation and Computation	10.1080/03610918.2012.728274	biological classification;data mining	EDA	13.885814459616721	-41.516554326163345	42194
fd5e995cc1db8d5a6c647c9300ab69c489c44107	online sequential extreme learning machine with forgetting mechanism	forgetting mechanism;online learning;timeliness;extreme learning machine	The ensemble of online sequential extreme learning machine (EOS-ELM), an average of several online sequential extreme learning machines (OS-ELMs), can learn data one-by-one or chunk-by-chunk with fixed or varying chunk size. EOS-ELM provides higher accuracy with fewer training time, better generalization performance and stability than other popular sequential learning algorithms. However, timeliness, that is, each datum has a period of validity. In order to reflect the timeliness of training data in the process of learning, an improved EOS-ELM, called online sequential extreme learning machine with forgetting mechanism (FOS-ELM), is proposed in this paper. The proposed FOS-ELM cannot only retain the advantages of EOS-ELM, but also improve the learning effects by discarding the outdated data quickly in the process of learning to reduce their bad affection to the following learning. Detailed performance comparisons of FOS-ELM are carried out with EOS-ELM in the stock price short-term predictions. The experimental results show that FOS-ELM has higher accuracy with fewer training time, better stability and short-term predictability than EOS-ELM. & 2012 Elsevier B.V. All rights reserved.	algorithm;eos;elm;geodetic datum;machine learning;operating system	Jianwei Zhao;Zhihui Wang;Dong Sun Park	2012	Neurocomputing	10.1016/j.neucom.2012.02.003	semi-supervised learning;unsupervised learning;multi-task learning;instance-based learning;simulation;computer science;artificial intelligence;online machine learning;machine learning;ensemble learning;stability;computational learning theory;active learning;generalization error	AI	14.705388709124227	-37.75439575640518	42271
4052154bd186f9fe7f860e3621c68220e58ddafb	guaranteed learning algorithm for network with units having periodic threshold output function	learning algorithm	"""Although it has been shown that multiple layer networks can, potentially, approximate any continuous function (Carrol and Dickinson 1989; Cybenko 1989; Funahashi 19891, automated learning of an arbitrary training set has not been demonstrated. Backpropagation algorithms, for example, are prone to local minima problems. This paper will discuss a model for a network unit that can be trained to compute any discrete function : R"""" i {0,1}. That is, given a set of m training pairs {(v,, 61), . . . , (v,,,, b,,,)}, the unit can be configured to output b, whenever v, is the input, where the components of vector v, are in R and b, is in {0,1}."""	approximation algorithm;backpropagation;maxima and minima;test set	Mark J. Brady	1990	Neural Computation	10.1162/neco.1990.2.4.405	mathematical optimization;wake-sleep algorithm;computer science;machine learning;control theory;mathematics;active learning	ML	17.52372737785751	-30.459570161406848	42346
8268a90c4850d1139dbe6fe1bf1924e9570d5ada	novelty detection and in-line learning of novel concepts according to a case-based reasoning process schema for high-content image analysis in system biology and medicine	concept drift;quality improvement method;case base reasoning;memory organization for learning;novelty detection;novelty handling;incremental learning;computerized methods in system biology;outlier handling;system biology;image analysis;case based reasoning;medical diagnosis	Novelty detection, the ability to identify new or unknown situations that were never experienced before, is useful for intelligent systems aspiring to operate in environments where data are acquired incrementally. This characteristic is common to numerous problems in medical diagnosis and visual perception. We propose to see novelty detection as a case-based reasoning process. Our novelty-detection method is able to detect the novel situation as well as to use the novel events for immediate reasoning. To ensure this capacity we combine statistical and similarity inference and learning. This view of CBR takes into account the properties of data such as the uncertainty, and the underlying concepts such as storage, learning, retrieval and indexing can be formalized and performed efficiently.	case-based reasoning;color vision;image analysis;novelty detection;organizing (structure);reasoning system;ron appel;sparse matrix;systems biology	Petra Perner	2009	Computational Intelligence	10.1111/j.1467-8640.2009.00341.x	case-based reasoning;image analysis;computer science;artificial intelligence;concept drift;machine learning;medical diagnosis;data mining	AI	-0.15408730884929642	-30.712858105568387	42397
2a69f4d3dd7a71a8c593e5fd30167febef8365a5	variational autoencoder with implicit optimal priors		The variational autoencoder (VAE) is a powerful generative model that can estimate the probability of a data point by using latent variables. In the VAE, the posterior of the latent variable given the data point is regularized by the prior of the latent variable using Kullback Leibler (KL) divergence. Although the standard Gaussian distribution is usually used for the prior, this simple prior incurs over-regularization. As a sophisticated prior, the aggregated posterior has been introduced, which is the expectation of the posterior over the data distribution. This prior is optimal for the VAE in terms of maximizing the training objective function. However, KL divergence with the aggregated posterior cannot be calculated in a closed form, which prevents us from using this optimal prior. With the proposed method, we introduce the density ratio trick to estimate this KL divergence without modeling the aggregated posterior explicitly. Since the density ratio trick does not work well in high dimensions, we rewrite this KL divergence that contains the high-dimensional density ratio into the sum of the analytically calculable term and the lowdimensional density ratio term, to which the density ratio trick is applied. Experiments on various datasets show that the VAE with this implicit optimal prior achieves high density estimation performance.	autoencoder;calculus of variations;computability;data point;encoder;experiment;explicit modeling;generative model;kl-one;kullback–leibler divergence;latent variable;loss function;optimization problem;rewrite (programming);variational principle	Hiroshi Takahashi;Tomoharu Iwata;Yuki Yamanaka;Masanori Yamada;Satoshi Yagi	2018	CoRR		mathematics;mathematical optimization;autoencoder;kullback–leibler divergence;generative model;prior probability;density estimation;divergence;gaussian;artificial intelligence;latent variable;pattern recognition	ML	23.804367257520973	-32.24862847631513	42398
27129da26f0fda275c798f5c92a160dfbc368f59	mcar: multi-class classification based on association rule	decision tree;t technology general;processor scheduling;large data sets;association rules;data mining;intelligent control;error analysis;qa75 electronic computers computer science;research paper;promotion marketing;transaction databases;association rule;multiclass classification based on association rules;multi class classification;frequent item discovery;pattern classification;rule ranking method large data sets data mining knowledge discovery multiclass classification based on association rules frequent item discovery;error rate;classification tree analysis;rule ranking method;association rules data mining classification tree analysis decision trees processor scheduling intelligent control error analysis marketing and sales transaction databases promotion marketing;decision trees;pattern classification data mining;marketing and sales;knowledge discovery	Summary form only given. Constructing fast, accurate classifiers for large data sets is an important task in data mining and knowledge discovery. In this research paper, a new classification method called multi-class classification based on association rules (MCAR) is presented. MCAR uses an efficient technique for discovering frequent items and employs a rule ranking method which ensures detailed rules with high confidence are part of the classifier. After experimentation with fifteen different data sets, the results indicated that the proposed method is an accurate and efficient classification technique. Furthermore, the classifiers produced are highly competitive with regards to error rate and efficiency, if compared with those generated by popular methods like decision trees, RIPPER and CBA.	association rule learning;c4.5 algorithm;data mining and knowledge discovery;decision tree;missing data;multiclass classification;statistical classification	Fadi A. Thabtah;Peter I. Cowling;Yonghong Peng	2005	The 3rd ACS/IEEE International Conference onComputer Systems and Applications, 2005.	10.1109/AICCSA.2005.1387030	association rule learning;computer science;data science;machine learning;decision tree;pattern recognition;data mining;database;intelligent control	ML	8.357714752609423	-39.16723446744843	42452
27af45c936e7a5d5ac06856a52b47f29347a08ee	completeness and consistency conditions for learning fuzzy rules	machine abstraite;base donnee;learning algorithm;fuzzy rules;logique floue;maquina abstracta;database;base dato;logica difusa;algorithme apprentissage;algoritmo genetico;abstract machine;consistencia;classification problems;fuzzy logic;machine learning;consistance;algorithme genetique;completitud;genetic algorithm;genetic algorithms;feature selection;completeness;classification automatique;automatic classification;completude;algoritmo aprendizaje;clasificacion automatica;consistency	The completeness and consistency conditions were introduced in order to achieve acceptable concept recognition rules. In real problems, we can handle noise-aaected examples and it is not always possible to maintain both conditions. Moreover, when we use fuzzy information there is a partial matching between examples and rules, therefore the consistency condition becomes a matter of degree. In this paper, a learning algorithm based on soft consistency and completeness conditions is proposed. This learning algorithm is tested on diierent databases.	algorithm;database;fuzzy rule;race condition	Antonio González;Raúl Pérez	1998	Fuzzy Sets and Systems	10.1016/S0165-0114(96)00280-1	weak consistency;genetic algorithm;computer science;artificial intelligence;consistency model;machine learning;mathematics;abstract machine;feature selection;sequential consistency;algorithm;local consistency	AI	8.37357912742461	-32.39409205113752	42501
e7050345139408a477aeb9c67b1cb1e7f1dde3a0	margin optimization based pruning for random forest	margin optimization;random forests;ensemble pruning;article	This article introduces a margin optimization based pruning algorithm which is able to reduce the ensemble size and improve the performance of a random forest. A key element of the proposed algorithm is that it directly takes into account the margin distribution of the random forest model on the training set. Four different metrics based on the margin distribution are used to evaluate the ensemble. After a forest is built, the trees in the ensemble are first ranked according to the margin metrics and subensembles with decreasing sizes are then built by recursively removing the least important trees one by one. Experiments on 10 benchmark datasets demonstrate that our proposed algorithm can significantly improve the generalization performance while reducing the ensemble size at the same time. Furthermore, empirical comparison with other pruning methods indicates that the margin distribution plays an important role in evaluating the performance of a random forest, and can be directly used to select the near-optimal subensembles. & 2012 Elsevier B.V. All rights reserved.	adaboost;algorithm;alpha–beta pruning;benchmark (computing);experiment;genetic algorithm;hill climbing;margin (machine learning);mathematical optimization;optimization problem;radio frequency;random forest;recursion;recursion (computer science);semidefinite programming;test set	Fan Yang;Wei-hang Lu;Linkai Luo;Tao Li	2012	Neurocomputing	10.1016/j.neucom.2012.04.007	random forest;margin;computer science;machine learning;pattern recognition;data mining	AI	17.5446286209544	-40.89149893401792	42522
bba14f5b45b5d3e4318eec69847f68863b7f232b	neural network piecewise linear preprocessing for time-series prediction			artificial neural network;piecewise linear continuation;preprocessor;time series	Tommy W. S. Chow;Chi-Tat Leung	1995			artificial neural network;machine learning;artificial intelligence;time series;time delay neural network;pattern recognition;piecewise linear function;computer science;preprocessor	NLP	12.909084755446015	-27.207661230124895	42611
16bff4823e67e606054ea49da54a20f34456e708	a consensus algorithm for simple motifs finding	indexing structures;approximate consensus string search consensus algorithm simple motif finding problem biological macromolecule string coding simple motif search problem smp sms h cca problem pattern search hash table indexing structure;simple motifs;string matching bioinformatics data mining database indexing dna rna;bilogical macromolecules;hash table;consensus strings;approximation algorithms algorithm design and analysis proteins biological information theory time complexity search problems bioinformatics;algorithms;complexities simple motifs indexing structures consensus strings hash table bilogical macromolecules algorithms;complexities	In this paper, we are interested in the problem of finding patterns in strings coding biological macromolecules. We are, particularly, interested in the Simple Motif Search Problem (SMP). We propose a new algorithm to process this problem called SMS_H_CCA, which allows searching the most specific patterns and therefore the most relevant ones to biologists. This algorithm is based on the use of a hash table of patterns as an indexing structure, and the search for the approximate consensus strings. SMS_H_CCA makes use of less time and space than the known algorithms dealing with SMP.	approximation algorithm;chandra–toueg consensus algorithm;computation;dspace;experiment;hash table;relevance;search problem;sequence motif;symmetric multiprocessing;time complexity;word lists by frequency	Tarek El Falah;Maroua Ghnimi;Mourad Elloumi	2014	2014 25th International Workshop on Database and Expert Systems Applications	10.1109/DEXA.2014.24	hash table;computer science;bioinformatics;theoretical computer science;data mining;programming language	DB	-3.0970760857179465	-51.70357628669392	42634
079108ed2845d78de2b89e4e283ea4b8b46c6dac	patrones de sistemas de primero y segundo orden, en un ambiente de instrumentación virtual	prediccion;neuronales;patrones;patterns;neuronal network;virtual;supervision;prediction	This paper presents the analysis of patterns which allow to recognize dynamic models of first and second order systems by means of a backpropagation neuronal network. The neuronal network is of three layers. The input layer has 30 neurons, the hidden layer has 11 neurons and the exit layer has 4 neurons. A circular buffer is used to store the n last acquired values from each variable. The stored data are filtered digitally before executing the neuronal network. The conversion of the sampling frequency does possible to obtain 30 points. The exit of the neuronal network will indicate the most appropriate model. Software is developed using LabVIEW and DLL written in DELPHI and C.	backpropagation;circular buffer;dynamic-link library;embarcadero delphi;labview;multilayer perceptron;sampling (signal processing)	Luis Pastor Sánchez Fernández	2003	Computación y Sistemas		simulation;engineering;artificial intelligence;cartography	ML	11.317653311977695	-28.954292686495336	42656
7bbdd31c4bde8698fde002157a2b7823b030cbbf	rgcli: robust graph that considers labeled instances for semi-supervised learning	k nearest neighbors;label propagation;semi supervised learning;graph construction	"""Graph-based semi-supervised learning (SSL) provides a powerful framework for the modeling of manifold structures in high-dimensional spaces. Additionally, graph representation is effective for the propagation of the few initial labels existing in training data. Graph-based SSL requires robust graphs as input for an accurate data mining task, such as classification. In contrast to most graph construction methods, which ignore the labeled instances available in SSL scenarios, a previous study proposed a graph-construction method, named GBILI, to exploit the informativeness conveyed by such instances available in a semi-supervised classification domain. Here, we have improved the method proposing an optimized algorithm referred to as Robust Graph that Considers Labeled Instances (RGCLI) for the generation of more robust graphs. The contributions of this paper are threefold: i) reduction of GBILI time complexity from quadratic to  <span class=""""formulatext stixSupport mathImg"""" data-mathURL=""""/science?_ob=MathURL&_method=retrieve&_eid=1-s2.0-S0925231216314680&_mathId=si0003.gif&_user=111111111&_pii=S0925231216314680&_rdoc=1&_issn=09252312m ii) demonstration of RGCLI mathematical properties, proving the constructed graph is an optimal graph to model the smoothness assumption of SSL; and iii) evaluation of the efficacy of the proposed approach in a comprehensive semi-supervised classification scenario with several datasets, including an image segmentation task, which needs a large graph to represent the image. Such experiments show the use of labeled vertices in the graph construction process improves the graph topology, hence, the learning task in which it will be employed."""	semi-supervised learning;semiconductor industry;supervised learning	Lilian Berton;Thiago de Paulo Faleiros;Alan Valejo;Jorge Carlos Valverde-Rebaza;Alneu de Andrade Lopes	2017	Neurocomputing	10.1016/j.neucom.2016.11.053	semi-supervised learning;graph power;factor-critical graph;graph bandwidth;null graph;graph property;graph labeling;computer science;clique-width;theoretical computer science;machine learning;pattern recognition;mathematics;voltage graph;distance-hereditary graph;graph;k-nearest neighbors algorithm;complement graph;strength of a graph;statistics;graph rewriting	ML	21.32712529151657	-43.89848632919875	42698
29ed53165bd7f1ea1b2fea6727d9f9776bea0e08	edge-detection method for image processing based on generalized type-2 fuzzy logic	detectors;pragmatics;uncertainty;interval type two fuzzy inference system edge detection method image processing generalized type two fuzzy logic morphological gradient technique defuzzification process approximation methods type one fuzzy inference system;fuzzy reasoning approximation theory edge detection fuzzy logic;fuzzy logic;image edge detection;image edge detection fuzzy logic fuzzy systems uncertainty pragmatics detectors;image processing alpha planes representation edge detection generalized type 2 fuzzy logic;fuzzy systems	This paper presents an edge-detection method that is based on the morphological gradient technique and generalized type-2 fuzzy logic. The theory of alpha planes is used to implement generalized type-2 fuzzy logic for edge detection. For the defuzzification process, the heights and approximation methods are used. Simulation results with a type-1 fuzzy inference system, an interval type-2 fuzzy inference system, and with a generalized type-2 fuzzy inference system for edge detection are presented. The proposed generalized type-2 fuzzy edge-detection method was tested with benchmark images and synthetic images. We used the merit of Pratt measure to illustrate the advantages of using generalized type-2 fuzzy logic.	approximation;benchmark (computing);defuzzification;dhrystone;edge detection;fuzzy logic;image processing;inference engine;knuth–morris–pratt algorithm;morphological gradient;simulation	Patricia Melin;Claudia I. González;Juan R. Castro;Olivia Mendoza;Oscar Castillo	2014	IEEE Transactions on Fuzzy Systems	10.1109/TFUZZ.2013.2297159	fuzzy logic;detector;discrete mathematics;uncertainty;membership function;defuzzification;adaptive neuro fuzzy inference system;fuzzy mathematics;fuzzy classification;computer science;artificial intelligence;fuzzy subalgebra;fuzzy number;neuro-fuzzy;machine learning;fuzzy measure theory;mathematics;fuzzy set;fuzzy associative matrix;fuzzy set operations;algorithm;fuzzy control system;pragmatics	Robotics	0.37308836961369324	-24.51960236144578	42714
06de139bfc771c4dd1708ed5b78ce1bee5db7ccb	learning arithmetic circuits	bayesian network;score function;learning model;context specific independence;graphical model;approximate inference;conditional distribution;arithmetic circuit	Graphical models are usually learned without regard to the cost of doing inference with them. As a result, even if a good model is learned, it may perform poorly at prediction, because it requires approximate inference. We propose an alternative: learning models with a score function that directly penalizes the cost of inference. Specifically, we learn arithmetic circuits with a penalty on the number of edges in the circuit (in which the cost of inference is linear). Our algorithm is equivalent to learning a Bayesian network with context-specific independence by greedily splitting conditional distributions, at each step scoring the candidates by compiling the resulting network into an arithmetic circuit, and using its size as the penalty. We show how this can be done efficiently, without compiling a circuit from scratch for each candidate. Experiments on several real-world domains show that our algorithm is able to learn tractable models with very large treewidth, and yields more accurate predictions than a standard context-specific Bayesian network learner, in far less time.	approximation algorithm;arithmetic circuit complexity;bayesian network;cobham's thesis;compiler;graphical model;greedy algorithm;treewidth	Daniel Lowd;Pedro M. Domingos	2008			conditional probability distribution;fiducial inference;computer science;machine learning;pattern recognition;bayesian network;mathematics;graphical model;score;statistics	ML	24.17414738171	-28.706388540935215	42787
f918b3eac233c5be5b9b247871f0bce9cbae157b	active feature acquisition with supervised matrix completion		Feature missing is a serious problem in many applications, which may lead to low quality of training data and further significantly degrade the learning performance. While feature acquisition usually involves special devices or complex process, it is expensive to acquire all feature values for the whole dataset. On the other hand, features may be correlated with each other, and some values may be recovered from the others. It is thus important to decide which features are most informative for recovering the other features as well as improving the learning performance. In this paper, we try to train an effective classification model with least acquisition cost by jointly performing active feature querying and supervised matrix completion. When completing the feature matrix, a novel objective function is proposed to simultaneously minimize the reconstruction error on observed entries and the supervised loss on training data. When querying the feature value, the most uncertain entry is actively selected based on the variance of previous iterations. In addition, a bi-objective optimization method is presented for cost-aware active selection when features bear different acquisition costs. The effectiveness of the proposed approach is well validated by both theoretical analysis and experimental study.	experiment;ground truth;information;iteration;loss function;mathematical optimization;missing data;objective-c;optimization problem;unified framework	Sheng-Jun Huang;Miao Xu;Ming-Kun Xie;Masashi Sugiyama;Gang Niu;Songcan Chen	2018		10.1145/3219819.3220084	matrix completion;computer science;machine learning;artificial intelligence;active learning;training set;matrix (mathematics)	ML	20.332849175356266	-43.071151178196175	42857
95bc1a485c877d8eb284fb4a71bed59d13914c49	mkl-rt: multiple kernel learning for ratio-trace problems via convex optimization		In the recent past, automatic selection or combination of kernels (or features) based on multiple kernel learning (MKL) approaches has been receiving significant attention from various research communities. Though MKL has been extensively studied in the context of support vector machines (SVM), it is relatively less explored for ratio-trace problems. In this paper, we show that MKL can be formulated as a convex optimization problem for a general class of ratio-trace problems that encompasses many popular algorithms used in various computer vision applications. We also provide an optimization procedure that is guaranteed to converge to the global optimum of the proposed optimization problem. We experimentally demonstrate that the proposed MKL approach, which we refer to as MKL-RT, can be successfully used to select features for discriminative dimensionality reduction and cross-modal retrieval. We also show that the proposed convex MKL-RT approach performs better than the recently proposed non-convex MKL-DR approach.	algorithm;computer vision;converge;convex optimization;dimensionality reduction;experiment;global optimization;kernel (operating system);local-density approximation;math kernel library;mathematical optimization;modal logic;multi-factor authentication;multiple kernel learning;norton power eraser;optimization problem;same-day affirmation;support vector machine;windows rt	Raviteja Vemulapalli;Vinay Praneeth Boda;Rama Chellappa	2014	CoRR		mathematical optimization;machine learning;pattern recognition;mathematics	ML	24.30386863706529	-40.966865333792185	42878
15e0810d3590c355fd234a6cd478022487abdab3	"""erratum to """"distance metric learning by knowledge embedding"""" [pattern recognition 37(1)161-163(2004)]"""	distance metric learning;pattern recognition	The authors would like to draw your attention to the fact that the second author’s name was stated incorrectly in the published version of their paper, and should be Chang Shui Zhang, as stated above. In addition the Abstract should read “This paper presents an algorithm which learns a distance metric from a data set by knowledge embedding and uses the new distance metric to solve nonlinear pattern recognition problems such as clustering.” The Publisher apologises for these errors.	algorithm;cluster analysis;nonlinear system;pattern recognition	Yungang Zhang;Changshui Zhang;David Zhang	2004	Pattern Recognition	10.1016/j.patcog.2003.12.001	topology;computer science;machine learning;pattern recognition	Vision	23.450227977100006	-41.71307904651029	42902
a5fa071c1c39d3596f0277b9e6b539ebe9232f9b	an ensemble classifier based on kernel method for multi-situation dna microarray data	classifier combination;ensemble learning;kernel function;discriminant analysis;classifier;kernel machine;learning methods;subspace method;kernel method;principle component analysis;dna microarray data;support vector machine;dna microarray;classification accuracy;multi situation;high dimension;kernel partial least squares	In order to deal with the interaction between genes effectively, a kernel technology was adopted into a subspace method in our study. A linear subspace classifier was generalized to a nonlinear kernel subspace classifier by using a kernel principle component analysis method to constitute nonlinear feature subspaces. Because DNA microarray data have characteristics of high dimension, few samples and strong nonlinearity, three types of classifiers based on kernel machine learning method were designed, i.e., support vector machine (SVM), kernel subspace classifier (KSUB-C) and kernel partial least-squares discriminant analysis (KPLS-DA). But the performances of these classifiers lie on the optimum setting of kernel functions and parameters. Therefore, to avoid the difficulty of selecting optimal kernel functions and parameters and to further improve the accuracy and generalization property of the classifiers, an ensemble classifier based on kernel method for multi-situation DNA microarray data was proposed by adopting the idea of ensemble learning. The ensemble classifier combines the classification results of the SVM, KSUB-C and KPLS-DA classifiers. Experimental results involving three public DNA microarray datasets indicate that the proposed ensemble classifier has high classification accuracy and perfect generalization property.	dna microarray;ensemble learning;kernel method	Xuesong Wang;Yangyang Gu;Yuhu Cheng;Ruhai Lei	2009		10.1007/978-3-642-04070-2_6	random subspace method;margin classifier;support vector machine;kernel method;kernel fisher discriminant analysis;string kernel;kernel embedding of distributions;radial basis function kernel;quadratic classifier;kernel principal component analysis;computer science;machine learning;linear classifier;pattern recognition;data mining;mathematics;ensemble learning;tree kernel;variable kernel density estimation;polynomial kernel	ML	18.399476438927124	-41.40331130374496	42967
ac1611bbe12f2dc91dad1d1ded3e618b0b848f21	a new approach to fuzzy classifier systems and its application in self-generating neuro-fuzzy systems	neuro fuzzy systems;neural networks;reinforcement learning;performance;classifier system;reinforcement;machine learning;bucket brigade algorithm;neuro fuzzy system;genetic algorithm;learning control network;classifier systems;neural network;fuzzy classifier	A classifier system is a machine learning system that learns syntactically simple string rules (called classifiers) through a genetic algorithm to guide its performance in an arbitrary environment. In a classifier system, the bucket brigade algorithm is used to solve the problem of credit assignment, which is a critical problem in the field of reinforcement learning. In this paper, we propose a new approach to fuzzy classifier systems and a neuro-fuzzy system referred to as ACSNFIS to implement the proposed fuzzy classifier system. The proposed system is tested by the balancing problem of a cart pole and the back-driving problem of a truck to demonstrate its performance. r 2005 Elsevier B.V. All rights reserved.	feasible region;fuzzy control system;genetic algorithm;inference engine;kerrison predictor;learning classifier system;moe;machine learning;national supercomputer centre in sweden;neuro-fuzzy;reinforcement learning;self-organization;simulation;temporal difference learning	Mu-Chun Su;Chien-Hsing Chou;Eugene Lai;Jonathan Lee	2006	Neurocomputing	10.1016/j.neucom.2004.11.033	margin classifier;reinforcement;margin;genetic algorithm;performance;adaptive neuro fuzzy inference system;quadratic classifier;computer science;artificial intelligence;neuro-fuzzy;machine learning;pattern recognition;learning classifier system;artificial neural network	AI	13.24407199940796	-25.788224172476085	43002
29957a1002549333f8c797df619d4b327df7cac7	using the master-slave parallel architecture for genetic-fuzzy data mining	parallel algorithms data mining parallel architectures fuzzy set theory genetic algorithms;fuzzy set;parallel algorithm;fuzzy data;parallel processing master slave parallel architecture genetic fuzzy data mining parallel algorithm association rule membership function quantitative transaction master processor genetic algorithm slave processor evolutionary process fuzzy set;data mining;fuzzy set theory;association rule data mining fuzzy set genetic algorithm parallel processing;transaction data;simple genetic algorithm;parallel architectures;association rule;theoretical analysis;master slave parallel architectures data mining association rules genetic algorithms itemsets genetic mutations production algorithm design and analysis fuzzy set theory;membership function;genetic algorithm;genetic algorithms;parallel architecture;evolutionary process;parallel processing;parallel algorithms;fuzzy association rules	Data mining is most commonly used in attempts to induce association rules from transaction data. In the past, we used the fuzzy and GA concepts to discover both useful fuzzy association rules and suitable membership functions from quantitative values. The evaluation for fitness values was, however, quite time-consuming. In this paper, we thus propose a parallel genetic-fuzzy mining algorithm based on the master-slave architecture to extract both association rules and membership functions from quantitative transactions. The master processor uses a single population as a simple genetic algorithm does, and distributes the tasks of fitness evaluation to slave processors. The evolutionary processes, such as crossover, mutation and production are performed by the master processor. Both the theoretic analysis and the experimental results show that the speed-up of the proposed parallel algorithm can increase nearly linear along with the number of individuals to be evaluated.	association rule learning;central processing unit;crossover (genetic algorithm);data mining;genetic algorithm;in-phase and quadrature components;master/slave (technology);membership function (mathematics);mutation (genetic algorithm);parallel algorithm;parallel computing;software release life cycle;speedup;theory;transaction data	Tzung-Pei Hong;Yeong-Chyi Lee;Min-Thai Wu	2005	2005 IEEE International Conference on Systems, Man and Cybernetics	10.1109/ICSMC.2005.1571644	parallel processing;genetic algorithm;computer science;artificial intelligence;theoretical computer science;machine learning;data mining;parallel algorithm;fuzzy set	HPC	0.9320857145966454	-36.66649867246165	43005
4e027e2e4d722bff258fc7eb58a9142ed8a303b8	adaptive kernel diverse density estimate for multiple instance learning	real-world benchmark mil datasets;adaptive kernel;diverse positive bag;diverse density estimate scheme;mil method;positive bag;diverse density;kernel density estimate;multiple instance learning;negative bag	real-world benchmark mil datasets;adaptive kernel;diverse positive bag;diverse density estimate scheme;mil method;positive bag;diverse density;kernel density estimate;multiple instance learning;negative bag	kernel (operating system);multiple instance learning	Tao Xu;Iker Gondra;David K. Y. Chiu	2011		10.1007/978-3-642-23199-5_14	kernel;kernel density estimation;mathematical optimization;machine learning;pattern recognition;mathematics;variable kernel density estimation	ML	17.887743586376	-41.17504537624316	43083
543309bb12e0511256e5ba8f0e67215fe4690dcf	a hybrid approach based on particle swarm optimization and random forests for e-mail spam filtering		Internet is flooded every day with a huge number of spam emails. This will lead the internet users to spend a lot of time and effort to manage their mailboxes to distinguish between legitimate and spam emails, which can considerably reduce their productivity. Therefore, in the last decade, many researchers and practitioners proposed different approaches in order to increase the effectiveness and safety of spam filtering models. In this paper, we propose a spam filtering approach consisted of two main stages; feature selection and emails classification. In the first step a Particle Swarm Optimization (PSO) based Wrapper Feature Selection is used to select the best representative set of features to reduce the large number of measured features. In the second stage, a Random Forest spam filtering model is developed using the selected features in the first stage. Experimental results on real-world spam data set show the better performance of the proposed method over other five traditional machine learning approaches from the literature. Furthermore, four cost functions are used to evaluate the proposed spam filtering method. The results reveal that the PSO based Wrapper with Random Forest can effectively be used for spam detection.	anti-spam techniques;particle swarm optimization;random forest	Hossam Faris;Ibrahim Aljarah;Bashar Al-Shboul	2016		10.1007/978-3-319-45243-2_46	mathematical optimization;multi-swarm optimization;theoretical computer science;machine learning	Vision	6.188185215585027	-38.47939911563276	43140
938d363a87fa4020fe1e526c439f6f52e66c33c9	formulating face verification with semidefinite programming	reconnaissance visage;similarity metric;evaluation performance;decomposition valeur singuliere;similarity metric matrix face verification semidefinite programming subspace learning techniques;programmation;performance evaluation;semidefinite programming;threshold detection;subspace learning;learning;support vector machines;biometrie;evaluacion prestacion;singular value decomposition;biometrics;projection method;biometria;face verification;metodo subespacio;matrix algebra;similitude;subspace dimension determination;similarity metric matrix;methode sous espace;programacion;algorithme;aprendizaje;subspace learning techniques;algorithm;detection seuil;accuracy;matrix algebra face recognition;apprentissage;deteccion umbral;automatic recognition;precision;face recognition;dimensionality reduction;methode projection;matrix decomposition;principal component analysis;metodo proyeccion;classification algorithms;similarity;pattern recognition;subspace method;threshold determination dimensionality reduction face verification subspace dimension determination;principal component analysis linear discriminant analysis support vector machines automatic programming matrix decomposition singular value decomposition tensile stress eigenvalues and eigenfunctions bayesian methods design methodology;decomposicion valor singular;reconnaissance forme;similitud;reconocimiento patron;dimensional reduction;programming;algorithms artificial intelligence biometry face humans image enhancement image interpretation computer assisted information storage and retrieval pattern recognition automated reproducibility of results sensitivity and specificity;algorithm design and analysis;reconocimiento automatico;threshold determination;reconnaissance automatique;semidefinite program;algoritmo	This paper presents a unified solution to three unsolved problems existing in face verification with subspace learning techniques: selection of verification threshold, automatic determination of subspace dimension, and deducing feature fusing weights. In contrast to previous algorithms which search for the projection matrix directly, our new algorithm investigates a similarity metric matrix (SMM). With a certain verification threshold, this matrix is learned by a semidefinite programming approach, along with the constraints of the kindred pairs with similarity larger than the threshold, and inhomogeneous pairs with similarity smaller than the threshold. Then, the subspace dimension and the feature fusing weights are simultaneously inferred from the singular value decomposition of the derived SMM. In addition, the weighted and tensor extensions are proposed to further improve the algorithmic effectiveness and efficiency, respectively. Essentially, the verification is conducted within an affine subspace in this new algorithm and is, hence, called the affine subspace for verification (ASV). Extensive experiments show that the ASV can achieve encouraging face verification accuracy in comparison to other subspace algorithms, even without the need to explore any parameters.	algorithmic efficiency;automatic differentiation;experiment;inference;large;semidefinite programming;singular value decomposition;spectrometry, mass, matrix-assisted laser desorption-ionization;verification of theories;weight;algorithm	Shuicheng Yan;Jianzhuang Liu;Xiaoou Tang;Thomas S. Huang	2007	IEEE Transactions on Image Processing	10.1109/TIP.2007.906271	mathematical optimization;computer science;machine learning;pattern recognition;mathematics;accuracy and precision;algorithm;statistics;semidefinite programming	Vision	23.804942271844585	-39.41688045038375	43159
786d67e3d84f07b80eb9120745254beb0cd7aa99	planning with ifalcon: towards a neural-network-based bdi agent architecture	agent interaction;supervised learning belief desire intention agent self organizing neural network architecture multichannel network model ifalcon gradient encoding sequences representation hierarchical structures;subspace constraints;computer architecture;artificial neural networks;multi agent systems;computational modeling;adaptation model;self organising feature maps;coalition;neural networks subspace constraints intelligent agent computer architecture intelligent networks service oriented architecture computer networks encoding supervised learning process planning;planning;encoding;self organising feature maps multi agent systems;protocol	This paper presents iFALCON, a model of BDI (belief-desire-intention) agent that is fully realized as a self-organizing neural network architecture. Based on multichannel network model called fusion ART, iFALCON is developed to bridge the gap between a self-organizing neural network that autonomously adapts its knowledge and the BDI agent model that follows explicit descriptions. Novel techniques called gradient encoding are introduced for representing sequences and hierarchical structures to realize plans and the intention structure. This paper shows that a simplified plan representation can be encoded as weighted connections in the neural network through a process of supervised learning. A case study using the blocks world domain shows that an iFALCON agent can also do planning to solve problems when the knowledge is incomplete.	agent architecture;artificial neural network;blocks world;gradient;network architecture;network model;organizing (structure);self-organization;supervised learning	Budhitama Subagdja;Ah-Hwee Tan	2008	2008 IEEE/WIC/ACM International Conference on Web Intelligence and Intelligent Agent Technology	10.1109/WIIAT.2008.29	planning;protocol;computer science;artificial intelligence;machine learning;multi-agent system;data mining;time delay neural network;computational model;artificial neural network;encoding	AI	6.064098115406109	-28.44311953637493	43212
e87b74832b3d4d79228065bf647c12c1d051cd75	a learning approach with under-and over-sampling for imbalanced data sets	under sampling paired t tests parkinson s disease data set minority data set synthetic sample generation majority data set size reduction classification performance learning models imbalanced data sets over sampling;weibull distribution;weibull distribution shape data models information management support vector machines training data testing;sampling methods data reduction diseases learning artificial intelligence medical computing pattern classification;support vector machine imbalance data set synthetic sample generation weibull distribution;synthetic sample generation;support vector machine;imbalance data set	It is difficult for learning models to achieve high classification performance with imbalanced data sets. To conquer the problem, this study presents a strategy involving the reduction of size of majority data set and the generation of synthetic samples of minority data set. Parkinson's disease data set is used to examine and to compare the performance of classification methods. The paired t-tests are also used to show the effectiveness of the proposed method compari.ng with that of the other methods.	algorithm;data mining;experiment;machine learning;oversampling;sampling (signal processing);synthetic data;synthetic intelligence;test set	Chun-Wu Yeh;Der-Chiang Li;Liang-Sian Lin;Tung-I Tsai	2016	2016 5th IIAI International Congress on Advanced Applied Informatics (IIAI-AAI)	10.1109/IIAI-AAI.2016.20	test set;computer science;machine learning;pattern recognition;data mining	ML	13.713810109107968	-42.01517903869825	43220
2c465f435179c6d8ef9a0dc482fa86a7967149b5	cost-sensitive neural network with roc-based moving threshold for imbalanced classification		Pattern classification algorithms usually assume, that the distribution of examples in classes is roughly balanced. However, in many cases one of the classes is dominant in comparison with others. Here, the classifier will become biased towards the majority class. This scenario is known as imbalanced classification. As the minority class is usually the one more valuable, we need to counter the imbalance effect by using one of several dedicated techniques. Cost-sensitive methods assume a penalty factor for misclassifying the minority objects. This way, by assuming a higher cost to minority objects we boost their importance for the classification process. In this paper, we propose a model of cost-sensitive neural network with moving threshold. It relies on scaling the output of the classifier with a given cost function. This way, we adjust our support functions towards the minority class. We propose a novel method for automatically determining the cost, based on the Receiver Operating Characteristic (ROC) curve analysis. It allows us to select the most efficient cost factor for a given dataset. Experimental comparison with state-of-the-art methods for imbalanced classification and backed-up by a statistical analysis prove the effectiveness of our proposal.	artificial neural network	Bartosz Krawczyk;Michal Wozniak	2015		10.1007/978-3-319-24834-9_6	artificial intelligence;pattern recognition;machine learning;computer science;scaling;receiver operating characteristic;factor cost;artificial neural network;statistical classification	ML	13.590000860334708	-41.24102014047371	43266
5930f937eef54229e8e2a1381e2031c2795a8cac	sequential conditional entropy maximization semi-supervised hashing for semantic image retrieval		Hashing has been widely applied to large scale semantic image retrieval. Unsupervised hashing cannot work well for semantic image retrieval while supervised hashing requiring full label information for large databases is not practical. Semi-supervised hashing (SSH) solves this problem by learning the semantic information from a small portion of labeled images and the data structure information from the unlabeled images. The major drawback of the current SSH is that they cannot guarantee the maximization of entropy over all hash bits for a better coding efficiency. We propose a SSH which maximizes the conditional entropy of a bit with respect to all previous bits, i.e. the sequential conditional entropy maximization SSH. It is further extended to a nonlinear SSH with a new mapping method to enhance precision and recall rates. Experimental results show that the nonlinear SSH does not work well for all cases, and a heuristic guideline for the selection between linear and nonlinear hashing is given based on the characteristics of the database. We also propose a multiple hashing version of the proposed method for high recall rate with few hash bucket visits. Experimental results show that the proposed method outperforms current SSH methods.	conditional entropy;entropy maximization;hash function;image retrieval;semi-supervised learning;semiconductor industry	Daniel S. Yeung;Yueming Lv;Ziqian Zeng;Daniel S. Yeung;Patrick P. K. Chan	2017	Int. J. Machine Learning & Cybernetics	10.1007/s13042-015-0350-9	feature hashing;hash table;double hashing;dynamic perfect hashing;open addressing;computer science;universal hashing;pattern recognition;data mining;k-independent hashing;locality preserving hashing;2-choice hashing;information retrieval	AI	20.63891243904605	-47.60466987640463	43306
584c254a866637746781e32fe107c0ac5e8c0139	in pursuit of patterns in data reasoning from data - the rough set way	bayes estimation;analisis datos;bayes theorem;intelligence artificielle;aprendizaje probabilidades;systemy informacyjne;data analysis;estimacion bayes;teoria zbiorow przyblizonych;informatyka;analiza danych;pattern recognition;zbiory przyblizone;apprentissage probabilites;artificial intelligence;analyse donnee;graphe fluence;inteligencia artificial;reconnaissance forme;reconocimiento patron;rough set;twierdzenie bayes a;grafo fluencia;ensemble approximatif;probability learning;teoria prawdopodobienstwa;fluence graph;estimation bayes	This paper concerns some aspects of rough set based data analysis. In particular rough set look on Bayes’ formula leads to new methodology of reasoning from data and shows interesting relationship between Bayes’ theorem, rough sets and flow graphs. Three methods of flow graphs application in drawing conclusions from data are presented and examined. MOTTO: “It is a capital mistake to theorise before one has data” Sherlock Holmes In: A Scandal in Bohemia	algorithm;bayesian programming;decision table;rough set	Zdzislaw Pawlak	2002		10.1007/3-540-45813-1_1	rough set;computer science;artificial intelligence;machine learning;pattern recognition;mathematics;bayes' theorem;data analysis;statistics;dominance-based rough set approach	ML	8.32255501980008	-32.80666936188313	43320
f9b1f9d05605604f236320e6510feceb96983452	a fitting model for feature selection with fuzzy rough sets	rough sets algorithm design and analysis approximation algorithms computational modeling computers search problems fuzzy sets;feature selection dependency function fuzzy rough set fuzzy similarity relation	A fuzzy rough set is an important rough set model used for feature selection. It uses the fuzzy rough dependency as a criterion for feature selection. However, this model can merely maintain a maximal dependency function. It does not fit a given dataset well and cannot ideally describe the differences in sample classification. Therefore, in this study, we introduce a new model for handling this problem. First, we define the fuzzy decision of a sample using the concept of fuzzy neighborhood. Then, a parameterized fuzzy relation is introduced to characterize the fuzzy information granules, using which the fuzzy lower and upper approximations of a decision are reconstructed and a new fuzzy rough set model is introduced. This can guarantee that the membership degree of a sample to its own category reaches the maximal value. Furthermore, this approach can fit a given dataset and effectively prevents samples from being misclassified. Finally, we define the significance measure of a candidate attribute and design a greedy forward algorithm for feature selection. Twelve datasets selected from public data sources are used to compare the proposed algorithm with certain existing algorithms, and the experimental results show that the proposed reduction algorithm is more effective than classical fuzzy rough sets, especially for those datasets for which different categories exhibit a large degree of overlap.	approximation;curve fitting;feature selection;forward algorithm;fuzzy set;greedy algorithm;information privacy;maximal set;rough set;statistical classification	Changzhong Wang;Yali Qi;Ming-Wen Shao;Qinghua Hu;Degang Chen;Yuhua Qian;Yaojin Lin	2017	IEEE Transactions on Fuzzy Systems	10.1109/TFUZZ.2016.2574918	rough set;membership function;defuzzification;fuzzy mathematics;fuzzy classification;computer science;fuzzy number;neuro-fuzzy;machine learning;pattern recognition;fuzzy measure theory;data mining;mathematics;fuzzy set;fuzzy set operations;dominance-based rough set approach	AI	2.65189029526383	-29.924569912735922	43324
107d0f24b62c89979dc076003cc04593463be812	fuzzy perceptron neural networks for classifiers with numerical data and linguistic rules as inputs	second order;fuzzy functions;fuzzy classifiers;learning algorithm;fuzzy neural nets;fuzzy logic pattern classification fuzzy neural nets learning artificial intelligence;fuzzy number;pattern classification learning algorithm fuzzy neural networks fuzzy perceptron linguistic rules if then rules fuzzy classifiers;level set;indexing terms;discriminant function;perceptron learning;fuzzy logic;fuzzy neural networks neural networks fuzzy sets humans level set vectors computational modeling fuzzy set theory fuzzy logic councils;pattern classification;fuzzy if then rules;expert knowledge;learning artificial intelligence;computational efficiency;article;neural network;fuzzy classifier	This paper presents a novel learning algorithm of fuzzy perceptron neural networks (FPNNs) for classifiers that utilize expert knowledge represented by fuzzy IF-THEN rules as well as numerical data as inputs. The conventional linear perceptron network is extended to a second-order one, which is much more flexible for defining a discriminant function. In order to handle fuzzy numbers in neural networks, level sets of fuzzy input vectors are incorporated into perceptron neural learning. At different levels of the input fuzzy numbers, updating the weight vector depends on the minimum of the output of the fuzzy perceptron neural network and the corresponding nonfuzzy target output that indicates the correct class of the fuzzy input vector. This minimum is computed efficiently by employing the modified vertex method to lessen the computational load and the training time required. Moreover, the pocket algorithm, called fuzzy pocket algorithm, is introduced into our fuzzy perceptron learning scheme to solve the nonseparable problems. Simulation results demonstrate the effectiveness of the proposed FPNN model.	algorithm;artificial neural network;computation;discriminant;flow-based programming;fuzzy number;level of measurement;numerical analysis;perceptron;simulation	Jia-Lin Chen;Jyh-Yeong Chang	2000	IEEE Trans. Fuzzy Systems	10.1109/91.890331	fuzzy logic;index term;defuzzification;adaptive neuro fuzzy inference system;fuzzy classification;computer science;artificial intelligence;level set;fuzzy number;neuro-fuzzy;perceptron;machine learning;pattern recognition;data mining;discriminant function analysis;mathematics;fuzzy associative matrix;multilayer perceptron;fuzzy set operations;second-order logic;artificial neural network	ML	6.070283193153387	-27.860447528804507	43391
2a9b4591eacc769c70a91dae097fde1633a88fa8	mining negative generalized knowledge from relational databases	relational data;reduction;discovery;association rules;relational database;data mining;multiple level mining;background knowledge;concept hierarchy;negative pattern;attribute oriented induction;generalized knowledge	Attribute-oriented induction (AOI) is a useful data mining method for extracting generalized knowledge from relational data and users’ background knowledge. Concept hierarchies can be integrated with the AOI method to induce multi-level generalized knowledge. However, the existing AOI approaches are only capable of mining positive knowledge from databases; thus, rare but important negative generalized knowledge that is unknown, unexpected, or contradictory to what the user believes, can be missed. In this study, we propose a global negative attribute-oriented induction (GNAOI) approach that can generate comprehensive and multiple-level negative generalized knowledge at the same time. Two pruning properties, the downward level closure property and the upward superset closure property, are employed to improve the efficiency of the algorithm, and a new interest measure, nim(cl), is exploited to measure the degree of the negative relation. Experiment results from a real-life dataset show that the proposed method is effective in finding global negative generalized knowledge. 2010 Elsevier B.V. All rights reserved.	algorithm;closure (computer programming);data mining;effective method;fuzzy concept;horner's method;real life;relational database;structure mining	Yu-Ying Wu;Yen-Liang Chen;Ray-I Chang	2011	Knowl.-Based Syst.	10.1016/j.knosys.2010.07.013	relational database;computer science;data science;machine learning;data mining;knowledge extraction	AI	-2.935060609877521	-28.817350748286323	43392
1a9a51a42f65b6f69c7e9572e9560ca8d3f4a472	incremental online learning in high dimensions	second order;metodo cuadrado menor;confidence inter val;methode moindre carre;calcul neuronal;neural computation;minimos cuadrados parciales;estimator robustness;high dimensionality;validacion cruzada;least squares method;funcion no lineal;intervalo confianza;complexite calcul;dimension reduction;approximation algorithm;weighting;modele lineaire;partial least square regression;pls regression;non linear function;regression non parametrique;modelo lineal;online learning;ponderacion;partial least squares;statistical regression;interpretacion probabilista;approximation fonction;probabilistic interpretation;reduction dimension;confidence interval;complejidad computacion;robustez estimador;regression pls;analisis regresion;learning methods;incremental learning;interpretation probabiliste;function approximation;locally weighted projection regression;computational complexity;regresion estadistica;intervalle confiance;moindre carre partiel;linear model;validation croisee;algoritmo aproximacion;fonction non lineaire;regression projection;nonparametric regression;analyse regression;regression analysis;cross validation;ponderation;spatial locality;reseau neuronal;algorithme approximation;regression statistique;apprentissage en ligne;high dimension;empirical evaluation;dimensional reduction;article;regresion pls;red neuronal;computacion neuronal;leave one out cross validation;neural network;projection regression;robustesse estimateur	Locally weighted projection regression (LWPR) is a new algorithm for incremental nonlinear function approximation in high-dimensional spaces with redundant and irrelevant input dimensions. At its core, it employs nonparametric regression with locally linear models. In order to stay computationally efficient and numerically robust, each local model performs the regression analysis with a small number of univariate regressions in selected directions in input space in the spirit of partial least squares regression. We discuss when and how local learning techniques can successfully work in high-dimensional spaces and review the various techniques for local dimensionality reduction before finally deriving the LWPR algorithm. The properties of LWPR are that it (1) learns rapidly with second-order learning methods based on incremental training, (2) uses statistically sound stochastic leave-one-out cross validation for learning without the need to memorize training data, (3) adjusts its weighting kernels based on only local information in order to minimize the danger of negative interference of incremental learning, (4) has a computational complexity that is linear in the number of inputs, and (5) can deal with a large number ofpossibly redundantinputs, as shown in various empirical evaluations with up to 90 dimensional data sets. For a probabilistic interpretation, predictive variance and confidence intervals are derived. To our knowledge, LWPR is the first truly incremental spatially localized learning method that can successfully and efficiently operate in very high-dimensional spaces.	algorithm;algorithmic efficiency;approximation;computational complexity theory;confidence intervals;dimensionality reduction;dimensions;disease regression;evaluation;increment;interference (communication);linear model;nonlinear system;numerical analysis;partial least squares regression;projections and predictions;regression analysis;relevance;sample variance;triangulation	Sethu Vijayakumar;Aaron D'Souza;Stefan Schaal	2005	Neural Computation	10.1162/089976605774320557	econometrics;computer science;machine learning;mathematics;partial least squares regression;approximation algorithm;artificial neural network;cross-validation;regression analysis;statistics	ML	12.069514177572136	-30.573774963894394	43466
52596de1d9c2d86b8b327791dda7f76414e51472	riemannian stochastic variance reduced gradient		Stochastic variance reduction algorithms have recently become popular for minimizing the average of a large but finite number of loss functions. In this paper, we propose a novel Riemannian extension of the Euclidean stochastic variance reduced gradient algorithm (R-SVRG) to a manifold search space. The key challenges of averaging, adding, and subtracting multiple gradients are addressed with retraction and vector transport. We present a global convergence analysis of the proposed algorithm with a decay step size and a local convergence rate analysis under a fixed step size under some natural assumptions. The proposed algorithm is applied to problems on the Grassmann manifold, such as principal component analysis, low-rank matrix completion, and computation of the Karcher mean of subspaces, and outperforms the standard Riemannian stochastic gradient descent algorithm in each case.	algorithm;benchmark (computing);computation;local convergence;loss function;manifold regularization;numerical method;principal component analysis;rate of convergence;stochastic gradient descent;time complexity;variance reduction	Hiroyuki Sato;Hiroyuki Kasai;Bamdev Mishra	2017	CoRR		mathematical optimization;matrix completion;manifold;linear subspace;variance reduction;local convergence;frank–wolfe algorithm;principal component analysis;mathematics;stochastic gradient descent	ML	24.44254143888006	-33.79246369973085	43535
9c768cb2bd7b9b9e536feb613a566e756a843be7	an exact feature selection algorithm based on rough set theory	monotonic property;feature selection;rough set;solution tree	Feature reduction based on rough set theory is an effective feature selection method in pattern recognition applications. Finding a minimal subset of the original features is inherent in rough set approach to feature selection. As feature reduction is a Nondeterministic Polynomial-time-hard problem, it is necessary to develop fast optimal or nearoptimal feature selection algorithms. This article aims to propose an exact feature selection algorithm in rough set that is efficient in terms of computation time. The proposed algorithm begins the examination of a solution tree by a breadth-first strategy. The pruned nodes are held in a version of the trie data structure. Based on the monotonic property of dependency degree, all subsets of the pruned nodes cannot be optimal solutions. Thus, by detecting these subsets in trie, it is not necessary to calculate their dependency degree. The search on the tree continues until the optimal solution is found. This algorithm is improved by selecting an initial search level determined by the hillclimbing method instead of searching the tree from the level below the root. The length of the minimal reduct and the size of data set can influence which starting search level is more efficient. The experimental results using some of the standard UCI data sets, demonstrate that the proposed algorithm is effective and efficient for data sets with more than 30 features. VC 2014 Wiley Periodicals, Inc. Complexity 20: 50–62, 2015	breadth-first search;computation;data structure;feature selection;john d. wiley;np (complexity);pattern recognition;polynomial;rough set;selection algorithm;sensor;set theory;time complexity;trie	Mohammad Taghi Rezvan;Ali Zeinal Hamadani;Seyed Reza Hejazi	2015	Complexity	10.1002/cplx.21526	rough set;computer science;machine learning;pattern recognition;data mining;mathematics;feature selection;feature	AI	-4.32706666803212	-36.72305540229675	43541
8443fa5010f99eeeb8ce3509b1a27abfb48012e5	a signal detection system based on dempster-shafer theory and comparison to fuzzy detection	piecewise linear;probability;piecewise linear techniques;bayes methods;signal detection;mathematical operations signal detection algorithm dempster shafer theory multiple waveform features uncertainty detection decision waveform classification signal probability numbers piecewise linear function detector performance simulated data bayesian detection fuzzy signal detector;uncertainty handling;indexing terms;fuzzy logic;piecewise linear techniques signal detection information theory fuzzy logic bayes methods uncertainty handling probability;dempster shafer theory;dempster shafer;signal detection fuzzy systems detectors uncertainty bayesian methods fuzzy logic piecewise linear techniques error correction testing;information theory	This paper describes a signal detection algorithm based on Dempster-Shafer theory. The detector combines evidence provided by multiple waveform features and explicitly considers uncertainty in the detection decision. The detector classifies waveforms as including a signal, not including a signal, or being uncertain, in which case no conclusion regarding presence or absence of a signal is drawn. The probability numbers required in the Dempster-Shafer formulation are defined as piecewise linear functions that can be described by two parameters, and the effects of these parameters on detector performance, using simulated data, are compared to Bayesian detection and to a fuzzy signal detector that also considers uncertainty. The performance of the Dempster-Shafer and fuzzy detectors shows similar dependence on the parameters, although, if parameters are adjusted so that the number of correctly classified waveforms are equal, the Dempster-Shafer detector has more uncertain classifications and fewer errors than the fuzzy detector, providing superior performance. The Dempster-Shafer detector incorporates a different type of uncertainty than the fuzzy detector, which may contribute to this difference in performance. The difference may also reflect the different mathematical operations used.	detection theory	J. Robert Boston	2000	IEEE Trans. Systems, Man, and Cybernetics, Part C	10.1109/5326.827453	dempster–shafer theory;information theory;fuzzy number;machine learning;pattern recognition;mathematics;statistics	Embedded	-0.46912150348463505	-28.083000041741876	43548
593df085169b6c93af4dbac1208ca83809efd20c	newcastle disease virus clustering based on swarm rapid centroid estimation		Newcastle disease is considered to be one of the most important serious infectious poultry disease. The work introduced in this paper addresses the problem of clustering Newcastle disease dataset obtained from the National Center for Biotechnology Information GenBank (NCBI). A lightweight swarm clustering algorithm called Rapid Centroid Estimation (RCE) is applied in the clustering task. However, the best number of clusters is selected using silhouette measure. Hence, RCE is compared with K-means for the same number of clusters. The experiment shows that the external quality measures (purity, entropy, rand index, precision, recall and F-measure) of the RCE clustering technique outperform the ones of the K-means.		Fatma Helmy Ismail;Ahmed Fouad Ali;Saleh Esmat;Aboul Ella Hassanien	2015		10.1007/978-3-319-27400-3_32	mathematical optimization;statistics	ML	3.895178761888257	-42.89469389149675	43552
3397ca2e0ceae6e3b8c0808e827af482f6f3a0ea	constructing phylogenetic networks from trees	phylogeny transmission line matrix methods tree graphs network topology event detection computer science matrix decomposition bioinformatics biomedical engineering;biology computing;evolution biological;phylogenetic network;botany evolution biological biology computing;phylogenetic tree;botany phylogenetic networks phylogenetic tree recombination cycles decreasing distance deviation;botany	We present a new method of constructing a phylogenetic network from a given phylogenetic tree. It is based on a procedure that locally improves the tree. The procedure is quite general and can be applied to phylogenetic networks. By repeating local improvements user can introduce a given number of recombination cycles. A sequence of networks with decreasing distance deviation can be generated. The algorithm is efficient and shows a good performance on an example with plants. This is due to the fact that the update in every step is local and optimal.	algorithm;phylogenetic network;phylogenetic tree;phylogenetics	Sergey Bereg;Kathryn Bean	2005	Fifth IEEE Symposium on Bioinformatics and Bioengineering (BIBE'05)	10.1109/BIBE.2005.19	biology;zoology;phylogenetic tree;bioinformatics;computational phylogenetics;tree rearrangement;phylogenetic network	Theory	1.0917251633543892	-50.5284988535415	43554
5d6d8399c4f29f0cfb7c68920f70b220e8dd6e1a	ensemble clustering in the belief functions framework	distributed system;consensus;belief;systeme reparti;intervals of partitions;belief function;belief functions;intelligence artificielle;ensemble clustering;lattice of partitions;enrejado;sistema repartido;croyance;treillis;clustering;consenso;artificial intelligence;inteligencia artificial;creencia;lattice	In this paper, belief functions, defined on the lattice of intervals partitions of a set of objects, are investigated as a suitable framework for combining multiple clusterings. We first show how to represent clustering results as masses of evidence allocated to sets of partitions. Then a consensus belief function is obtained using a suitable combination rule. Tools for synthesizing the results are also proposed. The approach is illustrated using synthetic and real data sets.	arm cortex-m;cluster analysis;experiment;focal (programming language);feature vector;inverted index;pollard's rho algorithm for logarithms;rp (complexity);sampling (signal processing);state space;stellar classification;synthetic intelligence;transitive closure;unsupervised learning	Marie-Hélène Masson;Thierry Denoeux	2011	Int. J. Approx. Reasoning	10.1016/j.ijar.2010.04.007	consensus;computer science;artificial intelligence;belief;machine learning;lattice;data mining;mathematics;cluster analysis	ML	7.394954446647332	-34.38361183488412	43568
2de2eba5607976d867e797d88313e8f8e6d18776	input selection for nonlinear regression models	regression models;principal component analysis nonlinear systems fuzzy systems clustering algorithms system identification delay effects autocorrelation linear regression testing control engineering education;noisy data;regression model;indexing terms;fuzzy set theory;input output;fuzzy modeling;fuzzy clustering;similarity measure input selection nonlinear regression model fuzzy clustering;data models regression analysis fuzzy set theory;similarity measures;input selection;regression analysis;similarity measure;fuzzy model;nonlinear regression;data models	A simple and effective method for the selection of significant inputs in nonlinear regression models is proposed. Given a set of input-output data and an initial superset of potential inputs, the relevant inputs are selected by checking whether after deleting a particular input, the data set is still consistent with the basic property of a function. In order to be able to handle real-valued and noisy data in a sensible manner, fuzzy clustering is first applied. The obtained clusters are compared by using a similarity measure in order to find inconsistencies within the data. Several examples using simulated and real-world data sets are presented to demonstrate the effectiveness of the algorithm.	algorithm;autoregressive model;cluster analysis;coefficient;computation;decision tree;effective method;feature selection;finite impulse response;fuzzy clustering;fuzzy cognitive map;input/output;mutual exclusion;nonlinear autoregressive exogenous model;nonlinear system;scott continuity;signal-to-noise ratio;similarity measure;simulation	Radek Sindelár;Robert Babuska	2004	IEEE Transactions on Fuzzy Systems	10.1109/TFUZZ.2004.834810	computer science;machine learning;pattern recognition;mathematics;regression analysis;statistics	DB	5.446440835972662	-26.134070006060224	43605
e727c46cd004c7d2b201a54f3000e49ec89c61ee	ilpc: iterative learning using physical constraints in real-world sensing data		In this paper, we present Iterative Learning using Physical Constraints (ILPC) method. ILPC is an iterative learning method targeting at model inaccuracy caused by a distribution change in training and test data. This change in distribution can be due to the complexity of many real-world physical systems. Although domain adaptation methods, which consider both training and test data distribution when building models, also target this distribution change, these methods can only handle a limited difference between training and test data. ILPC handles different distributions based on a key observation: gradual changes in physical condition often cause gradual data distribution changes. Instead of treating test data as generated by an identical distribution, ILPC builds a model iteratively, guided by a system’s physical measurements. In each iteration, the model is only extended with data that has similar physical measurements to the last iteration. This approach leads to higher accuracy. To evaluate ILPC, we apply it to two real-world datasets and achieve up to a 2.7× improvement in prediction accuracy compared to existing domain adaptation	domain adaptation;ibm notes;iteration;test data;turing test	Tong Yu;Shijia Pan;Susu Xu;Xinlei Chen;Mostafa Mirshekari;Jonathon Fagert;Hae Young Noh;Pei Zhang;Ole J. Mengshoel	2018			artificial intelligence;iterative learning control;machine learning;computer science	AI	19.691124255158407	-41.268869122364535	43614
0fe30a2722b469719acd3d8c579d2909a1058b5a	on applying probabilistic logic programming to breast cancer data		Medical data is particularly interesting as a subject for relational data mining due to the complex interactions which exist between different entities. Furthermore, the ambiguity of medical imaging causes interpretation to be complex and error-prone, and thus particularly amenable to improvement through automated decision support. Probabilistic Inductive Logic Programming (PILP) is a particularly well-suited tool for this task, since it makes it possible to combine the relational nature of this field with the ambiguity inherent in human interpretation of medical imaging. This work presents a PILP setting for breast cancer data, where several clinical and demographic variables were collected retrospectively, and new probabilistic variables and rules reflecting domain knowledge were introduced. A PILP predictive model was built automatically from this data and experiments show that it can not only match the predictions of a team of experts in the area, but also consistently reduce the error rate of malignancy prediction, when compared to other non-relational techniques.	logic programming	Joana Côrte-Real;Inês de Castro Dutra;Ricardo Rocha	2017		10.1007/978-3-319-78090-0_3	artificial intelligence;machine learning;relational data mining;probabilistic logic;word error rate;ambiguity;decision support system;domain knowledge;medical imaging;inductive logic programming;computer science	ML	5.493097094910857	-45.095970445888206	43630
7127aefba81475a96b1cb36c22fbd7d6ba2fcd96	a new pruning algorithm for neural network dimension analysis	neural network application;generalization capacity;neural networks;network dimension;selected works;neural nets;joints;neural network dimension analysis;artificial neural networks;pruning algorithm;computational complexity;sensitivity analysis;pattern classification pruning algorithm neural network dimension analysis network dimension optimal neural network topology computational complexity generalization capacity cross validation sensitivity analysis;sensitivity analysis computational complexity generalisation artificial intelligence neural nets pattern classification;optimal neural network topology;artificial neural networks joints;pattern classification;network dimensioning;bepress;cross validation;generalisation artificial intelligence;computer simulation;algorithm design and analysis;neural network	The choice of network dimension is a fundamental issue in neural network applications. An optimal neural network topology not only reduces the computational complexity, but also improves its generalization capacity. In this research, a new pruning algorithm based on cross validation and sensitivity analysis is developed and compared with three existing pruning algorithms on various pattern classification problems. Computer simulation results show the network size can be significantly reduced using this new algorithm while the neural network still maintains satisfactory generalization accuracy.	algorithm;artificial neural network;computational complexity theory;computer simulation;cross-validation (statistics);network topology;pruning (morphology)	Devin Sabo;Xiao-Hua Yu	2008	2008 IEEE International Joint Conference on Neural Networks (IEEE World Congress on Computational Intelligence)	10.1109/IJCNN.2008.4634268	algorithm design;probabilistic neural network;computer science;artificial intelligence;machine learning;pattern recognition;computational complexity theory;sensitivity analysis;artificial neural network;cross-validation;pruning	Vision	13.795826811798472	-31.598024612280454	43709
6e404e76bac444cd88f9df89460e118d139b2e61	a graph-based elastic net for variable selection and module identification for genomic data analysis	graph theory;genomics;optimisation;microarray gene expression;conference_paper;module identification;efficient algorithm;laplacian graph;regression model;kyoto encyclopedia of genes and genomes transcriptional pathways;sparse;equations mathematical model laplace equations bioinformatics genomics optimization;pathway;genetics;medical computing;elastic net;optimization problem;gene expression;variable selection;data analysis;network constrained regularization;laplace equations;graph based elastic net;pathway laplacian graph elastic net;kyoto encyclopedia of genes and genomes transcriptional pathways graph based elastic net variable selection module identification genomic data analysis network constraint regression model l 1 norm sparse laplacian operation laplacian smoothness optimization network constrained regularization alzheimer disease microarray gene expression;network constraint regression model;sparse matrices cellular biophysics diseases genomics graph theory medical computing molecular biophysics optimisation regression analysis;molecular biophysics;laplacian smoothness;mathematical model;diseases;simulation study;l 1 norm;regression analysis;optimization;alzheimer disease;cellular biophysics;sparse matrices;laplacian operation;genomic data analysis;kyoto encyclopedia of genes and genomes;bioinformatics	Recently a network-constraint regression model[1] is proposed to incorporate the prior biological knowledge to perform regression and variable selection. In their method, a l1-norm of the coefficients is defined to impose sparse, meanwhile a Laplacian operation on the biological graph is designed to encourage smoothness of the coefficients along the network. However the grouping effect of their Laplacian smoothness operation only exits when the two connected genes both have positive or negative effects on the response. To overcome this problem, we proposed to apply the Laplacian operation on the absolute values of the coefficients to take account of the positive and negative effects. Here, we call the presented method as graph-based elastic net (GENet) because the proposed method has similar grouping effect with elastic net(ENet)[2] except the smoothness of two coefficients are specified by the network in GENet. Further, an efficient algorithm which has same spirit with LARS [3] is developed to solve our optimization problem. Simulation studies showed that the proposed method has better performance than network-constrained regularization without absolute values. Application to Alzheimer's disease(AD) microarray gene-expression dataset identified several subnetworks on Kyoto Encyclopedia of Genes and Genomes(KEGG) transcriptional pathways that are related to progression of AD. Many of those findings are confirmed by published literatures.		Zheng Xia;Xiaobo Zhou;Wei Chen;Chunqi Chang	2010	2010 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)	10.1109/BIBM.2010.5706591	mathematical optimization;genomics;computer science;bioinformatics;graph theory;machine learning;data mining;mathematics;genetics;regression analysis;statistics;molecular biophysics	Robotics	8.098856824137735	-51.62806477889794	43736
18fd60fc31494e752999e16c05c0494037e7a88f	the design of polynomial function-based neural network predictors for detection of software defects	neural networks;imbalanced data;software defect;fuzzy clustering;pattern classification;two class discrimination	In this study, we introduce a design methodology of polynomial function-based Neural Network (pf-NN) classifiers (predictors). The essential design components include Fuzzy C-Means (FCM) regarded as a generic clustering algorithm and polynomials providing all required nonlinear capabilities of the model. The learning method uses a weighted cost function (objective function) while to analyze the performance of the system we engage a standard receiver operating characteristics (ROC) analysis. The proposed networks are used to detect software defects. From the conceptual standpoint, the classifier of this form can be expressed as a collection of ''if-then'' rules. Fuzzy clustering (Fuzzy C-Means, FCM) is aimed at the development of premise layer of the rules while the corresponding consequences of the rules are formed by some local polynomials. A detailed learning algorithm for the pf-NNs is presented with particular provisions made for dealing with imbalanced classes encountered quite commonly in software quality problems. The use of simple measures such as accuracy of classification becomes questionable. In the assessment of quality of classifiers, we confine ourselves to the use of the area under curve (AUC) in the receiver operating characteristics (ROCs) analysis. AUC comes as a sound classifier metric capturing a tradeoff between the high true positive rate (TP) and the low false positive rate (FP). The performance of the proposed classifier is contrasted with the results produced by some ''standard'' Radial Basis Function (RBF) neural networks.	artificial neural network;polynomial;software bug	Byoung-Jun Park;Sung-Kwun Oh;Witold Pedrycz	2013	Inf. Sci.	10.1016/j.ins.2011.01.026	software bug;fuzzy clustering;computer science;artificial intelligence;machine learning;pattern recognition;data mining;artificial neural network;algorithm;statistics	Logic	10.430036103543468	-37.66098700652645	43779
305be32e5ba359feba7cc8247c669716c12da725	bimodal biometrics based on a two-stage test sample representation	biometrics;face recognition;linear representation	Bimodal biometrics based on a two-stage test sample representation method for use with face recognition is presented in this paper. Until now a large amount of research has been proved that multi-biometrics can outperform single biometrics. The proposed method first let the test sample be linearly constructed from all the training samples each with a complex vector. By this step we find k 'nearest neighbors' for the test sample. Then we re-expressed the test sample as a linear combination of the k samples obtained above and classify the test sample into the class that makes the greatest contribution. The experimental results on CSIST and AR face image database demonstrate the efficiency and effectiveness of our method.	biometrics	Yu Hou;Caikou Chen	2012		10.1007/978-3-642-33478-8_88	facial recognition system;computer science;machine learning;pattern recognition;mathematics;biometrics;statistics	NLP	23.977584216823992	-41.35724843085687	43802
f672e0f19089152cb38e7bab69b60683b04c37df	bayesian biomarker discovery for rnaseq data		RNAseq has become a popular technology for biomarker discovery. However, in many applications, such as single cell sequencing, zero counts comprise a considerable portion of data. Here we propose a new RNAseq model that explicitly models zero counts and solve a previously proposed feature selection framework, called Optimal Bayesian Filter (OBF), for this model and find the posterior probability of a feature having distributional differences across classes. As the posterior does not exist in closed form, we propose Sequence Approximation OBF (SA-OBF) as a closed form approximation which is based on log transformations of non-zero reads. We use SA-OBF to study two breast cancer RNAseq datasets.	approximation;bayesian network;feature selection;open bioinformatics foundation	Ali Foroughi Pour;Lori A. Dalton	2018		10.1145/3233547.3233693	single cell sequencing;bioinformatics;feature selection;posterior probability;biomarker discovery;bayesian probability;computer science	ML	16.468568092646777	-36.31360290218588	43843
e014be15a4b885b742801adfc46b5a9722ae26ad	fixed points of split quaternionic hopfield neural networks	rotational invariance;quaternion;hopfield neural network;fixed point;split activation function	In a complex-valued phasor Hopfield neural network with a training pattern, only the rotated patterns are fixed points, while in a complex-valued  K -state Hopfield neural network, there exist  K  fixed points. In the case of a quaternionic Hopfield neural network (QHNN) with a continuous activation function, again only the rotated patterns are fixed points. We consider a QHNN with a split activation function, which is a 16-state activation function. This type of QHNN is referred to as a split QHNN (SQHNN). It is expected to have 16 fixed points, all of which are global minima. The rate at which the training pattern would be recalled from random initial states would thus be expected to be 1/16. However, the rate was higher in our computer simulations. We investigate the reasons for this discrepancy.	artificial neural network;hopfield network	Masaki Kobayashi	2017	Signal Processing	10.1016/j.sigpro.2016.11.020	mathematical optimization;combinatorics;discrete mathematics;rotational invariance;mathematics;fixed point;hopfield network;quaternion	ML	17.609878441322206	-29.019513322638257	43844
1ad3ceca6a0c258f5ad1397f85e70b047ec8e4f6	experiences of using a quantitative approach for mining association rules	extraction information;base donnee;learning;information extraction;aumentacion;examination;control conocimientos;industrialization;database;base dato;intelligence artificielle;augmentation;data mining;industrializacion;scaling up;aprendizaje;apprentissage;controle connaissance;regle association;regla asociacion;association rule;fouille donnee;increase;decouverte connaissance;estructura datos;artificial intelligence;descubrimiento conocimiento;structure donnee;knowledge discovery in database;inteligencia artificial;data structure;busca dato;extraccion informacion;industrialisation;knowledge discovery	In recent years interest has grown in “mining” large databases to extract novel and interesting information. Knowledge Discovery in Databases (KDD) has been recognised as an emerging research area. Association rules discovery is an important KDD technique for better data understanding. This paper proposes an enhancement with a memory efficient data structure of a quantitative approach to mine association rules from data. The best features of the three algorithms (the Quantitative Approach, DHP, and Apriori) were combined to constitute our proposed approach. The obtained results accurately reflected knowledge hidden in the datasets under examination. Scale-up experiments indicated that the proposed algorithm scales linearly as the size of the dataset increases.	apriori algorithm;association rule learning;data mining;data structure;database;experiment	Limin Dong;Christos Tjortjis	2003		10.1007/978-3-540-45080-1_93	data structure;computer science;artificial intelligence;data science;data mining;industrialisation;information extraction	ML	-2.843102278175716	-33.27139854777735	43850
98d74d42553e0184bc7f38790bee5d2866adf7b2	different aspects of clustering the self-organizing maps	topological organization;ahc;k means;graph coloring;som	Self-organizing map (SOM) is an artificial neural network tool that is trained using unsupervised learning to produce a low dimensional representation of the input space, called a map. This map is generally the object of a clustering analysis step which aims to partition the referents vectors (map neurons) into compact and well-separated groups. In this paper, we consider the problem of the clustering SOM using different aspects: partitioning, hierarchical and graph coloring based techniques. Unlike the traditional clustering SOM techniques, which use k-means or hierarchical clustering, the graph-based approaches have the advantage of providing a partitioning of the SOM by simultaneously using dissimilarities and neighborhood relations provided by the map. We present the experimental results of several comparisons between these different ways of clustering.	artificial neural network;cladogram;cluster analysis;experiment;graph coloring;hierarchical clustering;k-means clustering;organizing (structure);self-organizing map;unsupervised learning	Haytham Elghazel;Khalid Benabdeslem	2013	Neural Processing Letters	10.1007/s11063-013-9292-y	correlation clustering;combinatorics;data stream clustering;fuzzy clustering;computer science;artificial intelligence;canopy clustering algorithm;machine learning;consensus clustering;cure data clustering algorithm;graph coloring;mathematics;cluster analysis;single-linkage clustering;brown clustering;k-means clustering;conceptual clustering	ML	1.9748854392398079	-41.973677500907655	43861
6c0b53ab8199b773e63821a0e31b31588f3b4c77	no bad local minima: data independent training error guarantees for multilayer neural networks		We use smoothed analysis techniques to provide guarantees o n the training loss of Multilayer Neural Networks (MNNs) at differentiable local minima. Specifically, we examine MNNs with piecewise linear activation functions , quadratic loss and a single output, under mild over-parametrization. We prove t hat for a MNN with one hidden layer, the training error is zero at every differenti able local minimum, for almost every dataset and dropout-like noise realization. W e then extend these results to the case of more than one hidden layer. Our theoretic al guarantees assume essentially nothing on the training data, and are verified nu merically. These results suggest why the highly non-convex loss of such MNNs can be eas ily optimized using local updates (e.g., stochastic gradient descent), a s observed empirically.	activation function;dropout (neural networks);maxima and minima;multilayer perceptron;neural networks;piecewise linear continuation;smoothed analysis;smoothing;stochastic gradient descent;theory	Daniel Soudry;Yair Carmon	2016	CoRR		mathematical optimization;machine learning;mathematics;algorithm	ML	21.689118793665457	-32.526139010213015	43862
f0fb77521e8dafdfadde01b47b2ea83bf49798b3	a direct search algorithm based on kernel density estimator for nonlinear optimization	search problems estimation theory nonlinear programming;ascent direction direct search algorithm kernel density estimator nonlinear optimization problems objective function;kernel linear programming optimization search problems signal processing algorithms approximation algorithms bandwidth	In this paper, we propose a direct search algorithm based on kernel density estimator for the nonlinear optimization problems. It estimates the objective function by the kernel density estimator with the local samples only, and then approximates the ascent direction of the objective function with the one of the estimator. The proposed optimization approach features the derivative-free with much likely generating an ascent direction. We not only theoretically show that the search direction, which is used in the proposed algorithm towards maximizing the objective function, is the ascent direction of the objective function, but also empirically investigate the effectiveness of the search direction.	approximation algorithm;derivative-free optimization;descent direction;kernel (operating system);kernel density estimation;mathematical optimization;nonlinear programming;nonlinear system;optimization problem;search algorithm;times ascent	Yiu-ming Cheung;Fangqing Gu	2014	2014 10th International Conference on Natural Computation (ICNC)	10.1109/ICNC.2014.6975851	beam search;econometrics;mathematical optimization;kernel embedding of distributions;radial basis function kernel;criss-cross algorithm;nonlinear programming;machine learning;mathematics;variable kernel density estimation;metaheuristic;search algorithm	Robotics	23.738581447949805	-35.06905805608338	43864
3d013d2ceb1089eca3ca69b6fd265eaed5d0c303	exploiting network structure for active inference in collective classification	database indexing;inference mechanisms;pattern classification;relational databases;active inference;collective classification;network structure indexing;relational data	Active inference seeks to maximize classification performance while minimizing the amount of data that must be labeled ex ante. This task is particularly relevant in the context of relational data, where statistical dependencies among instances can be exploited to improve classification accuracy. We show that efficient methods for indexing network structure can be exploited to select high-value nodes for labeling. This approach substantially outperforms random selection and selection based on simple measures of local structure. We demonstrate the relative effectiveness of this selection approach through experiments with a relational neighbor classifier on a variety of real and synthetic data sets, and identify the necessary characteristics of the data set that allow this approach to perform well.	experiment;free energy principle;synthetic data	Matthew J. Rattigan;Marc E. Maier;David D. Jensen;Bin Wu;Xin Pei;Jianbin Tan;Yi Wang	2007	Seventh IEEE International Conference on Data Mining Workshops (ICDMW 2007)	10.1109/ICDMW.2007.124	data mining;machine learning;relational database;sampling (statistics);search engine indexing;inference;database index;pattern recognition;indexation;synthetic data;artificial intelligence;computer science	DB	-1.7366569341884108	-42.703375938199386	44000
617e215cad07a6b00dddec20586f8a62a50a1593	representation and recognition of regular grammars by means of second-order recurrent neural networks	second order;linear system of equations;linear approximation;regular language;satisfiability;neural net;recurrent network;finite state automaton;grammatical inference;recurrent neural network;neural network	Recently, some models of neural networks, recurrent neural networks, have been used in conjunction with their associated neural learning schemes to infer regular grammars from a set of sample strings. The representation of the inferred automata is hidden in the weights and connections of the net, this being a common feature in emergent subsymbolic representations. In order to relate the symbolic and connectionist approaches to the tasks of grammatical inference and recognition, we address and solve a basic problem, which is, how to build a neural net recognizer for a given regular language specified by a deterministic finite-state automaton. A second-order recurrent network model is employed, which allows to formulate the problem as one of solving a linear system of equations. These equations directly represent the automaton transitions in terms of static linear approximations of the network running equations, and can be viewed as constraints to be satisfied by the network weights. A description is given both for the weight computation step and the string recognition procedure.	neural networks;recurrent neural network	René Alquézar;Alberto Sanfeliu	1993		10.1007/3-540-56798-4_138	stochastic neural network;system of linear equations;feedforward neural network;discrete mathematics;probabilistic neural network;types of artificial neural networks;regular language;computer science;recurrent neural network;machine learning;time delay neural network;mathematics;deep learning;second-order logic;artificial neural network;algorithm;linear approximation;satisfiability	ML	17.877971282580305	-26.56196669041725	44003
f7a4a7d97f9ff9b462796e3fc4ccf8d61317820e	an industrial application of neural networks to natural textures classification	global solution;human vision;texture classification;mathematical model;industrial application;quality control;human perception;neural network	In this paper, we describe an application of neural network for the classification of natural materials textures. We developped this solution in the context of leather quality control. This leather is used in car sits manufacturing (c.f. figure 1). The aim of this control is to make sure of the compatibility of every visual aspect in the whole car. This job is currently processed by human experts that cannot inspect every sits with the same attention. The automation of such a process is very complicated because it is necessary to build a model of human vision in order to take into account how a texture is interpreted as an aspect. As a matter of fact, human perception is processed with subjectivity that makes very hard to propose an efficient explicit mathematical model. We explain why neural networks can be useful in such an application, and we expose our solution. We describe technical gears of this solution (fractals preprocessing, neural architecture,...) and we explain how we built the global solution with the help of the A.G.E.N.D.A. methodology.	artificial neural network	Gérard Yahiaoui;Bertrand Borocco	1993		10.1007/3-540-56798-4_202	computer vision;quality control;computer science;artificial intelligence;machine learning;mathematical model;perception;artificial neural network	ML	6.711111013518188	-24.70446823189233	44040
f789d37586b2a6f282f4928bea88f232be4bbb85	an importance sampling approach to integrate expert knowledge when learning bayesian networks from data	bayesian network;bayesian statistics;learning methods;probability distribution;experimental validation;expert knowledge;importance sampling;monte carlo simulation	The introduction of expert knowledge when learning Bayesian Networks from data is known to be an excellent approach to boost the performance of automatic learning methods, specially when the data is scarce. Previous approaches for this problem based on Bayesian statistics introduce the expert knowledge modifying the prior probability distributions. In this study, we propose a new methodology based on Monte Carlo simulation which starts with non-informative priors and requires knowledge from the expert a posteriori, when the simulation ends. We also explore a new Importance Sampling method for Monte Carlo simulation and the definition of new non-informative priors for the structure of the network. All these approaches are experimentally validated with five standard Bayesian networks.	bayesian network;importance sampling	Andrés Cano;Andrés R. Masegosa;Serafín Moral	2010		10.1007/978-3-642-14049-5_70	probability distribution;variable-order bayesian network;importance sampling;computer science;machine learning;bayesian network;data mining;mathematics;bayesian statistics;statistics;monte carlo method	ML	23.42769484358185	-27.62409669659446	44058
85fe43e6ae380d51136f533bc14032d4cb5de6f5	incremental state aggregation for value function estimation in reinforcement learning	learning;reinforcement learning;parameter estimation function approximation learning artificial intelligence;reinforcement learning rl;adaptive basis function construction technique incremental state aggregation value function estimation reinforcement learning linear coefficients parameter estimation;function approximation;artificial intelligence computer simulation game theory models psychological models statistical reinforcement psychology;value function adaptive construction of basis functions reinforcement learning rl;mathematical model;adaptive construction of basis functions;value function;parameter estimation;learning artificial intelligence;computational efficiency;learning function approximation mathematical model computational efficiency	In reinforcement learning, large state and action spaces make the estimation of value functions impractical, so a value function is often represented as a linear combination of basis functions whose linear coefficients constitute parameters to be estimated. However, preparing basis functions requires a certain amount of prior knowledge and is, in general, a difficult task. To overcome this difficulty, an adaptive basis function construction technique has been proposed by Keller recently, but it requires excessive computational cost. We propose an efficient approach to this difficulty, in which the problem of approximating the value function is decomposed into a number of subproblems, each of which can be solved with small computational cost. Computer experiments show that the CPU time needed by our method is much smaller than that by the existing method.	algorithmic efficiency;basis function;bellman equation;cpu (central processing unit of computer system);central processing unit;coefficient;computation;computational complexity theory;computer experiment;increment;preparation;reinforcement learning;small	Takeshi Mori;Shin Ishii	2011	IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)	10.1109/TSMCB.2011.2148710	unsupervised learning;mathematical optimization;function approximation;computer science;artificial intelligence;machine learning;mathematical model;mathematics;bellman equation;estimation theory;reinforcement learning;q-learning;statistics	ML	21.582580510045936	-27.89441862167718	44110
6bb9ad169a385ccc66c8947cbafca4c556b46e9b	a fast channel change technique based on channel prediction		The channel zapping delay problem is a well-known problem in digital television. It has been researched quite extensively in the context of IPTV. In this paper, we present a technique for delay reduction that predicts the next channel that will be selected by the user. The technique is applicable to DVB-C/S/T, as well as in IPTV. The prediction is based on an adaptive model, which is built during a training process in which the history of channel changes is collected. The model is afterwards constantly updated. The problem is approached as a classification problem and C4.5 decision trees have shown the best performance among the tested algorithms. The proposed technique has been evaluated using channel history datasets obtained by simulation. The results of the evaluation show an increase of 5.67% in the probability that the next selected channel is already pre-joined, compared to the case when only neighboring channels are pre-joined. The application of the proposed technique is explained in detail.		Ilija Basicevic;Dragan Kukolj;Stanislav Ocovaj;Gordana Cmiljanovic;Nemanja Fimic	2018	IEEE Transactions on Consumer Electronics	10.1109/TCE.2018.2875271	computer science;iptv;computer vision;artificial intelligence;real-time computing;decision tree;digital television;communication channel	Mobile	2.3935268872981266	-35.649414929563434	44190
c047afde336a8560a5e65e74f8d3729cf469b480	streamxm: an adaptive partitional clustering solution for evolving data streams		A challenge imposed by continuously arriving data streams is to analyze them and to modify the models that explain them as new data arrives. We propose StreamXM, a stream clustering technique that does not require an arbitrary selection of number of clusters, repeated and expensive heuristics or in-depth prior knowledge of the data to create an informed clustering that relates to the data. It allows a clustering that can adapt its number of classes to those present in the underlying distribution. In this paper, we propose two different variants of StreamXM and compare them against a current, state-of-the-art technique, StreamKM. We evaluate our proposed techniques using both synthetic and real world datasets. From our results, we show StreamXM and StreamKM run in similar time and with similar accuracy when running with similar numbers of clusters. We show our algorithms can provide superior stream clustering if true clusters are not known or if emerging or disappearing concepts will exist within the data stream.	cluster analysis	Robert Anderson;Yun Sing Koh	2015		10.1007/978-3-319-22729-0_21	data stream;computer science;machine learning;artificial intelligence;heuristics;cluster analysis;data stream mining;unsupervised learning	ML	-1.555230461259095	-37.62612150864193	44244
c2f682d9229c58c78c785bfbef8f622f76163be4	comparison of decision tree and stepwise regression methods in classification of fdg-pet brain data using ssm/pca features	training;sensitivity;brain modeling;regression tree analysis diseases sensitivity training brain modeling;regression analysis decision trees image classification medical image processing positron emission tomography principal component analysis;stepwise regression parkinsonian syndromes fdg pet scaled sub profile model principal component analysis decision tree classification;human exploration stepwise regression methods fdg pet brain data classification ssm pca features parkinsonian syndromes classification scaled subprofile model principal component analysis ssm pca method fdg pet brain image data covariance patterns c4 5 decision tree algorithm subject brain image classification sr method scatter plots receiver operating characteristic curves roc curves subject classifications dt classification human interpretation;diseases;regression tree analysis	Objective: To compare the stepwise regression (SR) method and the decision tree (DT) method for classification of parkinsonian syndromes. Method: We applied the scaled subprofile model/principal component analysis (SSM/PCA) method to FDG-PET brain image data to obtain covariance patterns and the corresponding subject scores. The subject scores formed the input to the C4.5 decision tree algorithm to classify the subject brain images. For the SR method, scatter plots and receiver operating characteristic (ROC) curves indicate the subject classifications. We then compare the decision tree classifier results with those of the SR method. Results: We found out that the SR method performs slightly better than the DT method. We attribute this to the fact that the SR method uses a linear combination of the best features to form one robust feature, unlike the DT method. However, when the same robust feature is used as the input for the DT classifier, the performance is as high as that of the SR method. Conclusion: Even though the SR method performs better than the DT method, including the SR procedure in the DT classification yields a better performance. Additionally, the decision tree approach is more suitable for human interpretation and exploration than the SR method.	c4.5 algorithm;decision tree;feature vector;functional discourse grammar;generalization error;list of algorithms;monte carlo method;multiclass classification;newton's method;psi protein classifier;phet interactive simulations;polyethylene terephthalate;principal component analysis;receiver operating characteristic;statistical classification;stepwise regression	Deborah Mudali;Jos B. T. M. Roerdink;Laura K. Teune;Klaus Leonard Leenders;Remco J. Renken	2016	2016 Eighth International Conference on Advanced Computational Intelligence (ICACI)	10.1109/ICACI.2016.7449841	computer science;machine learning;pattern recognition;data mining	ML	9.7060417787205	-50.53407382264593	44275
0e56f8fd209d5284e5c2c92fe6b3b6d6cc1deb0f	detection of fuzzy association rules by fuzzy transforms	optimal fuzzy partition;coarse-grained association rule;census database;correct coarse-grained view;linguistic expression;data association rule set;fuzzy association rule;new method;apriorigen algorithm;confidence index	We present a new method based on the use of fuzzy transforms for detecting coarse-grained association rules in the datasets. The fuzzy association rules are represented in the form of linguistic expressions and we introduce a pre-processing phase to determine the optimal fuzzy partition of the domains of the quantitative attributes. In the extraction of the fuzzy association rules we use the AprioriGen algorithm and a confidence index calculated via the inverse fuzzy transform. Our method is applied to datasets of the 2001 census database of the district of Naples (Italy); the results show that the extracted fuzzy association rules provide a correct coarse-grained view of the data association rule set.		Ferdinando Di Martino;Salvatore Sessa	2012	Adv. Fuzzy Systems	10.1155/2012/258476	fuzzy logic;membership function;defuzzification;adaptive neuro fuzzy inference system;type-2 fuzzy sets and systems;fuzzy mathematics;fuzzy classification;fuzzy number;neuro-fuzzy;machine learning;pattern recognition;fuzzy measure theory;data mining;fuzzy set;fuzzy associative matrix;fuzzy set operations	DB	-0.35864043647901833	-26.26742609297136	44299
925d5e8fe7d6b04be75a3ac1e0da1b3f8a3db040	gear classification and fault detection using a diffusion map framework	fault detection;diffusion map;clustering	This article proposes a system health monitoring approach that detects abnormal behavior of machines. Diffusion map is used to reduce the dimensionality of training data, which facilitates the classification of newly arriving measurements. The new measurements are handled with Nyström extension. The method is trained and tested with real gear monitoring data from several windmill parks. A machine health index is proposed, showing that data recordings can be classified as working or failing using dimensionality reduction and warning levels in the low dimensional space. The proposed approach can be used with any system that produces high-dimensional measurement data.	computation;computational complexity theory;data point;diffusion map;dimensionality reduction;failure;fault detection and isolation;ground truth;kinetic data structure;maxima and minima;principal component analysis;real-time clock;real-time computing;sampling (signal processing);spectral method;time complexity;time series;windmill	Tuomo Sipola;Tapani Ristaniemi;Amir Averbuch	2015	Pattern Recognition Letters	10.1016/j.patrec.2014.10.019	computer vision;simulation;machine learning;pattern recognition;data mining;statistics	ML	23.14151242568825	-25.09353783169839	44320
bcc122aaebc89a6d6667307c2ac14d405c7acf6c	semi-supervised deep learning using pseudo labels for hyperspectral image classification		Deep learning has gained popularity in a variety of computer vision tasks. Recently, it has also been successfully applied for hyperspectral image classification tasks. Training deep neural networks, such as a convolutional neural network for classification requires a large number of labeled samples. However, in remote sensing applications, we usually only have a small amount of labeled data for training because they are expensive to collect, although we still have abundant unlabeled data. In this paper, we propose semi-supervised deep learning for hyperspectral image classification—our approach uses limited labeled data and abundant unlabeled data to train a deep neural network. More specifically, we use deep convolutional recurrent neural networks (CRNN) for hyperspectral image classification by treating each hyperspectral pixel as a spectral sequence. In the proposed semi-supervised learning framework, the abundant unlabeled data are utilized with their pseudo labels (cluster labels). We propose to use all the training data together with their pseudo labels to pre-train a deep CRNN, and then fine-tune using the limited available labeled data. Further, to utilize spatial information in the hyperspectral images, we propose a constrained Dirichlet process mixture model (C-DPMM), a non-parametric Bayesian clustering algorithm, for semi-supervised clustering which includes pairwise must-link and cannot-link constraints—this produces high-quality pseudo-labels, resulting in improved initialization of the deep neural network. We also derived a variational inference model for the C-DPMM for efficient inference. Experimental results with real hyperspectral image data sets demonstrate that the proposed semi-supervised method outperforms state-of-the-art supervised and semi-supervised learning methods for hyperspectral classification.	algorithm;artificial neural network;biologic preservation;biological neural networks;class;cluster analysis;computer vision;constrained clustering;convolutional neural network;deep learning;extraction;gain;guided imagery;inference;medicare access and chip reauthorization act of 2015;mixture model;neural network simulation;overfitting;pixel;pseudo brand of pseudoephedrine;recurrent neural network;remote sensing application;soap service description language;semi-supervised learning;semiconductor industry;supervised learning;tracer;variational principle;statistical cluster	Hao Wu;Saurabh Prasad	2018	IEEE Transactions on Image Processing	10.1109/TIP.2017.2772836	convolutional neural network;computer vision;cluster analysis;artificial neural network;feature extraction;deep learning;pattern recognition;hyperspectral imaging;recurrent neural network;mathematics;machine learning;artificial intelligence;contextual image classification	Vision	22.218671117296868	-45.974045859880576	44363
29ed573ecfb2e3a8847b21f05c057fbed5abb5e1	analyzing a class of decision problems: neural network based approach	feedforward neural network;decision models;neural net simulation;neural networks;supervised learning;input output data pairs;supervised learning rule;multilayer perceptrons;neural network based approach;diagrams;intrusion detection;neural networks intrusion detection costs;input output;decision problem;neural net;neural net simulation decision model neural network based approach decision class analysis influence diagram knowledge representation modeling classification problem input output data pairs feedforward neural network supervised learning rule;decision model;decision support systems;classification problem;feedforward neural nets;artificial neural net;learning artificial intelligence;knowledge representation;modeling;decision class analysis;influence diagram;neural network	This paper presents an application of an artifici neural net to the implementation of decision class analy (DCA), together with the generation of a decision mod influence diagram. The diagram is well-known as a go tool for knowledge representation of complex decisi problems. Generating influence diagram is known to practice require much time and effort, and the resulti model can be generally applicable to only a speci decision problem. In order to reduce the burden modeling decision problems, the concept of DCA introduced. DCA under consideration is viewed as classification problem where a set of input-output da pairs is given. We thus propose a method utilizing feedforward neural net with supervised learning rule develop DCA based on influence diagram. We a examine the results of neural net simulation with example of a class of decision problems.	analysis of algorithms;artificial neural network;decision problem;decision support system;feedforward neural network;influence diagram;knowledge representation and reasoning;learning rule;simulation;statistical classification;supervised learning;test set;well-formed element	Jae Kyeong Kim;Seok Chin Chu	1998		10.1109/HICSS.1998.648294	decision model;optimal decision;influence diagram;decision engineering;computer science;artificial intelligence;machine learning;decision tree;pattern recognition;decision rule;artificial neural network;weighted sum model	AI	7.290467164111974	-29.689660047120974	44371
7c3fc23634a82ce19a6172cbc0be78aceaf73ed7	ann vs. svm: which one performs better in classification of mccs in mammogram imaging	microcalcification clusters mcc;computer aided diagnosis;balanced learning;support vector machine;mammography;optimized decision making;electrical engineering electronics nuclear engineering;neural network	"""Classification of microcalcification clusters from mammograms plays essential roles in computer-aided diagnosis for early detection of breast cancer, where support vector machine (SVM) and artificial neural network (ANN) are two commonly used techniques. Although some work suggest that SVM performs better than ANN, the average accuracy achieved is only around 80% in terms of the area under the receiver operating characteristic curve Az. This performance may become much worse when the training samples are imbalanced. As a result, a new strategy namely balanced learning with optimized decision making is proposed to enable effective learning from imbalanced samples, which is further employed to evaluate the performance of ANN and SVM in this context. When the proposed learning strategy is applied to individual classifiers, the results on the DDSM database have demonstrated that the performance from both ANN and SVM has been significantly improved. Although ANN outperforms SVM when balanced learning is absent, the performance from the two classifiers becomes very comparable when both balanced learning and optimized decision making are employed. Consequently, an average improvement of more than 10% in the measurements of F""""1 score and Az measurement are achieved for the two classifiers. This has fully validated the effectiveness of our proposed method for the successful classification of clustered microcalcifications."""	monitor control command set	Jinchang Ren	2012	Knowl.-Based Syst.	10.1016/j.knosys.2011.07.016	support vector machine;computer science;artificial intelligence;machine learning;pattern recognition;artificial neural network	ML	13.642892447394912	-44.73798834661779	44385
a0e42f00c86df822d2caa0796b2b04d63c6ec96b	self-organizing graphs - a neural network perspective of graph layout	learning algorithm;geometrie algorithmique;grafo topologico;computational geometry;algorithme apprentissage;m 900 tree;m 300 dynamic incremental online;construction graphe;graph connectivity;g 999 others;p 060 3d;conectividad grafo;topological graph;graph layout;self organization;self organized map;geometria computacional;reseau neuronal;algoritmo aprendizaje;connectivite graphe;graph construction;graphe topologique;red neuronal;construccion grafo;neural network	The paper presents self-organizing graphs, a novel approach to graph layout based on a competitive learning algorithm. This method is an extension of self-organization strategies known from unsupervised neural networks, namely from Kohonen's self-organizing map. Its main advantage is that it is very exibly adaptable to arbitrary types of visualization spaces, for it is explicitly parameterized by a metric model of the layout space. Yet the method consumes comparatively little computational resources and does not need any heavy-duty preprocess-ing. Unlike with other stochastic layout algorithms, not even the costly repeated evaluation of an objective function is required. To our knowledge this is the rst con-nectionist approach to graph layout. The paper presents applications to 2D-layout as well as to 3D-layout and to layout in arbitrary metric spaces, such as networks on spherical surfaces.	algorithm;artificial neural network;competitive learning;computation;computational resource;graph drawing;loss function;naruto shippuden: clash of ninja revolution 3;optimization problem;organizing (structure);preprocessor;self-organization;self-organizing map;stochastic process	Bernd Meyer	1998		10.1007/3-540-37623-2_19	combinatorics;topological graph;self-organization;computational geometry;computer science;artificial intelligence;connectivity;theoretical computer science;machine learning;mathematics;artificial neural network;algorithm	ML	12.09195442545872	-31.202904130367468	44395
9608963104554765d847065ce98b13ed29eb7ad6	estimating posterior ratio for classification: transfer learning from probabilistic perspective		Transfer learning assumes classifiers of similar tasks share certain parameter structures. Unfortunately, modern classifiers uses sophisticated feature representations with huge parameter spaces which lead to costly transfer. Under the impression that changes from one classifier to another should be “simple”, an efficient transfer learning criteria that only learns the “differences” is proposed in this paper. We train a posterior ratio which turns out to minimizes the upper-bound of the target learning risk. The model of posterior ratio does not have to share the same parameter space with the source classifier at all so it can be easily modelled and efficiently trained. The resulting classifier therefore is obtained by simply multiplying the existing probabilistic-classifier with the learned posterior ratio.		Song Liu;Kenji Fukumizu	2016		10.1137/1.9781611974348.84	computer science;machine learning;pattern recognition;data mining;statistics	AI	17.71505130172351	-39.3915226313726	44471
3f5604f551b4531396a76f14016d0584f8d972ef	mapping of som and lvq algorithms on a tree shape parallel computer system	neural networks;tree architecture;self organizing map;parallel computer;self organized map;parallel implementation;learning vector quantization;neural network	Parallel mappings of Kohonen’s self organizing map (SOM) and learning vector quantization (LVQ) algorithms are presented for a tree shape parallel computer system called TUTNC (Tampere University of Technology Neural Computer). The lattice of neurons in SOM is partitioned columnwise to parallel processors in a neuron parallel manner. In addition, an efficient method is presented for the neighborhood computation to make the computation time independent of SOM size and processor count. The tree shape architecture is shown to match well the requirements of mapped algorithms and their relations in such a prototype system TUTNC are studied. Performance has heen measured for sample configurations and estimated for a larger system. Comparisons to other implementations on various platforms show, that good performance per processor has heen achieved.	academy;algorithm;automation;central processing unit;column (database);computation;computer;digital signal processor;ibm systems network architecture;idle scan;industry standard architecture;linc;learning vector quantization;neuron;organizing (structure);parallel computing;prototype;requirement;self-organization;self-organizing map;space partitioning;teuvo kohonen;time complexity	Timo Hämäläinen;Harri Klapuri;Jukka Saarinen;Kimmo Kaski	1997	Parallel Computing	10.1016/S0167-8191(97)00020-3	parallel computing;self-organizing map;learning vector quantization;computer science;artificial intelligence;theoretical computer science;machine learning;artificial neural network	HPC	13.739585213904379	-26.71807665063263	44482
b7b19dddd69b318b2cde75c18be1892219eaa0ee	a replica exchange monte carlo algorithm for protein folding in the hp model	ant colony optimisation;amino acid sequence;models chemical;energy function;computational biology bioinformatics;optimization problem;models molecular;protein conformation;molecular biology;protein structure prediction;monte carlo method;ground state;monte carlo algorithm;growth mechanism;models statistical;algorithms;protein folding;pruned enriched rosenbluth method;molecular sequence data;combinatorial libraries;monte carlo;lattice model;computer appl in life sciences;computer simulation;energy landscape;hydrophobic polar;sequence analysis protein;microarrays;bioinformatics	The ab initio protein folding problem consists of predicting protein tertiary structure from a given amino acid sequence by minimizing an energy function; it is one of the most important and challenging problems in biochemistry, molecular biology and biophysics. The ab initio protein folding problem is computationally challenging and has been shown to be N P MathType@MTEF@5@5@+=feaafiart1ev1aaatCvAUfKttLearuWrP9MDH5MBPbIqV92AaeXatLxBI9gBaebbnrfifHhDYfgasaacH8akY=wiFfYdH8Gipec8Eeeu0xXdbba9frFj0=OqFfea0dXdd9vqai=hGuQ8kuc9pgc9s8qqaq=dirpe0xb9q8qiLsFr0=vr0=vr0dc8meaabaqaciaacaGaaeqabaqabeGadaaakeaat0uy0HwzTfgDPnwy1egaryqtHrhAL1wy0L2yHvdaiqaacqWFneVtcqqGqbauaaa@3961@ -hard even when conformations are restricted to a lattice. In this work, we implement and evaluate the replica exchange Monte Carlo (REMC) method, which has already been applied very successfully to more complex protein models and other optimization problems with complex energy landscapes, in combination with the highly effective pull move neighbourhood in two widely studied Hydrophobic Polar (HP) lattice models. We demonstrate that REMC is highly effective for solving instances of the square (2D) and cubic (3D) HP protein folding problem. When using the pull move neighbourhood, REMC outperforms current state-of-the-art algorithms for most benchmark instances. Additionally, we show that this new algorithm provides a larger ensemble of ground-state structures than the existing state-of-the-art methods. Furthermore, it scales well with sequence length, and it finds significantly better conformations on long biological sequences and sequences with a provably unique ground-state structure, which is believed to be a characteristic of real proteins. We also present evidence that our REMC algorithm can fold sequences which exhibit significant interaction between termini in the hydrophobic core relatively easily. We demonstrate that REMC utilizing the pull move neighbourhood significantly outperforms current state-of-the-art methods for protein structure prediction in the HP model on 2D and 3D lattices. This is particularly noteworthy, since so far, the state-of-the-art methods for 2D and 3D HP protein folding – in particular, the pruned-enriched Rosenbluth method (PERM) and, to some extent, Ant Colony Optimisation (ACO) – were based on chain growth mechanisms. To the best of our knowledge, this is the first application of REMC to HP protein folding on the cubic lattice, and the first extension of the pull move neighbourhood to a 3D lattice.	amino acid sequence;amino acids;ant colony optimization algorithms;apache ant (another neat tool);benchmark (computing);biochemistry;cubic function;ground state;large;lattice model (physics);mathematical optimization;monte carlo algorithm;monte carlo method;needle-exchange programs;parallel tempering;protein structure prediction;protein folding;tertiary	Chris Thachuk;Alena Shmygelska;Holger H. Hoos	2007	BMC Bioinformatics	10.1186/1471-2105-8-342	computer simulation;biology;mathematical optimization;computer science;bioinformatics;monte carlo method	Comp.	0.02539361456976392	-50.08670964363926	44497
63ed6058582e7c969274073d97c9100142c3e2a1	unifying genetic algorithm and clustering method for recognizing activated fmri time series	nuclear magnetic resonance imaging;optimal solution;medical imagery;global solution;centro gravitacional;solution optimale;analyse amas;evasion;cluster;imagineria rmn;centre gravite;amas;algorithme k moyenne;functional mri;analyse fonctionnelle;center of mass;active region;intelligence artificielle;algorithme deterministe;time series;algoritmo genetico;data mining;classification;genetics;escape;deterministic algorithms;cluster analysis;functional analysis;fouille donnee;clustering method;solucion optima;serie temporelle;imagineria medica;imagerie medicale;serie temporal;algorithme genetique;artificial intelligence;algoritmo k media;genetic algorithm;k means algorithm;global optimization;analisis cluster;imagerie rmn;monton;solution globale;inteligencia artificial;busca dato;solucion global;clasificacion;k means clustering;analisis funcional	In order to get more reliable activation detection result in functional MRI data, we attempt to bring together the advantages of the genetic algorithm, which is deterministic and able to escape from the local optimal solution, and the K-means clustering, which is fast. Thus a novel clustering approach, namely the genetic K-means algorithm, is proposed to detect fMRI activation. It is more likely to find a global optimal solution to the K-means clustering, and is independent of the initial assignments of the cluster centroids. The experimental results show that the proposed method recognizes fMRI activation regions with higher accuracy than ordinary K-means clustering.		Lin Shi;Pheng-Ann Heng;Tien-Tsin Wong	2005		10.1007/11739685_25	functional analysis;correlation clustering;constrained clustering;fuzzy clustering;flame clustering;computer science;artificial intelligence;canopy clustering algorithm;machine learning;cure data clustering algorithm;cluster analysis;algorithm;global optimization;k-means clustering;clustering high-dimensional data	ML	11.37474173308002	-32.262075068004776	44508
a5c57cad7eab50f0dfa5d24429922bd02f925c22	principal graph and structure learning based on reversed graph embedding	grammar convergence manifolds skeleton bifurcation optical imaging cancer;structure learning principal curve principal graph	Many scientific datasets are of high dimension, and the analysis usually requires retaining the most important structures of data. Principal curve is a widely used approach for this purpose. However, many existing methods work only for data with structures that are mathematically formulated by curves, which is quite restrictive for real applications. A few methods can overcome the above problem, but they either require complicated human-made rules for a specific task with lack of adaption flexibility to different tasks, or cannot obtain explicit structures of data. To address these issues, we develop a novel principal graph and structure learning framework that captures the local information of the underlying graph structure based on reversed graph embedding. As showcases, models that can learn a spanning tree or a weighted undirected `1 graph are proposed, and a new learning algorithm is developed that learns a set of principal points and a graph structure from data, simultaneously. The new algorithm is simple with guaranteed convergence. We then extend the proposed framework to deal with large-scale data. Experimental results on various synthetic and six real world datasets show that the proposed method compares favorably with baselines and can uncover the underlying structure correctly.		Qi Mao;Li Wang;Ivor W. Tsang;Yijun Sun	2017	IEEE transactions on pattern analysis and machine intelligence	10.1109/TPAMI.2016.2635657	edge-transitive graph;factor-critical graph;combinatorics;geometric graph theory;discrete mathematics;graph embedding;directed graph;topology;null graph;graph property;computer science;distance-regular graph;simplex graph;mathematics;voltage graph;graph;butterfly graph;beta skeleton;quartic graph;line graph;string graph;strength of a graph;coxeter graph	ML	21.496916263703238	-43.82802619309977	44593
0e0f0cdd37032d86d755a138c1fb121a89eaa623	complete action map or best action map in accuracy-based reinforcement learning classifier systems	learning classifier system;classification;xcs;complete action map;xcsam;best action map	We study two existing Learning Classifier Systems (LCSs): XCS, which has a complete map (which covers all actions in each state), and XCSAMm, which has a best action map (which covers only the highest-return action in each state). This allows XCSAM to learn with a smaller population size limit (but larger population size) and to learn faster than XCS on well-behaved tasks. However, many tasks have dif- ficulties like noise and class imbalances. XCS and XCSAM have not been compared on such problems before. This pa- per aims to discover which kind of map is more robust to these difficulties. We apply them to a classification problem (the multiplexer problem) with class imbalance, Gaussian noise or alternating noise (where we return the reward for a different action). We also compare them on real-world data from the UCI repository without adding noise. We analyze how XCSAM focuses on the best action map and introduce a novel deletion mechanism that helps to evolve classifiers towards a best action map. Results show the best action map is more robust (has higher accuracy and sometimes learns faster) in all cases except small amounts of alternat- ing noise.	image noise;learning classifier system;multiplexer;reinforcement learning	Masaya Nakata;Pier Luca Lanzi;Tim Kovacs;Keiki Takadama	2014		10.1145/2576768.2598351	biological classification;computer science;artificial intelligence;machine learning;pattern recognition;mathematics;learning classifier system	ML	15.498016363005055	-36.90748550381126	44596
2e44b45778a97126b4ebea52f87b39192d8903cf	a novel knowledge discovering model for mining fuzzy multi-level sequential patterns in sequence databases	fuzzy set;multi level;sequence data;sequential patterns;data mining;fuzzy sets;concept hierarchy;sequential pattern mining;sequential pattern;computational efficiency	Items sold in a store can usually be organized into a concept hierarchy according to a taxonomy. Based on the hierarchy, sequential patterns can be found not only at the leaf nodes (individual items) of the hierarchy, but also at higher levels of the hierarchy; this is called multiple-level sequential pattern mining. In previous research, taxonomies had crisp relationships between the categories in one level and the categories in another level. In real life, however, crisp taxonomies cannot handle the uncertainties and fuzziness inherent in the relationships among items and categories. For example, the book Alice's Adventures in Wonderland can be classified into the Children's Literature category, but can also be related to the Action &Adventure category. To deal with the fuzzy nature of taxonomy, we apply fuzzy set techniques to concept taxonomies so that the relationships from one level to another can be represented by a value between 0 and 1. Accordingly, a fuzzy multiple-level mining algorithm, the fuzzy multi-level sequential mining algorithm (FMSM), is proposed to extract fuzzy multiple-level sequential patterns from databases. In addition, another algorithm, named the CROSS-FMSM algorithm, is developed to discover fuzzy cross-level sequential patterns. Experiments using synthetic datasets show the algorithms' computational efficiency and scalability, and a real dataset is used to prove the patterns' effectiveness.	sequence database	Yen-Liang Chen;Tony Cheng-Kui Huang	2008	Data Knowl. Eng.	10.1016/j.datak.2008.04.005	fuzzy classification;computer science;artificial intelligence;fuzzy number;machine learning;data mining;fuzzy set;fuzzy set operations	ML	-3.209317879257283	-29.660545119000062	44605
b9969031234ba163848f36dc9926560d54f8541e	linguistic modelling for function approximation using grid partitions	performance measure;machine learning algorithms;genetics based machine learning algorithm linguistic modeling function approximation grid partitions nonlinear functions linguistic rules general rules standard interpolation based fuzzy reasoning method nonstandard specificity based method rule base performance measures association rules data mining rule selection method;general rules;fuzzy reasoning;function approximation humans fuzzy sets input variables data mining machine learning algorithms fuzzy systems knowledge based systems fuzzy reasoning industrial engineering;input variables;rule based;linguistic modeling;inference mechanisms;association rules;data mining;grid partitions;fuzzy sets;standard interpolation based fuzzy reasoning method;fuzzy logic;nonlinear functions;function approximation;association rule;performance measures;fuzzy logic learning artificial intelligence inference mechanisms genetic algorithms function approximation nonlinear functions;nonstandard specificity based method;genetics based machine learning;genetic algorithm;genetics based machine learning algorithm;genetic algorithms;humans;rule selection method;learning artificial intelligence;linguistic rules;rule base;fuzzy systems;knowledge based systems;industrial engineering	Discusses various issues related to linguistic modeling of nonlinear functions with many input variables. Our task is to extract a small number of comprehensible linguistic rules from numerical data for describing nonlinear functions in a human understandable manner. First we show the necessity of general rules in the handling of nonlinear functions with many input variables. Next we compare a standard interpolation-based fuzzy reasoning method with our non-standard specificity-based method. When a rule base is a mixture of general and specific rules, different results are obtained from these two methods. Then we extend two performance measures (i.e., confidence and support) of association rules in data mining to the case of linguistic rules. These two measures are used for evaluating each linguistic rule. The validity of our fuzzy reasoning method is discussed using these measures. Finally we show two genetic algorithm-based approaches to linguistic modeling. One is a rule selection method, and the other is a genetics-based machine learning algorithm.	approximation	Hisao Ishibuchi;Takashi Yamamoto;Tomoharu Nakashima	2001		10.1109/FUZZ.2001.1007242	rule-based system;genetic algorithm;association rule learning;computer science;artificial intelligence;knowledge-based systems;machine learning;pattern recognition;data mining;mathematics;fuzzy control system	Robotics	3.9741595601489004	-27.728366863695058	44606
823d1238e1746b98e792d876b79b14b48f419aa4	unsupervised statistical clustering of environmental shotgun sequences	genomics;algorithm analysis;supervised learning;maximum likelihood;shotgun sequencing;low complexity;sequence analysis dna;first principle;feature space;statistical model;computational biology bioinformatics;k mer distribution;algorithmic analysis;cluster analysis;markov chain monte carlo;metagenomic data;genome;algorithms;combinatorial libraries;computer appl in life sciences;high performance;article;open source;microarrays;bioinformatics	The development of effective environmental shotgun sequence binning methods remains an ongoing challenge in algorithmic analysis of metagenomic data. While previous methods have focused primarily on supervised learning involving extrinsic data, a first-principles statistical model combined with a self-training fitting method has not yet been developed. We derive an unsupervised, maximum-likelihood formalism for clustering short sequences by their taxonomic origin on the basis of their k-mer distributions. The formalism is implemented using a Markov Chain Monte Carlo approach in a k-mer feature space. We introduce a space transformation that reduces the dimensionality of the feature space and a genomic fragment divergence measure that strongly correlates with the method's performance. Pairwise analysis of over 1000 completely sequenced genomes reveals that the vast majority of genomes have sufficient genomic fragment divergence to be amenable for binning using the present formalism. Using a high-performance implementation, the binner is able to classify fragments as short as 400 nt with accuracy over 90% in simulations of low-complexity communities of 2 to 10 species, given sufficient genomic fragment divergence. The method is available as an open source package called LikelyBin. An unsupervised binning method based on statistical signatures of short environmental sequences is a viable stand-alone binning method for low complexity samples. For medium and high complexity samples, we discuss the possibility of combining the current method with other methods as part of an iterative process to enhance the resolving power of sorting reads into taxonomic and/or functional bins.	community;dimensionality reduction;feature vector;formal system;genome;iterative method;k-mer;markov chain monte carlo;mer;metagenomics;monte carlo method;one thousand;open-source software;product binning;reading (activity);semantics (computer science);simulation;sorting;statistical model;supervised learning;type signature;unsupervised learning;statistical cluster	Andrey Kislyuk;Srijak Bhatnagar;Jonathan Dushoff;Joshua S. Weitz	2009	BMC Bioinformatics	10.1186/1471-2105-10-316	statistical model;biology;genomics;dna microarray;feature vector;markov chain monte carlo;first principle;computer science;bioinformatics;machine learning;data mining;maximum likelihood;cluster analysis;supervised learning;genome;shotgun sequencing	Comp.	3.410112773194013	-51.08621580865918	44616
0b08e4dd85093c59c8f35fbfc4bb2db42021e892	fusing fuzzy association rule-based classifiers using sugeno integral with ordered weighted averaging operators	classifier fusion;fuzzy classifiers;association rules;ordered weighted average;ordered weighted averaging;fuzzy association rules;sugeno integral	The time or space complexity may considerably increase for a single classifier if all features are taken into account. Thus, it is reasonable to train a single classifier by partial features. Then, a set of multiple classifiers can be generated, and an aggregation of outputs from different classifiers is subsequently performed. The aim of this paper is to propose a classification system with a heuristic fusion scheme in which multiple fuzzy association rule-based classifiers with partial features are combined, and show the feasibility and effectiveness of fusing multiple classifiers through the Sugeno integral extended by ordered weighted averaging operators. In comparison with the Sugeno integral by computer simulations on the iris data and the appendicitis data show that the overall classification accuracy rate could be improved by the Sugeno integral with ordered weighted averaging operators. The experimental results further demonstrate that the proposed method performs well in comparison with other fuzzy or non-fuzzy classification methods.	association rule learning;ordered weighted averaging aggregation operator;sugeno integral	Yi-Chung Hu;Jung-Fa Tsai	2007	International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems	10.1142/S0218488507004960	random subspace method;ordered weighted averaging aggregation operator;association rule learning;computer science;machine learning;pattern recognition;fuzzy measure theory;data mining;mathematics	Robotics	1.0089110181344054	-29.064524702691905	44628
8600c82b224153966a61e357016a0c589abcb6b3	research on eeg classification with neural networks based on the levenberg-marquardt algorithm		In the brain-computer interface (BCI), the feature extraction and classification of electroencephalogram (EEG) can be achieved by massive study of the Multilayer feedforward neural network. But the BP neural network based on error back propagation converges slowly, and has low efficiency in training, limited accuracy in classification. To solve these problems, the quick and stable Levenberg-Marquardt algorithm is adopted instead of the BP algorithm to train the neural network. The MATLAB simulation experiment of classifying the EEG signals of the motor imagery of left hand and right hand uses the Graz data set B from the BCI competition 2008. The simulation results show that the accuracy rate of this algorithm is 87.1%, which is superior to 78.2% of the BP algorithm, and it converges better as well. This technology provides an effective way to EEG classification.	artificial neural network;electroencephalography;levenberg–marquardt algorithm	Yue Chen;Shaobai Zhang	2012		10.1007/978-3-642-34041-3_29	machine learning;pattern recognition	ML	13.847934175036057	-33.172556922714314	44704
693c6276b58783ef3b2f1bdcaf10200202ba55d3	an addition to backpropagation for computing functional roots	backpropagation;neural network;chaos theory;system identification;multi layer perceptron	Many processes are composed of a n-fold repetition of some simpler process. If the whole process can be modeled with a neural network, we present a method to derive a model of the basic process, too, thus performing not only a system-identification but also a decomposition into basic blocks. Mathematically this is equivalent to the problem of computing iterative or functional roots: Given the equationF(x)=f(f(x)) and an arbitrary functionF(x) we seek a solution for f(x). A special topology of multilayer perceptrons and a simple addition to the delta rule of backpropagation will allow most NN tools to compute good approximations. Applications range from data analysis within chaos theory to the optimization of industrial processes, where production lines like steel mills often consist of several identical machines in a row.	approximation;artificial neural network;backpropagation;basic block;chaos theory;delta rule;iterative method;mathematical optimization;multilayer perceptron;roots;sbcl;system identification	Lars Kindermann	1998			mathematics;discrete mathematics;machine learning;artificial intelligence;artificial neural network;chaos theory;system identification;multilayer perceptron;backpropagation;mathematical optimization	ML	14.77352315831923	-26.813547817733298	44706
24e9de91656d6cf90be2e0da0a79fa45e5ccbbd5	discovering relations among go-annotated clusters by graph kernel methods	settore inf 01 informatica;gene expression data;meta analysis;large scale;machine learning;cell cycle;kernel method;gene ontology	The biological interpretation of large-scale gene expression data is one of the challenges in current bioinformatics. The state-of-theart approach is to perform clustering and then compute a functional characterization via enrichments by Gene Ontology terms [1]. To better assist the interpretation of results, it may be useful to establish connections among different clusters. This machine learning step is sometimes termed cluster meta-analysis, and several approaches have already been proposed; in particular, they usually rely on enrichments based on flat lists of GO terms. However, GO terms are organized in taxonomical graphs, whose structure should be taken into account when performing enrichment studies. To tackle this problem, we propose a kernel approach that can exploit such structured graphical nature. Finally, we compare our approach against a specific flat list method by analyzing the cdc15subset of the well known Spellman’s Yeast Cell Cycle dataset [2].	bioinformatics;cluster analysis;gene ontology term enrichment;graph kernel;jaccard index;kernel (operating system);kernel method;machine learning;similarity measure;taxonomy (general);timeline;whole earth 'lectronic link	Italo Zoppis;Daniele Merico;Marco Antoniotti;Bud Mishra;Giancarlo Mauri	2007		10.1007/978-3-540-72031-7_15	biology;kernel method;meta-analysis;computer science;bioinformatics;artificial intelligence;cell cycle;machine learning;data mining;database;algorithm;statistics	ML	5.130660146812228	-49.731301368710156	44712
759815d8dd9a2c09ff2a754dc3fcd3bb9d005841	feature selection using genetic algorithm for big data		Feature selection is a powerful technique for dimensionality reduction and an important step in successful machine learning applications. In the last few decades, data has become progressively larger in both numbers of instances and features which make it harder to deal with the feature selection problem. To cope with this new epoch of big data, new techniques need to be developed for addressing this problem effectively. Nonetheless, the suitability of current feature selection algorithms is extremely downgraded and are inapplicable, when data size exceeds hundreds of gigabytes. In this paper, we introduce a scalable implementation of a parallel feature selection approach using the genetic algorithm that has been done in parallel using MapReduce model. The experimental results showed that the proposed method can be suitable to improve the performance of feature selection.	big data;feature selection;genetic algorithm	Rania Saidi;Waad Bouaguel Ncir;Nadia Essoussi	2018		10.1007/978-3-319-74690-6_35	gigabyte;genetic algorithm;scalability;big data;feature selection;machine learning;dimensionality reduction;artificial intelligence;computer science	ML	12.072341797457698	-40.0916872428947	44713
0e9ee94f5fc37e77ca27dec04fbd06e9b036de34	unsupervised domain adaptation with adversarial residual transform networks.		Domain adaptation is widely used in learning problems lacking labels. Recent researches show that deep adversarial domain adaptation models can make markable improvements in performance, which include symmetric and asymmetric architectures. However, the former has poor generalization ability whereas the latter is very hard to train. In this paper, we propose a novel adversarial domain adaptation method named Adversarial Residual Transform Networks (ARTNs) to improve the generalization ability, which directly transforms the source features into the space of target features. In this model, residual connections are used to share features and adversarial loss is reconstructed, thus making the model more generalized and easier to train. Moreover, regularization is added to the loss function to alleviate a vanishing gradient problem, which enables the training process stable. A series of experimental results based on Amazon review dataset, digits datasets and Office-31 image datasets show that the proposed ARTN method greatly outperform the methods of the state-of-the-art.	domain adaptation;loss function;matrix regularization;vanishing gradient problem	Guanyu Cai;Yuqin Wang;Mengchu Zhou;Lianghua He	2018	CoRR		residual;adversarial system;machine learning;computer science;artificial intelligence;domain adaptation;pattern recognition;regularization (mathematics);vanishing gradient problem	Vision	22.947148630763806	-49.366900018610124	44718
f1a543eeaa64f7eab30241d8a1bf37d5d8210628	an ep algorithm for learning highly interpretable classifiers	rule mining;complexity metrics;evolutionary computation;evolutionary programming;interpretability;data mining;classification;measurement accuracy algorithm design and analysis prediction algorithms complexity theory proposals genetics;classification rules;pattern classification;pattern classification data mining evolutionary computation knowledge based systems learning artificial intelligence;rule mining interpretable classifier learning evolutionary programming algorithm classification problem interpretable if then classification rules complexity metric;learning artificial intelligence;rule mining classification evolutionary programming interpretability;knowledge based systems	This paper introduces an Evolutionary Programming algorithm for solving classification problems using highly interpretable IF-THEN classification rules. It is an algorithm aimed to maximize the comprehensibility of the classifier by minimizing the number of rules and employing only relevant attributes. The proposal is evaluated and compared to other 5 well-known classification techniques over 18 datasets. The results obtained from the experiments show its competitive accuracy and the significantly better interpretability of the classifiers provided in terms of number of rules, number of conditions and a complexity metric.	algorithm;ant colony optimization algorithms;computation;computational resource;decision tree;evolutionary programming;expectation propagation;experiment;internet relay chat;logic programming;machine learning;software metric;statistical classification	Alberto Cano;Amelia Zafra;Sebastián Ventura	2011	2011 11th International Conference on Intelligent Systems Design and Applications	10.1109/ISDA.2011.6121676	evolutionary programming;biological classification;computer science;artificial intelligence;machine learning;pattern recognition;data mining;evolutionary computation	Robotics	9.961547247147138	-41.39297914177813	44743
5856d8c16dce7d6aeb3836b476ff704d0770c58c	distributed clustering via lsh based data partitioning		Given the importance of clustering in the analysis of large scale data, distributed algorithms for formulations such as k-means, k-median, etc. have been extensively studied. A successful approach here has been the “reduce and merge” paradigm, in which each machine reduces its input size to Õ(k), and this data reduction continues (possibly iteratively) until all the data fits on one machine, at which point the problem is solved locally. This approach has the intrinsic bottleneck that each machine must solve a problem of size ≥ k, and needs to communicate at least Ω(k) points to the other machines. We propose a novel data partitioning idea to overcome this bottleneck, and in effect, have different machines focus on “finding different clusters”. Under the assumption that we know the optimum value of the objective up to a poly(n) factor (arbitrary polynomial), we establish worst-case approximation guarantees for our method. We see that our algorithm results in lower communication as well as a near-optimal number of ‘rounds’ of computation (in the popular MapReduce framework).	approximation;best, worst and average case;cluster analysis;computation;computer cluster;distributed algorithm;fits;information;k-means clustering;mapreduce;polynomial;programming paradigm;von neumann architecture;lsh	Aditya Bhaskara;Maheshakya Wijewardena	2018			machine learning;cluster analysis;artificial intelligence;computer science;pattern recognition	ML	-1.9196723369223192	-39.664320239170095	44750
f3cca4ef8291c7b784b36bc60e7ac16a07725d3e	fuzzy regression by fuzzy number neural networks	metodo cuadrado menor;methode moindre carre;optimisation;fuzzy regression;neural networks;least squares method;optimizacion;learning;regression lineaire floue;numero difuso;best approximation;fuzzy number;nombre flou;linear regression;regression model;backpropagation;aprendizaje;retropropagation;modelo regresion;apprentissage;fuzzy linear regression;fonction appartenance;modele regression;regresion lineal;membership function;controle qualite;mejor aproximacion;optimization;sistema difuso;systeme flou;funcion pertenencia;neural network model;reseau neuronal;fuzzy estimate;estimation floue;quality control;retropropagacion;back propagation;regression lineaire;red neuronal;fuzzy system;control calidad;neural network;meilleure approximation	In this paper, we describe a method for nonlinear fuzzy regression using neural network models. In earlier work, strong assumptions were made on the form of the fuzzy number parameters: symmetric triangular, asymmetric triangular, quadratic, trapezoidal, and so on. Our goal here is to substantially generalize both linear and nonlinear fuzzy regression using models with general fuzzy number inputs, weights, biases, and outputs. This is accomplished through a special training technique for fuzzy number neural networks. The technique is demonstrated with data from an industrial quality control problem.	artificial neural network;fuzzy number	James Dunyak;Donald Wunsch	2000	Fuzzy Sets and Systems	10.1016/S0165-0114(97)00393-X	membership function;defuzzification;adaptive neuro fuzzy inference system;fuzzy mathematics;fuzzy classification;computer science;artificial intelligence;fuzzy number;backpropagation;neuro-fuzzy;machine learning;fuzzy measure theory;mathematics;fuzzy set;fuzzy associative matrix;fuzzy set operations;artificial neural network;algorithm;fuzzy control system	ML	9.840144669943257	-29.398942058537997	44785
b97a6970416c23ca880f9898afdc8dae6fa17807	optimized fuzzy control of a greenhouse	optimisation;fuzzy controller;fuzzy system models;control difusa;optimizacion;modelisation foue;validacion;serre;implementation;fuzzy control;model validation;fuzzy modeling;ejecucion;control proceso;validation modele;wind velocity;process control;modele simulation;validation;optimization;greenhouse;sistema difuso;invernadero;systeme flou;modelo simulacion;production cost;simulation model;commande processus;fuzzy system;commande floue	Computer systems can be used to control the greenhouse climate in order to improve the culture development and to minimize the production costs. We have a system which allows to acquire the measurements of internal and external temperature and hygrometry, global radiation, and wind velocity. It consists of a heating system, moistening ducts and a static ventilation to control the internal climate. Since 1991, a classical controller on–o1 has been implemented in our experimental greenhouse, which enabled us to have a great number of data 2les. Knowing that the conventional techniques of regulation are di4cult to implement in this type of system (multivariable, nonlinear, nonstationary) where the interdependence of temperature and hygrometry with the meteorological disturbances are strong, we were brought to study the fuzzy controllers. This paper shows that it is possible to successfully control a greenhouse by using these techniques. During the probation period, we compare the various results obtained with these controllers. c © 2002 Elsevier Science B.V. All rights reserved.	fuzzy concept;fuzzy control system;fuzzy logic;interdependence;nonlinear system;usability;velocity (software development)	Frédéric Lafont;Jean-François Balmat	2002	Fuzzy Sets and Systems	10.1016/S0165-0114(01)00182-8	wind speed;greenhouse;simulation;computer science;artificial intelligence;simulation modeling;control theory;mathematics;regression model validation;implementation;fuzzy control system	Robotics	9.271657799607908	-24.795999362837662	44805
938d0ee23fb9f4da8dc4c26ffde12e9187a2dd83	simple algorithmic modifications for improving blind steganalysis performance	model selection;steganalysis;feature vector;svm;cross validation;decision rule	Most current algorithms for blind steganalysis of images are based on a two-stages approach: First, features are extracted in order to reduce dimensionality and to highlight potential manipulations; second, a classifier trained on pairs of clean and stego images finds a decision rule for these features to detect stego images. Thereby, vector components might vary significantly in their values, hence normalization of the feature vectors is crucial. Furthermore, most classifiers contain free parameters, and an automatic model selection step has to be carried out for adapting these parameters. However, the commonly used cross-validation destroys some information needed by the classifier because of the arbitrary splitting of image pairs (stego and clean version) in the training set. In this paper, we propose simple modifications of normalization and for standard cross-validation. In our experiments, we show that these methods lead to a significant improvement of the standard blind steganalyzer of Lyu and Farid.	algorithm;blind signature;cross-validation (statistics);experiment;farid f. abraham;feature vector;model selection;steganalysis;steganography;test set	Valentin Schwamberger;Matthias O. Franz	2010		10.1145/1854229.1854268	machine learning;pattern recognition;data mining;mathematics	ML	16.353523853807527	-50.61626871342899	44849
03efb44e9c88ac1b930a2c5e29c37dc25b96f27e	divide-and-conquer approach for the exemplar breakpoint distance	punto ruptura;multigen;genome rearrangement;plomb;gen;bioinformatique;point cassure;test;breakpoint;ensayo;genoma a;essai;genome a;lead;gene family;gene;plomo;multigene;bioinformatica;a genome;multiple;branch and bound;divide and conquer;multigene family;bioinformatics	MOTIVATION A one-to-one correspondence between the sets of genes in the two genomes being compared is necessary for the notions of breakpoint and reversal distances. To compare genomes where there are paralogous genes, Sankoff formulated the exemplar distance problem as a general version of the genome rearrangement problem. Unfortunately, the problem is NP-hard even for the breakpoint distance.   RESULTS This paper proposes a divide-and-conquer approach for calculating the exemplar breakpoint distance between two genomes with multiple gene families. The combination of our approach and Sankoff's branch-and-bound technique leads to a practical program to answer this question. Tests with both simulated and real datasets show that our program is much more efficient than the existing program that is based only on the branch-and-bound technique.   AVAILABILITY Code for the program is available from the authors.	algorithm;branch and bound;breakpoint;computation (action);dna sequence rearrangement;distance;gene family;genome;homology (biology);np-hardness;one-to-one (data model);phylogenetics;sequence homology;synteny;word lists by frequency	C. Thach Nguyen;Y. C. Tay;Louxin Zhang	2005	Bioinformatics	10.1093/bioinformatics/bti327	biology;lead;divide and conquer algorithms;computer science;bioinformatics;gene family;gene;software testing;breakpoint;genetics;branch and bound;multiple	Comp.	0.4285042785472477	-50.99059691646426	44851
8d6808071cad16574ffbf1d0a1586291d9dd542c	simple and scalable predictive uncertainty estimation using deep ensembles		Deep neural networks (NNs) are powerful black box predictors that have recently achieved impressive performance on a wide spectrum of tasks. Quantifying predictive uncertainty in NNs is a challenging and yet unsolved problem. Bayesian NNs, which learn a distribution over weights, are currently the state-of-the-art for estimating predictive uncertainty; however these require significant modifications to the training procedure and are computationally expensive compared to standard (non-Bayesian) NNs. We propose an alternative to Bayesian NNs that is simple to implement, readily parallelizable, requires very little hyperparameter tuning, and yields high quality predictive uncertainty estimates. Through a series of experiments on classification and regression benchmarks, we demonstrate that our method produces well-calibrated uncertainty estimates which are as good or better than approximate Bayesian NNs. To assess robustness to dataset shift, we evaluate the predictive uncertainty on test examples from known and unknown distributions, and show that our method is able to express higher uncertainty on out-of-distribution examples. We demonstrate the scalability of our method by evaluating predictive uncertainty estimates on ImageNet.	analysis of algorithms;approximation algorithm;artificial neural network;benchmark (computing);black box;display resolution;experiment;imagenet;performance tuning;scalability	Balaji Lakshminarayanan;Alexander Pritzel;Charles Blundell	2017			computer science;machine learning;data mining;statistics	ML	23.665201898015937	-30.57023207221548	44875
93e52fe6e4f07880b6f6302538ffa9a69cbdc14a	a game of prediction with expert advice	expert advice;cumulant;discrete time	We consider the following problem. At each point of discrete time the learner must make a prediction; he is given the predictions made by a pool of experts. Each prediction and the outcome, which is disclosed after the learner has made his prediction, determine the incurred loss. It is known that, under weak regularity, the learner can ensure that his cumulative loss never exceeds cL+a ln n, where c and a are some constants, n is the size of the pool, and L is the cumulative loss incurred by the best expert in the pool. We find the set of those pairs (c, a) for which this is true. )1998 Academic Press		Vladimir Vovk	1998	J. Comput. Syst. Sci.	10.1006/jcss.1997.1556	discrete time and continuous time;computer science;artificial intelligence;machine learning;data mining;mathematics;statistics;cumulant	Theory	20.668062620457786	-30.64995064883144	44878
2fc6beacd48c9bdccc3fb491f5b4ee4bf8a80e0a	collaborative fuzzy clustering algorithm: some refinements	collaborative strength optimization;horizontal mode of clustering;collaborative fuzzy clustering;granular partition matrix;partition matrix reordering	Abstract Since the inception of the concept of collaborative fuzzy clustering (CFC), many related ideas and algorithms have been proposed. In this study, we offer a synthetic view of this body of knowledge. We further concentrate on the horizontal version of the CFC algorithm being regarded as one of the major branches of the CFC. Our intent is to address the following three open questions: (a) assessing the necessity of reordering partition matrices prior to invoking the collaboration process; (b) analyzing the impact of linkage strengths on the performance of the clustering results; and (c) forming a representative global data structure with the use of the concept of information granules leading to so-called granular partition matrices. A collection of experimental studies is provided to quantify the underlying concepts and algorithms.	algorithm;cluster analysis;data structure;emoticon;fuzzy clustering;linkage (software);synthetic intelligence	Yinghua Shen;Witold Pedrycz	2017	Int. J. Approx. Reasoning	10.1016/j.ijar.2017.04.004	artificial intelligence;fuzzy clustering;machine learning;body of knowledge;cluster analysis;matrix (mathematics);partition (number theory);algorithm;data structure;computer science	DB	0.8949745858076952	-43.704791273236424	44883
49bcb563c18be9a974d6f8b388461ec8fea8844f	an analysis based on f-discrepancy for sampling in regression tree learning	trees mathematics learning artificial intelligence regression analysis sampling methods;regression tree analysis vegetation accuracy convergence computational modeling face estimation;optimal piecewise constant estimator f discrepancy concept regression tree learning regression tree estimator sampling method input generation process	When the problem of learning from data is solved through a regression tree estimator, the quality of the available observations is an important issue, since it influences directly the accuracy of the resulting model. It becomes particuarly relevant when there is freedom to sample the input space arbitrarily to build the tree model or, alternatively, when we need to select a subsample to train the tree estimator on a computationally feasible input set, or to evaluate the goodness of the estimation on a test set. Here the accuracy of estimation based on regression trees is analyzed from the point of view of geometric properties of the available input data. In particular, the concept of F-discrepancy, a quantity that measures how well a set of points represents the distribution underlying the input generation process, is applied to derive conditions for convergence to the optimal piecewise-constant estimator for the unknown function we want to learn. The analysis has a constructive nature, allowing to select in practice good input sets for the problem at hand, as shown in a simulation example involving a real data set.	algorithm;circuit complexity;decision tree learning;discrepancy function;sampling (signal processing);simulation;test set	Cristiano Cervellera;Mauro Gaggero;Danilo Macciò	2014	2014 International Joint Conference on Neural Networks (IJCNN)	10.1109/IJCNN.2014.6889665	local regression;machine learning;polynomial regression;pattern recognition;mathematics;logistic model tree;statistics	ML	22.961514657541734	-29.401756656303363	44887
2de886638127f7719e37854c9ca9acca3e9b0b20	probabilistic reasoning techniques for the tactical military domain	modelizacion;programmation stochastique;intelligence artificielle;aprendizaje probabilidades;data fusion;probabilistic approach;modelisation;object oriented;estimacion probabilista;enfoque probabilista;approche probabiliste;fusion donnee;apprentissage probabilites;oriente objet;artificial intelligence;estimation probabiliste;information fusion;inteligencia artificial;information system;probabilistic logic;fusion datos;stochastic programming;logique probabiliste;modeling;orientado objeto;situation assessment;programacion estocastica;systeme information;probabilistic relational model;probability learning;probabilistic reasoning;probabilistic assessment;sistema informacion	The use of probabilistic reasoning is a key capability in information fusion systems for a variety of domains such as military situation assessment. In this paper, we discuss two key approaches to probabilistic reasoning in military situation assessment: Probabilistic Relational Models and Object Oriented Probabilistic Relational Models. We compare the modeling and inferencing capabilities of these two languages and compare these capabilities against the requirements of the military situation assessment domain.		Catherine Howard;Markus Stumptner	2005		10.1007/11553939_7	computer science;artificial intelligence;machine learning;data mining;probabilistic logic;probabilistic argumentation	AI	7.474297226840443	-31.17526362982446	44898
938a855480e44827f6329c5bcbd4209ef375fbef	a mutual information-based two-phase memetic algorithm for large-scale fuzzy cognitive map learning		Various automatic learning algorithms have been proposed to learn fuzzy cognitive maps (FCMs), but most of them were only applied to learn small-scale FCMs and the learned maps obtained by such methods are usually much denser than the real maps. Learning FCMs requires the learning methods to not only determine the existence of links between concepts but also optimize the edge weights, which is the difficulty for FCM learning methods. Therefore, we propose a mutual information (MI)-based two-phase memetic algorithm (MA) for learning large-scale FCMs, termed as MIMA-FCM. In MIMA-FCM, the first phase is oriented to determine the existence of links between concepts by MI, which can reduce the search space significantly for MA, and then MA is used to optimize the edge weights according to the multiple observed response sequences in the second phase. Experiments on both synthetic and real-life data and the application for the gene regulatory network reconstruction problem demonstrate that the proposed method can not only find the plausible existence of links between concepts, but also optimize the edge weights rapidly. The comparison with existing algorithms shows that MIMA-FCM can learn large-scale FCMs with higher accuracy without expert knowledge.	experiment;fuzzy cognitive map;gene regulatory network;machine learning;memetic algorithm;mutual information;real life;reconstruction conjecture;synthetic intelligence;two-phase commit protocol	Xumiao Zou;Jing Liu	2018	IEEE Transactions on Fuzzy Systems	10.1109/TFUZZ.2017.2764445	genetic algorithm;artificial intelligence;machine learning;gene regulatory network;artificial neural network;mutual information;fuzzy cognitive map;memetic algorithm;computer science	AI	14.948336067474337	-33.42851607477813	44906
fc0b740176bc2679c12242a4ab2e321b89840325	incremental design of simplex basis function model for dynamic system identification		In this paper, we propose a novel adaptive piecewise linear model for dynamic system identification. It has four unique features. First, the model designs a new kind of basis function for function approximation. It maintains the uniform shape for each basis function, so as to achieve a satisfactory tradeoff between generalization ability and model complexity. Second, the model takes the structure of basis functions as decision variables to optimize the formulated identification problems instead of taking expansion coefficients as decision variables as proposed by many existing approaches. Third, we establish an incremental design strategy to solve the system identification problems. In each step of the identification, the selection of optimal basis function is a Lipschitz continuous optimization problem that is likely to be easily handled with some mature toolboxes. This incremental design strategy greatly reduces the estimation cost. Fourth, we introduce a smoothing mechanism to avoid overfitting, when the output of dynamic systems is disturbed by noise. Tests on several benchmark dynamic systems demonstrate the potential of the proposed model.	approximation;basis function;benchmark (computing);cyp1a1 gene;coefficient;continuous design;continuous optimization;decision theory;dynamical system;dynamical systems theory;function model;generalization (psychology);increment;linear function;linear model;mathematical optimization;nonlinear system identification;optimization problem;overfitting;piecewise linear continuation;smoothing (statistical technique);system identification;omacetaxine mepesuccinate	Juntang Yu;Shuning Wang;Li Li	2018	IEEE Transactions on Neural Networks and Learning Systems	10.1109/TNNLS.2017.2765201	artificial intelligence;overfitting;machine learning;computer science;function approximation;basis function;piecewise linear function;smoothing;optimization problem;system identification;design strategy	ML	20.43850391530139	-24.585857318098327	44910
0f7beb82cdb4a83de57cf4af1e4f001634affe73	on chaotic simulated annealing	convergence theorem;hopfield model;modele hopfield;optimisation;fonction energie;optimizacion;annealing;modelo hopfield;chaos;convergence of numerical methods;hopfield neural network simulated annealing chaos optimization convergence energy function euler approximation differential equations;simulation;caos;differential equation;hopfield neural nets;simulacion;indexing terms;simulated annealing;energy function;hopfield neural network;input output;optimization problem;convergence of numerical methods hopfield neural nets simulated annealing chaos function approximation differential equations;function approximation;chaos simulated annealing hardware convergence hopfield neural networks neurons cost function neural networks differential equations traveling salesman problems;recuit;network model;funcion energia;self organization;optimization;differential equations;recocido;reseau neuronal;red neuronal;neural network	Chen and Aihara recently proposed a chaotic simulated annealing approach to solving optimization problems. By adding a negative self-coupling to a network model proposed earlier by Aihara et al. and gradually removing this negative self-coupling, they used the transient chaos for searching and self-organizing, thereby achieving remarkable improvement over other neural-network approaches to optimization problems with or without simulated annealing. In this paper we suggest a new approach to chaotic simulated annealing with guaranteed convergence and minimization of the energy function by gradually reducing the time step in the Euler approximation of the differential equations that describe the continuous Hopfield neural network. This approach eliminates the need to carefully select other system parameters. We also generalize the convergence theorems of Chen and Aihara to arbitrarily increasing neuronal input-output functions and to less restrictive and yet more compact forms.	approximation;artificial neural network;biological neural networks;convergence (action);coupling (physics);entity–relationship model;euler method;hopfield network;mathematical optimization;network model;organizing (structure);self-organization;simulated annealing	Lipo Wang;Kate Smith-Miles	1998	IEEE transactions on neural networks	10.1109/72.701185	mathematical optimization;computer science;artificial intelligence;machine learning;mathematics;differential equation;adaptive simulated annealing;artificial neural network	Graphics	16.680120768601363	-27.71091948413887	44915
70138261ba14da9d9a183d18581960b2faf02d24	direct sparsity optimization based feature selection for multi-class classification		A novel sparsity optimization method is proposed to select features for multi-class classification problems by directly optimizing a l2,p -norm ( 0 < p ≤ 1 ) based sparsity function subject to data-fitting inequality constraints to obtain large between-class margins. The direct sparse optimization method circumvents the empirical tuning of regularization parameters in existing feature selection methods that adopt the sparsity model as a regularization term. To solve the direct sparsity optimization problem that is non-smooth and non-convex when 0 < p < 1, we propose an efficient iterative algorithm with proved convergence by converting it to a convex and smooth optimization problem at every iteration step. The proposed algorithm has been evaluated based on publicly available datasets. The experiments have demonstrated that our algorithm could achieve feature selection performance competitive to state-of-the-art algorithms.	bartlett's bisection theorem;curve fitting;elastic net regularization;experiment;feature selection;iteration;iterative method;linear classifier;loss function;mathematical optimization;matrix regularization;multiclass classification;optimization problem;parameter (computer programming);selection algorithm;social inequality;sparse approximation;sparse matrix	Hanyang Peng;Yong Fan	2016			mathematical optimization;machine learning;pattern recognition;mathematics	ML	22.14872098196184	-38.7685025557928	44927
faed25ef7672b5a9897b8a2fdae3b75fcc677afe	a comparison of categorical attribute data clustering methods		Clustering data in Euclidean space has a long tradition and there has been considerable attention on analyzing several different cost functions. Unfortunately these result rarely generalize to clustering of categorical attribute data. Instead, a simple heuristic k-modes is the most commonly used method despite its modest performance. In this study, we model clusters by their empirical distributions and use expected entropy as the objective function. A novel clustering algorithm is designed based on local search for this objective function and compared against six existing algorithms on well known data sets. The proposed method provides better clustering quality than the other iterative methods at the cost of higher time complexity.	ace;academy;algorithm;categorical variable;cluster analysis;fastest;heuristic;iterative method;k-means clustering;k-medoids;local search (optimization);loss function;medoid;optimization problem;prototype;time complexity	Ville Hautamäki;Antti Pöllänen;Tomi Kinnunen;Kong-Aik Lee;Haizhou Li;Pasi Fränti	2014		10.1007/978-3-662-44415-3_6	correlation clustering;constrained clustering;determining the number of clusters in a data set;data stream clustering;k-medians clustering;fuzzy clustering;flame clustering;canopy clustering algorithm;machine learning;consensus clustering;pattern recognition;cure data clustering algorithm;data mining;mathematics;cluster analysis;brown clustering;dbscan;biclustering;affinity propagation;clustering high-dimensional data;conceptual clustering	AI	0.06400139034023634	-40.595733633071646	44931
3df80a2d3c7203c3a109af4511e80b9aba0b5423	a divide-and-conquer implementation of three sequence alignment and ancestor inference	sequences;sequence evolution;phylogeny;biological system modeling;dynamic program;usa councils;binary trees;genetics;evolution biology;biomedical engineering;sequences costs phylogeny computer science biomedical engineering usa councils biological system modeling evolution biology binary trees genetic mutations;sequence alignment;multiple sequence alignment;genetic mutations;computer science;divide and conquer	In this paper, we present an algorithm to simultaneously align three biological sequences with affine gap model and infer their common ancestral sequence. Our algorithm can be further extended to perform tree alignment for more se- quences, and eventually unify the two procedures of phylo- genetic reconstruction and sequence alignment. The nov- elty of our algorithm is: it applies the divide-and-conquer strategy so that the memory usage is reduced from O (n3) to O (n2), while at the same time, it is based on dynamic programming and optimal alignment is guaranteed. Tra- ditionally, three sequence alignment is limited by the huge demand of memory space and can only handle sequences less than two hundred characters long. With the new im- proved algorithm, we can produce the optimal alignment of sequences of several thousand characters long. We implemented our algorithm as a C program package MSAM . It has been extensively tested with BAliBASE, a real manually refined multiple sequence alignment database, as well as simulated datasets generated by Rose (Ran- dom Model of Sequence Evolution). We compared our re- sults with those of other popular multiple sequence align- ment tools, including the widely used programs such as ClustalW and T-Coffee. The experiment shows that MSAM produces not only better alignment, but also better ancestral sequence. The software can be downloaded for free at http://www.cse.sc.edu/phylo/MSAM.html	algorithm;align (company);clustalw/clustalx;dspace;display resolution;dynamic programming;multiple sequence alignment;parallel computing;phylogenetic tree;phylogenetics;t-coffee;time complexity	Feng Yue;Jijun Tang	2007	2007 IEEE International Conference on Bioinformatics and Biomedicine (BIBM 2007)	10.1109/BIBM.2007.7	biology;divide and conquer algorithms;binary tree;multiple sequence alignment;computer science;bioinformatics;theoretical computer science;sequence alignment;data mining;sequence;genetics;alignment-free sequence analysis;phylogenetics	Comp.	-1.0658145357827036	-52.0702382839905	44952
1fc3dd6ffb8971b6f401e764690edfce1e780658	design and analysis of genetic fuzzy systems for intrusion detection in computer networks	high dimensionality;learning;fuzzy rules;fuzzy rule extraction;combinatorial problems;intrusion detection;rule learning;computer network;approximate reasoning;real world application;pattern recognition;genetic algorithm;genetic algorithms;evolutionary algorithm;genetic fuzzy system;fuzzy system;intrusion detection system	Research highlights? We present three kinds of genetic fuzzy systems for intrusion detection problem. ? These IDSs can detect normal and abnormal behaviors in computer networks efficiently. ? Computer simulations demonstrate high performance of the proposed IDSs.? GFSs are able to develop accurate and also interpretable intrusion detection systems. The capability of fuzzy systems to solve different kinds of problems has been demonstrated in several previous investigations. Genetic fuzzy systems (GFSs) hybridize the approximate reasoning method of fuzzy systems with the learning capability of evolutionary algorithms. The objective of this paper is to design and analysis of various kinds of genetic fuzzy systems to deal with intrusion detection problem as a new real-world application area which is not previously tackled with GFSs. The resulted intrusion detection system would be capable of detecting normal and abnormal behaviors in computer networks. We have presented three kinds of genetic fuzzy systems based on Michigan, Pittsburgh and iterative rule learning (IRL) approaches to deal with intrusion detection as a high-dimensional classification problem. Experiments were performed with DARPA data sets which have information on computer networks, during normal and intrusive behaviors. The paper presents some results and compares the performance of different generated fuzzy rule sets in detecting intrusion in a computer network according to three different types of genetic fuzzy systems.	fuzzy control system;genetic fuzzy systems;intrusion detection system	Mohammad Saniee Abadeh;Hamid Mohamadi;Jafar Habibi	2011	Expert Syst. Appl.	10.1016/j.eswa.2010.12.006	anomaly-based intrusion detection system;intrusion detection system;genetic algorithm;computer science;artificial intelligence;neuro-fuzzy;machine learning;evolutionary algorithm;data mining	Security	7.251055510094535	-37.014150038668525	44963
71d7440ca0f5fc54e13d0e37b4193dbdd56de180	lvq algorithm with instance weighting for generation of prototype-based rules	prototype based rules;cost function;rule based;similarity based methods;data mining;fuzzy logic;context dependent;knowledge based clustering;learning vector quantization;knowledge base	Crisp and fuzzy-logic rules are used for comprehensible representation of data, but rules based on similarity to prototypes are equally useful and much less known. Similarity-based methods belong to the most accurate data mining approaches. A large group of such methods is based on instance selection and optimization, with the Learning Vector Quantization (LVQ) algorithm being a prominent example. Accuracy of LVQ depends highly on proper initialization of prototypes and the optimization mechanism. This paper introduces prototype initialization based on context dependent clustering and modification of the LVQ cost function that utilizes additional information about class-dependent distribution of training vectors. This approach is illustrated on several benchmark datasets, finding simple and accurate models of data in the form of prototype-based rules.	algorithm;attempt;benchmark (computing);breast carcinoma;cluster analysis;cognition disorders;cognitive science;concentrate dosage form;concept learning;data mining;data model;data structure;distance;feature vector;futures and promises;fuzzy logic;kernel method;learning vector quantization;linear discriminant analysis;loss function;mathematical optimization;nonlinear system;optimization mechanism;prototype;reason applied by forcast logic to project this vaccine:finding:point in time:^patient:nominal;relevance;rule (guideline);selection algorithm;silo (dataset);sonar;user space;statistical cluster	Marcin Blachnik;Wlodzislaw Duch	2011	Neural networks : the official journal of the International Neural Network Society	10.1016/j.neunet.2011.05.013	fuzzy logic;knowledge base;learning vector quantization;computer science;artificial intelligence;machine learning;context-dependent memory;pattern recognition;data mining	ML	8.476836285575189	-44.520038526493906	45021
18d647a07355dc6a1918740947afe0a635923891	topology constraints in graphical models		Graphical models are a very useful tool to describe and understand natural phenomena, from gene expression to climate change and social interactions. The topological structure of these graphs/networks is a fundamental part of the analysis, and in many cases the main goal of the study. However, little work has been done on incorporating prior topological knowledge onto the estimation of the underlying graphical models from sample data. In this work we propose extensions to the basic joint regression model for network estimation, which explicitly incorporate graph-topological constraints into the corresponding optimization approach. The first proposed extension includes an eigenvector centrality constraint, thereby promoting this important prior topological property. The second developed extension promotes the formation of certain motifs, triangle-shaped ones in particular, which are known to exist for example in genetic regulatory networks. The presentation of the underlying formulations, which serve as examples of the introduction of topological constraints in network estimation, is complemented with examples in diverse datasets demonstrating the importance of incorporating such critical prior knowledge.	algorithm;eigenvector centrality;gene regulatory network;graphical model;ibm notes;interaction;mathematical optimization;next-generation access;optimization problem;sequence motif	Marcelo Fiori;Pablo Musé;Guillermo Sapiro	2012			combinatorics;machine learning;data mining;mathematics;statistics	AI	13.242251954837167	-50.7517264092952	45065
f2637621dfde438d67453395380620afe2a1dd5b	learning from missing data: a reflex fuzzy min-max neural network approach.	missing data;neural network	A treatment for herpes virus infections comprises topical application of a suspension of boric acid, tannic acid, and salicylic acid, preferably in an ethanol solvent/carrier. Typically, a solution would have about 15% wt each of tannic and boric acids to 3% wt salicylic acid. After treatment, herpes lesions disappear within 4-5 days.	artificial neural network;missing data	Abhijeet V. Nandedkar;Prabir Kumar Biswas	2007			probabilistic neural network;missing data;computer science;neuro-fuzzy;machine learning;pattern recognition;time delay neural network;artificial neural network	ML	11.520958450900398	-26.86511869536644	45075
360a6347e71fd5ebe0e842ac3a12c38fbac2b834	neurosymbolic integration: unified versus hybrid approaches		Since the mid-1980s, researchers have been pursuing the goal of neurosymbolic integration, i.e., the construction of systems capable of both symbolic and neural processing. We distinguish two major avenues toward this goal: the uniied and the hybrid approaches. Whereas the uniied approach claims that full symbol processing functionalities can be achieved via neural networks alone, the hybrid approach is premised on the necessity and complementarity of symbolic and neural structures and processes. This paper attempts to clarify and compare the assumptions, mechanisms as well as the open problems of both approaches. Since the resurgence of connectionist research in the mid-1980s, neurosymbolic integration (nsi))the incorporation of symbolic and neural processing func-tionalities in a single systemmhas been a persistent research goal. Attempts at nsi can be classiied into two major approaches according to the particular blend of symbolic and neural structures and processors involved. In the uniied approach, more widely known as connectionist symbol processing (csp) 6], neural networks are used as building blocks to create a cognitive architecture capable of complex symbol processing. The uniied approach is premised on the claim that there is no need for symbolic structures and processes as such: full symbol processing functionalities can be achieved using neural networks alone. The hybrid approach integrates complete symbolic and connectionist modules: in addition to neural networks, it implements both symbolic structures and processorsse.g., rule interpreters, parsers, case-based reasoners and theorem provers. The hybrid approach rests on the assumption that only the synergistic combination of neural and symbolic structures and processes can attain the full gamut of cognitive and computational powers which is beyond the reach of a single paradigm.	artificial neural network;central processing unit;cognitive architecture;complementarity theory;computation;connectionism;independence day: resurgence;parsing;programming paradigm;synergy;system integration	Melanie Hilario;Yannick Lallement;Frédéric Alexandre	1995			machine learning;artificial intelligence;computer science	ML	8.55526373853685	-26.623606834061317	45120
341d584d9b2ac60681c9be34571bd5b54e7a95cf	simple, efficient, and neural algorithms for sparse coding		Sparse coding is a basic task in many fields including signal processing, neuroscience and machine learning where the goal is to learn a basis that enables a sparse representation of a given set of data, if one exists. Its standard formulation is as a non-convex optimization problem which is solved in practice by heuristics based on alternating minimization. Recent work has resulted in several algorithms for sparse coding with provable guarantees, but somewhat surprisingly these are outperformed by the simple alternating minimization heuristics. Here we give a general framework for understanding alternating minimization which we leverage to analyze existing heuristics and to design new ones also with provable guarantees. Some of these algorithms seem implementable on simple neural architectures, which was the original motivation of Olshausen and Field (1997a) in introducing sparse coding. We also give the first efficient algorithm for sparse coding that works almost up to the information theoretic limit for sparse recovery on incoherent dictionaries. All previous algorithms that approached or surpassed this limit run in time exponential in some natural parameter. Finally, our algorithms improve upon the sample complexity of existing approaches. We believe that our analysis framework will have applications in other settings where simple iterative algorithms are used.	algorithm;compressed sensing;convex optimization;dictionary;heuristic (computer science);iterative method;machine learning;mathematical optimization;neural coding;optimization problem;provable security;sample complexity;signal processing;sparse approximation;sparse matrix;theory;time complexity	Sanjeev Arora;Rong Ge;Tengyu Ma;Ankur Moitra	2015			mathematical optimization;computer science;theoretical computer science;machine learning;sparse approximation;statistics	ML	23.925776443639684	-32.99452286308024	45128
20c83fbe8935519671a0ffb3d6f8a60be5cfa7a2	an error tolerant environment of multilayer perceptrons with controlled learning	multilayer perceptron		error-tolerant design;multilayer perceptron	Wellington C. P. Yu;Hoon heng Teh	1988	Neural Networks	10.1016/0893-6080(88)90354-1	artificial intelligence;machine learning;distributed computing	ML	12.545509246023393	-27.08532532260831	45133
b5028e718b9194d87d7f7c859de82f23ed59ad28	performance of deep learning algorithms vs. shallow models, in extreme conditions - some empirical studies		Deep convolutional neural networks (DCNN) successfully exhibit exceptionally good classification performance, despite their massive size. The effect of a large value of noise term, as irreducible error in Expected Prediction Error (EPE) is first discussed. Through extensive systematic experiments, we show how in extreme conditions the traditional approaches fare at par with large neural networks, which generalize well in practice. Specifically, our experiments establish that state-of-the-art convolutional networks trained for classification barely fit a random labeling of the training data as an extreme condition to learn. This phenomenon is quantitatively unaffected even if we train the CNNs with completely inseparable data. This can be due to large degree of corruption of the entire data by random noise or random labels associated with data due to observation error. We corroborate these experimental findings by showing that depth six CNN (VGG-6) fails to overcome large noise in image signals.		Samik Banerjee;Prateep Bhattacharjee;Sukhendu Das	2017		10.1007/978-3-319-69900-4_72	computer science;empirical research;support vector machine;convolutional neural network;artificial intelligence;machine learning;pattern recognition;artificial neural network;mean squared prediction error;deep learning;training set;phenomenon	SE	20.32150093719061	-50.03740770473705	45161
5136d3cfc1beff6f2db755e535754e98a84e307f	manufacturing process control through integration of neural networks and fuzzy model	systeme commande;sistema control;fuzzy neural network;learning algorithm;fuzzy neural nets;sensor integration;logique floue;logica difusa;reseau neuronal flou;algorithme apprentissage;backpropagation;statistical regression;analyse entree sortie;stability;fuzzy logic;control proceso;control system;estimation erreur;production and process control;error estimation;regresion multiple;regresion estadistica;backpropagation algorithm;estimacion error;process control;autoorganizacion;input output analysis;algorithme retropropagation;self organization;learning from experience;analisis entrada salida;stabilite;regression statistique;algoritmo aprendizaje;regression multiple;multi sensor integration;commande processus;autoorganisation;estabilidad;fuzzy model;artificial neural network;neural network;algoritmo retropropagacion;multiple regression	Artificial neural networks (ANNs) and fuzzy logic have been widely applied in many areas. This research is trying to discuss the integration of these two technologies. Three fuzzy models are utilized to update dynamically the training parameters in order to speed up the training. In addition, a fuzzy model is proposed which is self-organizing and self-adjusting, and able to learn from experience. In a self-organizing and self-adjusting fuzzy model (SOSAFM), the inputs and outputs are partitioned by Kohonen's feature mapping and the premise and consequence parameters are updated through an error backpropagation (EBP)-type learning algorithm. Physical experiments for manufacturing process control are implemented to evaluate the proposed methods. The results showed that updating the training parameters by using fuzzy models can accelerate the training speed. Moreover, SOSAFM is better than the multiple regression and artificial neural network both in speed and accuracy for the purpose of multi-sensor integration. © 1998 Published by Elsevier Science B.V. All rights reserved.	algorithm;artificial neural network;backpropagation;experiment;fuzzy concept;fuzzy logic;organizing (structure);self-organization;self-organizing map	R. J. Kuo;P. H. Cohen	1998	Fuzzy Sets and Systems	10.1016/S0165-0114(96)00382-X	defuzzification;adaptive neuro fuzzy inference system;computer science;artificial intelligence;backpropagation;neuro-fuzzy;machine learning;fuzzy associative matrix;fuzzy set operations;artificial neural network;algorithm	AI	10.443766122173724	-29.47099107709108	45189
13f240a08b75586682d62a25bd2189cc2e584552	ranking via robust binary classification and parallel parameter estimation in large-scale data		We propose RoBiRank, a ranking algorithm that is motivated by observing a close connection between evaluation metrics for learning to rank and loss functions for robust classification. The algorithm shows a very competitive performance on standard benchmark datasets against other representative algorithms in the literature. On the other hand, in large scale problems where explicit feature vectors and scores are not given, our algorithm can be efficiently parallelized across a large number of machines; for a task that requires 386, 133× 49, 824, 519 pairwise interactions between items to be ranked, our algorithm finds solutions that are of dramatically higher quality than that can be found by a state-of-the-art competitor algorithm, given the same amount of wallclock time for computation.	algorithm;benchmark (computing);binary classification;care-of address;computation;estimation theory;feature vector;interaction;learning to rank;loss function;mathematical optimization;parallel computing;scalability;stochastic optimization	Hyokun Yun;Parameswaran Raman;S. V. N. Vishwanathan	2014	CoRR		machine learning;pattern recognition;data mining;mathematics;statistics;population-based incremental learning	ML	22.677577697545587	-37.12089680637801	45213
bf7687d96e68042e9c629019a9c3fef22623990a	a weighting k-modes algorithm for subspace clustering of categorical data	k modes algorithm;weight;subspace clustering;categorical data	Traditional clustering algorithms consider all of the dimensions of an input data set equally. However, in the high dimensional data, a common property is that data points are highly clustered in subspaces, which means classes of objects are categorized in subspaces rather than the entire space. Subspace clustering is an extension of traditional clustering that seeks to find clusters in different subspaces categorical data and its corresponding time complexity is analyzed as well. In the proposed algorithm, an additional step is added to the k-modes clustering process to automatically compute the weight of all dimensions in each cluster by using complement entropy. Furthermore, the attribute weight can be used to identify the subsets of important dimensions that categorize different clusters. The effectiveness of the proposed algorithm is demonstrated with real data sets and synthetic data sets. & 2012 Elsevier B.V. All rights reserved.	algorithm;categorical variable;categorization;cluster analysis;clustering high-dimensional data;data point;dataspaces;scalability;sparse matrix;synthetic data;time complexity	Fuyuan Cao;Jiye Liang;Deyu Li;Xingwang Zhao	2013	Neurocomputing	10.1016/j.neucom.2012.11.009	complete-linkage clustering;correlation clustering;constrained clustering;determining the number of clusters in a data set;data stream clustering;subclu;categorical variable;k-medians clustering;fuzzy clustering;flame clustering;canopy clustering algorithm;machine learning;consensus clustering;pattern recognition;cure data clustering algorithm;data mining;mathematics;cluster analysis;single-linkage clustering;brown clustering;weight;dbscan;affinity propagation;clustering high-dimensional data	AI	0.9429226340111947	-41.333558393071186	45233
25b60bf22f6a7d0dc2b35c91d73955d7ba72d6f8	colon cancer survival prediction using ensemble data mining on seer data	machine learning prediction ensemble colon cancer;cancer;surveillance epidemiology and end results program colon cancer survival prediction ensemble data mining seer data colon cancer data seer program supervised classification methods synthetic minority over sampling technique roc curve prediction accuracy multiple classification schemes attribute selection techniques smote balanced set;cancer decision trees colon predictive models data mining accuracy logistics;pattern classification cancer data analysis data mining medical computing;data mining;medical computing;colon cancer;ensemble;data analysis;machine learning;pattern classification;prediction	We analyze the colon cancer data available from the SEER program with the aim of developing accurate survival prediction models for colon cancer. Carefully designed preprocessing steps resulted in removal of several attributes and applying several supervised classification methods. We also adopt synthetic minority over-sampling technique (SMOTE) to balance the survival and non-survival classes we have. In our experiments, ensemble voting of the three of the top performing classifiers was found to result in the best prediction performance in terms of prediction accuracy and area under the ROC curve. We evaluated multiple classification schemes to estimate the risk of mortality after 1 year, 2 years and 5 years of diagnosis, on a subset of 65 attributes after the data clean up process, 13 attribute carefully selected using attribute selection techniques, and SMOTE balanced set of the same 13 attributes, while trying to retain the predictive power of the original set of attributes. Moreover, we demonstrate the importance of balancing the classes of the data set to yield better results.	approximation algorithm;cellular automaton;colon classification;data mining;experiment;machine learning;oversampling;pascal's calculator;preprocessor;receiver operating characteristic;seer-sem;sampling (signal processing);supervised learning;synthetic intelligence	Reda Al-Bahrani;Ankit Agrawal;Alok N. Choudhary	2013	2013 IEEE International Conference on Big Data	10.1109/BigData.2013.6691752	computer science;machine learning;pattern recognition;data mining	DB	13.767560741971177	-41.63664231236226	45255
c28b19d23416b0cec949143be107eb0068c887a5	protein mixture inference as hitting set variants and linear algebra problems	parameterized complexity;fixed parameter tractable;shared peptides;hitting set;protein inference;hypergraph;star editing;union editing;protein quan ti;set cover;shotgun proteomics	This work is dedicated to the problems of protein inference and quantification in bottom-up proteomics, and, in particular, in shotgun proteomics. We adopt a rather classical approach of representing inference problem as a set cover, where proteins are understood as sets of their observations: peptides' masses or sequences. However, we seek concise enumeration of all possible mixtures rather than some optimal mixture. Such enumeration gives insight on how likely every protein is to be in the correct mixture. In general, the corresponding Set Cover instances, are not very hard unless one admits, that there were experimental errors. Therefore we state that the hardest part is to first remove all possible errors. The corresponding computational problem's formulation is provided. We proceed with studying its complexity and performance in practice. Protein quantification problem is modeled in terms of linear systems. We advocate use of shared peptides in the data. It is known that these data makes analysis more difficult and error-prone. We study how bad can be error propagation, if one uses shared peptides. We conclude with a method for adjusting incorrect observations, given that their number is considerably low.	linear algebra;set cover problem	Leonid Molokov	2013			combinatorics;bioinformatics;machine learning;mathematics	Theory	1.557937055807651	-51.51473517393426	45260
382be3998943521ebacc9e84226924f40fb889c3	the generalized dimensionality reduction problem	similarity search;objective function;data representation	The dimensionality reduction problem has been widely studied in the database literature because of its application for concise data representation in a variety of database applications. The main focus in dimensionality reduction is to represent the data in a smaller number of dimensions that the least amount of information is lost. In this paper, we study the dimensionality reduction problem from an entirely different perspective. We discuss methods to find a representation of the data so that a user-defined objective function is optimized. For example, we may desire to find a reduction of the data in which a particular kind of classifier works effectively. Another example (relevant to the similarity search domain) would be a reduction in which the cluster of k closest points provides the best distance based separation from the remaining data set. We discuss a general abstraction for the problem and provide the broad framework of an evolutionary algorithm which solves this abstraction. We test our framework on two separate instantiations of this framework and provide results illustrating the effectiveness and efficiency of our method.	baseline (configuration management);cluster analysis;collaborative filtering;converge;data (computing);data mining;dimensionality reduction;evolutionary algorithm;iterative and incremental development;loss function;nearest neighbour algorithm;optimization problem;proximity problems;reduction strategy (lambda calculus);similarity search;statistical classification	Charu C. Aggarwal	2010		10.1137/1.9781611972801.53	computer science;pattern recognition;artificial intelligence;machine learning;evolutionary algorithm;dimensionality reduction;dimensional reduction;abstraction;external data representation;nearest neighbor search	AI	22.471965939248438	-41.764380029851665	45306
5ba54150ea48e31abc6df8a2f55b1065b26ba1b3	evolvable hardware or learning hardware? induction of state machines from temporal logic constraints	minimisation;hardware field programmable gate arrays machine learning genetic algorithms logic programming artificial neural networks cellular neural networks intelligent robots learning systems cybernetics;learning algorithm;software prototyping;multi valued logic;temporal logic;soft computing;evolutionary programming;evolvable hardware;state machine;software prototyping finite state machines temporal logic minimisation field programmable gate arrays multivalued logic learning artificial intelligence;genetics;fuzzy logic;finite state machines;neural net;learning methods;machine learning;functional decomposition;system design;knowledge acquisition;constraint solving;genetic algorithm;scientific communication;artificial neural net;field programmable gate arrays;learning artificial intelligence;multivalued logic;rough set;learning strategies;occam s razor;reconfigurable hardware;finite state machine;artificial life;dec perle 1 fpga board evolvable hardware learning hardware state machines induction temporal logic constraints finite state machines constraints solving state machine minimization structural mapping functional decomposition multi valued logic functions fpga mapping binary switches learning algorithms;analytical model;approaches to learning	"""Here we advocate an approach to learning hardware based on induction of finite state machines from temporal logic constraints. The method involves training on examples, constraints solving, determinization, state machine minimization, structural mapping, functional decomposition of multi-valued logic functions and relations, and finally, FPGA mapping. In our approach, learning takes place on the level of constraint acquisition and functional decomposition rather than on the lower level of programming binary switches. Our learning strategy is based on the principle of Occam's Razor, facilitating generalization and discovery. We implemented several learning algorithms using DEC-PERLE-1 FPGA board. 1 Evolving in hardware versus learning in hardware In recent years the scientific community has witnessed rapid developments in the area of Soft Computing. These approaches include Artificial Neural Nets (ANNs), Cellular Neural Nets (CNNs), Fuzzy Logic, Rough Sets, Genetic Algorithms (GAs), Genetic and Evolutionary Programming. Several mixed approaches have also been created. In different ways, they combine elements of these areas with the goal of solving complex and poorly defined problems that could not be tackled by earlier, analytic models. What is common to all these approaches is that they propose a way of automatic learning by the system. The computer is taught by examples rather than completely programmed (instructed) in what to do. This philosophy also dominates areas of Artificial Life, solving problems by analogy to nature, decision making, knowledge acquisition, and new approaches to intelligent robotics. Machine Learning thus becomes a new and general system design paradigm unifying these previously disconnected research areas. It starts to become a new hardware construction paradigm as well. Recently, the term Evolvable Hardware (EHW) has been coined [15] which means the realization of genetic algorithm (GA) in reconfigurable hardware. It is exemplified by Brain Builder CBM [15]. The EHW approach to computing has raised considerable interest and enthusiasm among some researchers, but scepticism among others. One may ask: """"Why genetic algorithm""""? Our experience prompts us to question the usefulness of GA as a sole learning method to reconfigure binary FPGAs. Instead, we propose the Learning Hardware approach, which consists in using feedback from the environment (for instance, positive and negative examples from the trainer) to create a sequential network and subsequently realizing this network in FPGAs. Our approach of Universal Logic Machine [35, 40, 38, 24, 37, 45] proposes the creation of a learning machine based on logic principles, in particular, temporal logic [32, 4, 5, 6, 7], constructive induction [2, 11, 27, 28], and rough set theory [34]. Our software algorithms require fast operations on complex logic expressions and the ability to solve NPcomplete problems such as satisfiability. They should be realized in hardware to obtain the necessary speed-ups. Using a fast prototyping tool, the DEC-PERLE-1 board based on an array of Xilinx FPGAs, we are developing software/configware processors that accelerate the acquisition, synthesis, and optimization of Reactive State Machines. While GA is a simple and practically blind mechanism of Nature, it can be easily realizable in hardware. We believe that this mechanism alone cannot produce good results. (Although it is relatively easy to do crossover and mutation in hardware, the fitness function evaluation is difficult). In contrast, logic algorithms that draw upon human knowledge are optimal and mathematically sophisticated. They lead to high quality learning results: knowledge generalization, discovery, no overfitting, small learning errors [47, 1, 26, 20, 21]. Their software realizations, however, use such complex data structures and controls that it is difficult to realize them in hardware. When we refer to Learning Hardware, we define the term """"learning"""" very broadly, as any mechanism that leads to the improvement of operation; evolution-based learning is therefore included. Although specific learning concepts and their formalities differ from one learning approach to another, what is common is that, in the process of learning, a network (combinational or sequential) is constructed that stores the knowledge acquired in the learning phase. The learned network is next run on old or new data. Responses may be correct or erroneous. The network's behavior is then evaluated by some fitness (cost) functions and the learning and running phases are alternated. The process of solving problems consists of two phases: the phase of learning, which involves constructing and tuning the network, and the phase of acting. The second stage means using knowledge, that is, running the network for data sets. Compared to the process of developing and using a computer, the first stage can be likened to the entire process of conceptualizing, designing, and optimizing a computer, and the second stage to using this computer to perform calculations. You cannot redesign standard computer hardware, however, when it cannot solve a problem correctly. The Learning Hardware will redesign itself automatically using the new learning examples provided to it. 2 Logic rather than evolutionary methods for learning Our ULM approach is based on FPGA technology and associated logic development methods (called Logic Synthesis by the design automation community and Constructive Induction by the Machine Learning community) rather than neural or genetic algorithms. Michie [29] makes a distinction between black-box and knowledge-oriented concept learning systems by introducing concepts of weak and strong criteria. The system satisfies a weak criterium if it uses sample data to generate an updated basis for improved performance on subsequent data. A strong criterion is satisfied if the system communicates concepts learned in symbolic form [28]. Let us observe that ANNs, CNNs, and similar approaches satisfy only the weak criterium while our approach satisfies the strong criterium. We believe that the results of the learning process, and even the process itself, should be rational. They should be similar to those of teaching humans, based on symbolic logic and not on the methods of Nature. Human thinking consists in abstract use of symbols, rather than assigning numeric weights to neurons. Our approach operates on higher and more natural symbolic representation levels. The built-in mathematical optimization techniques (such as graph coloring or satisfiability) support the principle of Occam's Razor, offering solutions that are provably good in the sense of Computational Learning Theory (COLT) [1. 47]. Thus, learning on a symbolic level is the first main point of our approach. In our past research, we have used and compared in software, various network structures for learning: two-level AND/OR (Sum-of-Products (SOP), or Disjunctive-NormalForms (DNF)) [33], decision trees (C4.5), and multi-level decomposition structures [20, 21, 36, 53, 44], as well as various logic, non-logic and mixed optimization methods: search [37], rule-based, set-covering, graph-coloring, genetic algorithm [16, 18] (including mixtures of logic and GA approaches), genetic programming [17], artificial neural nets, and simulated annealing. We compared the resulting complexity of our networks (Occam's Razor), as well as various ways of controlling the number of errors in the learning process [20, 21, 26]. The Decomposed Function Cardinality (DFC) and its extensions for MV logic [1, 20, 21, 44] were used as common measures of complexity, because of their strong theoretically proven properties [1, 47]. Our conclusion, based on these investigations, is that logic approaches and especially the MV decomposition techniques, combined with smart heuristic strategies and good data representations, are usually superior to other approaches due to smaller net complexity and fewer learning errors. In our experience, especially poor results are obtained using genetic algorithms [16, 17, 18]. GA may perform well in other applications, but from both our experience and the literature we could not find a single problem domain in which a GA-based algorithm was superior to a hand-crafted algorithm in the design of a binary or multivalued logic network. This is perhaps because researchers have long experience in creating efficient logic minimization algorithms (for instance, more papers have been written on SOP minimization than perhaps on any other engineering topic). In our approach we want to make use of this accumulated human experience, rather than to """"reinvent"""" algorithms using GA. 3 Learning hardware approach in universal logic machines Developers of evolvable and learning systems agree that, realized with current software or even parallel programming technologies, the learning phase and/or the execution phase are too slow for real-life problems, especially real-time problems. The situation is essentially the same regardless of whether the exhaustive combinatorial search, simulated annealing, or evolutionary algorithms that involve millions of populations are used. Thus, the researchers proposed to speed-up some phases by migrating from software to hardware. Many ambitious projects based on ANNs, cellular logic, DNA, simulated evolution and biologically motivated hardware have been proposed that will perhaps be successful in the future, when realized on molecular or quantum levels. However, many of them are quite impractical in current technologies. Most of the approaches to evolvable hardware use binary Field Programmable Gate Arrays, because now there is simply no other mass-scale hardware reconfigurable (reprogrammable) and relatively inexpensive technology widely available. Since in binary FPGAs everything is realized on the level of binary logic gates and flip-flops, in our opinion, the learning process should be performed on this level also"""	artificial life;artificial neural network;black box;boolean satisfiability problem;c4.5 algorithm;colt;central processing unit;circuit minimization for boolean functions;combinational logic;combinatorial search;computation;computational learning theory;computer hardware;concept learning;covering graph;data structure;decision tree;disjunctive normal form;display resolution;empirical risk minimization;energy level;evolutionary algorithm;evolutionary programming;evolvable hardware;flops;field-programmable gate array;finite-state machine;fitness function;flip-flop (electronics);fuzzy logic;genetic algorithm;genetic programming;graph coloring;heuristic;knowledge acquisition;logic gate;logic programming;logic synthesis;mv-algebra;machine learning;mathematical induction;mathematical optimization;mental representation;network switch;occam's razor;overfitting;parallel computing;population;powerset construction;problem domain;programming paradigm;real life;real-time transcription;relation (database);response surface methodology;robotics;rough set;set theory;simulated annealing;soft computing;software release life cycle;symbol (formal);systems design;temporal logic;occam	Marek A. Perkowski;Alan Mishchenko;Anatoli N. Chebotarev	1999		10.1109/EH.1999.785444	computer science;artificial intelligence;theoretical computer science;machine learning	AI	15.335448675632906	-25.040597822167673	45308
7057fd5c6d9db496269d57eba8bba53d09b4fbe1	variable kernel density estimation in high-dimensional feature spaces		Estimating the joint probability density function of a dataset is a central task in many machine learning applications. In this work we address the fundamental problem of kernel bandwidth estimation for variable kernel density estimation in high-dimensional feature spaces. We derive a variable kernel bandwidth estimator by minimizing the leave-one-out entropy objective function and show that this estimator is capable of performing estimation in high-dimensional feature spaces with great success. We compare the performance of this estimator to state-of-the art maximumlikelihood estimators on a number of representative high-dimensional machine learning tasks and show that the newly introduced minimum leave-one-out entropy estimator performs optimally on a number of highdimensional datasets considered.	kernel (operating system);loss function;machine learning;optimization problem;variable kernel density estimation	Christiaan Maarten van der Walt;Etienne Barnard	2017			kernel (statistics);kernel principal component analysis;kernel bandwidth;kernel embedding of distributions;mathematical optimization;applied mathematics;polynomial kernel;computer science;kernel density estimation;variable kernel density estimation;radial basis function kernel	ML	24.199564232484942	-37.42337931875033	45351
71e92abb1e504d56b3f18b4909d73eee3b6048fb	sobolev training for neural networks		At the heart of deep learning we aim to use neural networks as function approximators – training them to produce outputs from inputs in emulation of a ground truth function or data creation process. In many cases we only have access to input-output pairs from the ground truth, however it is becoming more common to have access to derivatives of the target output with respect to the input – for example when the ground truth function is itself a neural network such as in network compression or distillation. Generally these target derivatives are not computed, or are ignored. This paper introduces Sobolev Training for neural networks, which is a method for incorporating these target derivatives in addition the to target values while training. By optimising neural networks to not only approximate the function’s outputs but also the function’s derivatives we encode additional information about the target function within the parameters of the neural network. Thereby we can improve the quality of our predictors, as well as the data-efficiency and generalization capabilities of our learned function approximation. We provide theoretical justifications for such an approach as well as examples of empirical evidence on three distinct domains: regression on classical optimisation datasets, distilling policies of an agent playing Atari, and on large-scale applications of synthetic gradients. In all three domains the use of Sobolev Training, employing target derivatives in addition to target values, results in models with higher accuracy and stronger generalisation.	approximation algorithm;artificial neural network;atari;deep learning;encode;emulator;gradient;ground truth;mathematical optimization;synthetic intelligence	Wojciech Czarnecki;Simon Osindero;Max Jaderberg;Grzegorz Swirszcz;Razvan Pascanu	2017			mathematics;machine learning;sobolev space;deep learning;function approximation;ground truth;artificial neural network;artificial intelligence;generalization	ML	21.928900727920745	-31.79692541576495	45443
47104f90ea772f5cedd22d9822bc9c26338616bc	a recurrent newton algorithm and its convergence properties	text;convergence;convergence of numerical methods;coaccion;simulation;contrainte;mean squared errors recurrent newton algorithm convergence properties recurrent neural networks;simulacion;recurrent algorithm;backpropagation;algorithme;algorithm;retropropagation;convergencia;algorithme recurrent;constraint;learning artificial intelligence recurrent neural nets newton method convergence of numerical methods;mean square error;backpropagation algorithm;algorithms;newton method;recurrent neural nets;recurrent neural network;learning artificial intelligence;reseau neuronal;convergence signal processing algorithms backpropagation algorithms output feedback recurrent neural networks target recognition neural networks feedforward neural networks process control system identification;retropropagacion;algorithme newton;newton algorithm;red neuronal;neural network;algoritmo	In this paper a recurrent Newton algorithm for an important class of recurrent neural networks is introduced. It is noted that a suitable constraint must be imposed on recurrent variables to ensure proper convergence behavior. The simulation results show that the proposed Newton algorithm with the suggested constraint performs uniformly better than the backpropagation algorithm and the Newton algorithm without the constraint, in terms of mean-squared errors.	algorithm;artificial neural network;backpropagation;convergence (action);neural network simulation;newton;newton's method in optimization;recurrent neural network	Chung-Ming Kuan	1995	IEEE transactions on neural networks	10.1109/72.377987	mathematical optimization;computer science;artificial intelligence;backpropagation;machine learning;artificial neural network;difference-map algorithm	ML	17.415576662792162	-28.04116934662085	45507
28f301bf5acc9ed610f9efe1096ca070675296c4	finding structure in brownian motion through correspondence analysis	minimum variance;efficient market hypothesis;brownian motion;data stream;qualitative data;time series;cluster analysis;data aggregation;correspondence analysis;geometric brownian motion;time series prediction	We study the use of categorical or qualitative data coding, as used commonly in correspondence analysis, for finding faint structure in financial time series. The overall objective is to use faint patterns in such data streams for prediction. We recall relevant definitions from correspondence analysis, in particular the simultaneous spatial and clustering analysis which is facilitated by it. We study in some depth a data set of financial futures (daily highs) in order to show that this approach to faint pattern finding, at an appropriate resolution level, works very well in practice.	brownian motion;category theory;cluster analysis;convenient vector space;correspondence analysis;euclidean distance;futures and promises;hierarchical clustering;map projection;resolution (logic);scalability;semiconductor industry;time series	Fionn Murtagh	2003	CoRR		econometrics;data mining;mathematics;correspondence analysis;multiple correspondence analysis;statistics	ML	0.4945201837599477	-33.16892824704584	45525
8e8dab6472b14f914d16fa7ce10a2339a3c0a0b4	hierarchical support vector machines for multi-class pattern recognition	learning algorithm;pattern classification learning automata;learning automata;support vector machines pattern recognition support vector machine classification machine learning statistical learning classification tree analysis voting binary trees statistics tree graphs;statistical learning theory;multi class classification;pattern classification;pattern recognition;binary classification;support vector machine;binary trees multi class pattern recognition support vector machines learning algorithms statistical learning theory binary classification multi class classification;binary tree	Support vector machines (SVM) are learning algorithms derived from statistical learning theory. The SVM approach was originally developed for binary classification problems. In this paper SVM architectures for multi-class classification problems are discussed, in particular we consider binary trees of SVMs to solve the multi-class problem. Numerical results for different classifiers on a benchmark data set of handwritten digits are presented.		Friedhelm Schwenker	2000		10.1109/KES.2000.884111	semi-supervised learning;statistical classification;support vector machine;least squares support vector machine;kernel method;algorithmic learning theory;feature vector;feature;computer science;online machine learning;machine learning;linear classifier;multiclass classification;pattern recognition;data mining;learning classifier system;relevance vector machine;computational learning theory;active learning;structured support vector machine;one-class classification	Vision	19.68617206717391	-38.951503021982006	45534
66e7458d1367e9a3206316e6ba4722657c98b6bb	interleaving forward backward feature selection		Selecting appropriate features has become a key task when dealing with high-dimensional data. We present a new algorithm designed to find an optimal solution for classification tasks. Our approach combines forward selection, backward elimination and exhaustive search. We demonstrate its capabilities and limits using artificial and real world data sets. Regarding artificial data sets interleaving forward backward selection performs similar as other well known feature selection methods.	algorithm;brute-force search;feature selection;forward error correction;stepwise regression	Michael Siebers;Ute Schmid	2010			machine learning;computer science;artificial intelligence;feature selection;interleaving	AI	10.441414764156777	-43.330972523259675	45616
126b8e4a74928108a019603566a2b3823a2cb364	an efficient randomised sphere cover classifier	milton friedman;rank sum tests;bias variance decomposition;gene expression datasets;sphere cover;randomised classifiers;universities;sphere covering;isolation;bias decomposition;data management;filters;higher education;sphere covers;university of california;data mining;gene expression dataset;non deterministic classifiers;training data;intelligent data analysis;accuracy;pruning;nearest neighbour classifiers;classifier;ensembles;feature filtering;non parametric tests;uc irvine;randomisation;statistical tests;algorithms;data modelling;cross validation;variance decomposition;benchmark datasets;uci machine learning repository;usa;instance based classifiers;set sizes;fast classifiers	This paper describes an efficient randomised sphere cover classifier (αRSC), that reduces the training dataset size without loss of accuracy when compared to nearest neighbour classifiers. The motivation for developing this algorithm is the desire to have a non-deterministic, fast, instance-based classifier that performs well in isolation but is also ideal for use with ensembles. Essentially we trade off decreased testing time for increased training time whilst retaining the simple and intuitive nature of instance-based classifiers. We use 24 benchmark datasets from UCI repository and six gene expression datasets for evaluation. The first set of experiments demonstrate the basic benefits of sphere covering. We show that there is no significant difference in accuracy between the basic αRSC algorithm and a nearest neighbour classifier, even though αRSC compresses the data by up to 75%. We then describe a pruning algorithm that removes spheres that contain α or fewer training instances and compare the results to three data reduction algorithms. The experiments show better average data reduction (89.5%) and improved overall accuracy. The second set of experiments demonstrate that when we set the α parameter through cross validation, the resulting αRSC algorithm outperforms several well known classifiers when compared using the Friedman rank sum test. Thirdly, we test the usefulness of αRSC when used with three attribute filtering methods on six gene expression datasets. Finally, we highlight the benefits of pruning with a bias/variance decomposition. In conclusion, we discuss why the randomisation inherent in αRSC makes them an ideal ensemble component and outline our future direction.	benchmark (computing);cross-validation (statistics);experiment;feature selection;instance-based learning;k-nearest neighbors algorithm;kernel method;model selection;naive bayes classifier;qr decomposition;variance reduction;while	Reda Younsi;Anthony J. Bagnall	2012	IJDMMM	10.1504/IJDMMM.2012.046808	nonparametric statistics;data modeling;training set;statistical hypothesis testing;isolation;classifier;data management;computer science;pruning;machine learning;pattern recognition;data mining;accuracy and precision;higher education;variance decomposition of forecast errors;cross-validation;statistics	ML	14.45997962509489	-40.92579347323848	45639
64c54a9c8a9e1f8f4d24ff3e44ded468dbe1ed86	the growing hierarchical self-organizing map: exploratory analysis of high-dimensional data	unsupervised learning;hierarchical clustering;high dimensionality;neural networks;hierarchical architecture;exploratory analysis;neural net architecture;pattern recognition growing hierarchical self organizing map high dimensional data analysis unsupervised neural network data mining ghsom hierarchical architecture unsupervised learning hierarchical relations;data mining;data analysis;navigation;high dimensional data analysis;data mining application;data analysis data mining space technology pattern recognition unsupervised learning navigation neural networks functional analysis pattern analysis multidimensional systems;functional analysis;self organising feature maps;high dimensional data;pattern recognition;unsupervised neural network;self organized map;pattern analysis;pattern recognition data analysis self organising feature maps neural net architecture data mining unsupervised learning;space technology;ghsom;multidimensional systems;hierarchical relations;growing hierarchical self organizing map;artificial neural network;exploratory data analysis;neural network	The self-organizing map (SOM) is a very popular unsupervised neural-network model for the analysis of high-dimensional input data as in data mining applications. However, at least two limitations have to be noted, which are related to the static architecture of this model as well as to the limited capabilities for the representation of hierarchical relations of the data. With our novel growing hierarchical SOM (GHSOM) we address both limitations. The GHSOM is an artificial neural-network model with hierarchical architecture composed of independent growing SOMs. The motivation was to provide a model that adapts its architecture during its unsupervised training process according to the particular requirements of the input data. Furthermore, by providing a global orientation of the independently growing maps in the individual layers of the hierarchy, navigation across branches is facilitated. The benefits of this novel neural network are a problem-dependent architecture and the intuitive representation of hierarchical relations in the data. This is especially appealing in explorative data mining applications, allowing the inherent structure of the data to unfold in a highly intuitive fashion.	adaptive architecture;algorithm;artificial neural network;biologic preservation;biological neural networks;cluster analysis;collections (publication);data collection;data mining;experiment;global illumination;information retrieval;navigation;network model;neural network simulation;organizing (structure);requirement;self-organization;self-organizing map;unsupervised learning;von neumann architecture;anatomical layer;benefit;statistical cluster	Andreas Rauber;Dieter Merkl;Michael Dittenbach	2002	IEEE transactions on neural networks	10.1109/TNN.2002.804221	navigation;multidimensional systems;computer science;machine learning;pattern recognition;data mining;hierarchical clustering;space technology;data analysis;exploratory data analysis;artificial neural network;clustering high-dimensional data	ML	5.699276571296828	-34.25185055030003	45658
9a01b3eb49973808d072c125e676b1b3d154df96	cross-guided clustering: transfer of relevant supervision across tasks	transfer;school of automation;multitask;computer science automation formerly;cluster alignment	Lack of supervision in clustering algorithms often leads to clusters that are not useful or interesting to human reviewers. We investigate if supervision can be automatically transferred for clustering a target task, by providing a relevant supervised partitioning of a dataset from a different source task. The target clustering is made more meaningful for the human user by trading-off intrinsic clustering goodness on the target task for alignment with relevant supervised partitions in the source task, wherever possible. We propose a cross-guided clustering algorithm that builds on traditional k-means by aligning the target clusters with source partitions. The alignment process makes use of a cross-task similarity measure that discovers hidden relationships across tasks. When the source and target tasks correspond to different domains with potentially different vocabularies, we propose a projection approach using pivot vocabularies for the cross-domain similarity measure. Using multiple real-world and synthetic datasets, we show that our approach improves clustering accuracy significantly over traditional k-means and state-of-the-art semi-supervised clustering baselines, over a wide range of data characteristics and parameter settings.	algorithm;benchmark (computing);cluster analysis;dhrystone;document;experiment;k-means clustering;loss function;optimization problem;relevance;semi-supervised learning;semiconductor industry;similarity measure;synthetic intelligence;vocabulary;wordnet	Indrajit Bhattacharya;Shantanu Godbole;Sachindra Joshi;Ashish Verma	2012	TKDD	10.1145/2297456.2297461	correlation clustering;constrained clustering;data stream clustering;human multitasking;fuzzy clustering;flame clustering;computer science;data science;canopy clustering algorithm;machine learning;consensus clustering;cure data clustering algorithm;data mining;cluster analysis;brown clustering;clustering high-dimensional data	ML	20.601192096512538	-42.790299638283194	45666
0cdf9559f75e6d245c4c4de82b83f3687ae6cafb	enhancing accuracy of multilabel classification by extracting hierarchies	cluster algorithm;complexity theory;prediction algorithms accuracy clustering algorithms training complexity theory manganese buildings;text mining;multilabel classification;training;prediction algorithms;taxonomy generation;data mining;manganese;logarithmic testing complexity multilabel classification hierarchy extraction maximal f measure phocs algorithm linear training;accuracy;hierarchy extraction;pattern classification;clustering algorithms;text mining multilabel classification taxonomy generation hierarchy extraction;buildings;pattern classification data mining	A novel algorithm of extracting hierarchies with the maximal F-measure for improving multilabel classification performance, the PHOCS, builds Predicted Hierarchy Of Classifiers. Nodes contain classifiers, and each intermediate node corresponds to a set of labels, and a leaf node to a single label. Any classifier in the extracted hierarchy deals with a considerably smaller set of labels as compared to the number L of labels, and with a more balanced training distribution. This leads to an improved classification performance. Our method has linear training and logarithmic testing complexity with respect to L. The experiment was conducted on 4 multilabel datasets and it has confirmed the effectiveness of the PHOCS algorithm.	algorithm;cluster analysis;experiment;maximal set;performance prediction;statistical classification;tree (data structure);weka	Alexander V Ulanov;German Sapozhnikov;Nikolay Lyubomishchenko;Vladimir Polutin;Georgy L. Shevlyakov	2011	2011 22nd International Workshop on Database and Expert Systems Applications	10.1109/DEXA.2011.29	text mining;computer science;manganese;machine learning;pattern recognition;data mining;statistics	Vision	13.128718927917285	-46.43735541273356	45686
870f8b3286eb2927a57bcfcee2d02897109a70db	revealing community structures by ensemble clustering using group diffusion		Abstract We propose an ensemble clustering approach using group diffusion to reveal community structures in data. We represent data points as a directed graph and assume each data point belong to single cluster membership instead of multiple memberships. The method is based on the concept of ensemble group diffusion with a parameter to represent diffusion depth in clustering. The ability to modulate the diffusion-depth parameter by varying it within a certain interval allows for more accurate construction of clusters. Depending on the value of the diffusion-depth parameter, the presented approach can determine very well both local clusters and global structure of data. At the same time, the ability to combine single outcomes of the method results in better cluster segmentation. Due to this property, the proposed method performs well on data sets where other conventional clustering methods fail. We test the method with both simulated and real-world data sets. The results support our theoretical conjectures on improved accuracy compared to other selected methods.	cluster analysis	Elena Ivannikova;Hyunwoo Park;Timo Hämäläinen;Kichun Lee	2018	Information Fusion	10.1016/j.inffus.2017.09.013	mathematics;artificial intelligence;machine learning;pattern recognition;data point;cluster (physics);directed graph;cluster analysis;data set	HCI	1.2573341168106607	-42.27842886390301	45704
