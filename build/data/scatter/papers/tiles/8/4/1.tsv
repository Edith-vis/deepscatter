id	title	keywords	abstract	entities	authors	year	journal	doi	fos	area	x	y	ix
0395449defb57a8513b1488e148a8faec6aa94a2	prediction of normal boiling points of hydrocarbons from molecular structure	molecular structure	Computer assisted methods are used to investigate the relationship between normal boiling point and molecular structure for a set of hydrocarbons. Multiple linear regression methods are used to develop a six-variable linear model with a low root mean square (rms) error. The six descriptors in the linear model are also used to develop a computational neural network model with a significantly lower rms error. The methodology used in this study is also compared to Joback's group contribution method to estimate physical properties. The methods used here are found to be superior to Joback's method. However, when one additional variable encoding the square root of the molecular weight is added to Joback's groups, an excellent model is developed.	artificial neural network;linear model;mean squared error;network model;newton's method	Matthew D. Wessel;Peter C. Jurs	1995	Journal of Chemical Information and Computer Sciences	10.1021/ci00023a010	chemistry;molecule;computer science;quantum mechanics	Comp.	12.81892937536904	-57.40002676839506	16299
dfd26869f0690b4615869886ef695df0b6ff373d	biologically inspired dictionary learning for visual pattern recognition		Holonomic brain theory provides an understanding of neural system behaviour. It is argued that recognition of objects in mammalian brain follows a sparse representation of responses to bar-like structures. We considered different scales and orie ntations of Gabor wavelets to form a dictionary. While previous works in the literature used greedy pursuit based methods for sparse coding, this work takes advantage of a locally competitive algorithm (LCA) which calculates more regular sparse coefficients by combining the interactions of artif icial neurons. Moreover the proposed learning algorithm can be implemented in parallel processing which makes it efficient for real-time application s. A complex-valued synergetic neural network is train ed using a quantum particle swarm optimization to perform a classification test. Finally, we provide an experimental real application for biological implementation of sparse dictionary learning to rec ognize emotion using body expression. Classificatio n results are promising and quite comparable to the r ecognition rate by human response.	artificial neural network;coefficient;gabor wavelet;greedy algorithm;interaction;machine learning;mathematical optimization;neural coding;parallel computing;particle swarm optimization;pattern recognition;real-time clock;real-time computing;sparse approximation;sparse dictionary learning;sparse matrix;spiking neural network;synergetics (fuller);synergetics (haken)	Ali Memariani;Chu Kiong Loo	2013	Informatica (Slovenia)		mathematical optimization;speech recognition;k-svd;computer science;artificial intelligence;machine learning;mathematics;algorithm	AI	21.98623964070225	-55.62979332379224	16367
72a08eefaca94d6111b9bddd5fbec7dfa8f9df7d	hihmm: bayesian non-parametric joint inference of chromatin state maps	software;animals;bayes theorem;journal article;histones;gene expression regulation developmental;chromatin immunoprecipitation;chromatin;promoter regions genetic;drosophila melanogaster;humans;computational biology;statistics nonparametric;regulatory sequences nucleic acid	MOTIVATION Genome-wide mapping of chromatin states is essential for defining regulatory elements and inferring their activities in eukaryotic genomes. A number of hidden Markov model (HMM)-based methods have been developed to infer chromatin state maps from genome-wide histone modification data for an individual genome. To perform a principled comparison of evolutionarily distant epigenomes, we must consider species-specific biases such as differences in genome size, strength of signal enrichment and co-occurrence patterns of histone modifications.   RESULTS Here, we present a new Bayesian non-parametric method called hierarchically linked infinite HMM (hiHMM) to jointly infer chromatin state maps in multiple genomes (different species, cell types and developmental stages) using genome-wide histone modification data. This flexible framework provides a new way to learn a consistent definition of chromatin states across multiple genomes, thus facilitating a direct comparison among them. We demonstrate the utility of this method using synthetic data as well as multiple modENCODE ChIP-seq datasets.   CONCLUSION The hierarchical and Bayesian non-parametric formulation in our approach is an important extension to the current set of methodologies for comparative chromatin landscape analysis.   AVAILABILITY AND IMPLEMENTATION Source codes are available at https://github.com/kasohn/hiHMM. Chromatin data are available at http://encode-x.med.harvard.edu/data_sets/chromatin/.	encode;gene ontology term enrichment;genome;hidden markov model;histone code;histones;inference;map;markov chain;qr code;sequence number;synthetic data;x-linked combined immunodeficiency diseases	Kyung-Ah Sohn;Joshua W. K. Ho;Djordje Djordjevic;Hyun-hwan Jeong;Peter J. Park;Ju Han Kim	2015		10.1093/bioinformatics/btv117	biology;chromatin immunoprecipitation;chromatin;bioinformatics;histone;bayes' theorem;genetics	Comp.	4.164848535950454	-58.57696404749679	16375
cb5a3cd73a6c112320bebbe84503b87d471f089c	how to generate ordered maps by maximizing the mutual information between input and output signals	unsupervised learning;lateral interaction;topographic map;average mutual information;probability distribution;mutual information;information theoretic	A learning rule that performs gradient ascent in the average mutual information between input and an output signal is derived for a system having feedforward and lateral interactions. Several processes emerge as components of this learning rule: Hebb-like modification, and cooperation and competition among processing nodes. Topographic map formation is demonstrated using the learning rule. An analytic expression relating the average mutual information to the response properties of nodes and their geometric arrangement is derived in certain cases. This yields a relation between the local map magnification factor and the probability distribution in the input space. The results provide new links between unsupervised learning and information-theoretic optimization in a system whose properties are biologically motivated.	feedforward neural network;gradient descent;hebbian theory;information theory;interaction;lateral thinking;learning rule;map;mathematical optimization;mutual information;times ascent;topography;unsupervised learning	Ralph Linsker	1989	Neural Computation	10.1162/neco.1989.1.3.402	unsupervised learning;probability distribution;variation of information;topographic map;computer science;machine learning;pattern recognition;mathematics;mutual information;conditional mutual information;interaction information;statistics;pointwise mutual information	ML	20.05169072318309	-67.73718509415274	16377
740b30ece1ab0461a50dd987fe86a46721f99e18	effects of heterogeneous and clustered contact patterns on infectious disease dynamics	random graph;statistical mechanics;social interaction;models theoretical;ordinary differential equation;interpersonal relations;disease susceptibility;contact tracing;journal article;graphs;network analysis;epidemiology;degree distribution;cluster analysis;percolation;probability distribution;network model;population structure;population dynamics;infectious diseases;disease dynamics;algorithms;survey data;humans;network structure;parameter estimation;infectious disease;disease transmission infectious;family characteristics;computational biology;spatial clustering;epidemics;article;infectious disease epidemiology;generating functions	The spread of infectious diseases fundamentally depends on the pattern of contacts between individuals. Although studies of contact networks have shown that heterogeneity in the number of contacts and the duration of contacts can have far-reaching epidemiological consequences, models often assume that contacts are chosen at random and thereby ignore the sociological, temporal and/or spatial clustering of contacts. Here we investigate the simultaneous effects of heterogeneous and clustered contact patterns on epidemic dynamics. To model population structure, we generalize the configuration model which has a tunable degree distribution (number of contacts per node) and level of clustering (number of three cliques). To model epidemic dynamics for this class of random graph, we derive a tractable, low-dimensional system of ordinary differential equations that accounts for the effects of network structure on the course of the epidemic. We find that the interaction between clustering and the degree distribution is complex. Clustering always slows an epidemic, but simultaneously increasing clustering and the variance of the degree distribution can increase final epidemic size. We also show that bond percolation-based approximations can be highly biased if one incorrectly assumes that infectious periods are homogeneous, and the magnitude of this bias increases with the amount of clustering in the network. We apply this approach to model the high clustering of contacts within households, using contact parameters estimated from survey data of social interactions, and we identify conditions under which network models that do not account for household structure will be biased.	approximation;cluster analysis;cobham's thesis;communicable diseases;degree distribution;epidemiology;genetic heterogeneity;interaction;node - plant part;parkinson disease;percolation theory;random graph;sample variance;statistical cluster	Erik M. Volz;Joel C. Miller;Alison P. Galvani;Lauren Ancel Meyers	2011		10.1371/journal.pcbi.1002042	probability distribution;random graph;ordinary differential equation;interpersonal relationship;generating function;degree distribution;epidemiology;network analysis;infectious disease;statistical mechanics;bioinformatics;network model;survey data collection;percolation;population dynamics;cluster analysis;graph;estimation theory;contact tracing;statistics	ML	8.753672488680854	-67.43677790014131	16404
1d9c745c027cac281de9cbf2f30b3e3192ee5be2	cellular neural networks for realizing associative memories	realizing associative memories;cellular neural networks;associative memory;cellular neural network	We studied the performance, as associative memory, of a !-dimensional Cellular Neural Network, with local connections and a local memorization law of Hebbian type. We found that, contrarily to what expected, this performance was decreasing with increasing neighbourhood amplitude. We proposed some possible explanations of this result, and a speculation about its cognitive meaning.	artificial neural network	Eliano Pessa;Carlo Palma;Maria Pietronilla Penna	1996			cellular neural network;computer science;bidirectional associative memory;autoassociative memory	ML	22.21028671993893	-69.9425411072413	16483
6bae027f1d7b9164546716281354afcda6355fd6	identifying abnormal network alterations common to traumatic brain injury and alzheimer's disease patients using functional connectome data		The objective of this study is to determine if patients with traumatic brain injury TBI have similar pathological changes in brain network organization as patients with Alzheimer's disease AD using functional connectome data reconstructed from resting-state fMRI rsfMRI. To achieve our objective a novel machine learning technique is proposed that uses a top-down reverse engineering approach to identify abnormal network alterations in functional connectome data that are common to patients with AD and TBI. In general, if the proposed machine learning approach classifies a TBI connectome as AD, then this suggests a common network pathology exists in the connectomes of AD and TBI. The advantage of proposed machine learning technique is two-fold: 1 existing longitudinal TBI imaging data is not required, and 2 the potential risk of a TBI patient converting to AD later in life does not require a lengthy and potentially expensive longitudinal imaging study. Experiments are provided that show the AD pathology learned by our connectome-based machine learning technique is able to correctly identify TBI patients with 80% accuracy. In summary, this research may lead to early interventions that can dramatically increase the quality of life for TBI patients who may convert to AD.	connectome	Davy Vanderweyen;Brent C. Munsell;Jacobo E. Mintzer;Olga Mintzer;Andy Gajadhar;Xun Zhu;Guorong Wu;Jane E. Joseph	2015		10.1007/978-3-319-24888-2_28	artificial intelligence	ML	22.739879146047702	-79.12663317972918	16485
1882f48d7ecdb634b675e40002b9afb64e13a2a6	vascular endothelial growth factor receptor-2 (vegfr-2) inhibitors: development and validation of predictive 3-d qsar models through extensive ligand- and structure-based approaches	vascular endothelial growth factor receptor-2 (vegfr-2);structure-based drug design (sbdd);ligand-based drug design (lbdd);3-d qsar;molecular docking;3-d qsautogrid/r	Vascular endothelial growth factor receptor-2, (VEGFR-2), is a key element in angiogenesis, the process by which new blood vessels are formed, and is thus an important pharmaceutical target. Here, 3-D quantitative structure-activity relationship (3-D QSAR) were used to build a quantitative screening and pharmacophore model of the VEGFR-2 receptors for design of inhibitors with improved activities. Most of available experimental data information has been used as training set to derive optimized and fully cross-validated eight mono-probe and a multi-probe quantitative models. Notable is the use of 262 molecules, aligned following both structure-based and ligand-based protocols, as external test set confirming the 3-D QSAR models' predictive capability and their usefulness in design new VEGFR-2 inhibitors. From a survey on literature, this is the first generation of a wide-ranging computational medicinal chemistry application on VEGFR2 inhibitors.	alignment;basal (phylogenetics);blood vessel;complementarity theory;dvd region code;drug design;endothelial growth factors;hinge (physical object);interaction;lattice boltzmann methods;lb substance;ligands;map;medicinal chemistry;numerous;pharmacophore;protocols documentation;quantitative structure-activity relationship;sandy bridge;test set;vascular endothelial growth factor receptor-2	Rino Ragno;Flavio Ballante;Adele Pirolli;Richard B. Wickersham;Alexandros Patsilinakos;Stéphanie Hesse;Enrico Perspicace;Gilbert Kirsch	2015	Journal of computer-aided molecular design	10.1007/s10822-015-9859-y	pharmacology;bioinformatics;combinatorial chemistry	Graphics	11.341989908643693	-59.11266233010448	16514
316140b93942acca18a58ac652ae6fd2270b615a	the potential of natural product vs neurodegenerative disorders: in silico study of artoflavanocoumarin as bace-1 inhibitor	alzheimer’s disease;artoflavanocoumarin;bace-1;in silico study;natural products	Increasing evidence suggests the beneficial impact of flavonoid-rich nutrition on normal cognitive function. It has been revealed that flavonoids can slow neurodegenerative processes in situations such as Alzheimer's disease (AD). The β-secretase (BACE-1) is one of the most studied targets in AD therapy owing to its role in producing Aβ plaques. In fact the unique role of BACE-1 in pathogenesis of neurodegenerative diseases has made it a druggable target to develop anti-AD agents. Taking into account the anti-amyloidogenic and anti-oxidative properties, flavonoids have received considerable attention as lead candidates for anti-AD drug discovery projects. In continuation to our interest toward rational exploration of potential anti-AD agents, it was attempted to conduct a combined structure based in silico study and explore pharmacophore of a flavanocoumarin derivative as BACE-1 Inhibitor. Ab initio studies showed that both pseudo-axial and pseudo-equatorial conformers could convert to each other freely at room temperature. Within this study it was revealed that artoflavanocoumarin possess essential pharmacophoric groups to inhibit BACE-1. Considering four different protonation states of BACE-1 as di-deprotonated, diprotonated, protonated Asp32 and protonated Asp228, it was also found that affinity of artoflavanocoumarin toward different protonation states of BACE-1could be ranked as Asp32p-Asp228i > di-deprotonated ∼ Asp32i-Asp228p >> diprotonated. PMF study on artoflavanocoumarin showed that it could pass 1.8 kcal/mol free energy barrier from water to DPPC lipid bilayer. Moreover the pros and cons of artoflavanocoumarin as a lead compound were elucidated.		Nima Razzaghi-Asl;Adibe Karimi;Ahmad Ebadi	2018	Computational biology and chemistry	10.1016/j.compbiolchem.2018.10.015		HCI	9.419201416079702	-62.33763707473118	16525
a1f9057b2c01a5b0ac2588ec19765680735ea732	a vector space model approach to identify genetically related diseases		OBJECTIVE The relationship between diseases and their causative genes can be complex, especially in the case of polygenic diseases. Further exacerbating the challenges in their study is that many genes may be causally related to multiple diseases. This study explored the relationship between diseases through the adaptation of an approach pioneered in the context of information retrieval: vector space models.   MATERIALS AND METHODS A vector space model approach was developed that bridges gene disease knowledge inferred across three knowledge bases: Online Mendelian Inheritance in Man, GenBank, and Medline. The approach was then used to identify potentially related diseases for two target diseases: Alzheimer disease and Prader-Willi Syndrome.   RESULTS In the case of both Alzheimer Disease and Prader-Willi Syndrome, a set of plausible diseases were identified that may warrant further exploration.   DISCUSSION This study furthers seminal work by Swanson, et al. that demonstrated the potential for mining literature for putative correlations. Using a vector space modeling approach, information from both biomedical literature and genomic resources (like GenBank) can be combined towards identification of putative correlations of interest. To this end, the relevance of the predicted diseases of interest in this study using the vector space modeling approach were validated based on supporting literature.   CONCLUSION The results of this study suggest that a vector space model approach may be a useful means to identify potential relationships between complex diseases, and thereby enable the coordination of gene-based findings across multiple complex diseases.	acclimatization;alzheimer's disease;base;endocrine system diseases;genbank;hematological disease;inference;information retrieval;knowledge bases;medline;multiple endocrine neoplasia;online mendelian inheritance in man;peer review;prader-willi syndrome;relevance;interest	Indra Neil Sarkar	2012	Journal of the American Medical Informatics Association : JAMIA	10.1136/amiajnl-2011-000480	bioinformatics;data mining	Comp.	4.596113002200884	-57.27791867631385	16641
580fc7de4a7267219ba4f7eac4cb53813354f089	nerve cells as source of time scale and processing density in brain function	time scale;brain function	So far, neural networks have been treated with emphasis on connectivity and synaptic strengths. It is obvious, however, that the response properties of the postsynaptic elements also play a crucial role for the overall performance of a network. Drawing mainly from our own experiments on nerve cells we illustrate how sophisticated response properties dedicate nerve cells to produce desired outputs, enhance processing density and provide time scale to network operations. We note that the response properties are specific for each cell type and open to modification by intrinsic activity and by certain classes of input. It is suggested that adopting new performance in some cases may be better served by changes in postsynaptic response properties rather than by changing synaptic strengths.	neuron	Jens Midtgaard;Jørn Hounsgaard	1989	Int. J. Neural Syst.	10.1142/S0129065789000505	computer science	ML	18.8265507622187	-71.35999962432916	16726
710c8befc6e2c312d74b4c77d34ac6007642f55b	models for the binding of amiodarone to the thyroid hormone receptor	conformational analysis;semiempirical molecular orbital calculations;low energy;derivatives;analogs;rat liver;thyroid hormone receptor;molecular orbital calculation;conformational search;antiarrhythmic drug;thyroxine;computer analysis;molecular mechanics;molecular graphics;thyroid hormone;molecular orbital	The antiarrhythmic drug amiodarone has recently been characterized as the first known thyroid hormone antagonist. Its mode of interaction with the thyroid hormone receptor is therefore of interest. A computational analysis of the conformational flexibility of amiodarone using molecular mechanics and the semiempirical molecular orbital method AM1 has been performed. The molecular mechanics studies show that the low-energy conformations of the benzoylbenzofuran portion of amiodarone can be grouped into 4 distinct classes, while the diethylaminoethoxy side chain is extremely flexible. Conformers representative of the 4 low-energy classes were fitted to an extended thyroid hormone receptor model. Four independent modes in which amiodarone could bind to the thyroid hormone receptor site were evaluated.	amiodarone;anti-arrhythmia agents;austin model 1;class;computational chemistry;molecular mechanics;molecular orbital;seizures;thyroid hormone receptor;thyroid hormones	David K. Chalmers;Sharon L. A. Munro;Magdy N. Iskander;David J. Craik	1992	Journal of computer-aided molecular design	10.1007/BF00124384	endocrinology;stereochemistry;structural analog;chemistry;molecular graphics;molecular mechanics;derivative;molecular orbital;computational chemistry;thyroid hormone receptor;quantum mechanics	Comp.	10.067425068386328	-61.14309722803766	16741
1faaa6a9fc4e4a817e7604f0813d3d6c850acbe7	software for selecting the most informative sets of genomic loci for multi-target microbial typing	software;genomics;multilocus sequence typing;methicillin resistant staphylococcus aureus;computational biology bioinformatics;algorithms;combinatorial libraries;cryptococcus;computer appl in life sciences;streptococcus pneumoniae;microarrays;bioinformatics;bacterial typing techniques	High-throughput sequencing can identify numerous potential genomic targets for microbial strain typing, but identification of the most informative combinations requires the use of computational screening tools. This paper describes novel software - Automated Selection of Typing Target Subsets (AuSeTTS) - that allows intelligent selection of optimal targets for pathogen strain typing. The objective of this software is to maximise both discriminatory power, using Simpson’s index of diversity (D), and concordance with existing typing methods, using the adjusted Wallace coefficient (AW). The program interrogates molecular typing results for panels of isolates, based on large target sets, and iteratively examines each target, one-by-one, to determine the most informative subset. AuSeTTS was evaluated using three target sets: 51 binary targets (13 toxin genes, 16 phage-related loci and 22 SCCmec elements), used for multilocus typing of 153 methicillin-resistant Staphylococcus aureus (MRSA) isolates; 17 MLVA loci in 502 Streptococcus pneumoniae isolates from the MLVA database ( http://www.mlva.eu ) and 12 MLST loci for 98 Cryptococcus spp. isolates. The maximum D for MRSA, 0.984, was achieved with a subset of 20 targets and a D value of 0.954 with 7 targets. Twelve targets predicted MLST with a maximum AW of 0.9994. All 17 S. pneumoniae MLVA targets were required to achieve maximum D of 0.997, but 4 targets reached D of 0.990. Twelve targets predicted pneumococcal serotype with a maximum AW of 0.899 and 9 predicted MLST with maximum AW of 0.963. Eight of the 12 MLST loci were sufficient to achieve the maximum D of 0.963 for Cryptococcus spp. Computerised analysis with AuSeTTS allows rapid selection of the most discriminatory targets for incorporation into typing schemes. Output of the program is presented in both tabular and graphical formats and the software is available for free download from http://www.cidmpublichealth.org/pages/ausetts.html .	adjusted winner procedure;bible concordance;biopolymer sequencing;coefficient;download;genetic selection;graphical user interface;information;methicillin;molecular typing;numerous;pathogenic organism;pneumonia;simpson's rule;staphylococcus aureus;streptococcus pneumoniae;subgroup;table (information);throughput;wallace tree;format	Matthew V. N. O'Sullivan;Vitali Sintchenko;Gwendolyn L. Gilbert	2012		10.1186/1471-2105-14-148	biology;genomics;dna microarray;bioinformatics;multilocus sequence typing;microbiology;genetics	Comp.	-0.10585138878032735	-57.54455869135071	16772
f9329895db85c8de7653312726c0f5755e05ff52	integrated semantic model for complex disease network		To understand biological phenomena, biologists have identified the interactions between biological molecules in vivo. Until recently, all of the unique and interactive information of such molecules has been built into a database and made available online. Among them, there was an effort to understand the relationship of molecules based on biological pathways, and a standard model called BioPAX was made to enable interchange and operation of data. In particular, Pathway Commons integrates other biological data besides biological pathways using BioPAX. We are interested in identifying the molecular mechanisms of disease and recommending drugs for treatment. In addition to data provided by Pathway Commons, additional disease and drug data was added to be used in various analysis. We extended the model to express the data that BioPAX could not cover and converted all the data to RDF based on the model. We integrate and present diverse biological data using semantic technologies from the perspective of representing disease networks. We hope that this information will aid in a deeper understanding of disease and drug recommendations.		Junho Park;Sung-Kwon Yang;Hong-Gee Kim	2018		10.1007/978-3-030-04284-4_28	data science;semantic data model;rdf;knowledge representation and reasoning;biopax : biological pathways exchange;biological data;disease;semantic technology;computer science	ML	-4.483011521510159	-63.406690240161254	16773
ea75f476f70f627a93f5912bf2880de4b3381c35	effects of low level light irradiation on the migration of mesenchymal stem cells derived from rat bone marrow	cellular effects of radiation;f-actin accumulation;wavelength 850 nm;biomembrane transport;light-irradiated msc migration;rat bone marrow mesenchymal stem cell migration;led;phosphorylation;cell mobility;near infrared light emitting diodes;llli;transmembrane migration;enzymes;bone;nir light irradiation;enzymatic activities;energy density;red light irradiation;biomolecular effects of radiation;cell motility;red light emitting diodes;light emitting diodes;low level light irradiation;biological effects of optical radiation;rbmsc migration;in vitro cells;reactive oxygen species;mmp-2;wavelength 630 nm;mmp-9;fluorescence;proteins;stem cells	Low level light irradiation (LLLI) was found to exert positive effects on various cells in vitro. The aim of this study was to investigate the effect of LLLI on the migration of rat bone marrow mesenchymal stem cells (rbMSCs). Light irradiation was applied at the energy density of 4 J/cm2 using red (630 nm) and near infrared (NIR, 850 nm) light emitting diodes (LEDs). Wound healing assay showed both red and NIR light irradiation increased cell mobility. Red and NIR light enhanced transmembrane migration of rbMSCs up to 292.9% and 263.6% accordingly. This agreed with enzymatic activities of MMP-2 and MMP-9 enhanced by irradiation. F-actin accumulation and distribution correlated to increased migration in light-irradiated MSCs. Reactive oxygen species production as well as the expression of pFAK and pNF-κB were elevated after red and NIR LLLI. The study demonstrated that red and NIR LLLI increased rbMSCs migration and identified the phosphorylation of FAK and NF-κB as critical steps for the elevated cell migration upon LLLI.	bone marrow;cell mobility;diode;focal adhesion kinase 1;immunoglobulin lambda-chains;light field;mesenchymal stem cells;noc2l gene;reactive oxygen species;stem of plant;tree accumulation;physical hard work	Wen-Tyng Li;Chih-Wei Chen;Po-Ya Huang	2013	2013 35th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)	10.1109/EMBC.2013.6610452		Visualization	10.657847102377472	-65.02334645694026	16779
18cc31e9b07ea8e5693d05a7f0dec8cb1175e608	dynamic substrate preferences predict metabolic properties of a simple microbial consortium	computational biology bioinformatics;algorithms;computer appl in life sciences;microarrays;bioinformatics	Mixed cultures of different microbial species are increasingly being used to carry out a specific biochemical function in lieu of engineering a single microbe to do the same task. However, knowing how different species’ metabolisms will integrate to reach a desired outcome is a difficult problem that has been studied in great detail using steady-state models. However, many biotechnological processes, as well as natural habitats, represent a more dynamic system. Examining how individual species use resources in their growth medium or environment (exometabolomics) over time in batch culture conditions can provide rich phenotypic data that encompasses regulation and transporters, creating an opportunity to integrate the data into a predictive model of resource use by a mixed community. Here we use exometabolomic profiling to examine the time-varying substrate depletion from a mixture of 19 amino acids and glucose by two Pseudomonas and one Bacillus species isolated from ground water. Contrary to studies in model organisms, we found surprisingly few correlations between resource preferences and maximal growth rate or biomass composition. We then modeled patterns of substrate depletion, and used these models to examine if substrate usage preferences and substrate depletion kinetics of individual isolates can be used to predict the metabolism of a co-culture of the isolates. We found that most of the substrates fit the model predictions, except for glucose and histidine, which were depleted more slowly than predicted, and proline, glycine, glutamate, lysine and arginine, which were all consumed significantly faster. Our results indicate that a significant portion of a model community’s overall metabolism can be predicted based on the metabolism of the individuals. Based on the nature of our model, the resources that significantly deviate from the prediction highlight potential metabolic pathways affected by species-species interactions, which when further studied can potentially be used to modulate microbial community structure and/or function.	amino acids;arginine;batch cell culture techniques;biomass;coculture techniques;culture media;depletion region;dynamical system;exometabolomics;glucose;glutamic acid;glycine;habitat;histidine;interaction;kinetics internet protocol;lysine;maximal set;membrane transport proteins;metabolic process, cellular;metabolism;microbial consortia;microorganism;proline;steady state	Onur Erbilgin;Benjamin P. Bowen;Suzanne M. Kosina;Stefan Jenkins;Rebecca K. Lau;Trent R. Northen	2017		10.1186/s12859-017-1478-2	biology;dna microarray;computer science;bioinformatics;ecology;genetics	AI	7.053952046488501	-63.6903111634305	16844
f9f93b642d8784d359de0b8f0972de83c4c925b7	an efficient algorithm for the stochastic simulation of the hybridization of dna to microarrays	dna;oligonucleotide microarray;efficient algorithm;stochastic simulation;computational biology bioinformatics;nucleic acid hybridization;thermodynamics;algorithms;dna hybridization;combinatorial libraries;computational biology;kinetics;computer appl in life sciences;nucleic acid;gene expression profiling;oligonucleotide array sequence analysis;microarrays;bioinformatics	"""Although oligonucleotide microarray technology is ubiquitous in genomic research, reproducibility and standardization of expression measurements still concern many researchers. Cross-hybridization between microarray probes and non-target ssDNA has been implicated as a primary factor in sensitivity and selectivity loss. Since hybridization is a chemical process, it may be modeled at a population-level using a combination of material balance equations and thermodynamics. However, the hybridization reaction network may be exceptionally large for commercial arrays, which often possess at least one reporter per transcript. Quantification of the kinetics and equilibrium of exceptionally large chemical systems of this type is numerically infeasible with customary approaches. In this paper, we present a robust and computationally efficient algorithm for the simulation of hybridization processes underlying microarray assays. Our method may be utilized to identify the extent to which nucleic acid targets (e.g. cDNA) will cross-hybridize with probes, and by extension, characterize probe robustnessusing the information specified by MAGE-TAB. Using this algorithm, we characterize cross-hybridization in a modified commercial microarray assay. By integrating stochastic simulation with thermodynamic prediction tools for DNA hybridization, one may robustly and rapidly characterize of the selectivity of a proposed microarray design at the probe and """"system"""" levels. Our code is available at http://www.laurenzi.net ."""	algorithmic efficiency;crossbreeding;dna microarray;dna, complementary;ephrin type-b receptor 1, human;kinetics internet protocol;microarray analysis;nucleic acid hybridization;nucleic acids;numerical analysis;quantitation;selectivity (electronic);sensorineural hearing loss (disorder);simulation;tablet dosage form;thermodynamics;transcript;algorithm;customary	Erdem Arslan;Ian J. Laurenzi	2008		10.1186/1471-2105-10-411	biology;nucleic acid;molecular biology;dna microarray;bioinformatics;stochastic simulation;gene expression profiling;genetics;dna;kinetics;nucleic acid thermodynamics;dna–dna hybridization	Comp.	7.917425475822989	-61.96594769909504	16845
8b433614dc0fa443b61e66f0351e7ccee69505e7	two routes to face perception: evidence from psychophysics and computational modeling	face processing;procesamiento informacion;psicofisica;etude experimentale;computer model;holistic processing;hombre;percepcion;01 zeitschriftenartikel journalartikel oder magazin;computational modeling;cognition;information processing;human;modele simulation;psychophysique;cognicion;face;face perception;modelo simulacion;perception;traitement information;r medicine general;vision;simulation model;estudio experimental;component and configural information processing;homme;psychophysics;cara	The aim of this study was to separately analyze the role of featural and configural face representations. Stimuli containing only featural information were created by cutting the faces into their parts and scrambling them. Stimuli only containing configural information were created by blurring the faces. Employing an old-new recognition task, the aim of Experiments 1 and 2 was to investigate whether unfamiliar faces (Exp. 1) or familiar faces (Exp. 2) can be recognized if only featural or configural information is provided. Both scrambled and blurred faces could be recognized above chance level. A further aim of Experiments 1 and 2 was to investigate whether our method of creating configural and featural stimuli is valid. Pre-activation of one form of representation did not facilitate recognition of the other, neither for unfamiliar faces (Exp. 1) nor for familiar faces (Exp. 2). This indicates a high internal validity of our method for creating configural and featural face stimuli. Experiment 3 examined whether features placed in their correct categorical relational position but with distorted metrical distances facilitated recognition of unfamiliar faces. These faces were recognized no better than the scrambled faces in Experiment 1, providing further evidence that facial features are stored independently of configural information. From these results we conclude that both featural and configural information are important to recognize a face and argue for a dual-mode hypothesis of face processing. Using the psychophysical results as motivation, we propose a computational framework that implements featural and configural processing routes using an appearance-based representation based on local features and their spatial relations. In three computational experiments (Experiments 4-6) using the same sets of stimuli, we show how this framework is able to model the psychophysical data.	blurred vision;computation;computational model;distance;dual;exptime;experiment;face perception;internal validity;mbnl1 gene;psychophysics	Adrian Schwaninger;Janek S. Lobmaier;Christian Wallraven;Stephan M. Collishaw	2009	Cognitive science	10.1111/j.1551-6709.2009.01059.x	psychology;cognitive psychology;face;vision;computer vision;face perception;cognition;information processing;artificial intelligence;simulation modeling;communication;perception;computational model;psychophysics	AI	24.093323782601164	-66.86664906995001	16886
09b7778811d514cd402e8dee90c1948765a72c3d	a machine learning approach to explore the spectra intensity pattern of peptides using tandem mass spectrometry data	peptides;qr microbiology;f180 analytical chemistry;mass spectrometry;bayes theorem;spectrum;information presentation;computational biology bioinformatics;tandem mass spectrometry;g990 mathematical and computing sciences not elsewhere classified;machine learning;g730 neural computing;b000 health professions;g760 machine learning;artificial intelligence;algorithms;neural networks computer;combinatorial libraries;high throughput;proteomics;computer appl in life sciences;neural network;microarrays;bioinformatics	A better understanding of the mechanisms involved in gas-phase fragmentation of peptides is essential for the development of more reliable algorithms for high-throughput protein identification using mass spectrometry (MS). Current methodologies depend predominantly on the use of derived m/z values of fragment ions, and, the knowledge provided by the intensity information present in MS/MS spectra has not been fully exploited. Indeed spectrum intensity information is very rarely utilized in the algorithms currently in use for high-throughput protein identification. In this work, a Bayesian neural network approach is employed to analyze ion intensity information present in 13878 different MS/MS spectra. The influence of a library of 35 features on peptide fragmentation is examined under different proton mobility conditions. Useful rules involved in peptide fragmentation are found and subsets of features which have significant influence on fragmentation pathway of peptides are characterised. An intensity model is built based on the selected features and the model can make an accurate prediction of the intensity patterns for given MS/MS spectra. The predictions include not only the mean values of spectra intensity but also the variances that can be used to tolerate noises and system biases within experimental MS/MS spectra. The intensity patterns of fragmentation spectra are informative and can be used to analyze the influence of various characteristics of fragmented peptides on their fragmentation pathway. The features with significant influence can be used in turn to predict spectra intensities. Such information can help develop more reliable algorithms for peptide and protein identification.	algorithm;artificial neural network;bayesian network;biological neural networks;fragmentation (computing);gene regulatory network;high-throughput computing;information;ions;machine learning;protons;rule (guideline);tandem mass spectrometry;throughput	Cong Zhou;Lucas D. Bowler;Jianfeng Feng	2008	BMC Bioinformatics	10.1186/1471-2105-9-325	high-throughput screening;tandem mass spectrometry;spectrum;dna microarray;mass spectrometry;computer science;bioinformatics;data science;proteomics;bayes' theorem	Comp.	7.221573260031039	-57.682112195146	16957
d905df870eabbe486598cb1ee2ab5b2764c34999	literature mining for the discovery of hidden connections between drugs, genes and diseases	genes;software;metabolic networks and pathways;drug discovery;monocytes;text mining;medline;cell differentiation;drug targeting;disease;signal transduction;pharmaceutical preparations;data mining;article letter to editor;statistical analysis;drug interactions;reproducibility of results;cell proliferation;roc curve;leukocytes mononuclear;serotonin;pattern recognition automated;humans;computational biology;obsessive compulsive disorder;disease severity	The scientific literature represents a rich source for retrieval of knowledge on associations between biomedical concepts such as genes, diseases and cellular processes. A commonly used method to establish relationships between biomedical concepts from literature is co-occurrence. Apart from its use in knowledge retrieval, the co-occurrence method is also well-suited to discover new, hidden relationships between biomedical concepts following a simple ABC-principle, in which A and C have no direct relationship, but are connected via shared B-intermediates. In this paper we describe CoPub Discovery, a tool that mines the literature for new relationships between biomedical concepts. Statistical analysis using ROC curves showed that CoPub Discovery performed well over a wide range of settings and keyword thesauri. We subsequently used CoPub Discovery to search for new relationships between genes, drugs, pathways and diseases. Several of the newly found relationships were validated using independent literature sources. In addition, new predicted relationships between compounds and cell proliferation were validated and confirmed experimentally in an in vitro cell proliferation assay. The results show that CoPub Discovery is able to identify novel associations between genes, drugs, pathways and diseases that have a high probability of being biologically valid. This makes CoPub Discovery a useful tool to unravel the mechanisms behind disease, to find novel drug targets, or to find novel applications for existing drugs.	cell proliferation;drug delivery systems;experiment;keyword;mental association;roc curve;receiver operator characteristics;scientific literature;thesaurus (information retrieval)	Raoul Frijters;Marianne van Vugt;Ruben Smeets;René C. van Schaik;Jacob de Vlieg;Wynand Alkema	2010		10.1371/journal.pcbi.1000943	pharmacology;biology;text mining;targeted drug delivery;bioinformatics;gene;data mining;cell growth;genetics;cellular differentiation;receiver operating characteristic;drug discovery;signal transduction	ML	5.953464384756217	-57.0307210256768	17033
b08bbbb71af7aaa6fe9d908eab1fb2d81f845ee7	genprotec: an updated and improved analysis of functions of escherichia coli k-12 proteins	escherichia coli	Using more than one approach to characterizing functions of unknown proteins, we now present in GenProtEC (http://genprotec.mbl.edu/) some level of function information for 87% of Escherichia coli K-12 proteins. A new approach that has yielded new information entails assigning content of structural domains and their functions to E.coli proteins. In addition, some earlier methods have been further refined to provide more meaningful data. The process of identifying and separating multimodular or fused proteins into component modules has been improved. As a result, groups of sequence-similar (paralogous) proteins have been refined. Experimental information from recent literature on previously unknown genes has been incorporated. We now use a rich system of characterizing cell roles which accents the fact that many proteins play more than one cellular role and therefore carry more than one designation from our detailed catalog of roles, MultiFun.	greater than;homology (biology);identifier;sequence homology	Margrethe H. Serres;Sulip Goswami;Monica Riley	2004	Nucleic acids research	10.1093/nar/gkh087	biology;bioinformatics;escherichia coli;genetics	Comp.	1.9115139219686137	-60.13314717540784	17071
e842b2b3dfa9b393a89a976196e8aa1f5924e5cf	a naïve bayes baseline for early gesture recognition	naive bayes;early recognition;gesture recognition	Early gesture/action recognition is the task of determining the identity of a gesture/action with as few information as possible. Although the topic is relatively new, there are some methods that address this problem. However, existing methods rely on complex modeling procedures, that do not necessarily paid off the computational effort. Thus, simple yet effective and efficient techniques are required for this task. This paper describes a new methodology for early gesture recognition based on the well known naïve Bayes classifier. The method is extremely simple and very fast, yet it compares favorably with more elaborated state of the art methodologies. The naïve baseline is based on three main observations: (1) the effectiveness of the naïve Bayes classifier in text mining problems; (2) the link between natural language processing and computer vision via the bag-of-words representation; and (3) the cumulative-evidence nature of the inference process of naïve Bayes. We evaluated the proposed method in several collections that included segmented and continuous video. Experimental results show that the proposed methodology compares favorably with state of the art methodologies that are more elaborated or were specifically designed for this purpose. © 2016 Elsevier B.V. All rights reserved.	bag-of-words model;baseline (configuration management);computation;computer vision;gesture recognition;naive bayes classifier;naivety;natural language processing;smoothing;statistical classification;text mining;whole earth 'lectronic link	Hugo Jair Escalante;Eduardo F. Morales;Luis Enrique Sucar	2016	Pattern Recognition Letters	10.1016/j.patrec.2016.01.013	computer vision;naive bayes classifier;speech recognition;computer science;machine learning;pattern recognition;gesture recognition	AI	24.097653911493282	-57.55927314663517	17074
b977eaef59ffd614449efc36ddbd210eabb767c9	interspecies protein-protein interaction network construction for characterization of host-pathogen interactions: a candida albicans-zebrafish interaction study	animals;simulation and modeling;candida albicans;multivariate analysis;intracellular space;systems biology;physiological cellular and medical topics;computational biology bioinformatics;oxidation reduction;zebrafish;host pathogen interactions;algorithms;protein interaction mapping;bioinformatics	Despite clinical research and development in the last decades, infectious diseases remain a top global problem in public health today, being responsible for millions of morbidities and mortalities each year. Therefore, many studies have sought to investigate host-pathogen interactions from various viewpoints in attempts to understand pathogenic and defensive mechanisms, which could help control pathogenic infections. However, most of these efforts have focused predominately on the host or the pathogen individually rather than on a simultaneous analysis of both interaction partners. In this study, with the help of simultaneously quantified time-course Candida albicans-zebrafish interaction transcriptomics and other omics data, a computational framework was developed to construct the interspecies protein-protein interaction (PPI) network for C. albicans-zebrafish interactions based on the inference of ortholog-based PPIs and the dynamic modeling of regulatory responses. The identified C. albicans-zebrafish interspecies PPI network highlights the association between C. albicans pathogenesis and the zebrafish redox process, indicating that redox status is critical in the battle between the host and pathogen. Advancing from the single-species network construction method, the interspecies network construction approach allows further characterization and elucidation of the host-pathogen interactions. With continued accumulation of interspecies transcriptomics data, the proposed method could be used to explore progressive network rewiring over time, which could benefit the development of network medicine for infectious diseases.	candida albicans ag:titr:pt:ser:qn:la;communicable diseases;homology (biology);host-pathogen interactions;inference;interaction network;morbidity - disease rate;mortality vital statistics;network medicine;omics;orthologous gene;pathogenic organism;pixel density;proton pump inhibitors;published comment;tree accumulation;zebrafish;negative regulation of defense response to bacterium, incompatible interaction;protein protein interaction	Yu-Chao Wang;Che Lin;Ming-Ta Chuang;Wen-Ping Hsieh;Chung-Yu Lan;Yung-Jen Chuang;Bor-Sen Chen	2013		10.1186/1752-0509-7-79	biology;redox;zebrafish information network genome database;intracellular;toxicology;bioinformatics;multivariate analysis;systems biology	AI	5.886857986345118	-60.19997537708954	17155
43babe1c868211171616d0dc8c43a9fa29144624	enumeration and extension of non-equivalent deterministic update schedules in boolean networks	biological patents;biomedical journals;text mining;europe pubmed central;citation search;citation networks;research articles;abstracts;open access;life sciences;clinical guidelines;full text;rest apis;orcids;europe pmc;biomedical research;bioinformatics;literature search	MOTIVATION Boolean networks (BNs) are commonly used to model genetic regulatory networks (GRNs). Due to the sensibility of the dynamical behavior to changes in the updating scheme (order in which the nodes of a network update their state values), it is increasingly common to use different updating rules in the modeling of GRNs to better capture an observed biological phenomenon and thus to obtain more realistic models.In Aracena et al. equivalence classes of deterministic update schedules in BNs, that yield exactly the same dynamical behavior of the network, were defined according to a certain label function on the arcs of the interaction digraph defined for each scheme. Thus, the interaction digraph so labeled (update digraphs) encode the non-equivalent schemes.   RESULTS We address the problem of enumerating all non-equivalent deterministic update schedules of a given BN. First, we show that it is an intractable problem in general. To solve it, we first construct an algorithm that determines the set of update digraphs of a BN. For that, we use divide and conquer methodology based on the structural characteristics of the interaction digraph. Next, for each update digraph we determine a scheme associated. This algorithm also works in the case where there is a partial knowledge about the relative order of the updating of the states of the nodes. We exhibit some examples of how the algorithm works on some GRNs published in the literature.   AVAILABILITY AND IMPLEMENTATION An executable file of the UpdateLabel algorithm made in Java and the files with the outputs of the algorithms used with the GRNs are available at: www.inf.udec.cl/ ∼lilian/UDE/ CONTACT: lilisalinas@udec.cl   SUPPLEMENTARY INFORMATION Supplementary data are available at Bioinformatics online.	algorithm;bioinformatics;biological phenomena;boolean network;class;computational complexity theory;directed graph;dynamical system;encode;executable;hereditary diseases;java programming language;non-deterministic turing machine;rule (guideline);schedule (computer science);schedule (document type);scientific publication;tracer;turing completeness	Eduardo Palma;Lilian Salinas;Julio Aracena	2016	Bioinformatics	10.1093/bioinformatics/btv628	text mining;medical research;computer science;bioinformatics;theoretical computer science;data mining;mathematics;algorithm;statistics	Comp.	1.904988297161908	-52.11028187281178	17162
a185bf76ab1c64d1606be400ffceabd26175adac	dbsno 2.0: a resource for exploring structural environment, functional and disease association and regulatory network of protein s-nitrosylation	animals;mice;rats;metabolic networks and pathways;disease;signal transduction;internet;proteins;protein processing post translational;amino acids;humans;nitric oxide;protein interaction mapping;databases protein	Given the increasing number of proteins reported to be regulated by S-nitrosylation (SNO), it is considered to act, in a manner analogous to phosphorylation, as a pleiotropic regulator that elicits dual effects to regulate diverse pathophysiological processes by altering protein function, stability, and conformation change in various cancers and human disorders. Due to its importance in regulating protein functions and cell signaling, dbSNO (http://dbSNO.mbc.nctu.edu.tw) is extended as a resource for exploring structural environment of SNO substrate sites and regulatory networks of S-nitrosylated proteins. An increasing interest in the structural environment of PTM substrate sites motivated us to map all manually curated SNO peptides (4165 SNO sites within 2277 proteins) to PDB protein entries by sequence identity, which provides the information of spatial amino acid composition, solvent-accessible surface area, spatially neighboring amino acids, and side chain orientation for 298 substrate cysteine residues. Additionally, the annotations of protein molecular functions, biological processes, functional domains and human diseases are integrated to explore the functional and disease associations for S-nitrosoproteome. In this update, users are allowed to search a group of interested proteins/genes and the system reconstructs the SNO regulatory network based on the information of metabolic pathways and protein-protein interactions. Most importantly, an endogenous yet pathophysiological S-nitrosoproteomic dataset from colorectal cancer patients was adopted to demonstrate that dbSNO could discover potential SNO proteins involving in the regulation of NO signaling for cancer pathways.	accessible surface area;amino acids;cell signaling;colorectal carcinoma;dual;entity name part qualifier - adopted;malignant neoplasms;mental association;patients;polynomial texture mapping;protein data bank;s-nitrosylation;sequence alignment;silo (dataset);protein protein interaction	Yi-Ju Chen;Cheng-Tsung Lu;Min-Gang Su;Kai-Yao Huang;Wei-Chieh Ching;Hsiao-Hsiang Yang;Yen-Chen Liao;Yu-Ju Chen;Tzong-Yi Lee	2015		10.1093/nar/gku1176	biology;biochemistry;the internet;nitric oxide;bioinformatics;signal transduction	Comp.	2.220613567219162	-60.559080019591256	17168
acd9244e709b4fc925f5075078080829c30a1ed1	a study of pre-decision evaluation using influence diagram: an estimation of the benefits of influenza vaccination	decision support;decision tree;decision analysis;influenza vaccine;influenza vaccination;sensitivity analysis;influence diagram;age groups;health expenditure	The purpose of this study is to develop a decision analysis model based on the influence diagram and estimate the benefits receiving of influenza vaccination. We collected more than 300,000 samples of elders aged over 65 years in Taiwan and then analyzed the health expenditure of the elders with and without influenza vaccination. We incorporate clinical results and the knowledge of physicians by an influence diagram. We divided our samples into four different age groups and the results showed that the total healthcare expenses for receiving influenza vaccination are more than the expenses for not receiving influenza vaccination for all age groups, we found there is a trend that the difference decreases if the age is older. We performed the one-way sensitivity analysis and Monde Carlo sensitivity analysis further and the results showed that the expected health expenditure is mostly sensitive to the hospitalization under the different condition.	decision analysis;elder extract;estimated;government;health expenditures;hospitalization;influence diagram;influenza vaccination;influenza virus vaccine;large;money;morbidity - disease rate;one-way function;surgical wound infection;urologic diseases;utility;benefit	Fan Wu;Pei-Ran Sun;His-Kun Ke;Hsieh-Hong Huang;Yungyen Chiang	2008	Journal of Medical Systems	10.1007/s10916-008-9160-x	intensive care medicine;influence diagram;medicine;decision analysis;computer science;decision tree;immunology;medical emergency;sensitivity analysis;demographic profile	HCI	7.2297204751060375	-75.21487847894092	17210
1482a2a7bd0d8ccf852a5ae7d9779332324288d0	discovery of influenza a virus sequence pairs and their combinations for simultaneous heterosubtypic targeting that hedge against antiviral resistance	animals;influenza human;drug resistance viral;zoonoses;rna sequence analysis;transcriptome analysis;journal article;graphs;sequence databases;conserved sequence;influenza a virus;chickens;orthomyxoviridae infections;host pathogen interactions;sequence motif analysis;h1n1;sequence analysis;humans;antiviral agents;biological sciences;base sequence;computational biology;computer simulation;gene expression profiling;swine	"""The multiple circulating human influenza A virus subtypes coupled with the perpetual genomic mutations and segment reassortment events challenge the development of effective therapeutics. The capacity to drug most RNAs motivates the investigation on viral RNA targets. 123,060 segment sequences from 35,938 strains of the most prevalent subtypes also infecting humans-H1N1, 2009 pandemic H1N1, H3N2, H5N1 and H7N9, were used to identify 1,183 conserved RNA target sequences (≥15-mer) in the internal segments. 100% theoretical coverage in simultaneous heterosubtypic targeting is achieved by pairing specific sequences from the same segment (""""Duals"""") or from two segments (""""Doubles""""); 1,662 Duals and 28,463 Doubles identified. By combining specific Duals and/or Doubles to form a target graph wherein an edge connecting two vertices (target sequences) represents a Dual or Double, it is possible to hedge against antiviral resistance besides maintaining 100% heterosubtypic coverage. To evaluate the hedging potential, we define the hedge-factor as the minimum number of resistant target sequences that will render the graph to become resistant i.e. eliminate all the edges therein; a target sequence or a graph is considered resistant when it cannot achieve 100% heterosubtypic coverage. In an n-vertices graph (n ≥ 3), the hedge-factor is maximal (= n- 1) when it is a complete graph i.e. every distinct pair in a graph is either a Dual or Double. Computational analyses uncover an extensive number of complete graphs of different sizes. Monte Carlo simulations show that the mutation counts and time elapsed for a target graph to become resistant increase with the hedge-factor. Incidentally, target sequences which were reported to reduce virus titre in experiments are included in our target graphs. The identity of target sequence pairs for heterosubtypic targeting and their combinations for hedging antiviral resistance are useful toolkits to construct target graphs for different therapeutic objectives."""	antiviral agents;computation;dual;experiment;gper protein, human;graph - visual representation;influenza a virus;influenza in birds;leucaena pulverulenta;list of toolkits;maximal set;monte carlo method;murine sarcoma viruses;mutation;rna;simulation;subtype (attribute);titer;cellular targeting;viral capsid secondary envelopment	Keng Boon Wee;Raphael Tze Chuen Lee;Jing Lin;Zacharias Aloysius Dwi Pramono;Sebastian Maurer-Stroh	2016		10.1371/journal.pcbi.1004663	computer simulation;biology;transcriptome;bioinformatics;virology;sequence analysis;gene expression profiling;conserved sequence;graph;genetics	Comp.	3.4756403410277814	-60.268208202835	17258
602abb9e776c14f9239352d083fdfdc168fbb5e2	gdap: a web tool for genome-wide protein disulfide bond prediction	software;cysteine;data interpretation statistical;genome archaeal;disulfides;internet;disulfide bond;genome bacterial;archaeal proteins;bacterial proteins;sequence analysis protein	The Genomic Disulfide Analysis Program (GDAP) provides web access to computationally predicted protein disulfide bonds for over one hundred microbial genomes, including both bacterial and achaeal species. In the GDAP process, sequences of unknown structure are mapped, when possible, to known homologous Protein Data Bank (PDB) structures, after which specific distance criteria are applied to predict disulfide bonds. GDAP also accepts user-supplied protein sequences and subsequently queries the PDB sequence database for the best matches, scans for possible disulfide bonds and returns the results to the client. These predictions are useful for a variety of applications and have previously been used to show a dramatic preference in certain thermophilic archaea and bacteria for disulfide bonds within intracellular proteins. Given the central role these stabilizing, covalent bonds play in such organisms, the predictions available from GDAP provide a rich data source for designing site-directed mutants with more stable thermal profiles. The GDAP web application is a gateway to this information and can be used to understand the role disulfide bonds play in protein stability both in these unusual organisms and in sequences of interest to the individual researcher. The prediction server can be accessed at http://www.doe-mbi.ucla.edu/Services/GDAP.	accepting of extremity;amino acid sequence;archaea;colony count, microbial;covalent interaction;data sources;disulfide linkage;disulfides;gateway (telecommunications);genome;internet access;peptide sequence;protein data bank;providing (action);sequence database;server (computing);silo (dataset);united states public health service;upload;web application;funding grant;mutant	Brian D. O'Connor;Todd O. Yeates	2004	Nucleic acids research	10.1093/nar/gkh376	biology;biochemistry;the internet;bioinformatics;genetics;disulfide bond	Comp.	-0.5807917783253944	-59.77565901151266	17265
fc1df4471ea3928c018b5f72efd8d290fc48948a	improved prediction of hiv-1 protease genotypic resistance testing assays using a consensus technique	drugs;drug targeting;testing diseases drugs inhibitors learning artificial intelligence medical computing patient treatment;testing;medical computing;hiv 1 protease;machine learning;testing immune system drugs medical treatment capacitive sensors genetic mutations human immunodeficiency virus biochemistry frequency neural networks;test methods;prediction accuracy;diseases;patient treatment;cross section;learning artificial intelligence;strains classification hiv 1 protease genotypic resistance testing assays consensus technique hiv 1 drug targets mutation antiretroviral inhibitors infected individuals treatment viral therapy computational docking method machine learning;inhibitors	Mutations in HIV-1 drug targets can cause reduced affinity to antiretroviral inhibitors, leading to the emergence of resistant variants resulting in failure of treatment in infected individuals. Resistance testing is an important factor in the continued success of viral therapy. We found that through combining a structural based computational docking method and a classic machine learning technique we could create a consensus system capable of improving the prediction accuracy by 5.56% over either method used individually. The result was the creation of a genotypic resistance testing approach capable of classifying a wider cross-section of strains, hence making it a more accurate resistance testing method.	docking (molecular);emergence;machine learning;processor affinity	Alex C. Thomas;Zheng Rong Yang	2006	The 2006 IEEE International Joint Conference on Neural Network Proceedings	10.1109/IJCNN.2006.247030	targeted drug delivery;computer science;bioinformatics;machine learning;cross section;software testing;test method	Visualization	8.70520761707831	-55.92928648675807	17272
c73e15195dc500ea704c8ee7e0b0dd8bda836942	homed: a homologous sequence editor			homology (biology)	P. A. Stockwell;G. B. Petersen	1987	Trends in biochemical sciences	10.1093/bioinformatics/3.1.37	molecular biology;biology;homologous chromosome	ML	1.3075888844321286	-63.83744805556347	17274
f9831695ea1eec52c6b72d707c274e16505cf993	orthographic distinctiveness and semantic elaboration provide separate contributions to memory	orthographe;nuclear magnetic resonance imaging;ortografia;memoire;imagineria rmn;systeme nerveux central;functional mag netic resonance imaging;lenguaje;semantics;hombre;langage;orthography;encefalo;semantica;semantique;functional imaging;sistema nervioso central;memoria;encephale;human;cerebral cortex;imagerie rmn;encephalon;language;cortex cerebral;imagineria funcional;recognition memory;corteza cerebral;central nervous system;memory;homme;imagerie fonctionnelle	Orthographic distinctiveness and semantic elaboration both enhance memory. The present behavioral and functional magnetic resonance imaging (fMRI) studies examined the relationship between the influences of orthographic distinctiveness and semantic elaboration on memory, and explored whether they make independent contributions. As is typical for manipulations of processing levels, words studied during semantic encoding were better remembered than words studied during nonsemantic encoding. Notably, orthographically distinct words were better recalled and received more remember responses on recognition memory tests than orthographically common words regardless of encoding task, suggesting that orthographic distinctiveness has an additive effect to that of semantic elaboration on memory. In the fMRI study, ortho-graphic distinctiveness and semantic elaboration engaged separate networks of brain regions. Semantic elaboration modulated activity in left inferior prefrontal and lateral temporal regions. In contrast, orthographic distinctiveness modulated activity in distinct bilateral inferior prefrontal, extrastriate, and parietal regions. Orthographic distinctiveness and semantic elaboration appear to have separate behavioral and functional-anatomic contributions to memory.	bilateral filter;character encoding;church encoding;lateral thinking;magnetic resonance imaging;memory disorders;modulation;orthographic projection;parietal lobe;temporal lobe;utility functions on indivisible goods;fmri	Brenda A. Kirchhoff;Melissa L. Schapiro;Randy L. Buckner	2005	Journal of Cognitive Neuroscience	10.1162/089892905775008670	psychology;cognitive psychology;developmental psychology;orthography;central nervous system;functional imaging;semantics;linguistics;language;memory;communication;recognition memory	AI	16.801393634815074	-77.03911915205943	17278
610a865ed1934233223fdaa64cde885dcdf8e6c1	designing qsar models for promising tlr4 agonists isolated from euodia asteridula by artificial neural networks enhanced by optimal brain surgeon		Undoubtedly, computer aided drug design (CADD) has gained important position in medicinal chemistry thanks to balancing random approaches to discovery of new drugs by prioritizing rational insight into the development process. From many CADD methods, quantitative structure activity relationships (QSAR), which are able to exploit chemical and biological information hidden in chemical structures through utilization of numerous machine learning and artificial intelligence methods, are expected to provide the necessary assistance in mechanistic interpretation and prediction of biological activities. In the present work, 56 derivatives of a natural adjuvant euodenine A, which occurs in Euodia asteridula, were selected for a QSAR study with the use of artificial neural networks (ANN). Since building of robust QSAR models is still a challenging research area, several methods had to be utilized to achieve a robust solution. Among various backpropagation based algorithms, much effort has been devoted to research of an optimal brain surgeon (OBS) method, which attempts to prune unimportant ANN elements according to the second derivation of the output signal error with respect to the weights. Herein, the performance of OBS in QSAR analyses is discussed and compared with other ANN learning methods.	artificial neural network;neural networks;quantitative structure–activity relationship	Rafael Dolezal;Jan Trejbal;Jakub Mesicek;Agata Milanov;Veronika Racakova;Jiri Krenek	2016		10.1007/978-3-319-45246-3_26	artificial intelligence	ML	8.239438781228587	-55.100520527010055	17299
829e5f95be93652ae1308aadf8bc0eaa4b5be337	knowledge representation in metabolic pathway databases	universiteitsbibliotheek	The accurate representation of all aspects of a metabolic network in a structured format, such that it can be used for a wide variety of computational analyses, is a challenge faced by a growing number of researchers. Analysis of five major metabolic pathway databases reveals that each database has made widely different choices to address this challenge, including how to deal with knowledge that is uncertain or missing. In concise overviews, we show how concepts such as compartments, enzymatic complexes and the direction of reactions are represented in each database. Importantly, also concepts which a database does not represent are described. Which aspects of the metabolic network need to be available in a structured format and to what detail differs per application. For example, for in silico phenotype prediction, a detailed representation of gene-protein-reaction relations and the compartmentalization of the network is essential. Our analysis also shows that current databases are still limited in capturing all details of the biology of the metabolic network, further illustrated with a detailed analysis of three metabolic processes. Finally, we conclude that the conceptual differences between the databases, which make knowledge exchange and integration a challenge, have not been resolved, so far, by the exchange formats in which knowledge representation is standardized.		Miranda D. Stobbe;Gerbert A. Jansen;Perry D. Moerland;Antoine H. C. van Kampen	2014	Briefings in bioinformatics	10.1093/bib/bbs060	biology;computer science;bioinformatics;data science;data mining	Web+IR	-4.449378503953292	-63.811159729843965	17328
3363c87f8b18995a7a4c0cd13b5851b2d684326d	episodes in space: a modeling study of hippocampal place representation	episodic memory;path integral;hebbian learning;space representation;grid cell;spatial memory;building block;mobile robot;computer model;hippocampus;computational neuroscience;simulation software;model building;place cell;hippocampal formation	A computer model of learning and representing spatial locations is studied. The model builds on biological constraints and assumptions drawn from the anatomy and physiology of the hippocampal formation of the rat. The emphasis of the presented research is on the usability of a computer model originally proposed to describe episodic memory capabilities of the hippocampus in a spatial task. In the present model two modalities – vision and path integration – are contributing to the recognition of a given place. We study how place cell activity emerges due to Hebbian learning in the model hippocampus as a result of random exploration of the environment. The model is implemented in the Webots mobile robotics simulation software. Our results show that the location of the robot is well predictable from the activity of a population of model place cells, thus the model is suitable to be used as a basic building block of location-based navigation strategies. However, some properties of the stored memories strongly resembles that of episodic memories, which do not match special spatial requirements.	computer simulation;hebbian theory;location-based service;mobile robot;numerical weather prediction;requirement;robotics;simulation software;usability	Balázs Ujfalussy;Péter Erös;Zoltán Somogyvári;Tamás Kiss	2008		10.1007/978-3-540-69134-1_13	mobile robot;spatial memory;path integral formulation;simulation;model building;simulation software;hebbian theory;computer science;artificial intelligence;machine learning;episodic memory;hippocampus;hippocampal formation;computational neuroscience	Robotics	19.276471045529306	-67.66166710047219	17380
38da4cc5d4f4c1aeb7bb99f00e25048cdc5efad2	models for the cross-correlation between retinal ganglion cells	time scale;cross correlation;leaky integrate and fire;ganglion cell;monte carlo simulation;retinal ganglion cell;nonlinear model	Neighboring ganglion cells in the vertebrate retina not only respond to the same stimuli but also display cross-correlated activity on a millisecond time scale. Recent studies of this cross-correlation have indicated that simple linear addition of common variability to each ganglion cell signal does not account for the observations (Levine 1997). In this report, Monte Carlo simulations of various linear and nonlinear models are presented that confirm the earlier speculations. Models in which common variability alters the leakages of a pair of leaky integrate-and-fire neurons account for the data and predict the cross-correlogram lag without invoking temporal delay lines.	biological neuron model;cell signaling;cross-correlation;delay line memory;ganglion cell;heart rate variability;leucaena pulverulenta;monte carlo method;nonlinear system;retina;retinal ganglion cells;stmn1 gene;simulation;spatial variability	Michael W. Levine	1998	Biological Cybernetics	10.1007/s004220050486	neuroscience;cross-correlation;mathematics;optics;statistics;monte carlo method	ML	19.24234044778612	-72.74396658342661	17409
502205d142c5f23df5e2013dcd4806255f251fe9	changes of symptom and eeg in mal de debarquement syndrome patients after repetitive transcranial magnetic stimulation over bilateral prefrontal cortex: a pilot study	transcranial magnetic stimulation electroencephalography independent component analysis mechanoception medical disorders medical signal processing neurophysiology patient treatment spectral analysis;protocols;brain;frequency 10 hz mal de debarquement syndrome patients repetitive transcranial magnetic stimulation bilateral prefrontal cortex chronic disorder imbalance swaying medical treatment clinical efficacy mdds patients rtms paradigm ipsilateral dorsal lateral prefrontal cortex dominant hand contralateral dlpfc potential efficacy subjective reported symptom visual analogue scale direct brain activity resting state electroencephalography brain substrates local networks rseeg signals group wise independent component analysis rocking sensation elevated spectral powers low frequency bands occipital cortex parietal cortex motor cortex cortical inhibition enhancement vas scores high frequency bands posterior parietal areas left visual areas spatial information processing frequency 1 hz;electroencephalography substrates protocols independent component analysis visualization brain correlation;independent component analysis;visualization;substrates;correlation;electroencephalography	Mal de debarquement syndrome (MdDS) is a chronic disorder of imbalance characterized by a feeling of rocking and swaying. The medical treatment for MdDS is still limited. Motivated by our previous pilot study that demonstrates the promising clinical efficacy of repetitive transcranial stimulation (rTMS) in MdDS patients, a novel rTMS paradigm, i.e., 1 Hz stimulation over ipsilateral dorsal lateral prefrontal cortex (DLPFC) with respect to the dominant hand followed by 10 Hz stimulation over contralateral DLPFC, was proposed and conducted in MdDS in the present study. To evaluate the potential efficacy, we examined the changes before and after rTMS in both subjective reported symptom using visual analogue scale (VAS) and direct brain activity in resting state electroencephalography (rsEEG). To disentangle activity from distinct brain substrates and/or local networks in rsEEG signals, a group-wise independent component analysis was employed and the corresponding spectral power changes were examined in the identified components. In general, reduction in rocking sensation was reported in five of ten subjects (with dramatic reductions (changes > 30) in three subjects) after rTMS using the present paradigm, while no changes and slight increases in rocking sensation were reported in the remaining subjects. In rsEEG, significant elevated spectral powers in low frequency bands (i.e., theta and alpha) over broad areas of occipital, parietal, motor, and prefrontal cortices were induced by rTMS, reflecting the enhancement of cortical inhibition over these areas. Meanwhile, the significant correlations between changes in rsEEG and VAS scores were detected in the high frequency bands (i.e., high alpha and beta) over posterior parietal and left visual areas, reflecting the suppression of spatial information processing. Therefore, the present findings demonstrate the promising clinical efficacy of a new rTMS paradigm for MdDS, and suggest its merit for further studies in more patients.	area striata structure;bands;bilateral filter;cerebral cortex;chronic disease;dominant hand;electroencephalography phase synchronization;frequency band;hertz (hz);independent component analysis;information processing;lateral thinking;mal de debarquement;patients;power (psychology);prefrontal cortex;programming paradigm;repetitive strain;rest;resting state fmri;transcranial magnetic stimulation;visual analog pain scale;zero suppression	Guofa Shou;Han Yuan;Diamond Urbano;Yoon-Hee Cha;Lei Ding	2014	2014 36th Annual International Conference of the IEEE Engineering in Medicine and Biology Society	10.1109/EMBC.2014.6944574	psychology;independent component analysis;communications protocol;neuroscience;developmental psychology;visualization;electroencephalography;computer science;machine learning;communication;correlation	Visualization	17.97876385294094	-79.48743535285095	17444
2e8fd8f3c48d5970ccd4dbe36ec099d956fdfeba	13c nmr-distance matrix descriptors: optimal abstract 3d space granularity for predicting estrogen binding		"""An improved three-dimensional quantitative spectral data-activity relationship (3D-QSDAR) methodology was used to build and validate models relating the activity of 130 estrogen receptor binders to specific structural features. In 3D-QSDAR, each compound is represented by a unique fingerprint constructed from (13)C chemical shift pairs and associated interatomic distances. Grids of different granularity can be used to partition the abstract fingerprint space into congruent """"bins"""" for which the optimal size was previously unexplored. For this purpose, the endocrine disruptor knowledge base data were used to generate 50 3D-QSDAR models with bins ranging in size from 2 ppm × 2 ppm × 0.5 Å to 20 ppm × 20 ppm × 2.5 Å, each of which was validated using 100 training/test set partitions. Best average predictivity in terms of R(2)test was achieved at 10 ppm ×10 ppm × Z Å (Z = 0.5, ..., 2.5 Å). It was hypothesized that this optimum depends on the chemical shifts' estimation error (±4.13 ppm) and the precision of the calculated interatomic distances. The highest ranked bins from partial least-squares weights were found to be associated with structural features known to be essential for binding to the estrogen receptor."""		Svetoslav H. Slavov;Elizabeth L. Geesaman;Bruce A. Pearce;Laura K. Schnackenberg;Dan A. Buzatu;Jon G. Wilkes;Richard D. Beger	2012	Journal of chemical information and modeling	10.1021/ci3001698	discrete mathematics;theoretical computer science;machine learning;mathematics	Comp.	11.687046996728125	-58.752175049370805	17468
51f28d1e157d9d9d1108dc60f2c540a2080e6ed3	neuronal entropy-rate feature of entopeduncular nucleus in rat model of parkinson's disease	basal ganglia;6 ohda;globus pallidus internal;entropy;rat;dopamine	The function of the nigro-striatal pathway on neuronal entropy in the basal ganglia (BG) output nucleus, i.e. the entopeduncular nucleus (EPN) was investigated in the unilaterally 6-hyroxydopamine (6-OHDA)-lesioned rat model of Parkinson's disease (PD). In both control subjects and subjects with 6-OHDA lesion of dopamine (DA) the nigro-striatal pathway, a histological hallmark for parkinsonism, neuronal entropy in EPN was maximal in neurons with firing rates ranging between 15 and 25 Hz. In 6-OHDA lesioned rats, neuronal entropy in the EPN was specifically higher in neurons with firing rates above 25 Hz. Our data establishes that the nigro-striatal pathway controls neuronal entropy in motor circuitry and that the parkinsonian condition is associated with abnormal relationship between firing rate and neuronal entropy in BG output nuclei. The neuronal firing rates and entropy relationship provide putative relevant electrophysiological information to investigate the sensory-motor processing in normal condition and conditions such as movement disorders.		Olivier Darbin;Xingxing Jin;Christof Von Wrangel;Kerstin Schwabe;Atsushi Nambu;Dean K. Naritoku;Joachim K. Krauss;Mesbah Alam	2016	International journal of neural systems	10.1142/S0129065715500380	entropy;dopamine	ML	18.86918299029303	-74.45721587433692	17507
ae77df577c0ebf9c6ed70fea87ffa61a5faa6816	active spike transmission in the neuron model with a winding threshold manifold	spike encoding;excitability;active response;spike transmission;nonlinear dynamics;threshold manifold	We analyze spiking responses of excitable neuron model with a winding threshold manifold on a pulse stimulation. The model is stimulated with external pulse stimuli and can generate nonlinear integrateand-fire and resonant responses typical for excitable neuronal cells (all-or-none). In addition we show that for certain parameter range there is a possibility to trigger a spiking sequence with a finite number incoming pulses to M (with M4N) outgoing spikes is possible. At the level of single neuron computations such property can provide an active ‘‘spike source’’ compensating ‘‘spike dissipation’’ due to the integrate-and-fire N to 1 response. We delineate the dynamical mechanism for the N to M transformation based on the winding threshold manifold in the neighborhood of big saddle loop bifurcation. Based on the theoretical predictions, a nonlinear electronic circuit is designed implementing the active transmission in physical conditions. & 2012 Elsevier B.V. All rights reserved.	bifurcation theory;biological neuron model;computation;dynamical system;electronic circuit;excitable medium;nonlinear system	Viktor B. Kazantsev;Aurélien Serge Tchakoutio Nguetcho;Sabir Jacquir;Stéphane Binczak;Jean-Marie Bilbault	2012	Neurocomputing	10.1016/j.neucom.2011.12.014	nonlinear system;machine learning;mathematics	ML	17.447400961525975	-70.64520658300152	17578
cce72937d6c244f05c474620b326591226125075	comparative experimental studies on spatial memory and learning in rats and robots	cognitive map;tecnologia industrial tecnologia mecanica;tecnologia electronica telecomunicaciones;biorobotics;hippocampus;striatum;spatial learning;ieg arc expression;tecnologias;grupo a;place recognition	The study of behavioral and neurophysiological mechanisms involved in rat spatial cognition provides a basis for the development of computational models and robotic experimentation of goal-oriented learning tasks. These models and robotics architectures offer neurobiologists and neuroethologists alternative platforms to study, analyze and predict spatial cognition based behaviors. In this paper we present a comparative analysis of spatial cognition in rats and robots by contrasting similar goal-oriented tasks in a cyclical maze, where studies in rat spatial cognition are used to develop computational system-level models of hippocampus and striatum integrating kinesthetic and visual information to produce a cognitive map of the environment and drive robot experimentation. During training, Hebbian learning and reinforcement learning, in the form of Actor-Critic architecture, enable robots to learn the optimal route leading to a goal from a designated fixed location in the maze. During testing, robots exploit maximum expectations of reward stored within the previously acquired cognitive map to reach the goal from different starting positions. A detailed discussion of comparative experiments in rats and robots is presented contrasting learning latency while characterizing behavioral procedures during navigation such as errors associated with the selection of a non-optimal route, body rotations, normalized length of the traveled path, and hesitations. Additionally, we present results from evaluating neural activity in rats through detection of the A. Barrera (B) · A. Weitzenfeld Computer Engineering Department–Robotics and Biorobotics Laboratories, Instituto Tecnológico Autónomo de México (ITAM), Río Hondo #1, Progreso Tizapán, CP 01080, México DF, México e-mail: abarrera@itam.mx A. Cáceres · V. Ramirez-Amaya Neurobiology Institute, Plastic Neural Networks Laboratory, Universidad Nacional Autónoma de México (UNAM), Boulevard Juriquilla #3001, CP 76230, Querétaro, México V. Ramirez-Amaya e-mail: ramirez@inb.unam.mx 362 J Intell Robot Syst (2011) 63:361–397 immediate early gene Arc to verify the engagement of hippocampus and striatum in information processing while solving the cyclical maze task, such as robots use our corresponding models of those neural structures.	amaya;biorobotics;cognition;cognitive map;computational model;computer engineering;direction finding;email;experiment;hebbian theory;information processing;neural networks;qualitative comparative analysis;reinforcement learning;robot	Alejandra Barrera;Alejandra Cáceres;Alfredo Weitzenfeld;Victor Ramirez-Amaya	2011	Journal of Intelligent and Robotic Systems	10.1007/s10846-010-9467-y	spatial memory;biorobotics;simulation;cognitive map;computer science;artificial intelligence;machine learning;hippocampus	AI	19.054104414380898	-67.55784457210585	17584
7fb9ce707b1b786ff94cbad278070cc7109d2a9a	trigger detection system for american sign language using deep convolutional neural networks		Automatic trigger-word detection in speech is a well known technology nowadays. However, for people who are incapable of speech or are in some silence zone, such voice activated trigger detection systems find no use. We have developed a trigger detection system using the 24 static hand gestures of the American Sign Language (ASL). Our model is primarily based on Deep Convolutional Neural Network (Deep CNN) as they are capable of capturing interesting visual features at each hidden layer. We aim at constructing a customisable switch that can turn u0027onu0027 if it finds a given trigger gesture in any video that it receives and stays u0027offu0027 if it does not. The model was trained on images of various hand gestures in a multi-class classification setting. This allows the user to choose a custom trigger gesture for oneself. To test the efficiency of such a model in the trigger detection process, we have made 7,000 videos (each 10s long) consisting of random images from the test set which were never shown to the model during the training process. It is experimentally shown that such a system has a better performance than the other state-of-the art techniques used in static hand gesture image recognition tasks. This approach also finds real-time application and can be applied to develop small scale devices which trigger any particular response by capturing the gestures made by the people.		Debasrita Chakraborty;Deepankar Garg;Ashish Ghosh;Jonathan H. Chan	2018		10.1145/3291280.3291783	voice command device;convolutional neural network;speech recognition;silence;american sign language;test set;computer science;gesture	ML	23.93054902830623	-62.72893788433434	17613
447c5493025f92bb3b0d05d9e96b0e8fc57da3f0	engineering protein therapeutics: predictive performances of a structure-based virtual affinity maturation protocol	focusing;fisica molecular;energie libre;proteine;focalizacion;interaction moleculaire;focalisation;etude experimentale;molecular interaction;echantillonnage;biopolimero;biopolymer;biopolymere;ingenieria de proteinas;residu;sampling;interfase;physique moleculaire;interaccion molecular;energia enlace;interface;macromolecule;proteina;energia libre;genie proteique;macromolecula;muestreo;residuo;protein;molecular physics;residue;estudio experimental;free energy;in vivo;protein engineering;energie liaison;binding energy	The implementation of a structure based virtual affinity maturation protocol and evaluation of its predictivity are presented. The in silico protocol is based on conformational sampling of the interface residues (using the Dead End Elimination/A* algorithm), followed by the estimation of the change of free energy of binding due to a point mutation, applying MM/PBSA calculations. Several implementations of the protocol have been evaluated for 173 mutations in 7 different protein complexes for which experimental data were available: the use of the Boltzamnn averaged predictor based on the free energy of binding (ΔΔG(*)) combined with the one based on its polar component only (ΔΔE(pol*)) led to the proposal of a subset of mutations out of which 45% would have successfully enhanced the binding. When focusing on those mutations that are less likely to be introduced by natural in vivo maturation methods (99 mutations with at least two base changes in the codon), the success rate is increased to 63%. In another evaluation, focusing on 56 alanine scanning mutations, the in silico protocol was able to detect 89% of the hot-spots.	a* search algorithm;alanine;anatomical maturation;biologic development;dead-end elimination;exanthema;kerrison predictor;ninety nine;performance;point mutation;processor affinity;protein engineering;sampling (signal processing);sampling - surgical action;subgroup;video-in video-out;free energy	Michael Oberlin;Romano T. Kroemer;Vincent Mikol;Hervé Minoux;Erdogan Tastan;Nicolas Baurin	2012	Journal of chemical information and modeling	10.1021/ci3001474	macromolecule;biochemistry;sampling;chemistry;bioinformatics;interface;protein engineering;in vivo;binding energy;residue	Comp.	10.328204783149312	-61.585140111640754	17655
f277083395482e395d8f0e13cfe919f0e5173163	scry: extending sparql with custom data processing methods for the life sciences	customization;data processing;rdf generation;sparql;extension	An ever-growing amount of life science databases are (partially) exposed as RDF graphs (e.g. UniProt, TCGA, DisGeNET, Human Protein Atlas), complementing traditional methods to disseminate biodata. The SPARQL query language provides a powerful tool to rapidly retrieve and integrate this data. However, the inability to incorporate custom data processing methods in SPARQL queries inhibits its application in many life science use cases. It should take far less effort to integrate data processing methods, such as BLAST, with SPARQL. We propose an effective framework for extending SPARQL with custom methods should fulfill four key requirements: generality, reusability, interoperability and scalability. We present SCRY, the SPARQL compatible service layer, which provides custom data processing within SPARQL queries. SCRY is a lightweight SPARQL endpoint that interprets parts of basic graph patterns as input for user defined procedures, generating an RDF graph against which the query is resolved on-demand. SCRY’s federationoriented design allows for easy integration with existing endpoints, extending SPARQL’s functionality to include custom data processing methods in a decoupled, standards-compliant, tool independent manner. We demonstrate the power of this approach by performing statistical analysis of a benchmark, and by incorporating BLAST in a query which simultaneously finds the tissues expressing Hemoglobin β and its homologs.	abstraction layer;analysis of algorithms;blast;benchmark (computing);communication endpoint;database;disgenet;human protein atlas;interoperability;overhead (computing);python;query language;requirement;sparql;scalability;semantic web;service layer;standards-compliant;uniprot	Bas Stringer;Albert Meroño-Peñuela;Sanne Abeln;Frank van Harmelen;Jaap Heringa	2016			computer science;sparql;data mining;database;information retrieval;rdf schema	Web+IR	-4.285315582994893	-63.34963889626351	17685
420bf61d6b9060341c55f302173102035f03d22c	inherited disorder phenotypes: controlled annotation and statistical analysis for knowledge mining from gene lists	signs and symptoms;web system;software;genomics;aggregation function;complex disease;genetics medical;databases nucleic acid;database management systems;genetic diseases inborn;databases genetic;information presentation;genetics;computational biology bioinformatics;models genetic;internet;statistical analysis;online mendelian inheritance in man;models statistical;algorithms;humans;user computer interface;combinatorial libraries;computational biology;phenotype;computer appl in life sciences;information storage and retrieval;gene expression profiling;oligonucleotide array sequence analysis;phenylketonurias;biological process;genetic disease;microarrays;bioinformatics	Analysis of inherited diseases and their associated phenotypes is of great importance to gain knowledge of underlying genetic interactions and could ultimately give clinically useful insights into disease processes, including complex diseases influenced by multiple genetic loci. Nevertheless, to date few computational contributions have been proposed for this purpose, mainly due to lack of controlled clinical information easily accessible and structured for computational genome-wise analyses. To allow performing phenotype analyses of inherited disorder related genes we implemented new original modules within GFINDer http://www.bioinformatics.polimi.it/GFINDer/ , a Web system we previously developed that dynamically aggregates functional annotations of user uploaded gene lists and allows performing their statistical analysis and mining. New GFINDer modules allow annotating large numbers of user classified biomolecular sequence identifiers with morbidity and clinical information, classifying them according to genetic disease phenotypes and their locations of occurrence, and statistically analyzing the obtained classifications. To achieve this we exploited, normalized and structured the information present in textual form in the Clinical Synopsis sections of the Online Mendelian Inheritance in Man (OMIM) databank. Such valuable information delineates numerous signs and symptoms accompanying many genetic diseases and it is divided into phenotype location categories, either by organ system or type of finding. Supporting phenotype analyses of inherited diseases and biomolecular functional evaluations, GFINDer facilitates a genomic approach to the understanding of fundamental biological processes and complex cellular mechanisms underlying patho-physiological phenotypes.	annotation;attention deficit hyperactivity disorder;biological processes;biological system;categories;classification;computation;data mining;databases;endocrine system diseases;evaluation;hereditary diseases;identifier;interaction;mode of inheritance;mood disorders;morbidity - disease rate;online mendelian inheritance in man;phenotype;video synopsis;body system	Marco Masseroli;Osvaldo Galati;Mauro Manzotti;Karina Gibert;Francesco Pinciroli	2005	BMC Bioinformatics	10.1186/1471-2105-6-S4-S18	biology;genomics;the internet;dna microarray;bioinformatics;phenotype;gene expression profiling;biological process;genetics;omim : online mendelian inheritance in man	Comp.	-0.34667766413815887	-62.11095272928062	17697
496dd71be8032024f7e490728a76cbe861e521f6	invariant visual object and face recognition: neural and computational bases, and a model, visnet	biological patents;object recognition;biomedical journals;text mining;face neurons;europe pubmed central;citation search;citation networks;qa76 electronic computers computer science computer software;invariance;research articles;abstracts;open access;life sciences;spatial scene;clinical guidelines;inferior temporal visual cortex;visual perception;full text;rc0321 neuroscience biological psychiatry neuropsychiatry;visual cortex;rest apis;orcids;europe pmc;biomedical research;visnet;bioinformatics;literature search	Neurophysiological evidence for invariant representations of objects and faces in the primate inferior temporal visual cortex is described. Then a computational approach to how invariant representations are formed in the brain is described that builds on the neurophysiology. A feature hierarchy model in which invariant representations can be built by self-organizing learning based on the temporal and spatial statistics of the visual input produced by objects as they transform in the world is described. VisNet can use temporal continuity in an associative synaptic learning rule with a short-term memory trace, and/or it can use spatial continuity in continuous spatial transformation learning which does not require a temporal trace. The model of visual processing in the ventral cortical stream can build representations of objects that are invariant with respect to translation, view, size, and also lighting. The model has been extended to provide an account of invariant representations in the dorsal visual system of the global motion produced by objects such as looming, rotation, and object-based movement. The model has been extended to incorporate top-down feedback connections to model the control of attention by biased competition in, for example, spatial and object search tasks. The approach has also been extended to account for how the visual system can select single objects in complex visual scenes, and how multiple objects can be represented in a scene. The approach has also been extended to provide, with an additional layer, for the development of representations of spatial scenes of the type found in the hippocampus.	cerebral cortex;computation;learning rule;object-based language;organizing (structure);physical object;primates;science of neurophysiology;scott continuity;self-organization;spatial analysis;synaptic package manager;top-down and bottom-up design;face recognition	Edmund T. Rolls	2012		10.3389/fncom.2012.00035	psychology;computer vision;text mining;neuroscience;visual perception;computer science;bioinformatics;artificial intelligence;invariant;cognitive neuroscience of visual object recognition;machine learning;communication;biased competition theory	ML	20.757985190284998	-67.66715177821658	17728
444519cac3bb5ef768566319afb6e3e82eb64162	study on the impact of affinity on the results of data mining in biological populations		In biological populations genetic correlations between individuals are the result of genetic relatedness. In its standard form, the data is not stored in a way that lets users easily take into account the information in the processes of data mining. The aim of this study was to verify whether and to what extent inclusion of this additional information (in the form of grandparents and great grandparents of data) affects the results of data mining. This paper is one of the stages of interdisciplinary research project investigating a population of Silesian horses. The database contains breeding history of roughly the complete population of Silesian horses bred in Poland over the last 50 years. Tests were conducted with a subset of individuals known to their parents due to the assumption that we try to predict characteristics of offspring, knowing the characteristics of ancestors (parents, grandparents, great grandparents).	affinity analysis;data mining;population	Pawel Skrobanek;Olgierd Unold;Ewa Walkowicz;Henryk Maciejewski;Maciej Dobrowolski	2012		10.1007/978-3-642-34654-5_12	toxicology;bioinformatics;data mining	ML	2.453829186290416	-56.63554780281371	17734
c28df6575cb7044339dcfcd184e4ebcdd58e188f	the edinburgh mouse atlas: using the cd	embryos;data handling	This paper provides a simple introduction to the reconstructions and data-handling tools stored on the Edinburgh Mouse Atlas CD, together with some of the ways in which the viewers and software can be used to understand mouse development and analyse data. The key aspect of the Mouse Atlas is that the underlying models are a complete representation of the histology, which has not been constrained to a particular interpretation. This means, for example, that the current anatomy domains can be further subdivided as required to any resolution up to the resolution of the models (2-7 microm). In the CD of the early embryos described here, virtually all tissues that can be usefully distinguished either by the histology or morphologically have been delineated.	anatomic structures;assumed;body tissue;cervical atlas;emage;embryo;handling (psychology);funding grant	Richard A. Baldock;Jonathan Bard;Roberto Brunelli;Bill Hill;Matthew Kaufman;Kristie Opstad;David K Smith;Margaret Stark;Andrew M. Waterhouse;Yiya Yang;Duncan Davidson	2001	Briefings in bioinformatics	10.1093/bib/2.2.159	biology;embryo;computer science;group method of data handling;operations research;genetics;anatomy	AI	-1.0776443942704166	-62.611435073272965	17804
f7c65c16a83ff39341b046752d383ece3ab6a0bd	product release pathways in human and plasmodium falciparum phosphoribosyltransferase		Atomistic molecular dynamics (MD) simulations coupled with the metadynamics technique were carried out to delineate the product (PPi.2Mg and IMP) release mechanisms from the active site of both human (Hs) and Plasmodium falciparum (Pf) hypoxanthine-guanine-(xanthine) phosphoribosyltransferase (HG(X)PRT). An early movement of PPi.2Mg from its binding site has been observed. The swinging motion of the Asp side chain (D134/D145) in the binding pocket facilitates the detachment of IMP, which triggers the opening of flexible loop II, the gateway to the bulk solvent. In PfHGXPRT, PPi.2Mg and IMP are seen to be released via the same path in all of the biased MD simulations. In HsHGPRT too, the product molecules follow similar routes from the active site; however, an alternate but minor escape route for PPi.2Mg has been observed in the human enzyme. Tyr 104 and Phe 186 in HsHGPRT and Tyr 116 and Phe 197 in PfHGXPRT are the key residues that mediate the release of IMP, whereas the motion of PPi.2Mg away from the reaction center is guided by the negatively charged Asp and Glu and a few positively charged residues (Lys and Arg) that line the product release channels. Mutations of a few key residues present in loop II of Trypanosoma cruzi (Tc) HGPRT have been shown to reduce the catalytic efficiency of the enzyme. Herein, in silico mutation of corresponding residues in loop II of HsHGPRT and PfHGXPRT resulted in partial opening of the flexible loop (loop II), thus exposing the active site to bulk water, which offers a rationale for the reduced catalytic activity of these two mutant enzymes. Investigations of the product release from these HsHGPRT and PfHGXPRT mutants delineate the role of these important residues in the enzymatic turnover.	aspartate;charge (electrical);design rationale;drug implant;hypoxanthine phosphoribosyltransferase;lesch-nyhan syndrome;lysine;metadynamics;molecular dynamics;mutation;phenylalanine;plasmodium falciparum ag:acnc:pt:bld:qn:if;precipitating factors;simulation;trypanosoma cruzi;tyrosine;enzyme activity	Tarak Karmakar;Sourav Roy;Hemalatha Balaram;Meher K. Prakash;Sundaram Balasubramanian	2016	Journal of chemical information and modeling	10.1021/acs.jcim.6b00203	crystallography;biochemistry;stereochemistry;chemistry	Robotics	9.154138579247387	-63.02272009139985	17812
36545920162d0cf2fd80f88696bf49677d62216c	combination of genetic screening and molecular dynamics as a useful tool for identification of disease-related mutations: zasp pdz domain g54s mutation case		Cypher/ZASP (LDB3 gene) is known to interact with a network of proteins. It binds to α-actinin and the calcium voltage channels (LTCC) via its PDZ domain. Here we report the identification of a highly conserved ZASP G54S mutation classified as a variant of unknown significance in a sample of an adult with hypertrophic cardiomyopathy (HCM). The initial bioinformatics calculations strongly evaluated G54S as damaging. Furthermore, we employed accelerated and classical molecular dynamics and free energy calculations to study the structural impact of this mutation on the ZASP apo form and to address the question of whether it can be linked to HCM. Seventeen independent MD runs and simulations of 2.5 μs total were performed and showed that G54S perturbs the α2 helix position via destabilization of the adjacent loop linked to the β5 sheet. This also leads to the formation of a strong H-bond between peptide target residues Leu17 and Gln66, thus restricting both the α-actinin2 and LTCC C-terminal peptides to access their natural binding site and reducing in this way their binding capacity. On the basis of these observations and the adult's clinical data, we propose that ZASP(G54S) and presumably other ZASP PDZ domain mutations can cause HCM. To the best of our knowledge, this is the first reported ZASP PDZ domain mutation that might be linked to HCM. The integrated workflow used in this study can be applied for the identification and description of other mutations that might be related to particular diseases.		Filip Fratev;Elina Mihaylova;Ilza Pajeva	2014	Journal of chemical information and modeling	10.1021/ci5001136	molecular biology;bioinformatics;genetics	Comp.	8.696592641537414	-61.968652376636925	17822
f2d9290a828bf6336fb95af42d01bb4de30d8d7f	what does a policy network learn after mastering a pong game?		Activities in reinforcement learning (RL) revolve around learning the Markov decision process (MDP) model, in particular, the following quantities: state values V , state-action values Q, and policy π. Due to high computational cost, the reinforcement learning problem is commonly formulated for learning task specific representations with handcrafted input features. In this report, we discuss an alternative end-to-end approach where the RL attempts to learn general task representations, in this context, learning how to play the Pong game from a sequence of screen snap shots. We apply artificial neural networks to approximate a policy of a reinforcement learning model. The policy network learns to play the game from a sequence of frames without any extra semantics apart from the pixel information and the score. Many games are simulated using different network architectures and different parameters settings. We examine the activation of hidden nodes and the weights between the input and the hidden layers, before and after the RL has successfully learned to play the game. Insights into the internal learning mechanisms and future research directions are discussed.	algorithmic efficiency;approximation algorithm;artificial neural network;biological system;bus mastering;computation;end-to-end encryption;end-to-end principle;gradient;hebbian theory;markov chain;markov decision process;network architecture;open research;pixel;reinforcement learning	Somnuk Phon-Amnuaisuk	2017		10.1007/978-3-319-69456-6_18		ML	19.08075187761523	-53.94021428397469	17845
0a3617fcc83c1acaaf0fee2417684645dabe62b2	dasmiweb: online integration, analysis and assessment of distributed protein interaction data	genes;software;serum immunosuppressive factor human;confidence measure;datasets;protein interaction domains and motifs;internet;online systems;user computer interface;protein interaction;protein interaction mapping;systems integration	In recent years, we have witnessed a substantial increase of the amount of available protein interaction data. However, most data are currently not readily accessible to the biologist at a single site, but scattered over multiple online repositories. Therefore, we have developed the DASMIweb server that affords the integration, analysis and qualitative assessment of distributed sources of interaction data in a dynamic fashion. Since DASMIweb allows for querying many different resources of protein and domain interactions simultaneously, it serves as an important starting point for interactome studies and assists the user in finding publicly accessible interaction data with minimal effort. The pool of queried resources is fully configurable and supports the inclusion of own interaction data or confidence scores. In particular, DASMIweb integrates confidence measures like functional similarity scores to assess individual interactions. The retrieved results can be exported in different file formats like MITAB or SIF. DASMIweb is freely available at http://www.dasmiweb.de.	access network;cloud computing;dna integration;distributed computing;interactome;multimodal interaction;repository;score;server (computing);source input format;sven jaschan;user interface;warren abstract machine;web server;amsonic acid;eric;protein protein interaction	Hagen Blankenburg;Fidel Ramírez;Joachim Büch;Mario Albrecht	2009		10.1093/nar/gkp438	biology;the internet;bioinformatics;gene;system integration	Comp.	-1.6183995974352097	-59.24448977972197	17853
18a3839435751ae1a22579605596d031607ff89e	space efficient computation of rare maximal exact matches between multiple sequences	gene loss;genome rearrangement;nucleotides;comparative genomics;regulatory element;suffix tree;strings;large scale;genome comparison;word alignment;horizontal gene transfer;point mutation;algorithms;genome evolution;suffix trees;alignment	In this article, we propose a new method for computing rare maximal exact matches between multiple sequences. A rare match between k sequences S(1), ... , S(k) is a string that occurs at most t(i)-times in the sequence S(i), where the t(i) > 0 are user-defined thresholds. First, the suffix tree of one of the sequences (the reference sequence) is built, and then the other sequences are matched separately against this suffix tree. Second, the resulting pairwise exact matches are combined to multiple exact matches. A clever implementation of this method yields a very fast and space efficient program. This program can be applied in several comparative genomics tasks, such as the identification of synteny blocks between whole genomes.	algorithm;computation (action);dspace;experiment;genome;maximal set;suffix tree;synteny;viz: the computer game;interest	Enno Ohlebusch;Stefan Kurtz	2008	Journal of computational biology : a journal of computational molecular cell biology	10.1089/cmb.2007.0105	point mutation;biology;nucleotide;bioinformatics;genome evolution;theoretical computer science;mathematics;horizontal gene transfer;comparative genomics;genetics;algorithm	Comp.	-1.1476558404672752	-52.14033447535054	17923
7b83256ef7315763430320706f85414048d29c7d	microcomputer programs for back translation of protein to dna sequences and analysis of ambiguous dna sequences	dna;computers;software;computer program;proteine;methods;computerized processing;amino acid sequence;genetic code;microordinateur;microcomputer;traduction;primary structure;proteins;translation;base sequence;dna sequence;code genetique;traitement informatique;microcomputers;programme ordinateur;protein biosynthesis;structure primaire	Three computer programs are described which may be used to translate a DNA sequence into a protein sequence, back translate the protein sequence into an ambiguous DNA sequence, and then do pattern searching in the ambiguous sequence. The programs are written in the C programming language, have been compiled to run on a microcomputer under the CP/M 80 operating system, and may be copied in binary format through a modem. They are also to become available for the IBM/PC.	amino acid sequence;binary file;cp/m;compiler;computer program;eighty;genetic translation process;ibm personal computer;inclusion body myositis (disorder);microcomputer;modem device component;operating system;peptide sequence;staphylococcal protein a;the c programming language	David W. Mount;Bruce Conrad	1984	Nucleic acids research	10.1093/nar/12.1Part2.819	biology;bioinformatics;microcomputer;genetics	Comp.	-4.510668205817756	-56.405702609825894	17926
8d17a94f352ac6624baa201cd2c8fc115f734693	neural processing of sensory and emotional-communicative information associated with the perception of vicarious pain	vicarious pain;pain communication;inferior parietal lobule ipl;inferior frontal gyrus ifg;functional magnetic resonance imaging fmri	The specific neural processes underlying vicarious pain perception are not fully understood. In this functional imaging study, 20 participants viewed pain-evoking or neutral images displaying either sensory or emotional-communicative information. The pain images displayed nociceptive agents applied to the hand or the foot (sensory information) or facial expressions of pain (emotional-communicative information) and were matched with their neutral counterparts. Combining pain-evoking and neutral images showed that body limbs elicited greater activity in sensory motor regions, whereas midline frontal and parietal cortices and the amygdala responded more strongly to faces. The pain-evoking images elicited greater activity than their neutral counterparts in the bilateral inferior frontal gyrus (IFG), the left inferior parietal lobule (IPL) and the bilateral extrastriate body area. However, greater pain-related activity was observed in the rostral IPL when images depicted a hand or foot compared to a facial expression of pain, suggesting a more specific involvement in the coding of somato-motor information. Posterior probability maps enabling Bayesian inferences further showed that the anterior IFG (BA 45 and 47) was the only region showing no intrinsic probability of activation by the neutral images, consistent with a role in the extraction of the meaning of pain-related visual cues. Finally, inter-individual empathy traits correlated with responses in the supracallosal mid/anterior cingulate cortex and the anterior insula when pain-evoking images of body limbs or facial expressions were presented, suggesting that these regions regulated the observer's affective-motivational response independent from the channels from which vicarious pain is perceived.	amygdaloid structure;area striata structure;bilateral filter;business architecture;chronic pain;cingulate cortex;consciousness;electroencephalography;empathy;face;frontal lobe gyrus;functional imaging;greater;health care;ifng gene;ifng wt allele;image;inferior frontal gyrus;inferior parietal lobule;insula of reil;limb structure;microtubule-associated proteins;neuroimaging;neutral monism;pain perception;parietal lobe;trait	Etienne Vachon-Presseau;Mathieu Roy;Marc-Olivier Martel;Geneviève Albouy;Jeni Chen;Lesley Budell;Michael J. Sullivan;Philip L Jackson;Pierre Rainville	2012	NeuroImage	10.1016/j.neuroimage.2012.06.030	psychology;cognitive psychology;developmental psychology;communication	HCI	17.412274730429058	-76.14543953395119	17977
d52dabbb50f6fbe1ef55786db9eb505921e6044c	anatomical parcellation of human brain using structural covariance	brain diffusion tensor imaging sparse matrices vectors silicon;magnetic resonance imaging anatomical parcellation human brain atlas structural covariance brain network analysis anatomical brain atlases structural covariance patterns white matter density grey matter density sparse representation anatomical connectivity functional connectivity mri;medical image processing biomedical mri brain covariance analysis image representation;sparse representation structural covariance brain parcellation	A reliable human brain atlas is critical for brain network analysis at macro-scale. Most studies employed existing anatomical brain atlases or randomly parcellated the whole brain into discrete regions. However, these anatomical atlases had a large variation in region sizes, and the random parcellation procedure was lack of explicit biological significance. In this study, we proposed a new brain parcellation framework which could automatically construct anatomical brain atlases for a specific group of subjects based on the structural covariance patterns. The changes of the modulated grey and white matter densities across individuals were used as features and sparse representation was employed to calculate the similarities. The results showed that our method achieved high consistency in brain parcellation on two independent datasets with well correspondence to existing anatomical atlases. Validation experiments on specific brain regions presented consistent parcellation patterns with anatomical and functional connectivity. These results implied that our method could generate biologically meaningful parcellations for the human brain.	brain atlas;brain implant;experiment;modulation;randomness;resting state fmri;social network analysis;sparse approximation;sparse matrix	Yu Zhang;Lingzhong Fan;Chunshui Yu;Tianzi Jiang	2014	2014 IEEE 11th International Symposium on Biomedical Imaging (ISBI)	10.1109/ISBI.2014.6868006	computer vision;machine learning	Vision	23.18415317624349	-78.03263615677146	17986
b9506b562784900e8f2f91367946a64f72626f0b	hpg pore: an efficient and scalable framework for nanopore sequencing data	computational biology bioinformatics;algorithms;combinatorial libraries;computer appl in life sciences;microarrays;bioinformatics	The use of nanopore technologies is expected to spread in the future because they are portable and can sequence long fragments of DNA molecules without prior amplification. The first nanopore sequencer available, the MinION™ from Oxford Nanopore Technologies, is a USB-connected, portable device that allows real-time DNA analysis. In addition, other new instruments are expected to be released soon, which promise to outperform the current short-read technologies in terms of throughput. Despite the flood of data expected from this technology, the data analysis solutions currently available are only designed to manage small projects and are not scalable. Here we present HPG Pore, a toolkit for exploring and analysing nanopore sequencing data. HPG Pore can run on both individual computers and in the Hadoop distributed computing framework, which allows easy scale-up to manage the large amounts of data expected to result from extensive use of nanopore technologies in the future. HPG Pore allows for virtually unlimited sequencing data scalability, thus guaranteeing its continued management in near future scenarios. HPG Pore is available in GitHub at http://github.com/opencb/hpg-pore .	apache hadoop;computer;distributed computing;individual computers;instrument - device;microsequencer;mobile device;real-time clock;scalability;solutions;throughput;usb	Joaquín Tárraga;Asunción Gallego;Vicente Arnau;Ignacio Medina;Joaquín Dopazo	2016		10.1186/s12859-016-0966-0	biology;dna microarray;computer science;bioinformatics;data science	DB	-1.8805283925850325	-54.756750759352826	18045
041ab0031f655ff2d313db5ae7150a9d67e437e3	rnashapes: an integrated rna analysis package based on abstract shapes	computer architecture;shape matching;software package;graphic user interface;sliding window	We introduce RNAshapes, a new software package that integrates three RNA analysis tools based on the abstract shapes approach: the analysis of shape representatives, the calculation of shape probabilities and the consensus shapes approach. This new package is completely reimplemented in C and outruns the original implementations significantly in runtime and memory requirements. Additionally, we added a number of useful features like suboptimal folding with correct dangling energies, structure graph output, shape matching and a sliding window approach.	command-line interface;energy, physics;graph - visual representation;graphical user interface;probability;requirement;usability;user interface device component	Peter Steffen;Björn Voß;Marc Rehmsmeier;Jens Reeder;Robert Giegerich	2006	Bioinformatics	10.1093/bioinformatics/btk010	sliding window protocol;real-time computing;computer hardware;computer science;bioinformatics;theoretical computer science;graphical user interface	Graphics	-2.114201639941175	-57.8860321895321	18064
dd0ea77d1cc0ab07c9fad05f6c3f5bf0c313a2df	energy directed conformational search of protein loops and segments				Robert E. Bruccoleri	1995				Theory	1.6792631021798554	-64.6731184592662	18117
1425765971a56490cecad11964da67e3fa78b0cb	using co-occurrence network structure to extract synonymous gene and protein names from medline abstracts	computers;software;vocabulary controlled;information systems;text mining;medline;database management systems;computer graphics;databases bibliographic;knowledge extraction;databases genetic;gold standard;information overload;computational biology bioinformatics;terminology as topic;named entity recognition;gene expression regulation neoplastic;genome;reproducibility of results;artificial intelligence;algorithms;pattern recognition automated;humans;network structure;neoplasms;neural networks computer;combinatorial libraries;software design;computational biology;computer appl in life sciences;high efficiency;information storage and retrieval;natural language processing;programming languages;microarrays;bioinformatics;automation	Text-mining can assist biomedical researchers in reducing information overload by extracting useful knowledge from large collections of text. We developed a novel text-mining method based on analyzing the network structure created by symbol co-occurrences as a way to extend the capabilities of knowledge extraction. The method was applied to the task of automatic gene and protein name synonym extraction. Performance was measured on a test set consisting of about 50,000 abstracts from one year of MEDLINE. Synonyms retrieved from curated genomics databases were used as a gold standard. The system obtained a maximum F-score of 22.21% (23.18% precision and 21.36% recall), with high efficiency in the use of seed pairs. The method performs comparably with other studied methods, does not rely on sophisticated named-entity recognition, and requires little initial seed knowledge.	abstract summary;collections (publication);f1 score;information overload;medline;name;named-entity recognition;published database;test set;text mining	Aaron M. Cohen;William R. Hersh;Christopher Dubay;Kent A. Spackman	2004	BMC Bioinformatics	10.1186/1471-2105-6-103	text mining;dna microarray;gold standard;computer science;bioinformatics;software design;automation;information overload;data mining;knowledge extraction;computer graphics;information retrieval;information system;genome	Comp.	-2.657020182533166	-63.889409421034394	18121
89d310ca6ad846a3ef145695dfd0363a87f3f14f	preemptive diagnosis of chronic kidney disease using machine learning techniques		Chronic Kidney Disease (CKD) is a major public health concern with rising prevalence. In Saudi Arabia, approximately 2 Billion Riyals are solely allocated for renal replacement therapy which is required for patients with advanced stages of CKD. Therefore, this study aims to decrease the number of patients and the expenses needed for treatment by preemptively diagnosing chronic kidney disease accurately using data mining and machine learning techniques. Data have been collected from a region that has never been explored before in literature. This study uses Saudi data retrieved from King Fahd University Hospital(KFUH) in Khobar to carry out the experiment. Experimental Results show that ANN, SVM, Naïve Bayes achieved a testing accuracy of 98.0% while k-NN has achieved an accuracy of 93.9%.		Reem A. Alassaf;Khawla A. Alsulaim;Noura Y. Alroomi;Nouf S. Alsharif;Mishael F. Aljubeir;Sunday O. Olatunji;Alaa Y. Alahmadi;Mohammed Imran;Rahma A. Alzahrani;Nora S. Alturayeif	2018	2018 International Conference on Innovations in Information Technology (IIT)	10.1109/INNOVATIONS.2018.8606040	naive bayes classifier;renal replacement therapy;support vector machine;public health;kidney disease;statistical classification;computer science;machine learning;artificial intelligence	Robotics	6.6620730258927825	-76.37951402971179	18164
929c0b35c74c034e6444413404006da427f7fed1	hippocampal based model reveals the distinct roles of dentate gyrus and ca3 during robotic spatial navigation		Animals are exemplary explorers and achieve great navigational performances in dynamic environments. Their robotic counterparts still have difficulties in self-localization and environment mapping tasks. Place cells, a type of cell firing at specific positions in the environment, are found in multiple areas of the hippocampal formation. Although, the functional role of these areas with a similar type of cell behavior is still not clearly distinguished. Biomimetic models of navigation have been tested in the context of computer simulations or small and controlled arenas. In this paper, we present a computational model of the hippocampal formation for robotic spatial representation within large environments. Necessary components for the formation of a cognitive map [1], such as grid and place cells, were obtained through attractor dynamics. Prediction of future hippocampal inputs was performed through self-organization. Obtained data suggests that the integration of the described components is sufficient for robotic space representation. In addition, our results suggest that dentate gyrus (DG), the hippocampal input area, integrates signals from different dorsal-ventral scales of grid cells and that spatial and sensory input are not necessarily associated in this region. Moreover, we present a mechanism for prediction of future hippocampal events based on associative learning.	spatial navigation	Diogo Santos Pata;Alex Escuredo;Stéphane Lallée;Paul F. M. J. Verschure	2014		10.1007/978-3-319-09435-9_24	neuroscience;hippocampal formation	Robotics	19.253738429174103	-67.80686593154566	18228
3ad370045d4e699392f027959e2df42539f77301	context-driven discovery of gene cassettes in mobile integrons using a computational grammar	dna;genes;drug resistance microbial;integrons;gold standard;gene cassette;higher order;computational biology bioinformatics;antibiotic resistance;dna structure;algorithms;combinatorial libraries;false positive;computational biology;computer appl in life sciences;antibiotic resistance genes;public health;microarrays;bioinformatics	Gene discovery algorithms typically examine sequence data for low level patterns. A novel method to computationally discover higher order DNA structures is presented, using a context sensitive grammar. The algorithm was applied to the discovery of gene cassettes associated with integrons. The discovery and annotation of antibiotic resistance genes in such cassettes is essential for effective monitoring of antibiotic resistance patterns and formulation of public health antibiotic prescription policies. We discovered two new putative gene cassettes using the method, from 276 integron features and 978 GenBank sequences. The system achieved κ = 0.972 annotation agreement with an expert gold standard of 300 sequences. In rediscovery experiments, we deleted 789,196 cassette instances over 2030 experiments and correctly relabelled 85.6% (α ≥ 95%, E ≤ 1%, mean sensitivity = 0.86, specificity = 1, F-score = 0.93), with no false positives. Error analysis demonstrated that for 72,338 missed deletions, two adjacent deleted cassettes were labeled as a single cassette, increasing performance to 94.8% (mean sensitivity = 0.92, specificity = 1, F-score = 0.96). Using grammars we were able to represent heuristic background knowledge about large and complex structures in DNA. Importantly, we were also able to use the context embedded in the model to discover new putative antibiotic resistance gene cassettes. The method is complementary to existing automatic annotation systems which operate at the sequence level.	annotation;antibiotic resistance, microbial;awards;candidate gene identification;compact cassette;context-sensitive grammar;deletion (action);design of experiments;discoverability;embedded system;embedding;experiment;experimental autoimmune encephalomyelitis;f1 score;genbank;heuristic;high-level programming language;infectious disease medicine;informatics;integrons;javascript;manuscripts;policy;sensitivity and specificity;seven of nine;signal recognition particle (sensu eukaryota) location;software testing controversies;systems design;tracer;algorithm;citation;funding grant;hemoglobin andrew-minneapolis	Guy Tsafnat;Enrico W. Coiera;Sally R. Partridge;Jaron Schaeffer;Jonathan R. Iredell	2009		10.1186/1471-2105-10-281	biology;public health;biotechnology;bioinformatics;genetics;dna	Comp.	2.124920823901367	-56.44910102553228	18237
563ae8cd335856ff18f11632c1f2abc091845fe8	probabilistic mixture regression models for alignment of lc-ms data	peptides;animals chromatography liquid computational biology databases factual humans mass spectrometry models chemical proteins regression analysis reproducibility of results sensitivity and specificity;splines mathematics chromatography expectation maximisation algorithm mass spectra proteins proteomics regression analysis;computer model;mass spectra;mass spectrometry;regression model;mixed regression model;joints;splines mathematics;retention time;data model;computational modeling;liquid chromatography;proteins;expectation maximization;expectation maximization algorithm;liquid chromatography mass spectrometry;data models probabilistic logic peptides extraterrestrial measurements computational modeling joints proteins;regression analysis;probabilistic logic;proteomics;proteins probabilistic mixture regression model lc ms data alignment liquid chromatography mass spectrometry retention time expectation maximization algorithm spline based mixture regression model prior transformation density model dynamic time warping correlation optimized warping continuous profile model peptides;dynamic time warping;extraterrestrial measurements;chromatography;data models;expectation maximization liquid chromatography mass spectrometry mixed regression model;expectation maximisation algorithm	A novel framework of a probabilistic mixture regression model (PMRM) is presented for alignment of liquid chromatography-mass spectrometry (LC-MS) data with respect to retention time (RT) points. The expectation maximization algorithm is used to estimate the joint parameters of spline-based mixture regression models and prior transformation density models. The latter accounts for the variability in RT points and peak intensities. The applicability of PMRM for alignment of LC-MS data is demonstrated through three data sets. The performance of PMRM is compared with other alignment approaches including dynamic time warping, correlation optimized warping, and continuous profile model in terms of coefficient variation of replicate LC-MS runs and accuracy in detecting differentially abundant peptides/proteins.	alignment;coefficient;dynamic time warping;expectation–maximization algorithm;liquid chromatography mass spectrometry;self-replicating machine;sensor;spatial variability;spline (mathematics)	Getachew K. Befekadu;Mahlet G. Tadesse;Tsung-Heng Tsai;Habtom W. Ressom	2011	IEEE/ACM Transactions on Computational Biology and Bioinformatics	10.1109/TCBB.2010.88	econometrics;mass spectrometry;expectation–maximization algorithm;computer science;machine learning;proteomics;regression analysis	ML	4.713100634133652	-53.78663317507343	18239
00353bef128d246f21da3076b002a30d7316e557	the problem of bias in training data in regression problems in medical decision support	anticoagulant drug therapy;artificial neural networks;regression;machine learning;extreme value;drug therapy;stratified sampling;medical decision support;artificial neural network	This paper describes a bias problem encountered in a machine learning approach to outcome prediction in anticoagulant drug therapy. The outcome to be predicted is a measure of the clotting time for the patient; this measure is continuous and so the prediction task is a regression problem. Artificial neural networks (ANNs) are a powerful mechanism for learning to predict such outcomes from training data. However, experiments have shown that an ANN is biased towards values more commonly occurring in the training data and is thus, less likely to be correct in predicting extreme values. This issue of bias in training data in regression problems is similar to the associated problem with minority classes in classification. However, this bias issue in classification is well documented and is an on-going area of research. In this paper, we consider stratified sampling and boosting as solutions to this bias problem and evaluate them on this outcome prediction problem and on two other datasets. Both approaches produce some improvements with boosting showing the most promise.	anticoagulants;artificial neural network;boosting (machine learning);class;decision support system;document completion status - documented;experiment;forecast of outcome;machine learning;patients;pharmacotherapy;sampling (signal processing);stratified sampling	Brian MacNamee;Padraig Cunningham;Stephen Byrne;O. I. Corrigan	2002	Artificial intelligence in medicine	10.1016/S0933-3657(01)00092-6	regression;computer science;artificial intelligence;machine learning;extreme value theory;data mining;stratified sampling;artificial neural network;statistics	ML	5.940654780260862	-75.42975753709044	18248
22fc57c22a0d87ba250c97c93fe66698e66be586	individual differences in sentence comprehension: a functional magnetic resonance imaging investigation of syntactic and lexical processing demands	nuclear magnetic resonance imaging;language comprehension;female;carga mental;comprension verbal;mental load;brain;syntax;imagineria rmn;procesamiento informacion;systeme nerveux central;topographie;selected works;working memory capacity;adolescent;frase;lexicon;interindividual comparison;reading;oxygen;lenguaje;male;sentence comprehension;hombre;langage;encefalo;image processing computer assisted;syntaxe;topography;comprehension verbale;functional imaging;sistema nervioso central;verbal comprehension;sentence;functional connectivity;comparacion interindividual;brain mapping;lecture;encephale;lexical processing;comparaison interindividuelle;adult;functional magnetic resonance images;magnetic resonance imaging;indexation;cognitive performance;cognition;information processing;human;individuality;cognicion;bepress;imagerie rmn;humans;phrase;encephalon;language;imagineria funcional;lectura;lexico;individual difference;sintaxis;traitement information;functional laterality;charge mentale;central nervous system;topografia;comprehension;task performance and analysis;homme;imagerie fonctionnelle;lexique	Language comprehension is neurally underpinned by a network of collaborating cortical processing centers; individual differences in comprehension must be related to some set of this network's properties. This study investigated the neural bases of individual differences during sentence comprehension by examining the network's response to two variations in processing demands: reading sentences containing words of high versus low lexical frequency and having simpler versus more complex syntax. In a functional magnetic resonance imaging study, readers who were independently identified as having high or low working memory capacity for language exhibited three differentiating properties of their language network, namely, neural efficiency, adaptability, and synchronization. First, greater efficiency (defined as a reduction in activation associated with improved performance) was manifested as less activation in the bilateral middle frontal and right lingual gyri in high-capacity readers. Second, increased adaptability was indexed by larger lexical frequency effects in high-capacity readers across bilateral middle frontal, bilateral inferior occipital, and right temporal regions. Third, greater synchronization was observed in high-capacity readers between left temporal and left inferior frontal, left parietal, and right occipital regions. Synchronization interacted with adaptability, such that functional connectivity remained constant or increased with increasing lexical and syntactic demands in high-capacity readers, whereas low-capacity readers either showed no reliable differentiation or a decrease in functional connectivity with increasing demands. These results are among the first to relate multiple cortical network properties to individual differences in reading capacity and suggest a more general framework for understanding the relation between neural function and individual differences in cognitive performance.	base;bilateral filter;index;large;list comprehension;memory disorders;occipital lobe;resonance;resting state fmri;temporal lobe;tongue;sentence	Chantel S. Prat;Timothy A. Keller;Marcel Adam Just	2007	Journal of Cognitive Neuroscience	10.1162/jocn.2007.19.12.1950	psychology;cognitive psychology;comprehension;neuroscience;cognition;developmental psychology;syntax;effects of sleep deprivation on cognitive performance;individualism;information processing;central nervous system;topography;magnetic resonance imaging;functional imaging;working memory;oxygen;linguistics;language;brain mapping;communication;reading	NLP	16.269527012714295	-78.04267372502107	18270
6690a23632d9e60cc620ef5cbff8973ef3882a9b	determinants of antigenicity and specificity in immune response for protein sequences	western blot;animals;protein sequence;immunohistochemistry;embryos;computational biology bioinformatics;chip;antigens;b cell;secondary structure;drosophila melanogaster;evolutionary conservation;artificial intelligence;algorithms;solvent accessibility;humans;epitopes b lymphocyte;support vector machine;combinatorial libraries;computer appl in life sciences;immune response;microarrays;bioinformatics	Target specific antibodies are pivotal for the design of vaccines, immunodiagnostic tests, studies on proteomics for cancer biomarker discovery, identification of protein-DNA and other interactions, and small and large biochemical assays. Therefore, it is important to understand the properties of protein sequences that are important for antigenicity and to identify small peptide epitopes and large regions in the linear sequence of the proteins whose utilization result in specific antibodies. Our analysis using protein properties suggested that sequence composition combined with evolutionary information and predicted secondary structure, as well as solvent accessibility is sufficient to predict successful peptide epitopes. The antigenicity and the specificity in immune response were also found to depend on the epitope length. We trained the B-Cell Epitope Oracle (BEOracle), a support vector machine (SVM) classifier, for the identification of continuous B-Cell epitopes with these protein properties as learning features. The BEOracle achieved an F1-measure of 81.37% on a large validation set. The BEOracle classifier outperformed the classical methods based on propensity and sophisticated methods like BCPred and Bepipred for B-Cell epitope prediction. The BEOracle classifier also identified peptides for the ChIP-grade antibodies from the modENCODE/ENCODE projects with 96.88% accuracy. High BEOracle score for peptides showed some correlation with the antibody intensity on Immunofluorescence studies done on fly embryos. Finally, a second SVM classifier, the B-Cell Region Oracle (BROracle) was trained with the BEOracle scores as features to predict the performance of antibodies generated with large protein regions with high accuracy. The BROracle classifier achieved accuracies of 75.26-63.88% on a validation set with immunofluorescence, immunohistochemistry, protein arrays and western blot results from Protein Atlas database. Together our results suggest that antigenicity is a local property of the protein sequences and that protein sequence properties of composition, secondary structure, solvent accessibility and evolutionary conservation are the determinants of antigenicity and specificity in immune response. Moreover, specificity in immune response could also be accurately predicted for large protein regions without the knowledge of the protein tertiary structure or the presence of discontinuous epitopes. The dataset prepared in this work and the classifier models are available for download at https://sites.google.com/site/oracleclassifiers/ .	accessibility;amino acid sequence;biological markers;cell (microprocessor);chronic lymphocytic leukemia;conserved sequence;download;encode;embryo;epitopes;f1 score;fluorescent antibody technique;interaction;leukemia, b-cell;peptide sequence;proteomics;sensitivity and specificity;silo (dataset);support vector machine;western blotting;tertiary	Yulong Wang;Wenjun Wu;Nicolas N. Negre;Kevin P. White;Cheng Li;Parantu K. Shah	2010		10.1186/1471-2105-12-251	immunohistochemistry;chip;biology;support vector machine;embryo;molecular biology;immune system;dna microarray;computer science;bioinformatics;protein sequencing;antigen;immunology;conserved sequence;genetics;protein secondary structure	Comp.	9.112832303099488	-56.31625093596222	18285
26491c722cb9958eb71c407c33b0424a6e96b514	bioverse: enhancements to the framework for structural, functional and contextual modeling of proteins and proteomes	software;proteome;computer graphics;structure function;ease of use;models molecular;internet;proteins;protein conformation;user computer interface;protein interaction mapping;computational biology;protein interaction network	We have made a number of enhancements to the previously described Bioverse web server and computational biology framework (http://bioverse.compbio.washington.edu). In this update, we provide an overview of the new features available that include: (i) expansion of the number of organisms represented in the Bioverse and addition of new data sources and novel prediction techniques not available elsewhere, including network-based annotation; (ii) reengineering the database backend and supporting code resulting in significant speed, search and ease-of use improvements; and (iii) creation of a stateful and dynamic web application frontend to improve interface speed and usability. Integrated Java-based applications also allow dynamic visualization of real and predicted protein interaction networks.	biosphere;code refactoring;computational biology;data sources;database;imagery;interface device component;java programming language;proteome;server (computing);stateful firewall;usability;web application;web server	Jason E. McDermott;Michal Guerquin;Zachary Frazier;Aaron N. Chang;Ram Samudrala	2005	Nucleic Acids Research	10.1093/nar/gki401	kolmogorov structure function;biology;protein structure;the internet;usability;bioinformatics;proteome;computer graphics	Comp.	-2.214080014554678	-58.80249221531873	18338
0f0a612cf79c3f34eac65f6f905de439d461ef7e	ompdb: a database of β-barrel outer membrane proteins from gram-negative bacteria	gram negative bacteria;outer membrane protein;bacterial outer membrane proteins;protein structure tertiary;databases protein	We describe here OMPdb, which is currently the most complete and comprehensive collection of integral β-barrel outer membrane proteins from Gram-negative bacteria. The database currently contains 69,354 proteins, which are classified into 85 families, based mainly on structural and functional criteria. Although OMPdb follows the annotation scheme of Pfam, many of the families included in the database were not previously described or annotated in other publicly available databases. There are also cross-references to other databases, references to the literature and annotation for sequence features, like transmembrane segments and signal peptides. Furthermore, via the web interface, the user can not only browse the available data, but submit advanced text searches and run BLAST queries against the database protein sequences or domain searches against the collection of profile Hidden Markov Models that represent each family's domain organization as well. The database is freely accessible for academic users at http://bioinformatics.biol.uoa.gr/OMPdb and we expect it to be useful for genome-wide analyses, comparative genomics as well as for providing training and test sets for predictive algorithms regarding transmembrane β-barrels.	algorithm;amino acid sequence;annotation;blast;bibliographic reference;bioinformatics;browsing;classification;cross-reference;functional programming;gram-negative bacteria;hidden markov model;markov chain;membrane proteins;peptide sequence;pfam;signal peptides;user interface;gram;viral capsid secondary envelopment	Konstantinos D. Tsirigos;Pantelis G. Bagos;Stavros J. Hamodrakas	2011		10.1093/nar/gkq863	biology;bioinformatics;protein structure database	Comp.	-1.190457293706111	-59.786296589993974	18346
4e14e9f3bf0eafb4ec62019857f131c73517bff3	spike-frequency adaptation of a two-compartment neuron modulated by extracellular electric fields	spike initiation dynamic;bifurcation;spike frequency adaptation;morphological parameter;extracellular electric field;two compartment neuron	Spike-frequency adaptation has been shown to play an important role in neural coding. Based on a reduced two-compartment model, here we investigate how two common adaptation currents, i.e., voltage-sensitive potassium current ( $$I_{\mathrm{M}}$$ I M ) and calcium-sensitive potassium current ( $$I_{\mathrm{AHP}}$$ I AHP ), modulate neuronal responses to extracellular electric fields. It is shown that two adaptation mechanisms lead to distinct effects on the dynamical behavior of the neuron to electric fields. These effects depend on a neuronal morphological parameter that characterizes the ratio of soma area to total membrane area and internal coupling conductance. In the case of $$I_{\mathrm{AHP}}$$ I AHP current, changing the morphological parameter switches spike initiation dynamics between saddle-node on invariant cycle bifurcation and supercritical Hopf bifurcation, whereas it only switches between subcritical and supercritical Hopf bifurcations for $$I_{\mathrm{M}}$$ I M current. Unlike the morphological parameter, internal coupling conductance is unable to alter the bifurcation scenario for both adaptation currents. We also find that the electric field threshold for triggering neuronal steady-state firing is determined by two parameters, especially by the morphological parameter. Furthermore, the neuron with $$I_{\mathrm{AHP}}$$ I AHP current generates mixed-mode oscillations through the canard phenomenon for some small values of the morphological parameter. All these results suggest that morphological properties play a critical role in field-induced effects on neuronal dynamics, which could qualitatively alter the outcome of adaptation by modulating internal current between soma and dendrite. The findings are readily testable in experiments, which could help to reveal the mechanisms underlying how the neuron responds to electric field stimulus.	anhaptoglobinemia;acclimatization;action potential;anatomical compartments;bifurcation theory;calcium;cell body of neuron;conductance (graph);dendrites;dynamical system;electroconvulsive therapy;experiment;hopf bifurcation;mixed-signal integrated circuit;modulation;multi-compartment model;network switch;neural coding;node - plant part;population parameter;potassium;steady state;switch device component;tissue membrane;electric field	Guosheng Yi;Jiang Wang;Kai Ming Tsang;Xile Wei;Bin Deng;Chunxiao Han	2014	Biological Cybernetics	10.1007/s00422-014-0642-2	electronic engineering;neuroscience;control theory;mathematics;bifurcation theory;communication	ML	17.451821020785108	-71.1098854150662	18354
f40ec39a45785083968533bea16ddfe999eef358	systematic tracking of coordinated differential network motifs identifies novel disease-related genes by integrating multiple data	classification;network motifs;subgraph;disease genes;data integration	Recently, one of the most hotspots in system biology is exploring the disease pathogenesis by integrating different omics data. A lot of methods are developed to identify disease genes for an indepth understanding of a given disease or a biological process. However, most of them do not sufficiently consider the relationship between epigenetic and expressional changes in deregulated genes. Here, we propose a network based approach to identify disease related genes by properly combining the network topological characteristic and the biological characteristic. Our approach identifies network motifs with coordinated changed pattern, differential-methylation and differential-expression, in the context of a human signaling network by integrating DNA methylation and gene expression data. For validation, we do experiments by using colorectal cancer data sets, the results show that the classification performance of our approach outperforms the existing method. The screened network motifs and predicted genes are almost epigenetically deregulated, which are highly associated with colorectal cancer development. Furthermore, functional enrichment analysis reveals that the functions they enriched in are hallmarks of cancer. We not only provide a method for identification of disease related genes but also add a new perspective to integrate heterogeneous data and mine subgraph with significant biological characteristics pattern. HighlightsA new network approach is proposed to identify disease genes.The network motifs with significant characteristics are as the skeleton for analysis.The change patterns of genes of coordinated differential motifs are identified.		Kai Shi;Lin Gao;Bingbo Wang	2016	Neurocomputing	10.1016/j.neucom.2015.12.120	biological classification;computer science;bioinformatics;data integration;data mining	Vision	5.771995118033047	-57.5822940741741	18362
2f552e1ffdd3cfcfb9d24fec85aabd99dd34f972	dynamic pursuit with a bio-inspired neural model	connectionist models;visual areas;image processing;connectionism;neural model;conexionismo;procesamiento imagen;natural images;filtro gabor;primary visual cortex;traitement image;filtre spatio temporel;temporal filtering;connexionnisme;gabor filter;motion perception;excitatory inhibitory connectionism;percepcion visual;biomimetique;bio inspired architecture;image sequence;pursuit;filtre gabor;perception visuelle;visual perception;secuencia imagen;reseau neuronal;red neuronal;modele perception mouvement;sequence image;biomimetics;neural network;middle temporal area	In this paper we present a bio-inspired connectionist model for visual perception of motion and its pursuit. It is organized in three stages: a causal spatio-temporal filtering of Gabor-like type, an antagonist inhibition mechanism and a densely interconnected neural population. These stages are inspired by the treatment of the primary visual cortex, middle temporal area and superior visual areas. This model has been evaluated on natural image sequences.	british informatics olympiad;causal filter;connectionism;neural ensemble	Claudio Castellanos Sánchez;Bernard Girau	2005		10.1007/11558484_36	biomimetics;computer vision;connectionism;motion perception;visual perception;image processing;computer science;artificial intelligence;artificial neural network	ML	21.794740555423008	-68.61815339355212	18378
d94ad57f63a22f709228c02fd884c3460db1a8b3	quantum chemical and molecular mechanics studies on the assessment of interactions between resveratrol and mutant sod1 (g93a) protein	als;sod1;dmd;resveratrol;docking;fmo	Amyotrophic lateral sclerosis (ALS) is a neurodegenerative disease that has been associated with mutations in metalloenzyme superoxide dismutase (SOD1) causing protein structural destabilization and aggregation. However, the mechanistic action and the cure for the disease still remain obscure. Herein, we initially studied the conformational preferences of SOD1 protein structures upon substitution of Ala at Gly93 in comparison with that of wild type. Our results corroborated with the previous experimental studies on the aggregation and the destabilizing activity of mutant SOD1 protein G93A. On the therapeutic point of view, we computationally analyzed the influence of resveratrol, a natural polyphenol widely found in red wine on mutant SOD1 relative to wild type, using molecular docking studies. Further, FMO calculations were performed, using GAMESS to study the pair residual interaction on the wild type and mutant complex systems. Consequently, the resveratrol showed greater interaction with mutant than the wild type. Subsequently, we evaluated the conformational preferences of wild type and mutant complex systems, where the protein conformational structures of mutant that were earlier found to lose their conformational stability was regained, upon binding with resveratrol. Similar trend of results were found on the 2-D free energy landscapes of both the wild type and mutant systems. Hence, the combined biophysical and quantum chemical studies in our study supported the results of previous experimental studies, thereby stipulating an action of resveratrol on mutant SOD1 and paving a way for the design of highly potent effective inhibitors against fALS affecting the mankind.	amyotrophic lateral sclerosis 1;alanine;docking -molecular interaction;juvenile-onset still disease;mechanics;mutation;neurodegenerative disorders;sod1 gene;superoxide dismutase;superoxides;wild type;free energy;polyphenols;resveratrol	E. Srinivasan;R. Rajasekaran	2018	Journal of computer-aided molecular design	10.1007/s10822-018-0175-1	protein structure;wild type;mutant;superoxide dismutase;docking (molecular);chemistry;bioinformatics;molecular mechanics;biochemistry;resveratrol;sod1	Comp.	9.482127154400384	-62.264558349944096	18385
c13a7fa776f8003827fb0b275a8c172f0da67ed8	a computer system to perform structure comparison using representations of protein structure	protein structure comparison;protein structure alignment;european bioinformatics institute;protein domains;protein topology;pattern discovery;protein structure;structure comparison;design and implementation;pattern matching;protein motif;preprint;protein data bank;protein motifs;constraints	We describe the design and implementation of a fast topology-based method for protein structure comparison. The approach uses the TOPS topological representation of protein structure, aligning two structures using a common discovered pattern and generating measure of distance derived from an insert score. Heavy use is made of a constraint-based pattern-matching algorithm for TOPS diagrams that we have designed and described elsewhere (Bioinformatics 15(4) (1999) 317). The comparison system is maintained at the European Bioinformatics Institute and is available over the Web at tops.ebi.ac.uk/tops. Users submit a structure description in Protein Data Bank (PDB) format and can compare it with structures in the entire PDB or a representative subset of protein domains, receiving the results by email.	algorithm;anatomy, regional;bioinformatics;cns disorder;diagram;email;linc;pattern matching;protein data bank (file format);protein domain;protein, organized by structure;subgroup;tops;world wide web	David R. Gilbert;David R. Westhead;Juris Viksna;Janet M. Thornton	2001	Computers & chemistry	10.1016/S0097-8485(01)00096-1	crystallography;biology;biochemistry;chemistry;computer science;bioinformatics;protein structure prediction;data mining;protein structure database;structural motif	Comp.	-2.3170136460887814	-60.97894202711164	18386
09f441915e08cbb0cac3b40d4169f9abfef6a813	refseq microbial genomes database: new representation and annotation strategy	biological patents;genomics;biomedical journals;text mining;europe pubmed central;citation search;molecular sequence annotation;databases genetic;citation networks;internet;research articles;abstracts;genome microbial;open access;genome;genome bacterial;life sciences;clinical guidelines;full text;reference standards;rest apis;orcids;europe pmc;bacterial proteins;biomedical research;bioinformatics;literature search	The source of the microbial genomic sequences in the RefSeq collection is the set of primary sequence records submitted to the International Nucleotide Sequence Database public archives. These can be accessed through the Entrez search and retrieval system at http://www.ncbi.nlm.nih.gov/genome. Next-generation sequencing has enabled researchers to perform genomic sequencing at rates that were unimaginable in the past. Microbial genomes can now be sequenced in a matter of hours, which has led to a significant increase in the number of assembled genomes deposited in the public archives. This huge increase in DNA sequence data presents new challenges for the annotation, analysis and visualization bioinformatics tools. New strategies have been developed for the annotation and representation of reference genomes and sequence variations derived from population studies and clinical outbreaks.	annotation;bioinformatics;biopolymer sequencing;colony count, microbial;entrez;genome;genome, microbial;international nucleotide sequence database collaboration;refseq;archive	Tatiana A. Tatusova;Stacy Ciufo;Boris Fedorov;Kathleen O'Neill;Igor Tolstoy	2014		10.1093/nar/gkt1274	biology;genomics;text mining;the internet;bioinformatics;genetics;genome	Comp.	-2.0412013595397456	-60.93244947394771	18441
b070962ae696ff8cdf61b8889f2df0e405c83782	batmat: bioinformatics autodiscovery of training materials	biological patents;biomedical journals;text mining;europe pubmed central;citation search;citation networks;research articles;abstracts;open access;life sciences;clinical guidelines;full text;rest apis;orcids;europe pmc;biomedical research;bioinformatics;literature search	UNLABELLED We present Bioinformatics Autodiscovery of Training Materials (BATMat), an open-source, Google-based, targeted, automatic search tool for training materials related to bioinformatics. BATMat helps gain access with one click to filtered and portable information containing links to existing materials (when present). It also offers functionality to sort results according to source site or title.   AVAILABILITY http://imbatmat.com   CONTACT piar301@gmail.com.		Vasileios Lapatas;Michalis Stefanidakis	2016	Briefings in bioinformatics	10.1093/bib/bbv071	text mining;medical research;computer science;bioinformatics;data science;data mining;information retrieval	Comp.	-3.618601510636217	-60.23717273569505	18466
930b185e36c2a9d751435562082c69eb7c145859	weekend triple billionaire		The UniProt Knowledgebase offers both manually curated and automatically generated information on proteins, and is one of the leading biological databases. While it is one of the largest free data sets that is available in RDF, our infrastructure and website are not based on RDF. We present numbers about the volume and growth of UniProt and show why this volume of data prevents using RDF triple stores and SPARQL with currently available tools. 1 UniProt Data: Nature and Volume The UniProt Knowledgebase (UniProtKB) [1] consists of two parts: UniProtKB/ Swiss-Prot, containing manually annotated records describing proteins with information from literature and curator-evaluated computational analysis, and UniProtKB/TrEMBL, with automatically annotated records. The UniProt consortium provides several additional data sets: UniRef [2] with clustered sets of sequences from UniProt, the amino acid sequence archive UniParc [3], and supporting data sets such as taxonomy and keywords. UniProt consists of almost three billion triples (see Table 1), making it one of the largest freely available RDF data sets. The data is maintained at three consortium member sites, and must be kept in sync and integrated into one combined public release. This number of triples consumes considerable harddisk space. We show estimates comparing different RDF stores, based on published LUBM 8000 results, with our solution, in Table 2.	archive;biological database;hard disk drive;knowledge base;peptide sequence;resource description framework;sparql;swiss-model;switzerland;triplestore;uniprot	Jerven T. Bolleman;Thomas Kappler	2009			computer science;performance art	ML	-2.6693955066622648	-60.98765872825633	18519
7c3f41899b67da4b5b40caaf48cfaf3cdd7a9f8e	parallel memory systems for talking about location and age in precuneus, caudate and broca's region	cortical hypoperfusion;language comprehension;relative position;unilateral neglect;sentence comprehension;subcortical aphasia;williams syndrome;cognitive neuroscience;visual working memory;specific activity;language processing;spatial language;parametric manipulation;working memory;memory systems;human navigation;reaction time;broca s area	"""Language comprehension relies on processing of context. Working memory (WM) evoked by linguistic cues for spatial and nonspatial aspects of a visual scene was investigated by correlating fMRI BOLD signal (or 'activation') with reaction times (RTs). Subjects were asked to indicate either the relative positions or ages of people or objects (referenced by the personal pronouns """"he/she/it"""") in a previously shown image. Good performers of a particular task showed shorter RTs than poor performers. Task-specific activation that is greater in good performers than poor ones is taken to indicate involvement of a given region in performance of the task. Our results indicate that dorsoposterior precuneus supports spatial WM during linguistic processing while a network of areas including the caudate support nonspatial WM in categorization of age. We argue that within-subjects variation of RTs across trials reflects effort. Good performers have higher activity in precuneus as a function of effort compared to poor performers during the spatial task, whereas the opposite is found for the nonspatial task, providing further evidence for specifically spatial WM in dorsoposterior precuneus. Task-independent performance-related modulations of activity were found in Broca's area and amygdala. Broca's area activity increased with effort in both tasks, with a greater increase in good performers than in poor performers, consistent with the region's general role in verbal WM. By contrast, activation in amygdala decreased with effort, with a greater decrease in good performers. We take this deactivation to reflect performance-mediating emotional control. These findings indicate that multiple parallel memory systems are available during language processing, appropriate for different tasks, with performance reflecting which system is selected trial-by-trial and subject-by-subject."""	amygdaloid structure;broca aphasia;categorization;linguistics;memory disorders;memory, short-term;physical object;speech;structure of precuneus;fmri	Mikkel Wallentin;Andreas Roepstorff;Rebecca Glover;Neil Burgess	2006	NeuroImage	10.1016/j.neuroimage.2006.05.002	psychology;cognitive psychology;mental chronometry;neuroscience;developmental psychology;cognitive neuroscience;working memory;specific activity;communication	HCI	15.76491157668056	-76.94448524175313	18553
621ea1f1e364262348135c803557e7b3454a804e	generative spatiotemporal modeling of neutrophil behavior		Cell motion and appearance have a strong correlation with cell cycle and disease progression. Many contemporary efforts in machine learning utilize spatio-temporal models to predict a cell's physical state and, consequently, the advancement of disease. Alternatively, generative models learn the underlying distribution of the data, creating holistic representations that can be used in learning. In this work, we propose an aggregate model that combine Generative Adversarial Networks (GANs) and Autoregressive (AR) models to predict cell motion and appearance in human neutrophils imaged by differential interference contrast (DIC) microscopy. We bifurcate the task of learning cell statistics by leveraging GANs for the spatial component and AR models for the temporal component. The aggregate model learned results offer a promising computational environment for studying changes in organellar shape, quantity, and spatial distribution over large sequences.	aggregate data;autoregressive model;color gradient;digital differential analyzer;generative adversarial networks;generative model;holism;interference (communication);machine learning	Narita Pandhe;Balázs Rada;Shannon Quinn	2018	2018 IEEE 15th International Symposium on Biomedical Imaging (ISBI 2018)	10.1109/ISBI.2018.8363732	machine learning;generative grammar;artificial intelligence;spatial distribution;computer science;pattern recognition;autoregressive model;differential interference contrast microscopy	Vision	23.77500170362731	-74.58720206114961	18601
cb5da3fb73c0a4fd74cf9f2b0d8090e488bb5f1b	digital analysis of esr spectra of spin labeled nucleic acid- systems	nucleic acid	Abstract   Programs written in FORTRAN II have been developed for analyzing ESR spectra of spin labeled nucleic acid ligand complexes. The spectra are aligned and standardized with respect to an external standard for studying parameters of nucleic acid ligand complexes by taking into account the entire spectral arrays. Results obtained on spin labeled nucleic acids and poly-L-lysine systems indicate the existence of a two component system with two kinds of apparent spin mobilities.		A. M. Bobst;Tuhin K. Sinha;P. W. Langemeier;R. L. Prairie	1980	Computers & Chemistry	10.1016/0097-8485(80)85007-8	biology;biochemistry;nucleic acid;chemistry;computer science;analytical chemistry;nuclear magnetic resonance;genetics	NLP	4.607181032934707	-64.93546684147273	18635
979d92b6209aa6933a5b5ef42e87b9cede6e2664	large scale metabolic characterization using flux balance analysis and data mining		Genome-scale metabolic models of several microbes have been reconstructed from sequenced genomes in the last years. These have been used in several applications in Biotechnology and biological discovery, since they allow to predict the phenotype of the microorganism in distinct environmental or genetic conditions, using for instance Flux Balance Analysis (FBA). This work proposes an analysis workflow using a combination of FBA and Data Mining (DM) classification methods, aiming to characterize the metabolic behaviour of microorganisms using the available models. This framework allows the large scale comparison of the metabolism of different organisms and the prediction of gene expression patterns. Also, it can provide insights about transcriptional regulatory events leading to the predicted metabolic behaviour. DM techniques, namely decision tree and classification rules inference, are used to provide patterns of gene expression based on environmental conditions (presence/ absence of substrates in the media). The methods proposed are applied to the study of the metabolism of two related microbes: Escherichia coli and Salmonella typhimurium.	data mining;flux balance analysis	Miguel Rocha	2013		10.1007/978-3-642-37213-1_35	flux balance analysis;decision tree;data mining;transcriptional regulation;computer science;systems biology	ML	5.240638487332936	-59.13829790157695	18728
8b671cba05c24944c0c354ba9ea82428b4733766	a message from the new editor-in-chief	nature; nature publishing group; bjc; british journal cancer; cancer research; cancers; prescription drugs; breast cancer; medical research laboratory; lung cancer; nature; prostate cancer; skin cancer; leukaemia; colon cancer; ovarian cancers; cervical cancer; liver cancer; cancer treatments; brain cancer; gene therapy; bone marrow; apoptosis; nature magazines; bone marrow transplant; science news articles; cell division; cancer cells; nature journals; oncogene; neoplasia; antioxidants; adipose tissue; science and nature; oncogene journals; tumours; cancer gene therapy; apoptosis pathway; anti cancer drugs; science research papers; anticancer			Fei-Yue Wang	2009	IEEE Trans. Intelligent Transportation Systems	10.1109/TITS.2009.2012525		Visualization	1.8453549991093523	-65.15939311409211	18824
b8e19efb0a2b92d0379669b04c221f0965d17160	template-based prediction of rna tertiary structure	rna;predictive models	RNA tertiary structure prediction approaches can be divided into two groups: de novo methods and template-based modeling. De novo are applicable only for small molecules while in case of medium and large size RNA molecules, template-based modeling needs to be employed. While this type of modeling is quite common in protein structure prediction field, there exist only very few tools for template-based RNA structure prediction. Therefore, we present a methodology for prediction of RNA three dimensional structure (target) utilizing a known structure of a related RNA molecule (template). First, the target and template sequences are aligned. Next, sequentially similar regions in the alignment are identified and corresponding substructures are transferred from template to target. The remaining parts of the target structures are predicted using an external tool. This phase includes treatment of indels and valid linking of the transferred and predicted portions of the target structure. Our proposed method is able to predict even large ribosomal RNA structures when sufficiently similar template is available. The experiments have shown that the main impact on the quality of prediction has the sequence similarity of the template and target and number of indels. For structures with size of hundreds of nucleotides with sequence similarity with template over 50% and ratio of indels up to 50% the method is able to generate target structures up to ten RMSD with respect to the reference structure.	ab initio quantum chemistry methods;de novo protein structure prediction;existential quantification;experiment;homology (biology);sequence alignment	Rastislav Galvanek;David Hoksza;Josef Pánek	2016	2016 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)	10.1109/BIBM.2016.7822808	biology;rna;computer science;bioinformatics;machine learning;data mining;predictive modelling;genetics	Comp.	10.126218861510726	-58.13344012474128	18826
6de8aeea10285e5ae5db7b72544104481a25c3eb	the functional role of motor activation in language processing: motor cortical oscillations support lexical-semantic retrieval	oscillations;lexical semantics;noun;semantic integration;premotor cortex;article letter to editor;language processing;motor imagery;motor activity	"""There is increasing experimental evidence that processing action-related language results in the automatic activation of associated regions of the motor and premotor cortex. However, the functional significance of motor activation in language processing is still under debate. In the present EEG study, we set out to investigate if language-induced motor activation primarily reflects the retrieval of lexical-semantic information or post-lexical motor imagery. The processing of action verbs was found accompanied by an early activation of motor-related brain areas, as reflected by a desynchronization in the mu- and beta-frequency bands which was localized to motor and premotor areas. A stronger motor activation was observed for verbs presented in an animal context (e.g. """"The deer jumped over the stream"""") compared to a human context (e.g. """"The athlete jumped over the fence"""") and motor resonance was directly modulated by the cloze probability of the noun-verb pairs. The onset of the motor effects preceded classical measures of semantic integration (i.e. the N400 component) and the strength of motor activation was found inversely related to the size of the N400 effect. These findings support the hypothesis that motor activation in language processing primarily supports the retrieval and integration of lexical-semantic information."""	bands;electroencephalography;frequency band;modulation;neural oscillation;onset (audio);resonance;semantic integration	Michiel van Elk;Hein T. van Schie;Rolf A. Zwaan;Harold Bekkering	2010	NeuroImage	10.1016/j.neuroimage.2009.12.123	muscle memory;psychology;cognitive psychology;noun;lexical semantics;semantic integration;developmental psychology;motor learning;communication;oscillation;motor imagery	ML	16.68123485529573	-77.48642511001688	18831
6b6ba66ef3cd5c7f6184a00444c9fce8a24fc1b0	end-to-end segmentation with recurrent attention neural network		Image segmentation quality depends heavily on the quality of the image. For many medical imaging modalities, image reconstruction is required to convert acquired raw data to images before any analysis. However, imperfect reconstruction with artifacts and loss of information is almost inevitable, which compromises the final performance of segmentation. In this study, we present a novel end-to-end deep learning framework that performs magnetic resonance brain image segmentation directly from the raw data. The end-toend framework consists a unique task-driven attention module that recurrently utilizes intermediate segmentation result to facilitate image-domain feature extraction from the raw data for segmentation, thus closely bridging the reconstruction and the segmentation tasks. In addition, we introduce a novel workflow to generate labeled training data for segmentation by exploiting imaging modality simulators and digital phantoms. Extensive experiment results show that the proposed method outperforms the state-of-the-art methods.		Qiaoying Huang;Xiao Chen;Mariappan S. Nadar	2018	CoRR			Vision	23.05469615065288	-56.81921487660395	18859
83aa853ac15622244e5fc847d2afe5c918b0c721	desenvolvimento de um programa computacional para o tratamento de sinais obtidos pela ressonancia paramagnetica eletronica na dosimetria de doses altas		This work presents the development of a computational system for the mathematical treatment of Electron Paramagnetic Resonance (EPR) spectrum. The system was developed to support the basic activities of highdoses dosimetry laboratory, including Its integration with a quality system based on the traceability of the information. The program was developed using the concepts of the Object Oriented Programming, allowing the recording, the storage and the analysis of the information present in the activity cycle that composes the dosimetry by EPR technique. This cycle comprises activities involving the planning of dosimetry until the dose evaluation in routine conditions or the estimative of retrospective dose in cases of an accident. A new method for the treatment of raw spectra based in Wavelet Filters is proposed in this work. The use of this method allows the extension of the alanina/EPR technique for low doses, in radiotherapy range, with total uncertainty less than 5%.	epr paradox;electron;numerical aperture;resonance;traceability;unified model;wavelet	Orlando Rodrigues Junior	2003				Robotics	11.482951997780223	-78.9164554902321	18861
a447b756ded47e8dd63f2b1c071b771639ef6813	computational purification of tumor gene expression data	health research;uk clinical guidelines;biological patents;europe pubmed central;citation search;computational biology bioinformatics;uk phd theses thesis;life sciences;algorithms;combinatorial libraries;uk research reports;medical journals;computer appl in life sciences;europe pmc;biomedical research;microarrays;bioinformatics	Background Cancer gene expression profiling is an indispensable tool for identifying drivers of tumor progression, identifying subtypes, and predicting clinical outcome. An outstanding challenge faced by cancer gene expression studies is the limited concordance between studies [1], driven in part by lack of statistical power [2]. Part of this lack of statistical power is due to the fact that tumor samples from some solid cancers contain between 30%-70% healthy tissue [3]. This healthy tissue contaminates tumor expression profiles and variable amounts of healthy tissue leads to increased variability between tumor expression profiles. Physical purification of these tumor samples before profiling is often not feasible.	color gradient;computation;concordance (publishing);gene expression profiling;heart rate variability;profiling (computer programming);purification of quantum state	Amit G. Deshwar;Gerald Quon;Quaid Morris	2011		10.1186/1471-2105-12-S11-A9	biology;dna microarray;computer science;bioinformatics;data science	Comp.	6.143605719389927	-55.07794834740717	18912
d965a0d1b818434cd8b0e7d562d2a39eaab29087	a novel computational analysis of heterogeneity in breast tissue	patient diagnosis;cancer;co morbidity computational analysis heterogeneity breast tissue breast cancer breast disease pathology pathologic association breast pathology related diagnosis diagnosis set co occurrence patient information socio economic status family history lifestyle choice;biological organs;tumours;breast tissue breast cancer lesions diseases pathology genomics bioinformatics proteomics medical diagnostic imaging data warehouses;null;gynaecology;family history;medical information systems;socio economic status;computer analysis;medical diagnostic computing;breast cancer;socio economic effects;medical information systems gynaecology biological organs cancer tumours patient diagnosis medical diagnostic computing socio economic effects	Breast cancer presents as part of a heterogeneous mix of breast disease pathologies whose biological origins are poorly understood. A systematic and quantitative study of heterogeneity in breast tissue would enable us to characterize the disease states present, and use that characterization to guide further research into the complex pathologic associations within breast tissue and between patients. Initially we focus on characterizing the co-occurrence of breast pathology-related diagnoses. In particular, this abstract presents our initial results from characterizing the co-occurrence of double and triple diagnoses. We will expand this analysis to co-occurrence of larger diagnosis sets. Additionally, we plan to analyze co-occurrence with other types of patient information, including: socio-economic status, family history, lifestyle choices, co-morbidity with other diseases, and many other factors hypothesized to contribute to an increased risk for developing breast cancer.		Susan Maskery;Yonghong Zhang;Rick Jordan;Hai Hu;Craig D. Shriver;Jeffrey Hooke;Michael N. Liebman	2005	18th IEEE Symposium on Computer-Based Medical Systems (CBMS'05)	10.1109/CBMS.2005.16	medicine;pathology;socioeconomic status;gynecology;breast cancer;cancer	Comp.	5.0010866842444734	-71.69864248054913	19043
b16e11c69e31e4755f361f8ff115c0aadc2b2311	spindlesphere: a web-based platform for large-scale sleep spindle analysis and visualization.		Sleep spindles are a hallmark of stage 2 non-REM sleep that contain information about heritable traits that play an important role in neurological diseases. One of the key challenges in leveraging spindles for clinical research is the lack of a data processing pipeline and web-based, platform for managing and visualizing spindle-specific data at scale. We propose SpindleSphere, a scalable integrated data management and visualization platform for spindle research. SpindleSphere has several features: (1) standardized, metadata-based, search and query of annotated polysomnography (PSG), the gold, standard for sleep diagnosis: (2) event-specific signal exporting: (3) interface for interactive waveform visualization: (4) multi-scale spindle rendering: and (5) parallel algorithm in MapReduce for detection of spindle segments. SpindleSphere provides real-time visualization of multi-modal signals from National Sleep Research Resource (NSRR) for spindle characterization. Preliminary evaluation of SpindleSphere was performed on the NSRR (130 GB of PSG data from 300 subjects).		Xiaojin Li;Licong Cui;Shiqiang Tao;Ningzhou Zeng;Guo-Qiang Zhang	2017	AMIA ... Annual Symposium proceedings. AMIA Symposium		web application;computer vision;visualization;sleep spindle;computer science;artificial intelligence	Visualization	-2.375339702500461	-71.26909888288428	19058
11ca6d9c9b7cbb96e3fcdbd453a4119297fd3b8a	correction: computational model explains high activity and rapid cycling of rho gtpases within protein complexes	protein structure networks;yeast;protein complex;saccharomyces cerevisiae;complex network;signal transduction;saccharomyces cerevisiae proteins;models biological;protein network;genetic networks;gene duplication;social network;fungal evolution;natural selection;molecular evolution;evolutionary genetics;cellular network;protein protein interaction;protein complexes;evolutionary conservation;algorithms;functional unit;protein interaction mapping;computer simulation;protein interaction networks	cg2445* hmuO putative heme oxygenase P 5.60 12.55 8.95 × 10 cg1931* putative secreted protein X 5.57 11.76 1.13 × 10 cg2797* conserved hypothetical protein S 5.39 11.46 7.24 × 10 cg2796* MMGE/PRPD family protein R 5.38 12.19 1.91 × 10 cg0467* cobalamin/Fe3+-siderophores transport system P 5.23 11.38 7.54 × 10 cg1903 ABC-type multidrug transport system V 5.21 12.66 3.69 × 10 cg0771* irp1 DtxR/iron-regulated lipoprotein precursor P 5.14 11.67 2.58 × 10 cg3156* putative secreted protein X 5.06 11.01 1.08 × 10 cg1120* ripA AraC-family transcriptional regulator K 4.99 12.35 9.15 × 10 cg1930* putative secreted hydrolase O 4.90 9.83 2.52 × 10 cg0922* ABC-type cobalamin/Fe3+-siderophores transport system P 4.50 10.96 5.85 × 10 cg0924* ABC-type cobalamin/Fe3+-siderophores transport system P 4.40 13.69 5.92 × 10 cg1405* siderophore-interacting protein P 4.36 13.40 1.11 × 10 cg0921* siderophore-interacting protein P 4.24 10.75 2.13 × 10 cg0928* ABC-type cobalamin/Fe3+-siderophores transport system P 4.22 11.50 2.11 × 10 cg0926* ABC-type cobalamin/Fe3+-siderophores transport system P 4.00 11.83 7.73 × 10 cg0963 hypothetical protein X 3.94 10.36 1.50 × 10 cg2444 hypothetical protein X 3.87 12.65 4.05 × 10 cg0469 ABC-type cobalamin/Fe3+-siderophores transport system P 3.74 11.93 7.09 × 10 cg0466* conserved secreted protein X 3.67 11.77 8.84 × 10 cg0526 translation initiation inhibitor J 3.53 9.81 6.22 × 10 cg0160* hypothetical protein X 3.49 12.53 2.44 × 10 cg0927* ABC-type cobalamin/Fe3+-siderophores transport system P 3.47 12.39 2.20 × 10 cg2962 conserved hypothetical protein R 3.42 12.04 2.53 × 10 cg1419 putative Na+-dependent transporter R 3.33 10.96 2.85 × 10 cg3404* ABC-type cobalamin/Fe3+-siderophores transport system P 3.29 8.66 2.05 × 10 cg0527* ArsR-family transcriptional regulator K 3.22 11.29 3.19 × 10 cg1883 putative secreted protein S 3.19 10.92 3.95 × 10 cg2234* ABC-type cobalamin/Fe3+-siderophores transport system P 3.18 11.80 1.62 ×10 cg0159* hypothetical protein X 3.13 10.50 3.29 × 10 cg0755 metY O-acetylhomoserine (thiol)-lyase E 3.09 12.59 7.47 × 10 cg2311* SAM-dependent methyltransferase QR 3.04 10.23 1.44 × 10 cg0468* ABC-type cobalamin/Fe3+-siderophores transport systems P 3.03 12.09 1.61 ×10 cg0748* ABC-type cobalamin/Fe3+-siderophores transport systems P 3.01 10.05 5.23 × 10 cg2381 conserved hypothetical protein X 2.92 11.42 3.25 × 10 cg1894 hypothetical protein X 2.91 8.78 8.16 × 10 cg2113 hypothetical protein X 2.58 10.90 6.32 × 10 cg3345 hypothetical protein X 2.53 10.43 5.62 × 10 cg0754 metX homoserine O-acetyltransferase E 2.49 12.06 1.41 × 10 cg1895 putative secreted protein X 2.43 8.83 2.42 × 10 cg1567 hypothetical protein X 2.34 9.47 1.05 × 10 cg2678 ABC-type dipeptide/oligopeptide/nickel transport system E 2.33 11.36 8.82 × 10 cg1898 hypothetical protein X 2.32 13.05 1.77 × 10 cg3119* fpr2 NADPH-dependent ferredoxin-reductase ER 2.30 13.79 4.40 × 10 cg2141 recA DNA recombination/repair protein L 2.28 12.31 4.88 × 10 cg2687 metB cystathionine gamma-synthase E 2.18 12.70 3.33 × 10 cg0899 glutamine amidotransferase H 2.16 11.16 1.52 × 10 cg0767* siderophore-interacting protein P 2.12 11.24 7.79 × 10 cg0769* ABC-type cobalamin/Fe3+-siderophores transport system P 2.06 9.75 5.15 × 10 cg1287 conserved hypothetical protein X 2.06 12.02 2.61 × 10 cg2336 putative secreted protein X 2.04 11.87 1.49 × 10 cg2533 conserved hypothetical protein X 2.03 10.38 7.31 × 10 cg2675 ATPase component of ABC-type transport system R 2.01 11.97 3.86 ×10 cg1806 metK S-adenosylmethionine synthetase H 1.97 9.75 8.12 × 10 cg3118* cysI ferredoxin-sulfite reductase P 1.94 13.32 1.73 ×10 cg0898 pyridoxine biosynthesis enzyme H 1.93 11.15 6.03 × 10 cg0839 hypothetical protein X 1.91 11.28 8.48 × 10 cg0770* ABC-type cobalamin/Fe3+-siderophores transport system P 1.90 10.96 6.55 × 10 cg0156 Crp-family transcriptional regulator KG 1.89 11.63 3.67 × 10 cg1404 gatA putative Glu-tRNA amidotransferase J 1.88 11.89 7.76 × 10 cg1896 putative secreted protein X 1.87 10.87 1.85 × 10 cg1418* ABC-type cobalamin/Fe3+-siderophores transport system P 1.85 11.89 1.57 × 10	computational model;hypothetical protein;ibm system r;interaction;iron man;kasparov's gambit;recombinant dna;voltage regulator module	Zhi Wang;Jianzhi Zhang	2007	PLoS Computational Biology	10.1371/journal.pcbi.0030107	computer simulation;biology;biochemistry;bioinformatics;modularity;multiprotein complex;genetics	Comp.	6.017173165556791	-65.15632579622809	19068
fc08b08de50261d95001e8c584e9b237c3e492dc	novel insight into the molecular interaction of catalase and sucrose: a combination of in silico and in planta assays study		Abstract Osmolytes are known to be an important factor for the stabilization and proficient functioning of proteins. However, the stabilization mechanism of proteins by the interaction of osmolytes is still not well explored. Here, we performed in silico 3D structure modelling of rice catalase-A (CatA) protein and its molecular interaction with sucrose. Further, in planta was conducted to see the effects of sucrose on catalase activity in rice grown in saline sodic soil at different time intervals. The molecular docking experiments results showed that sucrose can be ligated with CatA, protein forming hydrogen bond with precise amino acid residues like, R49, R89, P309, F311, Y335 and T338. The interaction also comprises the contribution of hydrophobic amino acid residues like V50, V51, H52, L123, A310, Q339 and R342. The planta in vitro catalase activity assay showed that plants treated with sucrose significantly affect the catalase activity in rice. Results revealed that maximum catalase activity was recorded in plants treated with 150 and 200 ppm of sucrose after 15 days of sucrose application. However, minimum activity was recorded in control plants. We believe that our study will provides an advanced understanding of catalase activity in plants exposed to osmotic stress.	interactome	Sunil Kumar;Khurshid Ahmad;Gitanjali Tandon;Udai B. Singh;Yachana Jha;Dipak T. Nagrale;Mahender Kumar Singh;Khyati Girdhar;Prosenjit Mondal	2018	Computers and Electronics in Agriculture	10.1016/j.compag.2018.06.005	sucrose;docking (molecular);control engineering;osmolyte;sodic soil;catalase;osmotic shock;amino acid;engineering;biochemistry;hydrogen bond	HCI	9.772501031331172	-63.58157154094567	19091
094e75a658290df0380079c9f20090cc9f11119a	computerized retrieval of information on biosynthesis and metabolic pathways	representation graphique;representacion grafica;biosintesis;metabolismo;biosynthesis;computer aid;asistencia ordenador;biosynthese;metabolic pathway;assistance ordinateur;graphics;metabolism;metabolisme	Biosynthetic metabolic pathways were analyzed, and a hierarchy of attributes was constructed. Representation of the knowledge base on metabolic conversions was effected in terms of this hierarchy of attributes and the chemical structures of molecules participating in metabolic conversion steps. A prototype database was constructed with the MACCS and DATACCS programs, already in use for storage, searching, and reporting of chemical structures, chemical-biological data, and chemical reactions at Sandoz. Key data in the new metabolic conversions database are the enzyme name and classification, effectors, inhibitors, literature reference, etc. Participating molecules, if known and under 255 heavy atoms, are stored and diagrammed as stereostructures. The crucial data on metabolic conversions are represented by From and To datatypes. All the data are exact match and range searchable for text and numbers. Thus, precursors and progenitors of compounds can be found. Structures are match and substructure searchable. This tool is a useful and very flexible complement to metabolic charts. It in itself can be used to report and graph conversion steps and sequences		Sandor Barcza;Lawrence A. Kelly;Christopher D. Lenz	1990	Journal of Chemical Information and Computer Sciences	10.1021/ci00067a006	biochemistry;metabolic pathway;chemistry;computer science;bioinformatics;graphics;artificial intelligence;database;metabolism;biosynthesis;algorithm	Theory	-0.40049828308126056	-61.339093022607045	19134
4ab11633387bd0044cab1a0091488ec53d00d56c	thermodynamic post-processing versus gc-content pre-processing for dna codes satisfying the hamming distance and reverse-complement constraints	dna;dna hamming distance algorithm design and analysis bioinformatics computational biology thermodynamics;ieee transactions;thermodynamics biology computing dna hamming codes melting molecular biophysics molecular configurations stochastic processes;linear codes;reverse complement dna design linear codes stochastic local search hamming distance;hamming distance;linear constructions thermodynamic post processing gc content preprocessing dna codes hamming distance reverse complement constraints stochastic algorithms meta heuristic algorithms linear construction algorithms dna strand hybridization strength thermodynamic calculations post processing melting temperatures large dna sets;thermodynamics;stochastic local search;dna design;reverse complement;computational biology;algorithm design and analysis;bioinformatics	Stochastic, meta-heuristic and linear construction algorithms for the design of DNA strands satisfying Hamming distance and reverse-complement constraints often use a GC-content constraint to pre-process the DNA strands. Since GC-content is a poor predictor of DNA strand hybridization strength the strands can be filtered by post-processing using thermodynamic calculations. An alternative approach is considered here, where the algorithms are modified to remove consideration of GC-content and rely on post-processing alone to obtain large sets of DNA strands with satisfactory melting temperatures. The two approaches (pre-processing GC-content and post-processing melting temperatures) are compared and are shown to be complementary when large DNA sets are desired. In particular, the second approach can give significant improvements when linear constructions are used.	algorithm;calculus of constructions;complement system proteins;hamming distance;heuristic;kerrison predictor;nucleic acid hybridization;preprocessor;strand (programming language);thermodynamics;video post-processing	Dan Tulpan;Derek H. Smith;Roberto Montemanni	2014	IEEE/ACM Transactions on Computational Biology and Bioinformatics	10.1109/TCBB.2014.2299815	biology;algorithm design;hamming distance;hamming bound;computer science;bioinformatics;theoretical computer science;complementarity;linear code;mathematics;genetics;dna;algorithm	Comp.	3.20393579293141	-60.20287864495682	19178
40282640473f46fd17283a55a5a4acedd0bd5d68	functional neuroimaging correlates of finger-tapping task variations: an ale meta-analysis	basal ganglia;finger tapping;motor skills;functional neuroimaging;premotor cortex;motor system;meta analysis;sequential finger movements;motor cortex;evoked potentials motor;brain mapping;visual stimulus;motor;fingers;movement complexity;motor activity;self paced movement;auditory stimulus;humans;bimanual;supplementary motor area;ale;task performance and analysis;paced finger tapping;activation likelihood estimation	Finger-tapping tasks are one of the most common paradigms used to study the human motor system in functional neuroimaging studies. These tasks can vary both in the presence or absence of a pacing stimulus as well as in the complexity of the tapping task. A voxel-wise, coordinate-based meta-analysis was performed on 685 sets of activation foci in Talairach space gathered from 38 published studies employing finger-tapping tasks. Clusters of concordance were identified within the primary sensorimotor cortices, supplementary motor area, premotor cortex, inferior parietal cortices, basal ganglia, and anterior cerebellum. Subsequent analyses performed on subsets of the primary set of foci demonstrated that the use of a pacing stimulus resulted in a larger, more diverse network of concordance clusters, in comparison to varying the complexity of the tapping task. The majority of the additional concordance clusters occurred in regions involved in the temporal aspects of the tapping task, rather than its execution. Tapping tasks employing a visual pacing stimulus recruited a set of nodes distinct from the results observed in those tasks employing either an auditory or no pacing stimulus, suggesting differing cognitive networks when integrating visual or auditory pacing stimuli into simple motor tasks. The relatively uniform network of concordance clusters observed across the more complex finger-tapping tasks suggests that further complexity, beyond the use of multi-finger sequences or bimanual tasks, may be required to fully reveal those brain regions necessary to execute truly complex movements.	3-iodobenzylguanidine;basal (phylogenetics);basal ganglia;cerebellum;cognitive network;concordance (publishing);functional gastrointestinal disorders;large;motor cortex;movement;neuroimaging;no pacing medical device problem;numerous;parietal lobe;scientific publication;sensorimotor cortex;task analysis;voxel	Suzanne T. Witt;Angela R. Laird;Mary E. Meyerand	2008	NeuroImage	10.1016/j.neuroimage.2008.04.025	psychology;cognitive psychology;electric motor;neuroscience;meta-analysis;motor skill;functional neuroimaging;motor system;brain mapping;communication	ML	17.628378513115948	-79.48122910150182	19229
907d3a3199d142644c6357403793ef4cf4e08519	the influence of stimulus format on drawing—a functional imaging study of decision making in portrait drawing	occipital lobe;psychomotor performance;female;brain;art;fixation ocular;male;brain mapping;adult;magnetic resonance imaging;face;humans;young adult;pattern recognition visual	To copy a natural visual image as a line drawing, visual identification and extraction of features in the image must be guided by top-down decisions, and is usually influenced by prior knowledge. In parallel with other behavioral studies testing the relationship between eye and hand movements when drawing, we report here a functional brain imaging study in which we compared drawing of faces and abstract objects: the former can be strongly guided by prior knowledge, the latter less so. To manipulate the difficulty in extracting features to be drawn, each original image was presented in four formats including high contrast line drawings and silhouettes, and as high and low contrast photographic images. We confirmed the detailed eye-hand interaction measures reported in our other behavioral studies by using in-scanner eye-tracking and recording of pen movements with a touch screen. We also show that the brain activation pattern reflects the changes in presentation formats. In particular, by identifying the ventral and lateral occipital areas that were more highly activated during drawing of faces than abstract objects, we found a systematic increase in differential activation for the face-drawing condition, as the presentation format made the decisions more challenging. This study therefore supports theoretical models of how prior knowledge may influence perception in untrained participants, and lead to experience-driven perceptual modulation by trained artists.	area striata structure;brain implant;decision making;drawings (art);eye tracking;face;functional imaging;lateral thinking;line drawing algorithm;modulation;movement;physical object;scanning systems;top-down and bottom-up design;touchscreen;format	R. Chris Miall;Se-Ho Nam;J. Tchalenko	2014		10.1016/j.neuroimage.2014.08.015	psychology;face;computer vision;radiology;young adult;magnetic resonance imaging;brain mapping;communication;social psychology	HCI	13.644703691293584	-77.90836695007151	19277
398901b7baa21f380bb2487c727ee2ccb764ff72	machine learning approach for early detection of autism by combining questionnaire and home video screening		Background Existing screening tools for early detection of autism are expensive, cumbersome, time- intensive, and sometimes fall short in predictive value. In this work, we sought to apply Machine Learning (ML) to gold standard clinical data obtained across thousands of children at-risk for autism spectrum disorder to create a low-cost, quick, and easy to apply autism screening tool.   Methods Two algorithms are trained to identify autism, one based on short, structured parent-reported questionnaires and the other on tagging key behaviors from short, semi-structured home videos of children. A combination algorithm is then used to combine the results into a single assessment of higher accuracy. To overcome the scarcity, sparsity, and imbalance of training data, we apply novel feature selection, feature engineering, and feature encoding techniques. We allow for inconclusive determination where appropriate in order to boost screening accuracy when conclusive. The performance is then validated in a controlled clinical study.   Results A multi-center clinical study of n = 162 children is performed to ascertain the performance of these algorithms and their combination. We demonstrate a significant accuracy improvement over standard screening tools in measurements of AUC, sensitivity, and specificity.   Conclusion These findings suggest that a mobile, machine learning process is a reliable method for detection of autism outside of clinical settings. A variety of confounding factors in the clinical analysis are discussed along with the solutions engineered into the algorithms. Final results are statistically limited and will benefit from future clinical studies to extend the sample size.	area under curve;autism spectrum disorders;autistic disorder;behavior;early diagnosis;feature engineering;feature selection;machine learning;numerous;semiconductor industry;sensitivity and specificity;solutions;sparse matrix;algorithm	Halim Abbas;Ford Garberson;Eric Glover;Dennis P. Wall	2018	Journal of the American Medical Informatics Association : JAMIA	10.1093/jamia/ocy039	data mining;scarcity;autism;training set;artificial intelligence;feature selection;machine learning;computer science;feature engineering	HCI	8.351514261974879	-78.61432837391439	19327
0d182d23ba510c16d70edf664be45b000d981b1a	modeling the shoot apical meristem in a. thaliana : parameter estimation for spatial pattern formation	shoot apical meristem;ordinary differential equation;network organization;reaction diffusion system;genetics;spatial pattern;molecular biology;evolutionary algorithm;parameter estimation;gene expression pattern	Understanding the self-regulatory mechanisms controlling the spatial and temporal structure of multicellular organisms represents one of the major challenges in molecular biology. In the context of plants, shoot apical meristems (SAMs), which are populations of dividing, undifferentiated cells that generate organs at the tips of stems and branches throughout the life of a plant, are of particular interest and currently studied intensively. Here, one key goal is to identify the genetic regulatory network organizing the structure of a SAM and generating the corresponding spatial gene expression patterns. This paper addresses one step in the design of SAM models based on ordinary differential equations (ODEs): parameter estimation for spatial pattern formation. We assume that the topology of the genetic regulatory network is given, while the parameters of an ODE system need to be determined such that a particular stable pattern over the SAM cell population emerges. To this end, we propose an evolutionary algorithmbased approach and investigate different ways to improve the efficiency of the search process. Preliminary results are presented for the Brusselator, a well-known reaction-diffusion system.	estimation theory;gene regulatory network;organizing (structure);pattern formation;population;spatiotemporal pattern	Tim Hohm;Eckart Zitzler	2007		10.1007/978-3-540-71783-6_10	meristem;biology;ordinary differential equation;botany;common spatial pattern;computer science;bioinformatics;evolutionary algorithm;estimation theory;genetics	ML	4.743967299116907	-59.94544083098499	19343
1a64235390f510e91790ab43ffdd45a403ab0435	predstp: a highly accurate svm based model to predict sequential cystine stabilized peptides	health research;uk clinical guidelines;biological patents;europe pubmed central;citation search;computational biology bioinformatics;uk phd theses thesis;life sciences;algorithms;combinatorial libraries;uk research reports;medical journals;computer appl in life sciences;europe pmc;biomedical research;microarrays;bioinformatics	Numerous organisms have evolved a wide range of toxic peptides for self-defense and predation. Their effective interstitial and macro-environmental use requires energetic and structural stability. One successful group of these peptides includes a tri-disulfide domain arrangement that offers toxicity and high stability. Sequential tri-disulfide connectivity variants create highly compact disulfide folds capable of withstanding a variety of environmental stresses. Their combination of toxicity and stability make these peptides remarkably valuable for their potential as bio-insecticides, antimicrobial peptides and peptide drug candidates. However, the wide sequence variation, sources and modalities of group members impose serious limitations on our ability to rapidly identify potential members. As a result, there is a need for automated high-throughput member classification approaches that leverage their demonstrated tertiary and functional homology. We developed an SVM-based model to predict sequential tri-disulfide peptide (STP) toxins from peptide sequences. One optimized model, called PredSTP, predicted STPs from training set with sensitivity, specificity, precision, accuracy and a Matthews correlation coefficient of 94.86 %, 94.11 %, 84.31 %, 94.30 % and 0.86, respectively, using 200 fold cross validation. The same model outperforms existing prediction approaches in three independent out of sample testsets derived from PDB. PredSTP can accurately identify a wide range of cystine stabilized peptide toxins directly from sequences in a species-agnostic fashion. The ability to rapidly filter sequences for potential bioactive peptides can greatly compress the time between peptide identification and testing structural and functional properties for possible antimicrobial and insecticidal candidates. A web interface is freely available to predict STP toxins from http://crick.ecs.baylor.edu/ .	adverse reaction to drug;british informatics olympiad;cross reactions;cystine;high-throughput computing;homologous gene;homology (biology);insecticides;internationalized domain name;interstitial webpage;matthews correlation coefficient;peptide sequence;pierre robin syndrome;protein data bank;sensitivity and specificity;test set;throughput;toxin;triangular function;trimipramine;user interface;tertiary	Shah Islam;Tanvir Sajed;Christopher Kearney;Erich J. Baker	2015		10.1186/s12859-015-0633-x	biology;dna microarray;computer science;bioinformatics;genetics	Comp.	9.106563682589856	-56.4440523622524	19397
23ba1576ca9e6770ee3e28b924b063e1fc85496f	inhibit yourself and understand the other: neural basis of distinct processes underlying theory of mind	inferior frontal gyrus;response inhibition;fmri;temporo parietal junction;individual differences;theory of mind;superior temporal gyrus;general population;functional magnetic resonance images;perspective taking;cognitive control;mental state attribution;time use;neuropsychological evidence;lobe contributions;inhibition;false belief;self	Taking the perspective of somebody else (Theory of Mind; ToM) is an essential human ability depending on a large cerebral network comprising prefrontal and temporo-parietal regions. Recently, ToM was suggested to consist of two processes: (1) self-perspective inhibition and (2) belief reasoning. Moreover, it has been hypothesized that self-perspective inhibition may build upon basic motor response inhibition. This study tested both hypotheses for the first time using functional Magnetic Resonance Imaging (fMRI), through administering both a ToM and a stop-signal paradigm in the same subjects. Both self-perspective and motor response inhibition yielded bilateral inferior frontal gyrus (IFG) activation, suggesting a common inhibitory mechanism, while belief reasoning was mediated by the superior temporal gyrus (STG) and temporo-parietal junction (TPJ). Thus, we provide neurobiological evidence for a subdivision of ToM into self-perspective inhibition and belief reasoning. Furthermore, evidence for partially shared neural mechanisms for inhibition in complex social situations and basic motor response inhibition was found.	administration procedure;bilateral filter;frontal lobe gyrus;ifng wt allele;inferior frontal gyrus;prpf6 gene;parietal lobe;programming paradigm;p–n junction;reasoning;resonance;star trek generations;subdivision surface;superior temporal gyrus;fmri	Lisette van der Meer;Nynke A. Groenewold;Willem A. Nolen;Marieke Pijnenborg;André Aleman	2011	NeuroImage	10.1016/j.neuroimage.2011.03.053	differential psychology;psychology;cognitive psychology;developmental psychology;self;inhibition theory;social psychology	ML	17.72155181121916	-77.0805021431336	19409
e5cb74cb425fcaf79c812c041719335e641bba6d	effective boolean dynamics analysis to identify functionally important genes in large-scale signaling networks	signaling network;boolean sensitivity;centrality measure;update rule perturbation;drug targets;essential genes;boolean dynamics	Efficiently identifying functionally important genes in order to understand the minimal requirements of normal cellular development is challenging. To this end, a variety of structural measures have been proposed and their effectiveness has been investigated in recent literature; however, few studies have shown the effectiveness of dynamics-based measures. This led us to investigate a dynamic measure to identify functionally important genes, and the effectiveness of which was verified through application on two large-scale human signaling networks. We specifically consider Boolean sensitivity-based dynamics against an update-rule perturbation (BSU) as a dynamic measure. Through investigations on two large-scale human signaling networks, we found that genes with relatively high BSU values show slower evolutionary rate and higher proportions of essential genes and drug targets than other genes. Gene-ontology analysis showed clear differences between the former and latter groups of genes. Furthermore, we compare the identification accuracies of essential genes and drug targets via BSU and five well-known structural measures. Although BSU did not always show the best performance, it effectively identified the putative set of genes, which is significantly different from the results obtained via the structural measures. Most interestingly, BSU showed the highest synergy effect in identifying the functionally important genes in conjunction with other measures. Our results imply that Boolean-sensitive dynamics can be used as a measure to effectively identify functionally important genes in signaling networks.		Hung-Cuong Trinh;Yung-Keun Kwon	2015	Bio Systems	10.1016/j.biosystems.2015.07.007	biology;bioinformatics;data mining	Comp.	6.141585619602775	-58.07574443409009	19432
0fd17363b7455195c47dbb256d5b84a6c55cbfe2	domain similarity based orthology detection	health research;uk clinical guidelines;biological patents;europe pubmed central;citation search;computational biology bioinformatics;uk phd theses thesis;life sciences;algorithms;combinatorial libraries;uk research reports;medical journals;computer appl in life sciences;europe pmc;biomedical research;microarrays;bioinformatics	Orthologous protein detection software mostly uses pairwise comparisons of amino-acid sequences to assert whether two proteins are orthologous or not. Accordingly, when the number of sequences for comparison increases, the number of comparisons to compute grows in a quadratic order. A current challenge of bioinformatic research, especially when taking into account the increasing number of sequenced organisms available, is to make this ever-growing number of comparisons computationally feasible in a reasonable amount of time. We propose to speed up the detection of orthologous proteins by using strings of domains to characterize the proteins. We present two new protein similarity measures, a cosine and a maximal weight matching score based on domain content similarity, and new software, named porthoDom. The qualities of the cosine and the maximal weight matching similarity measures are compared against curated datasets. The measures show that domain content similarities are able to correctly group proteins into their families. Accordingly, the cosine similarity measure is used inside porthoDom, the wrapper developed for proteinortho. porthoDom makes use of domain content similarity measures to group proteins together before searching for orthologs. By using domains instead of amino acid sequences, the reduction of the search space decreases the computational complexity of an all-against-all sequence comparison. We demonstrate that representing and comparing proteins as strings of discrete domains, i.e. as a concatenation of their unique identifiers, allows a drastic simplification of search space. porthoDom has the advantage of speeding up orthology detection while maintaining a degree of accuracy similar to proteinortho. The implementation of porthoDom is released using python and C++ languages and is available under the GNU GPL licence 3 at http://www.bornberglab.org/pages/porthoda .	amino acid metabolism, inborn errors;amino acid sequence;amino acids;arbitrary unit of igg isotype for phospholipid antigen;bio-informatics;bioinformatics;c++;computational complexity theory;concatenation;cosine similarity;gnu;homology (biology);level of detail;matching;maximal set;name;programming languages;python;sequence homology;similarity measure;string (computer science);unique identifier	Tristan Bitard-Feildel;Carsten Kemena;Jenny M. Greenwood;Erich Bornberg-Bauer	2015		10.1186/s12859-015-0570-8	biology;dna microarray;computer science;bioinformatics;data science;data mining	Comp.	1.9536063517422257	-56.75363961238661	19436
1a5bf0a1241b318f3ab579063ab8f7982ad4fba8	the process-interaction-model: a common representation of rule-based and logical models allows studying signal transduction on different levels of detail	software;signal transduction;models biological;computational biology bioinformatics;cell physiological phenomena;protein structure tertiary;protein processing post translational;algorithms;combinatorial libraries;computer appl in life sciences;microarrays;bioinformatics	Signaling systems typically involve large, structured molecules each consisting of a large number of subunits called molecule domains. In modeling such systems these domains can be considered as the main players. In order to handle the resulting combinatorial complexity, rule-based modeling has been established as the tool of choice. In contrast to the detailed quantitative rule-based modeling, qualitative modeling approaches like logical modeling rely solely on the network structure and are particularly useful for analyzing structural and functional properties of signaling systems. We introduce the Process-Interaction-Model (PIM) concept. It defines a common representation (or basis) of rule-based models and site-specific logical models, and, furthermore, includes methods to derive models of both types from a given PIM. A PIM is based on directed graphs with nodes representing processes like post-translational modifications or binding processes and edges representing the interactions among processes. The applicability of the concept has been demonstrated by applying it to a model describing EGF insulin crosstalk. A prototypic implementation of the PIM concept has been integrated in the modeling software ProMoT. The PIM concept provides a common basis for two modeling formalisms tailored to the study of signaling systems: a quantitative (rule-based) and a qualitative (logical) modeling formalism. Every PIM is a compact specification of a rule-based model and facilitates the systematic set-up of a rule-based model, while at the same time facilitating the automatic generation of a site-specific logical model. Consequently, modifications can be made on the underlying basis and then be propagated into the different model specifications – ensuring consistency of all models, regardless of the modeling formalism. This facilitates the analysis of a system on different levels of detail as it guarantees the application of established simulation and analysis methods to consistent descriptions (rule-based and logical) of a particular signaling system.	basis (linear algebra);crosstalk;description;directed graph;formal system;genetic translation process;graph - visual representation;interaction;level of detail;logic programming;logical data model;post-translational protein processing;process modeling;rule-based modeling;signal transduction;signalling system no. 7;simulation;specification;transduction (machine learning)	Katrin Kolczyk;Regina Samaga;Holger Conzelmann;Sebastian Mirschel;Carsten Conradi	2012		10.1186/1471-2105-13-251	biology;dna microarray;computer science;bioinformatics;theoretical computer science;algorithm;signal transduction	AI	6.690927816331815	-59.12253652672733	19460
341a310b56ae248b6c5bae4c98d953685a5933ba	generating synthetic gene regulatory networks	oscillations;causal model;gene network;small world;time delay;scale free;synthetic gene regulatory networks;feedback loop;causal models;gene regulatory network;simulation environment;microarrays;dynamic behavior	Reconstructing GRN from microarray dataset is a very challenging problem as these datasets typically have large number of genes and less number of samples. Moreover, the reconstruction task becomes further complicated as there are no suitable synthetic datasets available for validation and evaluation of GRN reconstruction techniques. Synthetic datasets allow validating new techniques and approaches since the underlying mechanisms of the GRNs, generated from these datasets, are completely known. In this paper, we present an approach for synthetically generating gene networks using causal relationships. The synthetic networks can have varying topologies such as small world, random, scale free, or hierarchical topologies based on the well-defined GRN properties. These artificial but realistic GRN networks provide a simulation environment similar to a real-life laboratory microarray experiment. These networks also provide a mechanism for studying the robustness of reconstruction methods to individual and combination of parametric changes such as topology, noise (background and experimental noise) and time delays. Studies involving complicated interactions such as feedback loops, oscillations, bi-stability, dynamic behavior, vertex in-degree changes and number of samples can also be carried out by the proposed synthetic GRN networks.	gene regulatory network;synthetic intelligence	Ramesh Ram;Madhu Chetty	2008		10.1007/978-3-540-88436-1_21	biology;gene regulatory network;computer science;bioinformatics;machine learning;data mining;genetics;causal model	Theory	6.608066927852863	-58.38096419314388	19575
22502e9d358fc5b0a4810d6415b40bc440be0dca	trophic relationships and ecosystem functioning of bakreswar reservoir, india		Reservoirs are artificial water bodies having social application and hybrid characters of both river and lake. Thorough analysis of water quantity and quality is necessary to ensure the health of these ecosystems, as they are considered one of the major water sources in developing countries. Biological subsystem of reservoirs consists of both autotrophs and heterotrophs in the open zone and littoral zone. These components are critical for freshwater aquatic food webs. Bakreswar reservoir has been selected as the current study site. Static model representing ecosystem trophic structure is developed through Ecopath with Ecosim software and is analysed to obtain idea about the ecosystem functioning and functioning. This reservoir is found to be approaching maturity but with vulnerabilities being present as is evident from the studies of ecosystem attributes, transfer efficiencies, mixed trophic impact, niche overlap and other attributes. Good assemblage of biota like macrophytes, zooplankton etc. is observed, thus presenting some diversity in the food web. Based on the primary production to respiration ratio, this system can be categorized as a moderately mature and healthy ecosystem but is vulnerable to perturbations as is evident by low values of connectance index and system omnivory index. Comparatively low Finn cycling index indicates that this system is approaching maturity but is vulnerable. With a pedigree index of 0.459, the model is well suited for the study site. The knowledge thus obtained for this reservoir can be utilized to form proper management strategies to facilitate successful conservation management and proper resource utilization.	aquatic ecosystem;capability maturity model;categorization;color cycling;freshwater ecosystem;niche blogging;trophic function;trophic species	Arnab Banerjee;Moitreyee Banerjee;Joyita Mukherjee;Nabyendu Rakshit;Santanu Ray	2016	Ecological Informatics	10.1016/j.ecoinf.2016.09.006	ecology	Web+IR	3.8984973677044983	-65.57117141472709	19649
eddae0b1ef2bc813d5673fc698f3086f88aa20a9	an hv-svm classifier to infer tf-tf interactions using protein domains and go annotations	biology computing;go annotations transcription factor support vector machine protein domains;transcription factor interaction;homo sapiens;support vector machines;protein domains;hv svm classifier;genetics;transcription regulation;support vector machine classifier;support vector machines biology computing cellular biophysics genetic algorithms genetics learning artificial intelligence pattern classification proteins;mus muculus;eukaryotes;vertical kernel;proteins;transcription factor;feature weighting;pattern classification;tf tf interaction;genetic algorithm;proteins kernel gene expression dna throughput data mining support vector machines support vector machine classification biology computing sequences;genetic algorithms;mus muculus hv svm classifier tf tf interaction protein domain go annotations transcription factor interaction eukaryotes support vector machine classifier horizontal kernel vertical kernel genetic algorithm homo sapiens;support vector machine;learning artificial intelligence;cellular biophysics;protein domain;go annotations;horizontal kernel	Interactions between transcription factors (TFs) are necessary for deciphering the complex mechanisms of transcription regulation in eukaryotes. In this paper, we proposed a novel HV-kernel based Support Vector Machine classifier (HV-SVM) to predict TF-TF interactions based on their protein domain information and GO annotations. Specifically, two types of pairwise kernels, namely, a horizontal kernel and a vertical kernel, were combined to evaluate the similarity between a pair of TFs, and a Genetic algorithm was used to obtain kernel and feature weights to optimize the classifier's performance. We applied our proposed HV-SVM method to predict TF interactions for Homo sapiens and Mus muculus. We obtained accuracy and F-measures of over 85% and an AUC of almost 93%, demonstrating that HV-SVM can accurately predict TF-TF interactions even in the higher and more complex eukaryotes.	genetic algorithm;imperative programming;interaction;kernel (operating system);pfam;support vector machine;transcription (software)	Xiaoli Li;Jun-Xiang Lee;Bharadwaj Veeravalli;See-Kiong Ng	2007	2007 IEEE 7th International Symposium on BioInformatics and BioEngineering	10.1109/BIBE.2007.4375747	biology;support vector machine;genetic algorithm;computer science;bioinformatics;machine learning;pattern recognition;protein domain;genetics	SE	9.346753844497364	-55.69186567879136	19708
1b60eceb769ec0062acf2b1ecd0444a157758832	modeling of the dorsal gradient across species reveals interaction between embryo morphology and toll signaling pathway during evolution	health research;uk clinical guidelines;biochemical simulations;biological patents;simulation and modeling;europe pubmed central;citation search;embryos;gene expression;drosophila;uk phd theses thesis;drosophila melanogaster;life sciences;mesoderm;uk research reports;medical journals;europe pmc;phylogenetics;biomedical research;bioinformatics	Morphogenetic gradients are essential to allocate cell fates in embryos of varying sizes within and across closely related species. We previously showed that the maternal NF-κB/Dorsal (Dl) gradient has acquired different shapes in Drosophila species, which result in unequally scaled germ layers along the dorso-ventral axis and the repositioning of the neuroectodermal borders. Here we combined experimentation and mathematical modeling to investigate which factors might have contributed to the fast evolutionary changes of this gradient. To this end, we modified a previously developed model that employs differential equations of the main biochemical interactions of the Toll (Tl) signaling pathway, which regulates Dl nuclear transport. The original model simulations fit well the D. melanogaster wild type, but not mutant conditions. To broaden the applicability of this model and probe evolutionary changes in gradient distributions, we adjusted a set of 19 independent parameters to reproduce three quantified experimental conditions (i.e. Dl levels lowered, nuclear size and density increased or decreased). We next searched for the most relevant parameters that reproduce the species-specific Dl gradients. We show that adjusting parameters relative to morphological traits (i.e. embryo diameter, nuclear size and density) alone is not sufficient to reproduce the species Dl gradients. Since components of the Tl pathway simulated by the model are fast-evolving, we next asked which parameters related to Tl would most effectively reproduce these gradients and identified a particular subset. A sensitivity analysis reveals the existence of nonlinear interactions between the two fast-evolving traits tested above, namely the embryonic morphological changes and Tl pathway components. Our modeling further suggests that distinct Dl gradient shapes observed in closely related melanogaster sub-group lineages may be caused by similar sequence modifications in Tl pathway components, which are in agreement with their phylogenetic relationships.	apache axis;axis vertebra;biological evolution;cell signaling;diameter (qualifier value);eaf2 gene;electronic toll collection;embryo;gene regulatory network;gradient;interaction;mathematical model;mathematical morphology;mathematics;nonlinear system;phylogenetics;signal transduction pathways;simulation;subgroup;tlr4 protein, human;trait;wild type;anatomical layer;childhood central nervous system germ cell tumor;nucleocytoplasmic transport	Priscilla Ambrosi;Juan Sebastian Chahda;Hannah R. Koslen;Hillel J. Chiel;Claudia Mieko Mizutani	2014		10.1371/journal.pcbi.1003807	biology;embryo;gene expression;bioinformatics;ecology;genetics;phylogenetics	Comp.	8.42855617940492	-64.08592027767479	19715
b3db96b5e8328ca08c31c3ee2c268333044a5152	contribution of chronic pain and neuroticism to abnormal forebrain gray matter in patients with temporomandibular disorder	chronic disease;female;healthy control;prosencephalon;neurotic disorders;temporomandibular disorder;male;cortical plasticity;prefrontal cortex;voxel based morphometry;pain modulation;primary somatosensory cortex;adult;magnetic resonance imaging;pain;gray matter;humans;neurons;cingulate cortex;chronic pain;sensorimotor cortex;orbitofrontal cortex;cortical thickness;temporomandibular joint disorders	Cortical plasticity is thought to occur following continuous barrage of nociceptive afferent signals to the brain. Hence, chronic pain is presumed to induce anatomical and physiological changes in the brain over time. Inherent factors, some pre-dating the onset of chronic pain, may also contribute to brain abnormalities present in patients. In this study we used structural MRI to examine whether patients with chronic temporomandibular (TMD) pain have abnormalities in gray matter (GM) within brain areas implicated in pain, modulation and sensorimotor function. We found that patients with TMD have cortical thickening in the primary somatosensory cortex (S1), frontal polar and the ventrolateral prefrontal cortex (PFC). These findings provide a structural basis for previous findings of TMD pain and cognitive sluggishness in TMD. We then examined the contribution of TMD characteristics to GM abnormalities. We found that 1) GM in the sensory thalamus positively correlated to TMD duration, 2) cortical thickness in the primary motor (M1) and the anterior mid-cingulate cortices (aMCC) were negatively correlated to pain intensity, and 3) pain unpleasantness was negatively correlated to cortical thickness in the orbitofrontal cortex (OFC). These findings suggest that an individual's TMD pain history contributes to GM in the brain. Lastly, we examined the contribution of a potential pre-existing vulnerability due to neuroticism. In the TMD patients, we found that there was an abnormal positive correlation between neuroticism and OFC thickness, in contrast to the negative correlation found in the healthy controls. Therefore, neuroticism may contribute to TMD pathophysiology. In sum, our data suggest that GM in the brain of patients with chronic TMD pain can be shaped by both personality and pain characteristics.	basal forebrain;brain neoplasms;chronic pain;cognition disorders;congenital abnormality;gray matter;modulation;neuroticism;orofacial cleft 1;onset (audio);patients;powerbuilder foundation classes;prefrontal cortex;prosencephalon;somatosensory cortex;temporomandibular joint disorders;thalamic structure;thickness (graph theory);tip-magnetic driving;transition metal dichalcogenide monolayers	Massieh Moayedi;Irit Weissman-Fogel;Adrian P. Crawley;Michael B. Goldberg;Bruce V. Freeman;Howard C. Tenenbaum;Karen D. Davis	2011	NeuroImage	10.1016/j.neuroimage.2010.12.013	psychology;neuroplasticity;psychiatry;neuroscience;developmental psychology;radiology;magnetic resonance imaging;somatosensory system;voxel-based morphometry	ML	18.614270327995094	-79.20052449294225	19775
81ec58850dfde7e200c789a251f0d0af8d8b655c	stochastic aspects of kinase cascade pathways in cellular signaling	fluctuation dissipation approximation;stochastic fluctuation;cellular signaling;kinase cascade;fluctuations;information science;signal analysis;kinase saturation levels;enzyme;attenuation;kinase cascade pathways;stochastic processes fluctuations proteins biochemistry signal analysis equations kinetic theory predictive models stochastic systems information science;gillespie simulation;stochastic processes biochemistry cellular biophysics enzymes;kinetic theory;enzymes;proteins;stochastic processes;stochastic fluctuation attenuator;fluctuation dissipation approximation stochastic fluctuation kinase cascade gillespie simulation;mathematical model;predictive models;approximation methods;substrates;stochastic model;gillespie simulations;stochastic systems;stochastic fluctuation accumulator;kinetics;cellular biophysics;biochemistry;kinase saturation levels kinase cascade pathways cellular signaling gillespie simulations stochastic fluctuation attenuator stochastic fluctuation accumulator enzymes;fluctuation dissipation	Simplified kinase cascade pathways in cellular signaling are analyzed from the viewpoint of the stochastic fluctuations of each activated constituent kinases. The analytical representations of the kinetics of the kinases are obtained by approximation for the two extreme cases of far-from-saturation with the substrate and of the saturation in enzymes. These stochastic models predict the attenuations of the stochastic fluctuations along downward in the cascade tiers for the case of far-from-saturation and the accumulations of the fluctuations for the case of the saturation. These predictions are further confirmed by the Gillespie simulations. Hence, kinase cascade pathways could work as both of the stochastic fluctuation attenuator and the accumulator, depending on the kinase saturation levels with the substrates.	accumulator (computing);approximation;cell signaling;gillespie algorithm;kinetics internet protocol;optical attenuator;quantum fluctuation;simulation;stochastic process	Takashi Naka	2010	2010 International Conference on Computational Science and Its Applications	10.1109/ICCSA.2010.70	enzyme;information science;computer science	Robotics	7.84201576194408	-65.4740939975937	19791
267d634808327c9ef6a471e125488ee42b0b042f	specific increase of human entorhinal population synaptic and neuronal activity during retrieval	microelectrodes;episodic memory;membrane potentials;linear array;entorhinal cortex;male;mental recall;declarative memory;adult;humans;neurons;electroencephalography;epilepsy temporal lobe;neuronal activity;synapses;semantic retrieval	Population transmembrane currents and neuronal firing in different layers of the human entorhinal cortex (ER) were recorded during semantic and episodic memory processes using a linear array of 24 laminar microelectrodes. Both measures, as well as local broadband spectral power, increased during retrieval of newly-learned characteristics, especially in superficial layers. No differences were observed in the activity evoked by remembering people as compared to places. Semantic retrieval evoked similar activity. In contrast, intentional encoding of declarative memory evoked relatively little activity. A double-dissociation of these responses with simultaneously recorded lateral inferotemporal recordings suggests that entorhinal cortex may be specifically engaged during retrieval, across multiple memory types and materials.	arm cortex-r;action potential;cerebral cortex;information retrieval;lateral computing;lateral thinking;memory, episodic;mental recall;structure of entorhinal cortex;synaptic package manager;the superficial;anatomical layer	Susanne Knake;Chun Mao Wang;István Ulbert;Donald L. Schomer;Eric Halgren	2007	NeuroImage	10.1016/j.neuroimage.2007.05.009	psychology;cognitive psychology;neuroscience;developmental psychology;membrane potential;electroencephalography;microelectrode;synapse;episodic memory;declarative memory;premovement neuronal activity	ML	17.25009778142399	-76.38536211339155	19798
d11cb87a2b4b1e3dd86e70e9a8ca088334643a45	low-power (1t1n) skyrmionic synapses for spiking neuromorphic systems		In this paper, we propose a “1-transistor 1-nanotrack” (1T1N) synapse based on the movement of magnetic skyrmions using spin-polarized current pulses. The proposed synaptic bit-cell has four terminals and fully decoupled spike transmission and programming paths. With careful tuning of programming parameters, we ensure multi-level non-volatile conductance evolution in the proposed skyrmionic synapse. Through micromagnetic simulations, we studied in detail the impact of the programming conditions (current density and pulse width) on synaptic performance parameters, such as the number of conductance levels and energy per transition. The programming parameters used for all further analysis gave rise to a synapse with 7 distinct conductance states and 1.2 fJ per conductance state transition event. Exploiting bidirectional conductance modulation, the 1T1N synapse is able to undergo long-term potentiation and depression according to a simplified variant of the biological spike timing-dependent plasticity rule. We present a subthreshold CMOS spike generator circuit which when coupled with a well-known subthreshold integrator circuit produces custom pre- and post-neuronal spike shapes responsible for implementing unsupervised learning with the proposed 1T1N synaptic bit-cell and consuming ~0.25 pJ/event. A spiking neural network incorporating the characteristics of the 1T1N synapse was simulated for two separate applications: pattern extraction from noisy video streams and handwritten digit classification.		Tinish Bhattacharya;Sai Li;Yangqi Huang;Wang Kang;Weisheng Zhao;Manan Suri	2019	IEEE Access	10.1109/ACCESS.2018.2886854	conductance;distributed computing;spiking neural network;subthreshold conduction;op amp integrator;computer science;modulation;pulse-width modulation;cmos;topology;neuromorphic engineering	ML	17.730621581495317	-70.1294719160011	19817
48b587c7e6c9ec88fabc11805d89532e3bed7a9f	the evolution of nitrogen fixation in cyanobacteria	nitrogen fixation;underlying nif gene;nitrogen-fixing cyanobacterial ancestor;bioinformatics online;biogeochemical history;fixed nitrogen;cyanobacterial nitrogen-fixing ability;nitrogen cycle;nif gene;species phylogeny	MOTIVATION Fixed nitrogen is an essential requirement for the biosynthesis of cellular nitrogenous compounds. Some cyanobacteria can fix nitrogen, contributing significantly to the nitrogen cycle, agriculture and biogeochemical history of Earth. The rate and position on the species phylogeny of gains and losses of this ability, as well as of the underlying nif genes, are controversial.   RESULTS We use probabilistic models of trait evolution to investigate the presence and absence of cyanobacterial nitrogen-fixing ability. We estimate rates of change on the species phylogeny, pinpoint probable changes and reconstruct the state and nif gene complement of the ancestor. Our results are consistent with a nitrogen-fixing cyanobacterial ancestor, repeated loss of nitrogen fixation and vertical descent, with little horizontal transfer of the genes involved.   SUPPLEMENTARY INFORMATION Supplementary data are available at Bioinformatics online.	anabolism;automatic bug fixing;biogeochemistry;bioinformatics;blood urea nitrogen measurement;complement system proteins;contribution;cyanobacteria;nitrogen cycle;nitrogen fixation;nitrogen-vacancy center;phylogenetics;probability	Natasha Latysheva;Vivien L. Junker;William J. Palmer;Geoffrey A. Codd;Daniel Barker	2012	Bioinformatics	10.1093/bioinformatics/bts008	biology;botany;ecology	Comp.	3.733059752190423	-61.68380316740128	19919
10d968ea03c75f04611312ce889a535b14cba279	distinctive and compact features	object recognition;facial features;feature selection;binary classification;difference set;face detection;visual system;distinctive features	We consider the problem of extracting features for multi-class recognition problems. The features are required to make fine distinction between similar classes, combined with tolerance for distortions and missing information. We define and compare two general approaches, both based on maximizing the delivered information for recognition: one divides the problem into multiple binary classification tasks, while the other uses a single multiclass scheme. The two strategies result in markedly different sets of features, which we apply to face identification and detection. We show that the first produces a sparse set of distinctive features that are specific to an individual face, and are highly tolerant to distortions and missing input. The second produces compact features, each shared by about half of the faces, and which perform better in general face detection. The results show the advantage of distinctive features for making fine distinctions in a robust manner. They also show that different features are optimal for recognition tasks at different levels of specificity. In performing recognition, the visual system, either human or artificial, must cope with the problem of image variability, that is, that an object’s appearance is highly variable due to changes in shape, viewing direction, illumination, and occlusion. At the same time, the task often requires making fine distinctions between objects, such as between similar faces. It is particularly surprising given these difficulties that reliable recognition can be obtained on the basis of reduced and distorted representations, such as the caricatures and the drawings produced by artists, e.g. [1], see examples in figure 2. In such images, the faces consist only of a few informative features that are distorted, often represented schematically, and placed in an inaccurate spatial arrangement. This illustrates a fundamental general question: how is it possible to reliably distinguish between multiple similar classes, and yet be tolerant to reduced and distorted information? To approach this problem, we define and compare two natural strategies for extracting classification features in problems involving multiple similar classes, and apply them to face examples. Both are based on maximizing information for classification, but they produce notable different features. One method divides the problem Preprint submitted to Elsevier Science 16 March 2006 into multiple binary classification tasks, while the other uses a single multi-class scheme. We show that the first leads to a sparse representation based on distinctive features, which is tolerant to large distortions and missing input, and better for robust face identification, requiring only a few distinctive features for reliable identification. The second leads to compact coding where each features is shared by about half of the faces, and which performs better in general face detection. The distinctive features are also shown to be similar to the ones selected by an artist specializing [1] in producing reduced face representations, and the algorithm is the first to automatically produce such distinctive features. The focus of the study is on feature selection for multi-class recognition, rather than face recognition. Face images are used as a testing domain, for which there are example of distinctive features selected by human experts. The rest of the paper is organized as follows: Section 2 reviews past relevant approaches to face recognition and detection, with emphasis on the type of features used by these approaches. Section 3 describes the two selection strategies, and automatic extraction of sparse and compact features. Section 4 presents experimental results, comparing sparse and compact features in face recognition and detection. We also compare between the distinctive fragments obtained by the current method and the representations produced by an artist. Section 5 includes a discussion of the results and conclusions.	algorithm;binary classification;distortion;face detection;facial recognition system;feature selection;information;sensitivity and specificity;sparse approximation;sparse language;sparse matrix;spatial variability;statistical classification;viewing cone	Ayelet Akselrod-Ballin;Shimon Ullman	2008	Image Vision Comput.	10.1016/j.imavis.2008.03.005	binary classification;computer vision;face detection;visual system;haar-like features;computer science;cognitive neuroscience of visual object recognition;machine learning;pattern recognition;mathematics;feature selection;difference set	Vision	22.27794339390001	-61.327389405739254	19967
ad79d2dc6829993396b77b152fc3a5dfe3c3a1b4	gpudepict: a parallel implementation of a clustering algorithm for computing degenerate primers on graphics processing units	dna;software;degenerate primer;shared memory;computer graphics;image processing computer assisted;polymerase chain reaction;computing power gpudepict parallel implementation clustering algorithm degenerate primers computing graphics processing units polymerase chain reaction nucleotides complementary flanking regions multiple closely related target sequences mutations pcr technique web accessible software package shared memory model nucleotides hybrid gpu cpu implementation human genome;parallelism;amino acids clustering algorithms graphics processing units instruction sets parallel processing bioinformatics dna;cluster analysis;graphics processing units;genome;dna primers;clustering algorithms;pattern clustering biochemistry biology computing enzymes genomics graphics processing units molecular biophysics molecular configurations parallel algorithms;amino acids;algorithms;graphics processing units gpus;computational biology;parallel processing;instruction sets;bioinformatics	"""In order to make multiple copies of a target sequence in the laboratory, the technique of Polymerase Chain Reaction (PCR) requires the design of """"primers"""", which are short fragments of nucleotides complementary to the flanking regions of the target sequence. If the same primer is to amplify multiple closely related target sequences, then it is necessary to make the primers """"degenerate"""", which would allow it to hybridize to target sequences with a limited amount of variability that may have been caused by mutations. However, the PCR technique can only allow a limited amount of degeneracy, and therefore the design of degenerate primers requires the identification of reasonably well-conserved regions in the input sequences. We take an existing algorithm for designing degenerate primers that is based on clustering and parallelize it in a web-accessible software package GPUDePiCt, using a shared memory model and the computing power of Graphics Processing Units (GPUs). We test our implementation on large sets of aligned sequences from the human genome and show a multi-fold speedup for clustering using our hybrid GPU/CPU implementation over a pure CPU approach for these sequences, which consist of more than 7,500 nucleotides. We also demonstrate that this speedup is consistent over larger numbers and longer lengths of aligned sequences."""	abnormal degeneration;alignment;cpu (central processing unit of computer system);central processing unit;cluster analysis;computation (action);copy (object);degeneracy (graph theory);flank (surface region);graphics processing unit;greater than;large;mutation;nucleotides;numerous;primer;reverse transcriptase polymerase chain reaction;shared memory;spatial variability;speedup;algorithm;statistical cluster	Trevor Cickovski;Tiffany Flor;Galen Irving-Sachs;Philip Novikov;James Parda;Giri Narasimhan	2015	IEEE/ACM Transactions on Computational Biology and Bioinformatics	10.1109/TCBB.2014.2355231	parallel processing;parallel computing;computer science;bioinformatics;theoretical computer science;cluster analysis;genetics	Comp.	-1.4002912699901593	-52.1892583979254	19980
39eb4ddd667ca4d63be2c78b2b51c42937c56073	a scale-changeable image analysis method	feedback control circuit;image representation;neurons;non-classical receptive field	The biological vision system is far more efficient than machine vision system. This is due to the former has rich neural layers for representation and process. In order to obtain a non-task-dependent image representation schema, the early phase of neural vision mechanism is worth simulating. We design a neural model to simulate non-classical receptive field of ganglion cell and its local feedback control circuit, and find it can represent image, beyond pixel level, self-adaptively and regularly. The experimental results prove this method can represent image faithfully with low cost, and can produce a compact and abstract approximation to facilitate successive image segmentation as well as integration operation. This representation schema is good at extracting spatial relationship from different components of image, thus it can be applied to formalize image semantics. Further it can be applied to object recognition or image classification tasks in future.	approximation;computer vision;feedback;image analysis;image segmentation;machine vision;outline of object recognition;pixel;simulation	Hui Wei;Bo Lang;Qingsong Zuo	2011		10.1007/978-3-642-23957-1_7	image texture;feature detection;color image;image gradient;binary image;image processing;image segmentation;image formation;top-hat transform;standard test image;image histogram	Vision	22.285352182658144	-66.50323832153923	19992
49c98c5e3e5ce0fa462f3989df8b4cbb4a146975	repositioning drugs by targeting network modules: a parkinson’s disease case study		Much effort has been devoted to the discovery of specific mechanisms between drugs and single targets to date. However, as biological systems maintain homeostasis at the level of functional networks robustly controlling the internal environment, such networks commonly contain multiple redundant mechanisms designed to counteract loss or perturbation of a single member of the network. As such, investigation of therapeutics that target dysregulated pathways or processes, rather than single targets, may identify agents that function at a level of the biological organization more relevant to the pathology of complex diseases such as Parkinson’s Disease (PD). Genome-wide association studies (GWAS) in PD have identified common variants underlying disease susceptibility, while gene expression microarray data provide genome-wide transcriptional profiles. These genomic studies can illustrate upstream perturbations causing the dysfunction in signaling pathways and downstream biochemical mechanisms leading to the PD phenotype. We hypothesize that drugs acting at the level of a gene expression module specific to PD can overcome the lack of efficacy associated with targeting a single gene in polygenic diseases. Thus, this approach represents a promising new direction for module-based drug discovery in human diseases such as PD. We built a framework that integrates GWAS data with gene co-expression modules from tissues representing three brain regions—the frontal gyrus, the lateral substantia, and the medial substantia in PD patients. Using weighted gene correlation network analysis (WGCNA) software package in R, we conducted enrichment analysis of data from a GWAS of PD. This led to the identification of two over-represented PD-specific gene co-expression network modules: the Brown Module (Br) containing 449 genes and the Turquoise module (T) containing 905 genes. Further enrichment analysis identified four functional pathways within the Br module (cellular respiration, intracellular transport, energy coupled proton transport against the electrochemical gradient, and microtubule-based movement), and one functional pathway within the T module (M-phase). Next, we utilized drug-protein regulatory relationship databases (DMAP) and developed a Drug Effect Sum Score (DESS) to evaluate all candidate drugs that might restore gene expression to normal level across the Br and T modules. Among the drugs with the 12 highest DESS scores, 5 had been reported as potential treatments for PD and 6 hold potential repositioning applications. In this study, we present a systems pharmacology framework which draws on genetic data from GWAS and gene expression microarray data to reposition drugs for PD. Our innovative approach integrates gene co-expression modules with biomolecular interaction network analysis to identify network modules critical to the PD pathway and disease mechanism. We quantify the positive effects of drugs in a DESS score that is based on known drug-target activity profiles. Our results illustrate that this modular approach is promising for repositioning drugs for use in polygenic diseases such as PD, and is capable of addressing challenges of the hindered gene target in drug repositioning approaches to date.	biological organisation;biological system;body tissue;brown-sequard syndrome;cell respiration;database;digital media access protocol;disease ontology;downstream (software development);drug discovery;endocrine system diseases;frontal lobe gyrus;gene expression;gene ontology term enrichment;gene co-expression network;gene regulatory network;genome-wide association study;gradient;hearing loss, high-frequency;homeostasis;interaction network;intracellular transport;lateral thinking;medial graph;microarray;microtubules;parkinson disease;parkinsonian disorders;patients;pharmacology;protons;repositioning (procedure);therapeutic procedure;transcription, genetic;upstream (software development);cellular targeting;proton transport	Zongliang Yue;Itika Arora;Eric Y. Zhang;Vincent Laufer;S. Louis Bridges;Jake Yue Chen	2017		10.1186/s12859-017-1889-0	cancer research;parkinson's disease;signal transduction;gene expression;drug discovery;gene;bioinformatics;biology;microarray analysis techniques;disease;genome-wide association study	Comp.	6.4542743190046865	-59.93623625872186	20002
c261d37cacdec751dee1292a412f9ccb9c07c3bc	vitamin d receptor gene polymorphism's effect of bone mineral density: analysis by use of belief functions	vitamin d receptor			Shih-Chuan Cheng;Alyssa A. Goetzinger;John N. Mordeson	2002			bone mineral;cancer research;biology;gene polymorphism;calcitriol receptor	Crypto	2.38180579911692	-64.42355060311472	20134
8b53bfa188619d026fae1ba3dfeb384c45e37d6d	biomoby extensions to the taverna workflow management and enactment software	software;workflow management;software tool;user needs;database management systems;biology;data type;web service;computational biology bioinformatics;complex data;internet;system biology;algorithms;user computer interface;databases factual;combinatorial libraries;computer appl in life sciences;information storage and retrieval;microarrays;bioinformatics	"""As biology becomes an increasingly computational science, it is critical that we develop software tools that support not only bioinformaticians, but also bench biologists in their exploration of the vast and complex data-sets that continue to build from international genomic, proteomic, and systems-biology projects. The BioMoby interoperability system was created with the goal of facilitating the movement of data from one Web-based resource to another to fulfill the requirements of non-expert bioinformaticians. In parallel with the development of BioMoby, the European myGrid project was designing Taverna, a bioinformatics workflow design and enactment tool. Here we describe the marriage of these two projects in the form of a Taverna plug-in that provides access to many of BioMoby's features through the Taverna interface. The exposed BioMoby functionality aids in the design of """"sensible"""" BioMoby workflows, aids in pipelining BioMoby and non-BioMoby-based resources, and ensures that end-users need only a minimal understanding of both BioMoby, and the Taverna interface itself. Users are guided through the construction of syntactically and semantically correct workflows through plug-in calls to the Moby Central registry. Moby Central provides a menu of only those BioMoby services capable of operating on the data-type(s) that exist at any given position in the workflow. Moreover, the plug-in automatically and correctly connects a selected service into the workflow such that users are not required to understand the nature of the inputs or outputs for any service, leaving them to focus on the biological meaning of the workflow they are constructing, rather than the technical details of how the services will interoperate. With the availability of the BioMoby plug-in to Taverna, we believe that BioMoby-based Web Services are now significantly more useful and accessible to bench scientists than are more traditional Web Services."""	acquired immunodeficiency syndrome;biomoby;bioinformatics;computational science;departure - action;interface device component;interoperability;pipeline (computing);plug (physical object);plug-in (computing);proteomics;registries;requirement;systems biology;web service;taverna	Edward A. Kawas;Martin Senger;Mark D. Wilkinson	2006	BMC Bioinformatics	10.1186/1471-2105-7-523	web service;workflow;the internet;dna microarray;data type;computer science;bioinformatics;data mining;world wide web;systems biology;complex data type	HPC	-3.8405062903630203	-59.847208336019015	20148
5dd644908d74337efd689f9c5faf870468882a62	simulating the cellular passive transport of glucose using a time-dependent extension of gillespie algorithm for stochastic pi-calculus	time dependent;stochastic 960;glucose passive transport;data mining;gillespie algorithm;calculus;cellular transport;chemical kinetics simulation;960;cell biology;stochastic amp;biochemical systems modelling;bioinformatics	Realistic simulations of the biological systems evolution require a mathematical model of the stochasticity of the involved processes and a formalism for specifying the concurrent nature of the biochemical interactions. A time-dependent extension of the Gillespie algorithm implementing the race condition of the stochastic pi-calculus formalism satisfies both these requirements. This paper formulates those modifications to the original Gillespie algorithm necessary when the time dependence of the reaction propensity is due to changes either of volume or temperature. This re-formulation has been incorporated in the framework of stochastic pi-calculus and has been applied to simulate the passive glucose cellular transport.		Paola Lecca	2007	International journal of data mining and bioinformatics	10.1504/IJDMB.2007.012963	computer science;bioinformatics;artificial intelligence;data mining;gillespie algorithm	SE	9.52737056400044	-68.41468940967158	20227
44aadfbd3f1dcb29c017ff1737f3d9f38992de62	prediction of the o -glycosylation with secondary structure information by support vector machines	protein sequence;amino acid sequence;protein secondary structure;local structure;secondary structure;svm;support vector machine;o glycosylation;protein;prediction;protein data bank	Mucin-type  O -glycosylation is one of the main types of the mammalian protein glycosylation. It is serine (Ser) or threonine (Thr) specific, though any consensus sequence is still unknown. In this report, support vector machines (SVM) are used for the prediction of  O -glycosylation for each Ser or Thr site in the protein sequences. 29 mammalian protein sequences are selected from UniProt8.0, and its structure information is obtained from Protein Data Bank (PDB). A protein subsequence with a prediction target of Ser or Thr site at the center is used as input to SVM, and its amino acid sequence information, and the secondary structure or accessibility, which are calculated by DSSP from PDB data, are encoded as an input data. The results of the preliminary experiments show the effectiveness of the local structure information added to the sequence information.	support vector machine	Ikuko Nishikawa;Hirotaka Sakamoto;Ikue Nouno;Kazutoshi Sakakibara;Masahiro Ito	2007		10.1007/978-3-540-74827-4_43	biology;biochemistry;homology modeling;bioinformatics;pattern recognition;protein structure prediction	Robotics	10.017713251330624	-56.07992952452781	20272
b15b419138fef4cb44a0a6202867c32bc7fc7cca	esprit-forest: parallel clustering of massive amplicon sequence data in subquadratic time	sequence databases;taxonomy;ribosomal rna;microbiome;algorithms;sequence analysis;sequence alignment;phylogenetic analysis	The rapid development of sequencing technology has led to an explosive accumulation of genomic sequence data. Clustering is often the first step to perform in sequence analysis, and hierarchical clustering is one of the most commonly used approaches for this purpose. However, it is currently computationally expensive to perform hierarchical clustering of extremely large sequence datasets due to its quadratic time and space complexities. In this paper we developed a new algorithm called ESPRIT-Forest for parallel hierarchical clustering of sequences. The algorithm achieves subquadratic time and space complexity and maintains a high clustering accuracy comparable to the standard method. The basic idea is to organize sequences into a pseudo-metric based partitioning tree for sub-linear time searching of nearest neighbors, and then use a new multiple-pair merging criterion to construct clusters in parallel using multiple threads. The new algorithm was tested on the human microbiome project (HMP) dataset, currently one of the largest published microbial 16S rRNA sequence dataset. Our experiment demonstrated that with the power of parallel computing it is now compu- tationally feasible to perform hierarchical clustering analysis of tens of millions of sequences. The software is available at http://www.acsu.buffalo.edu/∼yijunsun/lab/ESPRIT-Forest.html.	analysis of algorithms;biopolymer sequencing;cluster analysis;computation (action);dspace;hierarchical clustering;host media processing;largest;microbiome;parallel algorithm;parallel computing;pseudo brand of pseudoephedrine;scientific publication;sequence analysis;silo (dataset);time complexity;transcutaneous electric nerve stimulation;tree accumulation;statistical cluster	Yunpeng Cai;Wei Zheng;Jin Yao;Yujie Yang;Volker Mai;Qi Mao;Yijun Sun	2017		10.1371/journal.pcbi.1005518	correlation clustering;biology;ribosomal rna;bioinformatics;microbiome;theoretical computer science;sequence analysis;cure data clustering algorithm;sequence alignment;data mining;cluster analysis;single-linkage clustering;taxonomy;alignment-free sequence analysis	Comp.	-1.6166258612641795	-52.727262502491165	20310
01b9507688bafea6e8165f8c862664c22c6d63a3	lipophilicity in pk design: methyl, ethyl, futile	physicochemical properties;hydrogen bond;volume of distribution;p glycoprotein;molecular weight;calcium channel;distribution coefficient;plasma proteins	Lipophilicity, often expressed as distribution coefficients (log D) in octanol/water, is an important physicochemical parameter influencing processes such as oral absorption, brain uptake and various pharmacokinetic (PK) properties. Increasing log D values increases oral absorption, plasma protein binding and volume of distribution. However, more lipophilic compounds also become more vulnerable to P450 metabolism, leading to higher clearance. Molecular size and hydrogen bonding capacity are two other properties often considered as important for membrane permeation and pharmacokinetics. Interrelationships among these physicochemical properties are discussed. Increasing size (molecular weight) often gives higher potency, but inevitably also leads to either higher lipophilicity, and hence poorer dissolution/solubility, or to more hydrogen bonding capacity, which limits oral absorption. Differences in optimal properties between gastrointestinal absorption and uptake into the brain are addressed. Special attention is given to the desired lipophilicity of CNS drugs. In examples using beta-blockers, Ca channel antagonists and peptidic renin inhibitors we will demonstrate how potency and pharmacokinetic properties need to be balanced.		Han van de Waterbeemd;Dennis A. Smith;Barry C. Jones	2001	Journal of computer-aided molecular design	10.1023/A:1008192010023	partition coefficient;chromatography;stereochemistry;chemistry;blood proteins;volume of distribution;organic chemistry;hydrogen bond;calcium channel;molecular mass	Comp.	10.776876306544837	-63.38384799054679	20345
26e20cffcbc280b96a8e3db015d3f4f48b0ebcb2	sentra: a database of signal transduction proteins for comparative genome analysis	evolution molecular;phosphodiesterases;genomics;histidine kinase;response regulator;interaction analysis;phosphodiesterase;cyclases;comparative genomics;phosphatases;signal transduction;histidine;signal transduction pathway;automatic generation;internet;proteins;genome comparison;anl;archaeal proteins;user computer interface;basic biological sciences;protein phosphatase;protein kinase;phosphotransferases;intracellular signaling peptides and proteins;bacterial proteins;databases protein;principal component	Sentra (http://compbio.mcs.anl.gov/sentra), a database of signal transduction proteins encoded in completely sequenced prokaryotic genomes, has been updated to reflect recent advances in understanding signal transduction events on a whole-genome scale. Sentra consists of two principal components, a manually curated list of signal transduction proteins in 202 completely sequenced prokaryotic genomes and an automatically generated listing of predicted signaling proteins in 235 sequenced genomes that are awaiting manual curation. In addition to two-component histidine kinases and response regulators, the database now lists manually curated Ser/Thr/Tyr protein kinases and protein phosphatases, as well as adenylate and diguanylate cyclases and c-di-GMP phosphodiesterases, as defined in several recent reviews. All entries in Sentra are extensively annotated with relevant information from public databases (e.g. UniProt, KEGG, PDB and NCBI). Sentra's infrastructure was redesigned to support interactive cross-genome comparisons of signal transduction capabilities of prokaryotic organisms from a taxonomic and phenotypic perspective and in the framework of signal transduction pathways from KEGG. Sentra leverages the PUMA2 system to support interactive analysis and annotation of signal transduction proteins by the users.	adenylate;cell signaling;database;digital curation;gnu multiple precision arithmetic library;genome;kegg;national center for biotechnology information;organism;phosphoric monoester hydrolases;ploidies;protein data bank;protein phosphatase;reflow soldering;review [publication type];signal transduction pathways;threonine;transduction (machine learning);tyrosine;uniprot;comparative genomic analysis;phosphoric diester hydrolase	Mark D'Souza;Elizabeth M. Glass;Mustafa H. Syed;Yi Zhang;Alexis A. Rodriguez;Natalia Maltsev;Michael Y. Galperin	2007		10.1093/nar/gkl949	phosphodiesterase;biology;genomics;molecular biology;bioinformatics;phosphatase;genetics;signal transduction	Comp.	-0.554004148128931	-59.58795787880136	20354
f0ffe215020b0df153299a79efe403d96f6b175d	association rule mining to detect factors which contribute to heart disease in males and females	sick;association statistique;asintomatico;heart disease;female;factor riesgo;mujer;cleveland data;confiance;woman;risque eleve;heart;sex;risk factor;enfermedad;disease;cardiology;computational intelligence;asymptomatic;artere coronaire;database;male;base dato;statistical association;hombre;sexe;intelligence artificielle;electrocardiographie;data mining;pico;facteur risque;association rule mining;coeur;confidence;asociacion estadistica;electrocardiography;electrocardiografia;femme;confianza;fouille donnee;healthy;corazon;cardiologie;human;peak;pic;base de donnees;artificial intelligence;cardiologia;inteligencia artificial;riesgo alto;coronary artery;sexo;busca dato;asymptomatique;maladie;arteria coronaria;homme;high risk	This paper investigates the sick and healthy factors which contribute to heart disease for males and females. Association rule mining, a computational intelligence approach, is used to identify these factors and the UCI Cleveland dataset, a biological database, is considered along with the three rule generation algorithms - Apriori, Predictive Apriori and Tertius. Analyzing the information available on sick and healthy individuals and taking confidence as an indicator, females are seen to have less chance of coronary heart disease then males. Also, the attributes indicating healthy and sick conditions were identified. It is seen that factors such as chest pain being asymptomatic and the presence of exercise-induced angina indicate the likely existence of heart disease for both men and women. However, resting ECG being either normal or hyper and slope being flat are potential high risk factors for women only. For men, on the other hand, only a single rule expressing resting ECG being hyper was shown to be a significant factor. This means, for women, resting ECG status is a key distinct factor for heart disease prediction. Comparing the healthy status of men and women, slope being up, number of coloured vessels being zero, and oldpeak being less than or equal to 0.56 indicate a healthy status for both genders.	association rule learning	Jesmin Nahar;Tasadduq Imam;Kevin Tickle;Yi-Ping Phoebe Chen	2013	Expert Syst. Appl.	10.1016/j.eswa.2012.08.028	association;association rule learning;computer science;artificial intelligence;computational intelligence;sex;confidence;risk factor;heart	ML	8.595565454901072	-76.7294670211802	20377
890035591b1ebd1c2f59056cb81248414731f91f	a poor man’s blastx—high-throughput metagenomic protein database search using pauda	software;amino acid sequence;sequence analysis dna;metagenomics;algorithms;base sequence;databases protein	SUMMARY In the context of metagenomics, we introduce a new approach to protein database search called PAUDA, which runs ~10,000 times faster than BLASTX, while achieving about one-third of the assignment rate of reads to KEGG orthology groups, and producing gene and taxon abundance profiles that are highly correlated to those obtained with BLASTX. PAUDA requires <80 CPU hours to analyze a dataset of 246 million Illumina DNA reads from permafrost soil for which a previous BLASTX analysis (on a subset of 176 million reads) reportedly required 800,000 CPU hours, leading to the same clustering of samples by functional profiles.   AVAILABILITY PAUDA is freely available from: http://ab.inf.uni-tuebingen.de/software/pauda. Also supplementary method details are available from this website.	blast;cpu (central processing unit of computer system);central processing unit;cluster analysis;databases, protein;eighty;high-throughput computing;kegg;metagenomics;permafrost;poorman;reading (activity);sequence database;silo (dataset);subgroup;throughput;web site;statistical cluster	Daniel H. Huson;Chao Xie	2014		10.1093/bioinformatics/btt254	biology;bioinformatics;data mining;peptide sequence;genetics;metagenomics	Comp.	-0.23212801348099496	-55.99958578177253	20412
ceef66fde9f5e1f878cf36b765fcd31285111b15	extracting and exposing predictive cortical columns for selective attention	stimulus reliability;first order;generated input;cortical column;selective attention;correlation	We believe that the degree of importance of a particular stimulus is based on statistical and informational aspects of the environment rather than implicit processing constraints of the observer. Therefore we have designed an algorithm that finds important stimulus based on pairs of input and output for different tasks. An important stimulus shows first-order correlation with the output for the particular task. The problem is thus to separate the “correlations” for the different tasks. The algorithm is tested with two situations, one in which the task balance sensitivity is evaluated and another that tests a more complex setup.	column (database)	David Eriksson	2004	Neurocomputing	10.1016/j.neucom.2004.01.106	attention;computer science;machine learning;first-order logic;mathematics;correlation	ML	15.593567145995467	-75.73983609215234	20457
3a03a4c2b078f9167e54d3478ec027b3f002ebac	analysis of vehicle-following heterogeneity using self-organizing feature maps	health research;uk clinical guidelines;biological patents;europe pubmed central;citation search;uk phd theses thesis;life sciences;uk research reports;medical journals;europe pmc;biomedical research;bioinformatics	A self-organizing feature map (SOM) was used to represent vehicle-following and to analyze the heterogeneities in vehicle-following behavior. The SOM was constructed in such a way that the prototype vectors represented vehicle-following stimuli (the follower's velocity, relative velocity, and gap) while the output signals represented the response (the follower's acceleration). Vehicle trajectories collected at a northbound segment of Interstate 80 Freeway at Emeryville, CA, were used to train the SOM. The trajectory information of two selected pairs of passenger cars was then fed into the trained SOM to identify similar stimuli experienced by the followers. The observed responses, when the stimuli were classified by the SOM into the same category, were compared to discover the interdriver heterogeneity. The acceleration profile of another passenger car was analyzed in the same fashion to observe the interdriver heterogeneity. The distribution of responses derived from data sets of car-following-car and car-following-truck, respectively, was compared to ascertain inter-vehicle-type heterogeneity.	chimeric antigen receptor;classification;eighty;freeway;genetic heterogeneity;northbound interface;organizing (structure);prototype;self-organization;self-organizing map;semantic heterogeneity;velocity (software development)	Jie Yang;Ruey Long Cheu;Xiu-cheng Guo;Alicia Romo	2014		10.1155/2014/561036	psychology;medical research;simulation;medicine;computer science;bioinformatics;artificial intelligence;machine learning;data mining;operations research	ML	11.962947876417381	-70.51886171091286	20478
e3becb69832c5a4366438c74dff2fda2e93b5ff9	design, structure-based focusing and in silico screening of combinatorial library of peptidomimetic inhibitors of dengue virus ns2b-ns3 protease	qsar model;virtual library;score function;ns2b ns3 serine protease;amino acid;serine protease;enzyme;virtual library design;physico chemical properties;in silico screening;antiviral agent;peptidomimetic inhibitors;dengue fever;next generation;target specific scoring function;3d structure;dengue virus;in silico	Serine protease activity of the NS3 protein of Dengue virus is an important target of antiviral agents that interfere with the viral polyprotein precursor processing catalyzed by the NS3 protease (NS3pro), which is important for the viral replication and maturation. Recent studies showed that substrate-based peptidomimetics carrying an electrophilic warhead inhibit the NS2B-NS3pro cofactor-protease complex with inhibition constants in the low micromolar concentration range when basic amino acid residues occupy P(1) and P(2) positions of the inhibitor, and an aldehyde warhead is attached to the P(1). We have used computer-assisted combinatorial techniques to design, focus using the NS2B-NS3pro receptor 3D structure, and in silico screen a virtual library of more than 9,200 peptidomimetic analogs targeted around the template inhibitor Bz-Nle-Lys-Arg-Arg-H (Bz-benzoyl) that are composed mainly of unusual amino acid residues in all positions P(1)-P(4). The most promising virtual hits were analyzed in terms of computed enzyme-inhibitor interactions and Adsorption, Distribution, Metabolism and Excretion (ADME) related physico-chemical properties. Our study can direct the interest of medicinal chemists working on a next generation of antiviral chemotherapeutics against the Dengue Fever towards the explored subset of the chemical space that is predicted to contain peptide aldehydes with NS3pro inhibition potencies in nanomolar range which display ADME-related properties comparable to the training set inhibitors.	adme study;acetaldehyde;aldehydes;amino acids;amino acids, basic;analog;antiviral agents;bam 22p;biologic development;calpain;chemical space;clinical use template;combinatorial chemistry;dengue fever;dengue virus;digital library;endopeptidases;greater than;interaction;micromole/liter;next-generation network;subgroup;test set;virus replication;warhead;yellow fever;chemical cofactor;peptidase activity	Vladimir Frecer;Stanislav Miertus	2010	Journal of computer-aided molecular design	10.1007/s10822-010-9326-8	biology;biochemistry;enzyme;amino acid;chemistry;virology;dengue fever;combinatorial chemistry;score	Comp.	1.382455398505111	-61.42316715568205	20500
f84e41cf6ea32ca46dd8136094ef7e85b2814174	pathway analysis of microarray data via regression	microarray data;pathway analysis;gene clusters;gene expression;statistics	Pathway analysis of microarray data evaluates gene expression profiles of a priori defined biological pathways in association with a phenotype of interest. We propose a unified pathway-analysis method that can be used for diverse phenotypes including binary, multiclass, continuous, count, rate, and censored survival phenotypes. The proposed method also allows covariate adjustments and correlation in the phenotype variable that is encountered in longitudinal, cluster-sampled, and paired designs. These are accomplished by combining the regression-based test statistic for each individual gene in a pathway of interest into a pathway-level test statistic. Applications of the proposed method are illustrated with two real pathway-analysis examples: one evaluating relapse-associated gene expression involving a matched-pair binary phenotype in children with acute lymphoblastic leukemia; and the other investigating gene expression in breast cancer tissues in relation to patients' survival (a censored survival phenotype). Implementations for various phenotypes are available in R. Additionally, an Excel Add-in for a user-friendly interface is currently being developed.	body tissue;clinical trial censoring;gene expression;gene regulatory network;interface device component;mammary neoplasms;microarray;pathway analysis;patients;phenotype;precursor cell lymphoblastic leukemia lymphoma;usability;lymphoblast	Adeniyi J. Adewale;Irina Dinu;John D. Potter;Qi Liu;Yutaka Yasui	2008	Journal of computational biology : a journal of computational molecular cell biology	10.1089/cmb.2008.0002	biology;microarray analysis techniques;gene expression;bioinformatics;genetics;statistics	Comp.	5.667797590294235	-52.96526153764998	20542
e63e7fa9b23fb495bb131d1fbe39ae01e12976a5	diagnosis of airway obstruction or restrictive spirometric patterns by multiclass support vector machines	multiclass support vector machine svm;forced vital capacity;clinical decision making;spirometric patterns;airway obstruction;support vector machine;classification accuracy;error correcting output code	This paper presents the use of multiclass support vector machines (SVMs) for diagnosis of spirometric patterns (normal, restrictive, obstructive). The SVM decisions were fused using the error correcting output codes (ECOC). The multiclass SVM with the ECOC was trained on three spirometric parameters (forced expiratory volume in 1s—FEV1, forced vital capacity—FVC and FEV1/FVC ratio). The total classification accuracy of the SVM is 97.32%. The obtained results confirmed the validity of the SVMs to help in clinical decision-making.	airway obstruction;code;decision making;expiration, function;fingerprint verification competition;forced expiratory volume in 1 second to forced vital capacity ratio measurement;forced expiratory volume function;map;multiclass classification;pulmonary function test/forced expiratory volume 1;supernumerary maxillary right third molar;support vector machine	Deniz Sahin;Elif Derya Übeyli;Gul Ilbay;Murat Sahin;Alisan Burak Yasar	2009	Journal of Medical Systems	10.1007/s10916-009-9312-7	support vector machine;vital capacity;computer science;machine learning;pattern recognition;data mining	ML	7.587667131216547	-76.75107078506903	20566
0e61945bf2c6103b8afc9045e8143d5fcc0d2374	neuromodulation of reactive sensorimotor mappings as a short-term memory mechanism in delayed response tasks	neuronal activity;adaptive behavior;short term memory;control network;neural net;2;synaptic plasticity;higher order	This article addresses the relation between memory, representation, and adaptive behavior. More specifically, it demonstrates and discusses the use of synaptic plasticity, realized through neuromodulation of sensorimotor mappings, as a short-term memory mechanism in delayed response tasks. A number of experiments with extended sequential cascaded networks, that is, higher-order recurrent neural nets, controlling simple robotic agents in six different delayed response tasks are presented. The focus of the analysis is on how short-term memory is realized in such control networks through the dynamic modulation of sensorimotor mappings (rather than through feedback of neuronal activation, as in conventional recurrent nets), and how these internal dynamics interact with environmental/ behavioral dynamics. In particular, it is demonstrated in the analysis of the last experimental scenario how this type of network can make very selective use of feedback/memory, while as far as possible limiting itself to the use of reactive sensorimotor mechanisms and occasional switches between them.	adaptive behavior;artificial neural network;autonomous robot;experiment;feedback;maze generation algorithm;modulation;network switch;neural correlates of consciousness;neuromodulation (medicine);recurrent neural network;self-organization;software transactional memory;synaptic package manager;theory	Tom Ziemke;Mikael Thieme	2002	Adaptive Behaviour	10.1177/1059712302919993003	psychology;synaptic plasticity;cognitive psychology;control network;neuroscience;higher-order logic;computer science;artificial intelligence;adaptive behavior;machine learning;short-term memory;artificial neural network;premovement neuronal activity	ML	18.472906022717087	-69.24773999022955	20594
4c83c1c48a61c83db84f9f6c26e1441b54013774	spatio-temporal sequence learning of visual place cells for robotic navigation	spatio temporal sequence learning hierarchical memory architecture hubel and wiesel s model kflann;sequence recognition;short term memory mechanism;short term memory;hierarchical memory architecture;ventral stream;one shot learning mechanism;neural nets;path planning;long term memory cell;long term memory;spatio temporal sequence learning;robot navigation;ltm cell;k iteration fast learning neural network;sequence recognition visual place cell robotic navigation biologically inspired spatio temporal sequence learning autonomous navigation k iteration fast learning neural network kflann short term memory mechanism stm mechanism long term memory cell ltm cell one shot learning mechanism;sequence learning;iterative methods;computer architecture;navigation;visualization;adaptation model;memory architecture;feature extraction visualization computer architecture navigation neurons equations adaptation model;feature extraction;hubel and wiesel s model;place cell;robots;visual place cell;kflann;biologically inspired spatio temporal sequence learning;robots iterative methods learning artificial intelligence neural nets path planning;autonomous navigation;neurons;learning artificial intelligence;stm mechanism;robotic navigation;human brain;neural network	In this paper, we present a novel biologically-inspired spatio-temporal sequence learning architecture of visual place cells to leverage autonomous navigation. The construction of the place cells originates from the well-known architecture of Hubel and Wiesel to develop simple to complex features in ventral stream of the human brain. To characterize the contribution of each feature towards scene localization, we propose a novel significance analysis based on the activation profiles of features throughout the spatio-temporal domain. The K-iteration Fast Learning Neural Network (KFLANN) is then used as a Short-Term Memory (STM) mechanism to construct our sequence elements. Subsequently, each sequence is built and stored as a Long-Term Memory (LTM) cell via a one-shot learning mechanism. We also propose a novel algorithm for sequence recognition based on the LTM organization. The efficiency and efficacy of the architecture are evaluated with the vision dataset from ImageCLEF 2010 Competition.	algorithm;artificial neural network;autonomous robot;iteration;long short-term memory;one-shot learning;robotic mapping;software transactional memory;whole earth 'lectronic link	Vu Anh Nguyen;Janusz A. Starzyk;Alex Leng Phuan Tay;Wooi-Boon Goh	2010	The 2010 International Joint Conference on Neural Networks (IJCNN)	10.1109/IJCNN.2010.5596952	robot;computer vision;navigation;long-term memory;visualization;feature extraction;computer science;artificial intelligence;machine learning;short-term memory;motion planning;iterative method;artificial neural network	Vision	21.82131147242957	-54.75526736573671	20697
28ffe0dd4da19306d47dc26fd14e8563e516edc7	computation with spikes in a winner-take-all network	reseau recurrent;metodo estadistico;calcul neuronal;time varying;inhibicion;neural computation;haute performance;neurone impulsionnel;development;electronique;modelo markov;neurona pulsante;desarrollo;statistical method;excitacion;regular spiking;vainqueur prend tout;action;discriminant analysis;analyse discriminante;spike;analisis discriminante;markov model;spiking neurons;recurrent network;electronica;62h30;spiking neuron;methode statistique;developpement;electronics;alto rendimiento;regime permanent;regimen permanente;inhibition;modele markov;reseau neuronal;accion;action potential;winner take all;high performance;red neuronal;computacion neuronal;biological network;potentiel action;neural network;steady state;excitation	The winner-take-all (WTA) computation in networks of recurrently connected neurons is an important decision element of many models of cortical processing. However, analytical studies of the WTA performance in recurrent networks have generally addressed rate-based models. Very few have addressed networks of spiking neurons, which are relevant for understanding the biological networks themselves and also for the development of neuromorphic electronic neurons that commmunicate by action potential like address-events. Here, we make steps in that direction by using a simplified Markov model of the spiking network to examine analytically the ability of a spike-based WTA network to discriminate the statistics of inputs ranging from stationary regular to nonstationary Poisson events. Our work extends previous theoretical results showing that a WTA recurrent network receiving regular spike inputs can select the correct winner within one interspike interval. We show first for the case of spike rate inputs that input discrimination and the effects of self-excitation and inhibition on this discrimination are consistent with results obtained from the standard rate-based WTA models. We also extend this discrimination analysis of spiking WTAs to nonstationary inputs with time-varying spike rates resembling statistics of real-world sensory stimuli. We conclude that spiking WTAs are consistent with their continuous counterparts for steady-state inputs, but they also exhibit high discrimination performance with nonstationary inputs.	action potential;artificial neuron;cns disorder;central processing unit;computation (action);excitation;hysteresis;markov chain;markov model;microprocessor;network performance;neuromorphic engineering;recurrent neural network;spiking neural network;stationary process;steady state;switching time;weapon target assignment problem;winner-take-all (computing)	Matthias Oster;Rodney J. Douglas;Shih-Chii Liu	2009	Neural Computation	10.1162/neco.2009.07-08-829	winner-take-all;biological network;electronics;neuroscience;excitation;computer science;artificial intelligence;machine learning;markov model;linear discriminant analysis;steady state;action potential;artificial neural network;algorithm;models of neural computation	ML	20.704531105359457	-71.20706110980564	20708
7b1e6f60b07c1db35b390d511d343c3473137b7d	genome-wide analysis reveals novel molecular features of mouse recombination hotspots	transcription genetic;animals;genomics;mice;nucleotides;distributed consensus;genetic background;consensus sequence;meiosis;male;chromosome mapping;crossing over genetic;chromosome segregation;genetics;genetic marker;lysine;histones;methylation;nucleosomes;sister chromatid exchange;fine structure;genome;molecular sequence data;recombination genetic;dna breaks double stranded;testis;dna double strand breaks;genetic markers;organ specificity;mice inbred c57bl;chromosomes mammalian	Meiotic recombination predominantly occurs at discrete genomic loci called recombination hotspots, but the features defining these areas are still largely unknown (reviewed in refs 1–5). To allow a comprehensive analysis of hotspot-associated DNA and chromatin characteristics, we developed a direct molecular approach for mapping meiotic DNA double-strand breaks that initiate recombination. Here we present the genome-wide distribution of recombination initiation sites in the mouse genome. Hotspot centres are mapped with approximately 200-nucleotide precision, which allows analysis of the fine structural details of the preferred recombination sites. We determine that hotspots share a centrally distributed consensus motif, possess a nucleotide skew that changes polarity at the centres of hotspots and have an intrinsic preference to be occupied by a nucleosome. Furthermore, we find that the vast majority of recombination initiation sites in mouse males are associated with testis-specific trimethylation of lysine 4 on histone H3 that is distinct from histone H3 lysine 4 trimethylation marks associated with transcription. The recombination map presented here has been derived from a homogeneous mouse population with a defined genetic background and therefore lends itself to extensive future experimental exploration. We note that the mapping technique developed here does not depend on the availability of genetic markers and hence can be easily adapted to other species with complex genomes. Our findings uncover several fundamental features of mammalian recombination hotspots and underline the power of the new recombination map for future studies of genetic recombination, genome stability and evolution.	consensus (computer science);futures studies;genetic hotspot;genetic markers;genome;histone h3 lysine 4;histones;java hotspot virtual machine;mammals;meiotic recombination;motif;strand (programming language);transcription (software);transcription initiation;nucleosome location;polarity	Fatima Smagulova;Ivan V. Gregoretti;Kevin Brick;Pavel Khil;R. Daniel Camerini-Otero;Galina V. Petukhova	2011	Nature	10.1038/nature09869	biology;genomics;molecular biology;genetic marker;genetics	Comp.	4.293620714776074	-61.77444907873325	20713
79ead9639d4eae6a7b9261ee457ba7a54601db13	smarts: reconstructing disease response networks from multiple individuals using time series gene expression data		MOTIVATION Current methods for reconstructing dynamic regulatory networks are focused on modeling a single response network using model organisms or cell lines. Unlike these models or cell lines, humans differ in their background expression profiles due to age, genetics and life factors. In addition, there are often differences in start and end times for time series human data and in the rate of progress based on the specific individual. Thus, new methods are required to integrate time series data from multiple individuals when modeling and constructing disease response networks.   RESULTS We developed Scalable Models for the Analysis of Regulation from Time Series (SMARTS), a method integrating static and time series data from multiple individuals to reconstruct condition-specific response networks in an unsupervised way. Using probabilistic graphical models, SMARTS iterates between reconstructing different regulatory networks and assigning individuals to these networks, taking into account varying individual start times and response rates. These models can be used to group different sets of patients and to identify transcription factors that differentiate the observed responses between these groups. We applied SMARTS to analyze human response to influenza and mouse brain development. In both cases, it was able to greatly improve baseline groupings while identifying key relevant TFs that differ between the groups. Several of these groupings and TFs are known to regulate the relevant processes while others represent novel hypotheses regarding immune response and development.   AVAILABILITY AND IMPLEMENTATION Software and Supplementary information are available at http://sb.cs.cmu.edu/smarts/.   CONTACT zivbj@cs.cmu.edu   SUPPLEMENTARY INFORMATION Supplementary data are available at Bioinformatics online.		Aaron Wise;Ziv Bar-Joseph	2015	Bioinformatics	10.1093/bioinformatics/btu800	econometrics;computer science;bioinformatics;data mining;statistics	Comp.	4.7042057170235525	-58.63106446279546	20729
341329a12ded53caf8163284aab3ac523346eb8f	computational intelligence for metabolic pathway design: application to the pentose phosphate pathway	professor anil wipat;organisms;biological system modeling;james skelton;dr jennifer hallinan;eprints newcastle university;gold;open access;mathematical model;production;biochemistry;data models;sunny park	Metabolic engineering is increasingly being used for the production of industrial products such as pharmaceuticals and enzymes. These chemicals have traditionally been chemically synthesized, but the application of synthetic biology techniques to microbes facilitates faster, cheaper production. Modelling and the integration of existing data can help inform the design of synthetic pathways. We applied an evolutionary algorithm to a flux balance model of metabolism in the industrially important bacterium Bacillus subtilis. Our target metabolites are sedoheptulose-7-phosphate and riboflavin, components of the pentose phosphate pathway. The algorithm combines the results of the flux balance analysis with phylogenetic information derived from data warehouses, to predict several potential interventions to the metabolic network, mostly involving knockouts of genes related to the pathway.	computation;computational intelligence;evolutionary algorithm;flux balance analysis;gene regulatory network;phylogenetics;synthetic biology;synthetic intelligence	D. J. Skelton;Jennifer Hallinan;S. Park;Anil Wipat	2016	2016 IEEE Conference on Computational Intelligence in Bioinformatics and Computational Biology (CIBCB)	10.1109/CIBCB.2016.7758101	gold;biology;organism;data modeling;biochemistry;biotechnology;computer science;bioinformatics;mathematical model;genetics	Visualization	6.2318277180597335	-60.902451196558054	20747
105fcde13c21338e1159f45d53715c0630995eee	the karyotype ontology: a computational representation for human cytogenetic patterns	dr jennifer warrender;eprints newcastle university;open access;dr phillip lord	The karyotype ontology describes the human chromosome complement as determined cytogenetically, and is designed as an initial step toward the goal of replacing the current system which is based on semantically meaningful strings. This ontology uses a novel, semi-programmatic methodology based around the tawny library to construct many classes rapidly. Here, we describe our use case, methodology and the event-based approach that we use to represent karyotypes. The ontology is available at http://www.purl.org/ontolink/ karyotype/. The clojure code is available at http://code. google.com/p/karyotype-clj/.	clojure;google search;semiconductor industry	Jennifer D. Warrender;Phillip Lord	2013	CoRR		computer science;bioinformatics;artificial intelligence;algorithm	Comp.	-3.9289681455154906	-61.630701627922114	20755
407647ee360677564a511b491f5ff3930ad21f0f	construction of reliable protein-protein interaction networks using weighted sparse representation based classifier with pseudo substitution matrix representation features	protein sequence;weighted sparse representation;protein protein interaction networks;substitution matrix representation	Protein-protein interactions (PPIs) networks play an important role in most of biological processes. Although much effort has been devoted to using high-throughput biological technologies to identify PPIs of various kinds of organisms, the experimental methods are expensive, time-consuming, and tedious. Therefore, developing computational methods for predicting PPIs is of great significance in this postgenomic era. In recent years, the exponential increase of available protein sequence data leads to the urgent need for sequence-based prediction model. In this paper, we report a highly efficient method for constructing PPIs networks. The main improvements come from a novel protein sequence representation called pseudo-SMR, and from adopting weighted sparse representation based classifier (WSRC). When predicting the PPIs of Yeast, Human and H. pylori datasets, the 5-fold cross-validation accuracies performed by the proposed method achieve as high as 97.09%, 96.71% and 91.15% respectively, significantly better than previous methods. To further evaluate the performance of the proposed method, extensive experiments are performed to compare the proposed method with state-of-the-art Support Vector Machine (SVM) classifier. Promising results obtained show that the proposed method is feasible, robust and powerful. & 2016 Elsevier B.V. All rights reserved.	blosum;computation;computational model;cross-validation (statistics);experiment;feature extraction;high-throughput computing;interaction;machine learning;matrix representation;microelectronics and computer technology corporation;peptide sequence;protein structure prediction;robustness (computer science);shingled magnetic recording;sparse approximation;sparse matrix;substitution matrix;support vector machine;test set;throughput;time complexity	Yu-An Huang;Zhu-Hong You;Xiao Li;Xing Chen;Pengwei Hu;Shuai Li;Xin Luo	2016	Neurocomputing	10.1016/j.neucom.2016.08.063	computer science;bioinformatics;machine learning;protein sequencing;data mining	AI	9.744177899213817	-54.01670161134674	20757
fc510a012e0a96ed9bcd17059b560e471a6812f8	state of the art prediction of hiv-1 protease cleavage sites	bioinformatik berakningsbiologi;other medical sciences not elsewhere specified;ovrig annan medicin och halsovetenskap;bioinformatics computational biology	MOTIVATION Understanding the substrate specificity of human immunodeficiency virus (HIV)-1 protease is important when designing effective HIV-1 protease inhibitors. Furthermore, characterizing and predicting the cleavage profile of HIV-1 protease is essential to generate and test hypotheses of how HIV-1 affects proteins of the human host. Currently available tools for predicting cleavage by HIV-1 protease can be improved.   RESULTS The linear support vector machine with orthogonal encoding is shown to be the best predictor for HIV-1 protease cleavage. It is considerably better than current publicly available predictor services. It is also found that schemes using physicochemical properties do not improve over the standard orthogonal encoding scheme. Some issues with the currently available data are discussed.   AVAILABILITY AND IMPLEMENTATION The datasets used, which are the most important part, are available at the UCI Machine Learning Repository. The tools used are all standard and easily available.   CONTACT thorsteinn.rognvaldsson@hh.se.	endopeptidases;hiv;immunologic deficiency syndromes;kerrison predictor;line code;machine learning;sensitivity and specificity;support vector machine	Thorsteinn S. Rögnvaldsson;Liwen You;Daniel Garwicz	2015	Bioinformatics	10.1093/bioinformatics/btu810	biology;bioinformatics;artificial intelligence;data mining	Comp.	9.124182699130944	-55.71719259342246	20764
a52e444744684c5c48a89125ac4c068e74a4df47	a novel expert system for non-invasive liver iron overload estimation in thalassemic patients	patient monitoring biomedical mri liver mean square error methods medical expert systems medical image processing neural nets;liver;expert systems;neural nets;mri t2 assessment;osirix dicom viewer;iron;iron artificial neural networks liver magnetic resonance imaging expert systems neurons diseases;ann;experimental mean squared error results;osirix dicom viewer expert system noninvasive liver iron overload estimation thalassemic patients computational intelligence methods complex problem solving liver iron concentration classification ann l i o mo t method liver iron overload monitoring in thalassemia method mri t2 assessment experimental mean squared error results;complex problem solving;medical expert systems;osirix;artificial neural networks;liver iron overload monitoring in thalassemia method;thalassemic patients;mri t2;medical image processing;magnetic resonance imaging;mean square error methods;diseases;osirix liomot mri t2 iron liver thalassemia artificial neural network expert system;patient monitoring;noninvasive liver iron overload estimation;neurons;liomot;liver iron concentration classification;computational intelligence methods;l i o mo t method;artificial neural network;biomedical mri;thalassemia;expert system	Expert Systems can integrate logic based often on computational intelligence methods and they are used in complex problem solving. In this work an Expert System for classifying liver iron concentration in thalassemic patients is presented. In this work, an ANN is used to validate the output of the L.I.O.MO.T (Liver Iron Overload Monitoring in Thalassemia) method against the output of the state-of-the-art method based on MRI T2* assessment for liver iron concentration. The model has been validated with a dataset of 200 samples. The experimental Mean Squared Error results and Correlation show interesting performances. The proposed algorithm has been developed as a plug in for OsiriX Dicom Viewer.	algorithm;artificial neural network;computational intelligence;dicom;expert system;mean squared error;osirix;performance;problem solving	Alfonso Farruggia;Luca Agnello;Patrizia Toia;Elena Murmura;Maria Russo;Emanuele Grassedonio;Massimo Midiri;Salvatore Vitabile	2014	2014 Eighth International Conference on Complex, Intelligent and Software Intensive Systems	10.1109/CISIS.2014.16	pathology;engineering;artificial intelligence;biological engineering	Robotics	3.8710484119657886	-79.40705329560355	20868
2480e76191fd13846aca27ea70ad26ae9b2c1b35	dimensionality and dynamics in the behavior of c. elegans	lasers;animals;caenorhabditis elegans;model system;real time;gait;models biological;covariance;locomotion;animal behavior;behavior animal;eigenvalues;equations of motion;equation of motion;motor behavior;behavior;computer simulation;crawling	"""A major challenge in analyzing animal behavior is to discover some underlying simplicity in complex motor actions. Here, we show that the space of shapes adopted by the nematode Caenorhabditis elegans is low dimensional, with just four dimensions accounting for 95% of the shape variance. These dimensions provide a quantitative description of worm behavior, and we partially reconstruct """"equations of motion"""" for the dynamics in this space. These dynamics have multiple attractors, and we find that the worm visits these in a rapid and almost completely deterministic response to weak thermal stimuli. Stimulus-dependent correlations among the different modes suggest that one can generate more reliable behaviors by synchronizing stimuli to the state of the worm in shape space. We confirm this prediction, effectively """"steering"""" the worm in real time."""	abnormal behavior;behavior, animal;dimensions;entity name part qualifier - adopted;phylum nematoda;rbfox2 gene;real-time computing;sample variance;synchronizing word	Greg J. Stephens;Bethany Johnson-Kerner;William Bialek;William S. Ryu	2008	PLoS Computational Biology	10.1371/journal.pcbi.1000028	computer simulation;biology;computer vision;simulation;equations of motion	ML	8.963427361481783	-64.7397357060544	20877
030217f5495906f80e2d9e0dead594942a3b80d2	a clinical decision support platform for the risk stratification, diagnosis, and prediction of coronary artery disease evolution		SMARTool aims to perform accurate risk stratification of coronary artery disease patients as well as to provide early diagnosis and prediction of disease progression. This is achieved by the acquisition of data from about 263 patients including computed tomography angiographic images, clinical, molecular, biohumoral, exposome, inflammatory and omics data. Data are collected in two time points with a followup period of approximately 5 years. In the first step, data mining techniques are implemented for the estimation of risk stratification. In the next step, patients, who are classified as medium to high risk are considered for coronary imaging and computational modelling of blood flow, plaque growth and stenosis severity assessment. Additionally, patients with increased stenosis are selected for stent deployment. All the above modules are integrated in a cloud-based platform for the clinical decision support (CDSS) of patients with coronary artery disease. The work presents preliminary results employing the SMARTool dataset as well as the concept and architecture of the under development platform.	arteriopathic disease;biological evolution;ct scan;classification;clinical decision support system;cloud computing;color gradient;coronary artery disease;data mining;decision support systems, clinical;deploy;early diagnosis;omics;paget's disease, mammary;patients;progressive disease;senile plaques;silo (dataset);stenosis;stent device component;stratification;x-ray computed tomography	Antonis I. Sakellarios;Panagiotis K. Siogkas;Eleni I. Georga;Nikolaos S. Tachos;Vassiliki I. Kigka;Panagiota Tsompou;Ioannis O. Andrikos;Georgia S. Karanasiou;Silvia Rocchiccioli;Joao Correia;Gualtiero Pelosi;Paolo Stofella;Nenad Filipovic;Oberdan Parodi;Dimitrios I. Fotiadis	2018	2018 40th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)	10.1109/EMBC.2018.8513131	stent;coronary artery disease;stenosis;computer vision;exposome;clinical decision support system;decision support system;architecture;radiology;disease;artificial intelligence;computer science	ML	6.682937573857024	-76.70639432704448	20939
f40f973806c4c0894a8810ebdbd4766aa863576a	identification of human drug targets using machine-learning algorithms	smote;ensemble learning;property group composition;relieff;drug targets;dipeptide composition	Identification of potential drug targets is a crucial task in the drug-discovery pipeline. Successful identification of candidate drug targets in entire genomes is very useful, and computational prediction methods can speed up this process. In the current work we have developed a sequence-based prediction method for the successful identification and discrimination of human drug target proteins, from human non-drug target proteins. The training features include sequence-based features, such as amino acid composition, amino acid property group composition, and dipeptide composition for generating predictive models. The classification of human drug target proteins presents a classic example of class imbalance. We have addressed this issue by using SMOTE (Synthetic Minority Over-sampling Technique) as a preprocessing step, for balancing the training data with a ratio of 1:1 between drug targets (minority samples) and non-drug targets (majority samples). Using ensemble classification learning method-Rotation Forest and ReliefF feature-selection technique for selecting the optimal subset of salient features, the best model with selected features can achieve 87.1% sensitivity, 83.6% specificity, and 85.3% accuracy, with 0.71 Matthews correlation coefficient (mcc) on a tenfold stratified cross-validation test. The subset of identified optimal features may help in assessing the compositional patterns in human drug targets. For further validation, using a rigorous leave-one-out cross-validation test, the model achieved 88.1% sensitivity, 83.0% specificity, 85.5% accuracy, and 0.712 mcc. The proposed method was tested on a second dataset, for which the current pipeline gave promising results. We suggest that the present approach can be applied successfully as a complementary tool to existing methods for novel drug target prediction.		Priyanka Kumari;Abhigyan Nath;Radha Chaube	2015	Computers in biology and medicine	10.1016/j.compbiomed.2014.11.008	computer science;bioinformatics;machine learning;data mining;ensemble learning	ML	9.570003784812751	-55.01338752500206	20977
0c7f4cfc718ec142bb7f3e60072a693d5ad0a474	dna-templated synthesis optimization	dna-templated synthesis;optimization;trees;graphs;cheminformatics;68;92;68w40;92e10	In chemistry, synthesis is the process in which a target compound is produced in a step-wise manner from given base compounds. A recent, promising approach for carrying out these reactions is DNAtemplated synthesis, since, as opposed to more traditional methods, this approach leads to a much higher effective molarity and makes much desired one-pot synthesis possible. With this method, compounds are tagged with DNA sequences and reactions can be controlled by bringing two compounds together via their tags. This leads to new cost optimization problems of minimizing the number of different tags or strands to be used under various conditions. We identify relevant optimization criteria, provide the first computational approach to automatically inferring DNA-templated programs, and obtain optimal and near-optimal results.	mathematical optimization;speech synthesis	Bjarke N. Hansen;Kim S. Larsen;Daniel Merkle;Alexei Mihalchuk	2017		10.1007/978-3-319-66799-7_2	dna;cheminformatics;combinatorial chemistry;effective molarity;optimization problem;graph	Logic	13.229682315935094	-61.89496560989428	20989
6ea1e0caf616b997e55f5dab4313fb8c5bf2ef68	analysis on relationship between extreme pathways and correlated reaction sets	animals;escherichia coli;red blood cell;regulatory network;saccharomyces cerevisiae;metabolic networks and pathways;metabolic network;random sampling;computational biology bioinformatics;metabolic networks;large scale;correlated reaction sets;genome;extreme pathways;algorithms;humans;combinatorial libraries;constraint based modelling;computational biology;phenotype;constraint based modeling;computer appl in life sciences;erythrocytes;energy metabolism;microarrays;bioinformatics	Constraint-based modeling of reconstructed genome-scale metabolic networks has been successfully applied on several microorganisms. In constraint-based modeling, in order to characterize all allowable phenotypes, network-based pathways, such as extreme pathways and elementary flux modes, are defined. However, as the scale of metabolic network rises, the number of extreme pathways and elementary flux modes increases exponentially. Uniform random sampling solves this problem to some extent to study the contents of the available phenotypes. After uniform random sampling, correlated reaction sets can be identified by the dependencies between reactions derived from sample phenotypes. In this paper, we study the relationship between extreme pathways and correlated reaction sets. Correlated reaction sets are identified for E. coli core, red blood cell and Saccharomyces cerevisiae metabolic networks respectively. All extreme pathways are enumerated for the former two metabolic networks. As for Saccharomyces cerevisiae metabolic network, because of the large scale, we get a set of extreme pathways by sampling the whole extreme pathway space. In most cases, an extreme pathway covers a correlated reaction set in an 'all or none' manner, which means either all reactions in a correlated reaction set or none is used by some extreme pathway. In rare cases, besides the 'all or none' manner, a correlated reaction set may be fully covered by combination of a few extreme pathways with related function, which may bring redundancy and flexibility to improve the survivability of a cell. In a word, extreme pathways show strong complementary relationship on usage of reactions in the same correlated reaction set. Both extreme pathways and correlated reaction sets are derived from the topology information of metabolic networks. The strong relationship between correlated reaction sets and extreme pathways suggests a possible mechanism: as a controllable unit, an extreme pathway is regulated by its corresponding correlated reaction sets, and a correlated reaction set is further regulated by the organism's regulatory network.	anatomy, regional;blood cells;erythrocytes;flux qubit;gene regulatory network;microorganism;monte carlo method;phenotype;regenerative circuit;sampling (signal processing);sampling - surgical action;contents - htmllinktype	Yanping Xi;Yi-Ping Phoebe Chen;Ming Cao;Weirong Wang;Fei Wang	2009	BMC Bioinformatics	10.1186/1471-2105-10-S1-S58	biology;sampling;dna microarray;bioinformatics;phenotype;escherichia coli;genetics;metabolic network;genome	ML	5.10188522689144	-59.31981564254514	20996
d931ad2303e13adcbee800a37b7f665a5067451e	a spectral graphical model approach for learning brain connectivity network of children's narrative comprehension	narrative comprehension;brain development;functional magnetic resonance imaging;female;neural pathways;brain;learning;adolescent;narration;child preschool;male;bayes theorem;spectral density matrix;bayesian model averaging;graphical models;brain mapping;acoustic stimulation;magnetic resonance imaging;child;nerve net;humans;neural networks computer;comprehension	Narrative comprehension is a fundamental cognitive skill that involves the coordination of different functional brain regions. We develop a spectral graphical model with model averaging to study the connectivity networks underlying these brain regions using fMRI data collected from a story comprehension task. Based on the spectral density matrices in the frequency domain, this model captures the temporal dependency of the entire fMRI time series between brain regions. A Bayesian model averaging procedure is then applied to select the best directional links that constitute the brain network. Using this model, brain networks of three distinct age groups are constructed to assess the dynamic change of network connectivity with respect to age.	density matrix;ensemble learning;graphical model;list comprehension;program comprehension;spectral density;time series;emotional dependency;fmri	Xiaodong Lin;Xiangxiang Meng;Prasanna Karunanayaka;Scott Holland	2011	Brain connectivity	10.1089/brain.2011.0045	psychology;developmental psychology;artificial intelligence;communication	ML	21.384270922919587	-77.1532342683894	21005
a9756dc40a82082c3de83fe25996f54671826a94	misa-web: a web server for microsatellite prediction		Motivation Microsatellites are a widely-used marker system in plant genetics and forensics. The development of reliable microsatellite markers from resequencing data is challenging.   Results We extended MISA, a computational tool assisting the development of microsatellite markers, and reimplemented it as a web-based application. We improved compound microsatellite detection and added the possibility to display and export MISA results in GFF3 format for downstream analysis.   Availability and Implementation MISA-web can be accessed under http://misaweb.ipk-gatersleben.de/. The website provides tutorials, usage note as well as download links to the source code.   Contact scholz@ipk-gatersleben.de.	computer forensics;dna resequencing;download;downstream (software development);forensic medicine;general feature format;plant genetics;server (computer);server (computing);short tandem repeat;source code;web site;web application;web server	Sebastian Beier;Thomas Thiel;Thomas A Münch;Uwe Scholz;Martin Mascher	2017		10.1093/bioinformatics/btx198	computer science;web server;world wide web;microsatellite	Comp.	-3.3674278511892424	-59.31081543188504	21046
a38d41ac6c09de85f2b6ad2883b4955adc56718a	succfind: a novel succinylation sites online prediction tool via enhanced characteristic strategy	software;lysine;proteins;protein processing post translational;期刊论文;proteomics;succinates;sequence analysis protein	UNLABELLED Lysine succinylation orchestrates a variety of biological processes. Annotation of succinylation in proteomes is the first-crucial step to decipher physiological roles of succinylation implicated in the pathological processes. In this work, we developed a novel succinylation site online prediction tool, called SuccFind, which is constructed to predict the lysine succinylation sites based on two major categories of characteristics: sequence-derived features and evolutionary-derived information of sequence and via an enhanced feature strategy for further optimizations. The assessment results obtained from cross-validation suggest that SuccFind can provide more instructive guidance for further experimental investigation of protein succinylation.   AVAILABILITY AND IMPLEMENTATION A user-friendly server is freely available on the web at: http://bioinfo.ncu.edu.cn/SuccFind.aspx.   CONTACT jdqiu@ncu.edu.cn.   SUPPLEMENTARY INFORMATION Supplementary data are available at Bioinformatics online.	bioinformatics;biological processes;categories;cross reactions;cross-validation (statistics);decipher prostate cancer test;lysine;pathologic processes;proteome;server (computer);server (computing);synapomorphy;usability	Hao-Dong Xu;Shao-Ping Shi;Ping-Ping Wen;Jianding Qiu	2015	Bioinformatics	10.1093/bioinformatics/btv439	biology;biochemistry;fox proteins;molecular biology;bioinformatics;proteomics	Comp.	8.832376194889804	-56.51274118197222	21051
e2a0a77b9deadf3fc53fb4632ea74d2f2f1d17ea	task relevance enhances early transient and late slow-wave activity of distributed cortical sources	occipital cortex;visual working memory;working memory;visual cortex;slow wave	The primary purpose of these studies was to link together concepts related to attention/working memory and feedforward/feedback activity using MEG response profiles obtained in humans. Similar to recent studies of attention in monkeys, we show early “spike-like” activity (<200 ms poststimulus), most likely reflecting an early transient excitatory response mixed with feedback influences, followed by “slow-wave” activity (>200 ms poststimulus) in MEG cortical response profiles evoked by a visual working memory task. We experimentally dissociated the early transient activity from the later sustained activity (predominately feedback) by conducting an auditory size classification task. Words, representing common objects, evoked activity in occipital cortex (presumably due to imagery) even though visual stimuli were not present in this task. The initial “spike” was absent from the response profile obtained from occipital cortex, leaving only “slow-wave” activity, thereby allowing us to characterize or profile feedback activity in this situation. Attention or task relevance enhanced the initial “spike” and “slow-wave” activity in visually responsive areas. Prefrontal activity, along the superior frontal sulcus, evoked by the working memory task, was active later in time than initial activity in visual cortex and later than the earliest effect of attention modulation in visual cortex.	acoustic lobing;behavior;bottom-up parsing;cerebral cortex;complement system proteins;cross-correlation;departure - action;experiment;feedforward neural network;frontal sulcus;groove;guided imagery;information processing;magnetoencephalography;medial graph;memory disorders;modulation;monkeys;neuroimaging;physical object;propylene glycol;relevance;temporal lobe;top-down and bottom-up design	Cheryl J. Aine;Julia M. Stephen;R. Christner;David Hudson;Elaine Best	2003	Journal of Computational Neuroscience	10.1023/A:1025864825200	psychology;cognitive psychology;interference theory;neuroscience;developmental psychology;p200;visual memory;working memory;communication	ML	17.4643666929379	-75.84739960102482	21077
86f77e86b7b523373c886415d050fdb855ecbb8c	identification and marking of molecular surface feature regions based on spherical mapping	molecular biophysics biology computing;concave region molecular surface feature region identification molecular surface feature region marking spherical mapping molecular interactions molecular surfaces convex regions 1 1 mapping expansion distance feature regions spherical surface features comparison;feature regions;force;surface treatment;surface treatment proteins surface cracks force shape vectors;proteins;shape;spherical mapping molecular surface feature regions;vectors;spherical mapping;molecular surface;surface cracks	Most of molecular interactions often occur in feature regions of molecular surfaces such as convex regions, cavities or pockets. In this paper we propose a method to identify these feature regions by expanding the molecular surface to its surrounding spherical surface, that is, a 1-1 mapping is established between them. According to the expansion distance, feature regions can be determined to be concave or convex and marked with different colors on the spherical surface. The method brings convenience to features comparison and analysis between different molecular surfaces. The experimental results show that this method works well on identifying the concave and convex regions of molecular surfaces.	accessible surface area;color;concave function;docking (molecular);graph coloring;interaction;item unique identification;simulation	Jingqiao Zhang;Zhe Shi;Meiling Zhang	2014	2014 IEEE 17th International Conference on Computational Science and Engineering	10.1109/CSE.2014.60	computer vision;topology;shape;mathematics;geometry;force	Visualization	15.149086743179486	-61.39480401326585	21080
dc53cfffe4785edb14fa7a2d489e52cc1c671ff1	role of distinct parietal areas in arithmetic: an fmri-guided tms study	institutional repositories;magnitude;fedora;retrieval;calculation;vital;intraparietal sulcus;transcranial magnetic stimulation;superior parietal lobule;functional magnetic resonance images;semantic;error rate;language;vtls;memory retrieval;ils;procedure	Although several parietal areas are known to be involved in number processing, their possible role in arithmetic operations remains debated. It has been hypothesized that the horizontal segment of the intraparietal sulcus (hIPS) and the posterior superior parietal lobule (PSPL) contribute to operations solved by calculation procedures, such as subtraction, but whether these areas are also involved in operations solved by memory retrieval, such as multiplication, is controversial. In the present study, we first identified the parietal areas involved in subtraction and multiplication by means of functional magnetic resonance imaging (fMRI) and we found an increased activation, bilaterally, in the hIPS and PSPL during both arithmetic operations. In order to test whether these areas are causally involved in subtraction and multiplication, we used transcranial magnetic stimulation (TMS) to create, in each participant, a virtual lesion of either the hIPS or PSPL, over the sites corresponding to the peaks of activation gathered in fMRI. When compared to a control site, we found an increase in response latencies in both operations after a virtual lesion of either the left or right hIPS, but not of the PSPL. Moreover, TMS over the hIPS increased the error rate in the multiplication task. The present results indicate that even operations solved by memory retrieval, such as multiplication, rely on the hIPS. In contrast, the PSPL seems to underlie processes that are nonessential to solve basic subtraction and multiplication problems.	groove;hl7publishingsubsection <operations>;lobule;magnetic resonance imaging;multiplication;parietal lobe;structure of intraparietal sulcus;transcranial magnetic stimulation;fmri	Michael Andres;Barbara Pelgrims;Nicolas Michaux;Etienne Olivier;Mauro Pesenti	2011	NeuroImage	10.1016/j.neuroimage.2010.11.009	psychology;procedure;computer vision;calculation;word error rate;artificial intelligence;magnitude;language;communication	Security	17.80926090636434	-77.60618496801418	21086
0fea35d84f0af69c8825570051b8a6a187fce895	composite similarity measure algorithm	computers;market research;time measurement;data mining;time series analysis;transforms;mathematical model	Representation of time series and similarity measure are the basis of time series data mining, but the common method of similarity measure isnt considering the morphology features, or isnt considering it at all, or is considering one of morphology and statistical feature. Aiming at this problem, proposing the composite representation of Symbolic Aggregate approximation (SAX) and bending value of angular point that represents time series. SAX, as the most commonly representation method of statistical feature, can accurately reflect the average of sequences, and the bending value of angular point, that is a better robustness method, can precisely represent the trend change of sequences. It can mirror the general information of sequences and make sequence simply by combining the two methods. At the same time, applying the composite distance algorithm has highly quality to measuring the similarity, that can more effectively show the difference in the between of sequences and meet the demand of similarity measure. Experimental results show that is not only simply and highly accuracy and better robustness, but also obtain good result of the similarity measure.	aggregate function;angularjs;approximation;cluster analysis;data mining;entropy (information theory);genetic algorithm;mathematical morphology;numerical analysis;similarity measure;time complexity;time series	Yan Wang;Yunjie An	2016	2016 12th International Conference on Natural Computation, Fuzzy Systems and Knowledge Discovery (ICNC-FSKD)	10.1109/FSKD.2016.7603358	market research;machine learning;time series;mathematical model;data mining;mathematics;statistics;time	DB	19.09468767564237	-60.76044580215912	21111
8cec289ce2b06ed08c649925f24c9a801b2e0984	anticipating conflict facilitates controlled stimulus-response selection	female;conflict detection;cues;middle aged;male;response selection;attention;control network;temporal resolution;time factors;brain mapping;adult;cognitive control;conflict psychology;analysis of variance;evoked potentials visual;visual perception;humans;conflict monitoring;photic stimulation;young adult;electroencephalography;choice behavior;conflict resolution;reaction time	Cognitive control can be triggered in reaction to previous conflict, as suggested by the finding of sequential effects in conflict tasks. Can control also be triggered proactively by presenting cues predicting conflict (“proactive control”)? We exploited the high temporal resolution of ERPs and controlled for sequential effects to ask whether proactive control based on anticipating conflict modulates neural activity related to cognitive control, as may be predicted from the conflict-monitoring model. ERPs associated with conflict detection (N2) were measured during a cued flanker task. Symbolic cues were either informative or neutral with respect to whether the target involved conflicting or congruent responses. Sequential effects were controlled by analyzing the congruency of the previous trial. The results showed that cueing conflict facilitated conflict resolution and reduced the N2 latency. Other potentials (frontal N1 and P3) were also modulated by cueing conflict. Cueing effects were most evident after congruent than after incongruent trials. This interaction between cueing and sequential effects suggests neural overlap between the control networks triggered by proactive and reactive signals. This finding clarifies why previous neuroimaging studies, in which reactive sequential effects were not controlled, have rarely found anticipatory effects upon conflict-related activity. Finally, the high temporal resolution of ERPs was critical to reveal a temporal modulation of conflict detection by proactive control. This novel finding suggests that anticipating conflict speeds up conflict detection and resolution. Recent research suggests that this anticipatory mechanism may be mediated by preactivation of ACC during the preparatory interval.	conflict (psychology);file synchronization;genetic selection;influenza virus a n2 ab:prthr:pt:ser:ord;information;modulation;neuroimaging;resolution (logic)	Ángel Correa;Anling Rao;Anna Christina Nobre	2009	Journal of Cognitive Neuroscience	10.1162/jocn.2009.21136	psychology;control network;mental chronometry;neuroscience;developmental psychology;attention;analysis of variance;young adult;electroencephalography;visual perception;temporal resolution;conflict resolution;brain mapping;communication;social psychology	HCI	16.598890376830536	-77.58608011137339	21112
406dfda4ec5f7daf022794a49787e7c2ce384c5c	intelligent perioperative system: towards real-time big data analytics in surgery risk assessment	big data analysis;perioprative risk prediction;precision medicine;real-time processing	Surgery risk assessment is an effective tool for physicians to manage the treatment of patients, but most current research projects fall short in providing a comprehensive platform to evaluate the patients' surgery risk in terms of different complications. The recent evolution of big data analysis techniques makes it possible to develop a real-time platform to dynamically analyze the surgery risk from large-scale patients information. In this paper, we propose the Intelligent Perioperative System (IPS), a real-time system that assesses the risk of postoperative complications (PC) and dynamically interacts with physicians to improve the predictive results. In order to process large volume patients data in real-time, we design the system by integrating several big data computing and storage frameworks with the high through-output streaming data processing components. We also implement a system prototype along with the visualization results to show the feasibility of system design.	big data;cns disorder;computation (action);computer multitasking;financial risk modeling;imagery;numerous;patients;postoperative complications;programming paradigm;prototype;real-time clock;real-time computing;real-time transcription;risk assessment;stream (computing);streaming media;systems design;funding grant;research grants	Zheng Feng;Rajendra Rana Bhat;Xiaoyong Yuan;Daniel Freeman;Tezcan Baslanti;Azra Bihorac;Xiaolin Li	2017	2017 IEEE 15th Intl Conf on Dependable, Autonomic and Secure Computing, 15th Intl Conf on Pervasive Intelligence and Computing, 3rd Intl Conf on Big Data Intelligence and Computing and Cyber Science and Technology Congress(DASC/PiCom/DataCom/CyberSciTech)	10.1109/DASC-PICom-DataCom-CyberSciTec.2017.201	data modeling;visualization;big data;systems design;surgery;streaming data;risk assessment;perioperative;engineering	Robotics	5.820094416439547	-78.9610175644407	21234
9443ae685a8c183b2c16dc9325d08b76e581233c	beyond nodes and edges: multiresolution algorithms for network data		Networks are a fundamental tool for understanding and modeling complex systems in physics, biology, neuroscience, engineering, and social science. Many networks are known to exhibit rich, lower-order connectivity patterns that can be captured at the level of individual nodes and edges. However, higher-order organization of complex networks -- at the level of small network subgraphs -- remains largely unknown. Here, we develop a generalized framework for clustering networks on the basis of higher-order connectivity patterns. This framework provides mathematical guarantees on the optimality of obtained clusters and scales to networks with billions of edges. The framework reveals higher-order organization in a number of networks, including information propagation units in neuronal networks and hub structure in transportation networks. Results show that networks exhibit rich higher-order organizational structures that are exposed by clustering based on higher-order connectivity patterns.  Prediction tasks over nodes and edges in networks require careful effort in engineering features used by learning algorithms. Recent research in the broader field of representation learning has led to significant progress in automating prediction by learning the features themselves. However, present feature learning approaches are not expressive enough to capture the diversity of connectivity patterns observed in networks. Here we propose node2vec, an algorithmic framework for learning continuous feature representations for nodes in networks. In node2vec, we learn a mapping of nodes to a low-dimensional space of features that maximizes the likelihood of preserving network neighborhoods of nodes. We define a flexible notion of a node's network neighborhood and design a biased random walk procedure, which efficiently explores diverse neighborhoods. Our algorithm generalizes prior work which is based on rigid notions of network neighborhoods, and we argue that the added flexibility in exploring neighborhoods is the key to learning richer representations. We demonstrate the efficacy of node2vec over existing state-of-the-art techniques on multi-label classification and link prediction in several real-world networks from diverse domains. Taken together, our work represents a new way for efficiently learning state-of-the-art task-independent representations in complex networks.	algorithm;cluster analysis;complex network;complex systems;feature learning;multiclass classification;multiresolution analysis;software propagation;usb hub	Jure Leskovec	2016		10.1145/2980523.2980525	evolving networks;computer science;artificial intelligence;network motif;machine learning;hierarchical network model;data mining;spatial network;interdependent networks;complex network;series-parallel networks problem	ML	23.165730149111322	-75.03295689056205	21256
253ff4ca7808b6dd6ee90e909b6533c4a2ac635c	a hybrid generative and predictive model of the motor cortex	basal ganglia;unsupervised learning;prediccion;mental simulation;basal ganglion;mirror neuron;generic model;supervised learning;forward model;reinforcement learning;modelo hibrido;apprentissage non supervise;modele hybride;corteza motora;hybrid model;motor cortex;apprentissage renforce;nucleo basal;ecuacion helmholtz;noyau gris central;cortex moteur;helmholtz equation;equation helmholtz;prediction model;apprentissage supervise;continuous attractor network;reseau neuronal;perception and action;aprendizaje reforzado;aprendizaje supervisado;prediction;red neuronal;neural network;helmholtz machine	We describe a hybrid generative and predictive model of the motor cortex. The generative model is related to the hierarchically directed cortico-cortical (or thalamo-cortical) connections and unsupervised training leads to a topographic and sparse hidden representation of its sensory and motor input. The predictive model is related to lateral intra-area and inter-area cortical connections, functions as a hetero-associator attractor network and is trained to predict the future state of the network. Applying partial input, the generative model can map sensory input to motor actions and can thereby perform learnt action sequences of the agent within the environment. The predictive model can additionally predict a longer perception- and action sequence (mental simulation). The models' performance is demonstrated on a visually guided robot docking manoeuvre. We propose that the motor cortex might take over functions previously learnt by reinforcement in the basal ganglia and relate this to mirror neurons and imitation.	basal (phylogenetics);basal ganglia;boat dock;cerebral cortex;docking (molecular);generative model;lateral thinking;mirror neurons;predictive modelling;robot;simulation;sparse matrix;topography;unsupervised learning;primary motor cortex	Cornelius Weber;Stefan Wermter;Mark Elshaw	2006	Neural networks : the official journal of the International Neural Network Society	10.1016/j.neunet.2005.10.004	unsupervised learning;prediction;computer science;artificial intelligence;machine learning;predictive modelling;helmholtz equation;supervised learning;mirror neuron;reinforcement learning;artificial neural network	ML	20.841752109755298	-69.54701279056756	21287
07053a3ae71bbf5b7946bc361602fa863fcffbd5	measuring integrated information from the decoding perspective	animals;models neurological;normal distribution;theories of consciousness;covariance;plos computational biology;probability distribution;consciousness;electrocorticography;macaca;linear regression analysis;cerebral cortex;entropy;monkeys;computational biology;information theory	Accumulating evidence indicates that the capacity to integrate information in the brain is a prerequisite for consciousness. Integrated Information Theory (IIT) of consciousness provides a mathematical approach to quantifying the information integrated in a system, called integrated information, Φ. Integrated information is defined theoretically as the amount of information a system generates as a whole, above and beyond the amount of information its parts independently generate. IIT predicts that the amount of integrated information in the brain should reflect levels of consciousness. Empirical evaluation of this theory requires computing integrated information from neural data acquired from experiments, although difficulties with using the original measure Φ precludes such computations. Although some practical measures have been previously proposed, we found that these measures fail to satisfy the theoretical requirements as a measure of integrated information. Measures of integrated information should satisfy the lower and upper bounds as follows: The lower bound of integrated information should be 0 and is equal to 0 when the system does not generate information (no information) or when the system comprises independent parts (no integration). The upper bound of integrated information is the amount of information generated by the whole system. Here we derive the novel practical measure Φ* by introducing a concept of mismatched decoding developed from information theory. We show that Φ* is properly bounded from below and above, as required, as a measure of integrated information. We derive the analytical expression of Φ* under the Gaussian assumption, which makes it readily applicable to experimental data. Our novel measure Φ* can generally be used as a measure of integrated information in research on consciousness, and also as a tool for network analysis on diverse areas of biology.	computation (action);consciousness;experiment;integrated information theory;mathematics;network theory;normal statistical distribution;part dosing unit;requirement;space: above and beyond	Masafumi Oizumi;Shun-ichi Amari;Toru Yanagawa;Naotaka Fujii;Naotsugu Tsuchiya	2016		10.1371/journal.pcbi.1004654	normal distribution;probability distribution;variation of information;information algebra;entropy;electromagnetic theories of consciousness;information processing;information theory;computer science;bioinformatics;linear regression;artificial intelligence;theoretical computer science;covariance;consciousness;interaction information;statistics	ML	22.558172189347015	-72.29136876439597	21353
9383a51672e3f18294731ad639fc6550863d1877	continuous glucose monitoring enables the detection of losses in infusion set actuation (lisas)	type 1 diabetes;sensor augmented pump;continuous subcutaneous insulin infusion;fault detection	Reliable continuous glucose monitoring (CGM) enables a variety of advanced technology for the treatment of type 1 diabetes. In addition to artificial pancreas algorithms that use CGM to automate continuous subcutaneous insulin infusion (CSII), CGM can also inform fault detection algorithms that alert patients to problems in CGM or CSII. Losses in infusion set actuation (LISAs) can adversely affect clinical outcomes, resulting in hyperglycemia due to impaired insulin delivery. Prolonged hyperglycemia may lead to diabetic ketoacidosis-a serious metabolic complication in type 1 diabetes. Therefore, an algorithm for the detection of LISAs based on CGM and CSII signals was developed to improve patient safety. The LISA detection algorithm is trained retrospectively on data from 62 infusion set insertions from 20 patients. The algorithm collects glucose and insulin data, and computes relevant fault metrics over two different sliding windows; an alarm sounds when these fault metrics are exceeded. With the chosen algorithm parameters, the LISA detection strategy achieved a sensitivity of 71.8% and issued 0.28 false positives per day on the training data. Validation on two independent data sets confirmed that similar performance is seen on data that was not used for training. The developed algorithm is able to effectively alert patients to possible infusion set failures in open-loop scenarios, with limited evidence of its extension to closed-loop scenarios.	actuation dosing unit;alert:type:point in time:^patient:nominal;apple lisa;chamaecyparis lawsoniana;clinical act of insertion;diabetes mellitus;diabetes mellitus, insulin-dependent;diabetic ketoacidosis;fault detection and isolation;glucose metabolism disorders;hyperglycemia;insulin lispro;ketosis;metabolic process, cellular;microsoft windows;pancreas, artificial;patients;algorithm	Daniel P Howsmon;Faye Cameron;Nihat Baysal;Trang T. Ly;Gregory P. Forlenza;David M. Maahs;Bruce A. Buckingham;Juergen Hahn;B. Wayne Bequette	2017		10.3390/s17010161	embedded system;real-time computing;computer science;engineering;fault detection and isolation	ML	6.9037836457159605	-79.87495048434018	21355
307f535ce5ca06d8f5fb2877c10d4759e3dd602f	visual representation determines search difficulty: explaining visual search asymmetries	health research;uk clinical guidelines;biological patents;natural image statistics;asymmetry;europe pubmed central;citation search;novelty;attention;uk phd theses thesis;visual representation;visual search;life sciences;uk research reports;medical journals;attentional bias;europe pmc;biomedical research;bioinformatics	In visual search experiments there exist a variety of experimental paradigms in which a symmetric set of experimental conditions yields asymmetric corresponding task performance. There are a variety of examples of this that currently lack a satisfactory explanation. In this paper, we demonstrate that distinct classes of asymmetries may be explained by virtue of a few simple conditions that are consistent with current thinking surrounding computational modeling of visual search and coding in the primate brain. This includes a detailed look at the role that stimulus familiarity plays in the determination of search performance. Overall, we demonstrate that all of these asymmetries have a common origin, namely, they are a consequence of the encoding that appears in the visual cortex. The analysis associated with these cases yields insight into the problem of visual search in general and predictions of novel search asymmetries.	cerebral cortex;class;computation;existential quantification;experiment;primates;visual representation	Neil D. B. Bruce;John K. Tsotsos	2011		10.3389/fncom.2011.00033	psychology;attention;visual search;bioinformatics;artificial intelligence;machine learning;communication;social psychology;attentional bias;asymmetry	ML	15.553517323231182	-74.64612288952243	21358
a49dc5647c8f70c5c3c0338030360b189aebb1fb	fie2: a program for the extraction of genomic dna sequences around the start and translation initiation site of human genes	software;peptide chain initiation translational;information extraction;rna messenger;translation initiation site;sequence analysis dna;nucleotide sequence;internet;genomic dna;promoter regions genetic;genome human;human genome;humans;molecular sequence data;sequence alignment;sequence analysis rna;base sequence;multiple alignment;transcription initiation site	FIE2 (5' end Information Extraction v2) is a web-based program for easy identification and extraction of nucleotide sequence around the start of genes (promoter region) and their translation initiation site (TIS). Using information provided by the National Center for Biotechnology Information's (NCBI's) LocusLink, FIE2 identifies the 5'-most end of a gene on its respective chromosome based on alignment of a selected set of mRNAs representative of the gene. FIE2 then uses currently available human genome sequence information to extract the desired sequences. The accuracy of the information extracted is therefore limited by the accuracy and completeness of the sequence annotation and sequence alignment provided by LocusLink. In addition, multiple TIS positions are also occasionally presented, for example, as a result of multiple alignments of transcript variants. One of the key criteria of FIE2 is that it should extract only the correct information or attempt no extraction at all. To date, the authors are not aware of any publicly available web-based tool that uses the human genomic sequence to extract pertinent promoter- and TIS-region information in this fashion. FIE2 is freely available at http://sdmc.lit.org.sg/FIE2.0.	annotation;base sequence;genes, vif;information extraction;ncbi taxonomy;promoter regions, genetic;relevance;sequence alignment;transcript;transcription initiation;translation initiation;web application	Allen Chong;Guanglan Zhang;Vladimir B. Bajic	2003	Nucleic acids research	10.1093/nar/gkg604	biology;human genome;molecular biology;the internet;multiple sequence alignment;nucleic acid sequence;bioinformatics;genomic dna;sequence alignment;genetics;information extraction	Comp.	-0.8506085660867103	-58.06115906220377	21372
6b3dc84373ec210dcd93386a70bee3e943e2619b	comparative molecular field analysis of non-steroidal aromatase inhibitors related to fadrozole	aromatase inhibitor	A series of non-steroidal inhibitors of aromatase, structurally related to fadrozole (2), was investigated with the aim of developing a 3D QSAR model using the Comparative Molecular Field Analysis (CoMFA) technique. The alignment of the molecules was performed following two approaches (atom-by-atom and field fit), both starting from an initial hypothesis of superimposition of fadrozole to a steroidal inhibitor (3). From a number of CoMFA models built with different characteristics, one was recognized as the most statistically relevant; this one is discussed in detail. The features of the 3D QSAR model are consistent with those of other 3D and QSAR models of aromatase and its inhibitors.		Maurizio Recanatini	1996	Journal of computer-aided molecular design	10.1007/BF00124467	pharmacology;biology;endocrinology;chemistry;toxicology	Graphics	11.230209306239914	-59.000100559799186	21396
b47e6fc6e33b0a5ae8e3b76e47075ec2f722a374	hapconstructor: automatic construction and testing of haplotypes in a monte carlo framework	software;false discovery rate;construction process;haplotipo;bioinformatique;association study;haplotype;construccion;monte carlo method;missing data;bioinformatica;monte carlo;computer simulation;construction;polymorphism single nucleotide;haplotypes;candidate gene;bioinformatics	SUMMARY Haplotypes carry important information that can direct investigators towards underlying susceptibility variants, and hence multiple tagging single nucleotide polymorphisms (tSNPs) are usually studied in candidate gene association studies. However, it is often unknown which SNPs should be included in haplotype analyses, or which tests should be performed for maximum power. We have developed a program, hapConstructor, which automatically builds multi-locus SNP sets to test for association in a case-control framework. The multi-SNP sets considered need not be contiguous; they are built based on significance. An important feature is that the missing data imputation is carried out based on the full data, for maximal information and consistency. HapConstructor is implemented in a Monte Carlo framework and naturally extends to allow for significance testing and false discovery rates that account for the construction process and to related individuals. HapConstructor is a useful tool for exploring multi-locus associations in candidate genes and regions.   AVAILABILITY http://www-genepi.med.utah.edu/Genie.	chamaecyparis lawsoniana;genetic polymorphism;geo-imputation;haplotypes;locus;maximal set;maximum power transfer theorem;mental association;missing data;monte carlo method;nitroprusside;nucleotides;numerous;snp array;single nucleotide polymorphism;statistical imputation	Ryan Abo;Stacey Knight;Jathine Wong;Angela Cox;Nicola J. Camp	2008		10.1093/bioinformatics/btn359	computer simulation;biology;haplotype;bioinformatics;data mining;genetics;statistics;monte carlo method	Comp.	3.3381220013596895	-52.97240553382943	21431
d940be171f5c97678d019bffa66120a8fce2b364	instance-based object recognition with simultaneous pose estimation using keypoint maps and neural dynamics		We present a method for biologically-inspired object recognition with one-shot learning of object appearance. We use a computationally efficient model of V1 keypoints to select object parts with the highest information content and model their surroundings using simple colour features. This map-like representation is fed into a dynamical neural network which performs pose, scale and translation estimation of the object given a set of previously observed object views. We demonstrate the feasibility of our algorithm for cognitive robotic scenarios and evaluate classification performance on a dataset of household items.	3d pose estimation;algorithm;algorithmic efficiency;artificial neural network;cross-validation (statistics);dynamical system;expect;international symposium on fundamentals of computation theory;map;one-shot learning;outline of object recognition;real-time clock;robot;self-information;top-down and bottom-up design	Oliver Lomp;Kasim Terzic;Christian Faubel;J. M. Hans du Buf;Gregor Schöner	2014		10.1007/978-3-319-11179-7_57	computer vision;pose;3d pose estimation;machine learning;pattern recognition	Vision	23.520006932053946	-55.98042402934317	21434
e279ee592ba8f7d4af372c1807e615a5057077c3	cluster analysis method and near-infrared spectroscopy applied to the identification of food	pharmaceuticals;spectroscopy;pattern clustering;reflectivity;food processing industry;analysis of variance cluster analysis near infrared spectroscopy food identification reflectance spectroscopy ward method;statistical analysis food processing industry pattern clustering spectroscopy;peanut oil;milling balm;spectrum;jinhua ham;near infrared;petroleum;cluster analysis;jinhua ham cluster analysis near infrared spectroscopy peanut oil milling balm;statistical analysis;machine learning;monitoring;reflectance spectroscopy;spectroscopy petroleum milling pharmaceuticals monitoring reflectivity machine learning;near infrared spectroscopy;diffuse reflectance spectroscopy;analysis of variance;ward method;milling;food identification	Cluster analysis method and Near-infrared (NIR) diffuse reflectance spectroscopy are applied to develop a fast identification method of food. The samples are collected from different manufactures and they are peanut oil, milling balm, and Jinhua ham. NIR spectra are pretreated with first derivative calculation and vector normalization. The NIR data are evaluated by cluster analysis, which uses the components of each spectrum to construct an informative classification of an unclassified data set. The distances between clusters are evaluated by Ward's method of analysis of variance. The geometric distances in the multidimensional space are measured. The method can both distinguish peanut oil, milling balm, and Jinhua ham successfully. Overall, NIR diffuse reflectance spectroscopy using cluster analysis method is shown to have significant potential as a rapid and accurate method for identification of food.	cluster analysis;information;oren–nayar reflectance model;ward's method	Hong-Lian Li;Xiao-Ting Li;Zhi-Lei Zhao;Yan-Ping Pang	2010	2010 International Conference on Machine Learning and Cybernetics	10.1109/ICMLC.2010.5581027	near-infrared spectroscopy;spectroscopy;computer science;machine learning	Visualization	16.232321426557636	-56.641613068733065	21442
e97bd859e5231085a228827c1bb1bea17c6eac1f	repeatsdb 2.0: improved annotation, classification, search and visualization of repeat protein structures		RepeatsDB 2.0 (URL: http://repeatsdb.bio.unipd.it/) is an update of the database of annotated tandem repeat protein structures. Repeat proteins are a widespread class of non-globular proteins carrying heterogeneous functions involved in several diseases. Here we provide a new version of RepeatsDB with an improved classification schema including high quality annotations for ∼5400 protein structures. RepeatsDB 2.0 features information on start and end positions for the repeat regions and units for all entries. The extensive growth of repeat unit characterization was possible by applying the novel ReUPred annotation method over the entire Protein Data Bank, with data quality is guaranteed by an extensive manual validation for >60% of the entries. The updated web interface includes a new search engine for complex queries and a fully re-designed entry page for a better overview of structural data. It is now possible to compare unit positions, together with secondary structure, fold information and Pfam domains. Moreover, a new classification level has been introduced on top of the existing scheme as an independent layer for sequence similarity relationships at 40%, 60% and 90% identity.	annotation;data quality;display resolution;genetic heterogeneity;homology (biology);imagery;interface device component;pfam;pierre robin syndrome;protein data bank;tandem repeat sequences;uniform resource locator;user interface;web search engine	Lisanna Paladin;Layla Hirsh;Damiano Piovesan;Miguel A. Andrade-Navarro;Andrey V. Kajava;Silvio C. E. Tosatto	2017	Nucleic acids research	10.1093/nar/gkw1136	bioinformatics	Comp.	-1.244910626843361	-59.765344637438275	21463
40ceef4d7f7e25f199211bda8555f9ee32c8d0b4	virtual exploration of early stage atherosclerosis			atherosclerosis;limited stage (cancer stage)	Andy Luis Olivares;Miguel Ángel González Ballester;Jérôme Noailly	2017	Bioinformatics	10.1093/bioinformatics/btw743	data mining;computer science	NLP	10.24548425220695	-79.92604063971064	21574
392be8e78bf0bf840203f04040a79b3244a79da9	micro-mar: a database for dynamic representation of marine microbial biodiversity	high resolution;web interface;databases genetic;marine biology;classification;computational biology bioinformatics;research purpose;algorithms;molecular data;databases factual;combinatorial libraries;base sequence;dna sequence;biodiversity;computer appl in life sciences;microbial diversity;information storage and retrieval;sequence analysis protein;ecosystem;microarrays;bioinformatics	The cataloging of marine prokaryotic DNA sequences is a fundamental aspect for bioprospecting and also for the development of evolutionary and speciation models. However, large amount of DNA sequences used to quantify prokaryotic biodiversity requires proper tools for storing, managing and analyzing these data for research purposes. The Micro-Mar database has been created to collect DNA diversity information from marine prokaryotes for biogeographical and ecological analyses. The database currently includes 11874 sequences corresponding to high resolution taxonomic genes (16S rRNA, ITS and 23S rRNA) and many other genes including CDS of marine prokaryotes together with available biogeographical and ecological information. The database aims to integrate molecular data and taxonomic affiliation with biogeographical and ecological features that will allow to have a dynamic representation of the marine microbial diversity embedded in a user friendly web interface. It is available online at http://egg.umh.es/micromar/ .	bacterial 16s rna;embedded system;embedding;interface device component;prokaryote;usability;user interface	Ravindra Pushker;Giuseppe D'Auria;Jose Carlos Alba-Casado;Francisco Rodríguez-Valera	2005	BMC Bioinformatics	10.1186/1471-2105-6-222	biology;dna sequencing;biodiversity;ecosystem;dna microarray;image resolution;biological classification;bioinformatics;data mining;user interface;marine biology	DB	-0.32538036807682474	-59.56648423211918	21619
eef626f51fa6f8dc5e29915c7a6582b745fc3654	discriminative analysis of early alzheimer's disease using multi-modal imaging and multi-level characterization with multi-classifier (m3)	connectome;fmri;alff;reho;mri;alzheimer s disease;connectivity;network	Increasing attention has recently been directed to the applications of pattern recognition and brain imaging techniques in the effective and accurate diagnosis of Alzheimer's disease (AD). However, most of the existing research focuses on the use of single-modal (e.g., structural or functional MRI) or single-level (e.g., brain local or connectivity metrics) biomarkers for the diagnosis of AD. In this study, we propose a methodological framework, called multi-modal imaging and multi-level characteristics with multi-classifier (M3), to discriminate patients with AD from healthy controls. This approach involved data analysis from two imaging modalities: structural MRI, which was used to measure regional gray matter volume, and resting-state functional MRI, which was used to measure three different levels of functional characteristics, including the amplitude of low-frequency fluctuations (ALFF), regional homogeneity (ReHo) and regional functional connectivity strength (RFCS). For each metric, we computed the values of ninety regions of interest derived from a prior atlas, which were then further trained using a multi-classifier based on four maximum uncertainty linear discriminant analysis base classifiers. The performance of this method was evaluated using leave-one-out cross-validation. Applying the M3 approach to the dataset containing 16 AD patients and 22 healthy controls led to a classification accuracy of 89.47% with a sensitivity of 87.50% and a specificity of 90.91%. Further analysis revealed that the most discriminative features for classification are predominantly involved in several default-mode (medial frontal gyrus, posterior cingulate gyrus, hippocampus and parahippocampal gyrus), occipital (fusiform gyrus, inferior and middle occipital gyrus) and subcortical (amygdale and pallidum of lenticular nucleus) regions. Thus, the M3 method shows promising classification performance by incorporating information from different imaging modalities and different functional properties, and it has the potential to improve the clinical diagnosis and treatment evaluation of AD.	alzheimer's disease;amplitude of low frequency fluctuations;biological markers;brain diseases;cell nucleus;cervical atlas;crohn disease;cross reactions;cross-validation (statistics);default;diagnosis, clinical;frontal lobe gyrus;globus pallidus;gray matter;gyrus cinguli;imaging techniques;interphase cell;lateral occipitotemporal gyrus;lenticular printing;lentiform nucleus structure;linear discriminant analysis;m3 mental health checklist;medial graph;modal logic;multi-level cell;ninety;numerous;parahippocampal gyrus;patients;pattern recognition;region of interest;resting state fmri;sensitivity and specificity;silo (dataset);spontaneous order;tcp global synchronization;weight	Zhengjia Dai;Chaogan Yan;Zhiqun Wang;Jinhui Wang;Mingrui Xia;Kuncheng Li;Yong Jun He	2012	NeuroImage	10.1016/j.neuroimage.2011.10.003	psychology;neuroscience;developmental psychology;radiology;medicine;pathology;connectivity;magnetic resonance imaging;connectome	Vision	21.14349801499501	-80.06301530222	21632
086aac7010dcff346f64d72180f6690e98312adb	de novo peptide sequencing using ion peak intensity and amino acid cleavage intensity ratio	de novo sequencing;amino acid;amino acid sequence;spectrum;database search	MOTIVATION Peptide-sequencing methods by mass spectrum use the following two approaches: database searching and de novo sequencing. The database-searching approach is convenient; however, in cases wherein the corresponding sequences are not included in the databases, the exact identification is difficult. On the other hand, in the case of de novo sequencing, no preliminary information is necessary; however, continuous amino acid sequence peaks and the differentiation of these peaks are required. It is, however, very difficult to obtain and differentiate the peaks of all amino acids by using an actual spectrum. We propose a novel de novo sequencing approach using not only mass-to-charge ratio but also ion peak intensity and amino acid cleavage intensity ratio (CIR).   RESULTS Our method compensates for any undetectable amino acid peak intervals by estimating the amino acid set and the probability of peak expression based on amino acid CIR. It provides more accurate identification of sequences than the existing methods, by which it is usually difficult to sequence.	amino acid sequence;amino acids;biopolymer sequencing;committed information rate;database;de novo transcriptome assembly;estimated;ions;mass spectrometry;undetectable	Mitsuhiro Kanazawa;Hisae Anyoji;Atsushi Ogiwara;Umpei Nagashima	2007	Bioinformatics	10.1093/bioinformatics/btm062	biology;spectrum;biochemistry;database search engine;amino acid;bioinformatics;peptide sequence;genetics	Comp.	1.5530817346496542	-56.908600467407794	21669
81a8b053f1cef6037ad0a95b56bd583feef73f3e	prediction of readmissions in the german drg system based on §21 datasets	patient readmission;decision support techniques;diagnosis-related groups;hospital information systems;machine learning	"""Hospital readmissions receive increasing interest, since they are burdensome for patients and costly for healthcare providers. For the calculation of reimbursement fees, in Germany there is the German-Diagnosis Related Groups (G-DRG) system. For every hospital stay, data are collected as a so-called """"case"""", as the basis for the subsequent reimbursement calculations (""""§21 dataset""""). Merging rules lead to a loss of information in §21 datasets. We applied machine learning to §21 datasets and evaluated the influence of case merging for the resulting accuracy of readmission risk prediction. Data from 478,966 cases were analysed by applying a random forest. Many cases with readmissions within 30 days had been merged and thus their prediction required additional data. Using 10-fold cross validation, the prediction for readmissions within 31-60 days showed no notable difference in the area under the ROC curves comparing unedited §21 datasets with §21 datasets with restored original cases. The achieved AUC values of 0.69 lie in a similar range as the values of comparable state-of-the-art models. We conclude that dealing with merged cases, i.e. adding data, is required for 30-day-readmission prediction, whereas un-merging brings no improvement for the readmission prediction of period beyond 30 days."""	area under curve;crew resource management, healthcare;digital raster graphic;machine learning;merge;patients;roc curve;random forest;rule (guideline);silo (dataset);triangulation	Alphons Eggerth;Dieter Hayn;Sai P. K. Veeranki;Jörg Stieg;Günter Schreier	2018	Studies in health technology and informatics	10.3233/978-1-61499-896-9-170	data mining;computer science;german	ML	6.584111110747116	-75.5152088712511	21696
25503801d3b0fa56b6f0eeb7410eafdf36c5cc3a	novo&stitch: accurate reconciliation of genome assemblies via optical maps		Motivation De novo genome assembly is a challenging computational problem due to the high repetitive content of eukaryotic genomes and the imperfections of sequencing technologies (i.e. sequencing errors, uneven sequencing coverage and chimeric reads). Several assembly tools are currently available, each of which has strengths and weaknesses in dealing with the trade-off between maximizing contiguity and minimizing assembly errors (e.g. mis-joins). To obtain the best possible assembly, it is common practice to generate multiple assemblies from several assemblers and/or parameter settings and try to identify the highest quality assembly. Unfortunately, often there is no assembly that both maximizes contiguity and minimizes assembly errors, so one has to compromise one for the other.   Results The concept of assembly reconciliation has been proposed as a way to obtain a higher quality assembly by merging or reconciling all the available assemblies. While several reconciliation methods have been introduced in the literature, we have shown in one of our recent papers that none of them can consistently produce assemblies that are better than the assemblies provided in input. Here we introduce Novo&Stitch, a novel method that takes advantage of optical maps to accurately carry out assembly reconciliation (assuming that the assembled contigs are sufficiently long to be reliably aligned to the optical maps, e.g. 50 Kbp or longer). Experimental results demonstrate that Novo&Stitch can double the contiguity (N50) of the input assemblies without introducing mis-joins or reducing genome completeness.   Availability and implementation Novo&Stitch can be obtained from https://github.com/ucrbioinfo/Novo_Stitch.	alignment;biopolymer sequencing;carya illinoinensis nut ab.ige:ratio:pt:ser:qn;chimera organism;computational problem;de novo transcriptome assembly;decagram;genome assembly sequence;inferring horizontal gene transfer;manuscripts;map;np-hardness;optical mapping;paper;population parameter;software quality;tacrolimus binding proteins;weakness	Weihua Pan;Steve Wanamaker;Audrey M. V. Ah-Fong;Howard S. Judelson;Stefano Lonardi	2018		10.1093/bioinformatics/bty255	completeness (statistics);contiguity;computer science;computational problem;data mining;merge (version control);genome;sequence assembly;contig	Comp.	0.10292714828798294	-53.653458759184815	21726
725ca13313d1c6ce38fac920d8f462bd106f7ebc	large-scale computational modeling of genetic regulatory networks	bayesian network;signaling network;systems biology;computer model;reaction diffusion;gene regulation;genetic regulatory network;dna microarrays;genetics;gene expression;large scale;machine learning;genetic pathways;genetic network;nonlinear dynamics;system biology;point of view;dna microarray;measurement technique;neural network;bayesian networks	The perhaps most important signaling network in living cells is constitutedby the interactions of proteins with the genome – the regulatory geneticnetwork of the cell. From a system-level point of view, the variousinteractions and control loops, which form a genetic network, represent thebasis upon which the vast complexity and flexibility of life processesemerges. Here we provide a review over some efforts towards gaining aquantitative understanding of regulatory genetic networks by means of largescale computational models. After a brief description of the biologicalprinciples of gene regulation, we summarize recent advances in massivegene-expression measurements by DNA-microarrays, which form the to date mostpowerful data basis for models of genetic networks. One class of models suchas reaction-diffusion networks and nonlinear dynamical descriptions arebiased towards using explicit molecular biological knowledge. A secondclass, centered around machine learning approaches like neural networks andBayesian networks, adopts a more data-driven approach and thereby makesmassive use of the novel gene expression measurement techniques.	algorithm;artificial intelligence;artificial neural network;bayesian network;causal filter;cluster analysis;computation;computational model;dna microarray;data mining;gene expression profiling;gene regulatory network;high-throughput computing;interaction;machine learning;nonlinear system;point of view (computer hardware company);throughput	Martin Stetter;Gustavo Deco;Mathäus Dejori	2003	Artificial Intelligence Review	10.1023/A:1026088615145	biological network;dna microarray;computer science;bioinformatics;machine learning;bayesian network;systems biology	AI	4.239277530706073	-66.95667100880651	21797
eabc2e32b9a950c86d8a311761a54f02ba980ebf	mapping how local perturbations influence systems-level brain dynamics	connectomics;brain networks;kuramoto model;core periphery axis;brain simulation;computational modeling;hubs;functional magnetic resonance imaging fmri;connectivity;transcranial magnetic stimulation tms	The human brain exhibits a distinct spatiotemporal organization that supports brain function and can be manipulated via local brain stimulation. Such perturbations to local cortical dynamics are globally integrated by distinct neural systems. However, it remains unclear how local changes in neural activity affect large-scale system dynamics. Here, we briefly review empirical and computational studies addressing how localized perturbations affect brain activity. We then systematically analyze a model of large-scale brain dynamics, assessing how localized changes in brain activity at the different sites affect whole-brain dynamics. We find that local stimulation induces changes in brain activity that can be summarized by relatively smooth tuning curves, which relate a region's effectiveness as a stimulation site to its position within the cortical hierarchy. Our results also support the notion that brain hubs, operating in a slower regime, are more resilient to focal perturbations and critically contribute to maintain stability in global brain dynamics. In contrast, perturbations of peripheral regions, characterized by faster activity, have greater impact on functional connectivity. As a parallel with this region-level result, we also find that peripheral systems such as the visual and sensorimotor networks were more affected by local perturbations than high-level systems such as the cingulo-opercular network. Our findings highlight the importance of a periphery-to-core hierarchy to determine the effect of local stimulation on the brain network. This study also provides novel resources to orient empirical work aiming at manipulating functional connectivity using non-invasive brain stimulation.	brain implant;computation;deep brain stimulation;electroencephalography;exhibits as topic;experiment;focal (programming language);global brain;high- and low-level;map;peripheral;resting state fmri;system dynamics	Leonardo L. Gollo;James A. Roberts;Luca Cocchi	2017	NeuroImage	10.1016/j.neuroimage.2017.01.057	psychology;neuroscience;artificial intelligence;connectivity;communication;computational model;resting state fmri	ML	19.909342032386338	-76.78886994578114	21885
18c27776acbd7f5646e32c512eddc2c3107b3a00	protein data bank japan (pdbj): maintaining a structural data archive and resource description framework format	software;internet;proteins;protein conformation;user computer interface;databases protein	The Protein Data Bank Japan (PDBj, http://pdbj.org) is a member of the worldwide Protein Data Bank (wwPDB) and accepts and processes the deposited data of experimentally determined macromolecular structures. While maintaining the archive in collaboration with other wwPDB partners, PDBj also provides a wide range of services and tools for analyzing structures and functions of proteins, which are summarized in this article. To enhance the interoperability of the PDB data, we have recently developed PDB/RDF, PDB data in the Resource Description Framework (RDF) format, along with its ontology in the Web Ontology Language (OWL) based on the PDB mmCIF Exchange Dictionary. Being in the standard format for the Semantic Web, the PDB/RDF data provide a means to integrate the PDB with other biological information resources.	accepting of extremity;crystallographic information file;dictionary;digital archive;experiment;information resources;interoperability;research data archiving;resource description framework;semantic web;web ontology language;worldwide protein data bank	Akira R. Kinjo;Hirofumi Suzuki;Reiko Yamashita;Yasuyo Ikegawa;Takahiro Kudou;Reiko Igarashi;Yumiko Kengaku;Hasumi Cho;Daron M. Standley;Atsushi Nakagawa;Haruki Nakamura	2012		10.1093/nar/gkr811	biology;protein structure;the internet;protein data bank	Web+IR	-2.8705343610900798	-61.69542868823363	21934
30ecfa26b6952dfe8c20a93dfc55ac57a822ec6c	dynamic abandon/extract decisions for failed cardiac leads	medical decision making;implanted cardiac devices;semi markov decision process;maintenance optimization	When a cardiac lead fails, physicians implant a new lead and may opt to extract the failed lead and/or any previously abandoned leads. Because the risk of extraction increases in lead age, physicians may extract leads to reduce the future risk of mandatory extraction, due to either infection or limited space in the vein. We develop discrete-time semi-Markov decision process models for various types of cardiac devices to determine patient-specific, lifetime-maximizing extraction policies as a function of patient age and the age of every implanted lead. We use clinical data to calibrate these models and present insightful numerical results, including comparisons to policies commonly used in practice. Our numerical experiments suggest that extracting failed leads only when forced to because of space limitations is usually a good rule of thumb, but that following the optimal policy, as opposed to the commonly used heuristic policies, can extend an average patient’s expected lifetime by up to 1.2 years and dec...		Anahita Khojandi;Lisa M. Maillart;Oleg A. Prokopyev;Mark S. Roberts;Samir F. Saba	2018	Management Science	10.1287/mnsc.2016.2621	simulation;operations management	Logic	5.76635939290353	-73.7645550209457	22067
554e29cd9882066f423d4599bd4582c7f7d58e7e	the multiple common point set problem and its application to molecule binding pattern detection	multiple structure alignment of binding sites;k partite matching;pattern discovery;pattern detection;pattern matching;common point set problem;recognition of functional sites;consensus binding patterns	Recognition of binding patterns common to a set of protein structures is important for recognition of function, prediction of binding, and drug design. We consider protein binding sites represented by a set of 3D points with assigned physico-chemical and geometrical properties important for protein-ligand interactions. We formulate the multiple binding site alignment problem as detection of the largest common set of such 3D points. We discuss the computational problem of multiple common point set detection and, particularly, the matching problem in K-partite-epsilon graphs, where K partitions are associated with K structures and edges are defined between epsilon-close points. We show that the K-partite-epsilon matching problem is NP-hard in the Euclidean space with dimension larger than one. Consequently, we show that the largest common point set problem between three point sets is NP-hard. On the practical side, we present a novel computational method, MultiBind, for recognition of binding patterns common to a set of protein structures. It performs a multiple alignment between protein binding sites in the absence of overall sequence, fold, or binding partner similarity. Despite the NP-hardness results, in our applications, we practically overcome the exponential number of multiple alignment combinations by applying an efficient branchand- bound filtering procedure. We show applications of MultiBind to several biological targets. The method recognizes patterns which are responsible for binding small molecules, such as estradiol, ATP/ANP, and transition state analogues.		Maxim Shatsky;Alexandra Shulman-Peleg;Ruth Nussinov;Haim J. Wolfson	2006	Journal of computational biology : a journal of computational molecular cell biology	10.1089/cmb.2006.13.407	combinatorics;discrete mathematics;computer science;bioinformatics;pattern matching;mathematics	Comp.	12.442407390443528	-56.68971271361759	22090
528efc48badc97090ecfc9e79148fbb4764c6aff	dynamic knowledge representation in connectionist systems	learning process;traitement lineaire;representacion conocimientos;representacion sistema;procesamiento informacion;connectionism;debit information;conexionismo;neural code;indice informacion;endnotes;tratamiento lineal;dynamical system;systeme dynamique;cognitive process;connexionnisme;linear processing;sinapsis;spiking neurons;representation systeme;information processing;system representation;information rate;pubications;sistema dinamico;learning artificial intelligence;reseau neuronal;knowledge representation;traitement information;representation connaissances;red neuronal;neural network;synapse;apprentissage intelligence artificielle	One of the most pervading concepts underlying computational models of information processing in the brain is linear input integration of rate coded uni-variate information by neurons. After a suitable learning process this results in neuronal structures that statically represent knowledge as a vector of real valued synaptic weights. Although this general framework has contributed to the many successes of connectionism, in this paper we argue that for all but the most basic of cognitive processes, a more complex, multi-variate dynamic neural coding mechanism is required knowledge should not be spacially bound to a particular neuron or group of neurons. We conclude the paper with discussion of a simple experiment that illustrates dynamic knowledge representation in a spiking neuron connectionist system.	artificial neuron;computational model;connectionism;information processing;knowledge representation and reasoning;neural coding;synaptic package manager;synaptic weight	J. Mark Bishop;Slawomir J. Nasuto;Kris De Meyer	2002		10.1007/3-540-46084-5_51	connectionism;cognition;information processing;computer science;synapse;artificial intelligence;dynamical system;machine learning;neural coding;artificial neural network;algorithm	ML	21.0724645703725	-70.40793868571447	22091
ae9a79a1a54c579ac4fa23924e4a86cd4c1a61f3	accurate estimate of blood glucose through interstitial glucose by genetic programming		Subjects suffering from Type 1 diabetes mellitus need to constantly receive insulin injections. To improve their life quality, a desirable solution is represented by the implementation of an artificial pancreas. In this paper we move a preliminary step towards this goal. Namely, we work at the knowledge base for such a device. One of the main problems is to estimate the Blood Glucose (BG) values, starting from the easily available Interstitial Glucose (IG) ones, and this is the aim of our paper. To face this regression task we avail ourselves of Genetic Programming over a real-world database containing both BG and IG measurements for several subjects suffering from Type 1 diabetes, aiming at finding an explicit relationship between BG and IG values under the form of a mathematical expression. This latter could be the core of the knowledge base part of an artificial pancreas. Experimental comparisons against the state-of-the-art models evidence the quality of the proposed approach.	blood substitute;edmund m. clarke;genetic programming;interstitial webpage;job control (unix);knowledge base;mean squared error;test set	Ivanoe De Falco;Umberto Scafuri;Ernesto Tarantino;Antonio Della Cioppa	2017	2017 IEEE Symposium on Computers and Communications (ISCC)	10.1109/ISCC.2017.8024543	artificial pancreas;type 1 diabetes;genetic programming;computer science;knowledge-based systems;knowledge base;insulin;diabetes mellitus;artificial intelligence	AI	5.949970366866392	-77.88978836537783	22121
46c6938a363cffda8e68998a48f3a83d893a8616	dynamic link models for global decision making with binding-by-synchrony	object recognition;brain;recognition process;data integrity;individual object;dynamic linking;dynamic link matching binding problems recognition process binding by synchrony;computer vision;synchronisation;multiple objectives;decision making process;synchronisation brain computer vision data integrity decision making encoding object recognition;binding problem;dynamic link matching;binding problems;networked systems;synchronization desynchronization process global decision making binding by synchrony multiple objects visual scene primate visual system information integration neurally plausible mechanism global multiobject recognition dynamic link matching macrocolumnar cortical model encoding;encoding;visual system;oscillators synchronization visualization firing neurons biological system modeling;binding by synchrony	We address the problem of integrating information about multiple objects and their positions on a visual scene. A primate visual system has fewer difficulties in rapidly achieving integration, given even when presented with several objects. Here, we propose a neurally plausible mechanism for simultaneously coordinating the local decision-making process of “what”- and “where”-information for the organization of global multi-object recognition. The mechanism is based on paradigms of binding-by-synchrony and dynamic link matching in a network system of the macrocolumnar cortical model. These paradigms are responsible for encoding an individual object and its position through a synchronization-desynchronization process among selected or unselected links of the objects.	dynamic link matching;outline of object recognition	Yasuomi D. Sato;Jenia Jitsev;Thomas Burwick;Christoph von der Malsburg	2010	2010 Second World Congress on Nature and Biologically Inspired Computing (NaBIC)	10.1109/NABIC.2010.5716291	binding problem;synchronization;computer vision;decision-making;visual system;computer science;artificial intelligence;cognitive neuroscience of visual object recognition;machine learning;data integrity;encoding	Vision	20.215545677074914	-67.45926274790082	22132
1b124eb1b8906eab6c87bd04dca5ff5f297bd9ed	a merge-decoupling dead end elimination algorithm for protein side-chain conformation	global minimum energy;protein side chain conformation;sccp;rotamer elimination;data mining;protein structure;merge decoupling algorithm;dee;dead end elimination;residue elimination;prediction;bioinformatics	Dead End Elimination (DEE) is a technique for eliminating rotamers that can not exist in any global minimum energy configuration for the protein side chain conformation problem. A popular method is Simple Goldstein DEE (SG-DEE) which is fast and eliminates rotamers by considering single residues for possible elimination. We present a Merge-Decoupling DEE (MD-DEE) that further reduces the number of rotamers after SG-DEE. MD-DEE works by forming residue-pairs but is fast and, like SG-DEE, is practical even for large proteins. Our experiments show that MD-DEE achieves further reduction in residue elimination (up to 25%) after SG-DEE.	algorithm;coupling (computer programming);date attending md referred patient for:date:pt:speech therapy treatment:qn;dead-end elimination;excretory function;experiment;firing squad synchronization problem;hannah dee;maxima and minima;molecular dynamics;suicidegirls;receptor for advanced glycation endproducts	Ket Fah Chong;Hon Wai Leong	2007	International journal of data mining and bioinformatics	10.1504/IJDMB.2007.012966	signalling connection control part;protein structure;prediction;computer science;bioinformatics;data mining;statistics	Comp.	11.38994424267615	-62.7056532577834	22150
8a477b79651a762b8d9ad9b63b093e2403e06d29	aptacluster - a method to cluster ht-selex aptamer pools and lessons from its application	biological patents;biomedical journals;text mining;europe pubmed central;citation search;citation networks;research articles;abstracts;open access;life sciences;clinical guidelines;full text;rest apis;orcids;europe pmc;biomedical research;bioinformatics;literature search	Systematic Evolution of Ligands by EXponential Enrichment (SELEX) is a well established experimental procedure to identify aptamers - synthetic single-stranded (ribo)nucleic molecules that bind to a given molecular target. Recently, new sequencing technologies have revolutionized the SELEX protocol by allowing for deep sequencing of the selection pools after each cycle. The emergence of High Throughput SELEX (HT-SELEX) has opened the field to new computational opportunities and challenges that are yet to be addressed. To aid the analysis of the results of HT-SELEX and to advance the understanding of the selection process itself, we developed AptaCluster. This algorithm allows for an efficient clustering of whole HT-SELEX aptamer pools; a task that could not be accomplished with traditional clustering algorithms due to the enormous size of such datasets. We performed HT-SELEX with Interleukin 10 receptor alpha chain (IL-10RA) as the target molecule and used AptaCluster to analyze the resulting sequences. AptaCluster allowed for the first survey of the relationships between sequences in different selection rounds and revealed previously not appreciated properties of the SELEX protocol. As the first tool of this kind, AptaCluster enables novel ways to analyze and to optimize the HT-SELEX procedure. Our AptaCluster algorithm is available as a very fast multiprocessor implementation upon request.	algorithm;biological evolution;biopolymer sequencing;cluster analysis;computation;dec alpha;deep sequencing;emergence;gene ontology term enrichment;hyper-threading;hypertensive disease;il10ra wt allele;interleukin receptor common gamma subunit;interleukin-10 receptor alpha subunit;literal pool;multiprocessing;selex aptamer technique;synthetic intelligence;throughput;statistical cluster	Jan Hoinka;Alexey Berezhnoy;Zuben E. Sauna;Eli Gilboa;Teresa M. Przytycka	2014	Research in computational molecular biology : ... Annual International Conference, RECOMB ... : proceedings. RECOMB	10.1007/978-3-319-05269-4_9	biology;text mining;medical research;computer science;bioinformatics;data science;data mining	HPC	0.9462623844901779	-58.2359764493594	22190
88bee64d0a9fa68b08ac1327b8b5b96ee6012807	a model cortical circuit for the storage of temporal sequences	oscillations;walsh function;temporal information;memory systems;neural network model;system management;numerical simulation	Despite the fact that temporal information processing is of particular significance in biological memory systems, not much has yet been explored about how these systems manage to store temporal information involved in sequences of stimuli. A neural network model capable of learning and recalling temporal sequences is proposed, based on a neural mechanism in which the sequences are expanded into a series of periodic rectangular oscillations. Thus, the mathematical framework underlying the model, to some extent, is concerned with the Walsh function series. The oscillatory activities generated by the interplay between excitatory and inhibitory neuron pools are transmitted to another neuron pool whose role in learning and retrieval is to modify the rhythms and phases of the rectangular oscillations. Thus, a basic functional neural circuit involves three different neuron pools. The modifiability of rhythms and phases is incorporated into the model with the aim of improving the quality of the retrieval. Numerical simulations were conducted to show the characteristic features of the learning as well as the performance of the model in memory recall.	artificial neural network;artificial neuron;hadamard transform;information processing;network model;numerical analysis;numerical linear algebra;simulation	Tomoki Fukai	1995	Biological Cybernetics	10.1007/BF00202787	computer simulation;systems management;computer science;artificial intelligence;machine learning;mathematics;communication;oscillation;walsh function;artificial neural network	ML	19.30002783951849	-70.36520653156772	22207
5a1665c7ac9bc82968c03b5503ad4d2c5519d2d3	data visualization optimization via computational modeling of perception	human information processing;neural network simulation;biology computing;eye;human vision;streaklet based optimization;neural nets;head to tail streaklet alignment;computer model;utility function;information visualization;lic like result;automatic evaluation;primary visual cortex;data model;data visualisation;visualization;computational modeling;neural net;emergent properties;optimization information visualization perception human information processing neural nets;lic like result data visualization optimization perception computational modeling human vision computational model neural network simulation retina primary visual cortex hill climbing algorithm 2d flow visualizations streaklet based optimization head to tail streaklet alignment pixel based parameterization;image color analysis;retina;2d flow visualizations;data visualization;perception computational modeling;visual perception biology computing data visualisation digital simulation eye neural nets;visual perception;pixel based parameterization;data visualization computational modeling visualization neurons retina image color analysis data models;optimization;human vision computational model;hill climbing;computer graphics computer simulation humans models neurological nerve net retina visual cortex visual perception;neurons;perception;quality control;visual system;data visualization optimization;flow visualization;hill climbing algorithm;digital simulation;data models;neural network	We present a method for automatically evaluating and optimizing visualizations using a computational model of human vision. The method relies on a neural network simulation of early perceptual processing in the retina and primary visual cortex. The neural activity resulting from viewing flow visualizations is simulated and evaluated to produce a metric of visualization effectiveness. Visualization optimization is achieved by applying this effectiveness metric as the utility function in a hill-climbing algorithm. We apply this method to the evaluation and optimization of 2D flow visualizations, using two visualization parameterizations: streaklet-based and pixel-based. An emergent property of the streaklet-based optimization is head-to-tail streaklet alignment. It had been previously hypothesized the effectiveness of head-to-tail alignment results from the perceptual processing of the visual system, but this theory had not been computationally modeled. A second optimization using a pixel-based parameterization resulted in a LIC-like result. The implications in terms of the selection of primitives is discussed. We argue that computational models can be used for optimizing complex visualizations. In addition, we argue that they can provide a means of computationally evaluating perceptual theories of visualization, and as a method for quality control of display methods.	algorithm;area striata structure;artificial neural network;cerebral cortex;computation;computational model;data visualization;emergence;hill climbing;imagery;line integral convolution;mathematical optimization;neural network simulation;optimizing compiler;pixel;retina;utility	Daniel Pineo;Colin Ware	2012	IEEE Transactions on Visualization and Computer Graphics	10.1109/TVCG.2011.52	computer vision;simulation;computer science;hill climbing;machine learning;data visualization;artificial neural network	Visualization	23.54013429875102	-69.84216129485556	22238
3e5876c956aac9323d8f3588a21c4a435da037da	spiral waves in integrate-and-fire neural networks	integrate and fire;spiral wave;neural network	The formation of propagating spiral waves is studied in a randomly connected neural network composed of integrate-and-fire neurons with recovery period and excitatory connections using computer simulations. Network activity is initiated by periodic stimulation at a single point. The results suggest that spiral waves can arise in such a network via a sub-critical Hopf bifurcation.	bifurcation theory;biological neuron model;computer simulation;hopf bifurcation;neural networks;randomness;spiral wave	John G. Milton;Po Hsiang Chu;Jack D. Cowan	1992			simulation;telecommunications;computer science;machine learning;artificial neural network	ML	17.465517466431766	-70.43780011808828	22278
5435bd0b307d89121d8e8ef115a79fb99ba22339	computing interaction probabilities in signaling networks	signal image and speech processing;biological patents;biomedical journals;text mining;europe pubmed central;systems biology;citation search;citation networks;computational biology bioinformatics;biomedical engineering;research articles;abstracts;open access;life sciences;clinical guidelines;full text;rest apis;orcids;europe pmc;biomedical research;bioinformatics;literature search	Biological networks inherently have uncertain topologies. This arises from many factors. For instance, interactions between molecules may or may not take place under varying conditions. Genetic or epigenetic mutations may also alter biological processes like transcription or translation. This uncertainty is often modeled by associating each interaction with a probability value. Studying biological networks under this probabilistic model has already been shown to yield accurate and insightful analysis of interaction data. However, the problem of assigning accurate probability values to interactions remains unresolved. In this paper, we present a novel method for computing interaction probabilities in signaling networks based on transcription levels of genes. The transcription levels define the signal reachability probability between membrane receptors and transcription factors. Our method computes the interaction probabilities that minimize the gap between the observed and the computed signal reachability probabilities. We evaluate our method on four signaling networks from the Kyoto Encyclopedia of Genes and Genomes (KEGG). For each network, we compute its edge probabilities using the gene expression profiles for seven major leukemia subtypes. We use these values to analyze how the stress induced by different leukemia subtypes affects signaling interactions.		Haitham Gabr;Juan Carlos Rivera-Mulia;David M. Gilbert;Tamer Kahveci	2015	EURASIP J. Bioinformatics and Systems Biology	10.1186/s13637-015-0031-8	biology;text mining;medical research;computer science;bioinformatics;engineering;data science;data mining;biological engineering;systems biology	Comp.	7.5165867092070044	-58.826022294616706	22282
565ccf9e9b306bc2d8263e35dc54641b129b2eee	clinvar: public archive of interpretations of clinically relevant variants		ClinVar (https://www.ncbi.nlm.nih.gov/clinvar/) at the National Center for Biotechnology Information (NCBI) is a freely available archive for interpretations of clinical significance of variants for reported conditions. The database includes germline and somatic variants of any size, type or genomic location. Interpretations are submitted by clinical testing laboratories, research laboratories, locus-specific databases, OMIM®, GeneReviews™, UniProt, expert panels and practice guidelines. In NCBI's Variation submission portal, submitters upload batch submissions or use the Submission Wizard for single submissions. Each submitted interpretation is assigned an accession number prefixed with SCV. ClinVar staff review validation reports with data types such as HGVS (Human Genome Variation Society) expressions; however, clinical significance is reported directly from submitters. Interpretations are aggregated by variant-condition combination and assigned an accession number prefixed with RCV. Clinical significance is calculated for the aggregate record, indicating consensus or conflict in the submitted interpretations. ClinVar uses data standards, such as HGVS nomenclature for variants and MedGen identifiers for conditions. The data are available on the web as variant-specific views; the entire data set can be downloaded via ftp. Programmatic access for ClinVar records is available through NCBI's E-utilities. Future development includes providing a variant-centric XML archive and a web page for details of SCV submissions.	accession number (identifier);accession number (bioinformatics);aggregate data;archive;database;diploid cell;identifier;interpretation process;locus;laboratory;national center for biotechnology information;nomenclature;online mendelian inheritance in man;personnameuse - assigned;practice guidelines as topic;regulatory submission;remote control vehicle;single customer view;uniprot;upload;web page;xml;standards characteristics	Melissa J. Landrum;Jennifer M. Lee;Mark Benson;Garth R. Brown;Chen Chao;Shanmuga Chitipiralla;Baoshan Gu;Jennifer Hart;Douglas Hoffman;Jeffrey C Hoover;Wonhee Jang;Kenneth S. Katz;Michael Ovetsky;George R. Riley;Amanjeev Sethi;Ray E. Tully;Ricardo Villamarín-Salomón;Wendy S. Rubinstein	2016		10.1093/nar/gkv1222	bioinformatics	Web+IR	-2.9305535932109703	-61.072871310010015	22297
4ebbe28f4f8fcee637fa3a29d49bf2e693ca147b	dnafan: a software tool for automated extraction and analysis of user-defined sequence regions	software;outil logiciel;software tool;p16ink4a;logiciel;pattern search;bioinformatique;extraccion;5 fluorouracil;adjuvant chemotherapy;colorectal cancer;logicial;bioinformatica;false positive;herramienta software;thymidylate synthase;extraction;bioinformatics	SUMMARY DNAfan (DNA Feature ANalyzer) is a tool combining sequence-filtering and pattern searching. DNAfan automatically extracts user-defined sets of sequence fragments from large sequence sets. Fragments are defined by annotated gene feature keys and co- or non-occurring patterns within the feature or close to it. A gene feature parser and a pattern-based filter tool localizes and extracts the specific subset of sequences. The selected sequence data can subsequently be retrieved for analyses or further processed with DNAfan to find the occurrence of specific patterns or structural motifs. DNAfan is a powerful tool for pattern analysis. Its filter features restricts the pattern search to a well-defined set of sequences, allowing drastic reduction in false positive hits.   AVAILABILITY http://bighost.ba.itb.cnr.it:8080/Framework.	parser;pattern recognition;pattern search (optimization);programming tool;subgroup	Andreas Gisel;Maria Panetta;Giorgio Grillo;Flavio Licciulli;Sabino Liuni;Cecilia Saccone;Graziano Pesole	2004	Bioinformatics	10.1093/bioinformatics/bth420	pattern search;biology;extraction;type i and type ii errors;thymidylate synthase;computer science;bioinformatics;colorectal cancer;data mining;world wide web;genetics	Comp.	-3.959845252389454	-56.53761132030687	22320
46d51274b5ab18258bc5e0a12cd920415fa2a797	pattern recognition and massively distributed computing	screensavers;distributed computing;anthrax;pattern recognition;protein binding sites;inhibitors;anti cancer	A feature of Peter Kollman's research was his exploitation of the latest computational techniques to devise novel applications of the free energy perturbation method. He would certainly have seized upon the opportunities offered by massively distributed computing. Here we describe the use of over a million personal computers to perform virtual screening of 3.5 billion druglike molecules against protein targets by pharmacophore pattern matching, together with other applications of pattern recognition such as docking ligands without any a priori knowledge about the binding site location.		E. Keith Davies;Meir Glick;Karl N. Harrison;W. Graham Richards	2002	Journal of computational chemistry	10.1002/jcc.10107	theoretical computer science	HPC	0.3877435368410897	-64.92562364484365	22346
875c4443632ec09d2d7159fe73642c6603fa41eb	a novel 3-dimensional approach for cardiac regeneration	biological patents;biomedical journals;wounds biochemistry blood blood vessels calcium compounds cardiovascular system cellular biophysics drugs medical disorders microorganisms molecular biophysics muscle optimisation prosthetics proteins tissue engineering;text mining;europe pubmed central;citation search;heart proteins nitrogen in vitro production animals fibroblasts;citation networks;research articles;cacl 2 fibroblasts cellular compatibility in vitro vessel formation assay human umbilical vein endothelial cells collagen alginate microsphere scaffolds huvec formed networks 3 dimensional pattern healthy rat hearts tunable therapeutic approach viable therapeutic approach ischemic events protein release monodisperse populations extrusion velocity nozzle size nitrogen pressure modulation alginate microspheres optimization endothelial cells drugs implanted engineered tissues wound bed neovascularization wound healing process cardiomyocytes chronic ischemia acute ischemia heart muscle blood supply cardiovascular pathology microvascular disease coronary artery disease ischemic heart diseases cardiac regeneration 3 dimensional approach size 100 mum;abstracts;open access;life sciences;clinical guidelines;full text;rest apis;orcids;europe pmc;biomedical research;bioinformatics;literature search	Ischemic heart diseases, such as coronary artery disease and microvascular disease, are cardiovascular pathologies that cause reduced blood supply to the heart muscle. Acute and chronic ischemia cause cardiomyocytes to die, and these cells are not naturally replaced as part of the wound healing process in the heart. To promote neovascularization in the wound bed and in implanted engineered tissues, we have developed a collagen-alginate microspheres scaffold intended for local release of drugs and growth factors in order to recruit host endothelial cells to the area and provide them with geometrical cues to form new vessels. Optimization of alginate microspheres included modulation of nitrogen pressure, alginate and CaCl2 concentrations, nozzle size, and velocity of extrusion to achieve monodisperse populations of 100 μm diameter microspheres with protein release over 3 days. In vitro incorporation of fibroblasts in the bulk collagen demonstrated cellular compatibility with embedded alginate microspheres. An in vitro vessel formation assay, performed with human umbilical vein endothelial cells (HUVECs) immobilized in the collagen phase of the collagen-alginate microspheres scaffolds, showed that HUVECs formed networks following the 3-dimensional pattern of the microspheres even in the absence of growth factor. Implantation of acellular collagen-alginate microspheres scaffolds onto healthy rat hearts confirmed the invasion of host cells at one week. Together, these results suggest that the collagen-alginate microspheres scaffold is a viable, tunable therapeutic approach for directing neovascularization in engineered tissues and in the heart after ischemic events.	arteriopathic disease;artificial cardiac pacemaker;blood vessel tissue;body tissue;clinical regeneration;coronary artery disease;diameter (qualifier value);embedded system;embedding;growth factor;heart diseases;human umbilical vein endothelial cells;immobiliser;implants;ion implantation;medical device incompatibility problem;microspheres;modulation;muscle contraction;myocardial infarction;myocardial ischemia;myocardium;myocytes, cardiac;natural regeneration;nozzle device component;pathologic neovascularization;population;sinoatrial node;tissue engineering;umbilicus (anatomy);velocity (software development);alginate;cell growth;entry into host	F. Munarin;Kareen L K Coulombe	2015	2015 37th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)	10.1109/EMBC.2015.7318714	text mining;medical research;pathology;computer science;biological engineering;surgery	Visualization	12.472743991836527	-66.95050928477673	22383
0bf0cac2fce735670e1b3f9cdd21dab17295b53c	an integrative network approach to map the transcriptome to the phenome	genomics;artificial intelligence;algorithms;humans;phenotype;gene expression profiling	Although many studies have been successful in the discovery of cooperating groups of genes, mapping these groups to phenotypes has proved a much more challenging task. In this article, we present the first genome-wide mapping of gene coexpression modules onto the phenome. We annotated coexpression networks from 136 microarray datasets with phenotypes from the Unified Medical Language System (UMLS). We then designed an efficient graph-based simulated annealing approach to identify coexpression modules frequently and specifically occurring in datasets related to individual phenotypes. By requiring phenotype-specific recurrence, we ensure the robustness of our findings. We discovered 118,772 modules specific to 42 phenotypes, and developed validation tests combining Gene Ontology, GeneRIF and UMLS. Our method is generally applicable to any kind of abundant network data with defined phenotype association, and thus paves the way for genome-wide, gene network-phenotype maps.	gene regulatory networks;gene ontology;gene regulatory network;generif;map;microarray;phenome;phenotype;simulated annealing;unified medical language system	Michael R. Mehan;Juan Nunez-Iglesias;Mrinal Kalakrishnan;Michael S. Waterman;Xianghong Jasmine Zhou	2009	Journal of computational biology : a journal of computational molecular cell biology	10.1089/cmb.2009.0037	biology;genomics;bioinformatics;phenotype;data mining;gene expression profiling;genetics	Comp.	6.00067044507998	-56.36427672167696	22396
14f6716d826aadd6f152c70fab2538845a8f156e	eulerian emotion magnification for subtle expression recognition	motion magnification;classification;eulerian emotion magnification casme ii corpus svm classifier lbp top feature motion magnification microscopic world inspection microexpression facial muscle movement subtle expression recognition;emotion recognition face recognition feature extraction databases videos support vector machines training;subtle emotion;classification subtle emotion motion magnification micro expression recognition;support vector machines emotion recognition image classification;ta engineering general civil engineering general;micro expression recognition	Subtle emotions are expressed through tiny and brief movements of facial muscles, called micro-expressions; thus, recognition of these hidden expressions is as challenging as inspection of microscopic worlds without microscopes. In this paper, we show that through motion magnification, subtle expressions can be realistically exaggerated and become more easily recognisable. We magnify motions of facial expressions in the Eulerian perspective by manipulating their amplitudes or phases. To evaluate effects of exaggerating facial expressions, we use a common framework (LBP-TOP features and SVM classifiers) to perform 5-class subtle emotion recognition on the CASME II corpus, a spontaneous subtle emotion database. According to experimental results, significant improvements in recognition rates of magnified micro-expressions over normal ones are confirmed and measured. Furthermore, we estimate upper bounds of effective magnification factors and empirically corroborate these theoretical calculations with experimental data.	emotion recognition;fear, uncertainty and doubt;lagrangian and eulerian specification of the flow field;local binary patterns;regular expression;spontaneous order	Anh Cat Le Ngo;Yee-Hui Oh;Raphael C.-W. Phan;John See	2016	2016 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)	10.1109/ICASSP.2016.7471875	computer vision;speech recognition;biological classification;three-dimensional face recognition	Vision	24.560279367359893	-61.007978615043264	22497
a43744f87c11ea620d68c965433782506a683fc5	identifying haptic exploratory procedures by analyzing hand dynamics and contact force	shape information acquisition haptic exploratory procedures hand dynamics contact force prototypical hand movements object properties haptic perception ep identification model index finger position haptic exploratory behavior material properties hardness roughness temperature;exploratory movements;behavioral science;article letter to editor;touch;material properties haptic perception touch exploratory movements;perception;haptic interfaces;haptic perception;perception material properties behavioral science;material properties	Haptic exploratory procedures (EPs) are prototypical hand movements that are linked to the acquisition of specific object properties. In studies of haptic perception, hand movements are often classified into these EPs. Here, we aim to investigate several EPs in a quantitative manner to understand how hand dynamics and contact forces differ between them. These dissimilarities are then used to construct an EP identification model capable of discriminating between EPs based on the index finger position and contact force. The extent to which the instructed EPs were distinct, repeatable, and similar across subjects was confirmed by showing that more than 95 percent of the analyzed trials were classified correctly. Finally, the method is employed to investigate haptic exploratory behavior during similarity judgments based on several object properties. It seems that discrimination based on material properties (hardness, roughness, and temperature) yields more consistent classification results compared to discrimination based on the acquisition of shape information.	classification;depth perception;expectation propagation;exploratory testing;haptic device component;haptic technology;index finger;judgment;movement;rem sleep behavior disorder	Sander E. M. Jansen;Wouter M. Bergmann Tiest;Astrid M. L. Kappers	2013	IEEE Transactions on Haptics	10.1109/TOH.2013.22	stereotaxy;material properties;computer vision;simulation;behavioural sciences;perception	Robotics	13.8766083750786	-79.95412935387945	22501
1dd84979e192c5e802b6ef7b8838b1448f0e31b5	visualization and quality assessment of de novo genome assemblies	cytoscape software;ch availability;quality assessment;bioinformatics online;scaffolding information file;transcriptome sequence;genome scaffolding;fasta sequence;novo assembly;contiguous sequence;supplementary information	SUMMARY Recent technological progress has greatly facilitated de novo genome sequencing. However, de novo assemblies consist in many pieces of contiguous sequence (contigs) arranged in thousands of scaffolds instead of small numbers of chromosomes. Confirming and improving the quality of such assemblies is critical for subsequent analysis. We present a method to evaluate genome scaffolding by aligning independently obtained transcriptome sequences to the genome and visually summarizing the alignments using the Cytoscape software. Applying this method to the genome of the red fire ant Solenopsis invicta allowed us to identify inconsistencies in 7%, confirm contig order in 20% and extend 16% of scaffolds.   CONTACT oksana.ribagrognuz@unil.ch; yannick.wurm@unil.ch   AVAILABILITY Scripts that generate tables for visualization in Cytoscape from FASTA sequence and scaffolding information files are publicly available at https://github.com/ksanao/TGNet.   SUPPLEMENTARY INFORMATION Supplementary data are available at Bioinformatics online.	bioinformatics;chromosomes;cytoscape;data table;de novo transcriptome assembly;fasta format;imagery;pierre robin syndrome;whole genome sequencing	Oksana Riba-Grognuz;Laurent Keller;Laurent Falquet;Ioannis Xenarios;Yannick Wurm	2011	Bioinformatics	10.1093/bioinformatics/btr569	biology;bioinformatics;data mining;genetics	Comp.	-1.5662134076027818	-56.72951757290147	22504
19a4ae9ba77e6c0a40307ab6171a9dd1906eda24	a characterization of scale invariant responses in enzymatic networks	escherichia coli;metabolic networks and pathways;systems biology;models biological;chemotaxis;sensory systems;enzymes;differential equations;behavior;sensory physiology;erk signaling cascade;physiological adaptation	An ubiquitous property of biological sensory systems is adaptation: a step increase in stimulus triggers an initial change in a biochemical or physiological response, followed by a more gradual relaxation toward a basal, pre-stimulus level. Adaptation helps maintain essential variables within acceptable bounds and allows organisms to readjust themselves to an optimum and non-saturating sensitivity range when faced with a prolonged change in their environment. Recently, it was shown theoretically and experimentally that many adapting systems, both at the organism and single-cell level, enjoy a remarkable additional feature: scale invariance, meaning that the initial, transient behavior remains (approximately) the same even when the background signal level is scaled. In this work, we set out to investigate under what conditions a broadly used model of biochemical enzymatic networks will exhibit scale-invariant behavior. An exhaustive computational study led us to discover a new property of surprising simplicity and generality, uniform linearizations with fast output (ULFO), whose validity we show is both necessary and sufficient for scale invariance of three-node enzymatic networks (and sufficient for any number of nodes). Based on this study, we go on to develop a mathematical explanation of how ULFO results in scale invariance. Our work provides a surprisingly consistent, simple, and general framework for understanding this phenomenon, and results in concrete experimental predictions.	acclimatization;basal (phylogenetics);experiment;linear programming relaxation;mathematics;node - plant part;precipitating factors;saturated;signal-to-noise ratio	Maja Skataric;Eduardo D. Sontag	2012		10.1371/journal.pcbi.1002748	biology;biochemistry;artificial intelligence;escherichia coli;chemotaxis;ecology;genetics;systems biology;behavior	ML	8.273241085441684	-66.05892764043305	22517
313748989226592fe127911bd8a892808a949e2b	sequence analysis of the receptor activity-modifying proteins family, new putative peptides and structural conformation inferenc	recepteur biologique;prediccion;estructura 3 dimensiones;alignement sequence;biological receptor;proteine;conformation;bioinformatique;alineacion secuencia;data mining;structure 3 dimensions;receptor biologico;conformacion;fouille donnee;structure prediction;inferencia;analyse sequence;proteina;sequence alignment;bioinformatica;three dimensional structure;protein;ramp proteins;prediction;busca dato;inference;sequence alignments;bioinformatics	The Receptor Activity-Modifying Proteins (RAMP) is a family constituted by a single N-terminal extracellular domain and a transmembrane region ending in a short cytoplasmic region. Due to their specific role in modulating the specificity of ligand binding in many class II G-Protein Coupled Receptors, these proteins are awaiting further characterization and elucidation of their structure. This was the aim of this study. We were able to find 13 new RAMP sequences including new protein sequences and predicted peptides from Expressed Sequence Tags and genomic DNA, all of them annotated in databases such as GeneBank, EMBL, Swissprot and ENSEMBL. The predicted peptides came from an array of different organisms including Teleostei and Elasmobranchii species, of which the latter was the most ancient RAMP sequence found. It was also possible to efficiently predict the 1D structure of the extracellular RAMP domain and its 3D conformation was inferred through a combination of bioinformatic approaches such as threading. The 1D structure of the extracellular RAMP domain was predicted as three alpha-helix domain. The most highly conserved residues in the RAMP family were found to be involved in critical functions. Bioinformatic data mining and multiple sequence alignment analysis were crucial for improving the characterization of RAMP proteins and prediction of their 1D and 3D configurations.	amino acid sequence;bio-informatics;databases;elasmobranchii;inference;ligands;region of cytoplasm;swiss-prot;sequence alignment;sequence analysis;sequence tagged sites;teleostei;transmembrane domain;newton;receptor	Alfonso Benítez-Páez	2006	In silico biology		biology;prediction;computer science;bioinformatics;sequence alignment;genetics	Comp.	2.299934828792767	-59.443414046685874	22596
78b7805d345c3da048439ddc23eb1cdc7ddbb376	morphological gender recognition by a social robot and privacy concerns	morphological algorithms;social robots;gender recognition	An intuitive and robust user recognition system is at the key of a natural interaction between a social robot and its users. The gender of a new user can be guessed without explicitly asking it of her, which can then be used to personalize the interaction flow. In this LBR, a novel algorithm is used to estimate the gender of a person based on its morphological shape. More specifically, the vertical outline of the breast of the user is used to estimate his or her gender, based on similar shapes seen during training.  On early benchmarks with databases that represent well the diversity of human body shapes, the accuracy rate is close to 90% and outperforms a state-of-the-art algorithm. Our algorithm provides a fast and seamless estimation flow and needs limited computation resources, which tailor it for HRI. Its usefulness has been proved by integrating it in a social robot. However, its use raises concerns among the users about their privacy, which will lead to further study.	algorithm;benchmark (computing);computation;database;human–robot interaction;personalization;privacy;seamless3d;social robot	Arnaud A. Ramey;Miguel Angel Salichs	2014	2014 9th ACM/IEEE International Conference on Human-Robot Interaction (HRI)	10.1145/2559636.2563714	simulation;computer science;artificial intelligence;social robot	Robotics	23.81802893688389	-59.87598820687175	22618
8be8b9c9b8e35a6ea5e145670be5fd19d66fc6c2	image similarity models and the perception of artistic representations of natural images	databases;modelizacion;analisis contenido;object recognition;multimedia;image processing;procesamiento imagen;abstraction;hombre;multidimensional analysis;abstraccion;artist;traitement image;similitude;artiste;modelisation;artista;content analysis;analyse n dimensionnelle;percepcion visual;similarity;human;analisis n dimensional;perception visuelle;aparato visual;transformation non lineaire;transformacion no lineal;appareil visuel;visual perception;similitud;analyse contenu;modeling;visual system;vision;non linear transformation;homme;image retrieval	Next generation content-based retrieval systems for image and multimedia databases will benefit from utilizing higher level models of human visual processing. This includes incorporating models of early vision as well as more specialized areas like the IT cortex, which is thought to be important in object recognition. Artistic representation is typically based on abstraction of visual content in images. Analogies of various modes of artistic representation can be seen in scientific investigations of the visual system. These two observations suggest that an examination of traditional artistic representation may aid in constructing robust feature spaces for content abstraction in image retrieval. In addition, artistic renderings can be used to test the performance of models of image similarity in existing content-retrieval systems.	database;image retrieval;outline of object recognition	John C. Dalton	1997		10.1117/12.274549	computer vision;art;artificial intelligence;communication	Vision	23.510378449979964	-66.65472044929196	22624
8f67edc303376a4f54ef60f6e41777d54b03b437	integrating convolutional neural networks into a sparse distributed representation model based on mammalian cortical learning	pattern recognition convolution handwriting recognition learning artificial intelligence neural nets;biological neural networks pattern recognition brain modeling computational modeling computer architecture biological system modeling;sequence prediction convolutional neural networks sparse distributed representation model mammalian cortical learning brain inspired machine learning hierarchical temporal memory model htm model sequence recognition hybrid machine learning architecture handwritten digit recognition task pattern recognition performance sequence learning	Biological brains exhibit a remarkable capacity to recognise real-world patterns effectively. Despite major advances in neuroscience over the last few decades, an understanding of the brain's underlying mechanisms for pattern recognition remains unattained. Efforts to replicate such high-level brain functions on the basis of the limited, low-level known details of the brain have naturally led to critical assumptions that make brain-inspired machine learning possible. Convolutional neural networks are an example of such architectures, shown to produce state-of-the-art classification performance on practical applications. The Hierarchical Temporal Memory (HTM) model, on the other hand, performs pattern and sequence recognition on the basis of highly biologically plausible structure and operation. In this work we build on the strengths of convolutional neural networks by integrating them into the HTM framework. An analysis of the common and complementary features between the two models results in the proposal of an innovative, hybrid machine learning architecture. Practical tests on a handwritten digit recognition task reveal a 2% fall in pattern recognition performance, compared to that of the original convolutional neural network design. Nevertheless, key HTM features embedded in the novel architecture enable its potential future enhancement with sequence learning and prediction, an inexistent capability in traditional convolutional neural networks.	artificial neural network;convolutional neural network;embedded system;hierarchical temporal memory;high- and low-level;mnist database;machine learning;network planning and design;pattern recognition;self-replicating machine;sparse matrix	Daniel E. Padilla;Mark D. McDonnell	2016	2016 International Joint Conference on Neural Networks (IJCNN)	10.1109/IJCNN.2016.7727332	unsupervised learning;feature learning;types of artificial neural networks;feature;computer science;artificial intelligence;recurrent neural network;machine learning;pattern recognition;time delay neural network;deep learning;neocognitron;artificial neural network	ML	22.019099916235444	-53.75604965328972	22647
437246cdbafc51e715e235d80cf2122e9196849a	bistable oscillations arising from synaptic depression	34c15;oscillations;34c26;neuromodulation;synaptic plasticity;initial condition;periodic solution;bistability;inhibition;synaptic depression;short period;peripheral nervous system;short term plasticity;92c20;excitation	Synaptic depression is a common form of short-term plasticity in the central and peripheral nervous systems. We show that in a network of two reciprocally connected neurons a single depressing synapse can produce two distinct oscillatory regimes. These distinct periodic behaviors can be studied by varying the maximal conductance, ḡinh, of the depressing synapse. For small ḡinh, the network has a short-period solution controlled by intrinsic cellular properties. For large ḡinh, the solution has a much longer period and is controlled by properties of the synapse. We show that in an intermediate range of ḡinh values both stable periodic solutions exist simultaneously. Thus the network can switch oscillatory modes either by changing ḡinh or, for fixed ḡinh, by changing initial conditions.	conductance (graph);initial condition;maximal set;peripheral;synapse;synaptic package manager	Amitabha Bose;Yair Manor;Farzan Nadim	2001	SIAM Journal of Applied Mathematics	10.1137/S0036139900378050	synaptic plasticity;excitation;control theory;peripheral nervous system;bistability;oscillation;initial value problem;physics;quantum mechanics;neuromodulation	ML	17.528252278119375	-70.75370366952738	22729
f9c83b527a04db67886ab47c87ba822151a8bb85	accuracy-rejection curves (arcs) for comparing classification methods with a reject option		Data extracted from microarrays are now considered an important source of knowledge about various diseases. Several studies based on microarray data and the use of receiver operating characteristics (ROC) graphs have compared supervised machine learning approaches. These comparisons are based on classification schemes in which all samples are classified, regardless of the degree of confidence associated with the classification of a particular sample on the basis of a given classifier. In the domain of healthcare, it is safer to refrain from classifying a sample if the confidence assigned to the classification is not high enough, rather than classifying all samples even if confidence is low. We describe an approach in which the performance of different classifiers is compared, with the possibility of rejection, based on several reject areas. Using a tradeoff between accuracy and rejection, we propose the use of accuracy-rejection curves (ARCs) and three types of relationship between ARCs for comparisons of the ARCs of two classifiers. Empirical results based on purely synthetic data, semi-synthetic data (generated from real data obtained from patients) and public microarray data for binary classification problems demonstrate the efficacy of this method. c ©2010 Malik S.A. Nadeem, Jean-Daniel Zucker and Blaise Hanczar. Nadeem, Zucker and Hanczar	binary classification;biological anthropology;comparison shopping website;experiment;jean;machine learning;microarray;performance;receiver operating characteristic;rejection sampling;semiconductor industry;statistical classification;supervised learning;synthetic data;synthetic intelligence	Malik Sajjad Ahmed Nadeem;Jean-Daniel Zucker;Blaise Hanczar	2010			machine learning;pattern recognition;data mining;mathematics	ML	9.299574228559099	-74.30091823048315	22731
9a4b33d29dd911f346715edfae3416b38205c7f3	deciphering causal and statistical relations of molecular aberrations and gene expressions in nci-60 cell lines	simulation and modeling;rna neoplasm;systems biology;physiological cellular and medical topics;computational biology bioinformatics;dna copy number variations;cluster analysis;gene expression regulation neoplastic;cell line tumor;epigenesis genetic;algorithms;dna methylation;humans;neoplasms;computational biology;micrornas;computer simulation;mutation;bioinformatics	Cancer cells harbor a large number of molecular alterations such as mutations, amplifications and deletions on DNA sequences and epigenetic changes on DNA methylations. These aberrations may dysregulate gene expressions, which in turn drive the malignancy of tumors. Deciphering the causal and statistical relations of molecular aberrations and gene expressions is critical for understanding the molecular mechanisms of clinical phenotypes. In this work, we proposed a computational method to reconstruct association modules containing driver aberrations, passenger mRNA or microRNA expressions, and putative regulators that mediate the effects from drivers to passengers. By applying the module-finding algorithm to the integrated datasets of NCI-60 cancer cell lines, we found that gene expressions were driven by diverse molecular aberrations including chromosomal segments' copy number variations, gene mutations and DNA methylations, microRNA expressions, and the expressions of transcription factors. In-silico validation indicated that passenger genes were enriched with the regulator binding motifs, functional categories or pathways where the drivers were involved, and co-citations with the driver/regulator genes. Moreover, 6 of 11 predicted MYB targets were down-regulated in an MYB-siRNA treated leukemia cell line. In addition, microRNA expressions were driven by distinct mechanisms from mRNA expressions. The results provide rich mechanistic information regarding molecular aberrations and gene expressions in cancer genomes. This kind of integrative analysis will become an important tool for the diagnosis and treatment of cancer in the era of personalized medicine.	categories;causal filter;causality;copy number;dna binding site;dna computing;gene expression;genes, regulator;genome;methylation;micrornas;mutation;neoplasms;personalization;phenotype;proto-oncogene proteins c-myb;transcription factor;transcription (software);algorithm;cancer cell;citation;leukemia;study of epigenetics	Shyh-Dar Li;Tatsuaki Tagami;Ying-Fu Ho;Chen-Hsiang Yeang	2011		10.1186/1752-0509-5-186	computer simulation;mutation;biology;molecular biology;bioinformatics;dna methylation;cluster analysis;genetics;systems biology;microrna	Comp.	5.133838275771415	-58.411527291866335	22742
fc3b7dc6bdee2b59e5869bc53a78f264a7c99245	model-free analysis of brain fmri data by recurrence quantification	hemodynamic response;fmri;prior information;auto regressive;independent component analysis;recurrence quantification analysis;healthy subjects;functional magnetic resonance images;nonlinear dynamics;general linear model;temporal processing;contrast to noise ratio;supplementary motor area;model free	We propose a novel model-free univariate strategy for functional magnetic resonance imaging (fMRI) studies based upon recurrence quantification analysis (RQA). RQA is an auto-regressive method, which identifies recurrences in signals without any a priori assumptions. The performance of RQA is compared to that of univariate statistics based on a general linear model (GLM) and probabilistic independent component analysis (P-ICA) for a set of simulated and real fMRI data. RQA provides an appealing alternative to conventional GLM techniques, due to its exclusive feature of being model-free and of detecting potentially both linear and nonlinear dynamic processes, without requiring signal stationarity. The overall performance of the method compares positively also with P-ICA, another well-known model-free algorithm, which requires prior information to discriminate between different spatio-temporal processes. For simulated data, RQA is endowed with excellent accuracy for contrast-to-noise ratios greater than 0.2, and has a performance comparable to that of GLM for t(CNR)>or=0.8. For cerebral fMRI data acquired from a group of healthy subjects performing a finger-tapping task, (i) RQA reveals activations in the primary motor area contra-lateral to the employed hand and in the supplementary motor area, in agreement with the outcome of GLM analysis and (ii) identifies an additional brain region with transient signal changes. Moreover, RQA identifies signal recurrences induced by physiological processes other than BOLD (movement-related or of vascular origin). Finally, RQA is more robust than the GLM with respect to variations in the shape and timing of the underlying neuronal and hemodynamic responses which may vary between brain regions, subjects and tasks.	algorithm;bloc1s3 gene;broadcast delay;cardiomyoplasty;deconvolution;dynamical system;embedding;entropy (information theory);general linear model;hemodynamics;independent computing architecture;independent component analysis;indeterminacy in concurrent computation;influenza virus a h5 ica rna;lateral thinking;magnetic resonance imaging;map;motor neuron disease;nonlinear dynamics;nonlinear system;physiological processes;protocols documentation;quantitation;ref/rri - request patient referral status;rp (complexity);recurrence (disease attribute);recurrence plot;recurrence quantification analysis;recurrence relation;recurrent malignant neoplasm;recurrent neural network;sensor;shannon (unit);technological determinism;time series;voxel;fmri;neurocognitive;primary motor cortex	Marta Bianciardi;Paolo Sirabella;Gisela E. Hagberg;Alessandro Giuliani;Joseph P. Zbilut;Alfredo Colosimo	2007	NeuroImage	10.1016/j.neuroimage.2007.05.025	recurrence quantification analysis;independent component analysis;econometrics;speech recognition;nonlinear system;computer science;haemodynamic response;autoregressive model;statistics;contrast-to-noise ratio;general linear model	ML	21.763151228537232	-78.54564634301671	22764
545cfcf59281fae8da66d8520f720fd82b83ed96	changes in the fluctuation of interbeat intervals in spontaneously beating cultured cardiac myocytes: experimental and modeling studies	oscillations;coefficient of variation;cardiac myocyte;mathematical analysis;electrical coupling;van der pol oscillator	 Isolated and cultured neonatal cardiac myocytes contract spontaneously and cyclically, and have the properties of a non-linear oscillator. In this study, we have analyzed the relationship between the fluctuation of contraction rhythm of spontaneously beating cultured cardiac myocytes, and the coupling strength among them. The coefficient of variation of contraction intervals increased transiently in the early stages of incubation, and then decreased almost monotonically with time. The contraction rhythm of the myocytes became synchronized in the late stage of the culture. The day on which synchronization occurred almost coincided with the day when the coefficient of variation reached its lowest value. In addition, we have performed a mathematical analysis using interacting Bonhoeffer–van der Pol oscillators to clarify the mechanisms underlying the changes in the fluctuation of contraction rhythm with time. As the coupling strength among oscillators increased, the coefficient of variation of oscillation periods increased temporarily, but then decreased rapidly when the oscillators showed synchronization. These results suggest that the changes in the fluctuation of beating rhythm result from the increase in strength of electrical coupling among spontaneously beating cardiac myocytes.	artificial cardiac pacemaker;coefficient;coupling constant;interaction;mathematics;muscle cells;myocytes, cardiac;nonlinear system;oscillator device component;quantum fluctuation	Yoshiko Yamauchi;Akihiko Harada;Koichi Kawahara	2002	Biological Cybernetics	10.1007/s00422-001-0285-y	electronic engineering;coupling;engineering;electrical engineering;control theory;mathematics;oscillation;coefficient of variation;statistics;van der pol oscillator	Metrics	16.82631345219218	-71.58100060472289	22814
12d36335fada787640dd6e236038d75bd6191a77	development and preliminary validation of a dynamic, patient-tailored method to detect abnormal laboratory test results		Laboratory test results in primary care are flagged as 'abnormal' when they fall outside a population-based Reference Interval (RI), typically generating many alerts with a low specificity. In order to decrease alert frequency while retaining clinical relevance, we developed a method to assess dynamic, patient-tailored RIs based on mixed-effects linear regression models. Potassium test results from primary care were used as proof-of-concept test bed. Clinical relevance was assessed via a survey administered to general practitioners (GPs). Overall, the dynamic, patient-tailored method and the combination of both methods flagged 20% and 36% fewer values as abnormal than the population-based method. Nineteen out of 43 invited GPs (44%) completed the survey. The population-based method yielded a better sensitivity than the patient-tailored and the combined methods (0.51 vs 0.41 and 0.38, respectively) but a lower PPV (0.66 vs 0.67 and 0.76, respectively). We conclude that a combination of population-based and patient-tailored RIs can improve the detection of abnormal laboratory results. We suggest that lab values outside both RIs be flagged with high priority in clinical practice.	alert:type:point in time:^patient:nominal;general anesthetic drugs;laboratory procedures;normal range;patients;potassium;primary health care;rasl12 gene;relevance;sensitivity and specificity;testbed	Paolo Fraccaro;Benjamin Brown;Mattia C. F. Prosperi;Matthew Sperrin;Iain E. Buchan;Niels Peek	2015	Studies in health technology and informatics	10.3233/978-1-61499-564-7-701	data mining;clinical practice;linear regression;abnormal laboratory test;clinical significance;medicine;potassium test;population	HCI	7.621431948364736	-75.41245061272117	22825
670a95e2a576fec8ca907ad95253408e3c093bc5	structural and functional brain correlates of subclinical psychotic symptoms in 11–13 year old schoolchildren	healthy control;response inhibition;white matter;diffusion tensor images;fmri;inferior temporal;dti;schizophrenia;voxel based morphometry;structure and function;cognitive control;mri;gray matter;anterior cingulate;middle frontal gyrus;temporal cortex;fractional anisotropy;brain function;subjective assessment;psychotic like experiences children;high risk	Studying children experiencing psychotic symptoms provides a unique opportunity to examine the vulnerability to psychosis within the context of development. Using neuroimaging techniques this study investigated cognitive control functions, brain volumetrics and white matter integrity in an at-risk cohort of children. Between-subjects assessment of brain function and structure among 11 school-going, non-treatment seeking children aged 11-13 who were at symptomatic risk for psychosis (AR) and 14 healthy control children aged 11-12 without subclinical psychotic symptoms (CON). MRI assessments included functional measures of response inhibition and error-related processes, whole brain voxel-based morphometry (VBM) of gray matter (GM) and diffusion tensor imaging (DTI) utilizing fractional anisotropy to probe white matter (WM) integrity. fMRI results showed reduced activity in the AR group within right frontal and bilateral temporal cortex for response inhibition and reduced activity within the anterior cingulate, insula and middle frontal gyrus for error-related processing (p<.05, corrected). VBM analysis revealed GM increases in the AR group within middle and superior temporal gyri, angular gyrus, orbitofrontal gyrus and GM decrease within the inferior temporal gyrus (p<.05, corrected). DTI analysis identified WM decreases in the AR group along the inferior fronto-occipital fasciculus, cingulum and inferior longitudinal fasciculus (p<.05, corrected). This multimodal investigation revealed aberrant prefrontal-temporal dysfunction in addition to cingulate and insular dysfunctions which provide potential early neurocognitive risk markers related to the susceptibility for developing psychosis and subsequently the neurodevelopmental trajectory leading to schizophrenia.	angularjs;bilateral filter;brain;cognition disorders;control function (econometrics);diffusion tensor imaging;epilepsy, temporal lobe;evaluation procedure;focal (programming language);fascicle - nerve fibers;fractional anisotropy;frontal lobe gyrus;gray matter;insula of reil;middle frontal gyrus structure;morphometric analysis;morphometrics;multimodal interaction;neuroimaging;parahippocampal gyrus;psychoses, substance-induced;psychotic disorders;resting state fmri;schizophrenia;structure of inferior temporal gyrus;voxel;white matter;dinoflagellate cingulum;neurocognitive	Sarah Jacobson;Ian Kelleher;Michelle Harley;Aileen Murtagh;Mary Clarke;Mathieu Blanchard;Colm G Connolly;Erik O'Hanlon;Hugh Garavan;Mary Cannon	2010	NeuroImage	10.1016/j.neuroimage.2009.09.015	psychology;cognitive psychology;neuroscience;developmental psychology;radiology;medicine;magnetic resonance imaging;schizophrenia;fractional anisotropy	HCI	19.63198944948637	-79.74881869792235	22844
9fc19cb377f9bb635ebc8d7649c94186eb925b45	evolving neuromodulator architectures on non-associative learning tasks		Neuromodulation is an integral process in neural systems. Even the most well-studied neural circuits and organisms cannot be understood effectively without taking into account the effects of neuromodulators. The term neuromodulation refers to a broad range of phenomena, each of which has important computational distinctions. In this paper, we report on results measuring performance of differing forms of computational neuromodulation on a biologically meaningful, non-associative learning task. A novel neuroevolution approach, GasNEAT, is introduced and used to conduct the experiments. Findings indicate that, under certain conditions, networks with neuromodulation are more likely to evolve habituating behaviors than those without.	computation;experiment;neuroevolution;neuromodulation (medicine)	Jason Yoder	2017	2017 IEEE Symposium Series on Computational Intelligence (SSCI)	10.1109/SSCI.2017.8285214	associative property;machine learning;sensitization;biological neural network;neuroevolution;habituation;neuromodulation;artificial intelligence;computer science	Security	18.376127397082485	-69.78007257502686	22918
661a6c82900a2e9962ef7921d1143543a00e54fc	youtube for patient education: a deep learning approach for understanding medical knowledge from user-generated videos		YouTube presents an unprecedented opportunity to explore how machine learning methods can improve healthcare information dissemination. We propose an interdisciplinary lens that synthesizes machine learning methods with healthcare informatics themes to address the critical issue of developing a scalable algorithmic solution to evaluate videos from a health literacy and patient education perspective. We develop a deep learning method to understand the level of medical knowledge encoded in YouTube videos. Preliminary results suggest that we can extract medical knowledge from YouTube videos and classify videos according to the embedded knowledge with satisfying performance. Deep learning methods show great promise in knowledge extraction, natural language understanding, and image classification, especially in an era of patient-centric care and precision medicine.	computer vision;deep learning;embedded system;informatics;machine learning;natural language understanding;precision medicine;scalability;user-generated content	Xiao Liu;Bin Zhang;Anjana Susarla;Rema Padman	2018	CoRR		patient education;deep learning;machine learning;artificial intelligence;computer science;knowledge extraction;precision medicine;knowledge management;contextual image classification;natural language understanding;health literacy;health informatics	ML	1.836831080620414	-73.26937175152892	22952
ea993bd668b8574f7f32ce0a6e84b39bf6014ffd	prediction of protein structures using a hopfield network	biology computing;genetic algorithms proteins macromolecules molecular configurations biology computing hopfield neural nets;programming language;hopfield network;molecular configurations;amino acid sequence;hopfield neural nets;proteins neural networks genetic algorithms sequences biological system modeling computational modeling hopfield neural networks amino acids biology computing computer networks;protein structure;proteins;molecular biology;macromolecules;silicon graphics hopfield network globular protein 3d structure amino acid sequence folding process pathways structural molecular biology computer simulated neural networks neural network models protein structure prediction genetic algorithms ga macromolecule structures primary sequence tertiary structure cytochrome b sub 562 core c;genetic algorithm;genetic algorithms;monte carlo simulation;3d structure;computer simulation;neural network	Under proper conditions, a globular protein adopts a unique three-dimensional structure that is encoded in this amino acid sequence. The theoretical prediction of this structure, and the pathways followed during the folding process constitute the most challenging and still unsolved problems of structural molecular biology. Computersimulated neural networks have recently gained much attention and the application of neural networks models toward a variety of problems associated with protein structure prediction. Several works have been explored the application of genetic algorithms and neural networks to the determination of the protein structure. There are several techniques of computational simulation that can be used to study structure os proteins as methods of Monte Carlo, Simulated Annealing, Genetic Algorithms and Neural Networks. This work aims discusses the possibilities to use neural networks in the study of macromolecule structures and presents a example of a Hopfield Network to predict the structure of a protein and discusses the results and possible future works using neural networks and genetic algorithms to design new proteins and drugs. This paper used a Hopfield Network to predict a primary sequence and the tertiary structure of the core of the Cytochrome b562. The neural network was implemented using the language of programming C and the simulations was running in a Silicon Graphics.	genetic algorithm;graphics;hopfield network;monte carlo method;neural networks;peptide sequence;protein structure prediction;simulated annealing;simulation	Luis P. B. Scott;Jorge Chahine;José R. Ruggiero	2000		10.1109/SBRN.2000.889756	computer simulation;genetic algorithm;computer science;bioinformatics;theoretical computer science;machine learning;artificial neural network	ML	11.919787098688994	-53.524466676632315	22975
d7d0e262a3d3cd0c446ebdb2d0bcf3ab3414540c	partition function and base pairing probabilities for rna-rna interaction prediction	partition function;prediccion;base pairing;probability;interaction;fonction partition;rna;particion;probabilidad;apareamiento base;probabilite;appariement base;partition;interaccion;prediction;base pair;funcion particion	MOTIVATION The RNA-RNA interaction problem (RIP) consists in finding the energetically optimal structure of two RNA molecules that bind to each other. The standard model allows secondary structures in both partners as well as additional base pairs between the two RNAs subject to certain restrictions that ensure that RIP is solvabale by a polynomial time dynamic programming algorithm. RNA-RNA binding, like RNA folding, is typically not dominated by the ground state structure. Instead, a large ensemble of alternative structures contributes to the interaction thermodynamics.   RESULTS We present here an O(N(6)) time and O(N(4)) dynamics programming algorithm for computing the full partition function for RIP which is based on the combinatorial notion of 'tight structures'. Albeit equivalent to recent work by H. Chitsaz and collaborators, our approach in addition provides a full-fledged computation of the base pairing probabilities, which relies on the notion of a decomposition tree for joint structures. In practise, our implementation is efficient enough to investigate, for instance, the interactions of small bacterial RNAs and their target mRNAs.   AVAILABILITY The program rip is implemented in C. The source code is available for download from http://www.combinatorics.cn/cbpc/rip.html and http://www.bioinf.uni-leipzig.de/Software/rip.html.	algorithm;base pairing;computation (action);download;dynamic programming;ground state;interaction;partition function (mathematics);polynomial;probability;rna binding;rna folding;source code;thermodynamics;time complexity	Fenix W. D. Huang;Jing Qin;Christian M. Reidys;Peter F. Stadler	2009	Bioinformatics	10.1093/bioinformatics/btp481	biology;combinatorics;base pair;theoretical computer science;mathematics;genetics;algorithm;statistics	Comp.	11.829728992700385	-61.694398145695544	22978
ebead0b1ff78b4873b6477d9b51a6f7d4492f4e0	magic: access portal to a cross-platform gene expression compendium for maize	genomics;database;annotations;ibcn;settore agr 07 genetica agraria;biology and life sciences	To facilitate the exploration of publicly available Zea mays expression data, we constructed a maize expression compendium, making use of an integration methodology and a consistent probe to gene mapping based on the 5b.60 sequence release of Z. mays. The compendium is made available through a web portal MAGIC that hosts a variety of analysis tools to easily browse and analyze the data. Our compendium is different from previous initiatives in combining expression values across different experiments by providing a consistent gene annotation across different platforms.	browsing;chromosome mapping;compendium;experiment;gene annotation;gene expression;corn extract	Qiang Fu;Ana Carolina Fierro;Pieter Meysman;Aminael Sánchez-Rodríguez;Klaas Vandepoele;Kathleen Marchal;Kristof Engelen	2014	Bioinformatics	10.1093/bioinformatics/btt739	biology;genomics;computer science;bioinformatics;data mining;world wide web	Comp.	-1.9842915637056717	-59.11819970070365	22979
35c63042ef0d9b1871872b6931f493e4cde5a6f4	comparison of genomes using high-performance parallel computing	dna;dynamic programming;biology computing;dna nucleotide genome comparison parallel computing dna sequence microcomputer homologous gene dynamic programming xanthomonas genome organism homologous genes comparison amino acid;genomics bioinformatics parallel processing dna organisms microcomputers proteins sequences amino acids costs;nucleotides;amino acid;genetics;microcomputers dynamic programming biology computing genetics dna computational complexity parallel algorithms;gene expression;xanthomonas campestris pv campestris;computational complexity;parallel computer;dna sequence;high performance;microcomputers;parallel algorithms	Comparison of the DNA sequences and genes of two genomes can be useful to investigate the common functionalities of the corresponding organisms and get a better understanding of how the genes or groups of genes are organized and involved in several functions. In this paper we use high-performance parallel computing to compare the whole genomes of two organisms, namely Xanthomonas axonopodis pv. citri and Xanthomonas campestris pv. campestris, each with more than five million basepairs. Our purpose is two-fold. First we intend to exploit the high-performance power of a cluster of low-cost microcomputers, propose a parallel solution to this problem, and show its feasibility with implementation and performance results. Second we do additional comparisons of the two genomes by locating and compare not only the homologous genes (expressed in terms of the 20-letter amino acids) but also compare the regions or gaps (in terms of the 4letter DNA nucleotides) between the corresponding homologous genes. We have implemented the proposed comparison strategy to compare the two genomes Xanthomonas axonopodis pv. citri (Xac) and Xanthomonas campestris pv. campestris (Xcc). The parallel platform used is a Beowulf cluster of 64 nodes consisting of low cost microcomputers. Xac has 5,175,554 base pairs and 4,313 proteincoding genes while Xcc has 5,076,187 base pairs and 4,182 protein-coding genes. The parallel solution is based on the dynamic programming approach and presents not only less processing time, but also better quality results as compare d to approaches based on Blast and EGG. ∗ Partially supported by CNPq. † Partially supported by FINEP-PRONEX-SAI Proc. No. 76.97.1022.00, CNPq, FAPESP Proc. No. 1997/10982-0. ‡ Partially supported by CNPq Grants No. 52.3778/96-1, 55.20 28/02-9.	blast;beowulf cluster;dynamic programming;fold (higher-order function);microcomputer;parallel computing;solar cell	Nalvo F. de Almeida;Carlos Eduardo Rodrigues Alves;Edson Cáceres;Siang Wun Song	2003		10.1109/CAHPC.2003.1250332	dna sequencing;nucleotide;gene expression;amino acid;computer science;bioinformatics;dynamic programming;microcomputer;parallel algorithm;computational complexity theory;dna	HPC	-1.7218031973377772	-52.26206621704603	23016
d606960494308dc300b45a24710df7b77db217e3	semantic integration and exploitation of orthology information and genetic disorders		Translational bioinformatics includes research on the development of novel techniques for the integration of biological and clinical data and the evolution of clinical informatics methodology to encompass biological observations. In this way, the integration of information about gene-related diseases with information about gene orthology would be very helpful for clinical investigations.	bioinformatics;homology (biology);informatics;semantic integration	José Antonio Miñarro-Giménez;Marisa Madrid;Jesualdo Tomás Fernández-Breis	2009			semantic integration;translational bioinformatics;data mining;health informatics;bioinformatics;computer science	Comp.	-3.8209342604265073	-63.54474440835352	23062
75116430b3eb9890b3b1e5d6cc72816292f6ac97	sequence type analysis and recombinational tests (start)	sequence type;software;programa;mammalia;analisis datos;recombinaison;artiodactyla;logiciel;bacterie;bovino;selection;ungulata;bioinformatique;vertebrata;estructura poblacion;data analysis;bovine;estructura datos;population structure;recombination;analyse donnee;structure donnee;recombinacion;bacteria;bioinformatica;seleccion;data structure;structure population;bioinformatics;bovin	UNLABELLED The 32-bit Windows application START is implemented using Visual Basic and C(++) and performs analyses to aid in the investigation of bacterial population structure using multilocus sequence data. These analyses include data summary, lineage assignment, and tests for recombination and selection.   AVAILABILITY START is available at http://outbreak.ceid.ox.ac.uk/software.htm.   CONTACT keith.jolley@ceid.ox.ac.uk	32-bit;crossover (genetic algorithm);lineage (evolution);microsoft windows;recombination, genetic;visual basic	Keith A. Jolley;Edward J Feil;Man-Suen Chan;Martin C. J. Maiden	2001	Bioinformatics	10.1093/bioinformatics/17.12.1230	biology;selection;data structure;bacteria;computer science;bioinformatics;multilocus sequence typing;data analysis;genetics;recombination	Comp.	-3.944960002152966	-56.220301236872984	23090
5d00556fee9eaa4272787ae6aae01a38d79337e2	microinspector: a web tool for detection of mirna binding sites in an rna sequence	software;base pairing;rna messenger;binding site;binding sites;gene expression;internet;user computer interface;energy value;sequence analysis rna;micrornas;microrna;requirement specification	Regulation of post-transcriptional gene expression by microRNAs (miRNA) has so far been validated for only a few mRNA targets. Based on the large number of miRNA genes and the possibility that one miRNA might influence gene expression of several targets simultaneously, the quantity of ribo-regulated genes is expected to be much higher. Here, we describe the web tool MicroInspector that will analyse a user-defined RNA sequence, which is typically an mRNA or a part of an mRNA, for the occurrence of binding sites for known and registered miRNAs. The program allows variation of temperature, the setting of energy values as well as the selection of different miRNA databases to identify miRNA-binding sites of different strength. MicroInspector could spot the correct sites for miRNA-interaction in known target mRNAs. Using other mRNAs, for which such an interaction has not yet been described, we discovered frequently potential miRNA binding sites of similar quality, which can now be analysed experimentally. The MicroInspector program is easy to use and does not require specific computer skills. The service can be accessed via the MicroInspector web server at http://www.imbb.forth.gr/microinspector.	binding sites;database;databases;experiment;gene expression;micrornas;rna sequence;registration;server (computing);sex hormone-binding globulin;transcription, genetic;web server	Ventsislav Rusinov;Vesselin Baev;Ivan Nikiforov Minkov;Martin Tabler	2005	Nucleic Acids Research	10.1093/nar/gki364	biology;molecular biology;bioinformatics;binding site;genetics;microrna	Comp.	0.4536635522377585	-58.77801856803441	23125
0fbb6e54cc98a0fd7aeee5a1cd1fa7a37760ca2e	time-series infectious disease data analysis using svm and genetic algorithm	svm classifier time series infectious disease data analysis support vector machine genetic algorithm dengue health threat climatic factors disease incidence trend mosquito to human loop human to mosquito loop;support vector machines;time series;climatic factor;time series climatology diseases genetic algorithms health care medical computing support vector machines;medical computing;data analysis;time lag;diseases;genetic algorithm;diseases data analysis support vector machines genetic algorithms humans blood vaccines support vector machine classification temperature dependence temperature distribution;genetic algorithms;support vector machine;infectious disease;classification accuracy;climatology;health care	Dengue represents a serious health threat in the Tropics, owing to the year-round presence of Aedes mosquito vectors, and the lack of any anti-viral drugs or vaccines. Climatic factors are important in influencing the incidence of dengue. It is important to determine the relationships between climatic factors and disease incidence trends, which would be helpful for relevant environment and health agencies in planning appropriate pre-emptive control measures. Climatic factors and dengue case records vary over time. It is therefore difficult to justify the time-lag when a climatic factor affects the mosquito-to-human and human-to-mosquito loops. In this paper, we propose to use support vector machine (SVM) classifiers for analyzing the time- series dengue data and genetic algorithm (GA), to determine the time-lags and subset of climatic factors as effective factors influencing the spread of dengue. It is shown that the proposed model is able to detect important climatic factors and their time-lags which affect the disease, and the GA-based SVM classifiers could improve the classification accuracy significantly.	genetic algorithm;incidence matrix;software release life cycle;support vector machine;time series	Xiuju Fu;Christina Liew;Harold Soh;Gary Kee Khoon Lee;Terence Hung;Lee-Ching Ng	2007	2007 IEEE Congress on Evolutionary Computation	10.1109/CEC.2007.4424617	support vector machine;genetic algorithm;infectious disease;computer science;bioinformatics;machine learning;data mining	AI	4.2627195066199635	-75.95925477888485	23142
9d9292c4eabfb52da38f5ccc3dafc2f828fbfa95	automatic classification of epilepsy types using ontology-based and genetics-based machine learning	data mining knowledge discovery from medical data;genetics based classification;ontology based classification;epileptogenic zone identification	OBJECTIVES In the presurgical analysis for drug-resistant focal epilepsies, the definition of the epileptogenic zone, which is the cortical area where ictal discharges originate, is usually carried out by using clinical, electrophysiological and neuroimaging data analysis. Clinical evaluation is based on the visual detection of symptoms during epileptic seizures. This work aims at developing a fully automatic classifier of epileptic types and their localization using ictal symptoms and machine learning methods.   METHODS We present the results achieved by using two machine learning methods. The first is an ontology-based classification that can directly incorporate human knowledge, while the second is a genetics-based data mining algorithm that learns or extracts the domain knowledge from medical data in implicit form.   RESULTS The developed methods are tested on a clinical dataset of 129 patients. The performance of the methods is measured against the performance of seven clinicians, whose level of expertise is high/very high, in classifying two epilepsy types: temporal lobe epilepsy and extra-temporal lobe epilepsy. When comparing the performance of the algorithms with that of a single clinician, who is one of the seven clinicians, the algorithms show a slightly better performance than the clinician on three test sets generated randomly from 99 patients out of the 129 patients. The accuracy obtained for the two methods and the clinician is as follows: first test set 65.6% and 75% for the methods and 56.3% for the clinician, second test set 66.7% and 76.2% for the methods and 61.9% for the clinician, and third test set 77.8% for the methods and the clinician. When compared with the performance of the whole population of clinicians on the rest 30 patients out of the 129 patients, where the patients were selected by the clinicians themselves, the mean accuracy of the methods (60%) is slightly worse than the mean accuracy of the clinicians (61.6%). Results show that the methods perform at the level of experienced clinicians, when both the methods and the clinicians use the same information.   CONCLUSION Our results demonstrate that the developed methods form important ingredients for realizing a fully automatic classification of epilepsy types and can contribute to the definition of signs that are most important for the classification.		Yohannes Kassahun;Roberta Perrone;Elena De Momi;Elmar Berghöfer;Laura Tassi;Maria Paola Canevini;Roberto Spreafico;Giancarlo Ferrigno;Frank Kirchner	2014	Artificial intelligence in medicine	10.1016/j.artmed.2014.03.001	data mining	ML	3.609222953632101	-77.73828988463349	23145
d6d4b1e34626ea4c72aeddac15caad11ab177fa6	comparing manual and automated extraction of chemical entities from documents	biological patents;biomedical journals;text mining;europe pubmed central;citation search;computer applications in chemistry;citation networks;theoretical and computational chemistry;computational biology bioinformatics;research articles;abstracts;open access;life sciences;clinical guidelines;full text;rest apis;orcids;europe pmc;documentation and information in chemistry;biomedical research;bioinformatics;literature search	The chemical information landscape is changing rapidly with a yearly increase of over 1 million new compounds and more than 700,000 publications related to chemistry [1]. Exploring the chemical space covered by relevant journals and patents is a crucial step in early stage medicinal chemistry projects. Extracting chemical entities from unstructured text is a complex task and different approaches are currently used including manual extraction by expert curators, text mining supported by chemical NER or combinations thereof [2]. The chemical information and corresponding annotations are subsequently stored in relational databases allowing for complex chemical and text queries. To assess the capability of chemical NER in documents and to understand the coverage and accuracy of the underlying data we compared the chemistry extracted by manual curation (GVKBIO) and text mining (SureChem) from a small patent corpus. • GVKBIO databases are populated with explicit relationships between compounds, assays and sequence identifiers that have been manually extracted from journals and patents on a large scale [3]. • SureChem Portal [4] is a gateway for chemical patent search on full text collections for USPTO, EPO and WO. SureChem users can perform structure and keyword searches on more than 9 million unique compounds. We have selected a set of 250 patents covering various target classes and for which a minimum of 25 records per patents were retrieved from GVKBIO Patent database. The analysis was done using PipelinePilot protocols [5]. These initial results demonstrate the benefits and challenges of text mining for chemical information extraction from unstructured text.	assisted gps;chemical space;cheminformatics;digital curation;entity;identifier;information extraction;medicinal chemistry;named-entity recognition;population;relational database;text mining	Christian Tyrchan;Sorel Muresan	2010		10.1186/1758-2946-2-S1-P7	text mining;medical research;computer science;bioinformatics;data science;data mining;information retrieval	ML	-2.650605005483313	-63.07899802757727	23176
ea4f8fe24d700327890a83f13579b60ccbc31bdd	the neural hawkes process: a neurally self-modulating multivariate point process		Many events occur in the world. Some event types are stochastically excited or inhibited—in the sense of having their probabilities elevated or decreased—by patterns in the sequence of previous events. Discovering such patterns can help us predict which type of event will happen next and when. We model streams of discrete events in continuous time, by constructing a neurally self-modulating multivariate point process in which the intensities of multiple event types evolve according to a novel continuous-time LSTM. This generative model allows past events to influence the future in complex and realistic ways, by conditioning future event intensities on the hidden state of a recurrent neural network that has consumed the stream of past events. Our model has desirable qualitative properties. It achieves competitive likelihood and predictive accuracy on real and synthetic datasets, including under missing-data conditions.	artificial neural network;causal filter;excite;generative model;long short-term memory;missing data;point process;recurrent neural network;reinforcement learning;synthetic intelligence	Hongyuan Mei;Jason Eisner	2017			computer science;artificial intelligence;machine learning;data mining;statistics	ML	19.29137755423538	-63.581609701953695	23213
2b2e0baeab2dd458fde85574e34cf9659e959fe1	the apparent enhancement of cpg transversions in primate lineage is a consequence of multiple replacements	transitions;homo sapiens;cpg hypermutability;transversions	We claim that the apparently enhanced CpG transversions in the form CpG to CpC/GpG or to ApG/CpT are caused by the hypermutable CpG to CpA/TpG transition. The nucleotide replacement counts obtained from the human/chimpanzee/gorilla/orangutan sequence alignments representing the replacements due to the evolutionary species divergence and the results of 1000 genomes project that provide us with the differences due to the intraspecies diversification were analyzed to estimate the ratio of CpG versus non-CpG transversion probabilities. The trinucleotide replacement counts were extracted from the regions that are free of functional constraints. The CpG transversion probabilities based upon the genomic comparisons were found to exceed more than twice the non-CpG transversions. The diversity data emerging from 14 population groups were partitioned in five classes as a function of the parameter quantifying the spread of the polymorphic allele among the group of individuals. The results based upon the human polymorphism exhibit a trend where CpG over non-CpG transversion probability ratio is less and less exceeding unity as the values of the derived allele frequency (DAF) of snps are diminishing. A computer simulation of a simplified model indicates that the phenomenon of the apparent enhancement of CpG transversions can have its source in the interference of the entropic effects with the maximum likelihood methodologies.		Branko Borstnik;Danilo Pumpernik	2014	Journal of bioinformatics and computational biology	10.1142/S0219720014500115	models of dna evolution;biology;genetics	Comp.	3.931850233540233	-62.06371357410692	23216
38bb1cae47106cc90fdf986f1b1ae7c8ff4a5a80	information theoretic self-organised adaptation in reservoirs for temporal memory tasks	intrinsic plasticity;time series;delayed response;recurrent neural network;information theoretic;reservoir computing	Recurrent neural networks of the Reservoir Computing (RC) type have been found useful in various time-series processing tasks with inherent non-linearity and requirements of temporal memory. Here with the aim to obtain extended temporal memory in generic delayed response tasks, we combine a generalised intrinsic plasticity mechanism with an information storage based neuron leak adaptation rule in a self-organised manner. This results in adaptation of neuron local memory in terms of leakage along with inherent homeostatic stability. Experimental results on two benchmark tasks confirm the extended performance of this system as compared to a static RC and RC with only intrinsic plasticity. Furthermore, we demonstrate the ability of the system to solve long temporal memory tasks via a simulated T-shaped maze navigation scenario.	artificial neural network;benchmark (computing);computation;computational neuroscience;expectation–maximization algorithm;homeostasis;memory leak;neuron;noether's theorem;nonlinear system;phil bernstein;recurrent neural network;requirement;reservoir computing;robot;self-organization;simulation;spectral leakage;theory;time series	Sakyasingha Dasgupta;Florentin Wörgötter;Poramate Manoonpong	2012		10.1007/978-3-642-32909-8_4	computer science;artificial intelligence;theoretical computer science;machine learning	ML	18.759232370218367	-68.1985449053347	23249
2e5c339f1bb9b391e54e2f84189fa859a8bd2818	feedback control architecture and the bacterial chemotaxis network	escherichia coli;chemotactic factors;bacterial chemotaxis;systems biology;rhodobacter sphaeroides;bacterial physiological phenomena;models biological;system performance;journal article;cascade control;chemotaxis;signalling pathway;feedback physiological;parametric uncertainty;biology and other natural sciences;reproducibility of results;environmental change;linear models;feedback control;bacterial proteins	Bacteria move towards favourable and away from toxic environments by changing their swimming pattern. This response is regulated by the chemotaxis signalling pathway, which has an important feature: it uses feedback to 'reset' (adapt) the bacterial sensing ability, which allows the bacteria to sense a range of background environmental changes. The role of this feedback has been studied extensively in the simple chemotaxis pathway of Escherichia coli. However it has been recently found that the majority of bacteria have multiple chemotaxis homologues of the E. coli proteins, resulting in more complex pathways. In this paper we investigate the configuration and role of feedback in Rhodobacter sphaeroides, a bacterium containing multiple homologues of the chemotaxis proteins found in E. coli. Multiple proteins could produce different possible feedback configurations, each having different chemotactic performance qualities and levels of robustness to variations and uncertainties in biological parameters and to intracellular noise. We develop four models corresponding to different feedback configurations. Using a series of carefully designed experiments we discriminate between these models and invalidate three of them. When these models are examined in terms of robustness to noise and parametric uncertainties, we find that the non-invalidated model is superior to the others. Moreover, it has a 'cascade control' feedback architecture which is used extensively in engineering to improve system performance, including robustness. Given that the majority of bacteria are known to have multiple chemotaxis pathways, in this paper we show that some feedback architectures allow them to have better performance than others. In particular, cascade control may be an important feature in achieving robust functionality in more complex signalling pathways and in improving their performance.	architecture as topic;cascade device component;chemotaxis;computer architecture;control flow;experiment;feedback;gene regulatory network;homology (biology);signal transduction;biological signaling	Abdullah Hamadeh;Mark A. J. Roberts;Elias August;Patrick E. McSharry;Philip K. Maini;Judith P. Armitage;Antonis Papachristodoulou	2011		10.1371/journal.pcbi.1001130	biology;microbiology;chemotaxis;ecology;genetics;systems biology	AI	6.918969362328546	-62.56322292945537	23262
048620344e2cfd1df5eee267dbb446df9e525349	extending association rule summarization techniques to assess risk of diabetes mellitus	mathematics of computing;information technology and systems;emr association rule summarization techniques diabetes mellitus risk assessment association rule mining electronic medical records prediabetic patient cohort buttom up summarization bus algorithm high risk patients;association rule summarization;association rules;data mining;classification;database management;clustering;statistical computing;survival analysis;diabetes patient monitoring biomedical monitoring mathematical model statistical analysis database systems data mining clustering methods classification;risk management data mining electronic health records patient diagnosis;database applications;data mining mathematics of computing probability and statistics statistical computing survival analysis information technology and systems database management database applications clustering classification and association rules;probability and statistics;and association rules	Early detection of patients with elevated risk of developing diabetes mellitus is critical to the improved prevention and overall clinical management of these patients. We aim to apply association rule mining to electronic medical records (EMR) to discover sets of risk factors and their corresponding subpopulations that represent patients at particularly high risk of developing diabetes. Given the high dimensionality of EMRs, association rule mining generates a very large set of rules which we need to summarize for easy clinical use. We reviewed four association rule set summarization techniques and conducted a comparative evaluation to provide guidance regarding their applicability, strengths and weaknesses. We proposed extensions to incorporate risk of diabetes into the process of finding an optimal summary. We evaluated these modified techniques on a real-world prediabetic patient cohort. We found that all four methods produced summaries that described subpopulations at high risk of diabetes with each method having its clear strength. For our purpose, our extension to the Buttom-Up Summarization (BUS) algorithm produced the most suitable summary. The subpopulations identified by this summary covered most high-risk patients, had low overlap and were at very high risk of diabetes.	algorithm;association rule learning;automatic summarization;database;differentiator;excalibur: morgana's revenge;redirection (computing)	György J. Simon;Pedro J. Caraballo;Terry M. Therneau;Steven S. Cha;Regina Castro;Peter W. Li	2015	IEEE Transactions on Knowledge and Data Engineering	10.1109/TKDE.2013.76	probability and statistics;association rule learning;biological classification;computer science;data science;data mining;database;survival analysis;cluster analysis;world wide web;computational statistics;statistics	ML	2.4447092132767207	-76.90836021558674	23319
a75fb76d5fc11ddba4ceffcfbf8d2a2dc4be80c3	rapid elemental analysis and provenance study of blumea balsamifera dc using laser-induced breakdown spectroscopy	least squares analysis;lasers;asteraceae;spectrum analysis;discriminant analysis;elements;provenance study;principal component analysis;blumea balsamifera dc;libs;china;pls da;pca;geography	Laser-induced breakdown spectroscopy (LIBS) was applied to perform a rapid elemental analysis and provenance study of Blumea balsamifera DC. Principal component analysis (PCA) and partial least squares discriminant analysis (PLS-DA) were implemented to exploit the multivariate nature of the LIBS data. Scores and loadings of computed principal components visually illustrated the differing spectral data. The PLS-DA algorithm showed good classification performance. The PLS-DA model using complete spectra as input variables had similar discrimination performance to using selected spectral lines as input variables. The down-selection of spectral lines was specifically focused on the major elements of B. balsamifera samples. Results indicated that LIBS could be used to rapidly analyze elements and to perform provenance study of B. balsamifera.	disintegration (morphologic abnormality);dopamine;elemental;linear discriminant analysis;papillon-lefevre disease;partial least squares regression;populus balsamifera ab.ige:acnc:pt:ser:qn;principal component analysis;algorithm	Xiaona Liu;Qiao Zhang;Zhisheng Wu;Xinyuan Shi;Na Zhao;Yanjiang Qiao	2014		10.3390/s150100642	computer science;analytical chemistry;linear discriminant analysis;physics;principal component analysis	ML	16.270277759052664	-56.83647592589309	23329
260db7723289ba22147d606d17696f8f11d31c4a	predicting the behaviour of the renal transplant waiting list in the pais valencia (spain) using simulation modeling	belief networks;discrete event simulation;kidney;medical administrative data processing;bayesian inference;pais valencia;discrete event simulation;renal transplant waiting list;simulation modeling	A discrete event simulation model has been set up in order to analyze the renal transplant waiting list in the País Valencià, one of the autonomous regions in which Spain is divided. The model combines the information of the arrival of the patients onto the list and the process of donations, which also depend on the number of kidneys provided by each donor. Bayesian inference has been used to take into account the uncertainty about the parameters of the input distributions (acceptance, donation and transplantation rates). After validating the model, predictions about the future behaviour of the waiting list have been done. Results indicate a decrease in the size of the waiting list in a short and middle term. Comparison with other strategies of simulation has been done in order to confirm the problem of underestimation of the variance of the expected simulation output.	autonomous robot;bayesian approaches to brain function;geographic coordinate system;mathematical model;simulation	Juan J. Abellán;Carmen Armero;David V. Conesa;Jordi Pérez-Panadés;Miguel A. Martínez-Beneito;Oscar Zurriaga;María J. García-Blasco;Herme Vanaclocha	2004	Proceedings of the 2004 Winter Simulation Conference, 2004.			Robotics	6.7314386578824985	-73.62502058219052	23478
78d65e870b725747dff6114321950b0399478665	understanding mysql internals - discovering and improving a great database			mysql	Sasha Pachev	2007			data mining;database;world wide web	DB	-3.8280990921097304	-61.980041090677126	23498
6d37c0ce135db1a8d7119fb0ef1cf5d90db8dbd1	priaxplore® - a novel technology platform for the identification of small molecule modulators of protein-protein interactions	biological patents;biomedical journals;text mining;europe pubmed central;citation search;computer applications in chemistry;citation networks;theoretical and computational chemistry;computational biology bioinformatics;research articles;abstracts;open access;life sciences;clinical guidelines;full text;rest apis;orcids;europe pmc;documentation and information in chemistry;biomedical research;bioinformatics;literature search	Protein-protein interactions (PPIs) are broadly recognized as an emerging target class for a whole new era in drug discovery. They show significant differences to classical target classes and have been regarded as “undruggable” for a long time. Priaxon AG has developed a unique, proprietary technology platform for PPI drug discovery. PriaXplore employs novel computational and synthetic approaches to address PPIs with small molecule modulators. PriaXplore utilizes Multicomponent Reactions (MCRs) to create an in silico search space of 200 million compounds pre-selected for PPI relevance. The PriaXplore in silico screening process combines independent descriptor systems to search the MCR product space with maximum speed and accuracy. This combination of independent description methods enables a highly efficient selection of potential hit compounds that are further filter by our in-house docking protocol PriaDock. As proteinprotein interaction sites are known to be very flexible and binding pockets of small molecule modulators may not be (fully) accessible in all protein structures, PriaDock uses multiple protein conformations derived from crystal/NMR structures or molecular dynamics simulations to account for this flexibility. Thus, smaller sets of compounds have to be synthesized and tested, lab resources are saved. PriaXplore has been validated by a successfully outlicensed Mdm2/p53 PPI inhibitor program. Currently PriaXplore is applied in several drug discovery projects which are run either as Priaxon in-house projects or as cooperations with Pharma partners.	docking (molecular);interaction;memory card reader;molecular dynamics;pixel density;relevance;simulation;synthetic intelligence	Susanne Eyrisch;Tobias Girschick;Günter Ross;Cédric Kalinski;Vladimir Khazak;Lutz Weber	2013		10.1186/1758-2946-5-S1-P35	biology;text mining;medical research;medicine;computer science;bioinformatics	Comp.	10.071946262112155	-59.38640851735011	23500
7cd4aba4991b7f39c227b97a1f2d533e34b6a969	scene segmentation by spike synchronization in reciprocally connected visual areas. ii. global assemblies and synchronization on larger space and time scales	oscillations;hebbian learning;time scale;visual areas;traveling wave;primary visual cortex;standard model;associative memory;orientation selectivity;phase correlation	 We present further simulation results of the model of two reciprocally connected visual areas proposed in the first paper [Knoblauch and Palm (2002) Biol Cybern 87:151–167]. One area corresponds to the orientation–selective subsystem of the primary visual cortex, the other is modeled as an associative memory representing stimulus objects according to Hebbian learning. We examine the scene-segmentation capability of our model on larger time and space scales, and relate it to experimental findings. Scene segmentation is achieved by attention switching on a time-scale longer than the gamma range. We find that the time-scale can vary depending on habituation parameters in the range of tens to hundreds of milliseconds. The switching process can be related to findings concerning attention and biased competition, and we reproduce experimental poststimulus time histograms (PSTHs) of single neurons under different stimulus and attentional conditions. In a larger variant the model exhibits traveling waves of activity on both slow and fast time-scales, with properties similar to those found in experiments. An apparent weakness of our standard model is the tendency to produce anti-phase correlations for fast activity from the two areas. Increasing the inter-areal delays in our model produces alternations of in-phase and anti-phase oscillations. The experimentally observed in-phase correlations can most naturally be obtained by the involvement of both fast and slow inter-areal connections; e.g., by two axon populations corresponding to fast-conducting myelinated and slow-conducting unmyelinated axons.	axon;behavior;biological anthropology;cerebral cortex;content-addressable memory;exhibits as topic;experiment;hebbian theory;inter-process communication;large;myelin sheath;neurons;physical object;population;simulation;synchronization (computer science);transcutaneous electric nerve stimulation;biologic segmentation;travel	Andreas Knoblauch;Günther Palm	2002	Biological Cybernetics	10.1007/s00422-002-0332-3	psychology;standard model;simulation;hebbian theory;artificial intelligence;wave;machine learning;communication;oscillation;phase correlation;physics;quantum mechanics	ML	17.686583050363065	-71.35168205162762	23568
3f9ad07640bf9755ccfd727af9134560a297492a	classification of toxicity effects of biotransformed hepatic drugs using optimized support vector machine		Measuring toxicity is an important step in drug development, and there is a high demand to develop computational models that can predict the drug toxicity risks. In this study, we used a dataset that consists of 553 drug samples that biotransformed in liver. The toxic effects were calculated for the current data are mutagenic, tumorigenic, irritant, and reproductive effects. The proposed model has two phases, in the first phase; sampling algorithms were utilized to solve the problem of imbalanced dataset, in the second phase, the Support Vector Machines (SVM) classifier was used to classify an unknown drug sample into toxic or non-toxic. Moreover, in our model, Dragonfly Algorithm (DA) was used to optimize SVM parameters such as the penalty parameter and kernel parameters. The experimental results demonstrated that the proposed model obtained high sensitivity to all toxic effects, which indicates that it could be used for the prediction of drug toxicity in the early stage of drug development.	support vector machine	Alaa Tharwat;Thomas Gabel;Aboul Ella Hassanien	2017		10.1007/978-3-319-64861-3_15	kernel (linear algebra);support vector machine;drug;computational model;drug sample;drug development;classifier (linguistics);computer science;gibbs sampling;pattern recognition;artificial intelligence	HCI	10.669185875174174	-52.34462177403693	23606
d7daf642151cbaf34113c5510aa5436c6451532a	computational investigation of the binding mode of bis(hydroxylphenyl)arenes in 17β-hsd1: molecular dynamics simulations, mm-pbsa free energy calculations, and molecular electrostatic potential maps	drug targeting;enzyme;molecular dynamic simulation;drug design;electrostatic potential;free energy calculation;article;breast cancer;active site;md simulation;binding free energy	17β-Hydroxysteroid dehydrogenase type 1 (17β-HSD1) catalyzes the last step of the estrogen biosynthesis, namely the reduction of estrone to the biologically potent estradiol. As such it is a potentially attractive drug target for the treatment of estrogen-dependent diseases like breast cancer and endometriosis. 17β-HSD1 belongs to the bisubstrate enzymes and exists as an ensemble of conformations. These principally differ in the region of the βFαG'-loop, suggesting a prominent role in substrate and inhibitor binding. Although several classes of potent non-steroidal 17β-HSD1 inhibitors currently exist, their binding mode is still unclear. We aimed to elucidate the binding mode of bis(hydroxyphenyl)arenes, a highly potent class of 17β-HSD1 inhibitors, and to rank these compounds correctly with respect to their inhibitory potency, two essential aspects in drug design. Ensemble docking experiments resulted in a steroidal binding mode for the closed enzyme conformations and in an alternative mode for the opened and occluded conformers with the inhibitors placed below the NADPH interacting with it synergically via π-π stacking and H-bond formation. Both binding modes were investigated by MD simulations and MM-PBSA binding free energy estimations using as representative member for this class compound 1 (50 nM). Notably, only the alternative binding mode proved stable and was energetically more favorable, while when simulated in the steroidal binding mode compound 1 was displaced from the active site. In parallel, ab initio studies of small NADPH-inhibitor complexes were performed, which supported the importance of the synergistic interaction between inhibitors and cofactor.	anabolism;boat dock;class;docking (molecular);drug delivery systems;drug design;endometriosis;estradiol;estrogens;estrone;experiment;interaction;mammary neoplasms;microtubule-associated proteins;molecular dynamics;multicanonical ensemble;obstruction;qm/mm;simulation;stacking;synergy;estrogen biosynthetic process;free energy;poly(tetramethylene succinate-co-tetramethylene adipate)	Matthias Negri;Maurizio Recanatini;Rolf W. Hartmann	2011	Journal of computer-aided molecular design	10.1007/s10822-011-9464-7	biochemistry;stereochemistry;enzyme;targeted drug delivery;chemistry;active site;breast cancer;organic chemistry;computational chemistry;electric potential;drug design	EDA	9.55208075093136	-62.07666011752643	23630
33a7b968effb9c9da7f11fd27c21f58d566f62e4	meta-analysis of age-related gene expression profiles identifies common signatures of aging	transcription genetic;gene expression profile;animals;liverpool;mice;rats;perfil;gen;age;profile;aging;meta analysis;analyse;repository;meta analisis;gene expression;metaanalysis;expression genique;identification;metaanalyse;gene;identificacion;cell cycle;university;analysis;humans;expresion genetica;gene expression profiling;immune response;profil;biological process;edad;analisis	MOTIVATION Numerous microarray studies of aging have been conducted, yet given the noisy nature of gene expression changes with age, elucidating the transcriptional features of aging and how these relate to physiological, biochemical and pathological changes remains a critical problem.   RESULTS We performed a meta-analysis of age-related gene expression profiles using 27 datasets from mice, rats and humans. Our results reveal several common signatures of aging, including 56 genes consistently overexpressed with age, the most significant of which was APOD, and 17 genes underexpressed with age. We characterized the biological processes associated with these signatures and found that age-related gene expression changes most notably involve an overexpression of inflammation and immune response genes and of genes associated with the lysosome. An underexpression of collagen genes and of genes associated with energy metabolism, particularly mitochondrial genes, as well as alterations in the expression of genes related to apoptosis, cell cycle and cellular senescence biomarkers, were also observed. By employing a new method that emphasizes sensitivity, our work further reveals previously unknown transcriptional changes with age in many genes, processes and functions. We suggest these molecular signatures reflect a combination of degenerative processes but also transcriptional responses to the process of aging. Overall, our results help to understand how transcriptional changes relate to the process of aging and could serve as targets for future studies.   AVAILABILITY http://genomics.senescence.info/uarrays/signatures.html.   SUPPLEMENTARY INFORMATION Supplementary data are available at Bioinformatics online.	apod gene;abnormal degeneration;aging-related process;antivirus software;apoptosis;bioinformatics;bioinformatics;biological markers;chi;caloric restriction;categories;cell aging;cell cycle;computation;electronic signature;energy metabolism;experiment;futures studies;giant axonal neuropathy 1;gene expression;genes, mitochondrial;graham scan;jasmine;jasminum officinale;microarray;modelling biological systems;process (computing);r language;systems biology;tai ji;transcription, genetic;transcriptional regulation	João Pedro de Magalhães;João Curado;George M. Church	2009	Bioinformatics	10.1093/bioinformatics/btp073	biology;meta-analysis;bioinformatics;analysis;genetics	Comp.	3.5161827978872764	-60.3218359829033	23642
856646ff2181f1303991af3332d9b7720da765c8	numerosity processing in early visual cortex	calcarine sulcus;erps;numerosity;visual cortex;visual processing	While parietal cortex is thought to be critical for representing numerical magnitudes, we recently reported an event-related potential (ERP) study demonstrating selective neural sensitivity to numerosity over midline occipital sites very early in the time course, suggesting the involvement of early visual cortex in numerosity processing. However, which specific brain area underlies such early activation is not known. Here, we tested whether numerosity-sensitive neural signatures arise specifically from the initial stages of visual cortex, aiming to localize the generator of these signals by taking advantage of the distinctive folding pattern of early occipital cortices around the calcarine sulcus, which predicts an inversion of polarity of ERPs arising from these areas when stimuli are presented in the upper versus lower visual field. Dot arrays, including 8-32dots constructed systematically across various numerical and non-numerical visual attributes, were presented randomly in either the upper or lower visual hemifields. Our results show that neural responses at about 90ms post-stimulus were robustly sensitive to numerosity. Moreover, the peculiar pattern of polarity inversion of numerosity-sensitive activity at this stage suggested its generation primarily in V2 and V3. In contrast, numerosity-sensitive ERP activity at occipito-parietal channels later in the time course (210-230ms) did not show polarity inversion, indicating a subsequent processing stage in the dorsal stream. Overall, these results demonstrate that numerosity processing begins in one of the earliest stages of the cortical visual stream.	adrenal cortex;calcarine sulcus;chandra–toueg consensus algorithm;data collection;depth perception;distance (graph theory);erp;electronic signature;groove;numerical analysis;optic nerve glioma, childhood;parietal lobe;programming paradigm;randomness;united states national institutes of health;visual cortex;visual hierarchy;polarity	Michele Fornaciai;Elizabeth M. Brannon;Marty G. Woldorff;Joonkoo Park	2017	NeuroImage	10.1016/j.neuroimage.2017.05.069	visual n1;developmental psychology;psychology;posterior parietal cortex;cognitive psychology;visual field;stimulus (physiology);calcarine sulcus;numerosity adaptation effect;visual cortex;n2pc	ML	17.709254631493327	-76.88548302957784	23647
2011b6de69df52f340d68534399ae2c326f07747	flexible, cluster-based analysis of the electronic medical record of sepsis with composite mixture models	aic;akaike information criterion;bic;bayesian information criterion;cmm;cluster analysis;composite mixture model;ed;emr;electronic health records;kpnc;kaiser permanente northern california;mcar;mice;mixture modeling;pam;risk stratification;sepsis;composite mixture model;electronic medical record;emergency department;missing completely at random;multivariate imputation using chained equations;partitioning around medoids	The widespread adoption of electronic medical records (EMRs) in healthcare has provided vast new amounts of data for statistical machine learning researchers in their efforts to model and predict patient health status, potentially enabling novel advances in treatment. In the case of sepsis, a debilitating, dysregulated host response to infection, extracting subtle, uncataloged clinical phenotypes from the EMR with statistical machine learning methods has the potential to impact patient diagnosis and treatment early in the course of their hospitalization. However, there are significant barriers that must be overcome to extract these insights from EMR data. First, EMR datasets consist of both static and dynamic observations of discrete and continuous-valued variables, many of which may be missing, precluding the application of standard multivariate analysis techniques. Second, clinical populations observed via EMRs and relevant to the study and management of conditions like sepsis are often heterogeneous; properly accounting for this heterogeneity is critical. Here, we describe an unsupervised, probabilistic framework called a composite mixture model that can simultaneously accommodate the wide variety of observations frequently observed in EMR datasets, characterize heterogeneous clinical populations, and handle missing observations. We demonstrate the efficacy of our approach on a large-scale sepsis cohort, developing novel techniques built on our model-based clusters to track patient mortality risk over time and identify physiological trends and distinct subgroups of the dataset associated with elevated risk of mortality during hospitalization.		Michael B. Mayhew;Brenden K. Petersen;Ana Paula Sales;John D. Greene;Vincent X. Liu;Todd S. Wasson	2017	Journal of biomedical informatics	10.1016/j.jbi.2017.11.015	medical record;data mining;mixture model;multivariate analysis;computer science;risk of mortality;cohort;probabilistic logic;sepsis	ML	4.759212972147827	-73.90971749010444	23813
d331553efc16d1e4a59b0d55f8acb09af6ee7848	optimization and practical use of composition based approaches towards identification and collection of genomic islands and their ontology in prokaryotes		Abstract   Motivation  Horizontally transferred genomic islands (islands, GIs) have been referred to as important factors which contribute towards bacterial evolution in general and particularly towards the emergences of pathogens and outbreak instances. The development of tools for identification of such elements and retracing their distribution will help to understand how such cases arise. Sequence composition has been used to identify GIs, infer their phylogeny; and determine their relative time of insertion. Collection of metadata on known GIs will enhance insight into horizontal gene transfer ontology and flow.    Results  This paper introduces the merger of SeqWord Genomic Islands Sniffer (SWGIS), which utilizes composition based approaches for identification of GIs in bacterial genomic sequences, and the Predicted Genomic Islands (Pre_GI) database, which houses 26,744 islands found in 2,407 bacterial plasmids and chromosomes. SWGIS is a standalone program that detects GIs using a set of optimized parametric measures with estimates of acceptable false positive and false negative rates. Pre_GI is a novel repository that includes island ontology and flux. This study furthermore illustrates the need for parametric optimization towards the prediction of GIs to minimize false negative and false positive predictions. In addition Pre_GI emphasizes the practicality of the compounded knowledge that the database affords in detection and visualization of ontological links between GIs.    Availability  SWGIS is freely available on the web at  http://www.bi.up.ac.za/SeqWord/sniffer/index.html , and Pre_GI is freely accessible at http://pregi.bi.up.ac.za/index.php.	program optimization	Rian Pierneef;Oliver Bezuidt;Oleg N. Reva	2015		10.1016/j.procs.2015.05.183	bioinformatics;data mining;world wide web	NLP	0.8699563640763467	-60.499804320647584	23856
a80147f60948d165ed8d2da1653d61e218294d14	a new method for modeling coalescent processes with recombination	evolution molecular;genetics population;computational biology bioinformatics;models genetic;algorithms;humans;combinatorial libraries;recombination genetic;computer appl in life sciences;markov chains;microarrays;bioinformatics	Recombination plays an important role in the maintenance of genetic diversity in many types of organisms, especially diploid eukaryotes. Recombination can be studied and used to map diseases. However, recombination adds a great deal of complexity to the genetic information. This renders estimation of evolutionary parameters more difficult. After the coalescent process was formulated, models capable of describing recombination using graphs, such as ancestral recombination graphs (ARG) were also developed. There are two typical models based on which to simulate ARG: back-in-time model such as ms and spatial model including Wiuf&Hein’s, SMC, SMC’, and MaCS. In this study, a new method of modeling coalescence with recombination, Spatial Coalescent simulator (SC), was developed, which considerably improved the algorithm described by Wiuf and Hein. The present algorithm constructs ARG spatially along the sequence, but it does not produce any redundant branches which are inevitable in Wiuf and Hein’s algorithm. Interestingly, the distribution of ARG generated by the present new algorithm is identical to that generated by a typical back-in-time model adopted by ms, an algorithm commonly used to model coalescence. It is here demonstrated that the existing approximate methods such as the sequentially Markov coalescent (SMC), a related method called SMC′, and Markovian coalescent simulator (MaCS) can be viewed as special cases of the present method. Using simulation analysis, the time to the most common ancestor (TMRCA) in the local trees of ARGs generated by the present algorithm was found to be closer to that produced by ms than time produced by MaCS. Sample-consistent ARGs can be generated using the present method. This may significantly reduce the computational burden. In summary, the present method and algorithm may facilitate the estimation and description of recombination in population genomics and evolutionary biology.	approximation algorithm;coalescing (computer science);computation;crossover (genetic algorithm);diploidy;entity name part qualifier - adopted;gene expression programming;genomics;graph - visual representation;markov chains;markov chain;markov model;metagenomics;most recent common ancestor;recombination, genetic;rendering (computer graphics);serpina2 gene;simulation;trees (plant);variation (genetics)	Ying Wang;Ying Zhou;Linfeng Li;Xian Chen;Yuting Liu;Zhiming Ma;Shuhua Xu	2014		10.1186/1471-2105-15-273	biology;markov chain;dna microarray;computer science;bioinformatics;genetics	Comp.	1.6278214764791086	-53.35477132748161	23861
d3cba3d366dd72551b0adbe1f109db000a6e6b22	the precuneus/posterior cingulate cortex plays a pivotal role in the default mode network: evidence from a partial correlation network analysis	effective connectivity;default mode;fmri;resting state;weak interaction;network analysis;functional connectivity;partial correlation;functional magnetic resonance images;medial temporal lobe;working memory;parietal lobe;medial prefrontal cortex;default mode network;long range;brain activation;posterior cingulate cortex;neuronal network;spontaneous fluctuations	Recent research has shown that intrinsic brain activity as observed by functional magnetic resonance imaging (fMRI) manifest itself as coherent signal changes in networks encompassing brain regions that span long-range neuronal pathways. One of these networks, the so called default mode network, has become the primary target in recent investigations to link intrinsic activity to cognition and how intrinsic signal changes may be altered in disease. In this study we assessed functional connectivity within the default mode network during both rest and a continuous working memory task on a region-by-region basis using partial correlation analysis, a data-driven method that provides insight into effective connectivity within neuronal networks. Prominent features of functional connectivity within the default mode network included an overall strong level of interaction between the precuneus/posterior cingulate region and the rest of the default mode network, as well as a high degree of interaction between the left and right medial temporal lobes combined with weak interactions between the medial temporal lobes and the rest of the default mode network. Additionally, we found support for strong interactions between the precuneus/posterior cingulate cortex and the left inferior parietal lobe as well as between the dorsal and ventral sections of the medial prefrontal cortex. The suggested pivotal role of the precuneus/posterior cingulate cortex in the default mode network is discussed.	acoustic lobing;air traffic control radar beacon system;cingulate cortex;cognition;coherence (physics);default;electroencephalography;gyrus cinguli;interaction;magnetic resonance imaging;medial graph;memory disorders;network theory;parietal lobe;prefrontal cortex;resting state fmri;span distance;structure of precuneus;temporal lobe	Peter Fransson;Guillaume Marrelec	2008	NeuroImage	10.1016/j.neuroimage.2008.05.059	psychology;cognitive psychology;default mode network;biological neural network;neuroscience;developmental psychology;task-positive network	AI	20.262451148458943	-77.12928845839029	23915
2c51c4020dd8a02ebd0c0cfceff70ef1cf69f536	autonomous learning with complex dynamics	modelizacion;attracteur;point attractor dynamics;complex dynamics;biological system;systeme intelligent;memoire associative;voie olfactive;cortex olfactif;comportement;corteza olfativa;systeme nerveux central;connectionism;learning;conexionismo;bulbe olfactif;sistema inteligente;simulacion numerica;olfactory cortex;complex neurodynamics;attractor;encefalo;olfactory pathway;dynamical system;atractor;aprendizaje;bulbo olfatorio;modelisation;systeme dynamique;sistema nervioso central;connexionnisme;systeme biologique;apprentissage;conducta;encephale;via olfatoria;simulation numerique;intelligent system;pattern recognition;neuromodulatory control;associative memory;memoria asociativa;reconnaissance forme;sistema dinamico;reseau neuronal;behavior;reconocimiento patron;modeling;olfactory bulb;red neuronal;autonomous learning;central nervous system;sistema biologico;neural network;numerical simulation;brain vertebrata	Abstract#R##N##R##N#Traditionally, associative memory models are based on point attractor dynamics, where a memory state corresponds to a stationary point in state space. However, biological neural systems seem to display a rich and complex dynamics whose function is still largely unknown. We use a neural network model of the olfactory cortex to investigate the functional significance of such dynamics, in particular with regard to learning and associative memory. the model uses simple network units, corresponding to populations of neurons connected according to the structure of the olfactory cortex. All essential dynamical properties of this system are reproduced by the model, especially oscillations at two separate frequency bands and aperiodic behavior similar to chaos. By introducing neuromodulatory control of gain and connection weight strengths, the dynamics can change dramatically, in accordance with the effects of acetylcholine, a neuromodulator known to be involved in attention and learning in animals. With computer simulations we show that these effects can be used for improving associative memory performance by reducing recall time and increasing fidelity. the system is able to learn and recall continuously as the input changes, mimicking a real world situation of an artificial or biological system in a changing environment. © 1995 John Wiley & Sons, Inc.	complex dynamics	Hans Liljenström	1995	Int. J. Intell. Syst.	10.1002/int.4550100109	connectionism;olfactory system;computer science;artificial intelligence	ML	20.947667105340955	-70.33764488706726	23929
d60e1de5d9a79ca2b6c4d0008ff41c60efe92c6f	comparing the performance of mathematical models for surgical decisions on head injury patients.	health research;uk clinical guidelines;biological patents;europe pubmed central;citation search;uk phd theses thesis;life sciences;uk research reports;medical journals;europe pmc;biomedical research;bioinformatics	an o e e This paper compares three mathematical models f surgical decisions on head injury patients. A logisti regression and two neural network models wer developed using a large clinical database. Usin randomly selected 9480 cases as the training group a another 3160 cases as the validation group. W evaluated the performance of a logistic regressio model, a multi-layer perceptron (MLP) neural net and a radial-basis-function (RBF) neural net in terms of thei accuracy in predicting physician’s decision on open skull surgery. The resultant area under ROC curve fo logistic regression, MLP and RBF neural nets are 0.761 0.897 and 0.880 respectively. The results suggest th neural networks may be a better solution for comple non-linear medical decision support systems tha conventional statistical techniques such as logisti regression.	artificial neural network;clinical decision support system;emoticon;layer (electronics);logistic regression;mathematical model;memory-level parallelism;multilayer perceptron;nonlinear system;quad flat no-leads package;radial (radio);radial basis function;randomness;receiver operating characteristic;resultant	Yu-Chuan Li;Li Liu;Ten-Fang Yang;Wen-Ta Chiu	1997			library science;medicine;data science;data mining	ML	7.514752496849586	-76.6751336621433	23938
6838322e950ca03c8aa19f8299b6c8a6ffce818f	interface similarity improves comparison of dna-binding proteins: the homeobox example	protein dna;substitution matrices;dna motif;homeobox;protein dna interface;recognition;homeodomains;transcription factor;specificity;capitulo de libro	The recently published 3D-footprint database contains an up-to-date repository of protein-DNA complexes of known structure that belong to different superfamilies and bind to DNA with distinct specificities. This repository can be scanned by means of sequence alignments in order to look for similar DNA-binding proteins, which might in turn recognize similar DNA motifs. Here we take the complete set of Homeobox proteins from Drosophila melanogaster and their preferred DNA motifs, which would fall in the largest 3D-footprint superfamily and were recently characterized by Noyes and collaborators, and annotate their interface residues. We then analyze the observed amino acid substitutions at equivalent interface positions and their effect on recognition. Finally we estimate to what extent interface similarity, computed over the set of residues which mediate DNA recognition, outperforms BLAST expectation values when deciding whether two aligned Homeobox proteins might bind to the same DNA motif.	blast;motif;superfamily;sequence alignment	Álvaro Sebastián;Carlos P. Cantalapiedra;Bruno Contreras-Moreira	2010		10.1007/978-3-642-28062-7_8	bioinformatics;genetics;homeobox;sequence motif;transcription factor	Comp.	1.9917063077849626	-60.219923761536535	23963
0a6c75627fc29c3543d7f7b5161d5a4452c5b762	from networks of protein interactions to networks of functional dependencies	simulation and modeling;saccharomyces cerevisiae;computer graphics;systems biology;saccharomyces cerevisiae proteins;molecular sequence annotation;physiological cellular and medical topics;peroxisomes;computational biology bioinformatics;proteins;algorithms;computational biology;protein interaction maps;bioinformatics	As protein-protein interactions connect proteins that participate in either the same or different functions, networks of interacting and functionally annotated proteins can be converted into process graphs of inter-dependent function nodes (each node corresponding to interacting proteins with the same functional annotation). However, as proteins have multiple annotations, the process graph is non-redundant, if only proteins participating directly in a given function are included in the related function node. Reasoning that topological features (e.g., clusters of highly inter-connected proteins) might help approaching structured and non-redundant understanding of molecular function, an algorithm was developed that prioritizes inclusion of proteins into the function nodes that best overlap protein clusters. Specifically, the algorithm identifies function nodes (and their mutual relations), based on the topological analysis of a protein interaction network, which can be related to various biological domains, such as cellular components (e.g., peroxisome and cellular bud) or biological processes (e.g., cell budding) of the model organism S. cerevisiae. The method we have described allows converting a protein interaction network into a non-redundant process graph of inter-dependent function nodes. The examples we have described show that the resulting graph allows researchers to formulate testable hypotheses about dependencies among functions and the underlying mechanisms.	anatomic node;annotation;bud - plant part;cell budding;functional dependency;graph - visual representation;interaction network;node - plant part;proteomics;requirement prioritization;staphylococcal protein a;algorithm;cellular bud;molecular_function;peroxisome;protein protein interaction	Davide Luciani;Gianfranco Bazzoni	2011		10.1186/1752-0509-6-44	computational biology;biology;peroxisome;computer science;bioinformatics;theoretical computer science;computer graphics;systems biology	Comp.	3.5054006446832084	-57.95169458844936	23976
764fde26d61b2393f071928afd5dea61daf5504d	an analysis of the recurrence-progression process in bladder carcinoma by means of joint frailty models	random effects;transitional cell carcinoma;articulo;bladder carcinoma;event dependence;frailty model;joint frailty model;survival time;survival analysis;recurrent events	Multiple sequential recurrences are one of themost important characteristics of superficial transitional cell carcinoma of the bladder, more than 50% of the patients will have recurrences (reappearance of a new superficial tumor). When in the same subject recurrent events are considered and these observed events are clustered into groups, independence between the clustered survival times cannot be assumed. A natural way to model the dependence of clustered event times is through the introduction of a clusterspecific random effect: the frailty term. On the other hand, between 10% and 30% of patients diagnosed with bladder carcinoma will present a muscle invasive progression, so the observation process of recurrences could be interrupted by a major failure event (progression). In this regard, a joint modelling of the two processes could make the study of a joint evolution over time possible, giving unbiased and efficient parameters. We jointly analyze recurrences and progression processes by means of the joint frailty model. © 2010 Elsevier Ltd. All rights reserved.	color gradient;interrupt;random effects model;recurrence relation;recurrent neural network;the superficial	Cristina Santamaría;Belén García-Mora;Gregorio Rubio;S. Luján	2011	Mathematical and Computer Modelling	10.1016/j.mcm.2010.11.004	econometrics;mathematics;survival analysis;statistics;random effects model	AI	24.42569925040726	-75.56068158327948	23986
591d0967d1452d861bd8ad7689376ddae170d8da	comparative binding energy analysis of haloalkane dehalogenase substrates: modelling of enzyme-substrate complexes by molecular docking and quantum mechanical calculations	external validity;substrate specificity;docking substrate specifity design;quantum mechanical calculation;enzyme;complex i;binding affinity;long chain;3d structure;molecular docking;active site;binding energy;principal component	We evaluate the applicability of automated molecular docking techniques and quantum mechanical calculations to the construction of a set of structures of enzyme-substrate complexes for use in Comparative binding energy (COMBINE) analysis to obtain 3D structure-activity relationships. The data set studied consists of the complexes of eighteen substrates docked within the active site of haloalkane dehalogenase (DhlA) from Xanthobacter autotrophicus GJ10. The results of the COMBINE analysis are compared with previously reported data obtained for the same dataset from modelled complexes that were based on an experimentally determined structure of the DhlA-dichloroethane complex. The quality of fit and the internal predictive power of the two COMBINE models are comparable, but better external predictions are obtained with the new approach. Both models show a similar composition of the principal components. Small differences in the relative contributions that are assigned to important residues for explaining binding affinity differences can be directly linked to structural differences in the modelled enzyme-substrate complexes: (i) rotation of all substrates in the active site about their longitudinal axis, (ii) repositioning of the ring of epihalohydrines and the halogen substituents of 1,2-dihalopropanes, and (iii) altered conformation of the long-chain molecules (halobutanes and halohexanes). For external validation, both a novel substrate not included in the training series and two different mutant proteins were used. The results obtained can be useful in the future to guide the rational engineering of substrate specificity in DhlA and other related enzymes.	apache axis;combine;docking (molecular);docking -molecular interaction;eighteen;ethylene dichlorides;experiment;halogens;personnameuse - assigned;processor affinity;quantum mechanics;sensitivity and specificity;silo (dataset);haloalkane dehalogenase	Jan Kmunícek;Michal Bohác;Santos Luengo;Federico Gago;Rebecca C. Wade;Jiří Damborský	2003	Journal of computer-aided molecular design	10.1023/A:1026159215220	crystallography;biochemistry;stereochemistry;enzyme;chemistry;docking;external validity;active site;computational chemistry;ligand;binding energy;principal component analysis	Comp.	11.46195185458076	-59.183228258073214	23999
86891978f4097ee6a8e0faaf4b79fc241febfea5	vectorial magnetic stimulation of the human motor cortex				Shogo Ueno;Tsuruo Matsuda;Isao Ninoyama	1994	JRM	10.20965/jrm.1994.p0075	neuroscience;motor cortex;human brain;stimulation;physics	ML	19.721236358563225	-74.84662323181098	24007
06bd2418827b3881ec55717dbb02a59143c507b9	modeling overlapping execution/observation brain pathways	multi modality;humanoid robot;brain;evolutionary computation;agent based coevolutionary;brain modeling biological system modeling computer science computational modeling computer architecture computer vision robot vision systems laboratories humanoid robots humans;complex distributed systems;distributed computing system;modeling overlapping execution brain pathway;neurophysiology brain evolutionary computation;distributed computational system;brain imaging;observation brain pathways;neurophysiology;observation brain pathways modeling overlapping execution brain pathway distributed computational system agent based coevolutionary complex distributed systems multi modality	Recent brain imaging studies on primates revealed that a network of brain areas is activated both during observation and during execution of movements. The present work aims at modeling this group of areas, implementing a distributed computational system. The modeling process follows the agent-based coevolutionary framework that is very effective in terms of designing complex distributed systems addressing successfully the multi-modality of the interacting regions. The implemented model is successfully embedded in a simulated humanoid robot, replicating existing biological findings.	agent-based model;artificial intelligence;brain implant;computation;computational model;distributed computing;embedded system;humanoid robot;interaction;medical imaging;modality (human–computer interaction)	Michail Maniadakis;Emmanouil Hourdakis;Panos E. Trahanias	2007	2007 International Joint Conference on Neural Networks	10.1109/IJCNN.2007.4371138	computer vision;simulation;computer science;humanoid robot;artificial intelligence;machine learning;neurophysiology;evolutionary computation	Robotics	16.79933674170625	-66.69329010485244	24022
0b0b2ea9ec84fd3c6700491aa5a0006f3a62a03e	cardiac regeneration: different cells same goal	quality of life;embryonic stem cells;heart;cell differentiation;regeneration;extracellular matrix;universiteitsbibliotheek;cardiac development;somatic stem cells;cardiomyocytes;heart failure;cardiovascular disease;bone marrow transplantation;myocytes cardiac;stem cell transplantation;humans;heart transplantation;cardiac regeneration	Cardiovascular diseases are the leading cause of mortality, morbidity, hospitalization and impaired quality of life. In most, if not all, pathologic cardiac ischemia ensues triggering a succession of events leading to massive death of cardiomyocytes, fibroblast and extracellular matrix accumulation, cardiomyocyte hypertrophy which culminates in heart failure and eventually death. Though current pharmacological treatment is able to delay the succession of events and as a consequence the development of heart failure, the only currently available and effective treatment of end-stage heart failure is heart transplantation. However, donor heart availability and immunorejection upon transplantation seriously limit the applicability. Cardiac regeneration could provide a solution, making real a dream of both scientist and clinician in the previous century and ending an ongoing challenge for this century. In this review, we present a basic overview of the various cell types that have been used in both the clinical and research setting with respect to myocardial differentiation.	artificial cardiac pacemaker;cardiovascular diseases;cessation of life;clinical regeneration;extracellular matrix;fibroblasts;heart transplantation;heart failure;hospitalization;hypertrophy;morbidity - disease rate;myocardial ischemia;myocytes, cardiac;pharmacology;succession;tree accumulation	Phil Barnett;Maurice J. B. van den Hoff	2011		10.1007/s11517-011-0776-5	extracellular matrix;quality of life;adult stem cell;medicine;regeneration;biological engineering;cellular differentiation;heart;anatomy;cardiology;embryonic stem cell	HCI	6.4632254464112355	-69.84138208418378	24030
ab48a40b2ef1cf6e64a766c3a687d21891430353	detecting essential proteins based on network topology, gene expression data, and gene ontology information	gene expression profile protein protein interaction network essential proteins gene ontology;proteins network topology gene expression ontologies simulation electronics packaging;protein protein interaction network essential proteins gene ontology gene expression profile	The identification of essential proteins in protein-protein interaction PPI networks is of great significance for understanding cellular processes. With the increasing availability of large-scale PPI data, numerous centrality measures based on network topology have been proposed to detect essential proteins from PPI networks. However, most of the current approaches focus mainly on the topological structure of PPI networks, and largely ignore the gene ontology annotation information. In this paper, we propose a novel centrality measure, called TEO, for identifying essential proteins by combining network topology, gene expression profiles, and GO information. To evaluate the performance of the TEO method, we compare it with five other methods degree, betweenness, NC, Pec, and CowEWC in detecting essential proteins from two different yeast PPI datasets. The simulation results show that adding GO information can effectively improve the predicted precision and that our method outperforms the others in predicting essential proteins.		Wei Zhang;Jia Xu;Yuanyuan Li;Xiufen Zou	2018	IEEE/ACM transactions on computational biology and bioinformatics	10.1109/TCBB.2016.2615931	sox4;gatad2b;syt1;centrality;ontology (information science);protein function prediction;computer science;betweenness centrality;bioinformatics;network topology	Comp.	5.0940644962393415	-56.57552542085869	24042
d2ede224daf3dff43df28048c4959559022f600a	multiple grid arrangement improves ligand docking with unknown binding sites: application to the inverse docking problem	computational ligand docking;conformational search space;drug–target interactions;inverse docking;multiple grid arrangement;scoring function;structure-based drug design;virtual screening	The identification of comprehensive drug-target interactions is important in drug discovery. Although numerous computational methods have been developed over the years, a gold standard technique has not been established. Computational ligand docking and structure-based drug design allow researchers to predict the binding affinity between a compound and a target protein, and thus, they are often used to virtually screen compound libraries. In addition, docking techniques have also been applied to the virtual screening of target proteins (inverse docking) to predict target proteins of a drug candidate. Nevertheless, a more accurate docking method is currently required. In this study, we proposed a method in which a predicted ligand-binding site is covered by multiple grids, termed multiple grid arrangement. Notably, multiple grid arrangement facilitates the conformational search for a grid-based ligand docking software and can be applied to the state-of-the-art commercial docking software Glide (Schrödinger, LLC). We validated the proposed method by re-docking with the Astex diverse benchmark dataset and blind binding site situations, which improved the correct prediction rate of the top scoring docking pose from 27.1% to 34.1%; however, only a slight improvement in target prediction accuracy was observed with inverse docking scenarios. These findings highlight the limitations and challenges of current scoring functions and the need for more accurate docking methods. The proposed multiple grid arrangement method was implemented in Glide by modifying a cross-docking script for Glide, xglide.py. The script of our method is freely available online at http://www.bi.cs.titech.ac.jp/mga_glide/.		Tomohiro Ban;Masahito Ohue;Yutaka Akiyama	2018	Computational biology and chemistry	10.1016/j.compbiolchem.2018.02.008	grid;docking (dog);bioinformatics;drug discovery;ligand (biochemistry);target protein;virtual screening;binding site;biology;ligand	Comp.	11.355670161795341	-59.76406303834576	24091
713e5df0b34dd8f5773febe34587243480a7191e	an alignment-free approach for eukaryotic its2 annotation and phylogenetic inference	phylogeny;methods;rna folding;molecular sequence annotation;dna ribosomal spacer;sequence databases;molecular graphs;edge adjacency matrix;hidden markov models;eukaryota;dna structure;secondary structure;gene prediction;topological indexes;psidium guajava l;nucleic acid conformation;algorithms;biology and life sciences;genetic neural networks;sequence alignment;multiple sequence alignment;ascomycetes;qsar;neural networks computer;phylogenetic relationship;multiple alignment calculation;spectral moments;prediction;phylogenetic inference;phylogenetics;genome sequence;topological indices;artificial neural network;phylogenetic analysis	The ITS2 gene class shows a high sequence divergence among its members that have complicated its annotation and its use for reconstructing phylogenies at a higher taxonomical level (beyond species and genus). Several alignment strategies have been implemented to improve the ITS2 annotation quality and its use for phylogenetic inferences. Although, alignment based methods have been exploited to the top of its complexity to tackle both issues, no alignment-free approaches have been able to successfully address both topics. By contrast, the use of simple alignment-free classifiers, like the topological indices (TIs) containing information about the sequence and structure of ITS2, may reveal to be a useful approach for the gene prediction and for assessing the phylogenetic relationships of the ITS2 class in eukaryotes. Thus, we used the TI2BioP (Topological Indices to BioPolymers) methodology [1], [2], freely available at http://ti2biop.sourceforge.net/ to calculate two different TIs. One class was derived from the ITS2 artificial 2D structures generated from DNA strings and the other from the secondary structure inferred from RNA folding algorithms. Two alignment-free models based on Artificial Neural Networks were developed for the ITS2 class prediction using the two classes of TIs referred above. Both models showed similar performances on the training and the test sets reaching values above 95% in the overall classification. Due to the importance of the ITS2 region for fungi identification, a novel ITS2 genomic sequence was isolated from Petrakia sp. This sequence and the test set were used to comparatively evaluate the conventional classification models based on multiple sequence alignments like Hidden Markov based approaches, revealing the success of our models to identify novel ITS2 members. The isolated sequence was assessed using traditional and alignment-free based techniques applied to phylogenetic inference to complement the taxonomy of the Petrakia sp. fungal isolate.	altretamine;ankle brachial pressure index (observable entity);annotation;artificial neural network;ascomycota (fungus);class;complement system proteins;computational phylogenetics;dialign-tx;diplodia rosulata;emoticon;ephrin type-b receptor 1, human;euclidean distance;gene prediction;genus (mathematics);geographic information systems;graphium tynderaeus;hidden markov model;inference;internal transcribed spacer;krt76 gene;leotiomycetes;linkage (software);mafft;macintosh common lisp;markov chain;mesna;multiple sequence alignment;needleman–wunsch algorithm;neighbor joining;netware;neural network simulation;oidiodendron;performance;rna folding;receiver operating characteristic;single linkage cluster analysis;smith–waterman algorithm;tiff;tpo wt allele;tyro3 gene;taxonomy;test set;topological index;tracer;trees (plant);untranslated regions;ustilago avenae;x11 color names;genetic linkage;salal mycorrhizal fungus ubctra43;statistical cluster	Guillermín Agüero-Chapín;Aminael Sánchez-Rodríguez;Pedro I. Hidalgo-Yanes;Yunierkis Pérez-Castillo;Reinaldo Molina Ruiz;Kathleen Marchal;Vítor Vasconcelos;Agostinho Antunes	2011		10.1371/journal.pone.0026638	biology;whole genome sequencing;prediction;multiple sequence alignment;bioinformatics;sequence alignment;quantitative structure–activity relationship;genetics;dna;gene prediction;alignment-free sequence analysis;protein secondary structure;phylogenetics	Comp.	4.154885303411177	-57.48702310305239	24126
a1b1017cb94edc44742e33b035de787ea08f5d1b	embracing noise to improve cross-batch prediction accuracy	animals;simulation and modeling;mice;systems biology;physiological cellular and medical topics;computational biology bioinformatics;stochastic processes;statistics as topic;reproducibility of results;algorithms;humans;computational biology;prognosis;oligonucleotide array sequence analysis;bioinformatics	One important application of microarray in clinical settings is for constructing a diagnosis or prognosis model. Batch effects are a well-known obstacle in this type of applications. Recently, a prominent study was published on how batch effects removal techniques could potentially improve microarray prediction performance. However, the results were not very encouraging, as prediction performance did not always improve. In fact, in up to 20% of the cases, prediction accuracy was reduced. Furthermore, it was stated in the paper that the techniques studied require sufficiently large sample sizes in both batches (train and test) to be effective, which is not a realistic situation especially in clinical settings. In this paper, we propose a different approach, which is able to overcome limitations faced by conventional methods. Our approach uses ranking value of microarray data and a bagging ensemble classifier with sequential hypothesis testing to dynamically determine the number of classifiers required in the ensemble. Using similar datasets to those in the original study, we showed that in only one case (< 2%) is our performance reduced (by more than -0.05 AUC) and, in > 60% of cases, it is improved (by more than 0.05 AUC). In addition, our approach works even on much smaller training data sets and is independent of the sample size of the test data, making it feasible to be applied on clinical studies.	area under curve;ensemble learning;excision;microarray;sample size;scientific publication;small;test data	Chuan Hock Koh;Limsoon Wong	2012		10.1186/1752-0509-6-S2-S3	biology;computer science;bioinformatics;data science;data mining;systems biology;algorithm	AI	7.925817048409956	-53.06030256592738	24233
9435263a56c16e11bfac90d38bedc0b647986f12	spliceseq: a resource for analysis and visualization of rna-seq data on alternative splicing and its functional impacts	software;alternative splicing;computer graphics;algorithms;sequence analysis rna	SUMMARY SpliceSeq is a resource for RNA-Seq data that provides a clear view of alternative splicing and identifies potential functional changes that result from splice variation. It displays intuitive visualizations and prioritized lists of results that highlight splicing events and their biological consequences. SpliceSeq unambiguously aligns reads to gene splice graphs, facilitating accurate analysis of large, complex transcript variants that cannot be adequately represented in other formats.   AVAILABILITY AND IMPLEMENTATION SpliceSeq is freely available at http://bioinformatics.mdanderson.org/main/SpliceSeq:Overview. The application is a Java program that can be launched via a browser or installed locally. Local installation requires MySQL and Bowtie.   CONTACT mryan@insilico.us.com   SUPPLEMENTARY INFORMATION Supplementary data are available at Bioinformatics online.	alternative splicing;bioinformatics;bowtie (sequence analysis);graph - visual representation;imagery;java programming language;mysql;rna splicing;reading (activity);splice (system call);transcript;format	Michael C. Ryan;James A. Cleland;RyangGuk Kim;Wing Chung Wong;John N. Weinstein	2012		10.1093/bioinformatics/bts452	biology;computer science;bioinformatics;alternative splicing;data mining;computer graphics;world wide web;genetics	Comp.	-2.0944583525861837	-57.678356253333014	24249
ccb2b3da12932e33e6dc155f3988ac31b0beb88c	protherm, version 4.0: thermodynamic database for proteins and mutants		Release 4.0 of ProTherm, thermodynamic database for proteins and mutants, contains approximately 14,500 numerical data (approximately 450% of the first version) of several thermodynamic parameters along with experimental methods and conditions, and structural, functional and literature information. The sequence and structural information of proteins is connected with thermodynamic data through links between entries in Protein Data Bank, Protein Information Resource and SWISS-PROT and the data in ProTherm. We have separated the Gibbs free energy change obtained at extrapolated temperature from the data on denaturation temperature measured by the thermal denaturation method. We have added the statistics of amino acid replacements and links to homologous structures to each protein. Further, we have improved the search and display options to enhance search capability through the web interface. ProTherm is freely available at http://gibk26. bse.kyutech.ac.jp/jouhou/Protherm/protherm.html.	amino acids;extrapolation;geographic information systems;homology (biology);level of measurement;protein data bank;protein information resource;swiss-prot;surgical replantation;switzerland;thermodynamics;user interface;free energy;mutant	K. Abdulla Bava;M. Michael Gromiha;Hatsuho Uedaira;Koji Kitajima;Akinori Sarai	2004	Nucleic acids research	10.1093/nar/gkh082		Comp.	-1.444988309781569	-60.310236029314495	24329
a9a1b5681f6adab1e116c4e9ce4f01b1944c374b	multidimensional analysis of fetal growth curves	personalized diagnosis;big data techniques multidimensional analysis fetal growth curves fetal biometry fetal well being assessment ultrasound images reference charts pathological size biometric parameter gestational age pregnancy phase environmental factors open source software;distributed databases information management data handling data storage systems data models ultrasonic imaging pediatrics;multidimensional analysis;public domain software;data analysis;big data;multidimensional analysis cloud computing fetal growth personalized diagnosis;public domain software big data data analysis medical diagnostic computing obstetrics;medical diagnostic computing;obstetrics;cloud computing;fetal growth	Fetal biometry is considered the keystone in fetal well-being assessment. In particular, fetal growth curves built by means of ultrasound images and reference charts (defining the normal and pathological sizes for each biometric parameter and for each gestational age) are extensively adopted to track fetal sizes from the early phases of pregnancy up to delivery. In literature a large variety of reference charts are reported to consider the differences among different ethnic groups, but they are up to five decades old and they do not consider environmental factors such as foods, lifestyle, smoke, familial aspects, physiological and pathological variables, temporal parameters etc., which cannot be disregarded in a correct diagnosis. Therefore, current reference charts are rapidly becoming inadequate to support the melting pot of ethnic groups and lifestyles of our society, while customized reference charts can provide an accurate fetal assessment for the different fetal anthropometrical variables. Starting from a detailed analysis of the limits of classical reference charts, the paper presents a new method, based on multidimensional analysis for creating personalized fetal growth curves. A simple implementation, based on Open Source software and simulated data, shows the need of Big Data techniques in order to scale up the problem.	anthropometry;big data;biometrics;biostatistics;chart;keystone effect;multidimensional analysis;open-source software;personalization	Mario A. Bochicchio;Antonella Longo;Lucia Vaira;Antonio Malvasi;Andrea Tinelli	2013	2013 IEEE International Conference on Big Data	10.1109/BigData.2013.6691754	computer science;data science;data mining;biological engineering	Vision	0.8295088756117215	-79.03467468967574	24356
249d454cff6eddb8ab18146569cbc39e9d162a92	robust volcano plot: identification of differential metabolites in the presence of outliers	classical volcano plot;differential metabolites;fold change;metabolomics;receiver operating characteristic (roc) curve	The identification of differential metabolites in metabolomics is still a big challenge and plays a prominent role in metabolomics data analyses. Metabolomics datasets often contain outliers because of analytical, experimental, and biological ambiguity, but the currently available differential metabolite identification techniques are sensitive to outliers. We propose a kernel weight based outlier-robust volcano plot for identifying differential metabolites from noisy metabolomics datasets. Two numerical experiments are used to evaluate the performance of the proposed technique against nine existing techniques, including the t-test and the Kruskal-Wallis test. Artificially generated data with outliers reveal that the proposed method results in a lower misclassification error rate and a greater area under the receiver operating characteristic curve compared with existing methods. An experimentally measured breast cancer dataset to which outliers were artificially added reveals that our proposed method produces only two non-overlapping differential metabolites whereas the other nine methods produced between seven and 57 non-overlapping differential metabolites. Our data analyses show that the performance of the proposed differential metabolite identification technique is better than that of existing methods. Thus, the proposed method can contribute to analysis of metabolomics data with outliers. The R package and user manual of the proposed method are available at https://github.com/nishithkumarpaul/Rvolcano.	experiment;kruskal's algorithm;laboratory sample manual;mammary neoplasms;metabolite;metabolomics;numerical analysis;outlier;r language;receiver operating characteristic;silo (dataset);volcano plot (statistics);t test	Nishith Kumar;Md. Aminul Hoque;Masahiro Sugimoto	2018		10.1186/s12859-018-2117-2	metabolomics;volcano plot;word error rate;receiver operating characteristic;metabolite;outlier;biology;bioinformatics;artificial intelligence;pattern recognition	SE	5.251331255505608	-52.44883214616529	24390
fb23da66ff8782ab361adc7834df037b1880ab06	high-resolution generative adversarial neural networks applied to histological images generation		For many years, synthesizing photo-realistic images has been a highly relevant task due to its multiple applications from aesthetic or artistic [19] to medical purposes [1, 6, 21]. Related to the medical area, this application has had greater impact because most classification or diagnostic algorithms require a significant amount of highly specialized images for their training yet obtaining them is not easy at all. To solve this problem, many works analyze and interpret images of a specific topic in order to obtain a statistical correlation between the variables that define it. By this way, any set of variables close to the map generated in the previous analysis represents a similar image. Deep learning based methods have allowed the automatic extraction of feature maps which has helped in the design of more robust models photo-realistic image synthesis. This work focuses on obtaining the best feature maps for automatic generation of synthetic histological images. To do so, we propose a Generative Adversarial Networks (GANs) [8] to generate the new sample distribution using the feature maps obtained by an autoencoder [14, 20] as latent space instead of a completely random one. To corroborate our results, we present the generated images against the real ones and their respective results using different types of autoencoder to obtain the feature maps.	artificial neural network	Antoni Mauricio;Jorge López;Roger Huauya;Jose Diaz	2018		10.1007/978-3-030-01421-6_20	generative grammar;pattern recognition;machine learning;adversarial system;autoencoder;deep learning;artificial intelligence;artificial neural network;sampling distribution;computer science	ML	22.568983533174514	-54.08078488965351	24402
321ed81f5f16bdb7b2fbff7e8ae9c9d6f6b99f31	neural mechanisms of tactics decision-making	exogenous attention;software;level 2;tactic decision making;tactic intuition predominance;event related potential recording technique;neural mechanisms;training;elite fencers;data mining;accuracy;cerebral cortex neural mechanisms tactic decision making tactic intuition predominance elite fencers event related potential recording technique intuition decision making exogenous attention mental token;electrodes;intuition decision making;decision making electrodes enterprise resource planning electroencephalography monitoring cerebral cortex brain high resolution imaging image resolution aging;neurophysiology decision making;cerebral cortex;neurophysiology;electroencephalography;event related potential erp;mental token;level 1	The purpose of the study was to explore the neural mechanisms of tactics intuition predominance of elite fencers. This study selected 39 fencers. Event-related potential (ERP) recording technique was collected to compare between different level fencers. The behavioral data indicated that the task responses of elite, level-1 and level-2 fencers belonged to intuition decision-making. ERP data indicated that the pointing focus degree of exogenous attention and the updating degree of mental token of judging tactics intention of elite fencers were higher and their neural mechanisms of performance predominance maybe the nerve activity level of P1, P3 and PSW evoked at the special cerebral cortex were higher and the evoked time of P3 and PSW were earlier during the process of tactics decision-making. Keywords-fencing; tactics; decision-making; neural mechanisms; ERP	baillie–psw primality test;erp;elite;fencing (computing)	Yan Feng;Cheng-Lin Zhou	2009	2009 2nd International Conference on Biomedical Engineering and Informatics	10.1109/BMEI.2009.5304886	electroencephalography;electrode;artificial intelligence;accuracy and precision;neurophysiology;statistics	SE	17.154951087922207	-79.5948221251206	24425
58552624247f3787f77fef5710bf16ccb0a28984	mathematical description of ionic currents of the kenyon cell in the mushroom body of honeybee	calcium current;kenyon cell;honeybee;learning and memory;h h type equations;sodium current;mathematical model;ionic current;potassium current;whole cell recording;hodgkin huxley;mushroom body	The mushroom body of insects has been considered to be mainly involved in learning and memory. In the case of honeybee, it consists of about 340 000 intrinsic neurons, called Kenyon cells. Ionic currents in the isolated Kenyon cell somata were measured by the whole-cell recording method. Three outward currents: a rapidly activating and inactivating A-type potassium current ( I  A ), a calcium-activated potassium current ( I  C ) and a delayed rectifier-type potassium current ( I  K ); and several types of inward currents: a sodium current ( I  Na ) and a calcium current ( I  Ca ) were identified and investigated by Schafer et al. In this paper, we described the currents using Hodgkin–Huxley-type equations. The voltage responses of isolated Kenyon cell were reconstructed based on these mathematical models.	ionic	Hidetoshi Ikeno;Shiro Usui	1999	Neurocomputing	10.1016/S0925-2312(99)00079-X	mathematical model;hodgkin–huxley model	ML	17.012257269430773	-71.03584696585342	24430
d0472a6280e31f7a80083cdd88e225cd9f9d9d97	modular organization of cancer signaling networks is associated with patient survivability	cancer;robustness;modularity;networkanalysis;evolvability	Molecular signaling networks are believed to determine cancer robustness. Although cancer patient survivability was reported to correlate with the heterogeneous connectivity of the signaling networks inspired by theoretical studies on the increase of network robustness due to the heterogeneous connectivity, other theoretical and data analytic studies suggest an alternative explanation: the impact of modular organization of networks on biological robustness or adaptation to changing environments. In this study, thus, we evaluate whether the modularity-robustness hypothesis is applicable to cancer using network analysis. We focus on 14 specific cancer types whose molecular signaling networks are available in databases, and show that modular organization of cancer signaling networks is associated with the patient survival rate. In particular, the cancers with less modular signaling networks are more curable. This result is consistent with a prediction from the modularity-robustness hypothesis. Furthermore, we show that the network modularity is a better descriptor of the patient survival rate than the heterogeneous connectivity. However, these results do not contradict the importance of the heterogeneous connectivity. Rather, they provide new and different insights into the relationship between cellular networks and cancer behaviors. Despite several limitations of data analysis, these findings enhance our understanding of adaptive and evolutionary mechanisms of cancer cells.	acclimatization;cancer patient;cell signaling;database;databases;genetic heterogeneity;heterogeneous system architecture;inspiration function;neoplasms;patients;robustness (computer science);robustness of complex networks;cancer cell	Kazuhiro Takemoto;Kaori Kihara	2013	Bio Systems	10.1016/j.biosystems.2013.06.003	biology;bioinformatics;artificial intelligence	Comp.	6.379012984914841	-57.901643579839416	24464
50b9c8dad60634f8529f834c04f5ccf8eea8d49f	investigating cbir techniques for cervicographic images	female;longitudinal study;national library of medicine;computer graphics;average precision;cervix uteri;image processing computer assisted;digital archive;development tool;uterine cervical cancer;uterine cervical neoplasms;archives;databases as topic;papillomavirus infections;humans;user computer interface;national cancer institute;content based image retrieval;information storage and retrieval;medical education	The National Library of Medicine (NLM) and the National Cancer Institute (NCI) are creating a digital archive of 100,000 cervicographic images and clinical and diagnostic data obtained through two major longitudinal studies. In addition to developing tools for Web access to these data, we are conducting research in Content-Based Image Retrieval (CBIR) techniques for retrieving visually similar and pathologically relevant images. The resulting system of tools is expected to greatly benefit medical education and research into uterine cervical cancer which is the second most common cancer affecting women worldwide. Our current prototype system with fundamental CBIR functions operates on a small test subset of images and retrieves relevant cervix images containing tissue regions similar in color, texture, size, and/or location to a query image region marked by the user. Initial average precision result for retrieval by color of acetowhite lesions is 52%, and for the columnar epithelium is 64.2%, respectively.	behavior;cervix uteri;cervix carcinoma;content-based image retrieval;digital archive;epidemiologic research design;feature selection;graphical user interface;information retrieval;internet access;nc (complexity);national cancer institute;national library of medicine (u.s.);neck;neoplasms;netware loadable module;prototype;question (inquiry);similarity measure;subgroup;uterus;cervical cancer;columnar epithelium	Zhiyun Xue;Sameer K. Antani;L. Rodney Long;Jose Jeronimo;George R. Thoma	2007	AMIA ... Annual Symposium proceedings. AMIA Symposium		medicine;pathology;multimedia;information retrieval	Graphics	-3.597332376187797	-68.61934099742166	24475
12a1354ff0ff383a760dd7f3bcb8596ed82e865c	microscope: chip-seq and rna-seq software analysis suite for gene expression heatmaps	computational biology bioinformatics;algorithms;computer appl in life sciences;microarrays;bioinformatics	Heatmaps are an indispensible visualization tool for examining large-scale snapshots of genomic activity across various types of next-generation sequencing datasets. However, traditional heatmap software do not typically offer multi-scale insight across multiple layers of genomic analysis (e.g., differential expression analysis, principal component analysis, gene ontology analysis, and network analysis) or multiple types of next-generation sequencing datasets (e.g., ChIP-seq and RNA-seq). As such, it is natural to want to interact with a heatmap’s contents using an extensive set of integrated analysis tools applicable to a broad array of genomic data types. We propose a user-friendly ChIP-seq and RNA-seq software suite for the interactive visualization and analysis of genomic data, including integrated features to support differential expression analysis, interactive heatmap production, principal component analysis, gene ontology analysis, and dynamic network analysis. MicroScope is hosted online as an R Shiny web application based on the D3 JavaScript library: http://microscopebioinformatics.org/ . The methods are implemented in R, and are available as part of the MicroScope project at: https://github.com/Bohdan-Khomtchouk/Microscope .	base sequence;biopolymer sequencing;dna microarray chip;gene expression;gene ontology;hl7 data type;heatmap;imagery;interactive visualization;javascript library;massively-parallel sequencing;numerous;principal component analysis;r language;rna;sequence number;social network analysis;software suite;usability;web application;anatomical layer;contents - htmllinktype	Bohdan B. Khomtchouk;James R. Hennessy;Claes Wahlestedt	2016		10.1186/s12859-016-1260-x	biology;dna microarray;computer science;bioinformatics;data science;data mining	Comp.	-2.3892419957881765	-58.097551439839066	24539
5d939d0cfd5bb9aced5044cfa9b1bbbf7d2d37fb	optimal trajectories of brain state transitions	control theory;traumatic brain injury;network neuroscience;cognitive control;diffusion imaging	The complexity of neural dynamics stems in part from the complexity of the underlying anatomy. Yet how white matter structure constrains how the brain transitions from one cognitive state to another remains unknown. Here we address this question by drawing on recent advances in network control theory to model the underlying mechanisms of brain state transitions as elicited by the collective control of region sets. We find that previously identified attention and executive control systems are poised to affect a broad array of state transitions that cannot easily be classified by traditional engineering-based notions of control. This theoretical versatility comes with a vulnerability to injury. In patients with mild traumatic brain injury, we observe a loss of specificity in putative control processes, suggesting greater susceptibility to neurophysiological noise. These results offer fundamental insights into the mechanisms driving brain state transitions in healthy cognition and their alteration following injury.	anatomic structures;brain injuries;classification;cognition;control system;control theory;patients;sensitivity and specificity;traumatic brain injury;vulnerability (computing);white matter	Shi Gu;Richard F. Betzel;Marcelo Gomes Mattar;Matthew Cieslak;Philip R. Delio;Scott T. Grafton;Fabio Pasqualetti;Danielle S. Bassett	2017	NeuroImage	10.1016/j.neuroimage.2017.01.003	psychology;neuroscience;developmental psychology;social psychology	ML	19.03529968752517	-77.3355400188921	24542
c4280b43a1dcec1986b8eb6078f108958bac3d0b	chloromitossrdb 2.00: more genomes, more repeats, unifying ssrs search patterns and on-the-fly repeat detection	plants;molecular sequence annotation;databases genetic;sequence analysis dna;journal article;internet;microsatellite repeats;genome chloroplast;genome mitochondrial	Organelle genomes evolve rapidly as compared with nuclear genomes and have been widely used for developing microsatellites or simple sequence repeats (SSRs) markers for delineating phylogenomics. In our previous reports, we have established the largest repository of organelle SSRs, ChloroMitoSSRDB, which provides access to 2161 organelle genomes (1982 mitochondrial and 179 chloroplast genomes) with a total of 5838 perfect chloroplast SSRs, 37 297 imperfect chloroplast SSRs, 5898 perfect mitochondrial SSRs and 50 355 imperfect mitochondrial SSRs across organelle genomes. In the present research, we have updated ChloroMitoSSRDB by systematically analyzing and adding additional 191 chloroplast and 2102 mitochondrial genomes. With the recent update, ChloroMitoSSRDB 2.00 provides access to a total of 4454 organelle genomes displaying a total of 40 653 IMEx Perfect SSRs (11 802 Chloroplast Perfect SSRs and 28 851 Mitochondria Perfect SSRs), 275 981 IMEx Imperfect SSRs (78 972 Chloroplast Imperfect SSRs and 197 009 Mitochondria Imperfect SSRs), 35 250 MISA (MIcroSAtellite identification tool) Perfect SSRs and 3211 MISA Compound SSRs and associated information such as location of the repeats (coding and non-coding), size of repeat, motif and length polymorphism, and primer pairs. Additionally, we have integrated and made available several in silico SSRs mining tools through a unified web-portal for in silico repeat mining for assembled organelle genomes and from next generation sequencing reads. ChloroMitoSSRDB 2.00 allows the end user to perform multiple SSRs searches and easy browsing through the SSRs using two repeat algorithms and provide primer pair information for identified SSRs for evolutionary genomics.Database URL: http://www.mcr.org.in/chloromitossrdb.	access network;bloc1s3 gene;bio-informatics;bioinformatics;chloroplasts;communications satellite;genome;genome, chloroplast;genomics;graphical user interface;imagery;manuscripts;massively-parallel sequencing;mitochondrial diseases;motif;ninl gene;nr3c2 protein, human;natural language processing;primer;pictbridge;rp (complexity);reading (activity);roland gs;sql server reporting services;short tandem repeat;super bit mapping;uniform resource locator;algorithm;subsynaptic reticulum	Gaurav Sablok;G. V. Padma Raju;Suresh B. Mudunuri;Ratna Prabha;Dhananjaya P. Singh;Vesselin Baev;Galina Yahubyan;Peter J. Ralph;Nicola La Porta	2015		10.1093/database/bav084	biology;molecular biology;the internet;bioinformatics;direct repeat;genome project;law;genetics;tandem repeat;genome	Comp.	-1.359953983489429	-59.44664012481056	24610
cc3f54257fa8f932b95fd76b3c42a2030bb43f48	performance analysis of multiclass support vector machine classification for diagnosis of coronary heart diseases		Automatic diagnosis of coronary heart disease helps the doctor to support in decision making a diagnosis. Coronary heart disease have some types or levels. Referring to the UCI Repository dataset, it divided into 4 types or levels that are labeled numbers 1-4 (low, medium, high and serious). The diagnosis models can be analyzed with multiclass classification approach. One of multiclass classification approach used, one of which is a support vector machine (SVM). The SVM use due to strong performance of SVM in binary classification. This research study multiclass performance classification support vector machine to diagnose the type or level of coronary heart disease. Coronary heart disease patient data taken from the UCI Repository. Stages in this study is preprocessing, which consist of, to normalizing the data, divide the data into data training and testing. The next stage of multiclass classification and performance analysis. This study uses multiclass SVM algorithm, namely: Binary Tree Support Vector Machine (BTSVM), OneAgainst-One (OAO), One-Against-All (OAA), Decision Direct Acyclic Graph (DDAG) and Exhaustive Output Error Correction Code ( ECOC). Performance parameter used is recall, precision, F-measure and Overall accuracy. The experiment results showed that the multiclass SVM classification algorithm with the algorithm BT-SVM, OAA-SVM and the ECOC-SVM,gave the highest Recall in the diagnosis of type or healthy level with a value above 90%, precision 82.143% and 86.793% F-measure,. For all kinds of algorithms, except binary OAA-SVM algorithm gave the highest recall 0.0% for the type or level of sickhigh and sick-serious, and ECOCSVM algorithm gave the highest recall 0.0% for sick-medium and sickserious. While the type or level other, the performance of recall, precision and F-measure between 20% 30%,. The conclusion that can be drawn is that the approach to the multiclass classification algorithm BTSVM, OAO-SVM, DDAG-SVM to diagnosis the type or level of coronary heart disease provides better performance, than the binary classification approach.	algorithm;binary classification;binary tree;f1 score;multiclass classification;oddworld: abe's oddysee;open agent architecture;preprocessor;profiling (computer programming);support vector machine	Wiharto Wiharto;Hari Kusnanto;Herianto Herianto	2015	CoRR		computer science;machine learning;multiclass classification;pattern recognition;data mining;structured support vector machine	ML	7.973041188896232	-77.96217196785281	24631
d39de7aff76286a114182e2a54ea708753aecf9d	prospects for tertiary structure prediction of rna based on secondary structure information		We developed a method, called RNA Assembler using Secondary Structure Information Effectively (RASSIE), for predicting RNA tertiary structures using known secondary structure information. We attempted a fragment assembly-based method that uses a secondary structure-based fragment library. For several typical target structures such as stem-loops, bulge-loops, and 2-way junctions, our method provided numerous good quality candidate structures in less computational time than previously proposed methods. By using a high-resolution potential energy function, we were able to select good predicted structures from candidate structures. This method of efficient conformational search and detailed structure evaluation using high-resolution potential is potentially useful for the tertiary structure prediction of RNA.	assembly language;attempt;computation;earth bulge;image resolution;mathematical optimization;rna;symmetric multiprocessing;time complexity;tertiary	Satoshi Yamasaki;Shugo Nakamura;Kazuhiko Fukui	2012	Journal of chemical information and modeling	10.1021/ci2003413	crystallography;biology;bioinformatics;combinatorial chemistry	Comp.	11.186108101935972	-60.1085126644124	24659
ca8fe7228e73f2e88008804c7b9d084d8149f3d3	studying irreversible transitions in a model of cell cycle regulation	budding yeast;complex network;stochastic simulation;cell cycle regulation;signalling pathway;model checking;probabilistic model checking;blenx;cell division;cell cycle	Cells life follows a cycling behaviour which starts at cell birth and leads to cell division through a number of distinct phases. The transitions through the various cell cycle phases are controlled by a complex network of signalling pathways. Many cell cycle transitions are irreversible: once they are started they must reach completion. In this study we investigate the existence of conditions which lead to cases when irreversibility may be broken. Specifically, we characterise the elements of the cell cycle signalling network that are responsible for the irreversibility and we determine conditions for which the irreversible transitions may become reversible. We illustrate our results through a formal approach in which stochastic simulation analysis and model checking verification are combined. Through probabilistic model checking we provide a quantitative measure for the probability of irreversibility in the “Start” transition of the cell cycle.	cell (microprocessor);complex network;markov chain;model checking;positive feedback;simulation;statistical model	Paolo Ballarini;Tommaso Mazza;Alida Palmisano;Attila Csikász-Nagy	2009	Electr. Notes Theor. Comput. Sci.	10.1016/j.entcs.2009.02.049	simulation;computer science;cell cycle;mathematics;algorithm	Logic	8.6058487045396	-66.55441088127012	24678
4b6f345e6937ae0852109f8ebb265698d115a06b	toward computer-assisted text curation: classification is easy (choosing training data can be hard...)	classification;database curation;biomedical text mining;imbalanced and sparse data;text categorization	We aim to design a system for classifying scientific articles based on the presence of protein characterization experiments, intending to aid the curators populating JCVI’s Characterized Protein (CHAR) Database of experimentally characterized proteins. We trained two classifiers using small datasets labeled by CHAR curators, and another classifier based on a much larger dataset using annotations from public databases. Performance varied greatly, in ways we did not anticipate. We describe the datasets, the classification method, and discuss the unexpected results.	database;digital curation;experiment;high-level programming language;information source;naive bayes classifier;naivety;population;relevance;swiss-model;scientific literature;statistical classification;switzerland	Robert E Denroche;Ramana Madupu;Shibu Yooseph;Granger G. Sutton;Hagit Shatkay	2008		10.1007/978-3-642-13131-8_5	biomedical text mining;biological classification;computer science;bioinformatics;data science;data mining;information retrieval	NLP	-2.3067939070448538	-64.58931367550075	24695
4d6871cdfd5b63d7912f29540e6931afa32cb98e	cloning and sequence analysis of gyra gene of klebsiella pneumoniae	plasmide pbr322;cloning molecular;bacterie;dna topoisomerase atp hydrolysing;amino acid sequence;gen;enzyme;sousunite;subunitad;secuencia nucleotido;enzima;klebsiella pneumoniae;restriction mapping;nucleotide sequence;enterobacteriaceae;sequence nucleotide;plasmid;dna topoisomerases type ii;hydrogen bonding;clonacion molecular;plasmide;promoter regions genetic;clonage moleculaire;gene gyra;gene;nucleic acid conformation;southern blotting;molecular cloning;sequence analysis;molecular sequence data;bacteria;base sequence;genes bacterial;plasmido;klebsielleae;subunit;methode southern;regulatory sequences nucleic acid	The gene gyrA encoding the DNA gyrase A subunit of Klebsiella pneumoniae has been cloned in the plasmid pBR322. Bases of about 3.5 Kb DNA have been sequenced to locate the gyrA gene. An open reading frame of 2628 nucleotides coding for a 97 KD protein has been identified. Homology to the extent of about 85% was detected at the nucleotide level and about 90% at the amino acid level, when the sequences were compared with that of Escherichia coli gyrA. Some very interesting differences have, however, been found in the promoter region.	amino acids;base;clone cells;homology modeling;klebsiella pneumoniae;nucleotides;open reading frame;pneumonia;promoter regions, genetic;reading frames (nucleotide sequence);sequence analysis	Goberdhan P Dimri;H. K. Das	1990	Nucleic acids research	10.1093/nar/18.1.151	molecular cloning;biology;enzyme;molecular biology;bacteria;nucleic acid sequence;restriction map;sequence analysis;protein subunit;gene;peptide sequence;hydrogen bond;microbiology;plasmid;genetics;southern blot	Comp.	3.873430641054814	-63.54995817245674	24722
cf6450b1b8e8dd16d0ba9d8392f5c2edeba8afff	cap ribose methylation of c-mos mrna stimulates translation and oocyte maturation in xenopus laevis	animals;thionucleosides;cyclin b;rna caps;cyclin a;progesterone;xenopus laevis;protein synthesis;genes mos;methylation;xenopus oocyte;oocyte maturation;deoxyadenosines;enzyme inhibitors;base sequence;oocytes;translation initiation;protein biosynthesis;ribose	In Xenopus oocytes, progesterone stimulates the cytoplasmic polyadenylation and resulting translational activation of c-mos mRNA, which is necessary for the induction of oocyte maturation. Although details of the biochemistry of polyadenylation are beginning to emerge, the mechanism by which 3' poly(A) addition stimulates translation initiation is enigmatic. A previous report showed that polyadenylation induced cap-specific 2'-O-methylation, and suggested that this 5' end modification was important for translational activation. Here, we demonstrate that injected c-mos RNA undergoes polyadenylation and cap ribose methylation. Inhibition of this methylation by S-isobutylthioadenosine (SIBA), a methyltransferase inhibitor, has little effect on progesterone-induced c-mos mRNA polyadenylation or general protein synthesis, but prevents the synthesis of Mos protein as well as oocyte maturation. Maturation can be rescued, however, by the injection of factors that act downstream of Mos, such as cyclin A and B mRNAs. Most importantly, we show that the translational efficiency of injected mRNAs containing cap-specific 2'-O-methylation (cap I) is significantly enhanced compared to RNAs that do not contain the methylated ribose (cap 0). These results suggest that cap ribose methylation of c-mos mRNA is important for translational recruitment and for the progression of oocytes through meiosis.	biologic development;color gradient;cyclin a;downstream (software development);genetic translation process;meiosis;methyltransferase;oocytes;ovum;polyadenylation;progesterone;protein biosynthesis;protein methylation;rna;ribose;translation initiation;translational activation;xenopus laevis;oocyte maturation	Hideaki Kuge;George G. Brownlee;Paul D. Gershon;Joel D. Richter	1998	Nucleic acids research	10.1093/nar/26.13.3208	biology;biochemistry;molecular biology;genetics;protein biosynthesis	ML	6.175159725861165	-63.63373379036669	24724
7d2ba7c890c0fa55aaddd806959bea841a3df384	action expertise reduces brain activity for audiovisual matching actions: an fmri study with expert drummers	estimulacao luminosa;adulto;fmri;inferior temporal;action expertise;drumming;psicofisica;musica;action representation;adulto jovem;encefalo;feminino;inferior parietal lobule;cerebelo;adolescente;humanos;biological motion;lobo parietal;inf 01 informatica;functional magnetic resonance images;masculino;parahippocampal gyrus;middle frontal gyrus;analise de variância;action sound representation;m psi 01 psicologia generale;brain activation;brain function;analise por conglomerados;lobo temporal;audiovisual synchrony;meia idade;estimulacao acustica;destreza motora;cortex pre frontal;desempenho psicomotor;giro para hipocampal;imagem por ressonância magnetica	When we observe someone perform a familiar action, we can usually predict what kind of sound that action will produce. Musical actions are over-experienced by musicians and not by non-musicians, and thus offer a unique way to examine how action expertise affects brain processes when the predictability of the produced sound is manipulated. We used functional magnetic resonance imaging to scan 11 drummers and 11 age- and gender-matched novices who made judgments on point-light drumming movements presented with sound. In Experiment 1, sound was synchronized or desynchronized with drumming strikes, while in Experiment 2 sound was always synchronized, but the natural covariation between sound intensity and velocity of the drumming strike was maintained or eliminated. Prior to MRI scanning, each participant completed psychophysical testing to identify personal levels of synchronous and asynchronous timing to be used in the two fMRI activation tasks. In both experiments, the drummers' brain activation was reduced in motor and action representation brain regions when sound matched the observed movements, and was similar to that of novices when sound was mismatched. This reduction in neural activity occurred bilaterally in the cerebellum and left parahippocampal gyrus in Experiment 1, and in the right inferior parietal lobule, inferior temporal gyrus, middle frontal gyrus and precentral gyrus in Experiment 2. Our results indicate that brain functions in action-sound representation areas are modulated by multimodal action expertise.	academy;convergence (action);cortical cell layer of the cerebellum;electroencephalography;expectation propagation;experiment;frontal lobe gyrus;futures studies;judgment;lateral occipitotemporal gyrus;lobule;matching;mary tsingou;maximal set;middle frontal gyrus structure;modulation;movement;multimodal interaction;neuroimaging;parahippocampal gyrus;parietal lobe;resonance;robert;rubella;structure of inferior temporal gyrus;tellurium;test engineer;velocity (software development);word lists by frequency;fmri	Karin Petrini;Frank E. Pollick;Sofia Dahl;Phil McAleer;Lawrie S. McKay;Davide Rocchesso;Carl Haakon Waadeland;Scott A. Love;Federico Avanzini;Aina Puce	2011	NeuroImage	10.1016/j.neuroimage.2011.03.009	psychology;neuroscience;developmental psychology;biological motion;communication	ML	16.9102256954305	-77.49256208700206	24755
3fe60bb7c521c50cb60b498ab966fd3d7f99c9a0	modeling cancer progression via pathway dependencies	disease progression;signal transduction;male;models biological;interaction network;melanoma;genetics;gene expression;neoplasm proteins;prostatic neoplasms;cell cycle control;gene expression regulation neoplastic;differential expression;humans;building model;computer simulation;tumor progression;prostate cancer	Cancer is a heterogeneous disease often requiring a complexity of alterations to drive a normal cell to a malignancy and ultimately to a metastatic state. Certain genetic perturbations have been implicated for initiation and progression. However, to a great extent, underlying mechanisms often remain elusive. These genetic perturbations are most likely reflected by the altered expression of sets of genes or pathways, rather than individual genes, thus creating a need for models of deregulation of pathways to help provide an understanding of the mechanisms of tumorigenesis. We introduce an integrative hierarchical analysis of tumor progression that discovers which a priori defined pathways are relevant either throughout or in particular steps of progression. Pathway interaction networks are inferred for these relevant pathways over the steps in progression. This is followed by the refinement of the relevant pathways to those genes most differentially expressed in particular disease stages. The final analysis infers a gene interaction network for these refined pathways. We apply this approach to model progression in prostate cancer and melanoma, resulting in a deeper understanding of the mechanisms of tumorigenesis. Our analysis supports previous findings for the deregulation of several pathways involved in cell cycle control and proliferation in both cancer types. A novel finding of our analysis is a connection between ErbB4 and primary prostate cancer.	cell (microprocessor);cell cycle control;color gradient;deregulation;erbb4 wt allele;gene regulatory network;genetic heterogeneity;genetic editing;inference;interaction network;neoplastic cell transformation;prostatic neoplasms;receptor tyrosine-protein kinase erbb-4, human;refinement (computing);transcription initiation;tumor progression;melanoma	Elena J. Edelman;Justin Guinney;Jen-Tsan Chi;Phillip G. Febbo;Sayan Mukherjee	2008		10.1371/journal.pcbi.0040028	computer simulation;interaction network;biology;gene expression;bioinformatics;genetics;signal transduction	Comp.	6.318483291456134	-60.064121593998	24767
3c140136a18e65f3590ccce5518f58a6a3c763b1	driving phase synchronous plasma discharges with superimposed signals	phase synchronization;synchronization;plasma	Numerical simulations and experimental measurements performed on a plasma discharge, simultaneously paced with two independent sinusoidal functions, show the plasma moving from one synchronous state to another, back and forth, between the two independent pacers. Different approaches for studying this competition for phase synchronization indicate the relevance of the relative frequency values of the two sinusoidal functions with respect to the predominant frequency characteristic of the unpaced plasma discharge.		Matthew S. Davis;Nathan G. Nutter;Epaminondas Rosa	2007	I. J. Bifurcation and Chaos	10.1142/S0218127407019287	plasma;synchronization;phase synchronization;control theory;mathematics	ECom	16.615213620058757	-71.22868042769547	24774
7071cca09ae79bc283130b392e050e7654353ceb	semi-supervised analysis of human brain tumours from partially labeled mrs information, using manifold learning models	human brain tumours;manifold learning;semi supervised learning;unlabeled mrs information;human brain	Medical diagnosis can often be understood as a classification problem. In oncology, this typically involves differentiating between tumour types and grades, or some type of discrete outcome prediction. From the viewpoint of computer-based medical decision support, this classification requires the availability of accurate diagnoses of past cases as training target examples. The availability of such labeled databases is scarce in most areas of oncology, and especially so in neuro-oncology. In such context, semi-supervised learning oriented towards classification can be a sensible data modeling choice. In this study, semi-supervised variants of Generative Topographic Mapping, a model of the manifold learning family, are applied to two neuro-oncology problems: the diagnostic discrimination between different brain tumour pathologies, and the prediction of outcomes for a specific type of aggressive brain tumours. Their performance compared favorably with those of the alternative Laplacian Eigenmaps and Semi-Supervised SVM for Manifold Learning models in most of the experiments.	brain neoplasms;computation;data modeling;database;decision making;decision support systems, clinical;decision support system;departure - action;euclidean distance;experiment;forecast of outcome;generative topographic map;glioblastoma;grade;idi;inference;machine learning;magnetic resonance spectroscopy;minimal recursion semantics;natural regeneration;neuro-fuzzy;neurologic oncology;nonlinear dimensionality reduction;numerous;preparation;published comment;semi-supervised learning;semiconductor industry;slow-scan television;supervised learning;symantec endpoint protection;topography;tracer;university of alabama at birmingham comprehensive cancer center;wdfy2 wt allele;manifold;synovial sarcoma	Raúl Cruz-Barbosa;Alfredo Vellido	2011	International journal of neural systems	10.1142/S0129065711002626	semi-supervised learning;computer science;artificial intelligence;machine learning;pattern recognition;nonlinear dimensionality reduction	ML	7.650800378177267	-76.96145889629975	24836
9e0bdf864b10313f9bea4bb1bbc791c772ec7ba9	firedb: a compendium of biological and pharmacologically relevant ligands	evolution molecular;catalytic domain;ligands;molecular sequence annotation;pharmaceutical preparations;binding sites;internet;proteins;databases protein	FireDB (http://firedb.bioinfo.cnio.es) is a curated inventory of catalytic and biologically relevant small ligand-binding residues culled from the protein structures in the Protein Data Bank. Here we present the important new additions since the publication of FireDB in 2007. The database now contains an extensive list of manually curated biologically relevant compounds. Biologically relevant compounds are informative because of their role in protein function, but they are only a small fraction of the entire ligand set. For the remaining ligands, the FireDB provides cross-references to the annotations from publicly available biological, chemical and pharmacological compound databases. FireDB now has external references for 95% of contacting small ligands, making FireDB a more complete database and providing the scientific community with easy access to the pharmacological annotations of PDB ligands. In addition to the manual curation of ligands, FireDB also provides insights into the biological relevance of individual binding sites. Here, biological relevance is calculated from the multiple sequence alignments of related binding sites that are generated from all-against-all comparison of each FireDB binding site. The database can be accessed by RESTful web services and is available for download via MySQL.	accessibility;bibliographic reference;binding sites;compendium;cross-reference;database;digital curation;download;information;ligands;multiple sequence alignment;mysql;pharmacology;protein data bank;relevance;representational state transfer;web service	Paolo Maietta;Gonzalo López;Angel Carro;Benjamin J. Pingilley;Leticia G. Leon;Alfonso Valencia;Michael L. Tress	2014		10.1093/nar/gkt1127	biology;the internet;bioinformatics;binding site;ligand	Comp.	-0.9191440306061195	-60.59709831766106	24861
9df057f35246b1399b38a2f26ce4270e4c12402d	development of hybrid systems: interfacing a silicon neuron to a leech heart interneuron	hybrid system;mathematical model;oscillations	We have developed a silicon neuron that is inspired by a mathematical model of the leech heartbeat (HN) interneuron. The temporal and ionic current behaviors of this silicon neuron are close to that of the living cell. Because of this similarity we were able to interface this silicon neuron to a living HN cell using a dynamic clamp technique [8]. We present data showing dynamic behaviors of the hybrid half-center oscillator.	biological neuron model;central pattern generator;clamping (graphics);ionic;mathematical model	Mario F. Simoni;Gennady S. Cymbalyuk;Michael Elliott Sorensen;Ronald L. Calabrese;Stephen P. DeWeerth	2000			control engineering;machine learning;artificial intelligence;computer science;hybrid system;interfacing;heartbeat;leech;neuron;interneuron;silicon	HCI	15.836113497121703	-68.41027448128919	24926
8370c622bdd6d7e997fe8faf780b09cee2ff2120	multivariate pattern classification reveals differential brain activation during emotional processing in individuals with psychosis proneness	multivariate;fmri;abnormalities;metaanalysis;general population;machine learning;emotion;schizophrenia patients;functional neuroanatomy;schizotypy;support vector machine;amygdala;neural response;bipolar disorder;psychosis proneness;high risk	Among the general population, individuals with subthreshold psychotic-like experiences, or psychosis proneness (PP), can be psychometrically identified and are thought to have a 10-fold increased risk of psychosis. They also show impairments in measures of emotional functioning parallel to schizophrenia. Whilst previous studies have revealed altered brain activation in patients with schizophrenia during emotional processing, it is unclear whether these alterations are also expressed in individuals with high PP. Here we used Support Vector Machine (SVM) to perform multivariate pattern classification based on brain activation during emotional processing in 20 individuals with high PP and 20 comparison subjects (low PP). In addition, we performed a standard univariate analysis based on the General Linear Model (GLM) on the same data for comparison. The experimental task involved passively viewing negative and neutral pictures from the International Affective Picture System (IAPS). SVM allowed classification of the two groups with statistically significant accuracy (p=0.017) and identified group differences within an emotional circuitry including the amygdala, insula, anterior cingulate and medial prefrontal cortex. In contrast, the standard univariate analysis did not detect any significant between-group differences. Our results reveal a distributed and subtle set of alterations in brain function within the emotional circuitry of individuals with high PP, providing neurobiological support for the notion of dysfunctional emotional circuitry in this group. In addition, these alterations are best detected using a multivariate approach rather than standard univariate methods. Further application of this approach may aid in characterising people at clinical and genetic risk of developing psychosis.	amygdaloid structure;artificial neural network;cns disorder;cingulate cortex;congenital abnormality;electronic circuit;experience;general linear model;generalized linear model;insula of reil;internet addiction disorder;machine learning;medial graph;patients;prefrontal cortex;psychotic disorders;schizophrenia;statistical classification;support vector machine;support vector machine;while;fmri	Gemma Modinos;William Pettersson-Yeo;Paul Allen;Philip K. McGuire;André Aleman;Andrea Mechelli	2012	NeuroImage	10.1016/j.neuroimage.2011.10.048	psychology;cognitive psychology;support vector machine;developmental psychology;emotion;social psychology	ML	18.465691518715307	-79.61603307910377	24972
18d5b80757aebc994a8192b291ed1aba3b58f1b0	firing rate dynamics in recurrent spiking neural networks with intrinsic and network heterogeneity	biological patents;biomedical journals;text mining;dimension reduction;europe pubmed central;citation search;recurrent e i network;leaky integrate and fire;citation networks;research articles;intrinsic heterogeneity;abstracts;open access;life sciences;clinical guidelines;full text;rest apis;orcids;europe pmc;network heterogeneity;biomedical research;bioinformatics;literature search	Heterogeneity of neural attributes has recently gained a lot of attention and is increasing recognized as a crucial feature in neural processing. Despite its importance, this physiological feature has traditionally been neglected in theoretical studies of cortical neural networks. Thus, there is still a lot unknown about the consequences of cellular and circuit heterogeneity in spiking neural networks. In particular, combining network or synaptic heterogeneity and intrinsic heterogeneity has yet to be considered systematically despite the fact that both are known to exist and likely have significant roles in neural network dynamics. In a canonical recurrent spiking neural network model, we study how these two forms of heterogeneity lead to different distributions of excitatory firing rates. To analytically characterize how these types of heterogeneities affect the network, we employ a dimension reduction method that relies on a combination of Monte Carlo simulations and probability density function equations. We find that the relationship between intrinsic and network heterogeneity has a strong effect on the overall level of heterogeneity of the firing rates. Specifically, this relationship can lead to amplification or attenuation of firing rate heterogeneity, and these effects depend on whether the recurrent network is firing asynchronously or rhythmically firing. These observations are captured with the aforementioned reduction method, and furthermore simpler analytic descriptions based on this dimension reduction method are developed. The final analytic descriptions provide compact and descriptive formulas for how the relationship between intrinsic and network heterogeneity determines the firing rate heterogeneity dynamics in various settings.	artificial neural network;biological neural networks;description;dimensionality reduction;genetic heterogeneity;intrinsic dimension;leucaena pulverulenta;monte carlo method;network model;neural network simulation;recurrent neural network;spiking neural network;synaptic package manager;synaptic weight	Cheng Ly	2015	Journal of Computational Neuroscience	10.1007/s10827-015-0578-0	text mining;neuroscience;computer science;artificial intelligence;machine learning;data mining;statistics;dimensionality reduction	ML	18.25241786942615	-69.85863704532079	24997
42c0c31ebdd56411d940776060126449abce7db7	a cmi (cell metabolic indicator)-based controller for achieving high growth rate escherichia coli cultures	biochemistry sugar biological system modeling biomass sensors bioreactors;ph biochemistry cellular biophysics gas sensors microorganisms;mammalian cells cell metabolic indicator based controller cmi indicator based controller high growth rate escherichia coli cultures biopharmaceuticals industrial bioreactors benchtop bioreactors economical production protocols e coli metabolism oxygen uptake rate our base addition rate bar off gas sensor ph probe cell metabolic states cmi based controller e coli strain stem cells	A large fraction of biopharmaceuticals are produced in Escherichia coli, where each new product and strain currently requires a high degree of growth characterization in benchtop and industrial bioreactors to achieve economical production protocols. The capability to use a standard set of sensors to characterize a system quickly without the need to conduct numerous experiments to determine stable growth rate for the strain would significantly decrease development time. This paper presents a cell metabolic indicator (CMI) which provides better insight into the E. coli metabolism than a growth rate value. The CMI is the ratio of the oxygen uptake rate (OUR) of the culture and the base addition rate (BAR) required to keep pH at a desired setpoint. The OUR and BAR are measured using a off-gas sensor and pH probe, respectively, and thus the CMI can be computed online. Experimental results demonstrate the relationship between CMI and the different cell metabolic states. A previously published model is augmented with acid production dynamics, allowing for comparison of the CMI-based controller with an open-loop controller in simulation. The CMI-based controller required little a priori knowledge about the E. coli strain in order to achieve a high growth rate. Since many different types of cells exhibit similar behaviors, the CMI concept can be extended to mammalian and stem cells.	behavior;biological factors;bioreactors;cell signaling;computer memories inc.;controllers;experiment;industrial pc;mammals;metabolic process, cellular;oxygen;protocols documentation;scientific publication;setpoint (control system);simulation;stem cells;sensor (device)	Matthew E. Pepper;Li Wang;Ajay Padmakumar;Timothy C. Burg;Sarah W. Harcum;Richard E. Groff	2014	2014 36th Annual International Conference of the IEEE Engineering in Medicine and Biology Society	10.1109/EMBC.2014.6944232	biology;biochemistry;biotechnology;microbiology	Robotics	6.692758390459382	-61.95172379494517	25003
26e2fdaa5f12e8159ef0114f2672d7385a750f14	anatomical constraints on lateral competition in columnar cortical architectures		Competition is a well-studied and powerful mechanism for information processing in neuronal networks, providing noise rejection, signal restoration, decision making and associative memory properties, with relatively simple requirements for network architecture. Models based on competitive interactions have been used to describe the shaping of functional properties in visual cortex, as well as the development of functional maps in columnar cortex. These models require competition within a cortical area to occur on a wider spatial scale than cooperation, usually implemented by lateral inhibitory connections having a longer range than local excitatory connections. However, measurements of cortical anatomy reveal that the spatial extent of inhibition is in fact more restricted than that of excitation. Relatively few models reflect this, and it is unknown whether lateral competition can occur in cortical-like networks that have a realistic spatial relationship between excitation and inhibition. Here we analyze simple models for cortical columns and perform simulations of larger models to show how the spatial scales of excitation and inhibition can interact to produce competition through disynaptic inhibition. Our findings give strong support to the direct coupling effect—that the presence of competition across the cortical surface is predicted well by the anatomy of direct excitatory and inhibitory coupling and that multisynaptic network effects are negligible. This implies that for networks with short-range inhibition and longer-range excitation, the spatial extent of competition is even narrower than the range of inhibitory connections. Our results suggest the presence of network mechanisms that focus on intra-rather than intercolumn competition in neocortex, highlighting the need for both new models and direct experimental characterizations of lateral inhibition and competition in columnar cortex.	anatomic structures;architecture as topic;cerebral cortex;circuit restoration;column (database);content-addressable memory;decision making;deny (action);direct coupling;excitation;hypothalamic area, lateral;information processing;interaction;large;lateral thinking;map;negative feedback;neocortex;network architecture;noise reduction;noise shaping;rejection sampling;requirement;simulation;spatial scale;lateral inhibition	Dylan Richard Muir;Matthew Cook	2014	Neural Computation	10.1162/NECO_a_00613	neuroscience;communication	ML	19.45433717449073	-70.13867763546916	25006
07244c1bb605cebb1ef815747d870f47ac70149b	a plausible micro neural circuit for decision-making		An intermediate level between neural circuits and behaviors is neural computations, various behaviors that animals exhibit following some basic control laws can be implemented by some canonical neural computations [Carandini, 2012]. To explore how the microscopic activity of neurons leads to macroscopic behavioral control strategy, we consider basic logic-like operations as some canonical computations in the brain. In this paper, firstly we designed the functional circuits for basic logic-like operations based on the known neurophysiological properties. Secondly, using basic functional circuits constructed a possible neural network for decision logic of animal’s behavior. This study provides a general approach for constructing the neural circuits to implement the behavioral control rules. Furthermore, this study will help us to establish a transitional bridge between the microscopic activity of the nervous system and the macroscopic animal behavior.	artificial neural network;computation;computational neuroscience;control theory	Hui Wei;Dawei Dai;Yijie Bu	2017			cognitive psychology;psychology	ML	18.218564975408817	-69.64704869220505	25017
d90598f212a502745570f3680a125c16696c4137	multimedia data mining using p-trees	extraction information;text;multimedia;medicinal plant;analisis datos;information extraction;text mining;methode echelle multiple;gen;large data sets;metodo escala multiple;texte;spatial data structure;data mining;chip;gene expression;expression genique;data analysis;remote sensing imagery;fouille donnee;spatial temporal data mining;structure macroscopique;ndsu;gene;estructura macroscopica;analyse donnee;multiscale method;macroscopic structure;texto;temporal data mining;p tree;data structure;busca dato;expresion genetica;extraccion informacion;multimedia data mining	Peano count trees (P-trees) provide efficient, lossless, data mining ready representations of tabular data and make possible the mining of multiple very large data sets, including time-sequences of Remotely Sensed Imagery (RSI) and micro-array gene expression datasets (MA). Each MA dataset presents a one-time, gene expression level map of thousands of genes subjected to hundreds of conditions. MA data has traditionally been archived as text abstracts (e.g., Medline abstracts). An important multimedia application is to integrate macro-scale analysis of RSI with the micro-scale analysis of MA across multiple plant organisms. This is truly a multimedia data mining problem. Most multimedia data is mined by extracting pertinent features into tables, then mining the tables. P-trees are a convenient technology to mine all such multimedia data.	archive;data mining;lossless compression;medline;mined;peano axioms;relevance;table (information);x86	William Perrizo;William Jockheck;Amal Perera;Dongmei Ren;Weihua Wu;Yi Zhang	2002		10.1007/978-3-540-39666-6_7	chip;text mining;gene expression;data structure;computer science;artificial intelligence;data science;operating system;gene;data mining;database;data stream mining;data analysis;computer security;information extraction;algorithm	ML	-4.444994925525644	-58.02463208505291	25018
3c1d77b4ef5eb0693c4021bf7ee6ae6de915255b	drug target path discovery on semantic biomedical big data	distributed algorithms;drugs;semantics;big data;decision support systems;buildings;conferences	Systems chemical biology integrate chemistry, biology and computation tools as a whole system, which can help researchers to deeply study the interaction and relationship among small molecules, such as genes, proteins, targets, compounds and so on. With systems chemical biology, researchers can concentrate on new way of drug discovery, including drug target path discovery, which can not only help biomedical researchers to find evidences for existing disease associate genes, but also to design new effect medicine based on targets. Network based approaches are the state-of-art solutions for drug target path discovery, however, there are still some challenges: 1) The quality of the network dominate the efficiency and accuracy of the results, therefore a well designed network is quite important on drug target path discovery mission; 2) the existing network based approaches only work on small graph, it can not handle massive data well. In the paper, we designed a novel framework of systems chemical biology based on semantic big data. In the paper, we proposed a novel drug target path discovery approach. It can identify targets associated with specific medicines (disease) and the path of relationship based on a RDF semantic D-T network. The ranking of candidate targets is performed through an improved parallel random walk with restart algorithm. The experimental studies show that the proposed approaches can efficiently discover drug target relationship path, meanwhile, the approaches have good scalability which are suitable for big data analysis.	algorithm;big data;computation;resource description framework;scalability	Fang Du;Ting Li;Yingjie Shi;Lijuan Song;Xiaojun Gu	2016	2016 IEEE International Conference on Big Data (Big Data)	10.1109/BigData.2016.7840998	computer science;bioinformatics;data science;data mining	ML	4.384567381516191	-56.40888524278762	25100
aa755ab7a0ad5b97b52b0598f37b09ebe15b2f59	some examples on the performance of density functional theory in the description of bioinorganic systems and processes	dna;drugs;carbon dioxide;ions;exchange correlation functionals density functional theory bioinorganic systems complex systems catalytic mechanism carbonic anhydrase structural properties silver mediated dna dimers structural features spectroscopic features zn phthalocyanine derivatives carnosine carboplatin complexes fragmentation pathways carnosine oxaliplatin complexes fragmentation pathways;yttrium;yttrium dna drugs ions carbon dioxide;zinc compounds biochemistry catalysis density functional theory dna electron correlations enzymes exchange interactions electron molecular biophysics molecular configurations silver compounds	Density functional computations on a series of complex systems and processes are presented and discussed. In particular the following subject have been investigated: i) catalytic mechanism of carbonic anhydrase; ii) structural properties of silver mediated DNA dimers; iii) structural and spectroscopic features of Zn-phthalocyanine derivatives; iv) carnosine-carboplatin, carnosine-oxaliplatin complexes fragmentation pathways. Reported data indicate that good results can be obtained selecting the appropriate computational strategies, exchange-correlation functionals and basis sets.	basis set (chemistry);complex systems;computation;density functional theory;fragmentation (computing);functional theories of grammar	Tiziana Marino;Nino Russo;Emilia Sicilia;Marirosa Toscano	2015	2015 IEEE 15th International Conference on Bioinformatics and Bioengineering (BIBE)	10.1109/BIBE.2015.7367675	biochemistry;carbon dioxide;yttrium;genetics;dna;ion	Robotics	7.974559223470026	-62.47166146610818	25130
6cc1aa0e77ba7d85aa2d3736b99048198b694b42	a hidden markov model for predicting protein interfaces	protein function;protein interface;hidden markov model;sequence profile;protein protein interaction;support vector machine	Protein-protein interactions play a defining role in protein function. Identifying the sites of interaction in a protein is a critical problem for understanding its functional mechanisms, as well as for drug design. To predict sites within a protein chain that participate in protein complexes, we have developed a novel method based on the Hidden Markov Model, which combines several biological characteristics of the sequences neighboring a target residue: structural information, accessible surface area, and transition probability among amino acids. We have evaluated the method using 5-fold cross-validation on 139 unique proteins and demonstrated precision of 66% and recall of 61% in identifying interfaces. These results are better than those achieved by other methods used for identification of interfaces.	accessible surface area;amino acids;cross reactions;cross-validation (statistics);drug design;hidden markov model;interaction;markov chain;staphylococcal protein a	Cao D. Nguyen;Katheleen J. Gardiner;Krzysztof J. Cios	2007	Journal of bioinformatics and computational biology	10.1142/S0219720007002722	protein–protein interaction;biology;support vector machine;computer science;bioinformatics;machine learning;pattern recognition;hidden markov model	Comp.	9.486645869570461	-57.34668279013309	25151
d8abd286b65bfbaa4b2a63fdd66fd33458692a31	zinc - a free database of commercially available compounds for virtual screening	drug design;molecular structure	A critical barrier to entry into structure-based virtual screening is the lack of a suitable, easy to access database of purchasable compounds. We have therefore prepared a library of 727,842 molecules, each with 3D structure, using catalogs of compounds from vendors (the size of this library continues to grow). The molecules have been assigned biologically relevant protonation states and are annotated with properties such as molecular weight, calculated LogP, and number of rotatable bonds. Each molecule in the library contains vendor and purchasing information and is ready for docking using a number of popular docking programs. Within certain limits, the molecules are prepared in multiple protonation states and multiple tautomeric forms. In one format, multiple conformations are available for the molecules. This database is available for free download (http://zinc.docking.org) in several common file formats including SMILES, mol2, 3D SDF, and DOCK flexibase format. A Web-based query tool incorporating a molecular drawing interface enables the database to be searched and browsed and subsets to be created. Users can process their own molecules by uploading them to a server. Our hope is that this database will bring virtual screening libraries to a wide community of structural biologists and medicinal chemists.	boat dock;catalogs;docking (molecular);download;interface device component;libraries;logp machine;molecular weight;personnameuse - assigned;purchasing;question (inquiry);server (computer);server (computing);simplified molecular input line entry specification;simplified molecular-input line-entry system;upload;virtual screening;zinc database;format	John J. Irwin;Brian K. Shoichet	2005	Journal of chemical information and modeling	10.1021/ci049714+	chemistry;virtual screening;computer science;bioinformatics;zinc;combinatorial chemistry;computational chemistry;world wide web;drug design	Comp.	-3.011859836375528	-59.393483789640754	25270
a31f360cf95b5e5beee525e43ab31063cf235ee6	dynamics of emotional facial expression recognition in individuals with social anxiety		This paper demonstrates the utility of ambient-focal attention and pupil dilation dynamics to describe visual processing of emotional facial expressions. Pupil dilation and focal eye movements reflect deeper cognitive processing and thus shed more light on the dynamics of emotional expression recognition. Socially anxious individuals ( N = 24) and non-anxious controls ( N = 24) were asked to recognize emotional facial expressions that gradually morphed from a neutral expression to one of happiness, sadness, or anger in 10-sec animations. Anxious cohorts exhibited more ambient face scanning than their non-anxious counterparts. We observed a positive relationship between focal fixations and pupil dilation, indicating deeper processing of viewed faces, but only by non-anxious participants, and only during the last phase of emotion recognition. Group differences in the dynamics of ambient-focal attention support the hypothesis of vigilance to emotional expression processing by socially anxious individuals. We discuss the results by referring to current literature on cognitive psychopathology.		Krzysztof Krejtz;Katarzyna Wisiecka;Izabela Krejtz;Pawel Holas;Michal Olszanowski;Andrew T. Duchowski	2018		10.1145/3204493.3204533	pupillary response;social anxiety;cognitive psychology;facial expression;sadness;vigilance (psychology);emotional expression;anger;cognition;psychology	HCI	13.49691814760227	-76.38402315805503	25283
c9f8c5a71a75f148baf21b53325463225e411ad4	network analysis identifies regulatory hotspots in regions of chromosome interactions		The three-dimensional structure of the genome plays a key role in regulatory control of the cell. Chromosomes are organized nonrandomly inside the nucleus and form a network of interactions. Recent experimental methods such as Hi-C have been used to probe the 3D architecture of the genome, giving average pairwise contact frequencies between chromosomes. However, deducing the spatial organization of chromosomes from this data remains a challenge due to high levels of noise and technical bias. Here, we propose a novel framework that leverages 1D features of the genome (e.g. gene expression) in combination with Hi-C data to identify interacting regions in the genome. First, we find domains of high average interaction in Hi-C maps using a large average submatrix algorithm. Then we construct a weighted network with genomic regions as nodes and interactions as edges, where the edge weights are given by the correlation between genomic features. Individual interacting clusters are determined using weighted correlation clustering on the network. In addition to recapitulating known organizational patterns of chromosome interactions, we validate our predictions using fluorescence in situ hybridization (FISH). We uncover two types of intermingling clusters - active and inactive clusters based on enrichment for RNA polymerase II and H3K9me3, respectively. We show that active clusters are hotspots for transcription factor binding. Our method provides a quantitative framework that allows to couple features of the 1D genome with 3D interactions to uncover the guiding principles of genome spatial organization and regulatory control.	algorithm;cluster analysis;correlation clustering;dna binding site;gene ontology term enrichment;gene regulatory network;hotspot (wi-fi);image resolution;interaction;spatial organization;transcription (software);weighted network	Anastasiya Belyaeva;Saradha Venkatachalapathy;Mallika Nagarajan;G. V. Shivashankar;Caroline Uhler	2017		10.1145/3107411.3108216	weighted network;correlation clustering;transcription factor;bioinformatics;genome;architecture;chromosome;spatial organization;fluorescence in situ hybridization;genetics;biology	Comp.	4.969630744503854	-57.006127822934715	25312
2c1c97afb2cd9a3a3ccd18baea1677be9a06fe57	differentiation of internet addiction risk level based on autonomic nervous responses: the internet-addiction hypothesis of autonomic activity		How high-risk Internet addiction (IA) abusers respond to different autonomic nervous activities compared with low-risk subjects may be a critical research goal with prevention and treatment implications. The aim of the present study was to address this issue by observing differences between high- and low-risk IA abusers in four physiological assessments when surfing the Internet: blood volume pulse (BVP), skin conductance (SC), peripheral temperature (PTEMP), and respiratory response (RESPR). Forty-two male and ten female participants aged 18-24 years were screened with the Chen Internet Addiction Scale (CIAS, 2003), and then separated into high- and low-risk IA groups. Using psychophysiology equipment, participants encountered a 3-minute adaptation period followed by a 6-minute testing period for surfing the Internet on baseline and testing phases. The present results indicate that: (a) the CIAS scores were positively and negatively correlated with the RESPR and the PTEMP; (b) the PTEMP and RESPR of high-risk IA abusers were respectively weaker and stronger than those of low-risk IA abusers; the BVP and SC of high-risk IA abusers were respectively augmented and decreased relative to low-risk IA abusers. Thus we suggest that four autonomic responses may be differentially sensitive to abusers' potency in terms of the IA hypothesis of autonomic activity. The stronger BVP and RESPR responses and the weaker PTEMP reactions of the high-risk IA abusers indicate the sympathetic nervous system was heavily activated in these individuals. However, SC activates parasympathetic responses at the same time in the high-risk IA abusers. The paradoxical responses between the sympathetic and parasympathetic actions are addressed in the discussion.	acclimatization;addictive behavior;autonomic computing;autonomic nervous system;autonomic networking;baseline (configuration management);cns disorder;conductance (graph);drug dependence;emoticon;entity–relationship model;evaluation procedure;internet addiction disorder;mos technology cia;peripheral;projection screen;psychophysiology;pulse;skin conductance	Dong Wei Lu;Jenn Wu Wang;Andrew Chih Wei Huang	2010	Cyberpsychology, behavior and social networking	10.1089/cyber.2009.0254	psychology;psychiatry;simulation;developmental psychology;psychotherapist;social psychology	HCI	17.57949856015437	-79.83901054941092	25316
206344ec6b75890b604b64cead3c4125c98c5d01	conspred: a rule-based (re-)annotation framework for prokaryotic genomes	article letter to editor	MOTIVATION The rapidly growing number of available prokaryotic genome sequences requires fully automated and high-quality software solutions for their initial and re-annotation. Here we present ConsPred, a prokaryotic genome annotation framework that performs intrinsic gene predictions, homology searches, predictions of non-coding genes as well as CRISPR repeats and integrates all evidence into a consensus annotation. ConsPred achieves comprehensive, high-quality annotations based on rules and priorities, similar to decision-making in manual curation and avoids conflicting predictions. Parameters controlling the annotation process are configurable by the user. ConsPred has been used in the institutions of the authors for longer than 5 years and can easily be extended and adapted to specific needs.   SUMMARY The ConsPred algorithm for producing a consensus from the varying scores of multiple gene prediction programs approaches manual curation in accuracy. Its rule-based approach for choosing final predictions avoids overriding previous manual curations.   AVAILABILITY AND IMPLEMENTATION ConsPred is implemented in Java, Perl and Shell and is freely available under the Creative Commons license as a stand-alone in-house pipeline or as an Amazon Machine Image for cloud computing, see https://sourceforge.net/projects/conspred/.   CONTACT thomas.rattei@univie.ac.atSupplementary information: Supplementary data are available at Bioinformatics online.	amazon machine image;amazona;annotation;bioinformatics;choose (action);cloud computing;clustered regularly interspaced short palindromic repeats;conflict (psychology);decision making;digital curation;ephrin type-b receptor 1, human;gene prediction;genome;homologous gene;homology (biology);java programming language;logic programming;perl;rule (guideline);solutions;sourceforge;algorithm	Thomas Weinmaier;Alexander Platzer;Jeroen Frank;Hans-Jörg Hellinger;Patrick Tischler;Thomas Rattei	2016	Bioinformatics	10.1093/bioinformatics/btw393	biology;bioinformatics;data mining;information retrieval	Comp.	-0.5281084297257284	-56.68580537905498	25357
039a7c99c67560814b0f7529039bb3ef8214d032	discovering consensus patterns in biological databases	hierarchical clustering;motifs and tandem repeats;bepress selected works;consensus patterns;consensus patterns motifs and tandem repeats patterns clustering biological databases;biological databases;clustering;life sciences;health science;tandem repeat;patterns;biological database	Consensus patterns, like motifs and tandem repeats, are highly conserved patterns with very few substitutions where no gaps are allowed. In this paper, we present a progressive hierarchical clustering technique for discovering consensus patterns in biological databases over a certain length range. This technique can discover consensus patterns with various requirements by applying a post-processing phase. The progressive nature of the hierarchical clustering algorithm makes it scalable and efficient. Experiments to discover motifs and tandem repeats on real biological databases show significant performance gain over non-progressive clustering techniques.	algorithm;biological database;british informatics olympiad;cluster analysis;conserved sequence;domain-specific language;experiment;hierarchical clustering;requirement;scalability;sequence motif;video post-processing	Mohamed Y. Eltabakh;Walid G. Aref;Mourad Ouzzani;Mohamed H. Ali	2006		10.1007/11960669_15	biological database;computer science;bioinformatics;data mining;world wide web	ML	1.3214862168595236	-57.4030427032623	25362
14cf420e514f62c084adf2a72f4b4cbefe67494a	comparing causality measures of fmri data using pca, cca and vector autoregressive modelling	effective connectivity;functional mri;keywords causality;time series;journal article;conference paper;cca;autoregressive processes;var varx;principal component analysis;magnetic resonance imaging;brain causality;neurophysiology;pca;biomedical mri;causality	Extracting the directional interaction between activated brain areas from functional magnetic resonance imaging (fMRI) time series measurements of their activity is a significant step in understanding the process of brain functions. In this paper, the directional interaction between fMRI time series characterizing the activity of two neuronal sites is quantified using two measures; one derived based on univariate autoregressive and autoregressive exogenous (AR/ARX) and other derived based on multivariate vector autoregressive and vector autoregressive exogenous (VAR/VARX) models. The significance and effectiveness of these measures is illustrated on both simulated and real fMRI data sets. It has been revealed that VAR modelling of the regions of interest is robust in inferring true causality compared to principal component analysis (PCA) and canonical correlation analysis (CCA) based causality methods.	arx;autoregressive model;causality;dimensionality reduction;fbn2 wt allele;magnetic resonance imaging;principal component analysis;region of interest;time series;canonical correlation analysis;fmri	Adnan Shah;Muhammad Usman Khalid;Abd-Krim Karim Seghouane	2012	2012 Annual International Conference of the IEEE Engineering in Medicine and Biology Society	10.1109/EMBC.2012.6347406	econometrics;computer science;magnetic resonance imaging;machine learning;mathematics;neurophysiology;statistics;principal component analysis	ML	23.70923044331899	-76.73704510650906	25401
38f51f078126196b143b2c4b1ba77cd4c32b3675	coupled two-way clustering server	gene expression data;chip	UNLABELLED The CTWC server provides access to the software, CTWC1.00, that implements Coupled Two Way Clustering (Getz et al., 2000), a method designed to mine gene expression data   AVAILABILITY Free, at http://ctwc.weizmann.ac.il.   SUPPLEMENTARY INFORMATION The site has a link to an example which provides figures and detailed explanations	cluster analysis;computer cluster;gene expression;server (computer);server (computing);explanation	Gad Getz;Eytan Domany	2003	Bioinformatics	10.1093/bioinformatics/btg143	chip;biology;computer science;bioinformatics;data mining;database;world wide web	ML	-1.325294993636465	-58.290877370277784	25474
b4fe09003a7777e626efd83a0d1d76242dadc8c2	comparison of microarray designs for class comparison and class discovery	block design;statistical model;cluster analysis;relative efficiency;differentially expressed gene;monte carlo simulation	MOTIVATION Two-color microarray experiments in which an aliquot derived from a common RNA sample is placed on each array are called reference designs. Traditionally, microarray experiments have used reference designs, but designs without a reference have recently been proposed as alternatives.   RESULTS We develop a statistical model that distinguishes the different levels of variation typically present in cancer data, including biological variation among RNA samples, experimental error and variation attributable to phenotype. Within the context of this model, we examine the reference design and two designs which do not use a reference, the balanced block design and the loop design, focusing particularly on efficiency of estimates and the performance of cluster analysis. We calculate the relative efficiency of designs when there are a fixed number of arrays available, and when there are a fixed number of samples available. Monte Carlo simulation is used to compare the designs when the objective is class discovery based on cluster analysis of the samples. The number of discrepancies between the estimated clusters and the true clusters were significantly smaller for the reference design than for the loop design. The efficiency of the reference design relative to the loop and block designs depends on the relation between inter- and intra-sample variance. These results suggest that if cluster analysis is a major goal of the experiment, then a reference design is preferable. If identification of differentially expressed genes is the main concern, then design selection may involve a consideration of several factors.	aliquotting;class comparison;cluster analysis;estimated;experiment;microarray;monte carlo method;rna;reference design;reference implementation;sample variance;simulation;statistical model	Kevin Dobbin;Richard Simon	2002	Bioinformatics	10.1093/bioinformatics/18.11.1438	statistical model;econometrics;block design;computer science;bioinformatics;efficiency;cluster analysis;statistics;monte carlo method	Comp.	4.762729505228371	-52.46313065685751	25484
393ddf850d806c4eeaec52a1e2ea4c4dcc5c76ee	learning over long time lags		The advantage of recurrent neural networks (RNNs) in learni ng dependencies between time-series data has distinguished RNNs from other deep learning models. Recent ly, many advances are proposed in this emerging field. However, there is a lack of comprehensive review on mem ory models in RNNs in the literature. This paper provides a fundamental review on RNNs and long short te rm memory (LSTM) model. Then, provides a surveys of recent advances in different memory enhancement s and learning techniques for capturing long term dependencies in RNNs.	artificial neural network;deep learning;long short-term memory;recurrent neural network;time series	Hojjat Salehinejad	2016	CoRR		simulation;computer science;artificial intelligence;machine learning	ML	17.72094904287366	-53.460477371067945	25490
b57c9e9d91afda0d1e17e8457c1f589050375a4c	"""novel angiogenic functional targets predicted through """"dark matter"""" assessment in protein networks"""	random walks with restart;ppi networks;genes candidate prioritization;functional prediction proteins;networks topology;protein domain fusions	In order to model protein networks we must extend our knowledge of the protein associations occurring in molecular systems and their functional relationships. We have significantly increased the accuracy of protein association predictions by the meta-statistical integration of three computational methods specifically designed for eukaryotic proteomes. From this former work it was discovered that high-throughput experimental assays seem to perform biased screenings of the real protein networks and leave important areas poorly characterized. This finding supports the convenience to combine computational prediction approaches to model protein interaction networks. We address in this work the challenge of integrating context information, present in predicted and known protein network models, to functionally characterize novel proteins. We applied a random walk-with-restart kernel to our models aiming at fixing some poorly described or unknown proteins involve in angiogenesis. This approach reveals some novel key angiogenic components within the human interactome.	dark matter	Ian Morilla;Miguel Ángel Medina;Juan Garcia Ranea	2010		10.1007/978-3-642-28062-7_10	bioinformatics;data mining	Comp.	6.399803403694197	-57.236917816740615	25502
e74ace7763f7bdebb4beb0a6e139fa07f28407ab	rapid comparison of protein binding site surfaces with property encoded shape distributions	computers;protein structure secondary;ligands;binding sites;models molecular;time factors;proteins;glutamic acid;protein binding;inositol phosphates;user computer interface	Patterns in shape and property distributions on the surface of binding sites are often conserved across functional proteins without significant conservation of the underlying amino-acid residues. To explore similarities of these sites from the viewpoint of a ligand, a sequence and fold-independent method was created to rapidly and accurately compare binding sites of proteins represented by property-mapped triangulated Gauss-Connolly surfaces. Within this paradigm, signatures for each binding site surface are produced by calculating their property-encoded shape distributions (PESD), a measure of the probability that a particular property will be at a specific distance to another on the molecular surface. Similarity between the signatures can then be treated as a measure of similarity between binding sites. As postulated, the PESD method rapidly detected high levels of similarity in binding site surface characteristics even in cases where there was very low similarity at the sequence level. In a screening experiment involving each member of the PDBBind 2005 data set as a query against the rest of the set, PESD was able to retrieve a binding site with identical E.C. (Enzyme Commission) numbers as the top match in 79.5% of cases. The ability of the method in detecting similarity in binding sites with low sequence conservations was compared to state-of-the-art binding site comparison methods.	accessible surface area;binding sites;caspase-1;enzyme commission number;gauss;hl7publishingsubsection <query>;ligands;name binding;pdbbind database;programming paradigm;published comment;sensor;type signature	Sourav Das;Arshad Kokardekar;Curt M. Breneman	2009	Journal of chemical information and modeling	10.1021/ci900317x	crystallography;biochemistry;plasma protein binding;chemistry;bioinformatics;binding site;organic chemistry;ligand	Comp.	11.395469819564182	-59.193089676913814	25561
0796146a39688f9be4957be5b6f00f05b716cc0d	latent attractors: a model for context-dependent place representations in the hippocampus	modelizacion;attracteur;neurologie;pyramidal cell;cognitive map;connectionism;system dynamics;conexionismo;dentate gyrus hilus;hippocampus;neurology;selection;modele calcul;attractor;hipocampo;atractor;modelisation;latent attractor;connexionnisme;hippocampe;attracteur latent;neurologia;context dependent;reseau neuronal;seleccion;modeling;computational model;red neuronal;context dependent place representation;representation place contexte dependant;neural network;dgh system	Cells throughout the rodent hippocampal system show place-specific patterns of firing called place fields, creating a coarse-coded representation of location. The dependencies of this place codeor cognitive mapon sensory cues have been investigated extensively, and several computational models have been developed to explain them. However, place representations also exhibit strong dependence on spatial and behavioral context, and identical sensory environments can produce very different place codes in different situations. Several recent studies have proposed models for the computational basis of this phenomenon, but it is still not completely understood. In this article, we present a very simple connectionist model for producing context-dependent place representations in the hippocampus. We propose that context dependence arises in the den-tate gyrus-hilus (DGH) system, which functions as a dynamic selector, disposing a small group of granule and pyramidal cells to fire in response to afferent stimulus while depressing the rest. It is hypothesized that the DGH system dynamics has latent attractors, which are unmasked by the afferent input and channel system activity into subpopulations of cells in the DG, CA3, and other hippocampal regions as observed experimentally. The proposed model shows that a minimally structured hippocampus-like system can robustly produce context-dependent place codes with realistic attributes.	ca3 field;code;computation;computational model;connectionism;context-sensitive language;discontinuous galerkin method;experiment;granule (oracle dbms);hippocampus (brain);precentral gyrus;system dynamics;decigram	Simona Doboli;Ali A. Minai;Phillip J. Best	2000	Neural Computation	10.1162/089976600300015484	psychology;selection;connectionism;neurology;neuroscience;systems modeling;cognitive map;computer science;artificial intelligence;machine learning;context-dependent memory;hippocampus;system dynamics;communication;computational model;attractor;artificial neural network	ML	20.660316322356717	-70.14028689498129	25605
141d4d6f17ceb4357dddf616e6f286bb2415f911	growing bayesian network models of gene networks from seed genes	learning process;bayesian network;high dimensionality;gene network;gene finding;gene expression data;engineering and technology;teknik och teknologier;biological data;computational biology	MOTIVATION For the last few years, Bayesian networks (BNs) have received increasing attention from the computational biology community as models of gene networks, though learning them from gene-expression data is problematic. Most gene-expression databases contain measurements for thousands of genes, but the existing algorithms for learning BNs from data do not scale to such high-dimensional databases. This means that the user has to decide in advance which genes are included in the learning process, typically no more than a few hundreds, and which genes are excluded from it. This is not a trivial decision. We propose an alternative approach to overcome this problem.   RESULTS We propose a new algorithm for learning BN models of gene networks from gene-expression data. Our algorithm receives a seed gene S and a positive integer R from the user, and returns a BN for the genes that depend on S such that less than R other genes mediate the dependency. Our algorithm grows the BN, which initially only contains S, by repeating the following step R + 1 times and, then, pruning some genes; find the parents and children of all the genes in the BN and add them to it. Intuitively, our algorithm provides the user with a window of radius R around S to look at the BN model of a gene network without having to exclude any gene in advance. We prove that our algorithm is correct under the faithfulness assumption. We evaluate our algorithm on simulated and biological data (Rosetta compendium) with satisfactory results.	algorithm;bayesian network;cs-rosetta;compendium;database;databases;exclusion;gene regulatory network;integer (number);positive integer;seed;emotional dependency	José M. Peña;Johan Björkegren;Jesper Tegnér	2005	Bioinformatics	10.1093/bioinformatics/bti1137	biology;gene regulatory network;biological data;computer science;bioinformatics;machine learning;bayesian network;data mining;mathematics;genetics;statistics	ML	1.4783181742808351	-52.41152267598616	25606
8faccc02f96d1b6d043f69bcae61d48ef2afbe8c	the arabidopsis information resource (tair): a model organism database providing a centralized, curated gateway to arabidopsis biology, research materials and community	functional annotation;controlled vocabulary;computer graphics;genome plant;databases genetic;models biological;gene expression data;nucleotide sequence;arabidopsis thaliana;polymorphism genetic;interactive display;internet;gene ontology annotation;polymorphism;arabidopsis;data visualization;gene family;the arabidopsis information resource;arabidopsis proteins;metabolic pathway;information storage and retrieval;data retrieval;oligonucleotide array sequence analysis	Arabidopsis thaliana is the most widely-studied plant today. The concerted efforts of over 11 000 researchers and 4000 organizations around the world are generating a rich diversity and quantity of information and materials. This information is made available through a comprehensive on-line resource called the Arabidopsis Information Resource (TAIR) (http://arabidopsis.org), which is accessible via commonly used web browsers and can be searched and downloaded in a number of ways. In the last two years, efforts have been focused on increasing data content and diversity, functionally annotating genes and gene products with controlled vocabularies, and improving data retrieval, analysis and visualization tools. New information include sequence polymorphisms including alleles, germplasms and phenotypes, Gene Ontology annotations, gene families, protein information, metabolic pathways, gene expression data from microarray experiments and seed and DNA stocks. New data visualization and analysis tools include SeqViewer, which interactively displays the genome from the whole chromosome down to 10 kb of nucleotide sequence and AraCyc, a metabolic pathway database and map tool that allows overlaying expression data onto the pathway diagrams. Finally, we have recently incorporated seed and DNA stock information from the Arabidopsis Biological Resource Center (ABRC) and implemented a shopping-cart style on-line ordering system.	base sequence;centralized computing;controlled vocabulary;data retrieval;data visualization;diagram;experiment;gene expression;gene family;gene ontology;gene regulatory network;genetic polymorphism;geographic information systems;imagery;information resources;interactivity;laryngeal web;microarray;nucleotides;online and offline;phenotype;weatherstar	Seung Yon Rhee;William D. Beavis;Tanya Z. Berardini;Guanghong Chen;David A. Dixon;Aisling Doyle;Margarita Garcia-Hernandez;Eva Huala;Gabriel C Lander;Mary Montoya;Neil Miller;Lukas A. Mueller;Suparna Mundodi;Leonore Reiser;Julie Tacklind;Dan C. Weems;Yihe Wu;Iris Xu;Daniel Yoo;Jungwon Yoon	2003	Nucleic acids research	10.1093/nar/gkg076	biology;polymorphism;metabolic pathway;controlled vocabulary;the internet;nucleic acid sequence;bioinformatics;gene family;computer graphics;genetics;data retrieval;data visualization	Comp.	-2.1564336689847416	-60.138599748097285	25650
b18337b82533b023d8d25685d46fec50d2dbbc92	intelligent data analysis of human bone density	databases;definite medical diagnosis;information services bone density measurement data analysis decision trees medical diagnostic computing diseases medical expert systems;longitudinal study;human bone density;decision tree;density measurement;minerals;random sampling;information services;medical expert systems;human bone density osteoporosis database women precautionary examinations definite medical diagnosis intelligent data analysis decision tree construction known medical criteria;intelligent data analysis;data analysis;bones;data analysis humans osteoporosis medical diagnostic imaging bones decision trees minerals databases medical diagnosis decision making;precautionary examinations;intelligence analysis;bone;osteoporosis;diseases;women;bone density;humans;decision trees;osteoporosis database;medical diagnostic computing;medical diagnosis;decision tree construction;known medical criteria;medical diagnostic imaging	In this paper we present the results of an intelligent analysis of osteoporosis database gathered during a longitudinal study in which a random sample of 100 women who had passed precautionary examinations for detection of osteoporosis over five years and were not referred for a definite medical diagnosis was pulled from the records. The intelligent data analysis using advanced methods for decision tree construction was used in order to try to find the main factors that can reduce the risk for development of osteoporosis in women. Most of the extracted knowledge confirmed known medical criteria that put women to risk for osteoporosis, however some new interesting patterns have also been shown.	decision tree;trusted computer system evaluation criteria	Petra Povalej Brzan;Mitja Lenic;Milan Zorman;Peter Kokol;Margaret G. E. Peterson;Joseph M. Lane	2003	16th IEEE Symposium Computer-Based Medical Systems, 2003. Proceedings.	10.1109/CBMS.2003.1212821	medicine;pathology;computer science;machine learning;decision tree;statistics	Embedded	2.9930368686148046	-77.58238831905226	25772
be2c2735d2674f04df6f7a3e4c6d5cee22f796c9	modulation of neuronal activity after spinal cord stimulation for neuropathic pain; h<ce:inf loc=post>2</ce:inf><ce:sup loc=post>15</ce:sup>o pet study	spinal cord stimulation;statistical parametric map;complex regional pain syndrome;positron emission tomography;pain threshold;visual analog scale;spinal cord injury;anterior cingulate cortex;regional cerebral blood flow;neuropathic pain;lower limb;neuronal activity	Spinal cord stimulation (SCS) is an effective therapy for chronic neuropathic pain. However, the detailed mechanisms underlying its effects are not well understood. Positron emission tomography (PET) with H(2)(15)O was applied to clarify these mechanisms. Nine patients with intractable neuropathic pain in the lower limbs were included in the study. All patients underwent SCS therapy for intractable pain, which was due to failed back surgery syndrome in three patients, complex regional pain syndrome in two, cerebral hemorrhage in two, spinal infarction in one, and spinal cord injury in one. Regional cerebral blood flow (rCBF) was measured by H(2)(15)O PET before and after SCS. The images were analyzed with statistical parametric mapping software (SPM2). SCS reduced pain; visual analog scale values for pain decreased from 76.1+/-25.2 before SCS to 40.6+/-4.5 after SCS (mean+/-SE). Significant rCBF increases were identified after SCS in the thalamus contralateral to the painful limb and in the bilateral parietal association area. The anterior cingulate cortex (ACC) and prefrontal areas were also activated after SCS. These results suggest that SCS modulates supraspinal neuronal activities. The contralateral thalamus and parietal association area would regulate the pain threshold. The ACC and prefrontal areas would control the emotional aspects of intractable pain, resulting in the reduction of neuropathic pain after SCS.	analog;bilateral filter;cerebral cortex;cerebrovascular circulation;cingulate cortex;cognition;complex regional pain syndromes;deep brain stimulation;failed back surgery syndrome;infarction;limb structure;modulation;neuralgia;neurostimulation procedures of spinal cord tissue;pain disorder;pain, intractable;patients;polyethylene terephthalate;positron-emission tomography;positrons;spinal cord injuries;spinal cord neoplasms;spinal cord stimulator;thalamic structure;traumatic cerebral hemorrhage	Haruhiko Kishima;Youichi Saitoh;Satoru Oshino;Koichi Hosomi;Mohamed Ali;Tomoyuki Maruo;Masayuki Hirata;Tetsu Goto;Takufumi Yanagisawa;Masahiko Sumitani;Yasuhiro Osaki;Jun Hatazawa;Toshiki Yoshimine	2010	NeuroImage	10.1016/j.neuroimage.2009.10.054	psychology;neuroscience;visual analogue scale;anesthesia;referred pain;premovement neuronal activity;surgery;threshold of pain	ML	18.911106146346825	-79.39892109181163	25908
1381c62ddb7c34de60a04d9fcc09aa29f0bfa01a	neurally-based algorithms for image processing	oscillations;brain;image segmentation;image processing;neural nets image segmentation brain image reconstruction;neural nets;primary visual cortex image processing neurally based algorithms image segmentation human brain contiguous stimuli synchronous oscillations neural synchrony;primary visual cortex;local features;image reconstruction;temporal coding;human brain;image processing neurons fires timing image reconstruction biology biological information theory physics laboratories image segmentation	One of the more difficult problems in image processing is segmentation. The human brain has an ability that is unmatched by any current technology for breaking down the world into distributed features and reconstructing them into distinct objects. Neurons encode information both in the number of spikes fired in a given time period, which indicates the strength with which a given local feature is present, and in the temporal code or relative timing of the spike, indicating whether the individual features are part of the same or different objects. Neurons that respond to contiguous stimuli produce synchronous oscillations, while those that are not fire independently. Thus, neural synchrony could be used as a tag for each pixel in an image indicating to which object it belongs. We have developed a simulation based on the primary visual cortex. We found that neurons that respond to the same object oscillate synchronously while those that respond to different objects fire independently.	algorithm;encode;image processing;neural coding;neural oscillation;pixel;simulation;the spike (1997)	Mark Flynn;Henry D. I. Abarbanel;Garrett T. Kenyon	2004	33rd Applied Imagery Pattern Recognition Workshop (AIPR'04)	10.1109/AIPR.2004.34	iterative reconstruction;computer vision;feature detection;image processing;computer science;machine learning;image segmentation;oscillation	ML	20.625853288379872	-68.35818173625243	25965
5e36fa3110584ecb446e3beeac1c45e5a9fae920	a dynamical clustering model of brain connectivity inspired by the n-body problem	biological patents;biomedical journals;text mining;europe pubmed central;citation search;n body simulation;gravity;citation networks;research articles;abstracts;open access;mri;life sciences;clinical guidelines;connectivity;full text;diffusion;rest apis;orcids;europe pmc;biomedical research;bioinformatics;literature search	We present a method for studying brain connectivity by simulating a dynamical evolution of the nodes of the network. The nodes are treated as particles, and evolved under a simulated force analogous to gravitational acceleration in the well-known N -body problem. The particle nodes correspond to regions of the cortex. The locations of particles are defined as the centers of the respective regions on the cortex and their masses are proportional to each region's volume. The force of attraction is modeled on the gravitational force, and explicitly made proportional to the elements of a connectivity matrix derived from diffusion imaging data. We present experimental results of the simulation on a population of 110 subjects from the Alzheimer's Disease Neuroimaging Initiative (ADNI), consisting of healthy elderly controls, early mild cognitively impaired (eMCI), late MCI (LMCI), and Alzheimer's disease (AD) patients. Results show significant differences in the dynamic properties of connectivity networks in healthy controls, compared to eMCI as well as AD patients.	adjacency matrix;alzheimer's disease neuroimaging initiative;diffusion anisotropy;dynamical system;hyperlipoproteinemia type v;inspiration function;n-body problem;patients;simulation;whole earth 'lectronic link	Gautam Prasad;Josh Burkart;Shantanu H. Joshi;Talia M. Nir;Arthur W. Toga;Paul M. Thompson	2013	Multimodal brain image analysis : third International Workshop, MBIA 2013, held in conjunction with MICCAI 2013, Nagoya, Japan, September 22, 2013 : proceedings. MBIA (Workshop)	10.1007/978-3-319-02126-3_13	computer science;bioinformatics;artificial intelligence;data mining	ML	21.088494891631957	-76.4969744953918	25971
43ac488b7b81ddeb9d9bd2aa0e4aa3dc54ef7568	attention allocation and task representation during joint action planning	event related potentials;social sciences;performing musicians;electrophysiological analysis;spatial attention;cortical potentials;supplementary motor area;movement related potentials;contingent negative variation;finger movements;action simulation	We investigated whether people take into account an interaction partner's attentional focus and whether they represent in advance their partner's part of the task when planning to engage in a synchronous joint action. The experiment involved two participants planning and performing joint actions (i.e., synchronously lifting and clinking glasses), unimanual individual actions (i.e., lifting and moving a glass as if clinking with another person), and bimanual individual actions. EEG was recorded from one of the participants. We employed a choice reaction paradigm where a visual cue indicated the type of action to be planned, followed 1.5 sec later by a visual go stimulus, prompting the participants to act. We studied attention allocation processes by examining two lateralized EEG components, namely the anterior directing attention negativity and the late directing attention positivity. Action planning processes were examined using the late contingent negative variation and the movement-related potential. The results show that early stages of joint action planning involve dividing attention between locations in space relevant for one's own part of the joint action and locations relevant for one's partner's part of the joint action. At later stages of joint action planning, participants represented in advance their partner's upcoming action in addition to their own action, although not at an effector-specific level. Our study provides electrophysiological evidence supporting the operation of attention sharing processes and predictive self/other action representation during the planning phase of a synchronous joint task.	automated planning and scheduling;bereitschaftspotential;contingency (philosophy);contingent negative variation;electroencephalography;eyeglasses;lambda lifting;negativity (quantum mechanics);optic nerve glioma, childhood;programming paradigm	Dimitrios Kourtis;Günther Knoblich;Mateusz Woźniak;Natalie Sebanz	2014	Journal of Cognitive Neuroscience	10.1162/jocn_a_00634	psychology;event-related potential;developmental psychology;contingent negative variation;communication;social psychology;cognitive science	AI	15.88230398964518	-77.54544955797151	26014
9a76e3722eb8a2e38233e11e44edb6de4be6b2c7	modeling flexible pharmacophores with distance geometry, scoring, and bound stretching		"""The study of pharmacophores, i.e., of common features between different ligands, is important for the quantitative identification of """"compatible"""" enzymes and binding species. A pharmacophore-based technique is developed that combines multiple conformations with a distance geometry method to create flexible pharmacophore representations. It uses a set of low-energy conformations combined with a new process we call bound stretching to create sets of distance bounds, which contain all or most of the low-energy conformations. The bounds can be obtained using the exact distances between pairs of atoms from the different low-energy conformations. To avoid missing conformations, we can take advantage of the triangle distance inequality between sets of three points to logically expand a set of upper and lower distance bounds (bound stretching). The flexible pharmacophore can be found using a 3-D maximal common subgraph method, which uses the overlap of distance bounds to determine the overlapping structure. A scoring routine is implemented to select the substructures with the largest overlap because there will typically be many overlaps with the maximum number of overlapping bounds. A case study is presented in which 3-D flexible pharmacophores are generated and used to eliminate potential binding species identified by a 2-D pharmacophore method. A second case study creates flexible pharmacophores from a set of thrombin ligands. These are used to compare the new method with existing pharmacophore identification software."""		Michael Binns;Sam P. de Visser;Constantinos Theodoropoulos	2012	Journal of chemical information and modeling	10.1021/ci200442h	mathematical optimization;combinatorics;computational chemistry;mathematics;ligandscout	Robotics	13.657410833956137	-58.02574611462651	26067
58bdc626d19fd01375985d20e8c972338b5ad87b	a new model of the spinal locomotor networks of a salamander and its properties	salamander;spinal locomotor networks;locomotion-controlled neural networks (lcnns);biomechanical model;gait transition	A salamander is an ideal animal for studying the spinal locomotor network mechanism of vertebrates from an evolutionary perspective since it represents the transition from an aquatic to a terrestrial animal. However, little is known about the spinal locomotor network of a salamander. A spinal locomotor network model is a useful tool for exploring the working mechanism of the spinal networks of salamanders. A new spinal locomotor network model for a salamander is built for a three-dimensional (3D) biomechanical model of the salamander using a novel locomotion-controlled neural network model. Based on recent experimental data on the spinal circuitry and observational results of gaits of vertebrates, we assume that different interneuron sets recruited for mediating the frequency of spinal circuits are also related to the generation of different gaits. The spinal locomotor networks of salamanders are divided into low-frequency networks for walking and high-frequency networks for swimming. Additionally, a new topological structure between the body networks and limb networks is built, which only uses the body networks to coordinate the motion of limbs. There are no direct synaptic connections among limb networks. These techniques differ from existing salamander spinal locomotor network models. A simulation is performed and analyzed to validate the properties of the new spinal locomotor networks of salamanders. The simulation results show that the new spinal locomotor networks can generate a forward walking gait, a backward walking gait, a swimming gait, and a turning gait during swimming and walking. These gaits can be switched smoothly by changing external inputs from the brainstem. These properties are consistent with those of a real salamander. However, it is still difficult for the new spinal locomotor networks to generate highly efficient turning during walking, 3D swimming, nonrhythmic movements, and so on. New experimental data are required for further validation.	aquatic ecosystem;artificial neural network;brain stem;chorea;electronic circuit;interneurons;limb structure;movement;network model;simulation;smoothing;spinal cord stimulator;synaptic package manager;terrestrial television;vertebrates	Qiang Liu;Huizhen Yang;Jinxue Zhang;Jingzhuo Wang	2018	Biological Cybernetics	10.1007/s00422-018-0759-9	backward walking;neuroscience;machine learning;artificial neural network;artificial intelligence;network model;gait;mathematics;brainstem	AI	18.223311954878852	-70.96263138810066	26160
18f1dcdab0da2755f56994993241e4e6920917a4	generalisation in humans and deep neural networks		We compare the robustness of humans and current convolutional deep neural networks (DNNs) on object recognition under twelve different types of image degradations. First, using three well known DNNs (ResNet-152, VGG-19, GoogLeNet) we find the human visual system to be more robust to nearly all of the tested image manipulations, and we observe progressively diverging classification error-patterns between humans and DNNs when the signal gets weaker. Secondly, we show that DNNs trained directly on distorted images consistently surpass human performance on the exact distortion types they were trained on, yet they display extremely poor generalisation abilities when tested on other distortion types. For example, training on salt-and-pepper noise does not imply robustness on uniform white noise and vice versa. Thus, changes in the noise distribution between training and testing constitutes a crucial challenge to deep learning vision systems that can be systematically addressed in a lifelong machine learning approach. Our new dataset consisting of 83K carefully measured human psychophysical trials provide a useful reference for lifelong robustness against image degradations set by the human visual system.	artificial neural network;convolutional neural network;deep learning;distortion;human reliability;machine learning;outline of object recognition;salt-and-pepper noise;white noise	Robert Geirhos;Carlos R. Medina Temme;Jonas Rauber;Heiko H. Schütt;Matthias Bethge;Felix A. Wichmann	2018			pattern recognition;computer science;deep learning;artificial intelligence;artificial neural network;robustness (computer science);distortion;cognitive neuroscience of visual object recognition;generalization;white noise;human visual system model	ML	20.373157221447936	-52.16845800142664	26245
b954f309c83b2d2b272b160fb87cf0d88dcbaafb	inference of tumor phylogenies with improved somatic mutation discovery	phylogeny;high throughput nucleotide sequencing;dna mutational analysis;models genetic;algorithms;humans;neoplasms;computer simulation;polymorphism single nucleotide;mutation	Next-generation sequencing technologies provide a powerful tool for studying genome evolution during progression of advanced diseases such as cancer. Although many recent studies have employed new sequencing technologies to detect mutations across multiple, genetically related tumors, current methods do not exploit available phylogenetic information to improve the accuracy of their variant calls. Here, we present a novel algorithm that uses somatic single-nucleotide variations (SNVs) in multiple, related tissue samples as lineage markers for phylogenetic tree reconstruction. Our method then leverages the inferred phylogeny to improve the accuracy of SNV discovery. Experimental analyses demonstrate that our method achieves up to 32% improvement for somatic SNV calling of multiple, related samples over the accuracy of GATK's Unified Genotyper, the state-of-the-art multisample SNV caller.		Raheleh Salari;Syed Shayon Saleh;Dorna Kashef Haghighi;David Khavari;Daniel E. Newburger;Robert B. West;Arend Sidow;Serafim Batzoglou	2013	Journal of computational biology : a journal of computational molecular cell biology	10.1089/cmb.2013.0106	computer simulation;mutation;biology;molecular biology;bioinformatics;genetics	Comp.	1.6022485696841544	-54.295883163080646	26258
220df5a77ebc3ed6dd59175b07ae828c07b2af97	fully automated ab initio protein structure prediction using i-stes, hmmstr and rosetta		MOTIVATION The Monte Carlo fragment insertion method for protein tertiary structure prediction (ROSETTA) of Baker and others, has been merged with the I-SITES library of sequence structure motifs and the HMMSTR model for local structure in proteins, to form a new public server for the ab initio prediction of protein structure. The server performs several tasks in addition to tertiary structure prediction, including a database search, amino acid profile generation, fragment structure prediction, and backbone angle and secondary structure prediction. Meeting reasonable service goals required improvements in the efficiency, in particular for the ROSETTA algorithm.   RESULTS The new server was used for blind predictions of 40 protein sequences as part of the CASP4 blind structure prediction experiment. The results for 31 of those predictions are presented here. 61% of the residues overall were found in topologically correct predictions, which are defined as fragments of 30 residues or more with a root-mean-square deviation in superimposed alpha carbons of less than 6A. HMMSTR 3-state secondary structure predictions were 73% correct overall. Tertiary structure predictions did not improve the accuracy of secondary structure prediction.	algorithm;amino acid sequence;amino acids;casp4 protein, human;carbon;clinical act of insertion;contact order;correctness (computer science);de novo protein structure prediction;high-throughput computing;insertion mutation;internet backbone;mandibular right second molar tooth;merge;monte carlo method;peptide sequence;protein, organized by structure;server (computer);server (computing);simulation;three-state logic;throughput;torsion (gastropod);vertebral column;algorithm;tertiary	Christopher Bystroff;Yu Shao	2002	Bioinformatics			Comp.	12.384979313379077	-60.01234678501506	26272
a30d96efe5fc460c7096eba129dc9ce9e2fadabd	space is special: a domain-specific mapping between time and nontemporal magnitude		Across different domains the magnitude of a stimulus is positively correlated with its perceived duration: bigger, brighter or louder stimuli are usually perceived to last longer than smaller, dimmer or softer ones. According to A Theory of Magnitude (ATOM), temporal and nontemporal magnitudes are linked in the human mind by virtue of sharing a common metric. This claim has been challenged by studies in the domains of brightness and loudness suggesting that it is not the difference in magnitude between stimuli, but rather their degree of change from background that modulates duration judgments. But do the same relationships hold between perceived duration and all prothetic dimensions? We tested the influence of stimulus magnitude and relative change on temporal judgment in the domain of space. We found that, unlike brightness and loudness, spatial length can influence duration judgments independently of the degree of change from a common background, and that this effect is context dependent. Thus, an approach based exclusively on the degree of change between stimulus and background is not sufficient to account for the effect of magnitude on temporal judgments. Our results suggest that space has a privileged link with temporal representations compared to other prothetic domains, challenging the hypothesis that space-time relationships are the product of a domain-general magnitude system.	atom;mind;modulation;relative change and difference;sensitivity and specificity;unidentified flying oddball	Roberto Bottini;Daniel Casasanto	2013			social psychology;psychology;goldstone;stimulus (physiology);absolute magnitude;brightness;magnitude (mathematics);loudness;spite	Web+IR	15.32434098283665	-76.85826294618384	26282
96f97f13f7d3288c3e42317260681c2ce9c2688b	comprehensive evaluation of rna-seq quantification methods for linearity	computational biology bioinformatics;algorithms;computer appl in life sciences;microarrays;bioinformatics	Deconvolution is a mathematical process of resolving an observed function into its constituent elements. In the field of biomedical research, deconvolution analysis is applied to obtain single cell-type or tissue specific signatures from a mixed signal and most of them follow the linearity assumption. Although recent development of next generation sequencing technology suggests RNA-seq as a fast and accurate method for obtaining transcriptomic profiles, few studies have been conducted to investigate best RNA-seq quantification methods that yield the optimum linear space for deconvolution analysis. Using a benchmark RNA-seq dataset, we investigated the linearity of abundance estimated from seven most popular RNA-seq quantification methods both at the gene and isoform levels. Linearity is evaluated through parameter estimation, concordance analysis and residual analysis based on a multiple linear regression model. Results show that count data gives poor parameter estimations, large intercepts and high inter-sample variability; while TPM value from Kallisto and Salmon shows high linearity in all analyses. Salmon and Kallisto TPM data gives the best fit to the linear model studied. This suggests that TPM values estimated from Salmon and Kallisto are the ideal RNA-seq measurements for deconvolution studies.	benchmark (computing);concordance (publishing);count data;curve fitting;deconvolution;electronic signature;estimation theory;heart rate variability;linear model;massively-parallel sequencing;mathematics;mixed-signal integrated circuit;next-generation network;population parameter;quantitation;rna;regression analysis;sequence number;silo (dataset);trusted platform module;topiramate	Haijing Jin;Ying-Wooi Wan;Zhandong Liu	2017		10.1186/s12859-017-1526-y	biology;dna microarray;computer science;bioinformatics	Comp.	4.697593027859731	-52.935822822409435	26318
fc594eeb23bcf33d88cd6403a9772a49c1d7cc10	soymetdb: the soybean metabolome database	databases;stress;chemicals;soymetdb;arabidopsis metabolomic data soymetdb soybean metabolome database soybean community one stop web resource data integration data mining data visualization metabolite profiling data hmdb knapsack;arabidopsis metabolomic data;expression pattern;metabolomics;compounds;time course;metabolite profiling data;database;soybean metabolome database;one stop web resource;multimedia databases bioinformatics botany data mining data visualisation;dynamic linking;data mining;data visualisation;metabolome;metabolite profiling;proteins;glycine max;data visualization;multimedia databases;soybean;hmdb;tool integration;metabolite;metabolomics databases hair compounds stress chemicals proteins;soybean community;glycine max metabolome soybean metabolite database;botany;data integration;bioinformatics;knapsack;hair	SoyMetDB is a metabolomic database for soybean, developed to target the growing needs of the soybean community. The goal is to provide a one-stop web resource for integrating, mining and visualizing soybean metabolomic data, including identification and expression of various metabolites across different experiments and time courses. It incorporates GC-MS and LC-MS based metabolite-profiling data dynamically linked to metabolite information from other public metabolomic databases, including HMDB and Knapsack. SoyMetDB includes Arabidopsis metabolomic data for cross-species comparisons and can retrieve information including the expression patterns of various experiments for complete or partial metabolite name queries. It also incorporates a pathway viewer tool integrating the data from various experimental conditions and presenting them on the pathways to highlight the expressed metabolite, and identifies the most highly represented pathways for multiple metabolite queries. SoyMetDB can be accessed at http://soymetdb.org.	experiment;gene regulatory network;human metabolome database;metabolomics;web resource	Trupti Joshi;Qiuming Yao;D. Franklin Levi;Laurent Brechenmacher;Babu Valliyodan;Gary Stacey;Henry T. Nguyen;Dong Xu	2010	2010 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)	10.1109/BIBM.2010.5706563	biology;chemical industry;computer science;bioinformatics;data science;data integration;metabolome;data mining;human metabolome database;stress;knapsack problem;data visualization	DB	-1.733988219024751	-58.849399025422464	26319
ec943927c81dbe3fc5df152cf44bc1199620a514	synthesis of (r)-modafinil via organocatalyzed and non-heme iron-catalyzed sulfoxidation using h2o2 as an environmentally benign oxidant		The first organocatalyzed sulfoxidation reaction towards enantioenriched (R)-modafinil (Armodafinil®), a drug against narcolepsy, is reported here. A series of chiral organocatalysts, e.g., different chiral BINOL-phosphates, or a fructose-derived N-substituted oxazolidinone ketone (Shi catalyst) were applied for the sulfoxidation reaction with environmentally friendly H2O2 as a convenient oxygen transferring agent. Furthermore, the potential of a biomimetic catalytic system consisting of FeCl3 and a dipeptide-based chiral ligand was demonstrated, which constitutes the most successful asymmetric non-heme iron-catalyzed synthesis of (R)-modafinil so far.	biomimetics;chirality (chemistry);hydrogen	Felix E. Held;Kerstin A. Stingl;Svetlana B. Tsogoeva	2017	Symmetry	10.3390/sym9060088	combinatorial chemistry;combinatorics;hydrogen peroxide;organocatalysis;heme;ketone;mathematics;chiral ligand;dipeptide;catalysis;chirality (chemistry)	AI	9.942788699251683	-62.11250404071862	26367
6871eb3306a42253ea8ac604696f457b8b4b584e	the impact of spike timing variability on the signal-encoding performance of neural spiking models	desciframiento;neural spiking model;variabilidad;spike potential;ion channel;decodage;decoding;potencial espiga;integrate and fire;pointe onde;i f model;codificacion;spike timing;spike wave;signal processing;coding;mutual information;integrate and fire model;spike train;reseau neuronal;variability;caltech library services;variabilite;information theoretic;potentiel pointe;red neuronal;random times;espiga onda;codage;neural network;timing;modele pointe positive neuronale	It remains unclear whether the variability of neuronal spike trains in vivo arises due to biological noise sources or represents highly precise encoding of temporally varying synaptic input signals. Determining the variability of spike timing can provide fundamental insights into the nature of strategies used in the brain to represent and transmit information in the form of discrete spike trains. In this study, we employ a signal estimation paradigm to determine how variability in spike timing affects encoding of random time-varying signals. We assess this for two types of spiking models: an integrate-and-fire model with random threshold and a more biophysically realistic stochastic ion channel model. Using the coding fraction and mutual information as information-theoretic measures, we quantify the efficacy of optimal linear decoding of random inputs from the model outputs and study the relationship between efficacy and variability in the output spike train. Our findings suggest that variability does not necessarily hinder signal decoding for the biophysically plausible encoders examined and that the functional role of spiking variability depends intimately on the nature of the encoder and the signal processing task; variability can either enhance or impede decoding performance.	biological neuron model;channel (communications);encoder device component;heart rate variability;information theory;ion channel;iontophoresis;juvenile neuronal ceroid lipofuscinosis;mutual information;programming paradigm;signal processing;spatial variability;spiking neural network;synaptic package manager;transponder timing;video-in video-out;spike train	Amit Manwani;Peter N. Steinmetz;Christof Koch	2002	Neural Computation	10.1162/08997660252741158	simulation;computer science;artificial intelligence;signal processing;mathematics;spike potential;coding;mutual information;communication;ion channel;artificial neural network;statistics	ML	21.38362931918617	-71.45487640939238	26372
d87a8d3d322c9c18af03553708031474d7470756	improved prediction of cyp-mediated metabolism with chemical fingerprints	sitios de ligacao;reprodutibilidade dos testes;descoberta de drogas;sistema enzimatico do citocromo p 450;biologia computacional;internet;isoenzimas	Molecule and atom fingerprints, similar to path-based Daylight fingerprints, can substantially improve the accuracy of P450 site-of-metabolism prediction models. Only two chemical fingerprints have been used in metabolism prediction, so little is known about the importance of fingerprint parameters on site of metabolism predictions. It is possible that different fingerprints might yield more accurate models. Here, we study if tuning fingerprints to specific site of metabolism data sets can lead to improved models. We measure the impact of 484 specific chemical fingerprints on the accuracy of P450 site-of-metabolism prediction models on nine P450 isoform site of metabolism data sets. Using a range of search depths, we study path, circular, and subgraph fingerprints. Two different labelings, also, are considered, both standard SMILES labels and also a labeling that marks ring bonds differently than nonring bonds, enabling ortho, para, and meta positioning of substituents to be more clearly encoded. Optimal fingerprint models chosen by cross-validation performance on the full training data are, on average, 3.8% (Top-2; percent of molecules with a site of metabolism in the top two predictions) and 1.4% (AUC; area under the ROC curve) more accurate than base fingerprint models. These gains represent, respectively, a 25.6% and 16.7% reduction in error. A more rigorous assessment selects fingerprints within each cross-validation fold, sometimes selecting different fingerprints for different folds, but yielding a more reliable estimate of generalization error. In this assessment, averaging the scores from the top few fingerprints yields performances improvements of, on average, 3.0% (Top-2) and 0.7% (AUC). These gains are statistically significant and represent, respectively, a 20.1% and 8.8% reduction in error. Between different isoforms, not many consistencies were observed among the top performing fingerprints, with different fingerprints working best for different isoforms. These results suggest that there are important gains achievable in site of metabolism modeling by including and optimizing atom and molecule fingerprints. The optimal site of metabolism models determined by this approach are available for use at http://swami.wustl.edu/.		Jed Zaretzki;Kevin M. Boehm;Sanjay Joshua Swamidass	2015	Journal of chemical information and modeling	10.1021/ci5005652	stereochemistry;the internet;chemistry;bioinformatics	HCI	11.225189853252909	-56.22981146140901	26388
a39a3d23826455285039041f8a9a393b09119b86	the neural career of sensory-motor metaphors	neural career;female;lexical semantics;judgment;bepress selected works;conceptual understanding;adolescent;reading;recognition psychology;oxygen;right hemisphere;male;motor system;image processing computer assisted;inferior parietal lobule;action plan;biological motion;brain mapping;sensory motor metaphors;statistics as topic;adult;magnetic resonance imaging;neuropsychological tests;motor activity;cerebral cortex;humans;neural career sensory motor metaphors;young adult;metaphor;reaction time;concept formation	The role of sensory-motor systems in conceptual understanding has been controversial. It has been proposed that many abstract concepts are understood metaphorically through concrete sensory-motor domains such as actions. Using fMRI, we compared neural responses with literal action (Lit; The daughter grasped the flowers), metaphoric action (Met; The public grasped the idea), and abstract (Abs; The public understood the idea) sentences of varying familiarity. Both Lit and Met sentences activated the left anterior inferior parietal lobule, an area involved in action planning, with Met sentences also activating a homologous area in the right hemisphere, relative to Abs sentences. Both Met and Abs sentences activated the left superior temporal regions associated with abstract language. Importantly, activation in primary motor and biological motion perception regions was inversely correlated with Lit and Met familiarity. These results support the view that the understanding of metaphoric action retains a link to sensory-motor systems involved in action performance. However, the involvement of sensory-motor systems in metaphor understanding changes through a gradual abstraction process whereby relatively detailed simulations are used for understanding unfamiliar metaphors, and these simulations become less detailed and involve only secondary motor regions as familiarity increases. Consistent with these data, we propose that anterior inferior parietal lobule serves as an interface between sensory-motor and conceptual systems and plays an important role in both domains. The similarity of abstract and metaphoric sentences in the activation of left superior temporal regions suggests that action metaphor understanding is not completely based on sensory-motor simulations but relies also on abstract lexical-semantic codes.	code;conceptual system;cumulative trauma disorders;literal (mathematical logic);lobule;sensorimotor cortex;simulation;spastic paraplegia, hereditary;temporal lobe;fmri;flower allergenic extracts;sentence	Rutvik H. Desai;Jeffrey R. Binder;Lisa L. Conant;Quintino R. Mano;Mark S. Seidenberg	2011	Journal of Cognitive Neuroscience	10.1162/jocn.2010.21596	psychology;cognitive psychology;mental chronometry;judgment;lexical semantics;neuroscience;developmental psychology;biological motion;young adult;magnetic resonance imaging;motor system;oxygen;linguistics;brain mapping;communication;social psychology;reading;cognitive science;recognition memory	AI	16.71945800160855	-77.63178484334638	26505
5c9103f8b2dcc791c78eb6c2e088877bba0ea22e	modelling self-assembly in blenx	self assembly;protein complex;process calculi;programming language;biological process	The process through which disordered components spontaneously arrange themselves into patterns is called self-assembly. Molecular self-assembly describes the process by which molecules adopt a defined arrangement without external guidance (e.g. formation of membranes and protein complexes). These biological processes are essential to the functioning of cells. We investigate the usage of BlenX, a process calculi based programming language, for modelling molecular self-assembly of filaments, trees and rings. Moreover, we show how these structures can be used to model actin polymerization.	self-assembly	Roberto Larcher;Corrado Priami;Alessandro Romanel	2010	Trans. Computational Systems Biology	10.1007/978-3-642-11712-1_5	crystallography;computer science;communication;algorithm	Graphics	6.1040715348487975	-67.34802677068645	26625
a114acb9c90d29d9611674824b01a007b6b7a115	bismark: a flexible aligner and methylation caller for bisulfite-seq applications	dna;software;aplicacion;sulfites;sequence analysis dna;metilacion;methylation;cytosine;dna methylation;application	SUMMARY A combination of bisulfite treatment of DNA and high-throughput sequencing (BS-Seq) can capture a snapshot of a cell's epigenomic state by revealing its genome-wide cytosine methylation at single base resolution. Bismark is a flexible tool for the time-efficient analysis of BS-Seq data which performs both read mapping and methylation calling in a single convenient step. Its output discriminates between cytosines in CpG, CHG and CHH context and enables bench scientists to visualize and interpret their methylation data soon after the sequencing run is completed.   AVAILABILITY AND IMPLEMENTATION Bismark is released under the GNU GPLv3+ licence. The source code is freely available from www.bioinformatics.bbsrc.ac.uk/projects/bismark/.	base sequence;biopolymer sequencing;cartilage-hair hypoplasia;chromogranins;cytosine;epigenomics;gnu;high-throughput computing;methylation;sequence number;snapshot (computer storage);source code;throughput;hydrogen sulfite	Felix Krueger;Simon R. Andrews	2011		10.1093/bioinformatics/btr167	biology;molecular biology;bioinformatics;methylation;dna methylation;genetics;dna	Comp.	-2.1522556028338258	-57.48330091297603	26653
4354cf81bf6055878f1c902ea7c477b52bd6aea8	gkaks: the pipeline for genome-level ka/ks calculation	genome-wide substitution rate;supplementary information;well-annotated genome;substitution rate estimation method;bioinformatics online;average ka;codon-based genome-level;ks computation pipeline;non-annotated genome;substitution rate	SUMMARY gKaKs is a codon-based genome-level Ka/Ks computation pipeline developed and based on programs from four widely used packages: BLAT, BLASTALL (including bl2seq, formatdb and fastacmd), PAML (including codeml and yn00) and KaKs_Calculator (including 10 substitution rate estimation methods). gKaKs can automatically detect and eliminate frameshift mutations and premature stop codons to compute the substitution rates (Ka, Ks and Ka/Ks) between a well-annotated genome and a non-annotated genome or even a poorly assembled scaffold dataset. It is especially useful for newly sequenced genomes that have not been well annotated. We applied gKaKs to estimate the genome-wide substitution rates in five pairs of closely related species. The average Ka and Ks computed by gKaKs were consistent with previous studies. We also compared the Ka, Ks and Ka/Ks of mouse and rat orthologous protein-coding genes estimated by gKaKs and based on the alignments generated by PAL2NAL. Results from two methods are compatible.   AVAILABILITY AND IMPLEMENTATION gKaKs is implemented in Perl and is freely available on http://longlab.uchicago.edu/?q=gKaKs. The detailed user manual is available on the website.	blat;codon (nucleotide sequence);codon, nonsense;computation;formatdb;frameshift mutation function;genome;homology (biology);ka band;laboratory sample manual;perl;sequence homology;silo (dataset);web site	Chengjun Zhang;Manyuan Long;Chuanzhu Fan	2013	Bioinformatics	10.1093/bioinformatics/btt009	biology;bioinformatics;algorithm	Comp.	0.07029297628203061	-55.49263675366887	26711
04236f6e0aab1b7004d13d6182d3dede186ecf77	detecting hidden batch factors through data-adaptive adjustment for biological effects		Motivation Batch effects are one of the major source of technical variations that affect the measurements in high-throughput studies such as RNA sequencing. It has been well established that batch effects can be caused by different experimental platforms, laboratory conditions, different sources of samples and personnel differences. These differences can confound the outcomes of interest and lead to spurious results. A critical input for batch correction algorithms is the knowledge of batch factors, which in many cases are unknown or inaccurate. Hence, the primary motivation of our paper is to detect hidden batch factors that can be used in standard techniques to accurately capture the relationship between gene expression and other modeled variables of interest.   Results We introduce a new algorithm based on data-adaptive shrinkage and semi-Non-negative Matrix Factorization for the detection of unknown batch effects. We test our algorithm on three different datasets: (i) Sequencing Quality Control, (ii) Topotecan RNA-Seq and (iii) Single-cell RNA sequencing (scRNA-Seq) on Glioblastoma Multiforme. We have demonstrated a superior performance in identifying hidden batch effects as compared to existing algorithms for batch detection in all three datasets. In the Topotecan study, we were able to identify a new batch factor that has been missed by the original study, leading to under-representation of differentially expressed genes. For scRNA-Seq, we demonstrated the power of our method in detecting subtle batch effects.   Availability and implementation DASC R package is available via Bioconductor or at https://github.com/zhanglabNKU/DASC.   Contact zhanghan@nankai.edu.cn or zhandonl@bcm.edu.   Supplementary information Supplementary data are available at Bioinformatics online.	algorithm;batch processing;bioconductor;bioinformatics;function (biology);gene expression;geographic information systems;glioblastoma multiforme;high-throughput computing;non-negative matrix factorization;rna;rna, small cytoplasmic;semiconductor industry;sensor;throughput;topotecan	Haidong Yi;Ayush T. Raman;Han Zhang;Genevera I. Allen;Zhandong Liu	2018	Bioinformatics	10.1093/bioinformatics/btx635	data mining;computer science	Comp.	4.181264532606056	-52.98165950448877	26742
f638ff70b84a0c648751a4b1cc9a5ab471b5552a	differential activity in heschl's gyrus between deaf and hearing individuals is due to auditory deprivation rather than language modality	fmri;sign language;speech;deafness;neurosciences;neurovetenskaper;heschl s gyrus	Sensory cortices undergo crossmodal reorganisation as a consequence of sensory deprivation. Congenital deafness in humans represents a particular case with respect to other types of sensory deprivation, because cortical reorganisation is not only a consequence of auditory deprivation, but also of language-driven mechanisms. Visual crossmodal plasticity has been found in secondary auditory cortices of deaf individuals, but it is still unclear if reorganisation also takes place in primary auditory areas, and how this relates to language modality and auditory deprivation. Here, we dissociated the effects of language modality and auditory deprivation on crossmodal plasticity in Heschl's gyrus as a whole, and in cytoarchitectonic region Te1.0 (likely to contain the core auditory cortex). Using fMRI, we measured the BOLD response to viewing sign language in congenitally or early deaf individuals with and without sign language knowledge, and in hearing controls. Results show that differences between hearing and deaf individuals are due to a reduction in activation caused by visual stimulation in the hearing group, which is more significant in Te1.0 than in Heschl's gyrus as a whole. Furthermore, differences between deaf and hearing groups are due to auditory deprivation, and there is no evidence that the modality of language used by deaf individuals contributes to crossmodal plasticity in Heschl's gyrus.	acoustic evoked brain stem potentials;auditory perceptual disorders;auditory area;cognition;congenital heart defects;hearing impaired persons;modality (human–computer interaction);optic nerve glioma, childhood;photic stimulation;sensorineural hearing loss (disorder);sign language;fmri;funding grant	Velia Cardin;Rebecca C. Smittenaar;Eleni Orfanidou;Jerker Rönnberg;Cheryl M. Capek;Mary Rudner;Bencie Woll	2016	NeuroImage	10.1016/j.neuroimage.2015.08.073	psychology;cognitive psychology;cross modal plasticity;sign language;speech;communication;audiology	ML	17.46276824107839	-78.17475427623503	26779
e284462a187ce91586f03e908a01f233a8f33de7	a holistic approach for integration of biological systems and usage in drug discovery		A system can be defined as an organized, interconnected structure consisting of interrelated and interdependent elements (e.g., components, factors, members, parts). These parts and processes are connected by structural and/or behavioral relationships and continually influence one another directly or indirectly to maintain a balance essential for the existence of the system, and for achieving its goal. With increasing inflow of biological data, serious efforts to empathize biological systems as true systems are nowadays almost practicable. Handling high-throughput data places stress mainly on in silico approach comprising database handling, modeling, simulation and analysis, resulting in dramatic progress in system-level analysis. The databases and methods in bioinformatics are now moving in the direction of implementation of integrative dataset systems to represent genes, proteins and metabolic pathways in combination with simulated environment which is dynamic. For understanding the complex biological disorders and normal pathways of system it is significant to integrate the reductionist data which comes from transcriptomics, genomics, proteomics, lipidomics, glycomics, fluxomics and metabolomics. Numerous bioinformatics approaches are being exploited to integrate the molecular information from the biological databases and assist in simulation of metabolic networks. High-throughput experimental data set systems are, however, established on the static representation of the molecular data and existing knowledge. Various biological tools have been developed for understanding the mechanism of several diseases for drug discovery process. Study of dynamic nature of genetic, biochemical and signal transduction pathways can be done by simulating reactions with the help of integrative tools. Rising usage of rational drug designing approach is significant for identification of target in disease polluted network and evaluating ligand interaction for enhanced efficacy. How in-depth investigation of the whole system (a holistic approach) leads to emergence of systems biology is the crux of this review.	bioinformatics;biological database;biological system;emergence;fluxomics;glycomics;high-throughput computing;holism;interdependence;metabolomics;proteomics;reductionism;simulation;throughput;transduction (machine learning);virtual reality	Manish Kumar Gupta;Krishna Misra	2015	Network Modeling Analysis in Health Informatics and Bioinformatics	10.1007/s13721-015-0111-4	biology;toxicology;bioinformatics;data mining	Comp.	5.577276824158823	-58.537833039129296	26803
e90452e8fd2652d433fdf0cdd0bd1b9f1e6fdba9	multi-objective optimization of communication network using nsga	multi objective optimization	The present invention relates to novel peptide fragments [targeting signal] that are obtainable from the C-terminal region [C-terminal extension] of plant vacuole proteins and that, in operable linkage with any desired protein molecule, ensure that the proteins associated with those peptide fragments are directed specifically into the plant vacuole, and to DNA molecules coding for the said peptide fragments. The present invention relates also to recombinant DNA molecules that comprise the DNA sequence according to the invention in operable linkage with an expressible DNA, and to the vectors derived therefrom. Also included are host cells and/or host organisms, including transgenic plants, that comprise the said recombinant DNA or the vectors derived therefrom. The present invention also relates to recombinant DNA molecules and vectors derived therefrom that comprise DNA sequences naturally coding for vacuolar proteins, but which are devoid of vacuole signal sequences and targeted for extracellular secretion.	multi-objective optimization;program optimization	Krishn Mishra;Sandeep Harit;Neeraj Tyagi	2009			secretion;dna;vacuole;extracellular;genetically modified crops;biochemistry;dna sequencing;recombinant dna;chemistry;peptide	Networks	2.9569199792673366	-63.50276957353811	26861
5b5e3d1da4b6d34c2a475e7e3adad2923865b755	an adaptive workflow coupled with random forest algorithm to identify intact n-glycopeptides detected from mass spectrometry		MOTIVATION Despite many attempts for algorithm development in recent years, automated identification of intact glycopeptides from LC-MS(2) spectral data is still a challenge in both sensitivity and precision.   RESULTS We implemented a supervised machine learning algorithm, Random Forest, in an automated workflow to identify N-glycopeptides using spectral features derived from ion trap-based LC-MS(2) data. The workflow streamlined high-confident N-glycopeptide spectral data and enabled adaptive model optimization with respect to different sampling strategies, training sample size and feature set. A critical evaluation of the features important for glycopeptide identification further facilitated effective feature selection for model improvement. Using split sample testing method from 577 high-confident N-glycopeptide spectral data, we demonstrated that an optimal true-positive rate, precision and false-positive rate of 73, 88 and 10%, respectively, can be attained for overall N-glycopeptide identification Availability and implementation: The workflow developed in this work and the application suite, Sweet-Heart, that the workflow supports for N-glycopeptide identification are available for download at http://sweet-heart.glycoproteomics.proteome.bc.sinica.edu.tw/.	algorithm;download;feature selection;glycopeptides;ion trap;ions;machine learning;mathematical optimization;random forest;sampling (signal processing);sensitivity and specificity;spectrometry;supervised learning	Suh-Yuen Liang;Sz-Wei Wu;Tsung-Hsien Pu;Fang-Yu Chang;Kay-Hooi Khoo	2014	Bioinformatics	10.1093/bioinformatics/btu139	computer science;bioinformatics;machine learning;data mining	ML	8.742819325942147	-53.060796570053704	26880
59b0a853ffdcb39e2436001a532f3f74340f7663	detection of driver metabolites in the human liver metabolic network using structural controllability analysis	simulation and modeling;liver;metabolic networks and pathways;systems biology;physiological cellular and medical topics;computational biology bioinformatics;reproducibility of results;algorithms;humans;computational biology;bioinformatics	Abnormal states in human liver metabolism are major causes of human liver diseases ranging from hepatitis to hepatic tumor. The accumulation in relevant data makes it feasible to derive a large-scale human liver metabolic network (HLMN) and to discover important biological principles or drug-targets based on network analysis. Some studies have shown that interesting biological phenomenon and drug-targets could be discovered by applying structural controllability analysis (which is a newly prevailed concept in networks) to biological networks. The exploration on the connections between structural controllability theory and the HLMN could be used to uncover valuable information on the human liver metabolism from a fresh perspective. We applied structural controllability analysis to the HLMN and detected driver metabolites. The driver metabolites tend to have strong ability to influence the states of other metabolites and weak susceptibility to be influenced by the states of others. In addition, the metabolites were classified into three classes: critical, high-frequency and low-frequency driver metabolites. Among the identified 36 critical driver metabolites, 27 metabolites were found to be essential; the high-frequency driver metabolites tend to participate in different metabolic pathways, which are important in regulating the whole metabolic systems. Moreover, we explored some other possible connections between the structural controllability theory and the HLMN, and find that transport reactions and the environment play important roles in the human liver metabolism. There are interesting connections between the structural controllability theory and the human liver metabolism: driver metabolites have essential biological functions; the crucial role of extracellular metabolites and transport reactions in controlling the HLMN highlights the importance of the environment in the health of human liver metabolism.	biological phenomena;chemical and drug induced liver injury;class;classification;liver diseases;liver neoplasms;metabolic process, cellular;metabolite;social network analysis;tree accumulation	Xueming Liu;Linqiang Pan	2014		10.1186/1752-0509-8-51	biology;toxicology;computer science;bioinformatics;systems biology	ML	6.039017605352484	-58.38710966690322	26938
cb5da8232bfbc35e6c4aeb9c0fc6d6c000a9a6ba	parameter estimation for reaction rate equation constrained mixture models		The elucidation of sources of heterogeneity in cell populations is crucial to fully understand biological processes. A suitable method to identify causes of heterogeneity is reaction rate equation (RRE) constrained mixture modeling, which enables the analysis of subpopulation structures and dynamics. These mixture models are calibrated using single cell snapshot data to estimate model parameters which are not measured or which cannot be assessed experimentally. In this manuscript, we evaluate different optimization methods for estimating the parameters of RRE constrained mixture models under the normal distribution assumption. We compare gradient-based optimization using sensitivity analysis with two other optimization methods – gradient-based optimization with finite differences and a stochastic optimization method – for simulation examples with artificial data. Furthermore, we compare different numerical schemes for the evaluation of the log-likelihood function. We found that gradient-based optimization using sensitivity analysis outperforms the other optimization methods in terms of convergence and computation time.	estimation theory;mixture model	Carolin Loos;Anna Fiedler;Jan Hasenauer	2016		10.1007/978-3-319-45177-0_12	mathematical optimization;statistics	ML	13.271080323220756	-53.2356143557934	26946
4a3b29d8041ff29525de2a451a2c92d0a847cfe9	can molecular dynamics simulations help in discriminating correct from erroneous protein 3d models?	sensitivity and specificity;fold recognition;amino acid sequence;false negative;spectrum;binding sites;models chemical;three dimensional;molecular dynamic simulation;energy function;computational biology bioinformatics;root mean square deviation;protein structure;models molecular;3d model;proteins;protein conformation;secondary structure;reproducibility of results;protein binding;molecular dynamic;algorithms;protein folding;molecular sequence data;sequence alignment;combinatorial libraries;monte carlo;false positive;potential function;kinetics;computer appl in life sciences;3d structure;computer simulation;structural similarity;surface area;sequence analysis protein;md simulation;microarrays;bioinformatics;structure alignment	Recent approaches for predicting the three-dimensional (3D) structure of proteins such as de novo or fold recognition methods mostly rely on simplified energy potential functions and a reduced representation of the polypeptide chain. These simplifications facilitate the exploration of the protein conformational space but do not permit to capture entirely the subtle relationship that exists between the amino acid sequence and its native structure. It has been proposed that physics-based energy functions together with techniques for sampling the conformational space, e.g., Monte Carlo or molecular dynamics (MD) simulations, are better suited to the task of modelling proteins at higher resolutions than those of models obtained with the former type of methods. In this study we monitor different protein structural properties along MD trajectories to discriminate correct from erroneous models. These models are based on the sequence-structure alignments provided by our fold recognition method, FROST. We define correct models as being built from alignments of sequences with structures similar to their native structures and erroneous models from alignments of sequences with structures unrelated to their native structures. For three test sequences whose native structures belong to the all-α, all-β and αβ classes we built a set of models intended to cover the whole spectrum: from a perfect model, i.e., the native structure, to a very poor model, i.e., a random alignment of the test sequence with a structure belonging to another structural class, including several intermediate models based on fold recognition alignments. We submitted these models to 11 ns of MD simulations at three different temperatures. We monitored along the corresponding trajectories the mean of the Root-Mean-Square deviations (RMSd) with respect to the initial conformation, the RMSd fluctuations, the number of conformation clusters, the evolution of secondary structures and the surface area of residues. None of these criteria alone is 100% efficient in discriminating correct from erroneous models. The mean RMSd, RMSd fluctuations, secondary structure and clustering of conformations show some false positives whereas the residue surface area criterion shows false negatives. However if we consider these criteria in combination it is straightforward to discriminate the two types of models. The ability of discriminating correct from erroneous models allows us to improve the specificity and sensitivity of our fold recognition method for a number of ambiguous cases.	3d modeling;alignment;amino acid sequence;amino acids;chamaecyparis lawsoniana;class;cluster analysis;de novo protein structure prediction;molecular dynamics;monte carlo method;plant roots;polypeptides;quantum fluctuation;sampling (signal processing);sensitivity and specificity;simulation;threading (protein sequence);statistical cluster	Jean-François Taly;Antoine Marin;Jean-François Gibrat	2007	BMC Bioinformatics	10.1186/1471-2105-9-6	computer simulation;biology;protein structure;computer science;bioinformatics;machine learning	Comp.	9.680576916481535	-58.865576435134024	26990
ca7e3f52225b0a7263cd9bdb6a73e949b57e4f53	molecular evolution: automated manipulation of hierarchical chemical topology and its application to average molecular structures	mathematica;genetic program;hierarchy;genetic operator;hierarchical data structure;chemical topology;direct manipulation;population size;topological descriptor;average chemical structure;molecular evolution;genetic algorithm;chemical structure;fitness function;molecular structure	A simple hierarchical data structure (tree) and associated set of algorithms (written in Mathematica) have been developed that permit the direct manipulation of the topology of a molecule while simultaneously maintaining valid chemical valence. Coupled with a genetic algorithm optimization engine, these computational tools can be used to optimize chemical structures under the guidance of an appropriate fitness function. A detailed study of the factors that influence the performance of the method revealed that it is strongly dependent on the size and complexity of the evolved chemical structures. The effects of population size and choice of genetic operators are much smaller. The results of an exploration into the discovery of average molecular structures using this methodology is also described.	abstract data type;battle of midway;benchmark (computing);chemical vapor deposition;computation;data structure;direct manipulation interface;directed acyclic graph;executable;fitness function;genetic algorithm;genetic operator;hierarchical database model;hypertext transfer protocol;mathematical optimization;maxima and minima;wolfram mathematica	Robert B. Nachbar	2000	Genetic Programming and Evolvable Machines	10.1023/A:1010072431120	population size;genetic algorithm;molecular evolution;molecule;computer science;bioinformatics;artificial intelligence;genetic operator;machine learning;chemical structure;fitness function;algorithm;hierarchy	HPC	12.829375607055882	-61.7166157260796	27014
0e986ac9484e0587b6ccf01a5db735b9bf185157	refining architectures of deep convolutional neural networks		Deep Convolutional Neural Networks (CNNs) have recently evinced immense success for various image recognition tasks [11, 27]. However, a question of paramount importance is somewhat unanswered in deep learning research - is the selected CNN optimal for the dataset in terms of accuracy and model size? In this paper, we intend to answer this question and introduce a novel strategy that alters the architecture of a given CNN for a specified dataset, to potentially enhance the original accuracy while possibly reducing the model size. We use two operations for architecture refinement, viz. stretching and symmetrical splitting. Stretching increases the number of hidden units (nodes) in a given CNN layer, while a symmetrical split of say K between two layers separates the input and output channels into K equal groups, and connects only the corresponding input-output channel groups. Our procedure starts with a pre-trained CNN for a given dataset, and optimally decides the stretch and split factors across the network to refine the architecture. We empirically demonstrate the necessity of the two operations. We evaluate our approach on two natural scenes attributes datasets, SUN Attributes [16] and CAMIT-NSAD [20], with architectures of GoogleNet and VGG-11, that are quite contrasting in their construction. We justify our choice of datasets, and show that they are interestingly distinct from each other, and together pose a challenge to our architectural refinement algorithm. Our results substantiate the usefulness of the proposed method.	algorithm;baseline (configuration management);channel (communications);computer vision;convolutional neural network;deep learning;input/output;neural networks;refinement (computing);viz: the computer game	Sukrit Shankar;Duncan P. Robertson;Yani Ioannou;Antonio Criminisi;Roberto Cipolla	2016	2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)	10.1109/CVPR.2016.243	computer science;artificial intelligence;machine learning;data mining;mathematics;algorithm;statistics	Vision	22.492789859366475	-52.47838601328374	27079
8ec646e218b0fc9ef38d18b9798052007a275436	improving mortality prediction in cardiovascular risk patients by balancing classes	machine learning cardiovascular risk unbalanced classes;niobium;diabetes;hypertension;data models training data radio frequency hypertension diabetes niobium diseases;unbalanced classes;training data;risk analysis cardiovascular system diseases medical computing pattern classification;intensified preventive interventions mortality prediction cardiovascular risk patients mortality risk escarval risk study cardiovascular cohort highly unbalanced classes cv dyslipidemia diabetes hypertension chronic kidney disease ckd glomerular filtration rate;radio frequency;machine learning;diseases;cardiovascular risk;data models	The objective of this work is to develop a prediction system for mortality risk based on ESCARVAL-RISK study, a large cardiovascular cohort (54,678 patients) with a follow-up starting in January 2008 through December 2012. The main challenge to face in this problem is the highly unbalanced classes that may lead to a poor performance in the classification, this work proposes a way to balance classes in order to circumvent that problem. Achieved results show that several factors emerged as the main factors of mortality in this population with a high cardiovascular (CV) risk, besides age and gender, treatments for hypertension, diabetes and dyslipidemia are the most relevant factors present in the cohort although the weight of each of them varies with the model. Despite the variation among the models, treatment for hypertension seems to be the most relevant factor. The presence of chronic kidney disease (CKD) defined by an estimated glomerular filtration rate.	stochastic process;unbalanced circuit	Emilio Soria-Olivas;José David Martín-Guerrero;Josep Redon;Maria Tellez-Plaza;Joan Vila-Francés	2015	2015 IEEE International Conference on Data Mining Workshop (ICDMW)	10.1109/ICDMW.2015.76	data modeling;niobium;training set;computer science;machine learning;data mining;radio frequency	DB	6.367782128940467	-75.9554135429727	27082
cc576a619c875a2dc400d4f95c40a1f745fbd87c	search for new methods for assignment of complex molecular spectra and a program package for simulation of molecular spectra	simulation ordinateur;high resolution;espectro optico;spectre optique;informing science;spectrum;sistema complejo;optical spectrum;molecules;data analysis;systeme complexe;complex system;computerized simulation;analyse donnee;molecule	Recent development of spectroscopic instruments has allowed us to obtain a large amount of spectral data in machine readable forms. High resolution molecular spectra contain abundant information on structures and dynamics of molecules. However, extraction of such useful information necessitates a procedure of spectral assignment in which each spectral line is assigned a set of quantum numbers. This procedure has traditionally been performed by making use of regular patterns that are obviously seen in the observed spectrum. However, we often encounter complex spectra in which such regular patterns may not be readily discerned. The purpose of the present work is to search for new methods which can assist in assigning such complex molecular spectra. We wish to devise computer aided techniques for picking out regular patterns buried in a list of observed values which look like randomly distributed. We hope that we may make use of various fruits of information sciences and may depend on great computational power of modern computers	rca spectra 70;simulation	Takehiko Tanaka;Takashi Imajo	1998		10.1007/3-540-49292-5_63	complex systems;molecule;telecommunications;computer science;artificial intelligence	Comp.	15.048818918466322	-59.66507785312367	27152
4ebc1a37be98d78878ee21ebd56f320219224a15	prediction of catalytic residues in proteins using a consensus of prediction (cop) approach	biophysical function;biology computing;manuals;genomics;biochemical function;diverse family;protein function;fully automated method;machine learning approach;molecular configurations;catalytic triad;hierarchical analysis;prediction algorithms;enzyme;large scale systems biochemistry genomics bioinformatics protein engineering automation availability accuracy machine learning testing;protein functional residues;protein structure initiative;catalytic triad catalytic residues consensus of prediction approach protein structure initiative genome sequencing era biochemical function biophysical function large scale analysis protein functional residues protein annotation fully automated method machine learning approach hierarchical analysis diverse family hydrolytic enzymes a b hydrolase fold phylogenetic origins;proteins biochemistry biological techniques biology computing catalysis enzymes genomics learning artificial intelligence molecular biophysics molecular configurations;accuracy;protein structure;large scale;enzymes;protein annotation;proteins;machine learning;conservation of prediction large scale analysis machine leaning catalytic residue protein function prediction cop;catalysis;molecular biophysics;hydrolytic enzymes;predictive models;consensus of prediction approach;biological techniques;cop;learning artificial intelligence;catalytic residue;genome sequencing era;phylogenetic origins;false positive;catalytic residues;conservation of prediction;prediction;biochemistry;large scale analysis;genome sequence;a b hydrolase fold;machine leaning	One of the aims of the Protein Structure Initiative (PSI) in the post genome-sequencing era is to elucidate biochemical and biophysical functions of each protein structure. Thus, the development of new methods for a large-scale analysis/annotation of protein functional residues is inevitable. Currently existing methods are not capable to do so due to the lack of automation, availability, and/or poor performance. In our previous work we were able to improve the accuracy of the prediction to ~86%, although the number of false-positives remained high. In this paper we present a fully-automated method for the prediction of catalytic residues in proteins that improves accuracy by reduction of false-positives, and is applicable for a large-scale analysis. Here, catalytic residues are predicted by machine learning approach followed by hierarchical analysis of the predicted residues. The capability of the method was tested on diverse family of hydrolytic enzymes with a/b hydrolase fold with widely differing phylogenetic origins and catalytic functions. The method was executed manually and then fully reproduces automatically. In the manual analysis, in 17 enzymes, the method correctly predicted all 3 residues of the catalytic triad with 3 false-positives out of 282 residues on average. Our method successfully eliminates the number of false-positives, while being applicable for a large-scale analysis of the protein function.	false diffusion;false precision;machine learning;phylogenetics	Natalia V. Petrova;Cathy H. Wu	2010	2010 IEEE International Conference on BioInformatics and BioEngineering	10.1109/BIBE.2010.44	biology;biochemistry;enzyme;genomics;prediction;biotechnology;computer science;bioinformatics;molecular biophysics	Comp.	7.7212672516266005	-56.490563337223975	27209
bcca7c1c5021b3ad1d48aa9d2a5b3015aec6f6d7	an expectation-maximization algorithm for analysis of evolution of exon-intron structure of eukaryotic genes	expectation maximization algorithm;gamma distribution	We propose a detailed model of evolution of exon-intron structure of eukaryotic genes that takes into account gene-specific intron gain and loss rates, branch-specific gain and loss coefficients, invariant sites incapable of intron gain, and rate variability of both gain and loss which is gamma-distributed across sites. We develop an expectation-maximization algorithm to estimate the parameters of this model, and study its performance using simulated data.	expectation–maximization algorithm	Liran Carmel;Igor B. Rogozin;Yuri I. Wolf;Eugene V. Koonin	2005		10.1007/11554714_4	biology;gamma distribution;mathematical optimization;expectation–maximization algorithm;bioinformatics;genetics;statistics	ML	4.711272562801078	-59.88615652502487	27220
e4249e84f9026c3a9c7f00b29e89c6d8e34be461	towards phylogenomic reconstruction		Reconstructing phylogenies is one of the primary objectives in evolution studies. Efficient software to reconstruct phylogenies based on isolated genes has existed for decades, yet, phylogenetic reconstructions from whole genomes are only beginning. The diversification of genome sequencing projects has generated thousands of whole genomes making phylogenomic reconstruction a challenging research topic. In this paper, we present an approach for pairwise alignment construction which deploys both nucleotide and locus (a segment of nucleotides) operations to minimize the total edit cost between genomes. The cost is composed of three factors: nucleotide transformation costs between loci, indel costs of loci, and rearrangement costs between locus orders. This approach is embedded within a direct optimization scheme to reconstruct phylogenies from whole unaligned genomes. Performance of this approach is demonstrated in our software, POY4, to reconstruct phylogenies from Coronavirus and Poxvirus genomes.	diversification (finance);embedded system;locus;mathematical optimization;phylogenetics;sequence alignment;whole genome sequencing	Le Vinh;Andrés Varón;Daniel Janies;Ward C. Wheeler	2007			magnesium;hydrogen sulfide;chemical engineering;activated carbon;dry basis;water softening;fluid dynamics;pressure drop;ion-exchange resin;materials science	Comp.	1.650773301996395	-62.91457577788623	27256
36e9a311373412a27fead957923234eec0eb9f8c	methods for reducing interference in the complementary learning systems model: oscillating inhibition and autonomous memory rehearsal	oscillations;interferencia;hebbian learning;learning algorithm;consolidacion;onde θ;hippocampus;algorithme apprentissage;interference;rem sleep;hipocampo;sleep;sommeil;sueno;learning system;consolidation;hippocampe;theta wave;neocortex;onda θ;reseau neuronal;algoritmo aprendizaje;neural oscillator;theta oscillations;red neuronal;neural network	The stability-plasticity problem (i.e. how the brain incorporates new information into its model of the world, while at the same time preserving existing knowledge) has been at the forefront of computational memory research for several decades. In this paper, we critically evaluate how well the Complementary Learning Systems theory of hippocampo-cortical interactions addresses the stability-plasticity problem. We identify two major challenges for the model: Finding a learning algorithm for cortex and hippocampus that enacts selective strengthening of weak memories, and selective punishment of competing memories; and preventing catastrophic forgetting in the case of non-stationary environments (i.e. when items are temporarily removed from the training set). We then discuss potential solutions to these problems: First, we describe a recently developed learning algorithm that leverages neural oscillations to find weak parts of memories (so they can be strengthened) and strong competitors (so they can be punished), and we show how this algorithm outperforms other learning algorithms (CPCA Hebbian learning and Leabra at memorizing overlapping patterns. Second, we describe how autonomous re-activation of memories (separately in cortex and hippocampus) during REM sleep, coupled with the oscillating learning algorithm, can reduce the rate of forgetting of input patterns that are no longer present in the environment. We then present a simple demonstration of how this process can prevent catastrophic interference in an AB-AC learning paradigm.	addresses (publication format);algorithm;autonomous robot;catastrophic interference;computation;hebbian theory;interaction;interference (communication);leabra;machine learning;microsoft forefront;n-cyclopropyl adenosine-5'-carboxamide;neural oscillation;programming paradigm;sleep apnea syndromes;stationary process;systems theory;test set	Kenneth A. Norman;Ehren L. Newman;Adler J. Perotte	2005	Neural networks : the official journal of the International Neural Network Society	10.1016/j.neunet.2005.08.010	consolidation;catastrophic interference;error-driven learning;hebbian theory;computer science;artificial intelligence;machine learning;theta rhythm;hippocampus;interference;sleep;oscillation;artificial neural network	ML	19.232448028542624	-70.42351375990262	27375
34f73febbe8bb9f928640c0c260c8abc9b0649de	theory of non-classical receptive field phenomena in the visual cortex	classical receptive field;contrast sensitivity;fixed point;center surround phenomena;orientation contrast sensitivity;parameter space;orientation selectivity;receptive field;fixed point analysis;visual cortex;neuronal activity;receptive fields	In many experiments it has been found that stimuli outside the classical receptive-field of orientation-selective cells in the visual cortex can strongly modulate the response properties of these cells. Typically, stimuli with orientation contrasts lead to enhancement, whereas iso-orientation stimuli lead to suppression of the neuronal activity, but these phenomena in general depend in a complicate manner on various parameters like stimulus configuration, contrast, and geometry. In this contribution, we develop a simple theory for such non-classical receptive-field phenomena. We explain the basic mechanisms by a fixed-point analysis. Within this analysis, center-surround experiments can be described by trajectories in parameter space. This allows for a systematic variation of the coupling and stimulation constants. We show that the strength or sign of the enhancement or suppression should not only vary with the experimental paradigm but also with the position of the cell within the cortex. Our results suggest that non-classical receptive-field phenomena are mediated through orientation-specific lateral excitatory interactions.		Udo Ernst;Klaus Pawelzik;Fredric M. Wolf;Theo Geisel	1999	Neurocomputing	10.1016/S0925-2312(99)00026-0	binocular neurons;computer vision;surround suppression;mathematics;receptive field	ML	20.038759466975144	-68.99968910566656	27391
a8ae216155fe61c8ef857b28aaf63382ea7b8ff0	selective phenome growth adapted nk model: a novel landscape to represent aptamer ligand binding		Aptamers are single-stranded oligonucleotides selected by evolutionary approaches frommassive libraries with significant potential for specific molecular recognition in diagnostics and therapeutics. A complete empirical characterisation of an aptamer selection experiment is not feasible due to the vast complexity of aptamer selection. Simulation of aptamer selection has been used to characterise and optimise the selection process; however, the absence of a good model for aptamer-target binding limits this field of study. Here, we generate theoretical fitness landscapes which appear to more accurately represent aptamer-target binding. The method used to generate these landscapes, selective phenome growth, is a new approach in which phenotypic contributors are added to a genotype/phenotype interaction map sequentially in such a way so as to increase the fitness of a selected fit sequence. In this way, a landscape is built around the selected fittest sequences. Comparison to empirical aptamer microarray data shows that our theoretical fitness landscapes more accurately represent aptamer ligand binding than other theoretical models.These improved fitness landscapes have potential for the computational analysis and optimisation of other complex systems.		Andrew Brian Kinghorn;Julian Alexander Tanner	2017	Complexity	10.1155/2017/6760852	oligonucleotide;phenome;fitness landscape;ligand (biochemistry);survival of the fittest;microarray analysis techniques;nk model;aptamer;biology;bioinformatics	ML	8.018185032422513	-59.424099165310906	27407
54c90751a49737012eb44e945979fddbf39a1649	analysis of large-scale sequencing of small rnas	whole exome sequencing;pirna	The advent of large-scale sequencing has opened up new areas of research, such as the study of Piwi-interacting small RNAs (piRNAs). piRNAs are longer than miRNAs, close to 30 nucleotides in length, involved in various functions, such as the suppression of transposons in germline. Since a large number of them (many tens of thousands) are generated from a wide range of positions in the genome, large-scale sequencing is the only way to study them. The key to understanding their genesis and biological roles is efficient analysis, which is complicated by the large volumes of sequence data. Taking account of the underlying biology is also important. We describe here novel analyses techniques and tools applied to small RNAs from germ cells in D. melanogaster, that allowed us to infer mechanism and biological function.	biopolymer sequencing;cluster analysis;experiment;function (biology);genesis;germ cells;inference;interaction;large-scale sequencing;micrornas;non-small cell lung carcinoma;nucleotides;staphylococcal protein a;transcutaneous electric nerve stimulation;zero suppression;statistical cluster	Andrew J. Olson;J. Brennecke;A. A. Aravin;Gregory J Hannon;Ravi Sachidanandam	2008	Pacific Symposium on Biocomputing. Pacific Symposium on Biocomputing		biology;molecular biology;exome sequencing;bioinformatics;piwi-interacting rna;genetics	Comp.	3.4979957246804587	-58.84043538433055	27480
5522560e0044882980dc145aa4f8dce92819040e	combine archive specification version 1		Several standard formats have been proposed that can be used to describe models, simulations, data or other essential information in a consistent fashion. These constitute various separate components required to reproduce a given published scientific result. The Open Modeling EXchange format (OMEX) supports the exchange of all the information necessary for a modeling and simulation experiment in biology. An OMEX file is a ZIP container that includes a manifest file, an optional metadata file, and the files describing the model. The manifest is an XML file listing all files included in the archive and their type. The metadata file provides additional information about the archive and its content. Although any format can be used, we recommend an XML serialization of the Resource Description Framework. Together with the other standard formats from the Computational Modeling in Biology Network (COMBINE), OMEX is the basis of the COMBINE Archive. The content of a COMBINE Archive consists of files encoded in COMBINE standards whenever possible, but may include additional files defined by an Internet Media Type. The COMBINE Archive facilitates the reproduction of modeling and simulation experiments in biology by embedding all the relevant information in one file. Having all the information stored and exchanged at once also helps in building activity logs and audit trails.		Frank T. Bergmann;Nicolas Rodriguez;Nicolas Le Novère	2015	Journal of integrative bioinformatics	10.2390/biecoll-jib-2015-261	computer file;computer science;bioinformatics;data mining;database;data file;file format;world wide web	Web+IR	-3.4695928589873577	-61.8762869668203	27536
38e7f54a683e178e5876decf222141485db6f882	information technologies in biomedicine	biological process;home care;medical information system;computational biology;computer scientist;book seamlessly;information technologies;biosignal analysis;web-based material;information technology;graduate student;information technology application;ehealth home monitoring service;information processing tool;patient care;data analysis;image processing;signal processing;patient diagnosis	In this paper, we present a solution to the blood vessel segmentation problem, with the long term goal of automatically diagnosing early stages of glaucoma. The images are obtained from the Heidelberg Retina Tomograph. We introduce two approaches. Firstly, we present the Thresholding Approach and secondly, the Clean Edge Map algorithm. The algorithms share their first steps adjusting the lighting and cutting out of the pupil. The preprocessed images are then modified by combination of tools such as the Canny operator or thresholds. The results are finally shown using an implemented GUI.	algorithm;canny edge detector;data pre-processing;graphical user interface;retina display;thresholding (image processing);tomography	Søren Brunak;Masha Gelfand;Thomas Lengauer;Satoru Miyano;Greg Myers;M.-F. Sagot D. Sankoff;Ron Shamir;T. Speed M. Vingron;Weng-Fai Wong;Ewa Pietka;Jacek Kawa	2012		10.1007/978-3-642-31196-3	medicine;data science;biological engineering;informatics	Robotics	1.0121275442948088	-74.82859074489276	27624
7152f0bb0e77919317d2d48dcb446a99e9f27eaf	dape: a web server to detect homorepeats and follow their evolution		Summary Homorepeats are low complexity regions consisting of repetitions of a single amino acid residue. There is no current consensus on the minimum number of residues needed to define a functional homorepeat, nor even if mismatches are allowed. Here we present dAPE, a web server that helps following the evolution of homorepeats based on orthology information, using a sensitive but tunable cutoff to help in the identification of emerging homorepeats.   Availability and Implementation dAPE can be accessed from http://cbdm-01.zdv.uni-mainz.de/∼munoz/polyx .   Contact munoz@uni-mainz.de.   Supplementary information Supplementary data are available at Bioinformatics online.	1,2-diarachidonoyl-glycero-3-phosphoethanolamine;amino acids;bioinformatics;geographic information systems;homology (biology);perseveration;server (computer);server (computing);web server	Pablo Mier;Miguel A. Andrade-Navarro	2017		10.1093/bioinformatics/btw790	world wide web	Comp.	-0.7510207156208635	-59.75472380090196	27642
d0ee2f77a75099cc7be4217c8f8f09df216c00c0	ddbj dealing with mass data produced by the second generation sequencer	dna;animals;genomics;host organism;databases nucleic acid;bombyx;protozoa;sequence analysis dna;drosophila;genome;lotus japonicus;humans;genus lotus;dna data bank of japan;biotechnology;bombyx mori;national center for biotechnology information	DNA Data Bank of Japan (DDBJ) (http://www.ddbj.nig.ac.jp) collected and released 2 368 110 entries or 1 415 106 598 bases in the period from July 2007 to June 2008. The releases in this period include genome scale data of Bombyx mori, Oryzas latipes, Drosophila and Lotus japonicus. In addition, from this year we collected and released trace archive data in collaboration with National Center for Biotechnology Information (NCBI). The first release contains those of O. latipes and bacterial meta genomes in human gut. To cope with the current progress of sequencing technology, we also accepted and released more than 100 million of short reads of parasitic protozoa and their hosts that were produced by using a Solexa sequencer.	archive;base;biopolymer sequencing;dna data bank of japan;genome;greater than;latipes;lotus 1-2-3;microsequencer;national center for biotechnology information;parasites;protozoa measurement;reading (activity)	Hideaki Sugawara;Kazuho Ikeo;Satoshi Fukuchi;Takashi Gojobori;Yoshio Tateno	2009		10.1093/nar/gkn724	biology;genomics;bioinformatics;genetics;dna;genome	ML	-2.72298563555878	-61.16757403393641	27680
955711792c74b0e76403608875eee68fe12b2909	computing expectation values for rna motifs using discrete convolutions	software;animals;data interpretation statistical;models theoretical;statistical independence;regulatory sequences ribonucleic acid;computational biology bioinformatics;single stranded;expected value;rna;sequence homology nucleic acid;nucleic acid conformation;models statistical;algorithms;humans;sequence alignment;sequence analysis rna;combinatorial libraries;base sequence;computational biology;computer appl in life sciences;selenoproteins;microarrays;bioinformatics	Computational biologists use Expectation values (E-values) to estimate the number of solutions that can be expected by chance during a database scan. Here we focus on computing Expectation values for RNA motifs defined by single-strand and helix lod-score profiles with variable helix spans. Such E-values cannot be computed assuming a normal score distribution and their estimation previously required lengthy simulations. We introduce discrete convolutions as an accurate and fast mean to estimate score distributions of lod-score profiles. This method provides excellent score estimations for all single-strand or helical elements tested and also applies to the combination of elements into larger, complex, motifs. Further, the estimated distributions remain accurate even when pseudocounts are introduced into the lod-score profiles. Estimated score distributions are then easily converted into E-values. A good agreement was observed between computed E-values and simulations for a number of complete RNA motifs. This method is now implemented into the ERPIN software, but it can be applied as well to any search procedure based on ungapped profiles with statistically independent columns.	column (database);computation (action);convolution;large;limit of detection;rna;randomness;sequence motif;simulation;solutions;strand (programming language)	André Lambert;Matthieu Legendre;Jean-Fred Fontaine;Daniel Gautheret	2005	BMC Bioinformatics	10.1186/1471-2105-6-118	independence;biology;rna;dna microarray;bioinformatics;theoretical computer science;sequence alignment;genetics;expected value	Comp.	1.4293223186228294	-53.96176733855475	27685
013917f0ed660929c636b9205a60188e4829a1f7	sharing privacy-sensitive access to neuroimaging and genetics data: a review and preliminary validation	health research;uk clinical guidelines;data sharing;biological patents;europe pubmed central;citation search;uk phd theses thesis;neuroimaging;life sciences;data integration computer science;collaborative research;uk research reports;medical journals;privacy;europe pmc;data integration;biomedical research;bioinformatics	"""The growth of data sharing initiatives for neuroimaging and genomics represents an exciting opportunity to confront the """"small N"""" problem that plagues contemporary neuroimaging studies while further understanding the role genetic markers play in the function of the brain. When it is possible, open data sharing provides the most benefits. However, some data cannot be shared at all due to privacy concerns and/or risk of re-identification. Sharing other data sets is hampered by the proliferation of complex data use agreements (DUAs) which preclude truly automated data mining. These DUAs arise because of concerns about the privacy and confidentiality for subjects; though many do permit direct access to data, they often require a cumbersome approval process that can take months. An alternative approach is to only share data derivatives such as statistical summaries-the challenges here are to reformulate computational methods to quantify the privacy risks associated with sharing the results of those computations. For example, a derived map of gray matter is often as identifiable as a fingerprint. Thus alternative approaches to accessing data are needed. This paper reviews the relevant literature on differential privacy, a framework for measuring and tracking privacy loss in these settings, and demonstrates the feasibility of using this framework to calculate statistics on data distributed at many sites while still providing privacy."""	computation;confidentiality;data mining;differential privacy;fingerprint;genetic markers;gray matter;neuroimaging;plague;random access;review [publication type];sensorineural hearing loss (disorder);benefit	Anand D. Sarwate;Sergey M. Plis;Jessica A. Turner;Mohammad Arbabshirani;Vince D. Calhoun	2014		10.3389/fninf.2014.00035	psychology;medicine;computer science;bioinformatics;data science;data integration;data mining;privacy;world wide web;neuroimaging	ML	-0.6366908231872789	-69.4788277881343	27688
8bf0c09a9046799d8ba5b63cc70c14160fcdb1d1	placebo hampers ability to self-regulate brain activity: a double-blind sham-controlled neurofeedback study	brain connectivity;neurofeedback;placebo;sensorimotor rhythm;sham tdcs	It is still poorly understood how unspecific effects peripheral to the supposed action mechanism of neurofeedback (NF) influence the ability to self-regulate one's own brain signals. Recently, skeptical researchers have even attributed the lion's part of therapeutic outcomes of NF to placebo and other psychosocial factors. Here, we investigated whether and by which mechanisms unspecific factors influence neural self-regulation during NF. To manipulate the impact of unspecific influences on NF performance, we used a sham transcranial direct current stimulation (tDCS) as active placebo intervention suggesting positive effects on NF performance. Our results show that the expectation of receiving brain stimulation, which should boost neural self-regulation, interferes with the ability to self-regulate the sensorimotor rhythm in the EEG. Hence, these results provide evidence that placebo reduces NF performance, and thereby challenge current theories on unspecific effects related to NF.	brain implant;deep brain stimulation;electroencephalography;kohn–sham equations;neurofeedback;peripheral;self-control as a personality trait;theory;transcranial direct current stimulation	Silvia Erika Kober;Matthias Witte;Sandra Grinschgl;Christa Neuper;Guilherme Wood	2018	NeuroImage	10.1016/j.neuroimage.2018.07.025	psychology;placebo;brain activity and meditation;cognitive psychology;neurofeedback;sensorimotor rhythm;transcranial direct-current stimulation;electroencephalography;active placebo;stimulation	HCI	16.080902512503293	-79.02283607187243	27728
98568906503e50266b1eaad35d05724ed66c2261	metaphorical vs. literal word meanings: fmri evidence against a selective role of the right hemisphere	right hemisphere;neural network	The neural networks associated with processing metaphorical word meanings were investigated in normal adults using fMRI. Subjects listened to sets of three adjectives and decided whether the last two had a similar meaning. One condition required accessing the literal meaning of the middle word (e.g., hot-cold-chilly), whereas the other condition required accessing its nonliteral, or metaphorical, meaning (e.g., hot-cold-unfriendly). Direct comparison of the nonliteral vs. literal condition showed reliable activity only in left prefrontal and temporo-parietal regions. These results argue against a selective role of the right hemisphere (RH) in accessing metaphorical word meanings. In line with a growing literature, these findings suggest that prior reports of greater RH involvement for metaphorical language might reflect the increased complexity of figurative language rather than an RH specialization for understanding metaphors.	artificial neural network;auditory perception;literal (mathematical logic);neural network simulation;parietal lobe;partial template specialization;fmri	Susan Shin-Jung Lee;Mirella Dapretto	2006	NeuroImage	10.1016/j.neuroimage.2005.08.003	psychology;natural language processing;communication;artificial neural network	NLP	16.071394905847306	-78.13954450142465	27737
f4e3a1e57802ef2becf76667e1ffb360fbf99e24	mathematical approach to sensory motor control and memory		In this chapter we provide mathematical models for a general memory structure and for sensory-motor control via perception, detailing on some of the Recurrent Neural Networks (RNNs) introduced in Chapter 4. In the first section we study how individual memory items are stored assuming that situations given in the environment can be represented in the form of synaptic-like couplings in recurrent neural networks (RNN). We provide a theoretical basis concerning the learning process convergence and the network response to novel stimuli. We show that a nD network can learn static and dynamic patterns and can also replicate a sequence of up to n different vectors or frames. Such networks can also perform arithmetic calculations by means of pattern completion. In the second section we introduce a robot platform including the simplest probabilistic sensory and motor layers. Then we use the platform as a test-bed for evaluating the capabilities of robot navigation with different neural networks. We show that the basic robot element, the short-time memory, is the key element in obstacle avoidance. However, in the simplest conditions of no obstacles the straightforward memoryless robot is usually superior in performance. Accordingly, we suggest that small organisms (or agents) with short life-time do not require complex brains and even can benefit from simple brain-like (reflex) structures. In section 3 we propose a memotaxis strategy for target searching, which requires minimal computational resources and can be easily implemented in hardware. The strategy makes use of a dynamical system modeling short time memory which “collects” information on successful steps and corrects decisions made by a gradient strategy. Thus a memotactic robot can take steps against the chemotactic-like sensory gradient. We show (theoretically and experimentally) that the memotaxis strategy effectively suppresses stochasticity observed in the behavior of chemotactic robots in the region of low SNR and provides from 50 to 200% performance gain. 5.1 Theory of Recurrent Neural Networks Used to Form Situation Models 5.1.1 RNNs as a Part of a General Memory Structure How biological memories are organized is still a fairly open question, although a huge number of experimental studies have been reported dealing with features at different levels and using methods from different fields such as psychology or neurophysiology including brain imaging techniques. This situation has eventually been dubbed the crisis of the experimentalists. In order to understand brain functions, simulation studies P. Arena and L. Patanè (Eds.): Spatial Temporal Patterns, COSMOS 1, pp. 219–268. springerlink.com c © Springer-Verlag Berlin Heidelberg 2009 220 M.G. Velarde et al. appear to be a useful pragmatic approach. Such simulations on the one hand can originate new principles of information storage and engineering, and, on the other hand, may suggest experimental procedures to test novel hypotheses. On the search for appropriate simulation models, recurrent neural networks (RNNs) have been intensively studied. This begun with Hopfield’s seminal papers [25, 26] and has led to a vast literature. Significant architectures are Elman-Jordan networks [19] or echo state networks [28]. Apart from many studies concentrating on monolithic architectures, sparsely coded networks [37] or expert networks (see e.g. [43]) have been investigated. In particular the latter show the advantage that they form separable modules which can be treated in an easier way compared to monolithic structures, both with respect to studying the mathematical properties [10, 38] and with respect to the way how these modules might be implemented into a large memory structure (see for details Chap. 4). The latter, for example, implies problems of how memory contents can be organized to reflect hierarchical or contextual relationships. Another question concerns the structure of the basic RNN forming the individual modules, or “neural assemblies”. Two simple types of RNNs have recently been investigated and proposed as a possible basis for such elementary memory structures, one being the so-called multiple solutions of basic equations (MSBE) networks [32, 33] and the other being the so-called mean of multiple computations (MMC) networks [30, 41]. In [17] a general memory architecture has been proposed, in which these relatively small RNNs can be embedded. This general architecture, inspired by the insect mushroom body system [47], can be used for learning and controlling more complex behaviors as for example landmark-based navigation. The same architecture is currently being studied to form a general theory explaining many of the Pavlovian paradigms [18]. 5.1.2 Input Compensation (IC) Units and RNNs The networks considered here consist of n recurrently connected “simple” nonlinear units called, respectively, “suppression unit” or Su and “max-unit” or Mu (Figs. 5.1A and 5.1B). Both units operate in a discrete time t ∈ Z and have an external input denoted as signal ξi(t) that we also call activation, an internal (recurrent) input si(t), and an output evaluated by the unit on the next time step xi(t +1). The recurrent input is given by a weighted sum of the output of all units in the network si(t) = n ∑ k=1 wikxk(t) (5.1) where the matrix W = {wi j} plays the role of inter-unit coupling (Fig. 5.1C). The non-linear properties of the units arise from the treatment of the recurrent signal according to the signal at the external input. In Su the recurrent signal is simply suppressed and replaced by the external input if the latter is different from zero, or otherwise sent unchanged to the output x(t + 1) = { ξ (t), if ξ (t) = 0 s(t), otherwise (5.2)	artificial neural network;biological system;c date and time functions;challenge-handshake authentication protocol;computation;computational resource;computer data storage;computer performance;dynamical system;embedded system;experiment;gradient;hopfield network;like button;mathematical model;memory management controller;neural networks;nonlinear system;obstacle avoidance;random neural network;recurrent neural network;robot;robotic mapping;self-replicating machine;signal-to-noise ratio;simulation;springer (tank);synaptic package manager;systems modeling;testbed;the matrix;weight function;zero suppression	Manuel G. Velarde;Valeri A. Makarov;N. P. Castellanos;Y. L. Song;Davide Lombardo	2009		10.1007/978-3-540-88464-4_5	simulation;computer science;artificial intelligence;communication	ML	17.688448724814197	-66.96142501110558	27812
92e0d3badeeb9a220ed995a003bc6a186261ea4a	modeling the response of a population of olfactory receptor neurons to an odorant	olfactory receptor neuron;standard deviation;lognormal distribution;computer and information science;fire frequency;neural population modeling;olfactory receptor;dynamic range;olfaction;data och informationsvetenskap;sensory coding;statistical distribution;gaussian distribution	We modeled the firing rate of populations of olfactory receptor neurons (ORNs) responding to an odorant at different concentrations. Two cases were considered: a population of ORNs that all express the same olfactory receptor (OR), and a population that expresses many different ORs. To take into account ORN variability, we replaced single parameter values in a biophysical ORN model with values drawn from statistical distributions, chosen to correspond to experimental data. For ORNs expressing the same OR, we found that the distributions of firing frequencies are Gaussian at all concentrations, with larger mean and standard deviation at higher concentrations. For a population expressing different ORs, the distribution of firing frequencies can be described as the superposition of a Gaussian distribution and a lognormal distribution. Distributions of maximum value and dynamic range of spiking frequencies in the simulated ORN population were similar to experimental results.	dynamic range;large;neurons;normal statistical distribution;nuclear receptor signaling atlas;odorants;olfactory receptor cells;population parameter;quantum superposition;receptors, odorant;spatial variability;statistical distributions	Malin Sandström;Anders Lansner;Jeanette Kotaleski;Jean-Pierre Rospars	2009	Journal of Computational Neuroscience	10.1007/s10827-009-0147-5	normal distribution;probability distribution;dynamic range;machine learning;olfaction;log-normal distribution;mathematics;standard deviation;communication;statistics	ML	20.269378595034283	-72.76490196923193	27875
4bd9874d19b37d4c90c23e5170b1b50cc5e9c645	physicochemical correlation between amino acid sites in short sequences under selective pressure	physicochemical properties;amino acid;amino acid sequence;selection;mhc class i;natural selection;structure and function;covariation;hepatitis c virus	The activities and properties of proteins are the result of interactionsamong their constitutive amino acids. In the course of natural selection, substitutionswhich tend to destabilize a particular structure may be compensated byother substitutions which confer stability to that structure. Patterns of coordinatedsubstitutions were studied in two sets of selected peptides. The first is aset of 181 amino acid sequences that were selected in vitro to bind a MHC classI molecule (Kb). The second is a set of 114 sequences of the Hypervariable Region1 of Hepatitis C virus, which, originating from infected patients, resultfrom natural selection in vivo. The patterns of coordinated substitutions in bothdatasets showed many significant structural and functional links between pairsof positions and conservation of specific selected physicochemical properties.		David S. Campo;Zoya Dimitrova;Yuri Khudyakov	2008		10.1007/978-3-540-79450-9_14	biology;biochemistry;selection;natural selection;amino acid;mhc class i;covariance;peptide sequence;genetics	Crypto	7.221529482760409	-62.704380964118705	27943
2717b72cb7fc0dcfface53ded8c6f394114e240a	mgene.web: a web service for accurate computational gene finding	dna;genes;software;genomics;rna splice sites;gene finding;sequence analysis dna;web service;internet;proteins;genome;gene organization;transcription initiation site	We describe mGene.web, a web service for the genome-wide prediction of protein coding genes from eukaryotic DNA sequences. It offers pre-trained models for the recognition of gene structures including untranslated regions in an increasing number of organisms. With mGene.web, users have the additional possibility to train the system with their own data for other organisms on the push of a button, a functionality that will greatly accelerate the annotation of newly sequenced genomes. The system is built in a highly modular way, such that individual components of the framework, like the promoter prediction tool or the splice site predictor, can be used autonomously. The underlying gene finding system mGene is based on discriminative machine learning techniques and its high accuracy has been demonstrated in an international competition on nematode genomes. mGene.web is available at http://www.mgene.org/web, it is free of charge and can be used for eukaryotic genomes of small to moderate size (several hundred Mbp).	annotation;gene prediction;genome;kerrison predictor;machine learning;million book project;nematodes;splice (system call);untranslated regions;web service	Gabriele Beate Schweikert;Jonas Behr;Alexander Zien;Georg Zeller;Cheng Soon Ong;Sören Sonnenburg;Gunnar Rätsch	2009		10.1093/nar/gkp479	web service;biology;genomics;molecular biology;the internet;bioinformatics;gene;genetics;dna;gene prediction;genome	Comp.	1.521241442338158	-59.07601491760724	27946
a6d1ac548ba759844e9859ba19a725f03ef11943	neural architecture for mental imaging of sequences based on optical flow predictions	architecture systeme;flux optique;imagerie;imagery;image sequence;biological systems;arquitectura sistema;secuencia imagen;optical flow;imagineria;reseau neuronal;system architecture;red neuronal;sequence image;neural network	In this paper we present a neural architecture for a mental imaging like generation of image sequences. Mental imaging plays a central role for various perception processes. Thereto, we investigated mechanisms to model this ability of biological systems at a functional level for sequences of images. Because it is impossible to memorize many experienced sequences, we developed an universal, general and very powerful approach based on the ability to predict optic flow fields as consequences of the systems own actions and tested the resulting architecture on a real mobile system.	optical flow	Volker Stephan;Horst-Michael Groß	2001		10.1007/3-540-44668-0_122	computer vision;computer science;artificial intelligence;machine learning;optical flow;artificial neural network;systems architecture	Vision	22.041842266281158	-68.94102147403832	27949
6b0189cf301f4c363f040a8b09fff1f5a39f08f7	a preliminary variable selection based regression analysis for predicting patient satisfaction on physician-patient cancer prognosis communication		We explore the use of variable selection methods to deal with high correlations among predicative variables (e.g., physician's voice tone and language certainty) for examining physician communication associated with prognosis discussion with cancer patients. Our main method is principal com- ponent analysis. The comparative results show its benefit in predicting patient satisfaction on the prognosis communication. This preliminary regression anal- ysis is expected to offer insights into patient-centered communication strategy design, especially for cancer prognosis communication with end-stage patients.	feature selection	Shuai Fang;Wenting Shi;Nan Kong;Cleveland G. Shields	2014		10.1007/978-3-319-08416-9_18	medicine;artificial intelligence;communication;social psychology	ML	3.7694903837182743	-77.5095325444951	27956
4d653b19ce1c7cba79fc2f11271fb90f7744c95c	light-weight refinenet for real-time semantic segmentation		We consider an important task of effective and efficient semantic image segmentation. In particular, we adapt a powerful semantic segmentation architecture, called RefineNet [46], into the more compact one, suitable even for tasks requiring real-time performance on high-resolution inputs. To this end, we identify computationally expensive blocks in the original setup, and propose two modifications aimed to decrease the number of parameters and floating point operations. By doing that, we achieve more than twofold model reduction, while keeping the performance levels almost intact. Our fastest model undergoes a significant speed-up boost from 20 FPS to 55 FPS on a generic GPU card on 512×512 inputs with solid 81.1% mean iou performance on the test set of PASCAL VOC [18], while our slowest model with 32 FPS (from original 17 FPS) shows 82.7% mean iou on the same dataset. Alternatively, we showcase that our approach is easily mixable with light-weight classification networks: we attain 79.2% mean iou on PASCAL VOC using a model that contains only 3.3M parameters and performs only 9.3B floating point operations.	analysis of algorithms;fastest;floating point systems;graphics processing unit;image resolution;image segmentation;real-time clock;real-time transcription;test set;x86 memory segmentation	Vladimir Nekrasov;Chunhua Shen;Ian D. Reid	2018			computer science;machine learning;computer vision;artificial intelligence;image segmentation;architecture;floating point;test set;segmentation	ML	23.582209132981582	-52.155383657044645	27977
dda0a82a6ee8cfc701aaf24ed27047231cbec7f7	graph slepians to probe into large-scale network organization of resting-state functional connectivity		Functional magnetic resonance imaging (fMRI) is providing large amounts of data about brain function. Measuring correlations between spontaneous activity time courses from resting-state fMRI has revealed large-scale network organization. In the graph-based approach for functional connectivity analysis, a graph is built where nodes are brain regions and edge weights are pairwise correlations between the associated time courses. Here, we propose to apply recent approaches from graph signal processing to analyze fMRI data. First, the graph is constructed from structural connectivity, then, the corresponding graph spectrum is obtained such that the graph Slepian design can be deployed. In particular, graph Slepians are band-limited (i.e., using only graph Laplacian eigenvectors with lowest eigenvalues) with optimal energy concentration in predefined subgraphs. The subgraphs selected here are default-mode network (DMN) and fronto-parietal network (FPN), known as task-negative and — positive networks, respectively. While their activity appears anti-correlated during resting-state, a much more complicated interplay has been suggested recently using dynamic and time-resolved approaches. Preliminary results using data from the Human Connectome Project show that the proposed framework can direct the analysis to specific parts of the network and bring to light interactions between local and global aspects of network organization that were hidden before.	bandlimiting;decision model and notation;fixed-pattern noise;human connectome project;interaction;laplacian matrix;network governance;neural oscillation;resonance;resting state fmri;signal processing;spectral graph theory;spontaneous order	Maria Giulia Preti;Dimitri Van De Ville	2017	2017 51st Asilomar Conference on Signals, Systems, and Computers	10.1109/ACSSC.2017.8335615	task analysis;resting state fmri;human connectome project;mathematical optimization;machine learning;signal processing;computer science;eigenvalues and eigenvectors;laplacian matrix;pairwise comparison;functional magnetic resonance imaging;artificial intelligence	ML	22.917577287512245	-75.30126230333781	28004
727d98b52a33e2fe82b66fb90cda2d0f41bddb10	experimental search for minimal organisms and the last universal common ancestor: reconstructing the ur-organism		T wo questions that should be closely related have historically been studied with very different approaches. One is what constitutes a minimal living system, whether minimal cell or minimal self-contained ecosystem. The other is what actual system was the last universal common ancestor (LUCA) of all modern cells. As the LUCA is supposed to have been a bottleneck through which all life passed before diversifying into modern forms, it is treated as a self-sufficient organism and would be a candidate for a minimal cell. Attempted reconstructions of the LUCA have largely been inferences in molecular phylogeny. Modern genes are grouped by common function and where possible by sequence homology, and primordial forms are traced back through the tree of life. In contrast, the search for minimal organisms has been mostly experimental, based on survey of short natural genomes and further random removal of genes. Current understanding of metabolism and control is still too primitive for theoretical approaches to have significantly affected this program. The experimental search for a minimal microbial genome began in the early 1960s, culminating with Mycoplasma genitalium, which has only 482 protein-coding genes and 580,076 [source http://cmr.tigr.org] base pairs in the wild type. Unfortunately this starting point cannot lead to either a minimal free-living organism or a model for the LUCA, because Mycoplasma and other small-genome organisms like Rickettsia and Chlamydia are obligate pathogens known as “cell wall defectives.” Descended from free-living Gram-positive bacteria with 4000 genes by loss of genes and functions, the Mycoplasmataceae depend on their hosts for most primary biosynthesis, and even for osmotic regulation. They are consummate heterotrophs, and their minimality reflects a high degree of ecological specialization rather than primitiveness. It has since become known that single cells can be autotrophic on environmental CO2, reductant (H2), water, H2S, NH3, phosphate, and trace minerals, and thermophilic organisms of this type with 1500 –2000 genes from both the Archeal (such as Methanococcus jannaschii) and Bacterial (such as Aquifex aeolicus) domains have been studied. Their genomes are smaller than those of the smallest photoEric Smith, Harold J. Morowitz, and Vijayasarathy Srinivasan	artificial cell;ecosystem;last universal common ancestor;list of google products;living systems;molecular phylogenetics;mycoplasma genitalium;partial template specialization;sequence homology;weatherstar	Eric Smith;Harold J. Morowitz;Vijayasarathy Srinivasan	2006	Complexity	10.1002/cplx.20154	biology;zoology;evolutionary biology	ML	3.393403329406029	-62.454019731044525	28031
78223ca9c9a6dad89e2ec70a119e312843dd6633	learning latent temporal connectionism of deep residual visual abstractions for identifying surgical tools in laparoscopy procedures		Surgical workflow in minimally invasive interventions like laparoscopy can be modeled with the aid of tool usage information. The video stream available during surgery primarily for viewing the surgical site using an endoscope can be leveraged for this purpose without the need for additional sensors or instruments. We propose a method which learns to detect the tool presence in laparoscopy videos by leveraging the temporal connectionist information in a systematically executed surgical procedures by learning the long and short order relationships between higher abstractions of the spatial visual features extracted from the surgical video. We propose a framework consisting of using Convolutional Neural Networks for extracting the visual features and Long Short-Term Memory network to encode the temporal information. The proposed framework has been experimentally verified using a publicly available dataset consisting of 10 training and 5 testing annotated videos to obtain an average accuracy of 88:75% in detecting the tools present.	baseline (configuration management);biological specimen;clipper;connectionism;convolutional neural network;encode;experiment;long short-term memory;neural networks;sensor;streaming media	Kaustuv Mishra;Rachana Sathish;Debdoot Sheet	2017	2017 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)	10.1109/CVPRW.2017.277	visualization;computer vision;residual;convolutional neural network;encode;artificial intelligence;connectionism;computer science;data mining;feature extraction;machine learning;workflow;laparoscopy	Vision	22.730169203213336	-56.946273202883496	28075
dbe5e374d15349025e1e2e6b0c368f88bde5458f	single-trial coupling of eeg and fmri reveals the involvement of early anterior cingulate cortex activation in effortful decision making	mental effort;temporal dynamics;random effects;simultaneous eeg fmri;cognitive process;healthy subjects;temporal resolution;anterior cingulate cortex;multiple comparisons;auditory cortex;eeg fmri;electroencephalography;multi modal imaging;acc;spatial resolution	While the precise role of the anterior cingulate cortex (ACC) is still being discussed, it has been suggested that ACC activity might reflect the amount of mental effort associated with cognitive processing. So far, not much is known about the temporal dynamics of ACC activity in effort-related decision making or auditory attention, because fMRI is limited concerning its temporal resolution and electroencephalography (EEG) is limited concerning its spatial resolution. Single-trial coupling of EEG and fMRI can be used to predict the BOLD signal specifically related to amplitude variations of electrophysiological components. The striking feature of single-trial coupling is its ability to separate different aspects of the BOLD signal according to their specific relationship to a distinct neural process. In the present study we investigated 10 healthy subjects with a forced choice reaction task under both low and high effort conditions and a control condition (passive listening) using simultaneous EEG and fMRI. We detected a significant effect of mental effort only for the N1 potential, but not for the P300 potential. In the fMRI analysis, ACC activation was present only in the high effort condition. We used single-trial coupling of EEG and fMRI in order to separate information specific to N1-amplitude variations from the unrelated BOLD response. Under high effort conditions we were able to detect circumscribed BOLD activations specific to the N1 potential in the ACC (t=4.7) and the auditory cortex (t=6.1). Comparing the N1-specific BOLD activity of the high effort condition versus the control condition we found only activation of the ACC (random effects analysis, corrected for multiple comparisons, t=4.4). These findings suggest a role of early ACC activation in effort-related decision making and provide a direct link between the N1 component and its corresponding BOLD signal.	auditory area;cerebral cortex;cingulate cortex;circumscribe (action);cognition disorders;decision making;electroencephalography phase synchronization;hearing problem;inline linking;random effects model;temporal logic;fmri	Christoph Mulert;Christian Seifert;Gregor Leicht;Valerie Kirsch;Matthias Ertl;Susanne Karch;Matthias Moosmann;Jürgen Lutz;Hans-Jürgen Möller;Ulrich Hegerl;Oliver Pogarell;Lorenz Jäger	2008	NeuroImage	10.1016/j.neuroimage.2008.04.236	psychology;cognitive psychology;eeg-fmri;cognition;developmental psychology;image resolution;electroencephalography;temporal resolution;communication;multiple comparisons problem;statistics;random effects model	ML	16.802143621151636	-77.61520329923127	28108
85029b04a54de5c9dddf83be20a77fc48b73edbf	dynamics of the hpa axis and inflammatory cytokines: insights from mathematical modeling	nervous system;hypothalamic pituitary adrenal hpa axis;immune system;mathematical model;inflammatory cytokines	In the work presented here, a novel mathematical model was developed to explore the bi-directional communication between the hypothalamic-pituitary-adrenal (HPA) axis and inflammatory cytokines in acute inflammation. The dynamic model consists of five delay differential equations 5D for two main pro-inflammatory cytokines (TNF-α and IL-6) and two hormones of the HPA axis (ACTH and cortisol) and LPS endotoxin. The model is an attempt to increase the understanding of the role of primary hormones and cytokines in this complex relationship by demonstrating the influence of different organs and hormones in the regulation of the inflammatory response. The model captures the main qualitative features of cytokine and hormone dynamics when a toxic challenge is introduced. Moreover, in this work a new simple delayed model of the HPA axis is introduced which supports the understanding of the ultradian rhythm of HPA hormones both in normal and infection conditions. Through simulations using the model, the role of key inflammatory cytokines and cortisol in transition from acute to persistent inflammation through stability analysis is investigated. Also, by employing a Markov chain Monte Carlo (MCMC) method, parameter uncertainty and the effects of parameter variations on each other are analyzed. This model confirms the important role of the HPA axis in acute and prolonged inflammation and can be a useful tool in further investigation of the role of stress on the immune response to infectious diseases.		Hamed Malek;Mohammad Mehdi Ebadzadeh;Reza Safabakhsh;Alireza Razavi;Jalal Zaringhalam	2015	Computers in biology and medicine	10.1016/j.compbiomed.2015.09.018	endocrinology;immune system;mathematical model;immunology;nervous system;proinflammatory cytokine	AI	9.48741530099762	-69.30744691949715	28177
c971f34ccd45306ac960596d9d57f09fe7c25730	qsar models for p-glycoprotein transport based on a highly consistent data set		P-Glycoprotein (Pgp) is involved in the elimination and in the disposition of a significant portion of marketed drugs. So far, publicly available data sets used for modeling Pgp transport included compounds tested in different assays, different cell lines, and different protocols. In this work, we present a collection of 478 Efflux Ratios (ERs) in MDCK-MDR1 cell lines, and from this collection we define a data set of 187 compounds that were tested in the Borst-derived MDCK-MDR1 cell lines. Of the 23 models resulting from the use of different descriptors, classification algorithms, and variable selection techniques, the 4 most accurate in external validation (∼0.86) are based on VolSurf+ (VS+) descriptors. Two of these models are Naïve Bayes (NB) classifiers using 4 descriptors that were selected through a new technique hereby first time extensively described.	bayes theorem;cultured cell line;excretory function;feature selection;naive bayes classifier;pretty good privacy;protocols documentation;quantitative structure-activity relationship;quantitative structure–activity relationship;algorithm;glycoprotein transport	Fabio Broccatelli	2012	Journal of chemical information and modeling	10.1021/ci3002809	applicability domain	ML	8.082519437918426	-54.43459275967711	28257
742ee5a5fc0faccc60a1b13c247d060ca2875134	an integrated medical cps for early detection of paroxysmal sympathetic hyperactivity	biomedical monitoring;medical cyber physical system;computational modeling;medical services;monitoring;feature extraction;paroxysmal sympathetic hyperactivity;mathematical model;early detection;medical diagnostic imaging	Paroxysmal sympathetic hyperactivity (PSH) is an important clinical problem of severe traumatic brain injury (TBI) which incurs approximately 90% of all TBI-related costs. However, current detection approach is hampered by no consensus clinical diagnostic criteria, paroxysmal episode feature with complex manifestations, and already overloaded clinical activities. These limitations cause delayed recognitions which result in poor clinical outcomes. In this paper, we design an integrated Medical Cyber-Physical System (Medical CPS) for early detection of paroxysmal sympathetic hyperactivity patients. First, a formal model is proposed to describe clinical diagnostic criteria. With the formalized models employed, we implement an early detector and integrate it with revised medical device adapters into Medical CPS. Our system will monitor patient conditions automatically and continuously to relieve medical staff from the heavy burden of clinical activities and provide timely decision supports. Evaluations on 107 clinical cases extracted from medical publications demonstrate the effectiveness and the efficiency of our integrated system.	cyber-physical system;formal language;history of wikis;polythematic structured subject heading system	Zuxing Gu;Hong Song;Yu Jiang;Jeonghone Choi;Hongjiang He;Lui Sha;Ming Gu	2016	2016 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)	10.1109/BIBM.2016.7822630	feature extraction;computer science;machine learning;mathematical model;computational model;statistics	SE	5.757059184519615	-79.32568040550979	28264
a7d938295d3d10ab974dd5a7737fcf27019618ef	steroid receptor rna activator protein binds to and counteracts sra rna-mediated activation of myod and muscle differentiation	rna interference;animals;mice;myotonic dystrophy;cell differentiation;databases genetic;binding sites;genetic variation;cells cultured;rna untranslated;satellite cells skeletal muscle;gene expression regulation;protein binding;carrier proteins;humans;muscle development;myod protein;rna long untranslated;cell line	The steroid receptor RNA activator (SRA) has the unusual property to function as both a non-coding RNA (ncRNA) and a protein SRAP. SRA ncRNA is known to increase the activity of a range of nuclear receptors as well as the master regulator of muscle differentiation MyoD. The contribution of SRA to either a ncRNA or a protein is influenced by alternative splicing of the first intron, the retention of which disrupts the SRAP open reading frame. We reported here that the ratio between non-coding and coding SRA isoforms increased during myogenic differentiation of human satellite cells but not myotonic dystrophy patient satellite cells, in which differentiation capacity is affected. Using constructs that exclusively produce SRA ncRNA or SRAP, we demonstrated that whereas SRA ncRNA was indeed an enhancer of myogenic differentiation and myogenic conversion of non-muscle cells through the co-activation of MyoD activity, SRAP prevented this SRA RNA-dependant co-activation. Interestingly, the SRAP inhibitory effect is mediated through the interaction of SRAP with its RNA counterpart via its RRM-like domain interacting with the functional sub-structure of SRA RNA, STR7. This study thus provides a new model for SRA-mediated regulation of MyoD transcriptional activity in the promotion of normal muscle differentiation, which takes into account the nature of SRA molecules present.	alternative splicing;automatic differentiation;cell differentiation process;enhancer of transcription;interaction;introns;muscle cells;myotonic dystrophy;open reading frame;patients;protein isoforms;rna recognition motif;rna splicing;rna, untranslated;radio resource management;reading frames (nucleotide sequence);receptors, nuclear;receptors, steroid;sequence read archive;staphylococcal protein a;steroids;transcription, genetic;muscle cell differentiation;steroid receptor rna activator	Florent Hubé;Guillaume Velasco;Jérôme Rollin;Denis Furling;Claire Francastel	2011		10.1093/nar/gkq833	biology;plasma protein binding;molecular biology;regulation of gene expression;rna interference;binding site;genetic variation;genetics;cell culture;cellular differentiation;carrier protein;anatomy	Comp.	5.599576653596259	-63.046415130509864	28269
a6ca182b36965935688c1452ff076b69d8c5257f	big data challenges in genome informatics		In recent years, we have witnessed a dramatic data explosion in genomics, thanks to the improvement in sequencing technologies and the drastically decreasing costs. We are entering the era of millions of available genomes. Notably, each genome can be composed of billions of nucleotides stored as plain text files in GigaBytes (GBs). It is undeniable that those genome data impose unprecedented data challenges for us. In this article, we briefly discuss the big data challenges associated with genomics in recent years.	big data;gigabyte;informatics	Ka-Chun Wong	2018	CoRR		data science;genomics;cell biology;big data;biology;genome;informatics;plain text	ML	-4.440487344076597	-61.49106034779744	28287
33c020dc4c1f9b17435423c3308675b64ae70934	molecular modeling of zabrotes subfasciatus a-amylase: an in silico strategy on development of novel bioinsecticides	molecular modeling		molecular modelling	André Murad	2004			computational biology;amylase;in silico;molecular model;zabrotes subfasciatus;biology	Robotics	1.6539664016493958	-64.24096100946876	28314
1ee8126dfecc72a5ded45c2bb1c4e4c077e66742	effects of viral mutation on cellular dynamics in a monte carlo simulation of hiv immune response model in three dimensions	monte carlo;hiv;mobility;mutation;latency	The cellular dynamics of HIV interaction with the immune system is explored in three-dimensions using a direct Monte Carlo simulation. Viral mutation with probability, Pmut, is considered with immobile and mobile cells. With immobile cells, the viral population becomes larger than that of the helper cells beyond a latency period Tcrit and above a mutation threshold Pcrit. That is at Pmut ≥ Pcrit, { $${\rm T}_{crit} \propto \left( {{\rm P}_{mut} - {\rm P}_{crit} } \right)^{ - \gamma } $$ }, with γ ⋍ 0.73 in three dimensions and γ ⋍ 0.88 in 2-D. Very little difference in Pcrit is observed between two and three dimensions. With mobile cells, no power-law is observed for the period of latency, but the difference in Pcrit between two and three dimensions is increased. The time-dependency of the density difference between Viral and Helper cell populations (ρV − ρH) is explored and follows the basic pattern of an immune response to infection. This is markedly more defined than in the 2-D case, where no clear pattern emerges.	emergence;monte carlo method;pmut;population;simulation	Rachel Mannion;Heather J. Ruskin;R. B. Pandey	2002	Theory in Biosciences	10.1007/s12064-002-0022-7	biology;immune system;virology;immunology;mobile computing;statistics;monte carlo method	Metrics	9.199707371745102	-65.95862827751432	28330
b301ee9da98a974752dc0e00d6d0e1c5ea138296	gossamer - a resource-efficient de novo assembler		MOTIVATION The de novo assembly of short read high-throughput sequencing data poses significant computational challenges. The volume of data is huge; the reads are tiny compared to the underlying sequence, and there are significant numbers of sequencing errors. There are numerous software packages that allow users to assemble short reads, but most are either limited to relatively small genomes (e.g. bacteria) or require large computing infrastructure or employ greedy algorithms and thus often do not yield high-quality results.   RESULTS We have developed Gossamer, an implementation of the de Bruijn approach to assembly that requires close to the theoretical minimum of memory, but still allows efficient processing. Our results show that it is space efficient and produces high-quality assemblies.   AVAILABILITY Gossamer is available for non-commercial use from http://www.genomics.csse.unimelb.edu.au/product-gossamer.php.		Thomas C. Conway;Jeremy Wazny;Andrew J. Bromage;Justin Zobel;Bryan Beresford-Smith	2012	Bioinformatics	10.1093/bioinformatics/bts297	computer science;bioinformatics;theoretical computer science;algorithm	Comp.	-1.0463040268991237	-53.848191152709965	28387
62bb83dd76e126fe16d89bd682e25e9bc8e80530	image segmentation using a sparse coding model of cortical area v1	image coding;image segmentation;perceptual reasoning computational models of vision computer vision edge and feature detection neural nets;image segmentation image coding;algorithms databases factual humans image processing computer assisted models neurological visual cortex visual perception;neurons image edge detection mathematical model equations image reconstruction kernel predictive models;image segmentation method sparse coding model cortical area v1 physiology image compression image restoration image classification response properties primary visual cortex perceptually salient boundary detection intensity information	Algorithms that encode images using a sparse set of basis functions have previously been shown to explain aspects of the physiology of a primary visual cortex (V1), and have been used for applications, such as image compression, restoration, and classification. Here, a sparse coding algorithm, that has previously been used to account for the response properties of orientation tuned cells in primary visual cortex, is applied to the task of perceptually salient boundary detection. The proposed algorithm is currently limited to using only intensity information at a single scale. However, it is shown to out-perform the current state-of-the-art image segmentation method (Pb) when this method is also restricted to using the same information.	algorithm;area striata structure;basis function;cerebral cortex;circuit restoration;encode;image compression;image segmentation;neural coding;sparse approximation;sparse language;sparse matrix;biologic segmentation;physiological aspects	Michael W. Spratling	2013	IEEE Transactions on Image Processing	10.1109/TIP.2012.2235850	image texture;computer vision;feature detection;scale space;edge detection;binary image;image processing;computer science;machine learning;segmentation-based object categorization;pattern recognition;image segmentation;scale-space segmentation	ML	21.829276058980714	-67.40710195260405	28407
372fe08b644dd5e4a24283edbdd33ba04226b04d	ramigo: an r/bioconductor package providing an amigo visualize interface	genes;software;breast neoplasms;female;vocabulary controlled;computer graphics;internet;transcriptome;humans;user computer interface	SUMMARY The R/Bioconductor package RamiGO is an R interface to AmiGO that enables visualization of Gene Ontology (GO) trees. Given a list of GO terms, RamiGO uses the AmiGO visualize API to import Graphviz-DOT format files into R, and export these either as images (SVG, PNG) or into Cytoscape for extended network analyses. RamiGO provides easy customization of annotation, highlighting of specific GO terms, colouring of terms by P-value or export of a simplified summary GO tree. We illustrate RamiGO functionalities in a genome-wide gene set analysis of prognostic genes in breast cancer.   AVAILABILITY AND IMPLEMENTATION RamiGO is provided in R/Bioconductor, is open source under the Artistic-2.0 License and is available with a user manual containing installation, operating instructions and tutorials. It requires R version 2.15.0 or higher. URL: http://bioconductor.org/packages/release/bioc/html/RamiGO.html	amigo1 gene;application programming interface;bioconductor;cytoscape;gene ontology;graphviz;imagery;interface device component;laboratory sample manual;mammary neoplasms;open-source software;owner's manual;portable network graphics;scalable vector graphics;trees (plant);uniform resource locator	Markus S. Schröder;Daniel Gusenleitner;John Quackenbush;Aedín C. Culhane;Benjamin Haibe-Kains	2013	Bioinformatics	10.1093/bioinformatics/bts708	biology;the internet;transcriptome;computer science;bioinformatics;gene;database;computer graphics;world wide web	Comp.	-3.5920079091558024	-58.48882776253887	28467
28bfecd1d9f1f47c70322a31dc455f20d854033d	cohesive versus flexible evolution of functional modules in eukaryotes	evolution molecular;protein complex;saccharomyces cerevisiae;metabolic networks and pathways;phylogeny;saccharomyces cerevisiae proteins;eukaryotic cells;models genetic;proteins;computational biology;databases protein	Although functionally related proteins can be reliably predicted from phylogenetic profiles, many functional modules do not seem to evolve cohesively according to case studies and systematic analyses in prokaryotes. In this study we quantify the extent of evolutionary cohesiveness of functional modules in eukaryotes and probe the biological and methodological factors influencing our estimates. We have collected various datasets of protein complexes and pathways in Saccheromyces cerevisiae. We define orthologous groups on 34 eukaryotic genomes and measure the extent of cohesive evolution of sets of orthologous groups of which members constitute a known complex or pathway. Within this framework it appears that most functional modules evolve flexibly rather than cohesively. Even after correcting for uncertain module definitions and potentially problematic orthologous groups, only 46% of pathways and complexes evolve more cohesively than random modules. This flexibility seems partly coupled to the nature of the functional module because biochemical pathways are generally more cohesively evolving than complexes.	biological evolution;estimated;evolutionary algorithm;gene regulatory network;genome;group cohesiveness;homology (biology);phylogenetics;prokaryote;sequence homology	Like Fokkens;Berend Snel	2009	PLoS Computational Biology	10.1371/journal.pcbi.1000276	computational biology;biology;bioinformatics;multiprotein complex;genetics;phylogenetics	Comp.	4.2576432548140755	-59.46149441423426	28510
d0085ab8e36dd512f2d8038db8605d54c636f3b2	using the longest significance run to estimate region-specific p-values in genetic association mapping studies	dna;false discovery rate;study design;complex disease;multiple testing;uncertainty;confidence intervals;reference values;disease susceptibility;genetic testing;logistic models;association study;genetic marker;computational biology bioinformatics;genetic association;false positive rate;gene frequency;chi square distribution;likelihood functions;sequence homology nucleic acid;genetic predisposition to disease;genome human;indexation;predictive value of tests;psoriasis;algorithms;humans;combinatorial libraries;computer appl in life sciences;linkage disequilibrium;genetic markers;haplotypes;microarrays;bioinformatics	Association testing is a powerful tool for identifying disease susceptibility genes underlying complex diseases. Technological advances have yielded a dramatic increase in the density of available genetic markers, necessitating an increase in the number of association tests required for the analysis of disease susceptibility genes. As such, multiple-tests corrections have become a critical issue. However the conventional statistical corrections on locus-specific multiple tests usually result in lower power as the number of markers increases. Alternatively, we propose here the application of the longest significant run (LSR) method to estimate a region-specific p-value to provide an index for the most likely candidate region. An advantage of the LSR method relative to procedures based on genotypic data is that only p-value data are needed and hence can be applied extensively to different study designs. In this study the proposed LSR method was compared with commonly used methods such as Bonferroni's method and FDR controlling method. We found that while all methods provide good control over false positive rate, LSR has much better power and false discovery rate. In the authentic analysis on psoriasis and asthma disease data, the LSR method successfully identified important candidate regions and replicated the results of previous association studies. The proposed LSR method provides an efficient exploratory tool for the analysis of sequences of dense genetic markers. Our results show that the LSR method has better power and lower false discovery rate comparing with the locus-specific multiple tests.	disease susceptibility;genetic markers;genotype;locus;p-value;psoriasis	Ie-Bin Lian;Yi-Hsien Lin;Ying-Chao Lin;Hsin-Chou Yang;Chee-Jang Chang;Cathy S. J. Fann	2007	BMC Bioinformatics	10.1186/1471-2105-9-246	biology;bioinformatics;genetic marker;genetics	Comp.	3.309192221208978	-53.16777883584876	28552
cd76c96cf65d6ecbf128aa25ebca06a3f9cf6fdf	modelling the comet assay	simulation and modeling;systems biology;physiological cellular and medical topics;computational biology bioinformatics;algorithms;comet assay;bioinformatics	"""Background The single cell gel electrophoresis or Comet assay is a sensitive, reliable, and quick fluorescent microscopic method for detecting DNA single-strand (SSBs) and double-strand breaks (DSBs) at an individual cell level [1]. In this assay, single cells are embedded in agarose on frosted slides, lysed to remove all cellular proteins, subjected to brief electrophoresis, stained with a DNA intercalating dye, and observed with fluorescence microscopy. Undamaged DNA is unable to enter the agarose gel, and is retained in the cavity formed by the lysed cell: damaged DNA streams down the electrophoretic field, and forms the """"tail"""" of a Comet [2,3]. The length and fluorescent intensity of the Comet tail relates to the number of DNA-strand breaks. Undamaged cells appear as intact nuclei (Comet heads) without tails. The Comet assay has been implemented successfully over the years in the areas of genotoxicology [1], clinical studies, DNA repair studies [4], environmental and human biomonitoring [1]."""	embedded system;sensor;strand (programming language);tails	Darragh G. McArt;Robert W. Cairns;Gillian Wasson;Kurt Saetzler	2007	BMC Systems Biology	10.1186/1752-0509-1-S1-P71	biology;molecular biology;toxicology;computer science;bioinformatics;systems biology	Comp.	5.338614831210733	-64.15245706880391	28645
24023d139eb969b2973a58bf803e62b330917298	secret laws of the labyrinth	inner;fluids;irrigation;endolymphatic fluid;proprioception;biomechanics;computer simulation ear inner humans models anatomic models biological postural balance proprioception;biological fluid dynamics;vertebrates;mathematical analysis;acceleration;human behavior;biological;sensitivity;irrigation sensitivity humans fluids acceleration equations biomechanics;ear;inner ear;cupula;structure and function;kinematic sensitivity;mathematical motion analysis;synchrotron microtomography;humans;bony labyrinth;inner ear structure;postural balance;kinematic sensitivity inner ear structure inner ear function vestibular system vertebrates mathematical motion analysis endolymphatic fluid cupula bony labyrinth synchrotron microtomography membranous labyrinth;inner ear function;computer simulation;physiological models;models;anatomic;diagnostic radiography;physiological models biological fluid dynamics diagnostic radiography ear;vestibular system;membranous labyrinth	This abstract presents new results on the structure and function of vestibular part of the inner ear of vertebrates with special emphasis on human behavior. First we summarize a mathematical analysis of motion of the endolymphatic fluid, justifying known approximated formulas for the cupula functioning based on a set of anatomical parameters. Some of these parameters can be estimated from the bony labyrinth, some others cannot be. We present original data issued from synchrotron microtomography (Sμ CT) of five tetrapod species, allowing to compare bony and membranous labyrinths. We derive several simple and robust empirical laws connecting membranous parameters and bony parameters. Then, using published results on human labyrinths (Bradshaw et al. 2009), we deduce functional consequences for the human labyrinths. For instance we show that, contrarily to current belief, the kinematic sensitivity for yaw is larger than for pitch and roll.	approximation algorithm;bony labyrinth structure;computational fluid dynamics;ken's labyrinth;large;mathematics;membranous labyrinth structure;scientific publication;synchrotrons;tissue membrane;word lists by frequency;x-ray microtomography;yaws	R. David;Alain Berthoz;Daniel Bennequin	2011	2011 Annual International Conference of the IEEE Engineering in Medicine and Biology Society	10.1109/IEMBS.2011.6090571	computer simulation;acceleration;sensitivity;vestibular system;engineering;biomechanics;irrigation;proprioception;physiology;audiology;human behavior;physics;anatomy;surgery	Robotics	13.109467270245002	-71.17656030639357	28654
d9080d1a5fad4ec4d328e91c6968fe59dabbeb83	when technology meets technology: retrained ‘inception v3’ classifier for ngs based pathogen detection		Accurate characterization of pathogenic microbes that may be present in food or clinical samples is essential in the design of appropriate intervention strategies. Inherent genomic patterns (codon-biases and rate of evolution) do simplify the classification of microbes at most taxonomic levels (genus and above), but mostly blur classification at Species/Strain levels. Hence, their classification at these finer taxonomic levels requires high-resolution genomic-data that provide SNP (Single Nucleotide Polymorphism) level precision. Existing classification methods involve either targeted amplification of sero-specific genes (serotyping and MLST) or sequencing of the entire microbial genome, both of which require extra time and resources. We present a computational approach, which harnesses the power of the metagenomic NGS-data and object-detection abilities of Convolutional Neural Networks (CNN)(Inception V3), for precise classification of pathogens by converting genomic-data (NGS-reads) into images (nucleotide-by-color). A small scale retraining (<50 images/class) of ‘Inception V3’ resulted in a classifier with 100% and 96% validation and test accuracies, respectively, when classifying pathogens such as Campylobacter coli/jejuni and Escherichia coli (O157:H7 and Non O157-STECs). We aim to extend this protocol to the detection of several microbes (multiple-objects) in a metagenomic image (genomic image of an entire microbial community).	communications satellite;convolutional neural network;gaussian blur;genus (mathematics);image resolution;metagenomics;statistical classification	Rohita Sinha;Jennifer Clarke	2017	2017 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)	10.1109/BIBM.2017.8217942	genomics;computer science;convolutional neural network;bioinformatics;multilocus sequence typing;single-nucleotide polymorphism;taxonomic rank;genome;deep learning;metagenomics;artificial intelligence	Visualization	1.6678237198624175	-56.06129980994329	28668
8c3232c2b8a0878e964dabb891981ab8536ff371	molecular genetics information system (molgenis): alternatives in developing local experimental genomics databases	genetique;automatic code generation;microarray data;genomique;genomics;database system;base donnee;standards;genetica;data management;database;code generation;genomica;base dato;bioinformatique;maintenance cost;expression;genetics;swr j;data model;repository;large scale;molecular genetics;t1r receptors;software development;129p3 j;sweet taste;decision process;dba 2j;bioinformatica;information system;c57bl 6j;information system development;design for change;bioinformatics	MOTIVATION Genomic research laboratories need adequate infrastructure to support management of their data production and research workflow. But what makes infrastructure adequate? A lack of appropriate criteria makes any decision on buying or developing a system difficult. Here, we report on the decision process for the case of a molecular genetics group establishing a microarray laboratory.   RESULTS Five typical requirements for experimental genomics database systems were identified: (i) evolution ability to keep up with the fast developing genomics field; (ii) a suitable data model to deal with local diversity; (iii) suitable storage of data files in the system; (iv) easy exchange with other software; and (v) low maintenance costs. The computer scientists and the researchers of the local microarray laboratory considered alternative solutions for these five requirements and chose the following options: (i) use of automatic code generation; (ii) a customized data model based on standards; (iii) storage of datasets as black boxes instead of decomposing them in database tables; (iv) loosely linking to other programs for improved flexibility; and (v) a low-maintenance web-based user interface. Our team evaluated existing microarray databases and then decided to build a new system, Molecular Genetics Information System (MOLGENIS), implemented using code generation in a period of three months. This case can provide valuable insights and lessons to both software developers and a user community embarking on large-scale genomic projects.   AVAILABILITY http://www.molgenis.nl	automatic programming;black box;code generation (compiler);computer scientist;customize;data table;data model;emoticon;genomics;heparin, low-molecular-weight;information system;laboratory;microarray databases;molecular genetics (discipline);published database;requirement;software developer;table (database);user interface device component;virtual community;web application;standards characteristics	Morris A. Swertz;Engbert O. de Brock;Sacha A. F. T. van Hijum;Anne de Jong;Girbe Buist;Richard J. S. Baerends;Jan Kok;Oscar P. Kuipers;Ritsert C. Jansen	2004	Bioinformatics	10.1093/bioinformatics/bth206	molecular genetics;biology;microarray analysis techniques;genomics;data model;data management;computer science;bioinformatics;expression;software development;data mining;database;genetics;information system;code generation	SE	-3.645366382982362	-58.25356290075135	28669
1e7b94b2ecf59f3a48e1d99b8c9f102204cd7b4e	molecular fingerprints of hemoglobin on a nanofilm chip	chip;hemoglobin;molecular imprinting;nanofilm;surface plasmon resonance	Hemoglobin is an iron carrying protein in erythrocytes and also an essential element to transfer oxygen from the lungs to the tissues. Abnormalities in hemoglobin concentration are closely correlated with health status and many diseases, including thalassemia, anemia, leukemia, heart disease, and excessive loss of blood. Particularly in resource-constrained settings existing blood analyzers are not readily applicable due to the need for high-level instrumentation and skilled personnel, thereby inexpensive, easy-to-use, and reliable detection methods are needed. Herein, a molecular fingerprints of hemoglobin on a nanofilm chip was obtained for real-time, sensitive, and selective hemoglobin detection using a surface plasmon resonance system. Briefly, through the photopolymerization technique, a template (hemoglobin) was imprinted on a monomeric (acrylamide) nanofilm on-chip using a cross-linker (methylenebisacrylamide) and an initiator-activator pair (ammonium persulfate-tetramethylethylenediamine). The molecularly imprinted nanofilm on-chip was characterized by atomic force microscopy and ellipsometry, followed by benchmarking detection performance of hemoglobin concentrations from 0.0005 mg mL-1 to 1.0 mg mL-1. Theoretical calculations and real-time detection implied that the molecularly imprinted nanofilm on-chip was able to detect as little as 0.00035 mg mL-1 of hemoglobin. In addition, the experimental results of hemoglobin detection on the chip well-fitted with the Langmuir adsorption isotherm model with high correlation coefficient (0.99) and association and dissociation coefficients (39.1 mL mg-1 and 0.03 mg mL-1) suggesting a monolayer binding characteristic. Assessments on selectivity, reusability and storage stability indicated that the presented chip is an alternative approach to current hemoglobin-targeted assays in low-resource regions, as well as antibody-based detection procedures in the field. In the future, this molecularly imprinted nanofilm on-chip can easily be integrated with portable plasmonic detectors, improving its access to these regions, as well as it can be tailored to detect other proteins and biomarkers.	acrylamide;anemia;atomic-force microscopy;biological markers;body tissue;clinical use template;coefficient;contour line;detectors;fingerprint;heart diseases;high- and low-level;imprinting (psychology);instrumentation (attribute);krt17 wt allele;lung;microscopy, atomic force;oxygen;real-time clock;scsi initiator and target;seizures;selectivity (electronic);surface plasmon resonance;thalassemia;leukemia;tetramethylethylenediamine	Yeseren Saylan;Adil Denizli	2018		10.3390/s18093016	analytical chemistry;chip;engineering;hemoglobin	EDA	11.908058338742569	-64.58770626547741	28695
3e3aad52d54ec49295de1a595db8ca676905527e	generating photorealistic facial expressions in dyadic interactions		We propose an approach for generating photorealistic facial expressions for multiple virtual identities in dyadic interactions. To this end, we study human-human interactions to model one individual’s facial expressions in the reaction of the other. We introduce a two level optimization of generative adversarial networks, wherein the first stage generates one’s face shapes conditioned on facial action features derived from their dyadic interaction partner and the second stage synthesizes high quality face images from sketches. A ‘layer features’ L1 regularization is employed to enhance the generation quality and an identity-constraint is utilized to ensure appearance distinction between different identities. We demonstrate that our model is effective at generating visually compelling facial expressions. Moreover, we quantitatively showed that generated agent facial expressions reflect valid emotional reactions to behavior of the human partner.	display resolution;dyadic transformation;generative adversarial networks;interaction;manifold regularization;mathematical optimization;regular expression	Yuchi Huang;Saad M. Khan	2018			computer science;artificial intelligence;computer vision;facial expression	Vision	20.961960537340953	-55.544251741900744	28714
3a62c88c45ea35d33102ccb8622df0c2ad4b1f65	analytical results on the beauchemin model of lymphocyte migration	cell movement;animals;models biological;chemotaxis;computational biology bioinformatics;algorithms;lymphocytes;combinatorial libraries;computer appl in life sciences;microarrays;bioinformatics	The Beauchemin model is a simple particle-based description of stochastic lymphocyte migration in tissue, which has been successfully applied to studying immunological questions. In addition to being easy to implement, the model is also to a large extent mathematically tractable. This article provides a comprehensive overview of both existing and new analytical results on the Beauchemin model within a common mathematical framework. Specifically, we derive the motility coefficient, the mean square displacement, and the confinement ratio, and discuss four different methods for simulating biased migration of pre-defined speed. The results provide new insight into published studies and a reference point for future research based on this simple and popular lymphocyte migration model.	cobham's thesis;coefficient;displacement mapping;mathematics;mean squared error;psychologic displacement;scientific publication;simulation;childhood lymphocyte depletion hodgkin's lymphoma;lymphocyte migration	Johannes Textor;Mathieu Sinn;Rob J. De Boer	2013		10.1186/1471-2105-14-S6-S10	biology;dna microarray;computer science;bioinformatics;chemotaxis	AI	9.144291384335558	-65.85932995327694	28725
8b9356c824780bb6fc8c44cc26fed6369b06508d	development of a unique 3d interaction model of endogenous and synthetic peripheral benzodiazepine receptor ligands	3d interaction;diazepam binding inhibitor;predictive value;amino acid;receptor binding;ligand binding;electrostatic interaction;electronic properties;electrostatic potential;molecular dynamic;peripheral benzodiazepine receptor;peripheral type benzodiazepine receptor	Different classes of Peripheral-type Benzodiazepine Receptor (PBR) ligands were examined and common structural elements were detected and used to develop a rational binding model based on energetically allowed ligand conformations. Two lipophilic regions and one electrostatic interaction site are essential features for high affinity ligand binding, while a further lipophilic region plays an important modulator role. A comparative molecular field analysis, performed over 130 PBR ligands by means of the GRID/GOLPE methodology, led to a PLS model with both high fitting and predictive values (r2 = 0.898, Q2 = 0.761). The outcome from the 3D QSAR model and the GRID interaction fields computed on the putative endogenous PBR ligands DBI (Diazepam Binding Inhibitor) and TTN (Tetracontatetraneuropeptide) was used to identify the amino acids most probably involved in PBR binding. Three amino acids, bearing lipophilic side chains, were detected in DBI (Phe49, Leu47 and Met46) and in TTN (Phe33, Leu31 and Met30) as likely residues underlying receptor binding. Moreover, a qualitative comparison of the molecular electrostatic potentials of DBI, TTN and selected synthetic ligands indicated also similar electronic properties. Convergent results from the modeling studies of synthetic and endogenous ligands suggest a common binding mode to PBRs. This may help the rational design of new high affinity PBR ligands.		Nunzia Cinone;Hans-Dieter Höltje;Angelo Carotti	2000	Journal of computer-aided molecular design	10.1023/A:1008168127539	pharmacology;biochemistry;stereochemistry;molecular dynamics;chemistry;ligand	Comp.	9.861119303702743	-61.05166627921351	28746
47d9ad0158043d500beb97335893c7b70cea3621	permutation test for periodicity in short time series data	computational biology bioinformatics;algorithms;combinatorial libraries;computer appl in life sciences;microarrays;bioinformatics	BackgroundrnPeriodic processes, such as the circadian rhythm, are important factors modulating and coordinating transcription of genes governing key metabolic pathways. Theoretically, even small fluctuations in the orchestration of circadian gene expression patterns among different tissues may result in functional asynchrony at the organism level and may contribute to a wide range of pathologic disorders. Identification of circadian expression pattern in time series data is important, but equally challenging. Microarray technology allows estimation of relative expression of thousands of genes at each time point. However, this estimation often lacks precision and microarray experiments are prohibitively expensive, limiting the number of data points in a time series expression profile. The data produced in these experiments carries a high degree of stochastic variation, obscuring the periodic pattern and a limited number of replicates, typically covering not more than two complete periods of oscillation.	quasiperiodicity;resampling (statistics);time series	Andrey A. Ptitsyn;Sanjin Zvonic;Jeffrey M. Gimble	2007	BMC Bioinformatics	10.1186/1471-2105-8-395	computational biology;biology;dna microarray;computer science;bioinformatics	DB	5.407724554400939	-60.71895863196345	28804
1c62baf7b24db65c182c749a458fbf4109b078dc	midaw: a web tool for statistical analysis of microarray data	microarray data;software;data interpretation statistical;web pages;normal distribution;web interface;discriminant analysis;data analysis;microarray data analysis;internet;statistical analysis;algorithms;source code;missing values;user computer interface;gene expression profiling;oligonucleotide array sequence analysis	MIDAW (microarray data analysis web tool) is a web interface integrating a series of statistical algorithms that can be used for processing and interpretation of microarray data. MIDAW consists of two main sections: data normalization and data analysis. In the normalization phase the simultaneous processing of several experiments with background correction, global and local mean and variance normalization are carried out. The data analysis section allows graphical display of expression data for descriptive purposes, estimation of missing values, reduction of data dimension, discriminant analysis and identification of marker genes. The statistical results are organized in dynamic web pages and tables, where the transcript/gene probes contained in a specific microarray platform can be linked (according to user choice) to external databases (GenBank, Entrez Gene, UniGene). Tutorial files help the user throughout the statistical analysis to ensure that the forms are filled out correctly. MIDAW has been developed using Perl and PHP and it uses R/Bioconductor languages and routines. MIDAW is GPL licensed and freely accessible at http://muscle.cribi.unipd.it/midaw/. Perl and PHP source codes are available from the authors upon request.	algorithm;bioconductor;code;contain (action);data table;database normalization;description;dynamic web page;entrez;experiment;fill;genbank;il31ra gene;infographic;interface device component;linear discriminant analysis;microarray;missing data;muscle;normalize;php;page (document);perl;programming languages;sample variance;transcript;unigene (experimental system);user interface	Chiara Romualdi;Nicola Vitulo;Micky Del Favero;Gerolamo Lanfranchi	2005	Nucleic Acids Research	10.1093/nar/gki497	microarray analysis techniques;gene chip analysis;bioinformatics;linear discriminant analysis;microarray databases	Comp.	-2.9098396652826737	-57.560966537803914	28839
c5e706edfba7a4b6e55273bec8014dea0f01af4d	development and production of an oligonucleotide musclechip: use for validation of ambiguous ests	transcription genetic;software;expression profile;rna complementary;oligonucleotide microarray;databases genetic;computational biology bioinformatics;gene expression;nucleic acid hybridization;cluster analysis;oligonucleotides;gene library;genome human;human genome;algorithms;humans;bio 18 genetica;combinatorial libraries;computational biology;kinetics;computer appl in life sciences;oligonucleotide array sequence analysis;expressed sequence tags;muscles;microarrays;bioinformatics;perfect match	"""We describe the development, validation, and use of a highly redundant 120,000 oligonucleotide microarray (MuscleChip) containing 4,601 probe sets representing 1,150 known genes expressed in muscle and 2,075 EST clusters from a non-normalized subtracted muscle EST sequencing project (28,074 EST sequences). This set included 369 novel EST clusters showing no match to previously characterized proteins in any database. Each probe set was designed to contain 20–32 25 mer oligonucleotides (10–16 paired perfect match and mismatch probe pairs per gene), with each probe evaluated for hybridization kinetics (Tm) and similarity to other sequences. The 120,000 oligonucleotides were synthesized by photolithography and light-activated chemistry on each microarray. Hybridization of human muscle cRNAs to this MuscleChip (33 samples) showed a correlation of 0.6 between the number of ESTs sequenced in each cluster and hybridization intensity. Out of 369 novel EST clusters not showing any similarity to previously characterized proteins, we focused on 250 EST clusters that were represented by robust probe sets on the MuscleChip fulfilling all stringent rules. 102 (41%) were found to be consistently """"present"""" by analysis of hybridization to human muscle RNA, of which 40 ESTs (39%) could be genome anchored to potential transcription units in the human genome sequence. 19 ESTs of the 40 ESTs were furthermore computer-predicted as exons by one or more than three gene identification algorithms. Our analysis found 40 transcriptionally validated, genome-anchored novel EST clusters to be expressed in human muscle. As most of these ESTs were low copy clusters (duplex and triplex) in the original 28,000 EST project, the identification of these as significantly expressed is a robust validation of the transcript units that permits subsequent focus on the novel proteins encoded by these genes."""	dna microarray;database;duplex (telecommunications);exons;expressed sequence tags;gper protein, human;kinetics internet protocol;license;mer;mismatch probe;nucleic acid hybridization;oligonucleotides;rna;rule (guideline);smooth muscle (tissue);transcript;transcription (software);algorithm;no match	Rehannah H. A. Borup;Stefano Toppo;Yi-Wen Chen;Tanya M. Teslovich;Gerolamo Lanfranchi;Giorgio Valle;Eric P. Hoffman	2002		10.1186/1471-2105-3-33	biology;human genome;molecular biology;gene expression;dna microarray;bioinformatics;genomic library;cluster analysis;genetics;kinetics;oligonucleotide;expressed sequence tag;nucleic acid thermodynamics	Comp.	2.0888909364944	-57.0761182796422	28845
d2a68ed59ece2fdba93faea86b737757c8dc7dba	on the role of aggregation prone regions in protein evolution, stability, and enzymatic catalysis: insights from diverse analyses	evolution molecular;protein stability;models molecular;proteins;protein structure tertiary;sequence homology amino acid;protein folding;sequence analysis protein;databases protein	The various roles that aggregation prone regions (APRs) are capable of playing in proteins are investigated here via comprehensive analyses of multiple non-redundant datasets containing randomly generated amino acid sequences, monomeric proteins, intrinsically disordered proteins (IDPs) and catalytic residues. Results from this study indicate that the aggregation propensities of monomeric protein sequences have been minimized compared to random sequences with uniform and natural amino acid compositions, as observed by a lower average aggregation propensity and fewer APRs that are shorter in length and more often punctuated by gate-keeper residues. However, evidence for evolutionary selective pressure to disrupt these sequence regions among homologous proteins is inconsistent. APRs are less conserved than average sequence identity among closely related homologues (≥80% sequence identity with a parent) but APRs are more conserved than average sequence identity among homologues that have at least 50% sequence identity with a parent. Structural analyses of APRs indicate that APRs are three times more likely to contain ordered versus disordered residues and that APRs frequently contribute more towards stabilizing proteins than equal length segments from the same protein. Catalytic residues and APRs were also found to be in structural contact significantly more often than expected by random chance. Our findings suggest that proteins have evolved by optimizing their risk of aggregation for cellular environments by both minimizing aggregation prone regions and by conserving those that are important for folding and function. In many cases, these sequence optimizations are insufficient to develop recombinant proteins into commercial products. Rational design strategies aimed at improving protein solubility for biotechnological purposes should carefully evaluate the contributions made by candidate APRs, targeted for disruption, towards protein structure and activity.	amino acid sequence;amino acids;biological evolution;composition;denial-of-service attack;homology (biology);intrinsically disordered proteins;keeper (password manager);procedural generation;randomness;recombinant dna;recombinants;sequence alignment;social network aggregation	Patrick M. Buck;Sandeep Kumar;Satish Kumar Singh	2013		10.1371/journal.pcbi.1003291	protein folding;biology;biochemistry;bioinformatics;genetics	Comp.	4.961044825341658	-62.50669356108443	28849
44ac00f26078c2568ea170724b9584be9ff74a43	nutrichem: a systems chemical biology resource to explore the medicinal value of plant-based foods	disease;preventive medicine;phytochemicals;internet;plants edible;diet;humans;databases factual;phenotype;article	There is rising evidence of an inverse association between chronic diseases and diets characterized by rich fruit and vegetable consumption. Dietary components may act directly or indirectly on the human genome and modulate multiple processes involved in disease risk and disease progression. However, there is currently no exhaustive resource on the health benefits associated to specific dietary interventions, or a resource covering the broad molecular content of food. Here we present the first release of NutriChem, available at http://cbs.dtu.dk/services/NutriChem-1.0, a database generated by text mining of 21 million MEDLINE abstracts for information that links plant-based foods with their small molecule components and human disease phenotypes. NutriChem contains text-mined data for 18478 pairs of 1772 plant-based foods and 7898 phytochemicals, and 6242 pairs of 1066 plant-based foods and 751 diseases. In addition, it includes predicted associations for 548 phytochemicals and 252 diseases. To the best of our knowledge this database is the only resource linking the chemical space of plant-based foods with human disease phenotypes and provides a foundation for understanding mechanistically the consequences of eating behaviors on health.	abstract summary;behavior;chemical space;chronic disease;color gradient;eating disorders;epidemiologic studies;epidemiology;food;medline;mental association;mined;pharmacodynamics;phenotype;phytochemicals;progressive disease;small molecule;text mining;benefit	Kasper Jensen;Gianni Panagiotou;Irene Kouskoumvekaki	2015		10.1093/nar/gku724	biology;food science;the internet;preventive healthcare;biotechnology;bioinformatics;phenotype;phytochemical;genetics	Comp.	-0.1044889061942144	-62.030125685247086	28897
babadc6abcb805dc66ed79c7c7466a9245a8ea71	a database for g proteins and their interaction with gpcrs	software;receptors g protein coupled;selected works;pattern search;relational database;computational biology bioinformatics;g protein coupled receptor;g protein;relational model;gtp binding proteins;bepress;algorithms;combinatorial libraries;protein interaction mapping;software design;computer appl in life sciences;databases protein;microarrays;bioinformatics;literature search	G protein-coupled receptors (GPCRs) transduce signals from extracellular space into the cell, through their interaction with G proteins, which act as switches forming hetero-trimers composed of different subunits (α,β,γ). The α subunit of the G protein is responsible for the recognition of a given GPCR. Whereas specialised resources for GPCRs, and other groups of receptors, are already available, currently, there is no publicly available database focusing on G Proteins and containing information about their coupling specificity with their respective receptors. gpDB is a publicly accessible G proteins/GPCRs relational database. Including species homologs, the database contains detailed information for 418 G protein monomers (272 Gα, 87 Gβ and 59 Gγ) and 2782 GPCRs sequences belonging to families with known coupling to G proteins. The GPCRs and the G proteins are classified according to a hierarchy of different classes, families and sub-families, based on extensive literature searchs. The main innovation besides the classification of both G proteins and GPCRs is the relational model of the database, describing the known coupling specificity of the GPCRs to their respective α subunit of G proteins, a unique feature not available in any other database. There is full sequence information with cross-references to publicly available databases, references to the literature concerning the coupling specificity and the dimerization of GPCRs and the user may submit advanced queries for text search. Furthermore, we provide a pattern search tool, an interface for running BLAST against the database and interconnectivity with PRED-TMR, PRED-GPCR and TMRPres2D. The database will be very useful, for both experimentalists and bioinformaticians, for the study of G protein/GPCR interactions and for future development of predictive algorithms. It is available for academics, via a web browser at the URL: http://bioinformatics.biol.uoa.gr/gpDB	academia (organization);blast;bibliographic reference;bioinformatics;celf proteins;class;classification;cross-reference;extracellular space;fifty nine;homology (biology);interaction;laryngeal web;network switch;pattern search (optimization);prednisone;relational database;relational model;search engine;sensitivity and specificity;switch device component;triple modular redundancy;uniform resource locator;algorithm;monomer	Antigoni L. Elefsinioti;Pantelis G. Bagos;Ioannis C. Spyropoulos;Stavros J. Hamodrakas	2004	BMC Bioinformatics	10.1186/1471-2105-5-208	pattern search;biology;relational model;dna microarray;relational database;computer science;bioinformatics;g protein-coupled receptor;software design;heterotrimeric g protein;g protein;gtpase-activating protein;data mining;rhodopsin-like receptors;gtp-binding protein regulators	DB	-0.17073321935849442	-60.528685897735464	28922
426a4c0b95d7ca4612706ac7d968a7214b6e4843	a common goodness-of-fit framework for neural population models using marked point process time-rescaling	goodness-of-fit;ks plots;neural modeling;neural population activity;spike trains;time-rescaling	A critical component of any statistical modeling procedure is the ability to assess the goodness-of-fit between a model and observed data. For spike train models of individual neurons, many goodness-of-fit measures rely on the time-rescaling theorem and assess model quality using rescaled spike times. Recently, there has been increasing interest in statistical models that describe the simultaneous spiking activity of neuron populations, either in a single brain region or across brain regions. Classically, such models have used spike sorted data to describe relationships between the identified neurons, but more recently clusterless modeling methods have been used to describe population activity using a single model. Here we develop a generalization of the time-rescaling theorem that enables comprehensive goodness-of-fit analysis for either of these classes of population models. We use the theory of marked point processes to model population spiking activity, and show that under the correct model, each spike can be rescaled individually to generate a uniformly distributed set of events in time and the space of spike marks. After rescaling, multiple well-established goodness-of-fit procedures and statistical tests are available. We demonstrate the application of these methods both to simulated data and real population spiking in rat hippocampus. We have made the MATLAB and Python code used for the analyses in this paper publicly available through our Github repository at https://github.com/Eden-Kramer-Lab/popTRT.	class;generalization (psychology);matlab;neural ensemble;neuron;neurons;point process;population model;python;statistical test;statistical model;spike train	Long Tao;Isis Henriques de Almeida Bastos;Kensuke Arai;Uri T. Eden	2018		10.1007/s10827-018-0698-4	machine learning;goodness of fit;population model;artificial intelligence;point process;statistical hypothesis testing;mathematics;spike train;statistical model;population;python (programming language)	ML	22.288868954794577	-74.21994825740187	28967
0d805949845db7de6e7c278b5d742fa984b3558e	distributed synchrony of spiking neurons in a hebbian cell assembly	learning curve;time delay;spiking neurons;neuronal activity	We investigate the behavior of a Hebbian cell assembly of spiking neurons formed via a temporal synaptic learning curve. This learning function is based on recent experimental findings . It includes potentiation for short time delays between preand post-synaptic neuronal spiking, and depression for spiking events occuring in the reverse order. The coupling between the dynamics of the synaptic learning and of the neuronal activation leads to interesting results. We find that the cell assembly can fire asynchronously, but may also function in complete synchrony, or in distributed synchrony. The latter implies spontaneous division of the Hebbian cell assembly into groups of cells that fire in a cyclic manner. We invetigate the behavior of distributed synchrony both by simulations and by analytic calculations of the resulting synaptic distributions.	hebbian theory;simulation;spontaneous order;synaptic package manager	David Horn;Nir Levy;Isaac Meilijson;Eytan Ruppin	1999			computer science;machine learning;learning curve;premovement neuronal activity	ML	17.94466593477369	-71.10895552340207	28984
465178c0bb85ef03299ff2a0a12e065ce0767333	exploitation of spr to investigate the importance of glycan chains in the interaction between lactoferrin and bacteria	bacterial binding;glycosylation;lactation;lactoferrin;surface plasmon resonance	Bovine lactoferrin (LF) has been shown to prevent adhesion to and invasion of mammalian cell lines by pathogenic bacteria, with evidence for direct bacterial binding by the milk glycoprotein. However, the glycosylation pattern of LF changes over the lactation cycle. In this study, we aim to investigate the effect that this variation has on the milk glycoprotein's ability to interact with pathogens. Surface plasmon resonance technology was employed to compare the binding of LF from colostrum (early lactation) and mature milk (late lactation) to a panel of pathogenic bacteria (Staphylococcus aureus, Escherichia coli, Cronobacter sakazakii, Streptococcus pneumoniae, Pseudomonas aeruginosa, Listeria monocytogenes and Salmonella typhimurium). Novel interactions with LF were identified for C. sakazakii, S. pneumoniae and P. aeruginosa with the highest binding ability observed for mature milk LF in all cases, with the exception of S. typhimurium. The difference in bacterial binding observed may be as a result of the varying glycosylation profiles. This work demonstrates the potential of LF as a functional food ingredient to prevent bacterial infection.	bacterial infections;bovine metabolome database;cellular phone;colostrum;cultured cell line;interaction;ltf protein, human;lactation;lactoferrin;listeria monocytogenes;mammals;pneumonia;pseudomonas aeruginosa ab:acnc:pt:ser:qn;salmonella typhimurium;surface plasmon resonance	Noelle O'Riordan;Michelle Kilcoyne;Lokesh Joshi;Rita M. Hickey	2017		10.3390/s17071515	cronobacter sakazakii;pathogenic bacteria;colostrum;bacteria;listeria monocytogenes;microbiology;escherichia coli;biology;glycosylation;biochemistry;lactoferrin	SE	6.01870220850382	-62.60467487430937	28994
83ea640f6e0b24815ffcfcd940c29b653a89c1ac	watching my mind unfold versus yours: an fmri study using a novel camera technology to examine neural differences in self-projection of self versus other perspectives	psychomotor performance;female;bf0309 consciousness cognition including learning attention comprehension memory imagination genius intelligence thought and thinking psycholinguistics mental fatigue;bf0180 experimental psychology;male;photography;image processing computer assisted;prefrontal cortex;functional connectivity;prospective studies;adult;projection;magnetic resonance imaging;medial temporal lobe;medial prefrontal cortex;humans;photic stimulation;young adult;rc0321 neuroscience biological psychiatry neuropsychiatry;self concept;psychophysiology;space perception;memory	Self-projection, the capacity to re-experience the personal past and to mentally infer another person's perspective, has been linked to medial prefrontal cortex (mPFC). In particular, ventral mPFC is associated with inferences about one's own self, whereas dorsal mPFC is associated with inferences about another individual. In the present fMRI study, we examined self-projection using a novel camera technology, which employs a sensor and timer to automatically take hundreds of photographs when worn, in order to create dynamic visuospatial cues taken from a first-person perspective. This allowed us to ask participants to self-project into the personal past or into the life of another person. We predicted that self-projection to the personal past would elicit greater activity in ventral mPFC, whereas self-projection of another perspective would rely on dorsal mPFC. There were three main findings supporting this prediction. First, we found that self-projection to the personal past recruited greater ventral mPFC, whereas observing another person's perspective recruited dorsal mPFC. Second, activity in ventral versus dorsal mPFC was sensitive to parametric modulation on each trial by the ability to relive the personal past or to understand another's perspective, respectively. Third, task-related functional connectivity analysis revealed that ventral mPFC contributed to the medial temporal lobe network linked to memory processes, whereas dorsal mPFC contributed to the fronto-parietal network linked to controlled processes. In sum, these results suggest that ventral–dorsal subregions of the anterior midline are functionally dissociable and may differentially contribute to self-projection of self versus other.	acoustic lobing;cerebral cortex;first-person (video games);inference;medial graph;modulation;prefrontal cortex;resting state fmri;spatial–temporal reasoning;temporal lobe;timer;photograph	Peggy St. Jacques;Martin A. Conway;Matthew W. Lowder;Roberto Cabeza	2011	Journal of Cognitive Neuroscience	10.1162/jocn.2010.21518	psychology;psychophysiology;cognitive psychology;prospective cohort study;neuroscience;developmental psychology;young adult;projection;photography;magnetic resonance imaging;memory;social psychology;cognitive science	HCI	17.689769821257926	-77.0359418097076	28995
079c268a8a2b90eedae1fbeae9280cb7ccb2092e	a robust method for estimating gene expression states using affymetrix microarray probe level data	microarray data;neuroblastoma;databases genetic;computational biology bioinformatics;gene expression;microarray data analysis;genome human;human genome;robust method;algorithms;humans;combinatorial libraries;high throughput;gene function;computer appl in life sciences;gene expression profiling;oligonucleotide array sequence analysis;quantitative rt pcr;qualitative evaluation;candidate gene;microarrays;bioinformatics	Microarray technology is a high-throughput method for measuring the expression levels of thousand of genes simultaneously. The observed intensities combine a non-specific binding, which is a major disadvantage with microarray data. The Affymetrix GeneChip assigned a mismatch (MM) probe with the intention of measuring non-specific binding, but various opinions exist regarding usefulness of MM measures. It should be noted that not all observed intensities are associated with expressed genes and many of those are associated with unexpressed genes, of which measured values express mere noise due to non-specific binding, cross-hybridization, or stray signals. The implicit assumption that all genes are expressed leads to poor performance of microarray data analyses. We assume two functional states of a gene - expressed or unexpressed - and propose a robust method to estimate gene expression states using an order relationship between PM and MM measures. An indicator 'probability of a gene being expressed' was obtained using the number of probe pairs within a probe set where the PM measure exceeds the MM measure. We examined the validity of the proposed indicator using Human Genome U95 data sets provided by Affymetrix. The usefulness of 'probability of a gene being expressed' is illustrated through an exploration of candidate genes involved in neuroblastoma prognosis. We identified the candidate genes for which expression states differed (un-expressed or expressed) when compared between two outcomes. The validity of this result was subsequently confirmed by quantitative RT-PCR. The proposed qualitative evaluation, 'probability of a gene being expressed', is a useful indicator for improving microarray data analysis. It is useful to reduce the number of false discoveries. Expression states - expressed or unexpressed - correspond to the most fundamental gene function 'On' and 'Off', which can lead to biologically meaningful results.	affymetrix genechip operating software;candidate disease gene;cryofibrinogen:prthr:pt:plas:ord:3d rt incubation;dna microarray;estimated;functional genomics;gene expression profiling;genes, vif;high-throughput computing;nucleic acid hybridization;personnameuse - assigned;protein microarray analysis;throughput;windows rt	Megu Ohtaki;Keiko Otani;Keiko Hiyama;Naomi Kamei;Kenichi Satoh;Eiso Hiyama	2009		10.1186/1471-2105-11-183	biology;microarray analysis techniques;molecular biology;bioinformatics;genetics	Comp.	4.887706695903592	-54.287330938779824	29005
53ee9429b85c44e649facf1f406980c0911e992f	do little interactions get lost in dark random forests?	computational biology bioinformatics;algorithms;combinatorial libraries;computer appl in life sciences;microarrays;bioinformatics	Random forests have often been claimed to uncover interaction effects. However, if and how interaction effects can be differentiated from marginal effects remains unclear. In extensive simulation studies, we investigate whether random forest variable importance measures capture or detect gene-gene interactions. With capturing interactions, we define the ability to identify a variable that acts through an interaction with another one, while detection is the ability to identify an interaction effect as such. Of the single importance measures, the Gini importance captured interaction effects in most of the simulated scenarios, however, they were masked by marginal effects in other variables. With the permutation importance, the proportion of captured interactions was lower in all cases. Pairwise importance measures performed about equal, with a slight advantage for the joint variable importance method. However, the overall fraction of detected interactions was low. In almost all scenarios the detection fraction in a model with only marginal effects was larger than in a model with an interaction effect only. Random forests are generally capable of capturing gene-gene interactions, but current variable importance measures are unable to detect them as interactions. In most of the cases, interactions are masked by marginal effects and interactions cannot be differentiated from marginal effects. Consequently, caution is warranted when claiming that random forests uncover interactions.	blinded;forests;interaction;large;marginal model;random forest;simulation	Marvin N. Wright;Andreas Ziegler;Inke R. König	2016		10.1186/s12859-016-0995-8	biology;dna microarray;computer science;bioinformatics;data science	ML	5.431589008098196	-53.67936639862834	29069
6aaa84584b95db0f1c757a160e5a5471b0680efe	scan: a scalable model of attentional selection	atencion;maastricht university;translation invariant;vision ordenador;translation invariance;statistical mechanics;neural networks;building block;routing;vision translation invariance;brain inspired modelling;natural images;attention;digital archive;computer vision;scalable architectures;machine learning;open access;network model;scalable architecture;adaptive resonance theory networks;pattern recognition;pattern routing;simulation study;vision ordinateur;encaminamiento;reconnaissance forme;neural network model;reseau neuronal;reconocimiento patron;publication;scientific;vision;covert attention;red neuronal;institutional repository;adaptive resonance theory;acheminement;neural network	This paper describes the SCAN (Signal Channelling Attentional Network) model, a scalable neural network model for attentional scanning. The building block of SCAN is a gating lattice, a sparsely-connected neural network defined as a special case of the Ising lattice from statistical mechanics. The process of spatial selection through covert attention is interpreted as a biological solution to the problem of translation-invariant pattern processing. In SCAN, a sequence of pattern translations combines active selection with translation-invariant processing. Selected patterns are channelled through a gating network, formed by a hierarchical fractal structure of gating lattices, and mapped onto an output window. We show how the incorporation of an expectation-generating classifier network (e.g. Carpenter and Grossberg's ART network) into SCAN allows attentional selection to be driven by expectation. Simulation studies show the SCAN model to be capable of attending and identifying object patterns that are part of a realistically sized natural image. Copyright 1997 Elsevier Science Ltd.	artificial neural network;copyright;fractal;genetic selection;ising model;language translations;network model;neural network simulation;scalability;statistical mechanics	Eric O. Postma;H. Jaap van den Herik;Patrick T. W. Hudson	1997	Neural networks : the official journal of the International Neural Network Society	10.1016/S0893-6080(97)00034-8	vision;computer vision;routing;attention;computer science;artificial intelligence;adaptive resonance theory;network model;machine learning;publication;artificial neural network	ML	21.889549379986693	-68.4612577185894	29087
11cd73ab0cc1060fc27a05729e521ae820e50795	spatio-temporal brain activity related to rotation method during a mental rotation task of three-dimensional objects: an meg study	mental simulation;rotation methods;three dimensional;magnetoencephalography;superior parietal lobule;brain activation;mental rotation;environmental monitoring;motor control	During mental rotation tasks, subjects perform mental simulation to solve tasks. However, detailed neural mechanisms underlying mental rotation of three-dimensional (3D) objects, particularly, whether higher motor areas related to mental simulation are activated, remain unknown. We hypothesized that environmental monitoring-a process based on environmental information and is included in motor execution-is as a key factor affecting the utilization of higher motor areas. Therefore, using magnetoencephalography (MEG), we measured spatio-temporal brain activities during two types (two-dimensional (2D) and 3D rotation tasks) of mental rotation of 3D objects. Only the 3D rotation tasks required subjects to mentally rotate objects in a depth plane with visualization of hidden parts of the visual stimuli by acquiring and retrieving 3D information. In cases showing significant differences in the averaged activities at 100-ms intervals between the two rotations, the activities were located in the right dorsal premotor (PMd) at approximately 500 ms. In these cases, averaged activities during 3D rotation were greater than those during 2D rotation, implying that the right PMd activities are related to environmental monitoring. During 3D rotation, higher activities were observed from 200 to 300 ms in the left PMd and from 400 to 700 ms in the right PMd. It is considered that the left PMd is related to primary motor control, whereas the right PMd plays a supplementary role during mental simulation. Further, during 3D rotation, late higher activities related to mental simulation are observed in the right superior parietal lobule (SPL), which is connected to PMd.	electroencephalography;imagery;magnetoencephalography;motor cortex;pmd;pelizaeus-merzbacher disease;physical object;simulation;structure of superior parietal lobule	Hiroaki Kawamichi;Yoshiaki Kikuchi;Shoogo Ueno	2007	NeuroImage	10.1016/j.neuroimage.2007.06.001	psychology;motor control;three-dimensional space;computer vision;neuroscience;developmental psychology;mental rotation;environmental monitoring;communication;magnetoencephalography	HCI	17.48143154374917	-77.11851990089689	29137
6b9ffa83ae09e6816137b5ab980d5b9e2cc372c9	similarity-based search of model organism, disease and drug effect phenotypes	biological patents;biomedical journals;text mining;europe pubmed central;citation search;data mining and knowledge discovery;citation networks;computational biology bioinformatics;research articles;abstracts;open access;life sciences;clinical guidelines;algorithms;full text;combinatorial libraries;computer appl in life sciences;rest apis;orcids;europe pmc;biomedical research;bioinformatics;literature search	BACKGROUND Semantic similarity measures over phenotype ontologies have been demonstrated to provide a powerful approach for the analysis of model organism phenotypes, the discovery of animal models of human disease, novel pathways, gene functions, druggable therapeutic targets, and determination of pathogenicity.   RESULTS We have developed PhenomeNET 2, a system that enables similarity-based searches over a large repository of phenotypes in real-time. It can be used to identify strains of model organisms that are phenotypically similar to human patients, diseases that are phenotypically similar to model organism phenotypes, or drug effect profiles that are similar to the phenotypes observed in a patient or model organism. PhenomeNET 2 is available at http://aber-owl.net/phenomenet.   CONCLUSIONS Phenotype-similarity searches can provide a powerful tool for the discovery and investigation of molecular mechanisms underlying an observed phenotypic manifestation. PhenomeNET 2 facilitates user-defined similarity searches and allows researchers to analyze their data within a large repository of human, mouse and rat phenotypes.	animal model;ephrin type-b receptor 1, human;ontology (information science);pathogenicity;patients;phenotype;real-time locating system;semantic similarity	Robert Hoehndorf;Michael Gruenberger;Georgios V. Gkoutos;Paul N. Schofield	2015		10.1186/s13326-015-0001-9	text mining;medical research;computer science;bioinformatics;data science;data mining;algorithm	ML	-0.226231766143778	-62.12412359940986	29178
de8c378d39113efae41e18f0050ba2fbba85951f	fully automated molecular mechanics based induced fit protein-ligand docking method	molecular mechanics;induced fit	We describe a method for docking a ligand into a protein receptor while allowing flexibility of the protein binding site. The method employs a multistep procedure that begins with the generation of protein and ligand conformations. An initial placement of the ligand is then performed by computing binding site hotspots. This initial placement is followed by a protein side-chain refinement stage that models protein flexibility. The final step of the process is an energy minimization of the ligand pose in the presence of the rigid receptor. Thus the algorithm models flexibility of the protein at two stages, before and after ligand placement. We validated this method by performing docking and cross docking studies of eight protein systems for which crystal structures were available for at least two bound ligands. The resulting rmsd values of the 21 docked protein-ligand complexes showed values of 2 A or less for all but one of the systems examined. The method has two critical benefits for high throughput virtual screening studies. First, no user intervention is required in the docking once the initial binding site selection has been made in the protein. Second, the initial protein conformation generation needs to be performed only once for a given binding region. Also, the method may be customized in various ways depending on the particular scenario in which dockings are being performed. Each of the individual steps of the method is fully independent making it straightforward to explore different variants of the high level workflow to further improve accuracy and performance.		Jurgen Koska;Velin Z. Spassov;Allister J. Maynard;Lisa Yan;Nic Austin;Paul K. Flook;C. M. Venkatachalam	2008	Journal of chemical information and modeling	10.1021/ci800081s	crystallography;biochemistry;simulation;chemistry;molecular mechanics;searching the conformational space for docking;bioinformatics;computational chemistry;enzyme catalysis	Comp.	11.489470912850159	-60.20316987909915	29182
61312caf3e8ebb7853b9d419cf4034ed5d1d525c	characterization of pathogenic germline mutations in human protein kinases	germ line mutation;nuclear receptor subfamily 4;protein function;molecular;somatic mutation;protein family;nuclear receptor subfamily 4 group a member 2;amino acid;group a;signal transduction;tertiary;amino acid composition;journal article;cell cycle regulation;computational biology bioinformatics;protein structure;models molecular;protein structure tertiary;polymorphism;point mutation;protein binding;algorithms;humans;neoplasms;combinatorial libraries;protein kinases;computer appl in life sciences;protein kinase;models;member 2;structural properties;microarrays;bioinformatics	Protein Kinases are a superfamily of proteins involved in crucial cellular processes such as cell cycle regulation and signal transduction. Accordingly, they play an important role in cancer biology. To contribute to the study of the relation between kinases and disease we compared pathogenic mutations to neutral mutations as an extension to our previous analysis of cancer somatic mutations. First, we analyzed native and mutant proteins in terms of amino acid composition. Secondly, mutations were characterized according to their potential structural effects and finally, we assessed the location of the different classes of polymorphisms with respect to kinase-relevant positions in terms of subfamily specificity, conservation, accessibility and functional sites. Pathogenic Protein Kinase mutations perturb essential aspects of protein function, including disruption of substrate binding and/or effector recognition at family-specific positions. Interestingly these mutations in Protein Kinases display a tendency to avoid structurally relevant positions, what represents a significant difference with respect to the average distribution of pathogenic mutations in other protein families. Disease-associated mutations display sound differences with respect to neutral mutations: several amino acids are specific of each mutation type, different structural properties characterize each class and the distribution of pathogenic mutations within the consensus structure of the Protein Kinase domain is substantially different to that for non-pathogenic mutations. This preferential distribution confirms previous observations about the functional and structural distribution of the controversial cancer driver and passenger somatic mutations and their use as a proxy for the study of the involvement of somatic mutations in cancer development.	accessibility;amino acids;cell cycle control;class;denial-of-service attack;diploid cell;genetic polymorphism;neoplasms;perturbation theory;point accepted mutation;protein family;superfamily;sensitivity and specificity;signal transduction;somatic mutation;transduction (machine learning)	José M. G. Izarzugaza;Lisa E. M. Hopcroft;Anja Baresic;Christine A. Orengo;Andrew C. R. Martin;Alfonso Valencia	2011		10.1186/1471-2105-12-S4-S1	biology;molecular biology;germline mutation;bioinformatics;silent mutation;genetics	Comp.	8.278503006906387	-62.04483662744504	29215
3665065d6ac79dcdddd1d48882d642eb7426eb59	unseen fearful faces influence face encoding: evidence from erps in hemianopic patients		Visual threat-related signals are not only processed via a cortical geniculo-striatal pathway to the amygdala but also via a subcortical colliculo-pulvinar-amygdala pathway, which presumably mediates implicit processing of fearful stimuli. Indeed, hemianopic patients with unilateral damage to the geniculo-striatal pathway have been shown to respond faster to seen happy faces in their intact visual field when unseen fearful faces were concurrently presented in their blind field [Bertini, C., Cecere, R., & Làdavas, E. I am blind, but I “see” fear. Cortex, 49, 985–993, 2013]. This behavioral facilitation in the presence of unseen fear might reflect enhanced processing of consciously perceived faces because of early activation of the subcortical pathway for implicit fear perception, which possibly leads to a modulation of cortical activity. To test this hypothesis, we examined ERPs elicited by fearful and happy faces presented to the intact visual field of right and left hemianopic patients, whereas fearful, happy, or neutral faces were concurrently presented in their blind field. Results showed that the amplitude of the N170 elicited by seen happy faces was selectively increased when an unseen fearful face was concurrently presented in the blind field of right hemianopic patients. These results suggest that when the geniculo-striate visual pathway is lesioned, the rapid and implicit processing of threat signals can enhance facial encoding. Notably, the N170 modulation was only observed in left-lesioned patients, favoring the hypothesis that implicit subcortical processing of fearful signals can influence face encoding only when the right hemisphere is intact.	amygdaloid structure;consciousness;delta modulation;face;fear (mental process);forty nine;gene regulatory network;patients;pulvinar structure;visual pathways;facilitation	Roberto Cecere;Caterina Bertini;Martin E. Maier;Elisabetta Làdavas	2014	Journal of Cognitive Neuroscience	10.1162/jocn_a_00671	psychology;cognitive psychology;communication;social psychology	ML	15.7873346325996	-76.94855879463545	29226
4a8cb4a1aba42c3b706d03dad745a705ec5899d0	on evaluating molecular-docking methods for pose prediction and enrichment factors	molecular docking;enrichment factor	Four of the most well-known, commercially available docking programs, FlexX, GOLD, GLIDE, and ICM, have been examined for their ligand-docking and virtual-screening capabilities. The relative performance of the programs in reproducing the native ligand conformation from starting SMILES strings for 164 high-resolution protein-ligand complexes is presented and compared. Applying only the native scoring functions, the latest versions of these four docking programs were also used to conduct virtual screening for 12 protein targets of therapeutic interest, involving both publicly available structures and AstraZeneca in-house structures. The capability of the four programs to correctly rank-order target-specific active compounds over alternative binders and nonbinders (decoys plus randomly selected compounds) and thereby enrich a small subset of a screening library is compared. Enrichments from the virtual-screening experiments are contrasted with those obtained with alternative 3D shape-matching and 2D similarity database-search methods.	boat dock;docking (molecular);experiment;extracellular matrix;gene ontology term enrichment;image resolution;iterated conditional modes;ligands;randomness;score;scoring functions for docking;simplified molecular input line entry specification;simplified molecular-input line-entry system;subgroup;version;virtual screening;gold	Hongming Chen;Paul D. Lyne;Fabrizio Giordanetto;Timothy Lovell;Jin Li	2006	Journal of chemical information and modeling	10.1021/ci0503255	simulation;chemistry;docking;bioinformatics;computational chemistry	Comp.	11.160721066961313	-59.67033439939486	29287
1363720bb4c2eb1abb054c486aa159a36e99653d	an experimental evaluation of inversion-and transposition-based genomic distances through simulations	i. introduction;bioinformatics;genomics;phylogeny;comparative genomics;genetics;computational modeling;cancer;mathematics	Rearrangements of genes and other syntenic blocks have become a topic of intensive study by phylogenists, comparative genomicists, and computational biologists: they are a feature of many cancers, must be taken into account to align highly divergent sequences, and constitute a phylogenetic marker of great interest. The mathematics of rearrangements is far more complex than for indels and mutations in sequences. Inversions have been well characterized through 20 years of work, but transpositions still await comparable results. We can compute inversion and DCJ (a combination of inversions and block exchanges) distances, and bounds on the transposition distance. The first has been extensively used in comparative genomics and phylogenetics, the second is quite new, and the third has not seen significant use to date. We present here a detailed experimental study of these three distance measures within the context of genome comparison (pairwise distances) and phylogenetic reconstruction. We used data generated through simulated evolution along various trees, using various evolutionary rates and various mixes of inversions and transpositions. Our main finding is that inversion and DCJ measures return very similar results even on data generated using only transpositions, while the measure based on Hartman's bound is often too loose to provide comparable accuracy in genomic comparisons or phylogenetic reconstruction	align (company);computer simulation;experiment;inversion (discrete mathematics);phylogenetics;synteny	Moulik Kothari;Bernard M. E. Moret	2007	2007 IEEE Symposium on Computational Intelligence and Bioinformatics and Computational Biology		biology;genomics;bioinformatics;comparative genomics;computational model;genetics;cancer	Comp.	-0.30157385788277075	-52.33562184048543	29318
2e987453f7adb85f03c854e61e1724c8650f50ef	chemnet: a transferable and generalizable deep neural network for small-molecule property prediction		With access to large datasets, deep neural networks (DNN) have achieved humanlevel accuracy in image and speech recognition tasks. However, in chemistry, availability of large standardized and labelled datasets is scarce, and many chemical properties of research interest, chemical data is inherently small and fragmented. In this work, we explore transfer learning techniques in conjunction with the existing Chemception CNN model, to create a transferable and generalizable deep neural network for small-molecule property prediction. Our latest model, ChemNet learns in a semi-supervised manner from inexpensive labels computed from the ChEMBL database. When fine-tuned to the Tox21, HIV and FreeSolv dataset, which are 3 separate chemical properties that ChemNet was not originally trained on, we demonstrate that ChemNet exceeds the performance of existing Chemception models and other contemporary DNN models. Furthermore, as ChemNet has been pre-trained on a large diverse chemical database, it can be used as a general-purpose plug-and-play deep neural network for the prediction of novel small-molecule chemical properties.	algorithm;artificial neural network;chembl;chemical database;computer vision;deep learning;experiment;fingerprint;general-purpose modeling;molecular descriptor;plug and play;semiconductor industry;software deployment;speech recognition	Garrett B. Goh;Charles Siegel;Abhinav Vishnu;Nathan O. Hodas	2017	CoRR		artificial neural network;machine learning;chembl;chemical database;artificial intelligence	ML	17.01931481087402	-52.265533912694586	29423
0168e2e522088ff227189b0190233555f36b1f9f	the preferred nucleotide contexts of the aid/apobec cytidine deaminases have differential effects when mutating retrotransposon and virus sequences compared to host genes		"""The AID / APOBEC genes are a family of cytidine deaminases that have evolved in vertebrates, and particularly mammals, to mutate RNA and DNA at distinct preferred nucleotide contexts (or """"hotspots"""") on foreign genomes such as viruses and retrotransposons. These enzymes play a pivotal role in intrinsic immunity defense mechanisms, often deleteriously mutating invading retroviruses or retrotransposons and, in the case of AID, changing antibody sequences to drive affinity maturation. We investigate the strength of various hotspots on their known biological targets by evaluating the potential impact of mutations on the DNA coding sequences of these targets, and compare these results to hypothetical hotspots that did not evolve. We find that the existing AID / APOBEC hotspots have a large impact on retrotransposons and non-mammalian viruses while having a much smaller effect on vital mammalian genes, suggesting co-evolution with AID / APOBECs may have had an impact on the genomes of the viruses we analyzed. We determine that GC content appears to be a significant, but not sole, factor in resistance to deaminase activity. We discuss possible mechanisms AID and APOBEC viral targets have adopted to escape the impacts of deamination activity, including changing the GC content of the genome."""	biologic development;citicoline;cytidine;deaminase;deamination;defense mechanisms;entity name part qualifier - adopted;genome;hotspot (wi-fi);mammals;mutate;mutation;nucleotides;processor affinity;retrotransposons;retroviridae;small;vertebrates;apolipoprotein b mrna editing enzyme complex	Jeffrey Chen;Thomas MacCarthy	2017		10.1371/journal.pcbi.1005471	biology;molecular biology;virology;genetics	Comp.	4.781902057782225	-62.22049229651445	29452
cf2e284825243a008eb0ab8455a5f85d84a99673	an algorithm for hierarchical classification of genes of prokaryotic genomes	hierarchical structure;context information;sequence similarity;gene cluster;functional equivalence;hierarchical classification;point of view	We present in this paper our hierarchical classification of genes for prokaryotic genomes from a methodological point of view. Our classification scheme is unique in that (1) the functional equivalence relationships among genes are assessed by using both sequence similarity and genomic context information, (2) genes are grouped into clusters of multiple resolution levels based on their equivalence relationships among each other, and (3) gene clusters, which are either parallel-to or inside-of one another, naturally form a hierarchical structure. This classification scheme has been applied for the genes of 224 complete prokaryotic genomes (release as of March, 2005). The classification results are available at http://csbl.bmb.uga.edu/HCG, and are validated through comparisons with the taxonomy of these 224 genomes, and with two existing gene classification schemes, Clusters of Orthologous Groups of proteins (COG) and Pfam, respectively.	algorithm	Hongwei Wu;Fenglou Mao;Victor Olman;Ying Xu	2007		10.1007/978-3-540-72031-7_50	biology;gene cluster;bioinformatics;pattern recognition;data mining;genetics	ML	2.455083629113721	-59.55512737898688	29586
01a56da09c06fd85b8ce144fe73d11e1278263af	analysis of sequence conservation at nucleotide resolution	evolution molecular;evolutionary history;human genomics;selective constraint;nucleotides;comparative genomics;base pair mismatch;chromosome mapping;allele frequency;sequence analysis dna;spectrum;journal article;conserved sequence;homo human;sequence homology nucleic acid;genome human;human genome;polymorphism;functional genomics;evolutionary conservation;sequence analysis;humans;molecular sequence data;sequence alignment;dna sequence analysis;human genetics;nucleotide sequencing;base sequence;computational biology;multiple alignment calculation;mammals;base pair;phylogenetic analysis	"""One of the major goals of comparative genomics is to understand the evolutionary history of each nucleotide in the human genome sequence, and the degree to which it is under selective pressure. Ascertainment of selective constraint at nucleotide resolution is particularly important for predicting the functional significance of human genetic variation and for analyzing the sequence substructure of cis-regulatory sequences and other functional elements. Current methods for analysis of sequence conservation are focused on delineation of conserved regions comprising tens or even hundreds of consecutive nucleotides. We therefore developed a novel computational approach designed specifically for scoring evolutionary conservation at individual base-pair resolution. Our approach estimates the rate at which each nucleotide position is evolving, computes the probability of neutrality given this rate estimate, and summarizes the result in a Sequence CONservation Evaluation (SCONE) score. We computed SCONE scores in a continuous fashion across 1% of the human genome for which high-quality sequence information from up to 23 genomes are available. We show that SCONE scores are clearly correlated with the allele frequency of human polymorphisms in both coding and noncoding regions. We find that the majority of noncoding conserved nucleotides lie outside of longer conserved elements predicted by other conservation analyses, and are experiencing ongoing selection in modern humans as evident from the allele frequency spectrum of human polymorphism. We also applied SCONE to analyze the distribution of conserved nucleotides within functional regions. These regions are markedly enriched in individually conserved positions and short (<15 bp) conserved """"chunks."""" Our results collectively suggest that the majority of functionally important noncoding conserved positions are highly fragmented and reside outside of canonically defined long conserved noncoding sequences. A small subset of these fragmented positions may be identified with high confidence."""	computation;conserved sequence;estimated;gene frequency;genetic polymorphism;genome;genomics;nucleotides;pierre robin syndrome;reside;score;spectral density;subgroup;transcutaneous electric nerve stimulation;variation (genetics)	Saurabh Asthana;Mikhail A. Roytberg;John A. Stamatoyannopoulos;Shamil R. Sunyaev	2007	PLoS Computational Biology	10.1371/journal.pcbi.0030254	biology;bioinformatics;sequence analysis;conserved sequence;genetics	Comp.	4.434963427670178	-62.11767049226166	29594
0c8d320ad604b00fa07bddd8a5698e7a0ee29fbf	a multi-layered approach to protein data integration for diabetes research	graph theory;random graph;protein protein interaction network;protein complex;data integrity;erdos renyi;small world;graph mining;degree distribution;scale free;protein protein interaction;cross validation;power law;network structure;protein interaction;high throughput;protein interactions;protein interaction network	OBJECTIVE Recent advances in high-throughput experimental techniques have enabled many protein-protein interactions to be identified and stored in large databases. Understanding protein interactions is fundamental to the advancement of science and medical knowledge, unfortunately the scale of the requires an automated approach to analysis. We describe our graph-mining techniques to identify important structures within protein-protein interaction networks to aid in human comprehension and computerised analysis.   METHODS AND MATERIALS We describe our techniques for characterizing graph type and associated properties which is constructed from data collated from the Human Protein Reference Database. Using random graph rewiring comparative techniques and cross-validation with other identification methods a further analysis of the identified essential proteins is presented to illustrate the accuracy of these measures. We argue for using techniques based upon graph structure for separating and encapsulating proteins based upon functionality.   RESULTS We demonstrate how rational Erdos numbers may be used as a method to identify collaborating proteins based solely upon network structure. Further, by using dynamic cut-off limit it demonstrates how collaboration subgraphs can be generated for each protein within the network, and how graph containment can be used as a means of identifying which of many possible graphs are likely to be actual protein complexes. The demonstration protein interaction network built for diabetes is found to be a scale-free, small-world graph with a power-law degree distribution of interactions on nodes. These findings are consistent with many other protein interaction networks.	centrality;cluster analysis;contain (action);cross reactions;cross-talk;cross-validation (statistics);crosstalk;data mining;databases;defense in depth (computing);degree distribution;denial-of-service attack;design of experiments;desquamative interstitial pneumonia;diabetes mellitus;dual in-line package;graph (discrete mathematics);graph - visual representation;high-throughput computing;human protein reference database;interaction design;interaction network;numerous;pixel density;proton pump inhibitors;random graph;regulatory communication material;small;structure mining;throughput;usb hub;anatomical layer;biological signaling;protein protein interaction;statistical cluster	Kenneth McGarry;James Chambers;Giles Oatley	2007	Artificial intelligence in medicine	10.1016/j.artmed.2007.07.009	protein–protein interaction;computer science;bioinformatics;graph theory;theoretical computer science;machine learning	Comp.	5.1782504635037645	-56.74016167428605	29629
434dfa09e8e84266a1cccd0f0d5f4d5fb465671c	regional patterns of cortical phase synchrony in the resting state	phase locking;resting state;phase flow;functional connectivity;phase synchrony	Synchronized phase estimates between oscillating neuronal signals at the macroscale level reflect coordinated activities between neuronal assemblies. Recent electrophysiological evidence suggests the presence of significant spontaneous phase synchrony within the resting state. The purpose of this study was to investigate phase synchrony, including directional interactions, in resting state subdural electrocorticographic recordings to better characterize patterns of regional phase interactions across the lateral cortical surface during the resting state. We estimated spontaneous phase locking value (PLV) as a measure of functional connectivity, and phase slope index (PSI) as a measure of pseudo-causal phase interactions, across a broad range of canonical frequency bands and the modulation of the amplitude envelope of high gamma (amHG), a band that is believed to best reflect the physiological processes giving rise to the functional magnetic resonance imaging BOLD signal. Long-distance interactions had higher PLVs in slower frequencies (≤theta) than in higher ones (≥beta) with amHG behaving more like slow frequencies, and a general trend of increasing frequency band of significant PLVs when moving across the lateral surface along an anterior-posterior axis. Moreover, there was a strong trend of frontal-to-parietal directional phase synchronization, measured by PSI across multiple frequencies. These findings, which are likely indicative of coordinated and structured spontaneous cortical interactions, are important in the study of time scales and directional nature of resting state functional connectivity, and may ultimately contribute to a better understanding of how spontaneous synchrony is linked to variation in regional architecture across the lateral cortical surface.		Kaitlyn Casimo;Felix Darvas;Jeremiah D. Wander;Andrew L. Ko;Thomas J. Grabowski;Edward J. Novotny;Andrew V. Poliakov;Jeffrey G. Ojemann;Kurt E. Weaver	2016	Brain connectivity	10.1089/brain.2015.0362	psychology;control theory;nuclear magnetic resonance;communication	ML	19.322148893951688	-76.65213822427164	29633
162e99a4cdf9e4e8758b880265a46b338a411c7d	plmaddon: a power-law module for the matlabtm sbtoolbox	kinetic model;ordinary differential equation;bioinformatique;taylor expansion;system biology;general public license;bioinformatica;power law;kinetics;open source;steady state;bioinformatics	PLMaddon is a General Public License (GPL) software module designed to expand the current version of the SBToolbox (a Matlab toolbox for systems biology; www.sbtoolbox.org) with a set of functions for the analysis of power-law models, a specific class of kinetic models, set in ordinary differential equations (ODE) and in which the kinetic orders can have positive/negative non-integer values. The module includes functions to generate power-law Taylor expansions of other ODE models (e.g. Michaelis-Menten type models), as well as algorithms to estimate steady-states. The robustness and sensitivity of the models can also be analysed and visualized by computing the power-law's logarithmic gains and sensitivities.	computation (action);differential diagnosis;integer (number);kinetics;matlab;systems biology;algorithm	Julio Vera;Cheng Sun;Yvonne Oertel;Olaf Wolkenhauer	2007	Bioinformatics	10.1093/bioinformatics/btm245	ordinary differential equation;power law;simulation;computer science;bioinformatics;taylor series;mathematics;steady state;systems biology;kinetics;statistics	Security	16.171891288028853	-59.90412266376744	29675
40f2e9b0e609afcbcfac9c298f6dfdcaaf95828a	irreversible metabolic transitions in bistable dynamic systems: the fructose 6-phosphat/fructose 1, 6-bisphosphate cycle in liver	dynamic system		dynamical system	Wolfgang Schellenberger;Jochen Frenzel;Klaus Eschrich	1996			fructose 6-phosphate;bistability;fructose;fructose 1,6-bisphosphate;biology;biochemistry	Logic	7.3335786536287495	-66.90248699954726	29682
79a59fdd3ce44cbbb0e4516c547b9ee67ef83db7	a two stage energy model exhibiting selectivity to changing disparity	motion energy;disparity energy;biological systems;changing disparity;stereo motion;visual cortex	We show that by cascading the disparity energy model and the motion energy model, we obtain neurons that are selective for changing disparity, which is a cue that biological systems may use in the perception of stereo-motion. We demonstrate that the outputs of this model exhibit joint tuning to disparity and stereo-motion. The output achieves a peak response for an input with a preferred disparity that also changes at a preferred rate. The joint tuning curve in the disparity---change of disparity space is approximately separable. We further demonstrate that incorporating a normalization step between the two stages reduces the variability of the model output.	binocular disparity;selectivity (electronic)	Xiaojiang Guo;Bertram E. Shi	2008		10.1007/978-3-540-87732-5_6	computer vision;simulation;control theory	Robotics	20.19548789113976	-68.90855483251691	29697
225905925cc697240788b03d45d0ef6f2348b4bd	corticomuscular activity modeling by combining partial least squares and canonical correlation analysis		Corticomuscular activity modeling based on multiple data sets such as electroencephalography (EEG) and electromyography (EMG) signals provides a useful tool for understanding human motor control systems. In this paper, we propose modeling corticomuscular activity by combining partial least squares (PLS) and canonical correlation analysis (CCA).The proposed method takes advantage of both PLS and CCA to ensure that the extracted components are maximally correlated across two data sets and meanwhile can well explain the information within each data set. This complementary combination generalizes the statistical assumptions beyond both PLS and CCA methods. Simulations were performed to illustrate the performance of the proposed method.We also applied the proposedmethod to concurrent EEG and EMG data collected in a Parkinson’s disease (PD) study.The results reveal several highly correlated temporal patterns between EEG and EMG signals and indicate meaningful corresponding spatial activation patterns. In PD subjects, enhanced connections between occipital region and other regions are noted, which is consistent with previous medical knowledge. The proposed framework is a promising technique for performing multisubject and bimodal data analysis.	computer simulation;control system;electroencephalography;electromyography;partial least squares regression	Xun Chen;Aiping Liu;Z. Jane Wang;Hu Peng	2013	J. Applied Mathematics	10.1155/2013/401976	machine learning;data mining	ML	23.930813314929377	-77.0910094092423	29748
7568d13a82f7afa4be79f09c295940e48ec6db89	image style transfer using convolutional neural networks	high level image synthesis image style transfer convolutional neural networks rendering semantic content image processing image representations semantic information object recognition neural algorithm artistic style image content arbitrary photograph;rendering computer graphics image representation neural nets object recognition;image reconstruction neural networks image representation semantics neuroscience feature extraction visualization	Rendering the semantic content of an image in different styles is a difficult image processing task. Arguably, a major limiting factor for previous approaches has been the lack of image representations that explicitly represent semantic information and, thus, allow to separate image content from style. Here we use image representations derived from Convolutional Neural Networks optimised for object recognition, which make high level image information explicit. We introduce A Neural Algorithm of Artistic Style that can separate and recombine the image content and style of natural images. The algorithm allows us to produce new images of high perceptual quality that combine the content of an arbitrary photograph with the appearance of numerous wellknown artworks. Our results provide new insights into the deep image representations learned by Convolutional Neural Networks and demonstrate their potential for high level image synthesis and manipulation.	algorithm;convolutional neural network;high-level programming language;image processing;outline of object recognition;rendering (computer graphics)	Leon A. Gatys;Alexander S. Ecker;Matthias Bethge	2016	2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)	10.1109/CVPR.2016.265	image warping;image texture;computer vision;feature detection;image processing;computer science;machine learning;digital image processing;multimedia;automatic image annotation;image-based lighting	Vision	23.6865106184353	-53.9546483578415	29760
e6c8c13b10dc1f4a8ee8352a6284e88992f7ec95	elderly fall risk prediction based on a physiological profile approach using artificial neural networks	physiological profile;neural networks;elderly;fall risk prediction	Falls play a critical role in older people's life as it is an important source of morbidity and mortality in elders. In this article, elders fall risk is predicted based on a physiological profile approach using a multilayer neural network with back-propagation learning algorithm. The personal physiological profile of 200 elders was collected through a questionnaire and used as the experimental data for learning and testing the neural network. The profile contains a series of simple factors putting elders at risk for falls such as vision abilities, muscle forces, and some other daily activities and grouped into two sets: psychological factors and public factors. The experimental data were investigated to select factors with high impact using principal component analysis. The experimental results show an accuracy of ≈90 percent and ≈87.5 percent for fall prediction among the psychological and public factors, respectively. Furthermore, combining these two datasets yield an accuracy of ≈91 percent that is better than the accuracy of single datasets. The proposed method suggests a set of valid and reliable measurements that can be employed in a range of health care systems and physical therapy to distinguish people who are at risk for falls.	accidental falls;algorithm;artificial neural network;backpropagation;elder extract;health care;morbidity - disease rate;muscle;principal component analysis;software propagation	Jafar Razmara;Mohammad Hassan Zaboli;Hadi Hassankhani	2018	Health informatics journal	10.1177/1460458216677841	simulation;computer science;artificial intelligence;data mining;artificial neural network	HCI	6.368009455858955	-78.07282853566086	29770
4998add7cba58f0a58d27e730e253904b7fe24ff	improving robustness of feature representations to image deformations using powered convolution in cnns		In this work, we address the problem of improvement of robustness of feature representations learned using convolutional neural networks (CNNs) to image deformation. We argue that higher moment statistics of feature distributions could be shifted due to image deformations, and the shift leads to degrade of performance and cannot be reduced by ordinary normalization methods as observed in experimental analyses. In order to attenuate this effect, we apply additional non-linearity in CNNs by combining power functions with learnable parameters into convolution operation. In the experiments, we observe that CNNs which employ the proposed method obtain remarkable boost in both the generalization performance and the robustness under various types of deformations using large scale benchmark datasets. For instance, a model equipped with the proposed method obtains 3.3% performance boost in mAP on Pascal Voc object detection task using deformed images, compared to the reference model, while both models provide the same performance using original images. To the best of our knowledge, this is the first work that studies robustness of deep features learned using CNNs to a wide range of deformations for object recognition and detection.	artificial neural network;benchmark (computing);circuit restoration;computer vision;convolution;experiment;nonlinear system;object detection;outline of object recognition	Zhun Sun;Mete Ozay;Takayuki Okatani	2017	CoRR		normalization (statistics);convolutional neural network;deformation (mechanics);pattern recognition;machine learning;robustness (computer science);artificial intelligence;object detection;moment (mathematics);reference model;convolution;mathematics	Vision	24.500991714009707	-52.685095459972345	29781
2f5e44bb69c01b994cdd9032585173d2da73650b	phylogenies scores for exhaustive searches and parsimony scores searches	gap open penalties;gep;maximum likelihood;nuclear ribosomal data;gap penalties;msa;multiple sequence alignment;gap extension penalties;phylogeny scores;maximum parsimony;exhaustive search;bioinformatics;gop	Fundamental to Multiple Sequence Alignment (MSA) algorithms is modelling insertions and deletions (gaps). The most prevalent model is to use Gap Open Penalties (GOP) and Gap Extension Penalties (GEP). While GOP and GEP are well understood conceptually, their effects on MSA and consequently on phylogeny scores are not as well understood. We use exhaustive phylogeny searching to explore the effects of varying the GOP and GEP for three nuclear ribosomal data sets. Particular attention is given to optimal maximum likelihood and parsimony phylogeny scores for various alignments of a range of GOP and GEP and their respective distribution of phylogeny scores.		Hyrum Carroll;Perry G. Ridge;Mark J. Clement;Quinn Snell	2007	International journal of bioinformatics research and applications	10.1504/IJBRA.2007.015417	biology;multiple sequence alignment;computer science;bioinformatics;theoretical computer science;brute-force search;maximum likelihood;maximum parsimony;algorithm	Comp.	0.5440349941785001	-53.23612912329471	29799
838c0072751c96976948111aa8fc1ded83ef8d9e	molecular signatures that can be transferred across different omics platforms		Motivation Molecular signatures for treatment recommendations are well researched. Still it is challenging to apply them to data generated by different protocols or technical platforms.   Results We analyzed paired data for the same tumors (Burkitt lymphoma, diffuse large B-cell lymphoma) and features that had been generated by different experimental protocols and analytical platforms including the nanoString nCounter and Affymetrix Gene Chip transcriptomics as well as the SWATH and SRM proteomics platforms. A statistical model that assumes independent sample and feature effects accounted for 69-94% of technical variability. We analyzed how variability is propagated through linear signatures possibly affecting predictions and treatment recommendations. Linear signatures with feature weights adding to zero were substantially more robust than unbalanced signatures. They yielded consistent predictions across data from different platforms, both for transcriptomics and proteomics data. Similarly stable were their predictions across data from fresh frozen and matching formalin-fixed paraffin-embedded human tumor tissue.   Availability and Implementation The R-package 'zeroSum' can be downloaded at https://github.com/rehbergT/zeroSum . Complete data and R codes necessary to reproduce all our results can be received from the authors upon request.   Contact rainer.spang@ur.de.	affymetrix;antivirus software;arabic numeral 0;b-cell lymphomas;burkitt lymphoma;code;dna microarray;diffuse large b-cell lymphoma;electronic signature;embedded system;embedding;formalin;heart rate variability;leukemia, b-cell;lymphoma, diffuse;matching;neoplasms;omics;proteomics;protocols documentation;spatial variability;statistical model;system reference manual;unbalanced circuit;weight;tumor tissue	Michael Altenbuchinger;P. Schwarzfischer;T. Rehberg;J. Reinders;Ch. W. Kohler;W. Gronwald;J. Richter;M. Szczepanowski;N. Masqué-Soler;Wolfram Klapper;Peter J. Oefner;Rainer Spang	2017		10.1093/bioinformatics/btx241	data mining;computer science;dna microarray;bioinformatics;statistical model;paired data;proteomics;omics	ML	5.997756240440725	-54.37138782707333	29818
2e95b2a10ed0ab50f4fdd9ce5bf952d756f14268	characterization of medical time series using fuzzy similarity-based fractal dimensions	intensive care unit;box dimension;time series;correlation dimension;scaling up;fractal dimension;information dimension and correlation dimension;fuzzy;characterization;fractal	This paper attempts to characterize medical time series using fractal dimensions. Existing fractal dimensions like box, information and correlation dimensions characterize the time series by measuring the rate at which the distribution of the time series changes when the length (or radius) of the box (or hypersphere) is changed. However, the measured dimensions significantly vary when the box (or hypersphere) position is changed slightly. It happens because the data points just outside the box (or hypersphere) are not accounted for, and all the data points inside the box or hypersphere are treated equally. To overcome these problems, the hypersphere is converted to a Gaussian, and thus the hard boundary becomes soft. The Gaussian represents the fuzzy similarity between the neighbors and the point around which the Gaussian is constructed. This concept of similarity is exploited to propose a fuzzy similarity-based fractal dimension. The proposed dimension aims to capture the regularity of the time series in terms of how the fuzzy similarity scales up/down when the resolution of the time series is decreased/increased. Experiments on intensive care unit (ICU) data sets show that the proposed dimension characterizes the time series better than the correlation dimension.	correlation dimension;data point;dimensions;electroencephalography;experiment;fractal dimension;gucy2c protein, human;hurst exponent;multifractal system;normal statistical distribution;sampling (signal processing);similarity measure;thinking outside the box;time series;intensive care unit	Manish Sarkar;Tze-Yun Leong	2003	Artificial intelligence in medicine	10.1016/S0933-3657(02)00114-8	fuzzy logic;multifractal system;correlation dimension;box counting;fractal;effective dimension;fractal dimension on networks;fractal analysis;time series;fractal dimension;minkowski–bouligand dimension;statistics	ML	19.06933807023532	-60.8043126059969	29850
1e1859200f5aa4c32d7a195aa03f02ab559efc48	anti-hiv activity of hept, tibo, and cyclic urea derivatives: structure-property studies, focused combinatorial library generation, and hits selection using substructural molecular fragments method	structural properties	"""Substructural molecular fragments (SMF) method [Solov'ev, V. P.; Varnek, A.; Wipff, G. J. Chem. Inf. Comput. Sci. 2000, 40, 847-858] was applied to assess anti-HIV activity for large data sets for three families of compounds: 1-[2-hydroxyethoxy)methyl]-6-(phenylthio)thymine (HEPT) derivatives, tetrahydroimidazobenzodiazepinone (TIBO) derivatives, and cyclic urea (CU) derivatives. The SMF method uses 49 types of topological descriptors (atom/bond sequences and """"augmented atoms"""") which, being coupled with 3 linear and nonlinear fitting equations, allows the user to generate up to 147 structure-property models. For each family of compounds, the modeling was performed on several training sets followed by the validation calculations where three best fit models were applied. Calculated activities well reproduce available experimental data. On the basis of the """"optimal"""" molecular fragments, the focused combinatorial library containing 252 virtual HEPT derivatives has been generated. Its filtering led to several hits potentially possessing anti-HIV activity."""		Vitaly P. Solov'ev;Alexandre Varnek	2003	Journal of chemical information and computer sciences	10.1021/ci020388c	stereochemistry;chemistry;computer science;organic chemistry;combinatorial chemistry;computational chemistry	Comp.	12.817605887093395	-58.51169480380525	29870
43e1660c2d0ef57e9b7bce7c996ebf520441f3f2	how bayes tests of molecular phylogenies compare with frequentist approaches	bayes procedure;bayes factor;nuisance parameter;molecular phylogeny;shimodaira hasegawa	MOTIVATION The desire to compare molecular phylogenies has stimulated the design of numerous tests. Most of these tests are formulated in a frequentist framework, and it is not known how they compare with Bayes procedures. I propose here two new Bayes tests that either compare pairs of trees (Bayes hypothesis test, BHT), or test each tree against an average of the trees included in the analysis (Bayes significance test, BST).   RESULTS The algorithm, based on a standard Metropolis-Hastings sampler, integrates nuisance parameters out and estimates the probability of the data under each topology. These quantities are used to estimate Bayes factors for composite vs. composite hypotheses. Based on two data sets, the BHT and BST are shown to construct similar confidence sets to the bootstrap and the Shimodaira Hasegawa test, respectively. This suggests that the known difference among previous tests is mainly due to the null hypothesis considered.	anatomy, regional;bootstrapping (statistics);butylated hydroxytoluene;erlang (unit);estimated;metropolis;metropolis–hastings algorithm;molecular phylogenetics;naive bayes classifier;null value;quantity;sampling (signal processing);statistical test;trees (plant)	Stéphane Aris-Brosou	2003	Bioinformatics	10.1093/bioinformatics/btg065	econometrics;bayes factor;nuisance parameter;data mining;mathematics;molecular phylogenetics;statistics	Comp.	6.1598354528878065	-52.50215840808283	29902
2cfecd54a95207d4bb3ccf6e3e2a98ec4d9a5b1a	automatic determination of reaction mappings and reaction center information. 2. validation on a biochemical reaction database.	reaction center	The correct identification of the reacting bonds and atoms is a prerequisite for the analysis of the reaction mechanism. We have recently developed a method based on the Imaginary Transition State Energy Minimization approach for automatically determining the reaction center information and the atom-atom mapping numbers. We test here the accuracy of this ITSE approach by comparing the predictions of the method against more than 1500 manually annotated reactions from BioPath, a comprehensive database of biochemical reactions. The results show high agreement between manually annotated mappings and computational predictions (98.4%), with significant discrepancies in only 24 cases out of 1542 (1.6%). This result validates both the computational prediction and the database, at the same time, as the results of the former agree with expert knowledge and the latter appears largely self-consistent, and consistent with a simple principle. In 10 of the discrepant cases, simple chemical arguments or independent literature studies support the predicted reaction center. In five reaction instances the differences in the automatically and manually annotated mappings are described in detail. Finally, in approximately 200 cases the algorithm finds alternate reaction centers, which need to be studied on a case by case basis, as the exact choice of the alternative may depend on the enzyme catalyzing the reaction.		Joannis Apostolakis;Oliver Sacher;Robert Körner;Johann Gasteiger	2008	Journal of chemical information and modeling	10.1021/ci700433d	chemistry;computer science;data mining;algorithm;photosynthetic reaction centre	AI	12.964016553658098	-59.252583768966396	29934
3223cf9e9cfb0e440cfde19c684a2be0388eaa72	graph-based representation and reasoning		The understanding of the mechanisms of information processing in the brain would yield practical impact on innovations such as brain-computer interfaces. Spatio-temporal patterns of spikes (or action potentials) produced by groups of neurons have been hypothesized to play an important role in cortical communication [1]. Due to modern advances in recording techniques at millisecond resolution, an empirical test of the spatio-temporal pattern hypothesis is now becoming possible in principle. However, existing methods for such a test are limited to a small number of parallel spike recordings. We propose a new method that is based on Formal Concept Analysis (FCA, [11]) to carry out this intensive search. We show that evaluating conceptual stability [18] is an effective way of separating background noise from interesting patterns, as assessed by precision and recall rates on ground truth data. Because of the scaling behavior of stability evaluation, our approach is only feasible on medium-sized data sets consisting of a few dozens of neurons recorded simultaneously for some seconds. We would therefore like to encourage investigations on how to improve this scaling, to facilitate research in this important area of computational neuroscience.	action potential;brain–computer interface;computational neuroscience;formal concept analysis;ground truth;image scaling;information processing;precision and recall;spatiotemporal pattern	Ollivier Haemmerlé;Gem Stapleton;Catherine Faron Zucker;Randy Goebel;Yuzuru Tanaka	2016		10.1007/978-3-319-40985-6	computer science;artificial intelligence;operations research	ML	22.582985083190795	-76.32019811048478	29947
cc2a7f2aa45031392ca55a6b73e16766ed99d2e1	human encoded mirnas that regulate the inflenenza virus genome	influenza a ns inflenenza virus genome regulation gene expression downregulation mrna cleavage mrna translational repression molecular targets drug development influenza control influenza prevention scoring based method human encoded mirnas complementary site secondary structure binding site has mir 489 has mir 325 has mir 876 3p has mir 2117 influenza a ha influenza a pb2 influenza a mp;molecular configurations;binding site;genetics;scoring;medical computing;rna;influenza sequences;rna genetics knowledge engineering medical computing microorganisms molecular biophysics molecular configurations;molecular biophysics;influenza humans rna genomics bioinformatics proteins;human encoded mirna;scoring human encoded mirna influenza sequences binding site;microorganisms;knowledge engineering	Motivation:MiRNAs can downregulate gene expression by mRNA cleavage or translational repression. Discovering human encoded miRNAs that regulate the influenza virus genome is important for molecular targets for drug development, and it also plays positive role in influenza control and prevention. Methods: We propose a new method based on scoring to discover human encoded miRNAs that regulate the influenza virus genome. The scoring based on the same complementary sites, the secondary structure of the complementary sites and the binding sites of all sequences respectively. Among them, taking the secondary structure as a vital factor is a new attempt. Results: Has-miR-489, has-miR-325, has-miR-876-3p and has-miR-2117 are targeted HA, PB2, MP and NS of influenza A, respectively.		Hao Zhang;Xin Li;Yuanning Liu;Zhi Li;Minggang Hu;Dong Xu	2012	2012 IEEE 6th International Conference on Systems Biology (ISB)	10.1109/ISB.2012.6314107	rna;bioinformatics;binding site;knowledge engineering;microorganism;molecular biophysics	Visualization	9.007495398331972	-56.55387781719069	29949
4cbdd127b0edb610f78dfffd59f7886c305fb97b	an analysis of single amino acid repeats as use case for application specific background models	software;background modeling;amino acid;protein domains;low complexity;regression model;higher order;computational biology bioinformatics;models genetic;proteins;protein structure tertiary;eukaryota;reference data;empirical model;amino acids;algorithms;signal peptide;sequence analysis;combinatorial libraries;computer appl in life sciences;use case;amino acid motifs;markov chains;microarrays;bioinformatics;markov chain	Sequence analysis aims to identify biologically relevant signals against a backdrop of functionally meaningless variation. Increasingly, it is recognized that the quality of the background model directly affects the performance of analyses. State-of-the-art approaches rely on classical sequence models that are adapted to the studied dataset. Although performing well in the analysis of globular protein domains, these models break down in regions of stronger compositional bias or low complexity. While these regions are typically filtered, there is increasing anecdotal evidence of functional roles. This motivates an exploration of more complex sequence models and application-specific approaches for the investigation of biased regions. Traditional Markov-chains and application-specific regression models are compared using the example of predicting runs of single amino acids, a particularly simple class of biased regions. Cross-fold validation experiments reveal that the alternative regression models capture the multi-variate trends well, despite their low dimensionality and in contrast even to higher-order Markov-predictors. We show how the significance of unusual observations can be computed for such empirical models. The power of a dedicated model in the detection of biologically interesting signals is then demonstrated in an analysis identifying the unexpected enrichment of contiguous leucine-repeats in signal-peptides. Considering different reference sets, we show how the question examined actually defines what constitutes the 'background'. Results can thus be highly sensitive to the choice of appropriate model training sets. Conversely, the choice of reference data determines the questions that can be investigated in an analysis. Using a specific case of studying biased regions as an example, we have demonstrated that the construction of application-specific background models is both necessary and feasible in a challenging sequence analysis situation.	amino acids;backdrop cms;consistency model;experiment;gene ontology term enrichment;leucine;markov chain;markov model;numerous;protein domain;sequence analysis;silo (dataset);globular protein	Pawel P. Labaj;Peter Sykacek;David P. Kreil	2010		10.1186/1471-2105-12-173	biology;markov chain;amino acid;computer science;bioinformatics;machine learning;genetics;empirical modelling	NLP	3.65237857346696	-58.65859005909379	29956
859da61b20af10ac819b9f6bbf8e0f752df96bc5	dynamics of active neuronal dendrites and their functional significance	excitatory stimuli;synaptic control;biomembrane transport neural nets neurophysiology brain models biocontrol;biocontrol;calcium dependent dynamics;neural nets;hippocampus;brain models;functional significance;synapse distribution active neuronal dendrite dynamics functional significance brain neurons neural network pyramidal neuron hippocampus calcium dependent dynamics excitatory stimuli somatic inhibitions synaptic control spatiotemporal dynamics highly organized neuronal information processing;neurons biomembranes brain modeling information processing neurophysiology artificial neural networks hippocampus spatiotemporal phenomena laboratories bioinformatics;biomembranes;artificial neural networks;brain modeling;active neuronal dendrite dynamics;brain neurons;synapse distribution;information processing;spatiotemporal phenomena;somatic inhibitions;compartment model;neurons;neurophysiology;biomembrane transport;computer simulation;highly organized neuronal information processing;artificial neural network;pyramidal neuron;neural network;spatiotemporal dynamics;dynamic properties;bioinformatics	Dynamical properties of brain neurons are much complex and diverse than the neuron models used in artificial neural network studies. Here a pyramidal neuron in hippocampus is modeled based on physiological findings, which is known to show calcium-dependent dynamics in dendrites. Responses of the model neuron to excitatory stimuli on the dendrites are studied under the varied somatic inhibitions. Computer simulations demonstrate synaptic control of spatiotemporal dynamics of the active dendrite system. Highly organized neuronal information processing might be possible by the interaction between the hierarchical dendrite system and the dendritic pattern of synapse distribution.	artificial neural network;dynamical system;information processing;neuron;simulation;synapse	N. Katayama;M. Nakao;Masahiro Yamamoto	1998		10.1109/KES.1998.725978	biology;neuroscience;artificial intelligence;dendritic spine;communication;dendritic spike	ML	18.0042263832735	-71.01527519712837	30004
0dd925fd513804216fb4c4a22ba85d6f398c6bb9	nematode.net: a tool for navigating sequences from parasitic and free-living nematodes	genes;community;animals;genomics;caenorhabditis elegans;parasites;plants;basic medicine;consensus sequence;web accessibility;parasitic nematode;databases genetic;genome sequencing;internet;genes helminth;nematoda;genome;scientific communication;user computer interface;computational biology;information storage and retrieval;human animation;basic local alignment search tool;genome sequence;expressed sequence tags	Nematode.net (www.nematode.net) is a web- accessible resource for investigating gene sequences from nematode genomes. The database is an outgrowth of the parasitic nematode EST project at Washington University's Genome Sequencing Center (GSC), St Louis. A sister project at the University of Edinburgh and the Sanger Institute is also underway. More than 295,000 ESTs have been generated from >30 nematodes other than Caenorhabditis elegans including key parasites of humans, animals and plants. Nematode.net currently provides NemaGene EST cluster consensus sequence, enhanced online BLAST search tools, functional classifications of cluster sequences and comprehensive information concerning the ongoing generation of nematode genome data. The long-term goal of nematode.net is to provide the scientific community with the highest quality sequence information and tools for studying these diverse species.	academic medical centers;blast;biopolymer sequencing;caenorhabditis elegans;classification;consensus sequence;ephrin type-b receptor 1, human;expressed sequence tags;gsc bus;genome;parasites;phylum nematoda	Todd Wylie;John C. Martin;Michael Dante;Makedonka Dautova Mitreva;Sandra W. Clifton;Asif T. Chinwalla;Robert H. Waterston;Richard K. Wilson;James P. McCarter	2004	Nucleic acids research	10.1093/nar/gkh010	consensus sequence;biology;dna sequencing;community;genomics;whole genome sequencing;the internet;bioinformatics;gene;web accessibility;genetics;expressed sequence tag;genome	Comp.	-2.2383863907075208	-61.10837652433118	30050
58bf18dccfee50fe50b6a9176d3f9015af7d0711	extension of mixture-of-experts networks for binary classification of hierarchical data.	supervised learning;280207;mixture of experts;hierarchical data;mixed effects model;neural networks genetic alogrithms and fuzzy logic;generalized linear mixed effects model;expectation maximization algorithm;pattern recognition;artificial intelligence;griffith health faculty;binary classification;computer science;menzies health institute qld;280212;population and social health research program	OBJECTIVE For many applied problems in the context of medically relevant artificial intelligence, the data collected exhibit a hierarchical or clustered structure. Ignoring the interdependence between hierarchical data can result in misleading classification. In this paper, we extend the mechanism for mixture-of-experts (ME) networks for binary classification of hierarchical data. Another extension is to quantify cluster-specific information on data hierarchy by random effects via the generalized linear mixed-effects model (GLMM).   METHODS AND MATERIAL The extension of ME networks is implemented by allowing for correlation in the hierarchical data in both the gating and expert networks via the GLMM. The proposed model is illustrated using a real thyroid disease data set. In our study, we consider 7652 thyroid diagnosis records from 1984 to early 1987 with complete information on 20 attribute values. We obtain 10 independent random splits of the data into a training set and a test set in the proportions 85% and 15%. The test sets are used to assess the generalization performance of the proposed model, based on the percentage of misclassifications. For comparison, the results obtained from the ME network with independence assumption are also included.   RESULTS With the thyroid disease data, the misclassification rate on test sets for the extended ME network is 8.9%, compared to 13.9% for the ME network. In addition, based on model selection methods described in Section 2, a network with two experts is selected. These two expert networks can be considered as modeling two groups of patients with high and low incidence rates. Significant variation among the predicted cluster-specific random effects is detected in the patient group with low incidence rate.   CONCLUSIONS It is shown that the extended ME network outperforms the ME network for binary classification of hierarchical data. With the thyroid disease data, useful information on the relative log odds of patients with diagnosed conditions at different periods can be evaluated. This information can be taken into consideration for the assessment of treatment planning of the disease. The proposed extended ME network thus facilitates a more general approach to incorporate data hierarchy mechanism in network modeling.	apollonian network;artificial intelligence;binary classification;data hierarchy;generalization (psychology);hierarchical database model;incidence matrix;interdependence;model selection;patients;random effects model;statistical classification;test set;thyroid diseases	Shu-Kay Ng;Geoffrey J. McLachlan	2007	Artificial intelligence in medicine	10.1016/j.artmed.2007.06.001	binary classification;mixed model;expectation–maximization algorithm;computer science;artificial intelligence;machine learning;data mining;supervised learning;hierarchical database model;statistics	AI	5.985473720645826	-74.82664581552733	30082
b74cda308838ae969c2cbef694982dde06794920	predicted structures and dynamics for agonists and antagonists bound to serotonin 5-ht2b and 5-ht2c receptors	substrate specificity;5 ht2c serotonin receptor;criblage;agonist;recepteur serotoninergique 5 ht2c;membrane;recepteur serotoninergique 5 ht2a;drug discovery;ligands;screening;5 ht2b serotonin receptor;agonista;eau;protein stability;binding site;binding sites;antagonist;serotonin 5 ht2 receptor agonists;receptor serotonin 5 ht2c;receptor serotonin 5 ht2b;receptor serotoninergico 5 ht2a;serotonin 5 ht2 receptor antagonists;site fixation;pyridine;models molecular;apoproteins;gastrointestinal;protein conformation;5 ht2a serotonin receptor;antagonista;selectividad;antagoniste;selectivity;cernido;thermodynamics;recepteur serotoninergique 5 ht2b;humans;piridina;agua;selectivite;computational biology;agoniste;sitio fijacion;amino acid motifs;water;membrana;receptor serotoninergico 5 ht2c;receptor serotoninergico 5 ht2b;databases protein	Subtype 2 serotonin (5-hydroxytryptamine, 5-HT) receptors are major drug targets for schizophrenia, feeding disorders, perception, depression, migraines, hypertension, anxiety, hallucinogens, and gastrointestinal dysfunctions. (1) We report here the predicted structure of 5-HT2B and 5-HT2C receptors bound to highly potent and selective 5-HT2B antagonist PRX-08066 3, (pKi: 30 nM), including the key binding residues [V103 (2.53), L132 (3.29), V190 (4.60), and L347 (6.58)] determining the selectivity of binding to 5-HT2B over 5-HT2A. We also report structures of the endogenous agonist (5-HT) and a HT2B selective antagonist 2 (1-methyl-1-1,6,7,8-tetrahydro-pyrrolo[2,3-g]quinoline-5-carboxylic acid pyridine-3-ylamide). We examine the dynamics for the agonist- and antagonist-bound HT2B receptors in explicit membrane and water finding dramatically different patterns of water migration into the NPxxY motif and the binding site that correlates with the stability of ionic locks in the D(E)RY region.	anxiety disorders;depressive disorder;drug delivery systems;gastrointestinal diseases;htr2b gene;hallucinogens;hypertensive disease;ionic;keyboard shortcut;lock (computer science);migraine disorders;motif;prx 08066;schizophrenia;selectivity (electronic);serotonin;thioctic acid;tissue membrane;receptor	Soo-Kyung Kim;Youyong Li;Ravinder Abrol;Jiyoung Heo;William A. Goddard	2011	Journal of chemical information and modeling	10.1021/ci100375b	pharmacology;endocrinology;biochemistry;chemistry;binding site;nuclear magnetic resonance	ML	9.576615420982586	-62.89294512388114	30115
21828232fa8b0c1b1c31c6a5f08c9ce236c2ea88	monitoring object orientation: effects of layout complexity, viewpoint changes, and object function	change detection;spatial memory;objective function;object oriented;spatial representation;spatial perception;motor processes	Abstract Studies of spatial representations have typically limited their analysis to memory for object location. Three experiments examined whether another spatial feature, object orientation, could be monitored and represented in a similar fashion. In Experiment 1, an adaptation of the change detection paradigm of Simons and Wang (1998), we found that, whereas unitary location or identity changes were readily noticed, generalized orientation changes were not. Experiment 2 showed that orientation monitoring is strongly affected by layout complexity, viewpoint changes, and the extent of array modifications. Finally, Experiment 3 suggested that an object's behavioral relevance may selectively enhance its orientation processing.	viewpoint	Catherine Mello;David Waller	2010	Spatial Cognition & Computation	10.1080/13875868.2010.487963	psychology;spatial memory;computer vision;neuroscience;pose;computer science;machine learning;mathematics;object-oriented programming;communication;change detection;statistics	HCI	14.28880255996342	-75.96668453203556	30157
2f732477d5d1462ef700a1428bd6d8e782684b1b	an application of artificial immune recognition system for prediction of diabetes following gestational diabetes	imbalanced data;world health organization;diabetes mellitus;logistic regression;gestational diabetes mellitus;vertebrate immune system;gestational diabetes;machine learning;artificial immune recognition system;immune system;type 2 diabetes;support vector machine;artificial immune recognition system airs;pregnant women	Diabetes mellitus (DM) is a disease prevalent in population and is not easily perceived in its initial stage but may sway a patient very seriously in later stage. In accordance with the estimation of World Health Organization (WHO), there will be 370 million diabetics which are 5.4% of the global people in 2030, so it becomes more and more important to predict whether a pregnant woman has or is likely to acquire diabetes. This study is conducted with the use of the machine learning—Artificial Immune Recognition System (AIRS)—to assist doctors in predicting pregnant women who have premonition of type 2 diabetes. AIRS is proposed by Andrew Watkins in 2001 and it makes use of the metaphor of the vertebrate immune system to recognize antigens, select clone, and memorize cells. Additionally, AIRS includes a mechanism, limited resource, to restrain the number of memory cells from increasing uncontrollably. It has also showed positive results on problems in which it was applied. The objective of this study is to investigate the feasibility in using AIRS to predict gestational diabetes mellitus (GDM) subsequent DM. The dataset of diabetes has imbalanced data, but the overall classification recall could still reach 62.8%, which is better than the traditional method, logistic regression, and the technique which is thought as one of the powerful classification approaches, support vector machines (SVM).	a library for support vector machines;central diabetes insipidus;clone;diabetes mellitus;diabetes mellitus, insulin-dependent;diabetes mellitus, non-insulin-dependent;exception handling;gestational diabetes;immune system;information explosion;logistic regression;machine learning;nsa product types;patients;population parameter;prediabetes syndrome;silo (dataset);support vector machine;world health organization	Hung-Chun Lin;Chao-Ton Su;Pa-Chun Wang	2009	Journal of Medical Systems	10.1007/s10916-009-9364-8	support vector machine;immune system;medicine;computer science;artificial intelligence;machine learning;logistic regression;immunology;diabetes mellitus	AI	6.600744300012089	-78.07861013959922	30252
68fc2918f6a137260bc8a9bb9844ae4a463fe13d	gene classification using codon usage and support vector machines	proteins;feature vector;major histocompatibility complex;cluster analysis;support vector machine;molecular structure;frequency;codon usage;support vector machines;dna sequence;genetics;gene expression;molecular biophysics;human leukocyte antigen;dna;molecular structures;codon usage bias;sequences;biological function	Abstract-- A novel approach for gene classification, which adopts codon usage bias as input feature vector for classification by support vector machines (SVM) is proposed. The DNA sequence is first converted to a 59-dimensional feature vector where each element corresponds to the relative synonymous usage frequency of a codon. As the input to the classifier is independent of sequence length and variance, our approach is useful when the sequences to be classified are of different lengths, a condition that homology-based methods tend to fail. The method is demonstrated by using 1,841 Human Leukocyte Antigen (HLA) sequences which are classified into two major classes: HLA-I and HLA-II; each major class is further subdivided into sub-groups of HLA-I and HLA-II molecules. Using codon usage frequencies, binary SVM achieved accuracy rate of 99.3% for HLA major class classification and multi-class SVM achieved accuracy rates of 99.73% and 98.38% for sub-class classification of HLA-I and HLA-II molecules, respectively. The results show that gene classification based on codon usage bias is consistent with the molecular structures and biological functions of HLA molecules.	support vector machine	Jianmin Ma;Minh Ngoc Nguyen;Jagath C. Rajapakse	2009	IEEE/ACM Trans. Comput. Biology Bioinform.	10.1145/1512443.1512445	biology;support vector machine;molecular biology;codon usage bias;computer science;bioinformatics;genetics;molecular biophysics	Metrics	9.451113377409389	-55.408749813835094	30293
a0fb8a7f8c95c0658d5f304144e704a74c624677	wkinmut: an integrated tool for the analysis and interpretation of mutations in human protein kinases	protein stability;computational biology bioinformatics;predictive value of tests;algorithms;receptor epidermal growth factor;humans;combinatorial libraries;computational biology;phenotype;protein kinases;computer appl in life sciences;information storage and retrieval;mutation;leukemia lymphocytic chronic b cell;databases protein;microarrays;bioinformatics	Protein kinases are involved in relevant physiological functions and a broad number of mutations in this superfamily have been reported in the literature to affect protein function and stability. Unfortunately, the exploration of the consequences on the phenotypes of each individual mutation remains a considerable challenge. The wKinMut web-server offers direct prediction of the potential pathogenicity of the mutations from a number of methods, including our recently developed prediction method based on the combination of information from a range of diverse sources, including physicochemical properties and functional annotations from FireDB and Swissprot and kinase-specific characteristics such as the membership to specific kinase groups, the annotation with disease-associated GO terms or the occurrence of the mutation in PFAM domains, and the relevance of the residues in determining kinase subfamily specificity from S3Det. This predictor yields interesting results that compare favourably with other methods in the field when applied to protein kinases. Together with the predictions, wKinMut offers a number of integrated services for the analysis of mutations. These include: the classification of the kinase, information about associations of the kinase with other proteins extracted from iHop, the mapping of the mutations onto PDB structures, pathogenicity records from a number of databases and the classification of mutations in large-scale cancer studies. Importantly, wKinMut is connected with the SNP2L system that extracts mentions of mutations directly from the literature, and therefore increases the possibilities of finding interesting functional information associated to the studied mutations. wKinMut facilitates the exploration of the information available about individual mutations by integrating prediction approaches with the automatic extraction of information from the literature (text mining) and several state-of-the-art databases. wKinMut has been used during the last year for the analysis of the consequences of mutations in the context of a number of cancer genome projects, including the recent analysis of Chronic Lymphocytic Leukemia cases and is publicly available at http://wkinmut.bioinfo.cnio.es .	abductive reasoning;chronic lymphocytic leukemia;database;databases;extraction;integrated services;kerrison predictor;mental association;mutation;neoplasms;pathogenicity;pfam;phenotype;protein data bank;protein kinases;relevance;superfamily;swiss-prot;sensitivity and specificity;server (computing);text mining;uniprot;web server	José M. G. Izarzugaza;Miguel Vazquez;Angela del Pozo;Alfonso Valencia	2012		10.1186/1471-2105-14-345	mutation;biology;dna microarray;cell biology;bioinformatics;phenotype;predictive value of tests;genetics	Comp.	1.9948958907709806	-59.38078630972706	30324
852c63cb9e6663656883966604c51b64e0929707	a hybrid approach using case-based reasoning and rule-based reasoning to support cancer diagnosis: a pilot study	bioinformatics;biomedical research	Recently there has been an increasing interest in applying information technology to support the diagnosis of diseases such as cancer. In this paper, we present a hybrid approach using case-based reasoning (CBR) and rule-based reasoning (RBR) to support cancer diagnosis. We used symptoms, signs, and personal information from patients as inputs to our model. To form specialized diagnoses, we used rules to define the input factors' importance according to the patient's characteristics. The model's output presents the probability of the patient having a type of cancer. To carry out this research, we had the approval of the ethics committee at Napoleão Laureano Hospital, in João Pessoa, Brazil. To define our model's cases, we collected real patient data at Napoleão Laureano Hospital. To define our model's rules and weights, we researched specialized literature and interviewed health professional. To validate our model, we used K-fold cross validation with the data collected at Napoleão Laureano Hospital. The results showed that our approach is an effective CBR system to diagnose cancer.		Renata M. Saraiva;João Bezerra;Mirko Perkusich;Hyggo Oliveira de Almeida;Clauirton de Siebra	2015	Studies in health technology and informatics	10.3233/978-1-61499-564-7-862	rule-based system;data science;data mining;medicine;case-based reasoning	AI	5.912045018669464	-77.49623568062874	30355
55412163445e2b88f0e7694fa376a198cbf18b46	simultaneous detection of α-fetoprotein and carcinoembryonic antigen based on si nanowire field-effect transistors	silicon;hydrogen ion concentration;primary hepatic carcinoma;biosensing techniques;optical imaging;期刊论文;α fetoprotein;electricity;alpha fetoproteins;alpha fetoprotein;nanowires;humans;silicon nanowire field effect transistor;polydimethylsiloxane microfluidic channel;calibration;transistors electronic;carcinoembryonic antigen	Primary hepatic carcinoma (PHC) is one of the most common malignancies worldwide, resulting in death within six to 20 months. The survival rate can be improved by effective treatments when diagnosed at an early stage. The α-fetoprotein (AFP) and carcinoembryonic antigen (CEA) have been identified as markers that are expressed at higher levels in PHC patients. In this study, we employed silicon nanowire field-effect transistors (SiNW-FETs) with polydimethylsiloxane (PDMS) microfluidic channels to simultaneously detect AFP and CEA in desalted human serum. Dual-channel PDMS was first utilized for the selective modification of AFP and CEA antibodies on SiNWs, while single-channel PDMS offers faster and more sensitive detection of AFP and CEA in serum. During the SiNW modification process, 0.1% BSA was utilized to minimize nonspecific protein binding from serum. The linear dynamic ranges for the AFP and CEA detection were measured to be 500 fg/mL to 50 ng/mL and 50 fg/mL to 10 ng/mL, respectively. Our work demonstrates the promising potential of fabricated SiNW-FETs as a direct detection kit for multiple tumor markers in serum; therefore, it provides a chance for early stage diagnose and, hence, more effective treatments for PHC patients.	11-(2-fluoroethyl)estradiol;apple filing protocol;biological markers;biosensors;ceacam5 gene;cessation of life;conflict (psychology);dimethylpolysiloxanes;dual;ethanol 0.62 ml/ml topical gel;experiment;fetal proteins;limited stage (cancer stage);liver carcinoma;mast/stem cell growth factor receptor kit, human;microfluidics;multi-channel memory architecture;nanowires;natural science disciplines;neoplasms;pdms;patients;preparation;silicon;survival rate;thin-film transistor;funding grant	Kuiyu Zhu;Yingjie Zhang;Zengyao Li;Fan Zhou;Kang Feng;Huiqiang Dou;Tong Wang	2015		10.3390/s150819225	calibration;analytical chemistry;optical imaging;nanotechnology;electricity;silicon;physics	HCI	11.748697106022284	-64.94745617960025	30431
941b86e4ea9c50e07b2e9c503d06fd0378856ff2	indirect two-sided relative ranking: a robust similarity measure for gene expression data	gene expression profile;scientific discovery;databases genetic;statistical significance;gene expression data;public domain;computational biology bioinformatics;gene expression;algorithms;pattern recognition automated;combinatorial libraries;computational biology;computer appl in life sciences;similarity measure;article;gene expression profiling;microarrays;bioinformatics	There is a large amount of gene expression data that exists in the public domain. This data has been generated under a variety of experimental conditions. Unfortunately, these experimental variations have generally prevented researchers from accurately comparing and combining this wealth of data, which still hides many novel insights. In this paper we present a new method, which we refer to as indirect two-sided relative ranking, for comparing gene expression profiles that is robust to variations in experimental conditions. This method extends the current best approach, which is based on comparing the correlations of the up and down regulated genes, by introducing a comparison based on the correlations in rankings across the entire database. Because our method is robust to experimental variations, it allows a greater variety of gene expression data to be combined, which, as we show, leads to richer scientific discoveries. We demonstrate the benefit of our proposed indirect method on several datasets. We first evaluate the ability of the indirect method to retrieve compounds with similar therapeutic effects across known experimental barriers, namely vehicle and batch effects, on two independent datasets (one private and one public). We show that our indirect method is able to significantly improve upon the previous state-of-the-art method with a substantial improvement in recall at rank 10 of 97.03% and 49.44%, on each dataset, respectively. Next, we demonstrate that our indirect method results in improved accuracy for classification in several additional datasets. These datasets demonstrate the use of our indirect method for classifying cancer subtypes, predicting drug sensitivity/resistance, and classifying (related) cell types. Even in the absence of a known (i.e., labeled) experimental barrier, the improvement of the indirect method in each of these datasets is statistically significant.	classification;fluorescent antibody technique, indirect;gene expression profiling;indirect treatment;neoplasms;silo (dataset);similarity measure;subtype (attribute);tracer;cell type	Louis Licamele;Lise Getoor	2009		10.1186/1471-2105-11-137	biology;public domain;gene expression;dna microarray;bioinformatics;data science;data mining;statistical significance;gene expression profiling	Comp.	7.679433846306267	-54.477442122018886	30436
d168cb6d51f8e6929ec225f92a93b428c3f0ebb8	water-mediated interactions in the crp-camp-dna complex: does water mediate sequence-specific binding at the dna primary-kink site?	escherichia coli;cyclic amp receptor protein;hydrogen bond;x ray crystal structure;water mediated interactions;molecular dynamics;dna binding;molecular dynamic simulation;protein dna binding;molecular dynamic;dna sequence;base pair	The cyclic AMP receptor protein (CRP) of Escherichia coli binds preferentially to DNA sequences possessing a T:A base pair at position 6 (at which the DNA becomes kinked), but with which it does not form any direct interactions. It has been proposed that indirect readout is involved in CRP-DNA binding, in which specificity for this base pair is primarily related to sequence effects on the energetic susceptibility of the DNA to kink formation. In the current study, the possibility of contributions to indirect readout by water-mediated hydrogen bonding of CRP with the T:A base pair was investigated. A 1.0 ns molecular dynamics simulation of the CRP-cAMP-DNA complex in explicit solvent was performed, and assessed for water-mediated CRP-DNA hydrogen bonds; results were compared to several X-ray crystal structures of comparable complexes. While several water-mediated CRP-DNA hydrogen bonds were identified, none of these involved the T:A base pair at position 6. Therefore, the sequence specificity for this base pair is not likely enhanced by water-mediated hydrogen bonding with the CRP.		Bryan M. B. VanSchouwen;Heather L. Gordon;Stuart M. Rothstein;Yuto Komeiji;Kaori Fukuzawa;Shigenori Tanaka	2008	Computational biology and chemistry	10.1016/j.compbiolchem.2008.01.001	crystallography;biology;biochemistry;dna sequencing;molecular dynamics;base pair;chemistry;hmg-box;hydrogen bond;nucleic acid secondary structure;escherichia coli;genetics	Comp.	8.969645274246085	-62.82213909458792	30443
3e86128ebdf55f3085ea4a100b9714e02692a55f	rna visualization: relevance and the current state-of-the-art focusing on pseudoknots	dna;biological patents;genomics;biomedical journals;text mining;europe pubmed central;viruses medical;citation search;citation networks;rna proteins visualization dna genomics viruses medical media;bioinformatics rna structure rna topology rna visualization pseudoknots;media;visualization;rna;proteins;research articles;abstracts;open access;life sciences;clinical guidelines;full text;pseudoknots bioinformatics rna structure rna topology rna visualization;rest apis;orcids;europe pmc;biomedical research;bioinformatics;literature search	RNA visualization is crucial in order to understand the relationship that exists between RNA structure and its function, as well as the development of better RNA structure prediction algorithms. However, in the context of RNA visualization, one key structure remains difficult to visualize: Pseudoknots. Pseudoknots occur in RNA folding when two secondary structural components form base-pairs between them. The three-dimensional nature of these components makes them challenging to visualize in two-dimensional media, such as print media or screens. In this review, we focus on the advancements that have been made in the field of RNA visualization in two-dimensional media in the past two decades. The review aims at presenting all relevant aspects of pseudoknot visualization. We start with an overview of several pseudoknotted structures and their relevance in RNA function. Next, we discuss the theoretical basis for RNA structural topology classification and present RNA classification systems for both pseudoknotted and non-pseudoknotted RNAs. Each description of RNA classification system is followed by a discussion of the software tools and algorithms developed to date to visualize RNA, comparing the different tools’ strengths and shortcomings.	anatomic structures;anatomy, regional;categorization;classification;data structure;enterprise life cycle;graph - visual representation;hhh syndrome;hiv;imagery;inspiration function;interaction;mathematics;natural science disciplines;network address translation;nucleotides;rna folding;relevance;review [publication type];unique identifier;usability testing;user interface device component;virus;visualization software;algorithm;cellular targeting;tertiary	Boris Shabash;Kay C. Wiese	2017	IEEE/ACM Transactions on Computational Biology and Bioinformatics	10.1109/TCBB.2016.2522421	biology;genomics;text mining;rna;media;visualization;computer science;bioinformatics;data science;world wide web;genetics;dna	Visualization	-0.7494443204691491	-62.340809012591	30468
a6c6c74c518cccfc66aa9153e6b406285ab5da56	diffusion weighted imaging distinguishes the vegetative state from the minimally conscious state	white matter;diffusion tensor images;clinical diagnosis;diffusion weighted images;magnetic resonance image;vegetative state;decision making process;magnetic resonance imaging;diffusion tensor imaging;diffuse axonal injury;minimally conscious state;mean diffusivity	The vegetative (VS) and minimally conscious (MCS) states are currently distinguished on the basis of exhibited behaviour rather than underlying pathology. Although previous histopathological studies have documented different degrees of diffuse axonal injury as well as damage to the thalami and brainstem regions in VS and MCS, these differences have not been assessed in vivo, and therefore, do not provide a measurable pathological marker to aid clinical diagnosis. Currently, the diagnostic decision-making process is highly subjective and prone to error. Indeed, previous work has suggested that up to 43% of patients in this group may be misdiagnosed. We used diffusion tensor imaging (DTI) to study the neuropathology of 25 vegetative and minimally conscious patients in vivo and to identify measures that could potentially distinguish the patients in these two groups. Mean diffusivity (MD) maps of the subcortical white matter, brainstem and thalami were generated. The MCS and VS patients differed significantly in subcortical white matter and thalamic regions, but appeared not to differ in the brainstem. Moreover, the DTI results predicted scores on the Coma Recovery Scale (p<0.001) and successfully classified the patients in to their appropriate diagnostic categories with an accuracy of 95%. The results suggest that this method may provide an objective and highly accurate method for classifying these challenging patient populations and may therefore complement the behavioural assessment to inform the diagnostic decision making process.	basal ganglia diseases;brain stem;classification;comatose;complement system proteins;conscious;consciousness;decision making;diagnosis, clinical;diffuse axonal injury;diffusion tensor imaging;document completion status - documented;magnetic resonance imaging;map;molecular dynamics;multi categories security;neuropathology;patients;persistent vegetative state;population;thalamic structure;video-in video-out;white matter	Davinia Fernández-Espejo;Tristan Bekinschtein;Martin M. Monti;John D. Pickard;Carme Junque;Martin R. Coleman;Adrian M. Owen	2011	NeuroImage	10.1016/j.neuroimage.2010.08.035	psychology;diffusion mri;decision-making;neuroscience;radiology;medicine;pathology;magnetic resonance imaging;surgery	ML	20.444129321202812	-79.8934659161019	30490
8f1b2a2af2e01829da6b2e48372c80e27132761e	one shot learning of simple visual concepts	social and behavioral sciences	People can learn visual concepts from just one example, but it remains a mystery how this is accomplished. Many authors have proposed that transferred knowledge from more familiar concepts is a route to one shot learning, but what is the form of this abstract knowledge? One hypothesis is that the sharing of parts is core to one shot learning, and we evaluate this idea in the domain of handwritten characters, using a massive new dataset. These simple visual concepts have a rich internal part structure, yet they are particularly tractable for computational models. We introduce a generative model of how characters are composed from strokes, where knowledge from previous characters helps to infer the latent strokes in novel characters. The stroke model outperforms a competing stateof-the-art character model on a challenging one shot learning task, and it provides a good fit to human perceptual data.	cobham's thesis;computational model;generative model	Brenden M. Lake;Ruslan Salakhutdinov;Jason Gross;Joshua B. Tenenbaum	2011			psychology;artificial intelligence;machine learning;communication;cognitive science	ML	19.81536339219894	-54.28292858277929	30509
b96e341142556f1ef77bd555414e3d2138e8d69c	a database of phylogenetically atypical genes in archaeal and bacterial genomes, identified using the darkhorse algorithm	evolution molecular;search engine;protein function;probability;ucsd;protein family;base composition;phylogeny;genome archaeal;amino acid sequence;databases genetic;sequence analysis dna;statistical method;gene transfer horizontal;relational database;computational biology bioinformatics;large scale;proteins;phylogenetic tree;indexation;genome bacterial;horizontal gene transfer;algorithms;user computer interface;bacterial genome;neural networks computer;combinatorial libraries;computer appl in life sciences;genome sequence;microarrays;bioinformatics	The process of horizontal gene transfer (HGT) is believed to be widespread in Bacteria and Archaea, but little comparative data is available addressing its occurrence in complete microbial genomes. Collection of high-quality, automated HGT prediction data based on phylogenetic evidence has previously been impractical for large numbers of genomes at once, due to prohibitive computational demands. DarkHorse, a recently described statistical method for discovering phylogenetically atypical genes on a genome-wide basis, provides a means to solve this problem through lineage probability index (LPI) ranking scores. LPI scores inversely reflect phylogenetic distance between a test amino acid sequence and its closest available database matches. Proteins with low LPI scores are good horizontal gene transfer candidates; those with high scores are not. The DarkHorse algorithm has been applied to 955 microbial genome sequences, and the results organized into a web-searchable relational database, called the DarkHorse HGT Candidate Resource http://darkhorse.ucsd.edu . Users can select individual genomes or groups of genomes to screen by LPI score, search for protein functions by descriptive annotation or amino acid sequence similarity, or select proteins with unusual G+C composition in their underlying coding sequences. The search engine reports LPI scores for match partners as well as query sequences, providing the opportunity to explore whether potential HGT donor sequences are phylogenetically typical or atypical within their own genomes. This information can be used to predict whether or not sufficient information is available to build a well-supported phylogenetic tree using the potential donor sequence. The DarkHorse HGT Candidate database provides a powerful, flexible set of tools for identifying phylogenetically atypical proteins, allowing researchers to explore both individual HGT events in single genomes, and large-scale HGT patterns among protein families and genome groups. Although the DarkHorse algorithm cannot, by itself, provide definitive proof of horizontal gene transfer, it is a flexible, powerful tool that can be combined with slower, more rigorous methods in situations where these other methods could not otherwise be applied.	acclimatization;algorithm;amino acid sequence;amino acids;annotation;body mass index;computation;computational resource;cyberinfrastructure;description;diversification (finance);ecology;email;geforce 9 series;gene transfer;gene transfer, horizontal;genome;genome, bacterial;genome, microbial;jolla;lineage (evolution);linear partial information;lysinuric protein intolerance;manuscripts;multi-drug resistance;nonprofit organizations;phylogenetic tree;phylogenetics;protein family;question (inquiry);relational database;requirement;reservoir device component;sequence analysis, protein;sequence alignment;software architecture;throughput;user interface device component;web search engine	Sheila Podell;Terry Gaasterland;Eric E. Allen	2008	BMC Bioinformatics	10.1186/1471-2105-9-419	biology;phylogenetic tree;whole genome sequencing;dna microarray;relational database;bioinformatics;probability;horizontal gene transfer;peptide sequence;protein family;genetics;search engine;bacterial genome size;phylogenetics	Comp.	1.0310822004930147	-59.82588310666242	30532
8bf3ddd097b9a1519e76038bc533a23dcee6813c	conceptual imitation learning: an application to human-robot interaction	human robot interaction;imitation learning	In general, imitation is imprecisely used to address different levels of social learning from high level knowledge transfer to low level regeneration of motor commands. However, true imitation is based on abstraction and conceptualization. This paper presents a conceptual approach for imitation learning using feedback cues and interactive training to abstract spatio-temporal demonstrations based on their perceptual and functional characteristics. Abstraction, concept acquisition, and self-organization of proto-symbols are performed through an incremental and gradual learning algorithm. In this algorithm, Hidden Markov Models (HMMs) are used to abstract perceptually similar demonstrations. However, abstract (relational) concepts emerge as a collection of HMMs irregularly scattered in the perceptual space. Performance of the proposed algorithm is evaluated in a human-robot interaction task of imitating signs produced by hand movements. Experimental results show efficiency of our model for concept extraction, symbol emergence, motion pattern recognition, and regeneration.	algorithm;autonomous robot;conceptualization (information science);emergence;hidden markov model;high-level programming language;human–robot interaction;markov chain;memory management;pattern recognition;self-organization	Hossein Hajimirsadeghi;Majid Nili Ahmadabadi;Mostafa Ajallooeian;Babak Nadjar Araabi;Hadi Moradi	2010			robot learning;imitative learning;computer science;cognitive imitation	AI	20.407999319443515	-64.63255221572935	30557
9c8e78be8280a45b6a32fffd3e2fa04329ed7351	mimumba revisited: torsion angle rules for conformer generation derived from x-ray structures		A method has been developed which automatically generates SMARTS patterns for four-atomic torsional fragments, searches experimental structures in the Cambridge Crystallographic Database, and obtains rules for preferred torsion angles in drug-size molecules. These rules can be used for exhaustive conformational analysis using the popular conformer generator OMEGA. This approach results in an overall improvement of quality and coverage of conformational space when comparing conformer ensembles generated by this method with results obtained by using the default OMEGA setup. In particular, the percentage of structures with at least one conformation closer than 0.5 A to the X-ray structure improves from 84% to 92% in a test set of 11 027 experimental structures from the CSD. Moreover, the average RMS distance of the closest conformation to the X-ray structure improves from 0.30 to 0.22 A.	cambridge structural database;default;diagnostic radiologic examination;omega;preparation;rule (guideline);smiles arbitrary target specification;test set;torsion (gastropod);x-ray (amazon kindle)	Jens Sadowski;Jonas Boström	2006	Journal of chemical information and modeling	10.1021/ci060042s		Comp.	12.017121656682312	-59.64208536288671	30573
53d157b83761a61443fc38335d8b05bc7298e01d	dna microarray data and contextual analysis of correlation graphs	software;saccharomyces cerevisiae;graphical interface;computer graphics;gene cluster;lymphoma b cell;computational biology bioinformatics;terminology as topic;numerical analysis computer assisted;cluster analysis;gene expression regulation fungal;gene expression regulation neoplastic;automatic annotation;contextual analysis;algorithms;computer terminals;lymphoma large b cell diffuse;humans;dna microarray data;dna microarray;combinatorial libraries;computational biology;computer appl in life sciences;dimensional reduction;gene expression profiling;leukemia lymphocytic chronic b cell;oligonucleotide array sequence analysis;microarrays;bioinformatics	DNA microarrays are used to produce large sets of expression measurements from which specific biological information is sought. Their analysis requires efficient and reliable algorithms for dimensional reduction, classification and annotation. We study networks of co-expressed genes obtained from DNA microarray experiments. The mathematical concept of curvature on graphs is used to group genes or samples into clusters to which relevant gene or sample annotations are automatically assigned. Application to publicly available yeast and human lymphoma data demonstrates the reliability of the method in spite of its simplicity, especially with respect to the small number of parameters involved. We provide a method for automatically determining relevant gene clusters among the many genes monitored with microarrays. The automatic annotations and the graphical interface improve the readability of the data. A C++ implementation, called Trixy, is available from http://tagc.univ-mrs.fr/bioinformatics/trixy.html .	annotation;c++;dna microarray format;experiment;graph - visual representation;graphical user interface;interface device component;lymphoma;mathematical concepts;mathematics;personnameuse - assigned;reduction (complexity);statistical classification;algorithm	Jacques Rougemont;Pascal Hingamp	2002	BMC Bioinformatics	10.1186/1471-2105-4-15	biology;molecular biology;context analysis;dna microarray;computer science;bioinformatics;genetics	Comp.	4.599914017821059	-54.576167698952986	30591
b10b39574aa817d67ea645e86ce2b8241c6f7bc1	mechanisms of fast and stringent search in homologous pairing of double-stranded dna		Self-organization in the cell relies on the rapid and specific binding of molecules to their cognate targets. Correct bindings must be stable enough to promote the desired function even in the crowded and fluctuating cellular environment. In systems with many nearly matched targets, rapid and stringent formation of stable products is challenging. Mechanisms that overcome this challenge have been previously proposed, including separating the process into multiple stages; however, how particular in vivo systems overcome the challenge remains unclear. Here we consider a kinetic system, inspired by homology dependent pairing between double stranded DNA in bacteria. By considering a simplified tractable model, we identify different homology testing stages that naturally occur in the system. In particular, we first model dsDNA molecules as short rigid rods containing periodically spaced binding sites. The interaction begins when the centers of two rods collide at a random angle. For most collision angles, the interaction energy is weak because only a few binding sites near the collision point contribute significantly to the binding energy. We show that most incorrect pairings are rapidly rejected at this stage. In rare cases, the two rods enter a second stage by rotating into parallel alignment. While rotation increases the stability of matched and nearly matched pairings, subsequent rotational fluctuations reduce kinetic trapping. Finally, in vivo chromosome are much longer than the persistence length of dsDNA, so we extended the model to include multiple parallel collisions between long dsDNA molecules, and find that those additional interactions can greatly accelerate the searching.	alignment;bacteria;binding sites;cobham's thesis;dna;homologous gene;homology (biology);inspiration function;interaction energy;kinetics;language binding;muscle rigidity;persistence (computer science);rod photoreceptors;self-organization;stage level 2;turbulence kinetic energy;video-in video-out;collision	Amir Bitran;Wei-Yin Chiang;Erel Levine;Mara Prentiss	2017		10.1371/journal.pcbi.1005421	genomics;dna;biology;bioinformatics;genetics;sequence analysis;homologous chromosome;dna-binding protein;chromosome;protein–protein interaction;pairing	Comp.	6.773514290610285	-63.679155868963335	30645
bf0232ac9e7d91e1265aa0b191c6676601f1c287	synchronization of neural activity is a promising mechanism of memory information processing in networks of columns	memoire;oscillations;procesamiento informacion;systeme nerveux central;actividad electrica;hombre;electrophysiology;oscillation;encefalo;activite electrique;synchronisation;sistema nervioso central;memoria;encephale;synchronization;network model;cognition;information processing;human;associative memory;cognicion;cerebral cortex;network dynamics;electrofisiologia;sincronizacion;oscilacion;cortex cerebral;functional unit;reseau neuronal;traitement information;corteza cerebral;electrophysiologie;cortical neurons;red neuronal;central nervous system;memory;homme;neural network;electrical activity;brain vertebrata	Synchronization of the oscillatory discharge of cortical neurons could be a part of the mechanism that is involved in cortical information processing. On the assumption that the basic functional unit is the column composed of local excitatory and inhibitory cells and generating oscillatory neural activity, a network model that attains associative memory function is proposed. The synchronization of oscillation in the model is studied analytically using a sublattice analysis. In particular, the retrieval of a single memory pattern can be studied in the system, which can be derived from the original network model of interacting columns and is formally equivalent to a system of an isolated column. The network model simulated numerically shows a remarkable performance in which retrieval is achieved simultaneously for more than one memory pattern. The manifestations of this simultaneous retrieval in the network dynamics are successive transitions of the network state from a synchronized oscillation for a memory pattern to that for another memory pattern.	column (database);content-addressable memory;discharger;execution unit;greater than;information processing;interaction;memory disorders;memory bound function;network model;neural oscillation;numerical analysis	Tomoki Fukai	1994	Biological Cybernetics	10.1007/BF00202761	psychology;synchronization;neuroscience;information processing;computer science;artificial intelligence;communication;oscillation;artificial neural network;quantum mechanics	ML	20.479223584244515	-70.4663588935298	30678
b61b6c47a6f332493dfe9ec1e61014af0898675c	computational discovery and in vivo validation of hnf4 as a regulatory gene in planarian regeneration		MOTIVATION Automated computational methods can infer dynamic regulatory network models directly from temporal and spatial experimental data, such as genetic perturbations and their resultant morphologies. Recently, a computational method was able to reverse-engineer the first mechanistic model of planarian regeneration that can recapitulate the main anterior-posterior patterning experiments published in the literature. Validating this comprehensive regulatory model via novel experiments that had not yet been performed would add in our understanding of the remarkable regeneration capacity of planarian worms and demonstrate the power of this automated methodology.   RESULTS Using the Michigan Molecular Interactions and STRING databases and the MoCha software tool, we characterized as hnf4 an unknown regulatory gene predicted to exist by the reverse-engineered dynamic model of planarian regeneration. Then, we used the dynamic model to predict the morphological outcomes under different single and multiple knock-downs (RNA interference) of hnf4 and its predicted gene pathway interactors β-catenin and hh Interestingly, the model predicted that RNAi of hnf4 would rescue the abnormal regenerated phenotype (tailless) of RNAi of hh in amputated trunk fragments. Finally, we validated these predictions in vivo by performing the same surgical and genetic experiments with planarian worms, obtaining the same phenotypic outcomes predicted by the reverse-engineered model.   CONCLUSION These results suggest that hnf4 is a regulatory gene in planarian regeneration, validate the computational predictions of the reverse-engineered dynamic model, and demonstrate the automated methodology for the discovery of novel genes, pathways and experimental phenotypes.   CONTACT michael.levin@tufts.edu.	clinical regeneration;computation;database;experiment;gene regulatory network;hnf4a gene;inference;interference (communication);mathematical model;natural regeneration;phenotype;planarians;programming tool;rna interference;resultant;reverse engineering;string;scientific publication;video-in video-out	Daniel Lobo;Junji Morokuma;Michael Levin	2016	Bioinformatics	10.1093/bioinformatics/btw299	biology;molecular biology;bioinformatics;anatomy	Comp.	6.655861408082469	-59.160142847195175	30748
6a639bd144c8996c5fd76d77f29d120245874b0d	dynamics of trna dissociation in early and later cycles of translation elongation by the ribosome	ribosome;elongation phase;initiation phase;molecular machine;translation	Deacylated tRNA dissociation from E site and aminoacyl-tRNA binding to the A site of the ribosome play a critical role in repetitive cycles of protein synthesis. Available experimental data showed that in the small range of aminoacyl-tRNA concentrations, during the first few cycles of translation elongation (initiation phase of translation) the E-site tRNA can be dissociated either before or after the A-site tRNA binding, while during the later cycles of elongation (elongation phase) the E-site tRNA is mostly dissociated before the A-site tRNA binding. Here, based on our proposed model of translation elongation we study analytically the dynamics of the E-site tRNA dissociation and A-site tRNA binding, providing quantitative explanations of the available experimental data in both the initiation and elongation phases. In our model there exist two routes of state transitions within an elongation cycle in the initiation phase, with each route having stochastic E-site tRNA dissociation but with different dissociation rates. Thus, the E-site tRNA dissociation is governed by a stochastic competition between the tRNA dissociation and A-site tRNA association reactions, although in the small range of aminoacyl-tRNA concentrations used in the experiments it seems that such stochastic competition does not exist. Moreover, the detailed comparisons between the dynamics of tRNA dissociation in the initiation phase and that in the elongation phase are made.		Xiao-Xuan Shi;Hong Chen;Zhanfeng Wang	2018	Bio Systems	10.1016/j.biosystems.2018.08.008	biophysics;transfer rna;genetics;a-site;protein biosynthesis;dissociation (psychology);elongation;e-site;ribosome;biology;trna binding	Comp.	7.4569064800254505	-64.34355096818261	30758
4c7c776fb6c57951fb2987a24a8c371d59c2fe58	a maximum common subgraph kernel method for predicting the chromosome aberration test	genetique;modelizacion;criblage;industria farmaceutica;optimisation;fiabilidad;reliability;medicament;analisis estadistico;subgrafo;guidage;optimizacion;graph method;genetica;methode noyau;etude experimentale;base donnee tres grande;analyse fonctionnelle;screening;endommagement;base de datos a gran escala;guiado;metodo grafo;high precision;algoritmo genetico;deterioracion;industrie pharmaceutique;genetics;methode graphe;modelisation;classification a vaste marge;phase initiale;statistical analysis;functional analysis;sous graphe;fiabilite;precision elevee;metodo nucleo;analyse statistique;precision elevada;algorithme genetique;fase inicial;cernido;guidance;kernel method;genetic algorithm;medicamento;optimization;drug;maquina ejemplo soporte;very large databases;vector support machine;subgraph;damaging;pharmaceutical industry;modeling;estudio experimental;early phase;in vitro;analisis funcional	The chromosome aberration test is frequently used for the assessment of the potential of chemicals and drugs to elicit genetic damage in mammalian cells in vitro. Due to the limitations of experimental genotoxicity testing in early drug discovery phases, a model to predict the chromosome aberration test yielding high accuracy and providing guidance for structure optimization is urgently needed. In this paper, we describe a machine learning approach for predicting the outcome of this assay based on the structure of the investigated compound. The novelty of the proposed method consists in combining a maximum common subgraph kernel for measuring the similarity of two chemical graphs with the potential support vector machine for classification. In contrast to standard support vector machine classifiers, the proposed approach does not provide a black box model but rather allows to visualize structural elements with high positive or negative contribution to the class decision. In order to compare the performance of different methods for predicting the outcome of the chromosome aberration test, we compiled a large data set exhibiting high quality, reliability, and consistency from public sources and configured a fixed cross-validation protocol, which we make publicly available. In a comparison to standard methods currently used in pharmaceutical industry as well as to other graph kernel approaches, the proposed method achieved significantly better performance.		Johannes Mohr;Brijnesh J. Jain;Andreas Sutter;Antonius ter Laak;Thomas Steger-Hartmann;Nikolaus Heinrich;Klaus Obermayer	2010	Journal of chemical information and modeling	10.1021/ci900367j	functional analysis;kernel method;systems modeling;genetic algorithm;computer science;artificial intelligence;machine learning;reliability;in vitro;algorithm;statistics	ML	11.612069170483796	-55.65087208316229	30766
74488528a1f9114e2622b3c2e3858dbb18ee2548	studying the growth kinetics of untreated clinical tumors by using an advanced discrete simulation model	clinical data;tumor free growth;tumor kinetics;parametric study;tumor growth;cancer modeling;tumor cells;exponential tumor growth;in silico oncology;discrete model;growth kinetics;growth rate;cell cycle;parametric analysis;discrete simulation;kinetics;in silico;dynamic behavior	Prior to an eventual clinical adaptation and validation of any clinically oriented model, a thorough study of its dynamic behavior is a sine qua non. Such a study can also elucidate aspects of the interplay of the involved biological mechanisms. Toward this goal, the paper focuses on an in-depth investigation of the free growth behavior of a macroscopically homogeneous malignant tumor system, using a discrete model of tumor growth. We demonstrate that when a clinical tumor grows exponentially, the following preconditionsmust be fulfilled: (a) timeand space-independent tumor dynamics, in terms of the transition rates among the considered cell categories and the duration of the cell cycle phases, and (b) a tumor system in a state of population equilibrium. Moreover, constant tumor dynamics during the simulation are assumed. In order to create a growing tumor, a condition that the model parameters must fulfill has been derived based on an analytical treatment of the model’s assumptions. A detailed parametric analysis of the model has been performed, in order to determine the impact and the interdependences of its parameters with focus on the free growth rate and the composition of cell population. Constraining tumor cell kinetics, toward limiting the number of possible solutions (i.e., sets of parameters) to the problem of adaptation to the real macroscopic features of a tumor, is also discussed. After completing all parametric studies and after adapting and validating the model on clinical data, it is envisaged to end up with a reliable tool for supporting clinicians in selecting the most appropriate pattern, extracted from several candidate therapeutic schemes, by exploiting tumorand patient-specific imaging, molecular and histological data. © 2011 Elsevier Ltd. All rights reserved.	cell signaling;emoticon;interdependence;kinetics internet protocol;simulation	Eleni A. Kolokotroni;Dimitra D. Dionysiou;Nikolaos K. Uzunoglu;Georgios S. Stamatakos	2011	Mathematical and Computer Modelling	10.1016/j.mcm.2011.05.007	simulation;computer science;bioinformatics;discrete event simulation;cell cycle;mathematics;parametric statistics;kinetics	Robotics	7.587255645448657	-67.7897535445692	30773
7164d6d812d8d29136edd7952a9600cc0696a796	an active efficient coding model of the optokinetic nystagmus	eye;neurons afferent;spatial vectors;nystagmus optokinetic;strabismus;motor neurons;motion;subcortical;neurons;reflex	Optokinetic nystagmus (OKN) is an involuntary eye movement responsible for stabilizing retinal images in the presence of relative motion between an observer and the environment. Fully understanding the development of OKN requires a neurally plausible computational model that accounts for the neural development and the behavior. To date, work in this area has been limited. We propose a neurally plausible framework for the joint development of disparity and motion tuning in the visual cortex and of optokinetic and vergence eye-movement behavior. To our knowledge, this framework is the first developmental model to describe the emergence of OKN in a behaving organism. Unlike past models, which were based on scalar models of overall activity in different neural areas, our framework models the development of the detailed connectivity both from the retinal input to the visual cortex and from the visual cortex to the motor neurons. This framework accounts for the importance of the development of normal vergence control and binocular vision in achieving normal monocular OKN behaviors. Because the model includes behavior, we can simulate the same perturbations as past experiments, such as artificially induced strabismus. The proposed model agrees both qualitatively and quantitatively with a number of findings from the literature on both binocular vision and the optokinetic reflex. Finally, our model makes quantitative predictions about OKN behavior using the same methods used to characterize OKN in the experimental literature.	behavior;binocular disparity;binocular vision;cerebral cortex;computation;computational model;digital single-lens reflex camera;emergence;experiment;eye abnormalities;eye movements;neurogenesis;neurons, efferent;optokinetic nystagmus;retina;simulation;vergence	Chong Zhang;Jochen Triesch;Bertram E. Shi	2016	Journal of vision	10.1167/16.14.10	psychology;reflex;motion;optics;communication;optokinetic reflex;physics;quantum mechanics	ML	19.135133630415947	-69.32090394193686	30795
965c89c2b26914c433112de30a6411f6c509ae55	the hicab cassette, a putative novel, rna-targeting toxin-antitoxin system in archaea and bacteria	ciblage;rna interference;prediccion;modulo;enlace;alignement sequence;discovery note;bacterie;archeen;double stranded rna;comparative genomics;estructura;helix turn helix;resistance;resistance mechanism;bioinformatique;note application;alineacion secuencia;gene cassette;archean;nota aplicacion;resistencia;dna binding domain;liaison;blancado;targeting;rna;family;toxin;scope note;horizontal gene transfer;antitoxine;toxine;toxin antitoxin;sequence alignment;bacteria;bioinformatica;ribbon helix helix;toxina;module;arqueano;prediction;structure;binding;bioinformatics	Toxin-antitoxin systems (TAS) are abundant, diverse, horizontally mobile gene modules that encode powerful resistance mechanisms in prokaryotes. We use the comparative-genomic approach to predict a new TAS that consists of a two-gene cassette encoding uncharacterized HicA and HicB proteins. Numerous bacterial and archaeal genomes encode from one to eight HicAB modules which appear to be highly prone to horizontal gene transfer. The HicB protein (COG1598/COG4226) has a partially degraded RNAse H fold, whereas HicA (COG1724) contains a double-stranded RNA-binding domain. The stable combination of these two domains suggests a link to RNA metabolism, possibly, via an RNA interference-type mechanism. In most HicB proteins, the RNAse H-like domain is fused to a DNA-binding domain, either of the ribbon-helix-helix or of the helix-turn-helix class; in other TAS, proteins containing these DNA-binding domains function as antitoxins. Thus, the HicAB module is predicted to be a novel TAS whose mechanism involves RNA-binding and, possibly, cleavage.	antitoxins;archaea;bacteria;compact cassette;encode (action);gene transfer, horizontal;genome;genome, archaeal;interference (communication);pentalogy of cantrell;prokaryote;rna interference;rna, double-stranded;thermal-assisted switching;cellular targeting	Kira S. Makarova;Nick V. Grishin;Eugene V. Koonin	2006	Bioinformatics	10.1093/bioinformatics/btl418	archean;targeting;module;biology;toxin-antitoxin system;structure;rna;prediction;bacteria;bioinformatics;rna interference;gene cassette;sequence alignment;dna-binding domain;horizontal gene transfer;resistance;comparative genomics;helix-turn-helix;genetics;modulo	Comp.	4.151808353093123	-63.50988606562221	30798
f283e47ae01ad6c8ba3622084f6ef541b1dba4f7	identification of canonical neural events during continuous gameplay of an 8-bit style video game	eeg;pattern classification;reward;salience;transfer learning;video game	Cognitive neuroscience suffers from a unique and pervasive problem of generalizability. Since neural findings are often interpreted in the context of a specific manipulation during a carefully controlled task, it is hard to transfer knowledge from one task to another. In this report we address problems of generalizability with two methodological advancements. First, we aimed to transcend status quo experimental procedures with a continuous, engaging task environment. To this end, we created a novel 8-bit style continuous space shooter video game that elicits a multitude of goal-oriented events, such as crashing into a wall or blowing up an enemy with a missile. Second, we aimed to objectively define the psychological significance of these events. To achieve this aim, we used pattern classification of EEG data to derive predictive weights from carefully controlled pre-game exemplar events (oddball target detection and gambling wins and losses) and transferred those weights to EEG activities during video game events. All major goal-oriented events (crashes into the wall, crashes into an enemy, missile hit on an enemy) had a significant between-task transfer bias towards oddball target weights in the time range of the canonical P3, indicating the presence of similar salience detection processes. Missile hits on an enemy were specifically identified as gambling wins, confirming the hypothesis that this goal-oriented event was appetitive. These findings suggest that it is possible to identify the contribution of canonical neural activities during otherwise ambiguous and uncontrolled task performance.	8-bit;blackjack;cognition disorders;computational neuroscience;download;electroencephalography;experiment;gambling;mental suffering;neuroscience discipline;patients;pervasive informatics;thrombocytopenia;triage;uncontrolled format string;unidentified flying oddball;video games;weight	James F. Cavanagh;Joel Castellanos	2016	NeuroImage	10.1016/j.neuroimage.2016.02.075	psychology;simulation;communication;social psychology	ML	13.16406758813692	-77.39344584367727	30825
2fcb229f4b8c244b17931248ea0ad0ecbc428889	little kevin: a program for the estimation of protein homology by analysing the amino acid compositions and sequences	software;investigation method;secuencia aminoacido;proteine;methode etude;sequence aminoacide;aminoacid sequence;logiciel;computerized processing;tratamiento informatico;computational method;amino acid composition;proteins;molecular weight;metodo estudio;homology;ibm pc compatible;logicial;proteina;homologia;traitement informatique;homologie	We present here a computational method based on the analysis of amino acid composition for performing comparisons between proteins. This user-friendly and reliable test is aimed at rapidly identifying, from data-base subsets, sequences--if necessary, partial sequences--which share similar amino acid compositions to the input composition (deduced from experimental results). Apparent molecular weight (as determined by SDS-PAGE) and artefactual modifications due to the experimental determination of the amino acid composition are taken into account to perform the comparison. This program thus constitutes a useful tool in searching for the probable identification of either non-sequenced proteins or peptides from hydrolysed proteins.	amino acids;composition;database;homologous gene;homology (biology);molecular weight;polyacrylamide gel electrophoresis;probability;sds-page;usability	Joël-Paul Grillasca;Denis Aubert;Richard Planells;N. Domingo;H. Lafont	1996	Computer applications in the biosciences : CABIOS	10.1093/bioinformatics/12.4.347	biology;biochemistry;homology;computer science;bioinformatics;ibm pc compatible;molecular mass;algorithm	Comp.	-4.112237218566864	-56.07220767133052	30835
587653afa36ded9cb33c9af197dcfe8a29841622	computational analysis of the cathepsin b inhibitors activities through lr-mmpbsa binding affinity calculation based on docked complex	pubchem;biological assay;binding sites;models chemical;cathepsin b protein;virtual screening;regression;structure activity relationship;drug design;cysteine proteinase inhibitors;cathepsin b;binding affinity;computer analysis;databases factual;modeling;free energy of binding;computer simulation	Cathepsin B, a ubiquitous lysosomal cysteine protease, is involved in many biological processes related to several human diseases. Inhibitors targeting the enzyme have been investigated as possible diseases treatments. A set of 37 compounds were recently found active in a high throughput screening assay to inhibit the catalytic activity of Cathepsin B, with chemical structures and biological test results available to the public in the PubChem BioAssay Database (AID 820). In this study, we compare these experimental activities to the results of theoretical predictions from binding affinity calculation with a LR-MM-PNSA approach based on docked complexes. Strong correlations (r(2) = 0.919 and q(2) = 0.887 for the best) are observed between the theoretical predictions and experimental biological activity. The models are cross-validated by four independent predictive experiments with randomly split compounds into training and test sets. Our results also show that the results based on protein dimer show better correlations with experimental activity when compared to results based on monomer in the in silico calculations.		Zhigang Zhou;Yanli Wang;Stephen H. Bryant	2009	Journal of computational chemistry	10.1002/jcc.21214	computer simulation;biochemistry;cathepsin b;structure–activity relationship;systems modeling;chemistry;regression;pubchem;virtual screening;binding site;combinatorial chemistry;computational chemistry;bioassay;ligand;drug design	Comp.	10.022762388010463	-58.4032788979289	30840
646a7487da3cb55b785c613b39a6ba36eeafee4f	deep learning models of the retinal response to natural scenes		A central challenge in sensory neuroscience is to understand neural computations and circuit mechanisms that underlie the encoding of ethologically relevant, natural stimuli. In multilayered neural circuits, nonlinear processes such as synaptic transmission and spiking dynamics present a significant obstacle to the creation of accurate computational models of responses to natural stimuli. Here we demonstrate that deep convolutional neural networks (CNNs) capture retinal responses to natural scenes nearly to within the variability of a cell's response, and are markedly more accurate than linear-nonlinear (LN) models and Generalized Linear Models (GLMs). Moreover, we find two additional surprising properties of CNNs: they are less susceptible to overfitting than their LN counterparts when trained on small amounts of data, and generalize better when tested on stimuli drawn from a different distribution (e.g. between natural scenes and white noise). An examination of the learned CNNs reveals several properties. First, a richer set of feature maps is necessary for predicting the responses to natural scenes compared to white noise. Second, temporally precise responses to slowly varying inputs originate from feedforward inhibition, similar to known retinal mechanisms. Third, the injection of latent noise sources in intermediate layers enables our model to capture the sub-Poisson spiking variability observed in retinal ganglion cells. Fourth, augmenting our CNNs with recurrent lateral connections enables them to capture contrast adaptation as an emergent property of accurately describing retinal responses to natural scenes. These methods can be readily generalized to other sensory modalities and stimulus ensembles. Overall, this work demonstrates that CNNs not only accurately capture sensory circuit responses to natural scenes, but also can yield information about the circuit's internal structure and function.	acclimatization;artificial neural network;computation;computational model;convolutional neural network;deep learning;emergence;feedforward neural network;ganglion cell;generalized linear model;heart rate variability;ibm notes;lateral thinking;map;neural network simulation;neuroscience discipline;nonlinear programming;nonlinear system;overfitting;retina;retinal ganglion cells;sensory neuroscience;spatial variability;spiking neural network;synaptic package manager;synaptic transmission;white noise;anatomical layer	Lane McIntosh;Niru Maheswaranathan;Aran Nayebi;Surya Ganguli;Stephen Baccus	2016	Advances in neural information processing systems		computer vision;computer science;machine learning	ML	19.678077310710535	-69.40835157976505	30872
cb0bad2d3560470a3525a29e5bf978292a8c36ce	collective cell motion in an epithelial sheet can be quantitatively described by a stochastic interacting particle model	cell movement;madin darby canine kidney cells;velocity;animals;simulation and modeling;cell cycle and cell division;dogs;epithelium;models biological;classical mechanics;motion;stochastic processes;approximation methods;computer simulation;autocorrelation;epithelial cells	"""Modelling the displacement of thousands of cells that move in a collective way is required for the simulation and the theoretical analysis of various biological processes. Here, we tackle this question in the controlled setting where the motion of Madin-Darby Canine Kidney (MDCK) cells in a confluent epithelium is triggered by the unmasking of free surface. We develop a simple model in which cells are described as point particles with a dynamic based on the two premises that, first, cells move in a stochastic manner and, second, tend to adapt their motion to that of their neighbors. Detailed comparison to experimental data show that the model provides a quantitatively accurate description of cell motion in the epithelium bulk at early times. In addition, inclusion of model """"leader"""" cells with modified characteristics, accounts for the digitated shape of the interface which develops over the subsequent hours, providing that leader cells invade free surface more easily than other cells and coordinate their motion with their followers. The previously-described progression of the epithelium border is reproduced by the model and quantitatively explained."""	color gradient;displacement mapping;kidney diseases;psychologic displacement;renal tissue;simulation;stochastic process;xenforo	Néstor Sepúlveda;Laurence Petitjean;Olivier Cochet;Erwan Grasland-Mongrain;Pascal Silberzan;Vincent Hakim	2013		10.1371/journal.pcbi.1002944	computer simulation;simulation;autocorrelation;epithelium;motion;velocity;statistics	Graphics	10.946991446648106	-67.80353731174446	30884
db0355f5d175bf4ce824d6915d8aab2a4dd9e584	the effect of intracortical competition on the formation of topographic maps in models of hebbian learning	second order;hebbian learning;learning model;topographic map;spatial correlation;self organized map;receptive field	Correlation-based learning (CBL) models and self-organizing maps (SOM) are two classes of Hebbian models that have both been proposed to explain the activity-driven formation of cortical maps. Both models differ significantly in the way lateral cortical interactions are treated, leading to different predictions for the formation of receptive fields. The linear CBL models predict that receptive field profiles are determined by the average values and the spatial correlations of the second order of the afferent activity patterns, wheras SOM models map stimulus features. Here, we investigate a class of models which are characterized by a variable degree of lateral competition and which have the CBL and SOM models as limit cases. We show that there exists a critical value for intracortical competition below which the model exhibits CBL properties and above which feature mapping sets in. The class of models is then analyzed with respect to the formation of topographic maps between two layers of neurons. For Gaussian input stimuli we find that localized receptive fields and topographic maps emerge above the critical value for intracortical competition, and we calculate this value as a function of the size of the input stimuli and the range of the lateral interaction function. Additionally, we show that the learning rule can be derived via the optimization of a global cost function in a framework of probabilistic output neurons which represent a set of input stimuli by a sparse code.	class;composite blocking list;exhibits as topic;hebbian theory;interaction;lateral computing;lateral thinking;learning rule;loss function;mathematical optimization;neural coding;normal statistical distribution;organizing (structure);self-organization;self-organizing map;sparse matrix;topography;anatomical layer	Christian Piepenbrock;Klaus Obermayer	2000	Biological Cybernetics	10.1007/s004220050588	psychology;topographic map;spatial correlation;neuroscience;hebbian theory;artificial intelligence;machine learning;mathematics;communication;receptive field;second-order logic	ML	20.21037696627381	-68.19608117314735	30903
e73a13e694db27067e9cf363a8ed17c737548cef	protein secondary structure prediction using data mining tool c5	biology computing;data mining tool;sequence homology;linear amino acid sequence;molecular configurations;machine learning software;protein molecule;tellurium;data mining protein engineering biochemistry amino acids nuclear magnetic resonance tellurium testing crystallography coils read only memory;nuclear magnetic resonance;testing;data mining;protein secondary structure;proteins;machine learning;coils;protein secondary structure prediction;secondary structure;prediction accuracy;amino acids;knowledge discovery in database;training cases;proteins data mining biology computing molecular configurations;linear amino acid sequence protein secondary structure prediction data mining tool c5 machine learning software training cases sequence homology predictive accuracy machine learning knowledge discovery protein molecule tertiary structure 3d structure;crystallography;3d structure;read only memory;protein engineering;biochemistry;predictive accuracy;tertiary structure;knowledge discovery	This paper reports our experimental results in protein secondary structure prediction using a machine learning software C5. Accuracy improvement in prediction of protein secondary structure is the focus of our study. Starting with a target protein with unknown secondary structures, we investigate three different approaches and find that training cases selected based on sequence homology can achieve the highest predictive accuracy of 75% in testing cases. Our result indicates that how to select proteins for the training cases has the most significant impact on predictive accuracy.	data mining;machine learning;protein structure prediction;sequence homology	Meiliu Lu;Du Zhang;Hongjun Xu;Ken Tse-yau Lau;Li Lu	1999		10.1109/TAI.1999.809774	computer science;bioinformatics;data science;machine learning;knowledge extraction;protein secondary structure	ML	10.82015759475583	-54.96543786365413	30940
a7fe96644e725bf9d61fb197a17cd536aff165e3	behavioural biometrics: utilizing eye-tracking to generate a behavioural pin using the eyewriter		Biometric technology allows a computer system to identify and authenticate a person directly based on physical or behavioural traits. A human body is absolutely unique. Each human body on earth, if measured by composition on molecular level, is so unique, that the particular composition has never existed before. When that human cease to exist, that unique composition will never exist again. However the ability to measure a human to a molecular level of accuracy is not currently possible with existing technology. Biometrics refers to the science and technology that measure and statistically analyse human body characteristics and biological data. DNA, fingerprints, eye retinas and irises, facial patterns and hand geometry are used for biometric for authentication purposes. Apart from having unique physical traits, all human also exhibit unique behavioural traits. The way that a person talks, or the way that a person walks (a person’s gait) can all assist in the identification of the person. Various research projects focused on the way that a person types a password. This behavioural trait can then be used to strengthen the security of a supplied password. This paper reports on research that investigates the uniqueness of eye movement. The way a person creates a pin, using his or her eyes are used as a behavioural biometric to strengthen the pin that is supplied. Eye tracking technology usually involves costly equipment such as the Tobii eye tracking system. For this research the Eyewriter system is used due to the affordability and the open source nature of the Eyewriter hardware and software. Earlier research concluded that the movement of a human eye is unique. Behavioural eye biometrics can be used to authenticate a human in a one to one match environment.	biometrics;eye tracking	Bobby L. Tait	2015		10.1007/978-3-319-23276-8_31	trait;password;computer vision;uniqueness;hand geometry;biological data;computer science;eye tracking;biometrics;authentication;artificial intelligence	NLP	-0.9366297994472191	-71.68692121167706	30944
07bb2b5fcae25ef1c7c161e554813d91482b7a0b	stochastic generator of chemical structure. 1. application to the structure elucidation of large molecules	structure elucidation;chemical structure			Jean-Loup Faulon	1994	Journal of Chemical Information and Computer Sciences	10.1021/ci00021a031	chemistry;organic chemistry;chemical structure	Vision	2.755271403580951	-64.73852131110122	30979
dec8c8748f6d576635ebf471c8c9e154f510ec9b	towards an integrative human pathway database for systems biology applications	data integrity;signaling pathways;cell differentiation;data model;data warehousing;system biology;cell growth;signaling pathway;bio molecular pathway;energy metabolism;data integration	While there are more than 217 online pathway databases of different coverage and quality as of September 2007, our knowledge of human pathways is still far from complete. It has been challenging to develop pathway tools and database resources that could expand the coverage of existing annotated pathway data by integrating these resources both at the syntactic and semantic levels. While developing the Human Pathway Database (HPD), we use data warehousing techniques and a unified pathway data model to integrate a total of 1,895 pathways and 10,631 molecular entities from four different annotated and predicted pathway resources in human. HPD provides a comprehensive and integrated view linking human proteins, genes, RNAs, signaling reactions, gene regulatory events for future systems biology applications. We studied pathways in the database for their merging potentials and showed a preliminary pathway merging result as 2-D clusters. We also examined pathway scale and the distribution of pathway-spanning proteins, pathway characteristics that suggest small pathways and large pathways may still be under-represented in the HPD. We also found many proteins with important energy metabolism, cell growth, and cell differentiation functions span across vast number of pathways. The raw data for HPD can be queried at: http://discover.uits.indiana.edu:8340/spathway/s_pathway/	data model;database;entity;file spanning;gene regulatory network;systems biology	Harini N. Kasamsetty;Xiaogang Wu;Jake Yue Chen	2008		10.1145/1363686.1363986	biopax : biological pathways exchange;small molecule pathway database;computer science;bioinformatics;data science;biological pathway;data warehouse;data mining;database;systems biology;signal transduction	Comp.	-4.295593100318575	-63.35706145807928	30988
61728109d49b965401ab2ce51fa9a8fdb286aaa1	rocs: a reproducibility index and confidence score for interaction proteomics studies	probability;confidence intervals;mass spectrometry;computational biology bioinformatics;proteins;chromatography affinity;reproducibility of results;algorithms;combinatorial libraries;protein interaction mapping;proteomics;computer appl in life sciences;microarrays;bioinformatics	Affinity-Purification Mass-Spectrometry (AP-MS) provides a powerful means of identifying protein complexes and interactions. Several important challenges exist in interpreting the results of AP-MS experiments. First, the reproducibility of AP-MS experimental replicates can be low, due both to technical variability and the dynamic nature of protein interactions in the cell. Second, the identification of true protein-protein interactions in AP-MS experiments is subject to inaccuracy due to high false negative and false positive rates. Several experimental approaches can be used to mitigate these drawbacks, including the use of replicated and control experiments and relative quantification to sensitively distinguish true interacting proteins from false ones. To address the issues of reproducibility and accuracy of protein-protein interactions, we introduce a two-step method, called ROCS, which makes use of Indicator Prey Proteins to select reproducible AP-MS experiments, and of Confidence Scores to select specific protein-protein interactions. The Indicator Prey Proteins account for measures of protein identifiability as well as protein reproducibility, effectively allowing removal of outlier experiments that contribute noise and affect downstream inferences. The filtered set of experiments is then used in the Protein-Protein Interaction (PPI) scoring step. Prey protein scoring is done by computing a Confidence Score, which accounts for the probability of occurrence of prey proteins in the bait experiments relative to the control experiment, where the significance cutoff parameter is estimated by simultaneously controlling false positives and false negatives against metrics of false discovery rate and biological coherence respectively. In summary, the ROCS method relies on automatic objective criterions for parameter estimation and error-controlled procedures. We illustrate the performance of our method by applying it to five previously published AP-MS experiments, each containing well characterized protein interactions, allowing for systematic benchmarking of ROCS. We show that our method may be used on its own to make accurate identification of specific, biologically relevant protein-protein interactions, or in combination with other AP-MS scoring methods to significantly improve inferences. Our method addresses important issues encountered in AP-MS datasets, making ROCS a very promising tool for this purpose, either on its own or in conjunction with other methods. We anticipate that our methodology may be used more generally in proteomics studies and databases, where experimental reproducibility issues arise. The method is implemented in the R language, and is available as an R package called “ROCS”, freely available from the CRAN repository http://cran.r-project.org/ .	database;downstream (software development);estimation theory;experiment;flaming (internet);heart rate variability;ms-dos;pixel density;population parameter;prey;proteomics;proton pump inhibitors;purification of quantum state;quantitation;r language;replication (computing);scientific publication;score;protein protein interaction	Jean-Eudes J. Dazard;Sudipto Saha;Rob M. Ewing	2011		10.1186/1471-2105-13-128	biology;confidence interval;dna microarray;mass spectrometry;computer science;bioinformatics;probability;proteomics	Comp.	4.640315616881426	-54.446556703002685	31002
2c291c9a916c0417edab992ab4988adbe89c81c7	neural computations in the tiger salamander and mudpuppy outer retinae and an analysis of gaba action from horizontal cells	neural network	 A neural network architecture based on the neural anatomy and function of retinal neurons in tiger salamander and mudpuppy retinae is proposed to study basic aspects of early visual information processing. The model predictions for the main response characteristics of retinal neurons are found to be in agreement with neurophysiological data, including the antagonistic role of horizontal cells in the outer plexiform layer. The examination of possible γ-aminobutyric acid (GABA) action from horizontal cells suggests that GABAA alone, GABAB alone, or their weighted combination can generate the response characteristics observed in bipolar cells.	anatomic structures;artificial neural network;biological neural networks;computation;computational neuroscience;information processing;necturus;network architecture;retina;retinal neurons;thioctic acid;tiger team;tigers;gamma-aminobutyric acid	Simon X. Yang;Haluk Ögmen;Greg Maguire	2003	Biological Cybernetics	10.1007/s00422-003-0398-6	neuroscience;communication	ML	18.64940116221669	-71.87662616032658	31011
0127aa9273f67a2046e7d9c0eface9899e2369eb	ales: cell lineage analysis and mapping of developmental events	operating system;cell lineage;gene expression pattern	MOTIVATION Animals build their bodies by altering the fates of cells. The way in which they do so is reflected in the topology of cell lineages and the fates of terminal cells. Cell lineages should, therefore, contain information about the molecular events that determined them. Here we introduce new tools for visualizing, manipulating, and extracting the information contained in cell lineages. Our tools enable us to analyze very large cell lineages, where previously analyses have only been carried out on cell lineages no larger than a few dozen cells.   RESULTS Ales (A Lineage Evaluation System) allows the display, evaluation and comparison of cell lineages with the aim of identifying molecular and cellular events underlying development. Ales introduces a series of algorithms that locate putative developmental events. The distribution of these predicted events can then be compared to gene expression patterns or other cellular characteristics. In addition, artificial lineages can be generated, or existing lineages modified, according to a range of models, in order to test hypotheses about lineage evolution.   AVAILABILITY The program can run on any operating system with a compliant Java 2 environment. Ales is free for academic use and can be downloaded from http://mbi.dkfz-heidelberg.de/mbi/research/cellsim/ales.	anatomy, regional;compliance behavior;contain (action);gene expression programming;java programming language;java version history;large;lineage (evolution);operating system;ale beer;algorithm	Volker Braun;Ricardo B. R. Azevedo;Markus Gumbel;Paul-Michael Agapow;Armand M. Leroi;Hans-Peter Meinzer	2003	Bioinformatics	10.1093/bioinformatics/btg087	biology;computer science;bioinformatics;genetics	Comp.	-2.0735996819133184	-56.655179937147096	31065
21672cf034717b030c8c029ae0a26add527069ad	image preprocessing with dynamic synapses	vlsnn;snn;espiga positiva;objet;filtering;effective connectivity;filtrage;time scale;stimulus;estimulo;echelle temps;potentiel postsynaptique;comportement;image processing;tree;x ray imaging;dynamique;potentiel;arbol;filtrado;influencia;very large scale spiking neural network;procesamiento imagen;response;object;hombre;time;image bruitee;potencial postsinaptico;traitement image;imagen rx borrosa;potential;informacion;dinamica;dynamical system;algorithme;pointe positive;imagen sonora;systeme dynamique;influence;spike;algorithm;spiking neural network;sinapsis;image rayon x;temps;conducta;dynamics;synaptic plasticity;conexion;noisy image;flou image rx;escala tiempo;raccordement;human;palabra;arbre;reponse;word;plasticite synaptique;potencial;respuesta;intencion;sistema dinamico;reseau neuronal;behavior;x ray image unsharpness;plasticidad sinaptica;connection;objeto;red neuronal;information;intention;variable;postsynaptic potential;mot;homme;neural network;x ray image;tiempo;algoritmo;synapse	Different algorithms suitable for a specific class of picture were developed for image processing. We will represent the filtering capability of a spiking neural network based on dynamic synapses. For this intention we chose an x-ray image of the human coronary trees and another noisy image. In other words the task at hand is to show how accurately such a network is able to store various aspects (object/background) of stimulus in the variables which describe dynamic of synaptic response. The behavior of these synapses influences the effective connection in the network in a short time-scale. Such a network has a low activity and a balanced behavior. Dynamic synapses are able to adjust their behavior by fast changing stimuli. These synapses retain the information in the variables, such as potential and time.	algorithm;artificial neural network;edge detection;electronic circuit;gene regulatory network;grayscale;image processing;preprocessor;radiography;selectivity (electronic);simulation;spiking neural network;synapse	Nasser Mehrtash;Dietmar Jung;Heinrich Klar	2003	Neural Computing & Applications	10.1007/s00521-030-0371-2	potential;image processing;computer science;artificial intelligence;mathematics;artificial neural network;spiking neural network	ML	21.219806281340798	-70.43180909412783	31106
ac0f2b58366b05382ece35cf8495c64a7858f671	fastchi: an efficient algorithm for analyzing gene-gene interactions	genome wide association study;chi square test;permutation test;biometry;family wise error rate;upper bound;phenotype;algorithms;chi square distribution;high throughput	Recent advances in high-throughput genotyping have inspired increasing research interests in genome-wide association study for diseases. To understand underlying biological mechanisms of many diseases, we need to consider simultaneously the genetic effects across multiple loci. The large number of SNPs often makes multilocus association study very computationally challenging because it needs to explicitly enumerate all possible SNP combinations at the genome-wide scale. Moreover, with the large number of SNPs correlated, permutation procedure is often needed for properly controlling family-wise error rates. This makes the problem even more computationally demanding, since the test procedure needs to be repeated for each permuted data. In this paper, we present FastChi, an exhaustive yet efficient algorithm for genome-wide two-locus chi-square test. FastChi utilizes an upper bound of the two-locus chi-square test, which can be expressed as the sum of two terms--both are efficient to compute: the first term is based on the single-locus chi-square test for the given phenotype; and the second term only depends on the genotypes and is independent of the phenotype. This upper bound enables the algorithm to only perform the two-locus chi-square test on a small number of candidate SNP pairs without the risk of missing any significant ones. Since the second part of the upper bound only needs to be precomputed once and stored for subsequence uses, the advantage is more prominent in large permutation tests. Extensive experimental results demonstrate that our method is an order of magnitude faster than the brute force alternative.	algorithm;brute-force search;chi-square test;enumerated type;genotype determination;high-throughput computing;inspiration function;locus;nitroprusside;precomputation;resampling (statistics);snp annotation;single nucleotide polymorphism;throughput;interest	Xiang Zhang;Fei Zou;Wei Wang	2009	Pacific Symposium on Biocomputing. Pacific Symposium on Biocomputing		genome-wide association study;high-throughput screening;biology;chi-square test;familywise error rate;resampling;bioinformatics;phenotype;mathematics;upper and lower bounds;chi-squared distribution;biostatistics;genetics;statistics	Comp.	2.592563058015401	-53.03949206748612	31163
8a297839f4d1cfca09481973c67c53657e86c6c8	studies on the interactions between β2 adrenergic receptor and gs protein by molecular dynamics simulations	null	The β2 adrenergic receptor (β2AR) plays a key role in the control of smooth muscle relaxation in airways, the therapy of asthma, and a series of other basic physiological functions. Recently, the crystal structure of the β2AR-Gs protein complex was reported, which facilitates study of the activation mechanism of the β2AR and G-protein-coupled receptors (GPCRs). In this work, we perform 20 ns molecular dynamics (MD) simulations of the β2AR-Gs protein complex with its agonist in an explicit lipid and water environment to investigate the activation mechanism of β2AR. We find that during 20 ns MD simulation with a nanobody bound the interaction between the β2AR and the Gs protein is stable and the whole system is equilibrated within 6 ns. However, without a nanobody stabilizing the complex, the agonist triggers conformational changes of β2AR sequentially from the extracellular region to the intracellular region, especially the intracellular parts of TM3, TM5, TM6, and TM7, which directly interact with the Gs protein. Our results show that the β2AR-Gs protein complex makes conformational changes in the following sequence: (1) an agonist-bound part of β2AR, (2) the intracellular region of β2AR, and (3) the Gs protein.		Zhiwei Feng;Tingjun Hou;Youyong Li	2012	Journal of chemical information and modeling	10.1021/ci200594d	bioinformatics;extracellular;molecular dynamics;agonist;intracellular;g protein-coupled receptor;gs alpha subunit;receptor;adrenergic receptor;chemistry	Comp.	8.8328391308544	-62.97198424515689	31173
a7cf6f4bf2f9fb4a15aa8f85f021400a51cb57ae	neural correlates of fixation duration in natural reading: evidence from fixation-related fmri		A key assumption of current theories of natural reading is that fixation duration reflects underlying attentional, language, and cognitive processes associated with text comprehension. The neurocognitive correlates of this relationship are currently unknown. To investigate this relationship, we compared neural activation associated with fixation duration in passage reading and a pseudo-reading control condition. The results showed that fixation duration was associated with activation in oculomotor and language areas during text reading. Fixation duration during pseudo-reading, on the other hand, showed greater involvement of frontal control regions, suggesting flexibility and task dependency of the eye movement network. Consistent with current models, these results provide support for the hypothesis that fixation duration in reading reflects attentional engagement and language processing. The results also demonstrate that fixation-related fMRI provides a method for investigating the neurocognitive bases of natural reading.	base;eye movements;neural correlates of consciousness;pseudo brand of pseudoephedrine;theory;emotional dependency;fmri;neurocognitive	John M. Henderson;Wonil Choi;Steven G. Luke;Rutvik H. Desai	2015	NeuroImage	10.1016/j.neuroimage.2015.06.072	psychology;cognitive psychology;developmental psychology;communication	AI	15.848315531888458	-77.4173046395999	31273
00d751c11cf2390626d051bcbda4a70cb9355a38	visualization and virtual screening of the chemical universe database gdb-17	biology;570 life sciences;540 chemistry	"""The chemical universe database GDB-17 contains 166.4 billion molecules of up to 17 atoms of C, N, O, S, and halogens obeying rules for chemical stability, synthetic feasibility, and medicinal chemistry. GDB-17 was analyzed using 42 integer value descriptors of molecular structure which we term """"Molecular Quantum Numbers"""" (MQN). Principal component analysis and representation of the (PC1, PC2)-plane provided a graphical overview of the GDB-17 chemical space. Rapid ligand-based virtual screening (LBVS) of GDB-17 using the city-block distance CBD(MQN) as a similarity search measure was enabled by a hashed MQN-fingerprint. LBVS of the entire GDB-17 and of selected subsets identified shape similar, scaffold hopping analogs (ROCS > 1.6 and T(SF) < 0.5) of 15 drugs. Over 97% of these analogs occurred within CBD(MQN) ≤ 12 from each drug, a constraint which might help focus advanced virtual screening. An MQN-searchable 50 million subset of GDB-17 is publicly available at www.gdb.unibe.ch ."""	analog;chemical space;fingerprint;frequency-hopping spread spectrum;graphical user interface;halogens;medicinal chemistry;obedience (human behavior);principal component analysis;quantum number;rule (guideline);similarity search;subgroup;surface hopping;synthetic intelligence;taxicab geometry;virtual screening	Lars Ruddigkeit;Lorenz C. Blum;Jean-Louis Reymond	2013	Journal of chemical information and modeling	10.1021/ci300535x	biology;chemistry;computer science;bioinformatics;organic chemistry;combinatorial chemistry;computational chemistry;mathematics;physics	Comp.	0.3555846278575858	-60.946123145982135	31308
a6c2dac94852dc0602413de248e9f5909b9dfe2a	a scalable approach for inferring transcriptional regulation in the yeast cell cycle	transcriptional regulation;saccharomyces cerevisiae;large dataset;gene regulation;transcription factor binding site;binding site;gene expression data;dynamic bayesian networks;genetics;transcription regulation;dynamic bayesian network;protein protein interaction;binding site data;cell cycle;microarray;high throughput;protein protein interaction data	The high complexity in the gene regulation mechanism and the prevalent noise in high-throughput detection experiments are considered to be the two major obstacles in discovering transcriptional regulation with high accuracy from experimental gene expression data. In this paper, we study a model based on dynamic Bayesian networks to predict gene regulation by integrating transcription factor binding site data and proteinprotein interaction data with gene expression data. The knowledge of genetic interactions between proteins and the presence of transcription factors binding site at the promoter region of a gene have been used to restrict the number of potential regulators of each gene. We show the effectiveness of combining multiple data sources in the prediction of transcriptional regulation through the analysis of Saccharomyces cerevisiae (Yeast) cell cycle data. Experiments conducted on real microarray datasets show that the proposed model is significantly more efficient and topologically more accurate compared to other existing models based on dynamic Bayesian networks. We also demonstrate the scalability of the proposed model through the analysis of a large dataset with a sustainable performance level.	cell (microprocessor);dna binding site;dynamic bayesian network;experiment;high-throughput computing;interaction;microarray;scalability;throughput;transcription (software)	Akther Shermin;Hasan M. Jamil;Mehmet A. Orgun	2011		10.1145/2147805.2147848	biology;molecular biology;bioinformatics;genetics	Comp.	4.875175332484634	-58.259932365107396	31319
9d132f7af2d176646f0dc649364f130acc745d68	application of w-curves and tsp to clustering hiv-1 sequences by epitope		The high mutation rate in HIV-1 makes it difficult to treat and analyze. Monitoring the evolution of drug resistance requires frequent resequencing, but comparing and visualizing the progress is difficult. One difficulty is simply locating the areas of interest: gaps and crossover mutations make it difficult to isolate clinically significant sequences for comparison. Effectively displaying the results of comparisons grouped according to multiple regions is also a problem. Our comparison algorithm based on the W-curve helps automate the comparison process, producing results suitable for clustering via a modified solution to the Traveling Salesman Problem (“TSP”). Appropriate colorcoding of the TSP results allows us to display the results of multiple comparisons effectively for single samples or time-series. The results can be useful for providing guidance in treatment, analyzing the membership in anonymous study populations, tracking the evolution of drug resistance in populations, or rates of co-infection within study groups.	algorithm;cluster analysis;population;time series;travelling salesman problem	Douglas Cork;Steven Lembark;Sodsai Tovanabutra;Eric Sanders-Buell;Bruce Brown;Merlyn Robb;Lindsay Wieczorek;Victoria Polonis;Nelson L Michael;Jerome H. Kim	2010			cluster analysis;mathematics;epitope;bioinformatics	Comp.	2.535134764461287	-54.810829079842286	31333
240593e61943a77f08fc697e767fbc3139dc3425	the graph of cellular automata applied for modelling tumour induced angiogenesis		Angiogenesis is the process of formation of vascular network. Blocking tumour induced angiogenesis is one of the treatments applied in oncology. Research involving computer simulations looking for the rules influencing the structure of vascular network and its functionality. This paper summarizes the applications of Graph of Cellular Automata modelling tool, developed by the Author, for modelling Tumour Induced Angiogenesis. Vascular network which is modelled by the graph interacts with surrounding tissue represented by the lattice of automata. The network is developed and reorganized accordingly to locally acting factors (stimulators and inhibitors). The model includes blood flow calculations in a modelled vascular network.	cellular automaton	Pawel Topa	2013		10.1007/978-3-642-55195-6_67	complex system;cellular automaton;distributed computing;angiogenesis;graph;computer science	Logic	6.0533106788377085	-67.78598549540953	31335
13464ecd0431c8db335337e7bd86e256d7e9cf01	a predictive model for the early identification of patients at risk for a prolonged intensive care unit length of stay	external validity;female;health informatics;outcome and process assessment health care;mechanical ventilation;multivariate analysis;intensive care unit;retrospective studies;data collection;male;information systems and communication service;resource use;information gathering;length of stay;intensive care units;risk factors;respiration artificial;management of computing and information systems;humans;prediction model;linear models;prognosis;multivariate regression;cohort studies;cohort study	BACKGROUND Patients with a prolonged intensive care unit (ICU) length of stay account for a disproportionate amount of resource use. Early identification of patients at risk for a prolonged length of stay can lead to quality enhancements that reduce ICU stay. This study developed and validated a model that identifies patients at risk for a prolonged ICU stay.   METHODS We performed a retrospective cohort study of 343,555 admissions to 83 ICUs in 31 U.S. hospitals from 2002-2007. We examined the distribution of ICU length of stay to identify a threshold where clinicians might be concerned about a prolonged stay; this resulted in choosing a 5-day cut-point. From patients remaining in the ICU on day 5 we developed a multivariable regression model that predicted remaining ICU stay. Predictor variables included information gathered at admission, day 1, and ICU day 5. Data from 12,640 admissions during 2002-2005 were used to develop the model, and the remaining 12,904 admissions to internally validate the model. Finally, we used data on 11,903 admissions during 2006-2007 to externally validate the model.   RESULTS The variables that had the greatest impact on remaining ICU length of stay were those measured on day 5, not at admission or during day 1. Mechanical ventilation, PaO2: FiO2 ratio, other physiologic components, and sedation on day 5 accounted for 81.6% of the variation in predicted remaining ICU stay. In the external validation set observed ICU stay was 11.99 days and predicted total ICU stay (5 days + day 5 predicted remaining stay) was 11.62 days, a difference of 8.7 hours. For the same patients, the difference between mean observed and mean predicted ICU stay using the APACHE day 1 model was 149.3 hours. The new model's r2 was 20.2% across individuals and 44.3% across units.   CONCLUSIONS A model that uses patient data from ICU days 1 and 5 accurately predicts a prolonged ICU stay. These predictions are more accurate than those based on ICU day 1 data alone. The model can be used to benchmark ICU performance and to alert physicians to explore care alternatives aimed at reducing ICU stay.	benchmark (computing);coronary care units;hospital admission;mechanical ventilation;oxygen measurement, partial pressure, arterial;patients;predictive modelling;respiration;sedation procedure;intensive care unit	Andrew A. Kramer;Jack E. Zimmerman	2010		10.1186/1472-6947-10-27	health informatics;intensive care medicine;medicine;cohort study;emergency medicine;medical emergency;statistics	HCI	6.525842503585898	-75.10902846471726	31368
2a92a98238c0397256b4b541f1e42a74a788f881	application of artificial neural network in the diagnostic system of osteoporosis	diagnostic system;logistic regression;osteoporosis;x ray;artificial neural network	In order to achieve a diagnosis system of osteoporosis with the assistance of a network, an artificial neural network model is established and applied. We extract features through the observation of X-ray images and clinical main symptoms from patients with osteoporosis by three experienced orthopedists and three experienced radiologists and score the features related to osteoporosis according to the quantified standard. Then parts of patients are selected randomly as the training set and the rest is regarded as the prediction set. Input score results and biochemical parameters are related to osteoporosis. The prediction results of all samples are compared with the predicted results of logistic regression. Diagnostic results of the artificial neural network model are compared with the results of logistic regression. The sensitivities are 94.5% and 63.6%, respectively. The specificities are 96.9% and 87.5%, respectively. The area under the receiver operating characteristic curve of the artificial neural network (0.950) is larger than that of logistic regression (0.870), P=0.034. The results of this study show that the artificial neural network is effective in the diagnostic system of osteoporosis.	artificial neural network	Xinghu Yu;Chao Ye;Liangbi Xiang	2016	Neurocomputing	10.1016/j.neucom.2016.06.023	econometrics;computer science;machine learning;logistic regression;artificial neural network	AI	7.03448035641492	-76.57090625723914	31390
780bfa0bf67c3bc4314abd37cfc546a0bb1a9177	on the correlation of chaotic signals generated by multimodal skew tent map		In recent years, a great deal of attention has been devoted to the application of chaos theory in signal processing and communications. Despite the importance of spectral analysis in these domains, there are few works that take an interest in spectral properties of chaotic signals. In this work, we derive analytic expressions for the autocorrelation function and the auto-spectral density function of chaotic signals generated by a multimodal skew tent map. Our results reveal that chaotic signals generated from a multimodal skew tent map have similar spectral properties to those generated from a unimodal skew tent map.	multimodal interaction;tent map	Ahmed Sahnoune;Daoud Berkani	2018	Signal, Image and Video Processing	10.1007/s11760-018-1279-8	probability density function;signal processing;artificial intelligence;chaos theory;autocorrelation;skew;expression (mathematics);tent map;mathematics;pattern recognition;correlation	Robotics	20.542358443100625	-61.75889956299694	31423
c159de644d8daaef0d7268f5944e2bc2da18838e	mining echocardiography workflows for disease discriminative patterns	data mining;echocardiography;workflow;pattern recognition automated;humans;diagnosis	OBJECTIVE To provide quick diagnostic insights to medical practitioners into echocardiograms by only analyzing the echocardiogram workflows (defined as the sequence of modalities examined).   METHODS We define a dictionary of workflows, called subflows, which are commonly encountered in echocardiography workflows but are mutually exclusive. We represent each workflow as a mixture of dictionary subflows and learn discriminative models for various cardiac diseases using Support Vector Machines. Using these discriminative models, we can predict occurrences of diseases for any, yet unseen, echocardiogram workflow.   RESULTS Working with a corpus of 2300 echocardiograms workflows, we build a dictionary of 172 subflows. Using the associated reports (expert created) we identify the ground-truth diagnoses. We then build discriminative models for 7 different cardiac diseases. Using just the workflow as input, these models can predict diseases on average with over 75% accuracy.   CONCLUSIONS Mining collection of echocardiography workflows, for the first time, we are able to predict diseases without even looking at the image contents.		Ritwik Kumar;Tanveer F. Syeda-Mahmood;David Beymer;Colin B. Compas;Karen Brannon	2013	AMIA ... Annual Symposium proceedings. AMIA Symposium		medicine;bioinformatics;data science;data mining	Arch	3.6375301913454354	-73.67594014167145	31438
e9d4486ee9e8a16da7250d7be0232af5b3a71388	recurrently connected and localized neuronal communities initiate coordinated spontaneous activity in neuronal networks		Developing neuronal systems intrinsically generate coordinated spontaneous activity that propagates by involving a large number of synchronously firing neurons. In vivo, waves of spikes transiently characterize the activity of developing brain circuits and are fundamental for activity-dependent circuit formation. In vitro, coordinated spontaneous spiking activity, or network bursts (NBs), interleaved within periods of asynchronous spikes emerge during the development of 2D and 3D neuronal cultures. Several studies have investigated this type of activity and its dynamics, but how a neuronal system generates these coordinated events remains unclear. Here, we investigate at a cellular level the generation of network bursts in spontaneously active neuronal cultures by exploiting high-resolution multielectrode array recordings and computational network modelling. Our analysis reveals that NBs are generated in specialized regions of the network (functional neuronal communities) that feature neuronal links with high cross-correlation peak values, sub-millisecond lags and that share very similar structural connectivity motifs providing recurrent interactions. We show that the particular properties of these local structures enable locally amplifying spontaneous asynchronous spikes and that this mechanism can lead to the initiation of NBs. Through the analysis of simulated and experimental data, we also show that AMPA currents drive the coordinated activity, while NMDA and GABA currents are only involved in shaping the dynamics of NBs. Overall, our results suggest that the presence of functional neuronal communities with recurrent local connections allows a neuronal system to generate spontaneous coordinated spiking activity events. As suggested by the rules used for implementing our computational model, such functional communities might naturally emerge during network development by following simple constraints on distance-based connectivity.	artificial neural network;asynchronous circuit;brain implant;community;computation;computational model;cross-correlation;exploit (computer security);gene regulatory networks;image resolution;interaction;n-methylaspartate;neural oscillation;noise shaping;rule (guideline);spontaneous order;transcription initiation;video-in video-out;gamma-aminobutyric acid	Davide Lonardoni;Hayder Amin;Stefano Di Marco;Alessandro Maccione;Luca Berdondini;Thierry Nieus	2017		10.1371/journal.pcbi.1005672	biology;network analysis;experimental data;bioinformatics;ampa receptor;multielectrode array;asynchronous communication;gamma-aminobutyric acid;biological system;machine learning;graph;artificial intelligence	ML	18.01689768293892	-71.61768918865589	31521
1a0f4bdb587d1813788a1a51312304a4a088517a	a marginalized two-part beta regression model for microbiome compositional data		In microbiome studies, an important goal is to detect differential abundance of microbes across clinical conditions and treatment options. However, the microbiome compositional data (quantified by relative abundance) are highly skewed, bounded in [0, 1), and often have many zeros. A two-part model is commonly used to separate zeros and positive values explicitly by two submodels: a logistic model for the probability of a specie being present in Part I, and a Beta regression model for the relative abundance conditional on the presence of the specie in Part II. However, the regression coefficients in Part II cannot provide a marginal (unconditional) interpretation of covariate effects on the microbial abundance, which is of great interest in many applications. In this paper, we propose a marginalized two-part Beta regression model which captures the zero-inflation and skewness of microbiome data and also allows investigators to examine covariate effects on the marginal (unconditional) mean. We demonstrate its practical performance using simulation studies and apply the model to a real metagenomic dataset on mouse skin microbiota. We find that under the proposed marginalized model, without loss in power, the likelihood ratio test performs better in controlling the type I error than those under conventional methods.	arabic numeral 0;coefficient;compositional data;marginal model;metagenomics;microbiome;silo (dataset);simulation;likelihood ratio	Haitao Chai;Hongmei Jiang;Lu Lin;Lei Liu	2018		10.1371/journal.pcbi.1006329	skewness;bioinformatics;regression analysis;statistics;biology;linear regression;microbiome;logistic regression;relative species abundance;covariate;likelihood-ratio test	ML	5.547505571722252	-52.84428093233766	31527
856e30171f7f05c340c0495a0b8901e1703f190b	the role of color in human face detection	deteccion;etude experimentale;color;scenes;hombre;percepcion;detection;cognition;human;bf psychology;cognicion;couleur;face;perception;face detection;vision;estudio experimental;homme;cara	"""Significant advances have been made in understanding human face recognition. However, a fundamental aspect of this process, how faces are located in our visual environment, is poorly understood and little studied. Here we examine the role of color in human face detection. We demonstrate that detection performance declines when color information is removed from faces, regardless of whether the surrounding scene context is rendered in color. Furthermore, faces rendered in unnatural colors are hard to detect, suggesting a role beyond simple segmentation. When faces are presented such that half the surface is colored appropriately, and half unnaturally, performance declines. This suggests that observers are not simply using the presence of skin color """"patches"""" to detect faces. Rather, our data suggest that detection operates via a face template combining diagnostic color and face-shape information. These findings are consistent with color-template approaches used in some computer-based face detection systems."""	clinical use template;color;face detection;facial recognition system;norm (social);skin pigmentation;observers	Markus Bindemann;A. Mike Burton	2009	Cognitive science	10.1111/j.1551-6709.2009.01035.x	psychology;cognitive psychology;face;vision;computer vision;face detection;aesthetics;cognition;communication;perception	Vision	-3.1443309424584327	-77.28190426469747	31533
b69048d7b4cc3b79ece4e68e11acb23b62c7518e	synchronization among tumour-like cell aggregations coupled by quorum sensing: a theoretical study	oscillations;genetic oscillators;repressilator;coupled system;quorum sensing;genetics;synchronization;cell aggregation	In this paper we examine the synchronization of a collection of repressilators in tumour-like cell aggregations coupled using quorum sensing. The force of diffusion that exists between neighbouring cells on the surface of the tumour has been paid due consideration. The study reveals that such a coupled system would show synchronization. Our computational results further show that such a prediction holds not only for individual tumours but also for multiple tumours coupled together. The degree of synchronization is found to be dependent on the strength of coupling, which is in turn determined by the cell density. c © 2007 Elsevier Ltd. All rights reserved.	coupling (computer programming);quorum sensing	J. C. Misra;A. Mitra	2008	Computers & Mathematics with Applications	10.1016/j.camwa.2007.06.027	synchronization;quorum sensing;control theory;oscillation	Mobile	7.283893359541483	-66.50373402250236	31554
13a395001eb697b22978412948134331b091b918	chortles: a method for representing oligomeric and template-based mixtures		Screening mixtures of synthetic oligomers or fixed templates (e.g., rings) with varying substituents is increasingly the focus of drug discovery programs. CHORTLES is designed and implemented to facilitate representation, storage, and searching of oligomeric and template-based mixtures of any size. Building upon the CHUCKLES method of representing oligomers as both monomer-based sequences and all-atom structures, CHORTLES compactly represents a mixture without explicitly enumerating individual molecules. This method lends itself to a hierarchy relating mixtures to submixtures and individual compounds, as one finds when deconvoluting mixtures in drug lead discovery programs. In addition, we describe two methods of searching mixtures at the monomer level. We also present a simple pictorial representation for describing all components in a mixture, which becomes essential as the list of monomer names is expanded beyond common names (e.g., amino acids).		Michael A. Siani;David Weininger;Craig A. James;Jeffrey M. Blaney	1995	Journal of chemical information and computer sciences	10.1021/ci00028a012	combinatorics;mathematics	Theory	13.454430752653133	-59.344970155992065	31572
80e31dc3deb2e6cb4aa3fb414e41d5a1e7cd24c1	predictive modeling of hospital readmission rates using electronic medical record-wide machine learning: a case-study using mount sinai heart failure cohort		Reduction of preventable hospital readmissions that result from chronic or acute conditions like stroke, heart failure, myocardial infarction and pneumonia remains a significant challenge for improving the outcomes and decreasing the cost of healthcare delivery in the United States. Patient readmission rates are relatively high for conditions like heart failure (HF) despite the implementation of high-quality healthcare delivery operation guidelines created by regulatory authorities. Multiple predictive models are currently available to evaluate potential 30-day readmission rates of patients. Most of these models are hypothesis driven and repetitively assess the predictive abilities of the same set of biomarkers as predictive features. In this manuscript, we discuss our attempt to develop a data-driven, electronic-medical record-wide (EMR-wide) feature selection approach and subsequent machine learning to predict readmission probabilities. We have assessed a large repertoire of variables from electronic medical records of heart failure patients in a single center. The cohort included 1,068 patients with 178 patients were readmitted within a 30-day interval (16.66% readmission rate). A total of 4,205 variables were extracted from EMR including diagnosis codes (n=1,763), medications (n=1,028), laboratory measurements (n=846), surgical procedures (n=564) and vital signs (n=4). We designed a multistep modeling strategy using the Naïve Bayes algorithm. In the first step, we created individual models to classify the cases (readmitted) and controls (non-readmitted). In the second step, features contributing to predictive risk from independent models were combined into a composite model using a correlation-based feature selection (CFS) method. All models were trained and tested using a 5-fold cross-validation method, with 70% of the cohort used for training and the remaining 30% for testing. Compared to existing predictive models for HF readmission rates (AUCs in the range of 0.6-0.7), results from our EMR-wide predictive model (AUC=0.78; Accuracy=83.19%) and phenome-wide feature selection strategies are encouraging and reveal the utility of such datadriven machine learning. Fine tuning of the model, replication using multi-center cohorts and prospective clinical trial to evaluate the clinical utility would help the adoption of the model as a clinical decision system for evaluating readmission status.	cerebrovascular accident;chronic fatigue syndrome;climate forecast system;code;compiler;cross reactions;cross-validation (statistics);decision support system;delivery of health care;electronic health records;electronics, medical;evaluation procedure;excalibur: morgana's revenge;extraction;feature selection;heart failure;helicon filter;machine learning;manuscripts;mathematical model;medical records;myocardial infarction;naive bayes classifier;numerous;operative surgical procedures;patients;phenome;phenomics;pneumonia;predictive modelling;probability;prospective search;scalability;stratification;algorithm	Khader Shameer;Kipp W. Johnson;Alexandre Yahi;Riccardo Miotto;Li Li;Doran Ricks;Jebakumar Jebakaran;Patricia A. Kovatch;Partho P. Sengupta;Annetine Gelijns;Alan Moskovitz;Bruce Darrow;David L. Reich;Andrew Kasarskis;Nicholas P. Tatonetti;Deborah F. Pinney;Joel Dudley	2017	Pacific Symposium on Biocomputing. Pacific Symposium on Biocomputing	10.1142/9789813207813_0027	medical record;bioinformatics;emergency medicine;mount;cohort;hospital readmission;heart failure;biology	ML	6.6761872577825905	-75.5702978360633	31703
8459e29679fcb697c147854a06c60478b523ee26	modélisation grande échelle de réseaux biologiques :vérification par contraintes booléennes de la cohérence des données. (large-scale modeling of biological networks: checking data consistency using boolean constraints)		Background Expression profiles obtained from multiple perturbation experiments are increasingly used to reconstruct transcriptional regulatory networks, from well studied, simple organisms up to higher eukaryotes. Admittedly, a key ingredient in developing a reconstruction method is its ability to integrate heterogeneous sources of information, as well as to comply with practical observability issues: measurements can be scarce or noisy. The purpose of this work is (1) to build a formal model of regulations among genes; (2) to check its consistency with gene expression data on stress perturbation assays; (3) to infer the regulatory role of transcription factors as inducer or repressor if the model is consistent with expression profiles; (4) to isolate ambiguous pieces of information if it is not. Results We validate our methods on E. Coli network with a compendium of expression profiles. We investigate the dependence between the number of available expression profiles and the number of inferred regulations, in the case where all genes are observed. This is done by simulating artificial observations for the transcriptional network of E. Coli (1529 nodes and 3802 edges). We prove that at most 40,8% of the network can be inferred and that 30 distinct expression profiles are enough to infer 30% of the network on average. We repeat this procedure in the case of missing observations, and show that our approach is robust to a significant proportion of unobserved genes. Finally, we apply our inference algorithms to S. Cerevisiae transcriptional network, and demonstrate that for small scale subnetworks of S. Cerevisiae we are able to infer more than 20% of the regulations. For more complex networks, we are able to detect and isolate inconsistencies between experimental sources and a non negligible portion of the model (15% of all interactions). Conclusions Our approach does not require accurate expression levels, nor times series. Nevertheless, we show both on real and artificial data that a relatively small number of perturbation experiments are enough to determine a significant portion of regulatory effects. This is a key practical asset compared to statistical methods for network reconstruction. In addition, we illustrate the capability of our method to validate networks. We conjecture that inconsistencies we detected might be good candidates for further experimental investigations. Contact philippe.veber@irisa.fr		Philippe Veber	2007				Comp.	3.835248278461027	-58.660768689577786	31769
915e4646e30e2072e7961257d4cfd4f02c1c161d	domain-general stroop performance and hemispheric asymmetries: a resting-state eeg study		The ability to suppress irrelevant information while executing a task, also known as interference resistance ability, is a function of pFC that is critical for successful goal-directed human behavior. In the study of interference resistance and, more generally, executive functions, two key questions are still open: Does pFC contribute to cognitive control abilities through lateralized but domain-general mechanisms or through hemispheric specialization of domain-specific processes? And what are the underlying causes of interindividual differences in executive control performance? To shed light on these issues, here we employed an interindividual difference approach to investigate whether participants' hemispheric asymmetry in resting-state electrophysiological brain dynamics may reflect their variability in domain-general interference resistance. We recorded participants' resting-state electroencephalographic activity and performed spectral power analyses on the estimated cortical source activity. To measure participants' lateralized brain dynamics at rest, we computed the right–left hemispheric asymmetry score for the β/α power ratio. To measure their domain-general interference resistance ability, verbal and spatial Stroop tasks were used. Robust correlations followed by intersection analyses showed that participants with stronger resting-state-related left-lateralized activity in different pFC regions, namely the mid-posterior superior frontal gyrus, middle and posterior middle frontal gyrus, and inferior frontal junction, were more able to inhibit irrelevant information in both domains. The present results confirm and extend previous findings showing that neurophysiological difference factors may explain interindividual differences in executive functioning. They also provide support for the hypothesis of a left pFC hemispheric specialization for domain-independent phasic cognitive control processes mediating Stroop performance.	cfp gene;electroencephalography;executive function;frontal lobe gyrus;heart rate variability;interference (communication);intersection of set of elements;middle frontal gyrus structure;partial template specialization;relevance;rest;executing - querystatuscode	Ettore Ambrosini;Antonino Vallesi	2017	Journal of Cognitive Neuroscience	10.1162/jocn_a_01076	psychology;developmental psychology;communication;social psychology	HCI	16.369308186311603	-77.64243135604892	31840
3e47e9c73b997e3d4a9ee626eefc1aaebcdb8369	pombase 2015: updates to the fission yeast database	databases;genes;fungal;genomics;schizosaccharomyces;high throughput nucleotide sequencing;molecular sequence annotation;databases genetic;gene expression;genes fungal;internet;gene ontology;genetic	PomBase (http://www.pombase.org) is the model organism database for the fission yeast Schizosaccharomyces pombe. PomBase provides a central hub for the fission yeast community, supporting both exploratory and hypothesis-driven research. It provides users easy access to data ranging from the sequence level, to molecular and phenotypic annotations, through to the display of genome-wide high-throughput studies. Recent improvements to the site extend annotation specificity, improve usability and allow for monthly data updates. Both in-house curators and community researchers provide manually curated data to PomBase. The genome browser provides access to published high-throughput data sets and the genomes of three additional Schizosaccharomyces species (Schizosaccharomyces cryophilus, Schizosaccharomyces japonicus and Schizosaccharomyces octosporus).	accessibility;annotation;database;genome;high-throughput computing;pombase;schizosaccharomyces pombe proteins;scientific publication;sensitivity and specificity;singlet fission;throughput;usb hub;usability	Mark D. McDowall;Midori A. Harris;Antonia Lock;Kim Rutherford;Daniel M. Staines;Jürg Bähler;Paul J. Kersey;Stephen G. Oliver;Valerie Wood	2015		10.1093/nar/gku1040	biology;genomics;the internet;gene expression;bioinformatics;gene;genetics	DB	-1.2465715684754535	-59.445501449064906	31871
19eac4ace2805085e2910e0cf7b44ada14b42c8e	performance analysis of network model to identify healthy and cancerous colon genes	analytical models;impedance;amino acids cancer integrated circuit modeling colon biological system modeling analytical models impedance;sensitivity analysis cancer genetics genomics medical diagnostic computing molecular biophysics molecular configurations;cancer;biological system modeling;colon;simulation colon cancer electrical network;receiver operating characteristic curve performance analysis network model healthy colon genes colon genes homo sapiens colon electrical network amino acid models hydropathy index amino acid side chain accuracy sensitivity specificity;integrated circuit modeling;amino acids	Modeling of cancerous and healthy Homo Sapiens colon gene using electrical network is proposed to study their behavior. In this paper, the individual amino acid models are designed using hydropathy index of amino acid side chain. The phase and magnitude responses of genes are examined to screen out cancer from healthy genes. The performance of proposed modeling technique is judged using various performance measurement metrics such as accuracy, sensitivity, specificity, etc. The network model performance is increased with frequency, which is analyzed using the receiver operating characteristic curve. The accuracy of the model is tested on colon genes and achieved maximum 97% at 10-MHz frequency.	amino acids;colon classification;network model;profiling (computer programming);rafivirumab;receiver operating characteristic;sensitivity and specificity	Tanusree Roy;Soma Barman	2016	IEEE Journal of Biomedical and Health Informatics	10.1109/JBHI.2015.2408366	pathology;bioinformatics;electrical impedance;cancer	Metrics	14.30952325978532	-64.25276886293305	31877
84b052f8dfb9a8c4b9235b71b054c82404629c2e	heterogeneous network edge prediction: a data integration approach to prioritize disease-associated genes	genome wide association studies;forecasting;animals;proteome;signal transduction;pathology and laboratory medicine;genome wide association study;catalogs;databases genetic;chromosome mapping;data mining;genetic networks;permutation;genetic predisposition to disease;algorithms;genetic loci;humans;protein interaction mapping;multiple sclerosis;systems integration	The first decade of Genome Wide Association Studies (GWAS) has uncovered a wealth of disease-associated variants. Two important derivations will be the translation of this information into a multiscale understanding of pathogenic variants and leveraging existing data to increase the power of existing and future studies through prioritization. We explore edge prediction on heterogeneous networks--graphs with multiple node and edge types--for accomplishing both tasks. First we constructed a network with 18 node types--genes, diseases, tissues, pathophysiologies, and 14 MSigDB (molecular signatures database) collections--and 19 edge types from high-throughput publicly-available resources. From this network composed of 40,343 nodes and 1,608,168 edges, we extracted features that describe the topology between specific genes and diseases. Next, we trained a model from GWAS associations and predicted the probability of association between each protein-coding gene and each of 29 well-studied complex diseases. The model, which achieved 132-fold enrichment in precision at 10% recall, outperformed any individual domain, highlighting the benefit of integrative approaches. We identified pleiotropy, transcriptional signatures of perturbations, pathways, and protein interactions as influential mechanisms explaining pathogenesis. Our method successfully predicted the results (with AUROC = 0.79) from a withheld multiple sclerosis (MS) GWAS despite starting with only 13 previously associated genes. Finally, we combined our network predictions with statistical evidence of association to propose four novel MS genes, three of which (JAK2, REL, RUNX3) validated on the masked GWAS. Furthermore, our predictions provide biological support highlighting REL as the causal gene within its gene-rich locus. Users can browse all predictions online (http://het.io). Heterogeneous network edge prediction effectively prioritized genetic associations and provides a powerful new approach for data integration across multiple domains.	anatomic node;anatomy, regional;antivirus software;body tissue;browsing;causal filter;collections (publication);extraction;futures studies;gene ontology term enrichment;genetic heterogeneity;genome-wide association study;high-throughput computing;interaction;janus kinase 2;locus;mental association;multiple sclerosis;node - plant part;rel gene;runx3 gene;receiver operating characteristic;throughput;transcription, genetic	Daniel Scott Himmelstein;Sergio Baranzini	2015		10.1371/journal.pcbi.1004259	genome-wide association study;biology;bioinformatics;data mining;genetics	Comp.	4.827758237080749	-57.386684395707356	31911
1ba3866e6a83dfe302bca44aea582e3c8cd0ea63	shotgun proteomic analysis of human head and neck squamous cell carcinoma cell line sq20b with diminished ahsg expression	health research;uk clinical guidelines;biological patents;europe pubmed central;citation search;computational biology bioinformatics;uk phd theses thesis;life sciences;algorithms;combinatorial libraries;uk research reports;medical journals;computer appl in life sciences;europe pmc;biomedical research;microarrays;bioinformatics	Background The Alpha-Heremans-Schmid Glycoprotein (AHSG) has tumor promoting properties in animal models of breast cancer and lung cancer [1,2]. These cancer cells do not synthesize AHSG, instead utilizing the liver-generated glycoprotein that is abundant in serum. We have reported that head and neck squamous cell carcinoma (HNSCC) cell lines synthesize AHSG (in press) and have also detected abundant AHSG in primary HNSCC tumors (unpublished). Growth in serum-free medium and in vitro tumorigenic properties, including proliferation, adhesion and migration, are diminished in the HNSCC SQ20B cell line modified with AHSG-specific shRNA to express only twenty percent of the wild-type SQ20B cell line (SQ20B-AH20) compared to SQ20B modified with empty vector alone and expressing the wild-type amount of AHSG (SQ20B-EV) [3]. Here we have used shotgun proteomic analysis to identify additional proteins whose expression may also affect these in vitro properties of tumorigenesis associated with AHSG.	extended validation certificate;proteomics	Georgina Iyamu;Pamela D. Thompson;Victor Paramov;Siddharth Pratap;Amos Sakwe;Josiah Ochieng;Dana Marshall	2014		10.1186/1471-2105-15-S10-P35	biology;dna microarray;computer science;bioinformatics	Visualization	8.769732545092689	-62.12049929174224	31915
0b92ee0f9dbec47c4a819139a069f988df8ba684	guugle: a utility for fast exact matching under rna complementary rules including g-u base pairing	helicidae;sufijo;prediccion;invertebrata;tree;structure secondaire;rna secondary structure;suffix;localization;arbol;bioinformatique;note application;hybridation;localizacion;nota aplicacion;suffix array;target;gastropoda;localisation;rna;estructura secundaria;mollusca;secondary structure;scope note;hybridization;blanco;arbre;cible;pulmonata;helix;hibridacion;bioinformatica;suffixe;prediction;base pair;bioinformatics	MOTIVATION RNA secondary structure analysis often requires searching for potential helices in large sequence data.   RESULTS We present a utility program GUUGle that efficiently locates potential helical regions under RNA base pairing rules, which include Watson-Crick as well as G-U pairs. It accepts a positive and a negative set of sequences, and determines all exact matches under RNA rules between positive and negative sequences that exceed a specified length. The GUUGle algorithm can also be adapted to use a precomputed suffix array of the positive sequence set. We show how this program can be effectively used as a filter preceding a more computationally expensive task such as miRNA target prediction.   AVAILABILITY GUUGle is available via the Bielefeld Bioinformatics Server at http://bibiserv.techfak.uni-bielefeld.de/guugle	accepting of extremity;analysis of algorithms;base pairing;bioinformatics;matching;precomputation;rna;rule (guideline);server (computer);suffix array;algorithm	Wolfgang Gerlach;Robert Giegerich	2006	Bioinformatics	10.1093/bioinformatics/btk041	biology;orbital hybridisation;rna;base pair;internationalization and localization;prediction;bioinformatics;helix;tree;nucleic acid secondary structure;genetics;algorithm;protein secondary structure	Comp.	-3.366410818748881	-55.5534191711261	31928
2deb9e84767e9dd751d8e5b2dc0512baff8c7c2d	a psti rflp for the human retinoic acid receptor in 17q21	receiver;hibridacion molecular;fragmento polimorfismo longitud restringida;receptor;retinoic acid receptor;hombre;polymorphisme longueur fragment restriction;dna complementario;retinoique acide;deoxyribonucleases type ii site specific;genetic mapping;e17 chromosome;retinoic acid;polymorphism genetic;complementary dna;determinismo genetico;receptors retinoic acid;estudio familiar;dna complementaire;gene frequency;cromosoma e17;dna restriction enzymes;etude familiale;restriction fragment length polymorphism;retinoico acido;polymorphism;determinisme genetique;human;recepteur;carte genetique;frequence genique;chromosomes human pair 17;family study;polymorphisme;carrier proteins;humans;mapa genetico;polimorfismo;molecular hybridization;chromosome e17;inheritance;hybridation moleculaire;frecuencia genica;polymorphism restriction fragment length;homme	POLYMORPHISM: PstI identifies a two allele polymorphism with bands at 3.0 kb (PI) or 2.6 kb + 0.4 kb (P2). Under medium stringency conditions (see below), invariant bands are detected at 5. CHROMOSOMAL LOCALISATION: The human retinoic acid receptor (hRAR) gene has been mapped in 17q21 by in situ hybridization (2).	17q21;bands;genetic polymorphism;in situ hybridization;language localisation;nucleic acid hybridization;restriction fragment length polymorphism;retinoic acid receptor;tretinoin	Benoît Arveiler;M. Petkovich;J. L. Mandel;Pierre Chambon	1988	Nucleic acids research	10.1093/nar/16.13.6252	receiver;biology;polymorphism;molecular biology;gene mapping;receptor;bioinformatics;allele frequency;retinoic acid receptor;restriction fragment length polymorphism;genetics;complementary dna;carrier protein	NLP	3.8213440948743833	-63.927812440929735	31930
5ae1af6cc9a0977af78134c99ce2643e6fe62312	a clinical decision support system for preventing adverse reactions to blood transfusion	continuous monitoring clinical decision support system integration prediction transfusion;servers;engines;system integration;blood;clinical decision support;continuous monitoring;transfusion;surgery;predictive models;engines blood predictive models surgery anesthesia servers;statistical analysis blood decision support systems health care learning artificial intelligence medical information systems patient monitoring patient treatment;mayo clinic perioperative environments clinical decision support system adverse reaction prevention blood transfusion transfusion related death transfusion related acute lung injury trali transfusion associated circulatory overload taco machine learning models surgical populations perioperative critical care environment continuous monitoring r statistical environment health information system transfusion related outcomes therapy therapeutic course care delivery;prediction;anesthesia	During 2011 approximately 21 million blood components were transfused in the United States, with roughly 1 in 414 resulting in complication. For Americans, the two leading causes of transfusion-related death are the respiratory complications Transfusion-related acute lung injury (TRALI) and Transfusion-associated circulatory overload (TACO). Each of these complications results in significantly longer ICU and hospital stays as well as significantly greater rates of mortality. We have developed a set of machine learning models for predicting the likelihood of these adverse reactions in surgical populations. Here we describe deploying these models into a perioperative critical care environment via a continuous monitoring and alerting clinical decision support system. The goal of this system, which directly integrates our suite of machine learning models running in the R statistical environment into a traditional health information system, is to improve transfusion-related outcomes in the perioperative environment. By identifying high-risk patients prior to transfusion, the clinical team may be able to choose a more appropriate therapy or therapeutic course. Identifying high-risk patients for increased observation after transfusion may also allow for a more timely intervention, thereby potentially improving care delivery and resulting patient outcome. An early prototype of this system is currently running in two Mayo Clinic perioperative environments.	clinical decision support system;information system;international components for unicode;machine learning;population;prototype	Dennis Murphree;Leanne Clifford;Yaxiong Lin;Nagesh Madde;Che Ngufor;Sudhindra Upadhyaya;Jyotishman Pathak;Daryl J. Kor	2015	2015 International Conference on Healthcare Informatics	10.1109/ICHI.2015.19	intensive care medicine;medicine;medical emergency;surgery	ML	6.628698128409597	-75.38780646461952	31972
e31d807c1c4465cfe13d6bf47b507bb1bb9bb284	time course rna-seq: a potential avenue with somewhat different approach in tandem of differential analysis	hidden markov models time series analysis gene expression trajectory biological system modeling data models;hidden markov model;rna seq;biological system modeling;time series;genetics;gene expression;hidden markov models;trajectory;rna;time series genetics hidden markov models molecular biophysics monte carlo methods rna statistical analysis;statistical analysis;time series analysis;markov chain monte carlo;markov chain monte carlo simulation time course rna seq data de facto standard approach conventional technologies microarray sequencing transcripts gene expression profile biological system dynamic temporal complexity intuitive solutions static differential expression methods time series trajectory index hidden markov model;molecular biophysics;markov chain monte carlo rna seq time series trajectory hidden markov model;monte carlo methods;data models	RNA-seq is exponentially becoming the de facto standard approach to compel considerable advantages over conventional technologies such as micro array by directly sequencing transcripts in gene expression profile. As the cost to sequencing is dropping rapidly, studies to dynamic change of gene expression in a given biological system over time have shown steady growth over the past few years as micro array, however, statistical approaches to characterize dynamic temporal complexities are currently elusive. In differential gene expression analysis, as somehow limited but intuitive solutions, static differential expression methods without respect to time can be applied, which do not take into account the inherent dependencies in time series explicitly that the expression patterns at later stages are dependent on patterns at earlier stages. We present a statistical framework to define dynamic gene expression patterns over time using trajectory index and Hidden Markov Model (HMM) approach in time series RNA-seq data, and our methods are validated through Markov Chain Monte Carlo (MCMC) simulation study in time series dependent data. The utility of the dynamic specific methods for temporal RNA-seq is demonstrated by application to the analyses of gene expression patterns in RNA-seq seven real data sets and MCMC simulation study in details.	biological system;color gradient;experiment;gene co-expression network;gene expression profiling;gene regulatory network;hidden markov model;markov chain monte carlo;microarray;monte carlo method;simulation;social network analysis;time series	Sunghee Oh;Hongyu Zhao;James Noonan	2012	2012 Sixth International Conference on Complex, Intelligent, and Software Intensive Systems	10.1109/CISIS.2012.204	econometrics;computer science;bioinformatics;statistics	Comp.	2.9939804866220254	-55.248952155724005	32029
3671e5d693560e6dfc24912b00ae77929c14f1a4	metabolomics spectral formatting, alignment and conversion tools (msfacts)	tratamiento datos;tissu;metabolic profile;spermatophyta;racine;angiospermae;visualizacion;analisis datos;data processing;traitement donnee;result;tejido;leguminosae;data analysis;visualization;modelo;feuille vegetal;complex data;metabolite profiling;visualisation;medicago truncatula;plant leaf;tissue;root;resultado;raiz;dicotyledones;analyse donnee;modele;resultat;models;hoja vegetal	MOTIVATION The amplified interest in metabolic profiling has generated the need for additional tools to assist in the rapid analysis of complex data sets.   RESULTS A new program; metabolomics spectral formatting, alignment and conversion tools, (MSFACTs) is described here for the automated import, reformatting, alignment, and export of large chromatographic data sets to allow more rapid visualization and interrogation of metabolomic data. MSFACTs incorporates two tools: one for the alignment of integrated chromatographic peak lists and another for extracting information from raw chromatographic ASCII formatted data files. MSFACTs is illustrated in the processing of GC/MS metabolomic data from different tissues of the model legume plant, Medicago truncatula. The results document that various tissues such as roots, stems, and leaves from the same plant can be easily differentiated based on metabolite profiles. Further, similar types of tissues within the same plant, such as the first to eleventh internodes of stems, could also be differentiated based on metabolite profiles.   AVAILABILITY Freely available upon request for academic and non-commercial use. Commercial use is available through licensing agreement http://www.noble.org/PlantBio/MS/MSFACTs/MSFACTs.html.	ascii;alignment;body tissue;fabaceae;imagery;medicago truncatula;metabolomics;open architecture;plant leaves;plant roots;structured product labeling licensing terminology;algorithm;format	Anthony L. Duran;Jian Yang;Liangjiang Wang;Lloyd W. Sumner	2003	Bioinformatics	10.1093/bioinformatics/btg315	botany;visualization;data processing;computer science;bioinformatics;data mining	Comp.	-3.230938784581201	-57.621184521975714	32104
4f726dbc194be06e760deae9b9d3fe00b75bf978	design of efficient and statistically powerful approaches for human genetics	genetics;computational genetics;statistics;computer science;statistical genetics;bioinformatics	Author(s): Sul, Jae Hoon | Advisor(s): Eskin, Eleazar | Abstract: The advent of genotyping and sequencing technologies has enabled human genetics to discover numerous genetic variants associated with many diseases and traits over the past decades. One of the most effective approaches to detect those variants has been genome-wide association studies (GWASs) that scan all variants found in genomes. GWASs collect people with a disease (called cases) and people without a disease (called controls) and compare allele frequencies between cases and controls to identify genetic variants associated the disease. This simple yet effective approach has been widely utilized by many studies, and more than 1,600 GWASs have been published during the last decade.An underlying assumption of GWAS is that cases and controls are sampled from the same population. If they are not, then a phenomenon called may cause spurious associations. Correcting for population structure in GWASs has been a very important problem in human genetics, and several methods have been proposed. However, those methods fail to correct for complex structure or are computationally too challenging for current GWAS datasets. I will introduce a new statistical approach that correctly removes effects of population structure and reduces the computational time from years to hours.Recently, sequencing technologies that enable a detection of rare variants have received considerable attention and been utilized by many GWASs. In these studies, rare variants in a gene are often grouped together to test the aggregated effect of rare variants on disease susceptibility. However, there are many different approaches to combine information of multiple rare variants, and it is unknown which approach is optimal in detecting associations of rare variants. I will introduce two novel approaches to better identify a group of rare variants involved in a disease. I will show using simulations that our approaches outperform previous methods, and using real sequencing data, I will show that our methods can identify an association reported by a previous study.Finally, I will introduce a statistical approach to identify expression quantitative trait loci (eQTL) or genetic variants that are associated with gene expression in multiple tissues. Recent technological developments and cost decreases have enabled eQTL studies to collect expression data in multiple tissues, but most studies focus on finding eQTLs in each tissue separately. I will introduce a statistical approach that combines results from multiple tissues to better identify eQTLs. I will show by using simulations and multiple tissue data from mouse that our approach detects many eQTLs undetected by traditional eQTL methods.		Jae Hoon Sul	2013			biology;bioinformatics;genetics	EDA	3.394893877715302	-53.49633199366322	32128
6dcb8d0117044f1c8d9c7c5ae8b141b470f93fba	hierarchical and multi-resolution representation of protein flexibility	conformational change;degree of freedom;protein flexibility;interactive visualization;computational method;biological systems;normal modes;multi resolution;molecular interactions;data structure	MOTIVATION Conformational rearrangements during molecular interactions are observed in a wide range of biological systems. However, computational methods that aim at simulating and predicting molecular interactions are still largely ignoring the flexible nature of biological macromolecules as the number of degrees of freedom is computationally intractable when using brute force representations.   RESULTS In this article, we present a computational data structure called the Flexibility Tree (FT) that enables a multi-resolution and hierarchical encoding of molecular flexibility. This tree-like data structure allows the encoding of relatively small, yet complex sub-spaces of a protein's conformational space. These conformational sub-spaces are parameterized by a small number of variables and can be searched efficiently using standard global search techniques. The FT structure makes it straightforward to combine and nest a wide variety of motion types such as hinge, shear, twist, screw, rotameric side chains, normal modes and essential dynamics. Moreover, the ability to assign shapes to the nodes in a FT allows the interactive manipulation of flexible protein shapes and the interactive visualization of the impact of conformational changes on the protein's overall shape. We describe the design of the FT and illustrate the construction of such trees to hierarchically combine motion information obtained from a variety of sources ranging from experiment to user intuition, and describing conformational changes at different biological scales. We show that the combination of various types of motion helps refine the encoded conformational sub-spaces to include experimentally determined structures, and we demonstrate searching these sub-spaces for specific conformations.	biological system;brute-force search;computational complexity theory;computer case screws;dna sequence rearrangement;data structure;experiment;hinge device component;interaction;interactive visualization;intuition;normal mode;numerous;search - action;simulation;staphylococcal protein a;trees (plant)	Yong Zhao;Daniel Stoffler;Michel F. Sanner	2006	Bioinformatics	10.1093/bioinformatics/btl481	simulation;interactive visualization;data structure;normal mode;computer science;bioinformatics;degrees of freedom	Comp.	12.731275371481546	-61.843023493820866	32198
5ad008605389668b296b0f5b32809e0040223fd5	protein folding potential functions	multichain aggregates;bound ligands protein folding potential functions protein structure recognition problem globular protein sequence plausible protein conformations native conformation single chain proteins nonnative structures multichain aggregates disulphide bonds;single chain proteins;protein structure recognition problem;potential energy functions;rotation measurement;nonnative structures;molecular configurations;potential functions;intramolecular mechanics proteins macromolecules molecular configurations potential energy functions;native conformation;bound ligands;nuclear magnetic resonance;testing;protein structure;intramolecular mechanics;proteins;protein conformation;globular protein sequence;crystallization;single chain;macromolecules;plausible protein conformations;amino acids;protein folding;disulphide bonds;protein engineering crystallization educational institutions nuclear magnetic resonance testing coordinate measuring machines rotation measurement amino acids;potential function;coordinate measuring machines;protein engineering	There has been a great deal of activity recently on approaches to the calculation of protein folding using specially devised empirical potential functions. We have developed one such function that solves the protein structure recognition problem: given the sequence for a globular protein and a collection of plausible protein conformations, including the native conformation for that sequence, identify the correct, native conformation. Although it nas been trained on only 58 single-chain proteins, it recognizes the native conformation for essentially all compact, soluble, globular proteins having known native conformations in comparisons with lo4 to lo6 reasonable alternative conformations apiece. Furthermore, it correctly discriminates between native and nonnative structures of multichain aggregates without additional ir@ormation about disuljide bonds or bound ligands. Given its broad successes, we can use it to gain insight into the d$erences between several seemingly related computational problems. 1: Problem definition There has been a lot of excitement in the recent literature about computer calculations that “fold up proteins”, particularly methods that employ specially designed potential functions that are not general purpose molecular mechanics force fields, yet somehow incorporate mformation about protein folding. Along with all the excitement and optimistic claims of success has come a great deal of confusion over who has really done what, and what does it mean in other contexts. Our purpose here is not to give an authoritative review of the field, but rather to clear up some of the misconceptions and define some terms precisely enough to explain what we have been doing. The long term goal of many investigators has been the protein folding problem (FP): given only t!?e amino acit sequence, calculate the detailed three-dimensional (3D) structure of the protein. However, this statement of FP is insufficient. We must add the target accuracy of the prediction and a requirement of generality. The experimental answer the calculation is trying to match is almost always taken to be a high-resolution X-ray crystal or NMR structure. There is also consensus that the appropriate measure of protein conformational similarity is the root-meansquare deviation in C” coordinates after optimal superposition by rigid body translation and rotation (denoted here by RMSD). (We believe that the test of “‘topological similarity” is so ill-defined as to be a meaningless measure.) Unfortunately, there is no consensus about how smalI the RMSD between the calculated and crystal structure must be to count as success. We have recently proposed an objective RMSD cutoff between similar and dissimilar protein structures that depends on chain length, but is free of arbitrary decisions.[l] Using this criterion we find several cases where various authors have calculated the tertiary structure of small proteins nearly well enough, and one or two cases where they have barely succeeded. Yet no one has succeeded on more than one protein, to our knowledge. This brings up the requirement of generality. A particular folding algorithm may inadvertently or intentionally incorporate information about the protein being predicted, or it may be subtly biased toward producing structures of that type. Success in FP must include the ability to function on a variety of different protein structural types, as well as extension beyond the set of proteins that may have been used to develop the method. Just how broad the range of proteins must be is up for debate, but we would propose that a successful method should work at least for cr, p, and CY//~ types of globular, water soluble proteins. There is a second major goal that is of more recent interest than FP and opposite to it, namely the inverse folding problem (IFP). Here the intent is to calculate a sequence or sequences that will uniquely fold to a given 3D structure. In IFP the solution is not unique, as we know from the great similarity of the many mutant T4 lysozyme crystal strucwes, but otherwise the accuracy and generality issues are the same. The experimentally determined 3D structure of the designed amino acid sequence must be unique enough to crystallize, and must lie within the proposed RMSD limit compared to the given target structure. Furthermore, this must be generally hue for some wide variety of proteins, particularly those that are significantly 1060-3425/95$4.00O1995IEEE 319 Proceedings of the 28th Hawaii International Conference on System Sciences (HICSS '95) 1060-3425/95 $10.00 © 1995 IEEE different from structures used to develop the method. FP and IFP so formulated are probably distant goals, and we need easier problems for now, such that their solution will lead the way to success on the more difficult ones. Certainly if we can’t even distinguish between correctly and incorrectly folded structures of the same sequence, we have little hope of solving FP. Our research has therefore centered around what we will call the structure identification problem (3DID): given a particular amino acid sequence and a large collection of 3D protein structures of the correct chain length, one of which is the correct native structure, select that native structure. Once again, the problem statement needs to be refined as to accuracy and generality. Most investigators of 3DID have used a statistical treatment of accuracy by developing a scalar function of structure that can be used to rank all the structures given, and then noting that the native lies far out on the favorable end of the disttibutionJ2, 3, 41 We have adopted the much more stringent, nonstatistical requirement that the native must always be ranked first, just as the real protein folds to its one native structure and no other. As for generality, there is the range of applicability concerning sizes and types of native proteins, as well as the range of nonnative structural types. We consider only native proteins that are compact, globular, and water soluble, consisting of one or more polypeptide chains of naturally occurring ammo acids. They may be of any folding motif and have associated ions, small ligands and prosthetic groups, but otherwise the set of polypeptide chains comprising the native structure must be able to fold up independently of other macromolecules. For example, if the experimentally stable state of a protein is the dimer, we must consider both chains at once, not just the monomer. As far as the diversity of the alternative structures goes, we assume that the obviously bad ones have already been rejected by some structure quality assessment program that looks for left-handed a-helices, van der Waals contacts, unusual d/$ values, etc. Otherwise, they may be compact or noncompact, similar to the native or very dissimilar. As does the Sippl group, we generate our alternatives by cutting out contiguous segments of polypeptide chain the length of the native from larger PDB entries. The opposite of 3DID and a restriction of IF? is what we will call the sequence identification problem (SEQID): given a particular native sequence and its high-resolution 3D structure, select from a large set of sequences the one or more that will fold to the target structure. As in IFP, the answer is clearly not unique, given a large assortment of sequences, although the native sequence should certainly be one of the hits. A successful algorithm should be applicable to a broad class of native protein 3D types. The accuracy issue is not so straightforward. Suppose the Proceedings of the 28th Annual Hawaii International Conference on System Sciences 1995 algorithm ranks sequences according to their suitability for the target structure, which is a globin, for instance. If the target is globin A, and it differs only a little in RMSD from globin B, then is ranking sequence B ahead of sequence A a mistake? Perhaps sequence B is more strongly biased toward the globin folding motif than sequence A is. One further question of problem definition common to both 3DID and SEQID is the treatment of insertions and deletions. In the same way that permitting indels is essential to the success of sequence alignment algorithms, this is a reasonable feature of SEQID. Without it, one can well expect to identify only the native sequence, even when clearly homologous sequences are available for selection. Similarly, it has often been argued that 3DID must select the native structure on the basis of the conserved interior strands (the “core” residues) alone, so that if the assortment of structures to choose from does not happen to include the native, the algorithm will at least recognize some homologous structure. We present the argument in the next section that such a goal for a 3DID algorithm is incompatible with experiment and with the previously stated objectives of the problem. In any case, we have strictly considered 3DID without gaps of any sort.	3did;algorithm;computation;computational problem;crystal structure;domino tiling;expect;experiment;force field (chemistry);hicss;homology (biology);image resolution;molecular mechanics;motif;peptide sequence;protein data bank;protein structure prediction;semantic similarity;sequence alignment;statistical potential;x-ray (amazon kindle)	Gordon M. Crippen	1995		10.1109/HICSS.1995.375324	protein structure	Comp.	10.974255136700075	-58.024770619892706	32260
f5c0a54171cb590c027e5f22591c337e9d586fb6	proposal of a 3d peptide pharmacophore of muramyl dipeptide-type immunostimulants. 2. computer docking to a model protein binding site	protein binding	The conformation of the immunostimulant muramyl dipeptide (N-acetylmuramyl-l-Ala-d-iGln, MDP) selected by the application of the CCLUES method (preceding paper) as the best candidate for the bioactive conformation is closely related to one of its parent compound, N-acetylglucosaminyl-β1→4-N-acetylmuramyl-l-Ala-d-iGln-γ-diaminopimeloyl-d-Ala, when bound to the T4 lysozyme [Kuroki, R. et al. Science 1993, 262, 2030]. A series of active and inactive MDP analogues has been docked to the same binding site and analyzed for site-to-ligand group−group interactions. The docking experiments demonstrate that the binding site qualitatively discriminates between the diastereomers of MDP and between the active and inactive analogues. It therefore appears to be a suitable model of peptide binding to the putative receptor for immunostimulant MDP-type peptides. The conformation of MDP docked to the model binding site is taken for the ab initio calculation (3-21G basis set) of the molecular electrostatic potential that is ...	pharmacophore	Primoz Pristovsek;Jurka Kidric;Dusan Hadzi	1997	Journal of Chemical Information and Computer Sciences	10.1021/ci970009t	biochemistry;plasma protein binding;chemistry;computer science;bioinformatics;combinatorial chemistry	Theory	10.191293534623307	-60.91686149003367	32261
cf9509120c92d85bf1d1be9779c26c35950a7ec1	identifying unproven cancer treatments on the health web: addressing accuracy, generalizability and scalability	evidence based medicine;quality assurance health care;consumer health information;marketing of health services;internet;outcome assessment health care;artificial intelligence;humans;neoplasms;consumer product safety;information storage and retrieval;natural language processing	Building machine learning models that identify unproven cancer treatments on the Health Web is a promising approach for dealing with the dissemination of false and dangerous information to vulnerable health consumers. Aside from the obvious requirement of accuracy, two issues are of practical importance in deploying these models in real world applications. (a) Generalizability: The models must generalize to all treatments (not just the ones used in the training of the models). (b) Scalability: The models can be applied efficiently to billions of documents on the Health Web. First, we provide methods and related empirical data demonstrating strong accuracy and generalizability. Second, by combining the MapReduce distributed architecture and high dimensionality compression via Markov Boundary feature selection, we show how to scale the application of the models to WWW-scale corpora. The present work provides evidence that (a) a very small subset of unproven cancer treatments is sufficient to build a model to identify unproven treatments on the web; (b) unproven treatments use distinct language to market their claims and this language is learnable; (c) through distributed parallelization and state of the art feature selection, it is possible to prepare the corpora and build and apply models with large scalability.	compression;distributed computing;emoticon;feature selection;machine learning;mapreduce;markov chain;neoplasms;parallel computing;scalability;subgroup;text corpus;www	Yindalon Aphinyanagphongs;Lawrence D. Fu;Constantin F. Aliferis	2013	Studies in health technology and informatics	10.3233/978-1-61499-289-9-667	simulation;engineering;data science;data mining	Web+IR	0.1101287562548883	-72.74445201653737	32284
b2e5e1fe3319e725e4a40089a85d75c7332efc5c	faster gaze prediction with dense networks and fisher pruning		Predicting human fixations from images has recently seen large improvements by leveraging deep representations which were pretrained for object recognition. However, as we show in this paper, these networks are highly overparameterized for the task of fixation prediction. We first present a simple yet principled greedy pruning method which we call Fisher pruning. Through a combination of knowledge distillation and Fisher pruning, we obtain much more runtime-efficient architectures for saliency prediction, achieving a 10x speedup for the same AUC performance as a state of the art network on the CAT2000 dataset. Speeding up single-image gaze prediction is important for many real-world applications, but it is also a crucial step in the development of video saliency models, where the amount of data to be processed is substantially larger.	autostereogram;fisher–yates shuffle;greedy algorithm;outline of object recognition;speedup	Lucas Theis;Iryna Korshunova;Alykhan Tejani;Ferenc Huszár	2018	CoRR		machine learning;gaze;pruning;salience (neuroscience);artificial intelligence;computer science;pattern recognition;speedup	ML	24.121507861048276	-52.248667146726135	32288
7f979903bc2c32626339082c9b03d21546be5d41	high-throughput dna methylation datasets for evaluating false discovery rate methodologies	microarray data;health research;uk clinical guidelines;false discovery rate;biological patents;europe pubmed central;citation search;gene expression;variable selection;sensitivity;methylation;uk phd theses thesis;multiple comparisons;analytical method;life sciences;simulation study;dna methylation;x chromosome inactivation;specificity;family wise error rate;high throughput;uk research reports;medical journals;sex chromosome;europe pmc;biomedical research;bioinformatics;hypothesis test	When analyzing high-throughput genomic data, the multiple comparison problem is most often addressed through estimation of the false discovery rate (FDR), using methods such as the Benjamini & Hochberg, Benjamini & Yekutieli, the q-value method, or in controlling the family-wise error rate (FWER) using Holm's step down method. To date, research studies that have compared various FDR/FWER methodologies have made use of limited simulation studies and/or have applied the methods to one or more microarray gene expression dataset(s). However, for microarray datasets the veracity of each null hypothesis tested is unknown so that an objective evaluation of performance cannot be rendered for application data. Due to the role of methylation in X-chromosome inactivation, we postulate that high-throughput methylation datasets may provide an appropriate forum for assessing the performance of commonly used FDR methodologies. These datasets preserve the complex correlation structure between probes, offering an advantage over simulated datasets. Using several methylation datasets, commonly used FDR methods including the q-value, Benjamini & Hochberg, and Benjamini & Yekutieli procedures as well as Holm's step down method were applied to identify CpG sites that are differentially methylated when comparing healthy males to healthy females. The methods were compared with respect to their ability to identify CpG sites located on sex chromosomes as significant, by reporting the sensitivity, specificity, and observed FDR. These datasets are useful for characterizing the performance of multiple comparison procedures, and may find further utility in other tasks such as comparing variable selection capabilities of classification methods and evaluating the performance of meta-analytic methods for microarray data.		N. Asomaning;K. J. Archer	2012	Computational statistics & data analysis	10.1016/j.csda.2011.10.020	high-throughput screening;x-inactivation;microarray analysis techniques;statistical hypothesis testing;false discovery rate;gene expression;sex-determination system;sensitivity;familywise error rate;bioinformatics;data science;methylation;dna methylation;data mining;feature selection;multiple comparisons problem;statistics	ML	5.297328623745278	-52.785936646773635	32290
207d5d3a53fd33d868931ada873d888173a67260	patient flow prediction via discriminative learning of mutually-correcting processes	imbalanced data;group lasso;hospitals;logistic regression;hidden markov models;patient flow;mutually correcting process;discriminative learning;robustness;copper;medical diagnostic imaging;data models	Over the past decade, the rate of care unit (CU) use in the United States has been increasing. With an aging population and ever-growing demand for medical care, effective management of patients' transitions among different care facilities will prove indispensible for shortening the length of hospital stays, improving patient outcomes, allocating critical care resources, and reducing preventable re-admissions. In this paper, we focus on an important problem of predicting the so-called “patient flow” from longitudinal electronic health records (EHRs), which has not been explored via existing machine learning techniques. By treating a sequence of transition events as a point process, we develop a novel framework for modeling patient flow through various CUs and jointly predicting patients' destination CUs and duration days. Instead of learning a generative point process model via maximum likelihood estimation, we propose a novel discriminative learning algorithm aiming at improving the prediction of transition events in the case of sparse data. By parameterizing the proposed model as a mutually-correcting process, we formulate the estimation problem via generalized linear models, which lends itself to efficient learning based on alternating direction method of multipliers (ADMM). Furthermore, we achieve simultaneous feature selection and learning by adding a group-lasso regularizer to the ADMM algorithm. Additionally, for suppressing the negative influence of data imbalance on the learning of model, we synthesize auxiliary training data for the classes with extremely few samples, and improve the robustness of our learning method accordingly. Testing on real-world data, we show that our method obtains superior performance in terms of accuracy of predicting the destination CU transition and duration of each CU occupancy.	algorithm;augmented lagrangian method;feature selection;generalized linear model;lasso;machine learning;multinomial logistic regression;point process;preprocessor;process modeling;sparse matrix;tip (unix utility)	Hongteng Xu;Weichang Wu;Shamim Nemati;Hongyuan Zha	2017	IEEE Transactions on Knowledge and Data Engineering	10.1109/TKDE.2016.2618925	semi-supervised learning;data modeling;computer science;artificial intelligence;machine learning;pattern recognition;data mining;logistic regression;copper;hidden markov model;discriminative model;statistics;robustness	ML	4.045121782326271	-73.85489391888952	32294
2a7058a720fa9da4b9b607ea00bfdb63652dff95	continuous probability distribution prediction of image emotions via multitask shared sparse regression	iterative reweighted least squares mtssr emotion distribution prediction task emotion feature extraction expectation maximization algorithm gaussian mixture model image emotion social net dataset large scale statistical analysis dimensional valence arousal space affective image classification dominant emotion category prediction image emotion analysis multitask shared sparse regression continuous probability distribution prediction;emotion recognition expectation maximisation algorithm feature extraction gaussian processes image classification iterative methods least squares approximations mixture models regression analysis statistical distributions;feature extraction probability distribution statistical analysis distance measurement visualization predictive models gaussian mixture model;distance measurement;visualization;gaussian mixture model;statistical analysis;feature extraction;probability distribution;multi task learning image emotion probability distribution valence arousal gaussian mixture model shared sparse regression;gaussian mixture model image emotion multi task learning probability distribution valence arousal shared sparse regression ssr;predictive models	Previous works on image emotion analysis mainly focused on predicting the dominant emotion category or the average dimension values of an image for affective image classification and regression. However, this is often insufficient in various real-world applications, as the emotions that are evoked in viewers by an image are highly subjective and different. In this paper, we propose to predict the continuous probability distribution of image emotions which are represented in dimensional valence-arousal space. We carried out large-scale statistical analysis on the constructed Image-Emotion-Social-Net dataset, on which we observed that the emotion distribution can be well-modeled by a Gaussian mixture model. This model is estimated by an expectation-maximization algorithm with specified initializations. Then, we extract commonly used emotion features at different levels for each image. Finally, we formalize the emotion distribution prediction task as a shared sparse regression (SSR) problem and extend it to multitask settings, named multitask shared sparse regression (MTSSR), to explore the latent information between different prediction tasks. SSR and MTSSR are optimized by iteratively reweighted least squares. Experiments are conducted on the Image-Emotion-Social-Net dataset with comparisons to three alternative baselines. The quantitative results demonstrate the superiority of the proposed method.	computer multitasking;computer vision;expectation–maximization algorithm;iteratively reweighted least squares;mixture model;sparse matrix	Sicheng Zhao;Hongxun Yao;Yue Gao;Rongrong Ji;Guiguang Ding	2017	IEEE Transactions on Multimedia	10.1109/TMM.2016.2617741	probability distribution;visualization;feature extraction;computer science;machine learning;pattern recognition;mixture model;predictive modelling;statistics	AI	19.437785128071013	-56.8581235676038	32314
bd517a0e783e8ba1a42346d0da1521e2d9a80d95	computational approaches to define a human milk metaglycome	biological patents;biomedical journals;text mining;europe pubmed central;citation search;citation networks;research articles;abstracts;open access;life sciences;clinical guidelines;full text;rest apis;orcids;europe pmc;biomedical research;bioinformatics;literature search	MOTIVATION The goal of deciphering the human glycome has been hindered by the lack of high-throughput sequencing methods for glycans. Although mass spectrometry (MS) is a key technology in glycan sequencing, MS alone provides limited information about the identification of monosaccharide constituents, their anomericity and their linkages. These features of individual, purified glycans can be partly identified using well-defined glycan-binding proteins, such as lectins and antibodies that recognize specific determinants within glycan structures.   RESULTS We present a novel computational approach to automate the sequencing of glycans using metadata-assisted glycan sequencing, which combines MS analyses with glycan structural information from glycan microarray technology. Success in this approach was aided by the generation of a 'virtual glycome' to represent all potential glycan structures that might exist within a metaglycomes based on a set of biosynthetic assumptions using known structural information. We exploited this approach to deduce the structures of soluble glycans within the human milk glycome by matching predicted structures based on experimental data against the virtual glycome. This represents the first meta-glycome to be defined using this method and we provide a publically available web-based application to aid in sequencing milk glycans.   AVAILABILITY AND IMPLEMENTATION http://glycomeseq.emory.edu   CONTACT sagravat@bidmc.harvard.edu   SUPPLEMENTARY INFORMATION Supplementary data are available at Bioinformatics online.	anabolism;annotation;bioinformatics;biopolymer sequencing;biosynthetic pathways;computation;emoticon;experiment;gene regulatory network;glycome;glycomics;high-throughput computing;ions;jamie wilkinson;knowledge bases;knowledge base;large;lectin;matching;manuscripts;mass spectrometry;microarray analysis;milk (body substance);milk, human;monosaccharides;n-acetylneuraminic acid;polysaccharides;rule (guideline);sensitivity and specificity;spectrometry, mass, matrix-assisted laser desorption-ionization;spreadsheet;technical support;throughput;united states national institutes of health;web application;xml path language;xpath;monorden;wu zhu yu extract	Sanjay Agravat;Xuezheng Song;Teerapat Rojsajjakul;Richard D. Cummings;David F. Smith	2016	Bioinformatics	10.1093/bioinformatics/btw048	biology;text mining;medical research;computer science;bioinformatics;data mining	Comp.	-0.282629256857097	-60.84415916842108	32342
3f3278a6b8376a1e31e56e595996a25452f3d6d1	erratum to: versatile and declarative dynamic programming using pair algebras	health research;uk clinical guidelines;biological patents;europe pubmed central;citation search;dynamic program;computational biology bioinformatics;uk phd theses thesis;life sciences;algorithms;combinatorial libraries;uk research reports;medical journals;computer appl in life sciences;europe pmc;biomedical research;microarrays;bioinformatics	We have located a typesetting error in our recent publication in BMC Bioinformatics (2005,6:224).	declarative programming;dynamic programming	Peter Steffen;Robert Giegerich	2006	BMC Bioinformatics	10.1186/1471-2105-7-214	biology;dna microarray;computer science;bioinformatics;data science;algorithm	PL	0.47582873706392936	-63.65425307448076	32361
d7706fc9a896bfed6e0c1e60a3e9cd1d75d69440	feature dimensionality reduction for video affect classification: a comparative study		Affective computing has become a very important research area in human-machine interaction. However, affects are subjective, subtle, and uncertain. So, it is very difficult to obtain a large number of labeled training samples, compared with the number of possible features we could extract. Thus, dimensionality reduction is critical in affective computing. This paper presents our preliminary study on dimensionality reduction for affect classification. Five popular dimensionality reduction approaches are introduced and compared. Experiments on the DEAP dataset showed that no approach can universally outperform others, and performing classification using the raw features directly may not always be a bad choice.	affective computing;dimensionality reduction;human–computer interaction	Chenfeng Guo;Dongrui Wu	2018	2018 First Asian Conference on Affective Computing and Intelligent Interaction (ACII Asia)		machine learning;computer science;dimensionality reduction;affective computing;artificial intelligence;principal component analysis;visualization;feature extraction	AI	23.692274680820447	-58.44474707788808	32371
3f02a6951dc18cf8ce0e27a054eaaf6deec5d1ae	composite module analyst: a fitness-based tool for prediction of transcription regulation	gene transcription;regulation of gene expression;transcription regulation;transcription factor binding site;binding site;gene expression;fitness function;molecular genetics;transcription factor	Functionally related genes involved in the same molecular-genetic, biochemical, or physiological process are often regulated coordinately Such regulation is provided by precisely organized binding of a multiplicity of special proteins (transcription factors) to their target sites (cis-elements) in regulatory regions of genes. Cis-element combinations provide a structural basis for the generation of unique patterns of gene expression. Here we present a new approach for defining promoter models based on composition of transcription factor binding sites and their pairs. We utilize a multicomponent fitness function for selection of that promoter model fitting best to the observed gene expression profile. We demonstrate examples of successful application of the fitness function with the help of a genetic algorithm for the analysis of functionally related or co-expressed genes as well as testing on simulated data.	curve fitting;emoticon;experiment;fitness function;gene expression profiling;genetic algorithm;mathematical optimization;medical transcription;microarray;motif;regulated rewriting;the matrix;transcription (software);transistor	Alexander E. Kel;Tatiana Konovalova;Tagir F. Valeev;Evgeny Cheremushkin;Olga V. Kel-Margoulis;Edgar Wingender	2005			promoter;taf2;operator (biology);regulation of gene expression;bioinformatics;enhancer;genetics;e-box;general transcription factor;response element;biology	Comp.	2.121589424903361	-58.75240524909723	32401
386144609878dc72a78acda4511f1a1a63bb0ada	(−) arctigenin and (+) pinoresinol are antagonists of the human thyroid hormone receptor β	furans;lignans;thyroid hormone receptors beta;hydrogen bonding;protein structure tertiary;humans;molecular docking simulation	Lignans are important biologically active dietary polyphenolic compounds. Consumption of foods that are rich in lignans is associated with positive health effects. Using modeling tools to probe the ligand-binding pockets of molecular receptors, we found that lignans have high docking affinity for the human thyroid hormone receptor β. Follow-up experimental results show that lignans (-) arctigenin and (+) pinoresinol are antagonists of the human thyroid hormone receptor β. The modeled complexes show key plausible interactions between the two ligands and important amino acid residues of the receptor.	amino acids;docking (molecular);food;gonadorelin;interaction;ligands;lignans;processor affinity;thyroid hormone receptor;thyroid hormones;arctigenin;pinoresinol	Ifedayo Victor Ogungbe;Rebecca A. Crouch;Teresa Demeritte	2014		10.1021/ci500537e	endocrinology;biochemistry;stereochemistry;chemistry;organic chemistry;hydrogen bond;nuclear magnetic resonance	HCI	9.185095382870829	-61.51090427743315	32436
e55806fce6f941e296aeb5c1f01b4d130937edd3	metriculator: quality assessment for mass spectrometry-based proteomics		SUMMARY Quality control in mass spectrometry-based proteomics remains subjective, labor-intensive and inconsistent between laboratories. We introduce Metriculator, a software designed to facilitate long-term storage of extensive performance metrics as introduced by NIST in 2010. Metriculator features a web interface that generates interactive comparison plots for contextual understanding of metric values and an automated metric generation toolkit. The comparison plots are designed for at-a-glance determination of outliers and trends in the datasets, together with relevant statistical comparisons. Easy-to-use quantitative comparisons and a framework for integration plugins will encourage a culture of quality assurance within the proteomics community.   AVAILABILITY AND IMPLEMENTATION Available under the MIT license at http://github.com/princelab/metriculator.	interface device component;laboratory;plug-in (computing);proteomics;spectrometry;user interface	Ryan M. Taylor;Jamison Dance;Russ J. Taylor;John T. Prince	2013	Bioinformatics	10.1093/bioinformatics/btt510	computer science;mass spectrometry;proteomics;bioinformatics	Visualization	-2.293890590912283	-57.169949650415056	32447
030ca2cf6c8265c1783df0c0231d86e0dcc5d271	a binary convolutional encoder-decoder network for real-time natural scene text processing		In this paper, we develop a binary convolutional encoder-decoder network (B-CEDNet) for natural scene text processing (NSTP). It converts a text image to a class-distinguished salience map that reveals the categorical, spatial and morphological information of characters. The existing solutions are either memory consuming or run-time consuming that cannot be applied to real-time applications on resource-constrained devices such as advanced driver assistance systems. The developed network can process multiple regions containing characters by one-off forward operation, and is trained to have binary weights and binary feature maps, which lead to both remarkable inference run-time speedup and memory usage reduction. By training with over 200, 000 synthesis scene text images (size of 32× 128), it can achieve 90% and 91% pixel-wise accuracy on ICDAR-03 and ICDAR-13 datasets. It only consumes 4.59 ms inference run-time realized on GPU with a small network size of 2.14 MB, which is up to 8× faster and 96% smaller than it full-precision version.	ascii art;algorithmic efficiency;convolutional code;encoder;graphics processing unit;map;pixel;real-time clock;real-time transcription;speedup	Zichuan Liu;Yixing Li;Fengbo Ren;Hao Yu	2016	CoRR		computer vision;speech recognition;computer science;machine learning;pattern recognition	ML	23.524848764884343	-52.107051134881054	32457
9090b05cee4f3424dbd79e6d450cb247589dcc55	"""combined use of pharmacophoric models together with drug metabolism and genotoxicity """"in silico"""" studies in the hit finding process"""	pde7;articulo;adme in silico;pharmacophore;virtual screening;toxicity;t lymphocytes	In this study we propose a virtual screening strategy based on the generation of a pharmacophore hypothesis, followed by an in silico evaluation of some ADME-TOX properties with the aim to apply it to the hit finding process and, specifically, to characterize new chemical entities with potential to control inflammatory processes mediated by T lymphocytes such as multiple sclerosis, systemic lupus erithematosus or rheumatoid arthritis. As a result, three compounds with completely novel scaffolds were selected as final hits for future hit-to-lead optimization due to their anti-inflammatory profile. The biological results showed that the selected compounds increased the intracellular cAMP levels and inhibited cell proliferation in T lymphocytes. Moreover, two of these compounds were able to increase the production of IL-4, an immunoregulatory cytokine involved in the selective deviation of T helper (Th) immune response Th type 2 (Th2), which has been proved to have anti-inflammatory properties in several animal models for autoimmune pathologies as multiple sclerosis or rheumatoid arthritis. Thus our pharmacological strategy has shown to be useful to find molecules with biological activity to control immune responses involved in many inflammatory disorders. Such promising data suggested that this in silico strategy might be useful as hit finding process for future drug development.	8-chloro-cyclic adenosine monophosphate;adme study;accessibility;adverse reaction to drug;angiotensin amide;animal model;anti-inflammatory agents;autoimmune diseases;cell proliferation;cell secretion;cell signaling;computation;cyclic amp;diabetes mellitus;entity;esterases;esters;excretory function;interleukin-4;iterative method;leukemia, b-cell;lupus erythematosus, systemic;mathematical optimization;modulation;multiple sclerosis;nsa product types;pharmacology;pharmacophore;predictive modelling;psoriasis;rheumatoid arthritis;signal transduction;statistical model;systemic scleroderma;t-helper cell type 1;test data;th17 cells;thrombocytopenia;transduction (machine learning);virtual screening;cytokine production;drug development;drug metabolism	Ma José Jerez;Miguel Jerez;Coral González-García;Sara Ballester;Ana Luiza Sarno Castro	2013	Journal of computer-aided molecular design	10.1007/s10822-012-9627-1	pharmacology;biology;chemistry;pharmacophore;virtual screening;toxicology;bioinformatics;toxicity;computational chemistry	ML	8.511171866439682	-60.73321374403427	32539
8c065fd5d8625cc91c7eab60ea71e21fc2f7c124	mining rare cases in post-operative pain by means of outlier detection	fuzzy c means algorithm;cluster algorithm;pattern clustering;medical informatics;fuzzy reasoning;electronic patient record;case mining;information technology;computer and information science;health professionals;post operative pain rare cases clustering case mining medical informatics information technology;pattern clustering fuzzy reasoning health care information technology medical information systems;outlier detection;engineering and technology;teknik och teknologier;clustering;medical information systems;post operative pain;rare cases;datavetenskap;post operative pain treatment domain outlier detection health professionals health care rare case identification electronic patient record information technology 2 nd order clustering algorithm fuzzy c means algorithm patient case;clustering algorithms pain partitioning algorithms surgery clustering methods statistical analysis chapters;computer science;medical informatic;data och informationsvetenskap;health care	Rare cases are often interesting for health professionals, physicians, researchers and clinicians in order to reuse and disseminate experiences in healthcare. However, mining, i.e. identification of rare cases in electronic patient records, is non-trivial for information technology. This paper investigates a number of well-known clustering algorithms and finally applies a 2nd order clustering approach by combining the Fuzzy C-means algorithm with the Hierarchical one. The approach was used to identify rare cases from 1572 patient cases in the domain of post-operative pain treatment. The results show that the approach enables the identification of rare cases in the domain of post-operative pain treatment and 18% of cases were identified as rare.	algorithm;anomaly detection;cluster analysis;fits;fuzzy cognitive map;hierarchical clustering;high-level programming language	Mobyen Uddin Ahmed;Peter Funk	2011	2011 IEEE International Symposium on Signal Processing and Information Technology (ISSPIT)	10.1109/ISSPIT.2011.6151532	computer science;bioinformatics;data science;machine learning;data mining;cluster analysis;information technology;health care	SE	3.302445894525792	-77.28009129242645	32554
2c3594175c75ca802e0653c0716535a26a1af392	microbidentifier: a microbial identification software based on mass-spectrometry	mass spectrometry;microbial identification	As the technology of microbial identification by mass cataloging has been widely used, we have developed the microbial identification software, MicrobIdentifier, which integrates and automates different steps in the procedure of rapid species identification based on mass-spectrometry. This software is written in Java for cross-platform intention.	java	Feng Liu;Lu Li;Chi Zhang;Lingbing Wang;Pei Li	2009	JSEA	10.4236/jsea.2009.23028	computer science;bioinformatics;engineering;world wide web	SE	-2.591180761246026	-58.42121617620062	32596
e729739e2796348faa50c0e88e38be83b070d3fe	latte: a language, compiler, and runtime for elegant and efficient deep neural networks	neural networks;compiler;deep learning;domain specific language;optimization	Deep neural networks (DNNs) have undergone a surge in popularity with consistent advances in the state of the art for tasks including image recognition, natural language processing, and speech recognition. The computationally expensive nature of these networks has led to the proliferation of implementations that sacrifice abstraction for high performance. In this paper, we present Latte, a domain-specific language for DNNs that provides a natural abstraction for specifying new layers without sacrificing performance. Users of Latte express DNNs as ensembles of neurons with connections between them. The Latte compiler synthesizes a program based on the user specification, applies a suite of domain-specific and general optimizations, and emits efficient machine code for heterogeneous architectures. Latte also includes a communication runtime for distributed memory data-parallelism. Using networks described using Latte, we demonstrate 3-6x speedup over Caffe (C++/MKL) on the three state-of-the-art ImageNet models executing on an Intel Xeon E5-2699 v3 x86 CPU.	analysis of algorithms;artificial neural network;central processing unit;compiler;computer vision;data parallelism;deep learning;distributed memory;domain-specific language;imagenet;machine code;natural language processing;parallel computing;speech recognition;speedup;x86	Leonard Truong;Rajkishore Barik;Ehsan Totoni;Chick Markley;Armando Fox;Tatiana Shpeisman	2016		10.1145/2908080.2908105	compiler;parallel computing;computer science;domain-specific language;theoretical computer science;deep learning;programming language	PL	22.29971181031252	-52.57511623402098	32633
75c992fa65c5bddd0e859a98bf4c80ebb16c5c77	charmm: the biomolecular simulation program	engineering;biophysical computation;charmm program;software;lipids;peptides;molecular modeling;biomolecular simulation;molecular dynamics;nucleic acids;models chemical;energy function;chemical engineering;models molecular;proteins;model building;quantum mechanics;boundary condition;quantum theory;force field;chemistry;particle system;theoretical physical and computational chemistry;molecular dynamic;materials science and engineering;parallel architecture;sampling methods;molecular mechanics;potential energy;computational biology;nucleic acid;computer simulation;free energy;carbohydrates	CHARMM (Chemistry at HARvard Molecular Mechanics) is a highly versatile and widely used molecular simulation program. It has been developed over the last three decades with a primary focus on molecules of biological interest, including proteins, peptides, lipids, nucleic acids, carbohydrates, and small molecule ligands, as they occur in solution, crystals, and membrane environments. For the study of such systems, the program provides a large suite of computational tools that include numerous conformational and path sampling methods, free energy estimators, molecular minimization, dynamics, and analysis techniques, and model-building capabilities. The CHARMM program is applicable to problems involving a much broader class of many-particle systems. Calculations with CHARMM can be performed using a number of different energy functions and models, from mixed quantum mechanical-molecular mechanical force fields, to all-atom classical potential energy functions with explicit solvent and various boundary conditions, to implicit solvent and membrane models. The program has been ported to numerous platforms in both serial and parallel architectures. This article provides an overview of the program as it exists today with an emphasis on developments since the publication of the original CHARMM article in 1983.	architecture as topic;charmm;carbohydrate nutrients;cell nucleus;implicit solvation;ligands;molecular dynamics;molecular mechanics;nucleic acids;parallel port;particle system;quantum mechanics;sampling (signal processing);serial port;simulation;small molecule;tissue membrane;water model;free energy	Bernard R. Brooks;Charles L. Brooks;Alexander D. MacKerell;Lennart Nilsson;Robert J. Petrella;Benoît Roux;Y. Won;G. Archontis;Christian Bartels;Stefan Boresch;Amedeo Caflisch;Leo S. D. Caves;Qiang Cui;Aaron R. Dinner;Michael Feig;S. Fischer;Jiali Gao;Milan Hodošček;Wonpil Im;Krzysztof Kuczera	2009	Journal of computational chemistry	10.1002/jcc.21287	nucleic acid;molecular dynamics;biophysics;chemistry;computational chemistry;physical chemistry;physics;quantum mechanics	Comp.	13.929757303813727	-63.38553624459733	32677
7de5d342ee505cd0acb5767114e235dfe0656dbd	a neurodynamical model for selective visual attention using oscillators	modelo dinamico;atencion selectiva;etude sur modele;oscilador;oscillations;neural models;neural model;time course;integrate and fire;dynamic model;model study;oscillator;atencion visual;corteza visual;phase oscillators;synchronisation;emergent properties;synchronization;oscillateur;visual search;estudio sobre modelo;modele dynamique;selective attention;sincronizacion;attention visuelle;model fitting;reseau neuronal;visual attention;cortex visuel;visual cortex;red neuronal;neural network;attention selective	We present a neurodynamical model to study and simulate visual search tasks experiments. The model consists of different pools of interconnected phase oscillators. Each oscillator is described by an integrate-and-fire type equation. Visual attention appears as an emergent property of the dynamic of the system, resulting from the temporal synchronization of the pools which bind the features of the searched target. The time courses observed in the psychophysical visual search experiments can be explained within a purely parallel dynamic and without assuming priority maps and serial spotlight mechanisms, as is usually done in the standard theories. The model fits also the measured activity reported for the neural responses in inferotemporal visual cortex of monkeys performing visual search tasks.		Silvia Corchs;Gustavo Deco	2001	Neural networks : the official journal of the International Neural Network Society	10.1016/S0893-6080(01)00055-7	synchronization;computer science;artificial intelligence;oscillation;artificial neural network	ML	20.764583399536775	-69.83712664920444	32700
48b19858d96e8409485b7b339bc834dcb755e6c9	ulysses: accurate detection of low-frequency structural variations in large insert-size sequencing libraries		MOTIVATION The detection of structural variations (SVs) in short-range Paired-End (PE) libraries remains challenging because SV breakpoints can involve large dispersed repeated sequences, or carry inherent complexity, hardly resolvable with classical PE sequencing data. In contrast, large insert-size sequencing libraries (Mate-Pair libraries) provide higher physical coverage of the genome and give access to repeat-containing regions. They can thus theoretically overcome previous limitations as they are becoming routinely accessible. Nevertheless, broad insert size distributions and high rates of chimerical sequences are usually associated to this type of libraries, which makes the accurate annotation of SV challenging.   RESULTS Here, we present Ulysses, a tool that achieves drastically higher detection accuracy than existing tools, both on simulated and real mate-pair sequencing datasets from the 1000 Human Genome project. Ulysses achieves high specificity over the complete spectrum of variants by assessing, in a principled manner, the statistical significance of each possible variant (duplications, deletions, translocations, insertions and inversions) against an explicit model for the generation of experimental noise. This statistical model proves particularly useful for the detection of low frequency variants. SV detection performed on a large insert Mate-Pair library from a breast cancer sample revealed a high level of somatic duplications in the tumor and, to a lesser extent, in the blood sample as well. Altogether, these results show that Ulysses is a valuable tool for the characterization of somatic mosaicism in human tissues and in cancer genomes.	annotation;breakpoint;chromosomal translocation;chromosome inversion;clinical act of insertion;diploid cell;genome;high-level programming language;inversion (discrete mathematics);kidney failure, chronic;libraries;mammary neoplasms;mike lesser;one thousand;p-value;sensitivity and specificity;statistical model;systemverilog;ulysses iii	Alexandre Gillet-Markowska;Hugues Richard;Gilles Fischer;Ingrid Lafontaine	2015	Bioinformatics	10.1093/bioinformatics/btu730	bioinformatics	Comp.	2.5810678287293385	-54.61906391989594	32709
eee892de610e4ac8feb698d36949f526dd559c91	identification of differentially expressed genes for time-course microarray data based on modified rm anova	microarray data;histograms;time dependent;regulation of gene expression;real data set;gene wise p values;time course;repeated measures;time course data;time course microarray data;dynamical processes;algorithms gene expression time course microarray data modified rm anova general statistical method single biological group classical f statistics gene wise p values pooled p values synthetic data sets real data set;statistical significance;statistical method;genetics;permutation;anova;gene expression;synthetic data sets;microarray data analysis;statistical analysis;general statistical method;yttrium;statistical analysis genetics;decision support systems;decision support systems analysis of variance yttrium histograms bioinformatics computational biology gene expression;classical f statistics;analysis of variance;pooled p values;algorithms;modified rm anova;variance moderation anova microarray data analysis permutation time course data;differentially expressed gene;synthetic data;variance moderation;computational biology;single biological group;bioinformatics	The regulation of gene expression is a dynamic process, hence it is of vital interest to identify and characterize changes in gene expression over time. We present here a general statistical method for detecting changes in microarray expression over time within a single biological group and is based on repeated measures (RM) ANOVA. In this method, unlike the classical F-statistic, statistical significance is determined taking into account the time dependency of the microarray data. A correction factor for this RM F-statistic is introduced leading to a higher sensitivity as well as high specificity. We investigate the two approaches that exist in the literature for calculating the p-values using resampling techniques of gene-wise p-values and pooled p-values. It is shown that the pooled p-values method compared to the method of the gene-wise p-values is more powerful, and computationally less expensive, and hence is applied along with the introduced correction factor to various synthetic data sets and a real data set. These results show that the proposed technique outperforms the current methods. The real data set results are consistent with the existing knowledge concerning the presence of the genes. The algorithms presented are implemented in R and are freely available upon request.	algorithm;gene expression regulation;microarray;p-value;pooled sample;r language;resampling (statistics);sensitivity and specificity;sensor;synthetic data;repeated measures	Ola ElBakry;M. Omair Ahmad;M. N. Shanmukha Swamy	2012	IEEE/ACM Transactions on Computational Biology and Bioinformatics	10.1109/TCBB.2011.65	microarray analysis techniques;gene chip analysis;decision support system;analysis of variance;computer science;bioinformatics;data mining;mathematics;statistics	Comp.	4.661199947187416	-52.1252350580648	32742
6a744d3a80aed7dc59b3bf2583229b5705c8237e	a new approach for combining knowledge from multiple coexpression networks of micrornas	cancer;algorithms bone marrow computer simulation gene expression regulation neoplastic humans information storage and retrieval leukemia micrornas models biological signal transduction;diseases cancer correlation robustness molecular biophysics couplings tumors;rna;blood;molecular biophysics;bone;leukemia multiple coexpression networks microrna mirna small noncoding rna coexpression networks systems biology integrative measure expression profiles bone marrow samples;network integration cancer coexpression network micrornas mirnas;rna blood bone cancer molecular biophysics	MicroRNAs (miRNAs) are a class of small non-coding RNAs that are known to have critical functions across various biological processes. Simultaneous activities of multiple miRNAs can be monitored from their expression profiles under various conditions. We often build up coexpression networks from such profiles. Unfortunately, due to the change of experimental setups (or conditions), the expression profiles do change, and consequently, the patterns of the coexpression networks vary. To obtain a robust functional relationship between miRNAs, by integrating different coexpression networks in a systems biology approach, we have to combine them properly. Here, we evaluate the state-of-the-art techniques and propose a novel integrative measure, and a corresponding methodology, that might be useful for identifying the dependence between coexpression and functional similarity. We establish the results by evaluating the expression profiles of miRNAs taken from bone marrow samples of patients with leukemia. The findings highlight the potential of the integrative algorithm in analyzing the expression profiles of miRNAs for further study.	biological processes;bone marrow;micrornas;patients;semantic network;systems biology;algorithm;leukemia	Malay Bhattacharyya;Manali Das;Sanghamitra Bandyopadhyay	2013	IEEE Transactions on Biomedical Engineering	10.1109/TBME.2013.2250285	biology;rna;medicine;pathology;bioinformatics;genetics;cancer;molecular biophysics	Comp.	5.925727234614005	-57.41132676341308	32746
a071813e0d55c8bbbfad9ccf5c7e77f919689d6e	sequence of information processing for emotions based on the anatomic dialogue between prefrontal cortex and amygdala	animals;female;emotions;models neurological;neural pathways;male;macaca mulatta;input output;prefrontal cortex;microscopy fluorescence;information processing;nerve net;layer 2;neurons;amygdala;information storage and retrieval;models anatomic;rhesus monkey	The prefrontal cortex and the amygdala have synergistic roles in regulating purposive behavior, effected through bidirectional pathways. Here we investigated the largely unknown extent and laminar relationship of prefrontal input-output zones linked with the amygdala using neural tracers injected in the amygdala in rhesus monkeys. Prefrontal areas varied vastly in their connections with the amygdala, with the densest connections found in posterior orbitofrontal and posterior medial cortices, and the sparsest in anterior lateral prefrontal areas, especially area 10. Prefrontal projection neurons directed to the amygdala originated in layer 5, but significant numbers were also found in layers 2 and 3 in posterior medial and orbitofrontal cortices. Amygdalar axonal terminations in prefrontal cortex were most frequently distributed in bilaminar bands in the superficial and deep layers, by columns spanning the entire cortical depth, and less frequently as small patches centered in the superficial or deep layers. Heavy terminations in layers 1-2 overlapped with calbindin-positive inhibitory neurons. A comparison of the relationship of input to output projections revealed that among the most heavily connected cortices, cingulate areas 25 and 24 issued comparatively more projections to the amygdala than they received, whereas caudal orbitofrontal areas were more receivers than senders. Further, there was a significant relationship between the proportion of 'feedforward' cortical projections from layers 2-3 to 'feedback' terminations innervating the superficial layers of prefrontal cortices. These findings indicate that the connections between prefrontal cortices and the amygdala follow similar patterns as corticocortical connections, and by analogy suggest pathways underlying the sequence of information processing for emotions.	amygdaloid structure;bands;calbindins;caudal;column (database);emotions;feedforward neural network;file spanning;gyrus cinguli;information processing;lateral thinking;macaca mulatta;medial graph;monkeys;phase i/ii trial;phase ii/iii trial;prefrontal cortex;projection defense mechanism;synergy;the superficial;tracer;anatomical layer	H Troy Ghashghaei;Claus C. Hilgetag;Helen Barbas	2007	NeuroImage	10.1016/j.neuroimage.2006.09.046	psychology;input/output;data link layer;neuroscience;developmental psychology;emotion;information processing;communication	ML	18.448045332485208	-75.17227278421862	32758
edc6915ff92f2308ab47e10d014478ed28a44dca	seeing is believing: depictive neuromodeling of visual awareness	neuromodelisation;memoria visual;encefalo;memoire travail;visual working memory;encephale;memoria trabajo;toma de conciencia;awareness;imaging;working memory;formation image;visual memory;arquitectura modular;formacion imagen;modular architecture;visual awareness;architecture modulaire;memoire visuelle;brain vertebrata;prise conscience	The object of seeing is for the brain to create inner states that accurately model the world and recall it for purposeful use. In this descriptive paper we present virtual neuro-architectures called 'depictive' which have been developed to create hypotheses for the mechanisms necessary for such depiction and explain some elements of verbally induced visual working memory. Early work on applications to understanding visual deficits in Parkinsons' sufferers is included.		Igor Aleksander;Helen Morton;Barry Dunmall	2001		10.1007/3-540-45720-8_92	medical imaging;awareness;visual memory;artificial intelligence;working memory	HCI	21.899587899880952	-69.13231493215044	32867
d834a2e7d3331983dc4cef8d8621d77b1b781f64	the h-invitational database (h-invdb), a comprehensive annotation resource for human genes and transcripts*	genes;animals;rna messenger;databases genetic;chromosome mapping;internet;proteins;dna complementary;humans;user computer interface	Here we report the new features and improvements in our latest release of the H-Invitational Database (H-InvDB; http://www.h-invitational.jp/), a comprehensive annotation resource for human genes and transcripts. H-InvDB, originally developed as an integrated database of the human transcriptome based on extensive annotation of large sets of full-length cDNA (FLcDNA) clones, now provides annotation for 120 558 human mRNAs extracted from the International Nucleotide Sequence Databases (INSD), in addition to 54 978 human FLcDNAs, in the latest release H-InvDB_4.6. We mapped those human transcripts onto the human genome sequences (NCBI build 36.1) and determined 34 699 human gene clusters, which could define 34 057 (98.1%) protein-coding and 642 (1.9%) non-protein-coding loci; 858 (2.5%) transcribed loci overlapped with predicted pseudogenes. For all these transcripts and genes, we provide comprehensive annotation including gene structures, gene functions, alternative splicing variants, functional non-protein-coding RNAs, functional domains, predicted sub cellular localizations, metabolic pathways, predictions of protein 3D structure, mapping of SNPs and microsatellite repeat motifs, co-localization with orphan diseases, gene expression profiles, orthologous genes, protein-protein interactions (PPI) and annotation for gene families. The current H-InvDB annotation resources consist of two main views: Transcript view and Locus view and eight sub-databases: the DiseaseInfo Viewer, H-ANGEL, the Clustering Viewer, G-integra, the TOPO Viewer, Evola, the PPI view and the Gene family/group.	alternative splicing;annotation;dna, complementary;database;extraction;gene family;interaction;locus;national center for biotechnology information;nucleotides;orphan diseases;pixel density;proton pump inhibitors;pseudogenes;rna splicing;sequence homology;short tandem repeat;single nucleotide polymorphism;transcript;transcriptome	Chisato Yamasaki;Katsuhiko Murakami;Yasuyuki Fujii;Yoshiharu Sato;Erimi Harada;Jun-ichi Takeda;Takayuki Taniya;Ryuichi Sakate;Shingo Kikugawa;Makoto Shimada;Motohiko Tanino;Kanako O. Koyanagi;Roberto A. Barrero;Craig Gough;Hong-Woo Chun;Takuya Habara;Hideki Hanaoka;Yosuke Hayakawa;Phillip Hilton	2008		10.1093/nar/gkm999	biology;molecular biology;the internet;bioinformatics;gene;genetics	Comp.	-0.811216525846939	-60.09398044056679	32881
2aff6857589d24d4341ca9b16269c49752346537	pmirp: a pre-microrna prediction method based on structure-sequence hybrid features	prediction method;nucleotides;pre microrna prediction;non coding rna;stem loop;secondary structure;support vector machine;microrna;free energy;base pair;hybrid features	OBJECTIVE MicroRNA is a type of small non-coding RNAs, which usually has a stem-loop structure. As an important stage of microRNA, the pre-microRNA is transported from nuclear to cytoplasm by exportin5 and finally cleaved into mature microRNA. Structure-sequence features and minimum of free energy of secondary structure have been used for predicting pre-microRNA. Meanwhile, the double helix structure with free nucleotides and base-pairing features is used to identify pre-miRNA for the first time.   METHODS We applied support vector machine for a novel hybrid coding scheme using left-triplet method, the free nucleotides, the minimum of free energy of secondary structure and base-pairings features. Data sets of human pre-microRNA, other 11 species and the latest pre-microRNA sequences were used for testing.   RESULTS In this study we developed an improved method for pre-microRNA prediction using a combination of various features and a web server called PMirP. The prediction specificity and sensitivity for real and pseudo human pre-microRNAs are as high as 98.4% and 94.9%, respectively. The web server is freely available to the public at http://ccst.jlu.edu.cn/ci/bioinformatics/MiRNA (accessed: 26 February 2010).   CONCLUSIONS Experimental results show that the proposed method improves the prediction efficiency and accuracy over existing methods. In addition, the PMirP has lower computational complexity and higher throughput prediction capacity than Mipred web server.		Dongyu Zhao;Yan Wang;Di Luo;Xiaohu Shi;Liupu Wang;Dong Xu;Jun Yu;Yanchun Liang	2010	Artificial intelligence in medicine	10.1016/j.artmed.2010.03.004	support vector machine;nucleotide;stem-loop;base pair;bioinformatics;data mining;non-coding rna;world wide web;microrna;protein secondary structure	AI	9.112895456087157	-56.774911991563776	32887
91eff030a98febbd2a83bd2c45d11379c2ef051d	learning internal representation of visual context in a neural coding network	visual context;neural coding;code generation;neural code;neural system;single cell;neural network model;object search;neural network	Visual context plays a significant role in humans’ gaze movement for target searching. How to transform the visual context into the internal representation of a brain-like neural network is an interesting issue. Population cell coding is a neural representation mechanism which was widely discovered in primates’ visual neural system. This paper presents a biologically inspired neural network model which uses a population cell coding mechanism for visual context representation and target searching. Experimental results show that the population-cell-coding generally performs better than the single-cell-coding system.	artificial neural network;network model;neural coding	Jun Miao;Baixian Zou;Laiyun Qing;Lijuan Duan;Yu Fu	2010		10.1007/978-3-642-15819-3_22	nervous system network models;computer vision;neural decoding;computer science;artificial intelligence;recurrent neural network;machine learning;time delay neural network;deep learning;neural coding;artificial neural network	ML	20.363351851148487	-66.90166005721176	32925
46f62353851b99bfb2c14fd84b620ace5cca3ae6	a preference for phase-based disparity in a neuromorphic implementation of the binocular energy model	ojo;silicon;sensibilite;system response;energy;preference theory;analisis sensibilidad;calcul neuronal;analisis numerico;neural computation;biological system;eye;estimator robustness;neurone impulsionnel;champ recepteur;electronique;57xx;energia;implementation;reponse systeme;logic;campo receptor;phase shift;cell complex;depth;circuito logico;pulga electronica;primary visual cortex;corteza visual;analyse numerique;neural circuit;red;chip;complexe cellulaire;spike;sensitivity;systeme biologique;neural system;energie;robustez estimador;spiking neurons;numerical analysis;electronica;circuit logique;spiking neuron;sensitivity analysis;retina;theorie preference;reseau arrangement;electronics;profundidad;retine;analyse sensibilite;array;receptive field;teoria preferencia;profondeur;binocular disparity;reseau neuronal;silicium;implementacion;logic circuit;puce electronique;cortex visuel;oeil;visual cortex;red neuronal;computacion neuronal;silicio;sistema biologico;logique;logica;sensibilidad;respuesta sistema;complex cell;potentiel action;neural network;transistor;robustesse estimateur;circuit neuronal	The relative depth of objects causes small shifts in the left and right retinal positions of these objects, called binocular disparity. This letter describes an electronic implementation of a single binocularly tuned complex cell based on the binocular energy model, which has been proposed to model disparity-tuned complex cells in the mammalian primary visual cortex. Our system consists of two silicon retinas representing the left and right eyes, two silicon chips containing retinotopic arrays of spiking neurons with monocular Gabor-type spatial receptive fields, and logic circuits that combine the spike outputs to compute a disparity-selective complex cell response. The tuned disparity can be adjusted electronically by introducing either position or phase shifts between the monocular receptive field profiles. Mismatch between the monocular receptive field profiles caused by transistor mismatch can degrade the relative responses of neurons tuned to different disparities. In our system, the relative responses between neurons tuned by phase encoding are better matched than neurons tuned by position encoding. Our numerical sensitivity analysis indicates that the relative responses of phase-encoded neurons that are least sensitive to the receptive field parameters vary the most in our system. We conjecture that this robustness may be one reason for the existence of phase-encoded disparity-tuned neurons in biological neural systems.	binocular disparity;binocular vision;cerebral cortex;eye;integrated circuit;logic gate;mammals;neuromorphic engineering;neuron;numerical analysis;physical object;retina;silicon;the spike (1997);transistor	Eric K. C. Tsang;Bertram E. Shi	2004	Neural Computation	10.1162/089976604774201604	binocular neurons;psychology;chip;binocular disparity;electronics;neuroscience;energy;sensitivity;numerical analysis;computer science;artificial intelligence;silicon;communication;implementation;logic;receptive field;sensitivity analysis;artificial neural network;transistor	ML	20.937114986979815	-70.11001536357102	33003
3dcbab59d17ffd4185909cce58b9d86888e8c7bc	study of completed archaeal genomes and proteomes: hypothesis of strong mutational at pressure existed in their common predecessor	g c;archaea;amino acid;gc content;vladislav v kturustalev eugene v barkovsky 压力突变 蛋白质组 基因组 假说 氨基酸含量 gc含量 密码子 生物信息学 study of completed archaeal genomes and proteomes hypothesis of strong mutational at pressure existed in their common predecessor;large scale;content distribution;degeneration;3gc;codon usage;entropy;mutational pressure;arginine	The number of completely sequenced archaeal genomes has been sufficient for a large-scale bioinformatic study. We have conducted analyses for each coding region from 36 archaeal genomes using the original CGS algorithm by calculating the total GC content (G+C), GC content in first, second and third codon positions as well as in fourfold and twofold degenerated sites from third codon positions, levels of arginine codon usage (Arg2: AGA/G; Arg4: CGX), levels of amino acid usage and the entropy of amino acid content distribution. In archaeal genomes with strong GC pressure, arginine is coded preferably by GC-rich Arg4 codons, whereas in most of archaeal genomes with G+C<0.6, arginine is coded preferably by AT-rich Arg2 codons. In the genome of Haloquadratum walsbyi, which is closely related to GC-rich archaea, GC content has decreased mostly in third codon positions, while Arg4>>Arg2 bias still persists. Proteomes of archaeal species carry characteristic amino acid biases: levels of isoleucine and lysine are elevated, while levels of alanine, histidine, glutamine and cytosine are relatively decreased. Numerous genomic and proteomic biases observed can be explained by the hypothesis of previously existed strong mutational AT pressure in the common predecessor of all archaea.	alanine;amino acids;archaea;archaeal proteins;arginine;bio-informatics;bioinformatics;cgs metric system;codon (nucleotide sequence);cybergraphx;cytosine;digital distribution;g+c composition;genome;genome, archaeal;glutamine;histidine;isoleucine;lysine;open reading frames;proteome;proteomics;ribosome subunits, small, archaeal;algorithm;polyethylene glycol-glutaminase-asparaginase	Vladislav Victorovich Khrustalev;Eugene Victorovich Barkovsky	2010		10.1016/S1672-0229(10)60003-4	biology;biochemistry;entropy;codon usage bias;amino acid;bioinformatics;gc-content;genetics;archaea	Comp.	4.26840043073856	-62.038687850593526	33030
5d2b986563a0574322fe282af1268d65904eacc2	junctionviewer: customizable annotation software for repeat-rich genomic regions	software;chromosomes artificial bacterial;genomics;centromere;maize;homology search;graphical interface;nucleotides;genome analysis;genome plant;molecular marker;genetic map;nucleotide sequences;repetitive sequences nucleic acid;genetic mapping;repetitive dna;automatic generation;genomes;computational biology bioinformatics;polymerase chain reaction;zea mays;graphical representation;dna sequencing;dna plant;algorithms;centromeres;computer software;primer design;combinatorial libraries;repetitive sequence;computer appl in life sciences;genetic markers;genome sequence;microarrays;bioinformatics	"""Repeat-rich regions such as centromeres receive less attention than their gene-rich euchromatic counterparts because the former are difficult to assemble and analyze. Our objectives were to 1) map all ten centromeres onto the maize genetic map and 2) characterize the sequence features of maize centromeres, each of which spans several megabases of highly repetitive DNA. Repetitive sequences can be mapped using special molecular markers that are based on PCR with primers designed from two unique """"repeat junctions"""". Efficient screening of large amounts of maize genome sequence data for repeat junctions, as well as key centromere sequence features required the development of specific annotation software. We developed JunctionViewer to automate the process of identifying and differentiating closely related centromere repeats and repeat junctions, and to generate graphical displays of these and other features within centromeric sequences. JunctionViewer generates NCBI BLAST, WU-BLAST, cross_match and MUMmer alignments, and displays the optimal alignments and additional annotation data as concise graphical representations that can be viewed directly through the graphical interface or as PostScript® output. This software enabled us to quickly characterize millions of nucleotides of newly sequenced DNA ranging in size from single reads to assembled BACs and megabase-sized pseudochromosome regions. It expedited the process of generating repeat junction markers that were subsequently used to anchor all 10 centromeres to the maize map. It also enabled us to efficiently identify key features in large genomic regions, providing insight into the arrangement and evolution of maize centromeric DNA. JunctionViewer will be useful to scientists who wish to automatically generate concise graphical summaries of repeat sequences. It is particularly valuable for those needing to efficiently identify unique repeat junctions. The scalability and ability to customize homology search parameters for different classes of closely related repeat sequences make this software ideal for recurring annotation (e.g., genome projects that are in progress) of genomic regions that contain well-defined repeats, such as those in centromeres. Although originally customized for maize centromere sequence, we anticipate this software to facilitate the analysis of centromere and other repeat-rich regions in other organisms."""	alu elements;annotation;blast cell;centromere;class;customize;expedited report;graphical user interface;homologous gene;homology (biology);infographic;interface device component;mummer;molecular marker;ncbi taxonomy;nucleotides;postscript;reading (activity);scalability	Thomas K. Wolfgruber;Gernot G. Presting	2009		10.1186/1471-2105-11-23	biology;centromere;genomics;molecular biology;bioinformatics;genetics	Comp.	-1.5706384648259117	-58.32559107929697	33095
1a6d318926d416b70927b46383f3b523c7cb5387	relationship between global structural parameters and enzyme commission hierarchy: implications for function prediction	physicochemical parameters;enzyme structure;ec hierarchy;artigo;function prediction;bioinformatics	In protein databases there is a substantial number of proteins structurally determined but without function annotation. Understanding the relationship between function and structure can be useful to predict function on a large scale. We have analyzed the similarities in global physicochemical parameters for a set of enzymes which were classified according to the four Enzyme Commission (EC) hierarchical levels. Using relevance theory we introduced a distance between proteins in the space of physicochemical characteristics. This was done by minimizing a cost function of the metric tensor built to reflect the EC classification system. Using an unsupervised clustering method on a set of 1025 enzymes, we obtained no relevant clustering formation compatible with EC classification. The distance distributions between enzymes from the same EC group and from different EC groups were compared by histograms. Such analysis was also performed using sequence alignment similarity as a distance. Our results suggest that global structure parameters are not sufficient to segregate enzymes according to EC hierarchy. This indicates that features essential for function are rather local than global. Consequently, methods for predicting function based on global attributes should not obtain high accuracy in main EC classes prediction without relying on similarities between enzymes from training and validation datasets. Furthermore, these results are consistent with a substantial number of studies suggesting that function evolves fundamentally by recruitment, i.e., a same protein motif or fold can be used to perform different enzymatic functions and a few specific amino acids (AAs) are actually responsible for enzyme activity. These essential amino acids should belong to active sites and an effective method for predicting function should be able to recognize them.		Marcelo Boareto;Michel E. B. Yamagishi;Nestor Caticha;Vitor B. P. Leite	2012	Computational biology and chemistry	10.1016/j.compbiolchem.2012.06.003	biology;computer science;bioinformatics;machine learning;data mining;mathematics	ML	8.409238400042105	-57.20937588941508	33105
90da69601c1cb04eb0b415c832e68ba4981e705f	structural and functional neuroimaging phenotypes in dysbindin mutant mice		Schizophrenia is a highly heritable psychiatric disorder that is associated with a number of structural and functional neurophenotypes. DTNBP1, the gene encoding dysbindin-1, is a promising candidate gene for schizophrenia. Use of a mouse model carrying a large genomic deletion exclusively within the dysbindin gene permits a direct investigation of the gene in isolation. Here, we use manganese-enhanced magnetic resonance imaging (MEMRI) to explore the regional alterations in brain structure and function caused by loss of the gene encoding dysbindin-1. We report novel findings that uniquely inform our understanding of the relationship of dysbindin-1 to known schizophrenia phenotypes. First, in mutant mice, analysis of the rate of manganese uptake into the brain over a 24-hour period, putatively indexing basal cellular activity, revealed differences in dopamine rich brain regions, as well as in CA1 and dentate subregions of the hippocampus formation. Finally, novel tensor-based morphometry techniques were applied to the mouse MRI data, providing evidence for structural volume deficits in cortical regions, subiculum and dentate gyrus, and the striatum of dysbindin mutant mice. The affected cortical regions were primarily localized to the sensory cortices in particular the auditory cortex. This work represents the first application of manganese-enhanced small animal imaging to a mouse model of schizophrenia endophenotypes, and a novel combination of functional and structural measures. It revealed both hypothesized and novel structural and functional neural alterations related to dysbindin-1.	24-hour clock;basal (phylogenetics);brain;ca1 field;candidate disease gene;cerebral cortex;dtnbp1 gene;deletion mutation;dopamine;functional neuroimaging;indexes;license;mental disorders;morphometric analysis;morphometrics;neostriatum;phenotype;preclinical imaging;resonance;schizophrenia;structure of dentate gyrus	Evan Lutkenhoff;Katherine H. Karlsgodt;Boris Gutman;Jason L. Stein;Paul M. Thompson;Tyrone D. Cannon;James David Jentsch	2012	NeuroImage	10.1016/j.neuroimage.2012.05.008	psychology;psychiatry;neuroscience;developmental psychology	Comp.	20.13976969578865	-78.2419123927784	33108
d85158b84c4905201d24c91f779a7ee447549fd6	ribotagger: fast and unbiased 16s/18s profiling using whole community shotgun metagenomic or metatranscriptome surveys	computational biology bioinformatics;algorithms;computer appl in life sciences;microarrays;bioinformatics	Taxonomic profiling of microbial communities is often performed using small subunit ribosomal RNA (SSU) amplicon sequencing (16S or 18S), while environmental shotgun sequencing is often focused on functional analysis. Large shotgun datasets contain a significant number of SSU sequences and these can be exploited to perform an unbiased SSU--based taxonomic analysis. Here we present a new program called RiboTagger that identifies and extracts taxonomically informative ribotags located in a specified variable region of the SSU gene in a high-throughput fashion. RiboTagger permits fast recovery of SSU-RNA sequences from shotgun nucleic acid surveys of complex microbial communities. The program targets all three domains of life, exhibits high sensitivity and specificity and is substantially faster than comparable programs.	biopolymer sequencing;cell nucleus;community;exhibits as topic;high-throughput computing;information;license;metagenomics;nucleic acids;rna;sensitivity and specificity;shotgun sequencing;synchronization in telecommunications;throughput	Chao Xie;Chin Lui Wesley Goi;Daniel H. Huson;Peter F. R. Little;Rohan B. H. Williams	2016		10.1186/s12859-016-1378-x	biology;molecular biology;dna microarray;computer science;bioinformatics	Comp.	2.378958039431128	-58.20107140348898	33194
3b1055c5f6042aad52942c7e41f889c7a62778b8	genetic effects on behavior are mediated by neurotransmitters and large-scale neural networks	female;genotype;male;image processing computer assisted;positron emission tomography;prefrontal cortex;adult;magnetic resonance imaging;cognition;nerve net;default mode network;humans;comt;catechol o methyltransferase;young adult;behavior;dopamine;set shifting	Claims of gene-behavior associations are complex and sometimes difficult to replicate because these relationships involve many downstream endogenous and environmental processes that mediate genetic effects. Knowing these mediating processes is critical to understanding the links between genes and behavior and how these factors differ between people. We identified and characterized the effects of a gene on neurochemistry and neural networks to elucidate the mechanism, at the systems level, whereby genes influence cognition. Catechol-O-methyltransferase (COMT) degrades dopamine in the prefrontal cortex (PFC) and is polymorphic with alleles differing in enzymatic activity. We found that COMT genotype determined dopamine synthesis, such that individuals with greater COMT activity synthesized more dopamine. Dopamine synthesis in the midbrain and ventral striatum affected functional connectivity in the default mode network, likely through the mesocorticolimbic pathway, in an inverted-U pattern with greater functional connectivity in medial PFC associated with intermediate levels of COMT activity and dopamine. Greater functional connectivity correlated with greater deactivation during performance of a set-shifting task that engaged the PFC. Greater deactivation was in turn associated with better performance. The integration of these results yields a model whereby COMT affects prefrontal function by a mechanism involving dopaminergic modulation of the default mode network. The model features the well-known inverted-U function between dopamine and performance and supports the hypothesis that dopamine and the default mode network shift attentional resources to influence prefrontal cognition.	acetylserotonin n-methyltransferase;alleles;artificial neural network;cfp gene;catechol o-methyltransferase;catechols;cognition;default;delta modulation;dopamine hydrochloride;downstream (software development);gene regulatory network;medial graph;mental association;methyltransferase;midbrain structure;neostriatum;neural network simulation;powerbuilder foundation classes;prefrontal cortex;resting state fmri;science of neurochemistry;self-replication;ventral striatum;whole earth 'lectronic link;dopamine biosynthetic process	Linh C. Dang;James P. O'Neil;William J. Jagust	2013	NeuroImage	10.1016/j.neuroimage.2012.10.090	psychology;catechol-o-methyl transferase;neuroscience;developmental psychology;magnetic resonance imaging;social psychology	ML	18.292989609400536	-77.58175162987904	33264
bcbc01ec0f6bd38c3995987fd3bb4776f29bccf1	an electrophysiological model of working memory performance		Abstract Working memory (WM) enables us to keep a limited amount of information in active mode. It is believed that attention refreshes necessary information in WM and prevents their forgetting. Despite a plethora of models offered, it is not fully understood that what factors may be involved in forgetfulness and in the required time for refreshing the information. In this study, an electrophysiological model of WM is proposed that consists of several resistor-capacitor units. Inspired of the “resource capacity theory,” attention as a limited source of energy refreshes the voltage level of these units. According to the “time-based resource sharing theory,” only one of these units is allowed to use the limited source of attention at each moment. The source of attention is shared between active units. This model mimics the pattern of several well-known observations of WM such as the recall interval, the word length, and the serial position effect. Some suggestions have been provided about influencing factors in WM performance. Model parameters give the ability of investigating the possible effect of some other factors on WM performance and also a probable prediction about how much information can we chunk?		Golnaz Baghdadi;Farzad Towhidkhah;Reza Rostami	2017	Cognitive Systems Research	10.1016/j.cogsys.2017.04.005	serial position effect;machine learning;psychology;artificial intelligence;working memory;shared resource;recall;forgetting;cognitive psychology	EDA	14.781851959901541	-74.89158047932813	33323
5cb0586fdb8418d3e6239ea23be1592855963b2d	stable receptive field structure of color neurons in primary visual cortex under adapting and non-adapting conditions		The way in which color signals from the three cone classes (L, M, S) are handled by the rest of the visual system to bring about color perception is incompletely known. In particular, the neural mechanism underlying two fundamental features of color vision, color contrast and color constancy, are unclear. Modeling efforts have shown that these features could be accounted for by neurons capable of making chromatic comparisons across visual space. The existence of such neurons in the primate is contested. I revisited the issue, recording the activity of single neurons in primary visual cortex of alert macaques trained to fixate a dot on a computer monitor, on which I flashed small spots of light that modulated a single cone class at a time. Cone-isolating stimuli can either increase or decrease one of the three cone types, thus there are a total of 6 stimuli; the stimuli were presented on a neutral gray adapting background. I correlated the location of the spots with the neural activity to produce receptive field maps. A fraction of neurons had both spatially and chromatically structured receptive fields. These were compared with receptive fields determined using stimuli presented on different-colored highcontrast (non-adapting) backgrounds. Receptive-fields with high-contrast stimuli had the same shape, but were slightly larger (10%) and had slightly shorter (5ms) latencies. These “double-opponent” neurons respond best to color contrast and could be the building blocks for color constancy. Introduction Some parvocellular neurons, located in the lateral geniculate nucleus early in visual processing, show opposite responses to opponent colors [1], a response attributed to opponent input from the cones [2] (Figure 1). Receptive fields of parvocellular neurons tend to be circularly symmetric, giving opposite responses in the center and the periphery: the center may be excited by red and the surround inhibited by green [3]. For these parvocellular neurons, the weakest stimulus would a stimulus with very high color contrast, e.g. a red spot on a green background. The particular balance in intensity of red to green that produces the weakest response can be called the “equiluminance null point”. There are several types of parvocellular neurons and each type has a slightly different equiluminance null point [4, 5]. Parvocellular neurons have been grouped into three categories, L vs. M, L+M vs. S and +( L, M, S) vs. –(L, M, S), which were once thought to underlie the cardinal color axes redgreen, blue-yellow and black-white. But the categorization appears to be somewhat arbitrary [6] [7] and does not reflect cardinal hues [8]. The basis for cardinal colors remains a mystery. In fact, the role of parvocellular neurons in color vision also remains mysterious because they respond worst to precisely the stimulus one would expect a color cell to be most sensitive to, a high color-contrast stimulus [9]. It has been argued that the main contribution of parvocellular neurons to vision is therefore not color, but sensitivity to high-resolution form. In this regard, the cone inputs that make up the excitation of the center of the “LON” and “M-ON” neurons (indicated by triangles and Xs on a white background in Figure 1) are irrelevant; what is important is that both give excitatory discharges to increases in light, i.e. both are sensitive to tiny light spots on a dark background. Neurons of the lateral geniculate nucleus send their signals to neurons in primary visual cortex. Each neuron in primary visual cortex receives several inputs [10], which results in receptive fields that have more elaborate structure, for example orientation-selective simple cells, which respond best to a bar of light at a given orientation [11](Figure 1). The spatial structure of the receptive fields of simple cells is organized into distinct sub-regions, so that the neurons respond best to one particular spatial frequency of a sine-wave grating. Simple cells are thought to arise by the orderly connection of lateral geniculate inputs [3, 10], and are thought to be critical for the detection of luminance edges. A given “ON”-center simple cell, responding best to a white bar on a black background, gets input from several “ON”center lateral geniculate neurons, possibly of both L-ON and MON varieties. Simple cells are then thought to send their outputs to complex cells [11]. Complex cells also respond well to edges, but their receptive fields show no spatial structure. Presumably this is because they receive inputs from many simple cells, of both “ON” and “OFF” varieties. Many neurons in primary visual cortex, perhaps the majority, do not have an equiluminance null [4, 12, 13]. Presumably this is because each cortical neuron receives input from many geniculate cells, each with a different null point; these different inputs compensate for each other: a particular balance of red:green, that nulls one input, excites an adjacent input. The lack of an equiluminance null point has been taken as a necessary feature of a color neuron. But lacking an equiluminance null is not sufficient to indicate that a neuron is contributing to color vision. Many psychophysical observations show that there are other important features of color, including color opponency and a lack of response to white [14], [15]. The riddle of contemporary color neurophysiology is that most neurons in primary visual cortex, even those that lack an equiluminance null, do not exhibit these features [16]. This could be because these neurons pool together inputs from a variety of parvocellular neurons, constrained by the sign of the center response, ON or OFF, but not by the cone type (in Figure 1, the ON-simple-cell inputs are all white, but two are triangles and one is an X). The solution to the riddle may be that color vision is subserved by only a tiny fraction of neurons in visual cortex, which could be missed in large surveys. Indeed one might predict that color requires only a small number of neurons, given the crumby resolution of color vision relative to form vision [17]. With this in mind, I have been investigating the properties of only those neurons in primary visual cortex that exhibit explicit coneFigure 1. Receptive fields of neurons in the parvocellular layers of the lateral geniculate nucleus (LGN) and primary visual cortex (V1). LGN neurons are the building blocks for receptive fields in V1. One question centers on the existence of neurons in V1 with double-opponent receptive fields. Such receptive fields are both chromatically opponent and spatially opponent (hence “double”). Note that simple cells have spatial luminance opponency but not chromatic opponency; i.e. a given simple cell could combine different types of LGN cells, so long as the centers of the LGN cells are all either excitatory or inhibitory. opponency: that show excitation to one cone type and suppression to another (e.g. excitation to red and suppression to green). Such cells are rare, perhaps only 10% [18]. Double Opponent Receptive Fields One feature of color vision invented by the brain is color contrast – that red looks redder against green. It has been argued that this, and the related problem of color constancy, could be partly resolved by a neural mechanism that makes simultaneous chromatic comparisons across space [19]. “Double-opponent” neurons capable of such comparisons have been found in the goldfish retina [20], but their existence in the primate visual system has been contested (hence the “?” in Figure 1, see [18] for a review). The cone inputs to primate primary visual cortical neurons have been mapped and support the conclusion that many cone-opponent neurons are double-opponent [18], having spatially offset receptive field sub-regions, with opposite chromatic opponency. Such neurons are simple-like because their receptive fields show spatial structure. But it has since been argued [21] that the stimuli used in these experiments were inadequate because they employed nonadapting conditions; the spatial structure observed is rationalized as just an artifact of the non-adapting stimulus. Other recent studies have failed to find double-opponent neurons [22], implying that simple-like double-opponent neurons do not exist. Thus it is argued that color calculations depend on complex neurons that respond at equiluminance and are spatial-frequency tuned; this implicates most primary visual cortex neurons in both color and form calculations. Although it may be tempting to call these complex-equiluminance neurons “double-opponent” [22], because they show both spatial-frequency and chromatic tuning, the wiring required to bring them about would seem to be fundamentally different from that required to bring about simplelike, proper double-opponent neurons. So it is probably worth distinguishing them, regardless of their role in color. Because simple-like double-opponent neurons are critical Figure 2. Spatial receptive field of a single cone-opponent neuron in primary visual cortex measured with high-contrast cone-isolating stimuli (top) and neutral-adapting stimuli (bottom). The receptive field shape is preserved under both conditions although the receptive field is slightly larger under high-contrast conditions. Grid shown to enable a comparison; small divisions are 0.75 degrees. Stimuli were 0.6 degrees square and were not constrained by the grid. Cone modulation index (CMI) = ((maximum cone activity minimum cone activity)/(maximum cone activity + minimum cone activity)) * 100. CMI (M, L, S, top) = 50, 50, 96; CMI (M, L, S, bottom) = 34, 34, 94. Methods are described in [18]; Stockman and Sharpe (2000) cone fundamentals were used [33]. to many models of color vision (e.g. [23-29]; complexequiluminant cells do not seem to do the trick), I revisited the issue of their existence. I recorded the activity of single neurons in primary visual cortex of alert macaques, trained to fixate a spot on a computer monitor whil	categorization;color vision;computer memories inc.;computer monitor;excited state;experiment;high color;image resolution;lateral computing;lateral thinking;map;modulation;neuron;opponent process;question answering;recession cone;relevance;wiring;zero suppression	Bevil R. Conway	2006			psychology;computer vision;optics;communication;color constancy	ML	16.841603446928257	-74.93822304686304	33345
78cf5a37a21da6984d322a52ba144527d20b5b3b	artificial neural networks to investigate the importance and the sensitivity to various parameters used for the prediction of chromosomal abnormalities		A selection of artificial neural network models were built and implemented for systematically study the contribution and the sensitivity of the main influencing parameters as important contributing factors for the noninvasive prediction of chromosomal abnormalities. The parameters that had been investigated are: the previous medical history of the pregnant mother, the nasal bone, the tricuspid flow, the ductus venosus flow, the PAPP-A value, the b-hCG value, the crown rump length (CRL), the changes in nuchal translucency (deltaNT) and the mother’s age. The main conclusions drawn are: 1) The deltaNT is the most significant factor for the overall prediction, while the CRL the least significant. 2) The previous medical history of the pregnant mother is not a significant factor for the prediction of the abnormal cases. 3) The nasal bone, the tricuspid flow and the ductus venosus flow contribute significantly in the prediction of trisomy 21 but not in the prediction of the “normal” cases. 4) The PAPP-A, the b-hCG and the mother’s age are of intermediate importance. Also, a sensitivity analysis of the attributes PAPP-A, b-hCG, CRL, deltaNT and of the mother’s age was done. This analysis showed that the CRL and deltaNT are more sensitive when their values are decreased, the PAPP-A is more sensitive when its values are increased and the b-hCG is insensitive to variations in its values.	artificial neural network;crown group;neural networks;rump kernel	Andreas C. Neocleous;Kypros H. Nikolaides;Argyro Syngelaki;Kleanthis C. Neokleous;Gianna Loizou;Costas Neocleous;Christos N Schizas	2012		10.1007/978-3-642-33412-2_5	crown-rump length;pattern recognition;artificial intelligence;ductus venosus;computer science;trisomy;artificial neural network;nasal bone	ML	9.010461694642034	-76.56381871745933	33355
25ae32693bb3bfe94852141071e7fe0abaeb4f76	examine: exploring annotated modules in networks	software;models biological;computational biology bioinformatics;cluster analysis;proteins;algorithms;combinatorial libraries;computer appl in life sciences;microarrays;bioinformatics	Biological networks have a growing importance for the interpretation of high-throughput “omics” data. Integrative network analysis makes use of statistical and combinatorial methods to extract smaller subnetwork modules, and performs enrichment analysis to annotate the modules with ontology terms or other available knowledge. This process results in an annotated module, which retains the original network structure and includes enrichment information as a set system. A major bottleneck is a lack of tools that allow exploring both network structure of extracted modules and its annotations. This paper presents a visual analysis approach that targets small modules with many set-based annotations, and which displays the annotations as contours on top of a node-link diagram. We introduce an extension of self-organizing maps to lay out nodes, links, and contours in a unified way. An implementation of this approach is freely available as the Cytoscape app eXamine eXamine accurately conveys small and annotated modules consisting of several dozens of proteins and annotations. We demonstrate that eXamine facilitates the interpretation of integrative network analysis results in a guided case study. This study has resulted in a novel biological insight regarding the virally-encoded G-protein coupled receptor US28.	cytoscape;diagram;extraction;gene ontology term enrichment;high-throughput computing;node - plant part;omics;organizing (structure);self-organization;self-organizing map;small;social network analysis;subnetwork;throughput	Kasper Dinkla;Mohammed El-Kebir;Cristina-Iulia Bucur;Marco Siderius;Martine J. Smit;Michel A. Westenberg;Gunnar W. Klau	2014		10.1186/1471-2105-15-201	biology;dna microarray;computer science;bioinformatics;data science;data mining;cluster analysis	Comp.	3.00804290485718	-57.40260020693517	33368
0ba1e2b84e5a557da3a9d702a2412d938c343e87	a gene network model for developing cell lineages	caenorhabditis elegans;c elegans;development;temporal dynamics;drgn gene regulation cell lineage development recurrent network c elegans;science artificial life genetic regulatory networks;locus of control;computer science artificial intelligence;gene regulation;specification;gene network;regulatory networks;recurrent network;single cell;cell lineage;morphogenesis;c elegans embryo;gene regulatory network;computer science theory methods;drgn	Biological development is a remarkably complex process. A single cell, in an appropriate environment, contains sufficient information to generate a variety of differentiated cell types, whose spatial and temporal dynamics interact to form detailed morphological patterns. While several different physical and chemical processes play an important role in the development of an organism, the locus of control is the cell's gene regulatory network. We designed a dynamic recurrent gene network (DRGN) model and evaluated its ability to control the developmental trajectories of cells during embryogenesis. Three tasks were developed to evaluate the model, inspired by cell lineage specification in C. elegans, describing the variation in gene activity required for early cell diversification, combinatorial control of cell lineages, and cell lineage termination. Three corresponding sets of simulations compared performance on the tasks for different gene network sizes, demonstrating the ability of DRGNs to perform the tasks with minimal external input. The model and task definition represent a new means of linking the fundamental properties of genetic networks with the topology of the cell lineages whose development they control.	anatomy, regional;diversification (finance);embryonic development;gene regulatory network;inspiration function;locus;lineage (evolution);network model;recurrent neural network;simulation;specification;unc13b gene	Nicholas Geard;Janet Wiles	2005	Artificial Life	10.1162/1064546054407202	biology;gene regulatory network;bioinformatics;genetics	Comp.	4.9420412604124415	-60.10347804571304	33408
996a024b4bb92f2324d0210c9dc7828cb73b8e14	"""unique hues of large stimuli: the """"colour size effect"""""""			mass effect trilogy	Péter Bodrogi;Gábor Kutas	2002			communication;unique hues;stimulus (physiology);biology	HCI	2.8924627312163573	-65.1575687139059	33419
4320c8054e5b2d970b5be6c11cff02e7ceb6dfd1	the free energy landscape of dimerization of a membrane protein, nanc	protein multimerization;escherichia coli;molecular dynamics simulation;models molecular;bacterial outer membrane proteins;protein conformation;escherichia coli proteins;phospholipids;porins;lipid bilayers	Membrane proteins are frequently present in crowded environments, which favour lateral association and, on occasions, two-dimensional crystallization. To better understand the non-specific lateral association of a membrane protein we have characterized the free energy landscape for the dimerization of a bacterial outer membrane protein, NanC, in a phospholipid bilayer membrane. NanC is a member of the KdgM-family of bacterial outer membrane proteins and is responsible for sialic acid transport in E. coli. Umbrella sampling and coarse-grained molecular dynamics were employed to calculate the potentials of mean force (PMF) for a variety of restrained relative orientations of two NanC proteins as the separation of their centres of mass was varied. We found the free energy of dimerization for NanC to be in the range of -66 kJ mol(-1) to -45 kJ mol(-1). Differences in the depths of the PMFs for the various orientations are related to the shape of the proteins. This was quantified by calculating the lipid-inaccessible buried surface area of the proteins in the region around the minimum of each PMF. The depth of the potential well of the PMF was shown to depend approximately linearly on the buried surface area. We were able to resolve local minima in the restrained PMFs that would not be revealed using conventional umbrella sampling. In particular, these features reflected the local organization of the intervening lipids between the two interacting proteins. Through a comparison with the distribution of lipids around a single freely-diffusing NanC, we were able to predict the location of these restrained local minima for the orientational configuration in which they were most pronounced. Our ability to make this prediction highlights the important role that lipid organization plays in the association of two NanCs in a bilayer.	dimerization;interaction;lateral thinking;maxima and minima;membrane proteins;mental orientation;molecular dynamics;n-acetylneuraminic acid;phospholipids;potential well;sampling (signal processing);sampling - surgical action;tissue membrane;umbrella sampling;free energy;kilojoule (kj);outer membrane;sialic acid transport;viral capsid secondary envelopment	Thomas A. Dunton;Joseph E. Goose;David J Gavaghan;Mark S. P. Sansom;James M. Osborne	2014		10.1371/journal.pcbi.1003417	biology;biochemistry;peripheral membrane protein;protein structure;lipid bilayer;molecular dynamics;escherichia coli;genetics	Comp.	8.82157855125457	-63.84791575142553	33454
0bc1533946a08e9e589ba35d79f4778ffa3d9939	training-induced changes in the dynamics of attention as reflected in pupil dilation		One of the major topics in attention literature is the attentional blink (AB), which demonstrates a limited ability to identify the second of two targets (T1 and T2) when presented in close temporal succession (200–500 msec). Given that the effect has been thought of as robust and resistant to training for over two decades, one of the most remarkable findings in recent years is that the AB can be eliminated after a 1-hr training with a color-salient T2. However, the underlying mechanism of the training effect as well as the AB itself is as of yet still poorly understood. To elucidate this training effect, we employed a refined version of our recently developed pupil dilation deconvolution method to track any training-induced changes in the amount and onset of attentional processing in response to target stimuli. Behaviorally, we replicated the original training effect with a color-salient T2. However, we showed that training without a salient target, but with a consistent short target interval, is already sufficient to attenuate the AB. Pupil deconvolution did not reveal any posttraining changes in T2-related dilation but instead an earlier onset of dilation around T1. Moreover, normalized pupil dilation was enhanced posttraining compared with pretraining. We conclude that the AB can be eliminated by training without a salient cue. Furthermore, our data point to the existence of temporal expectations at the time points of the trained targets posttraining. Therefore, we tentatively conclude that temporal expectations arise as a result of training.	attentional blink;color;data point;deconvolution;miosis disorder;mydriasis;onset (audio);pathological dilatation;pupil;succession;ultrasparc t2	Charlotte Willems;Atser Damsma;Stefan M. Wierda;Niels Taatgen;Sander Martens	2015	Journal of Cognitive Neuroscience	10.1162/jocn_a_00767	psychology;communication;social psychology	ML	16.17068300354234	-76.5699567668093	33458
3c7ce3c6062e83f54329db3f478bbb88aaed47ad	fsh: fast spaced seed hashing exploiting adjacent hashes	spaced seeds;k-mers;efficient hashing	Patterns with wildcards in specified positions, namely spaced seeds, are increasingly used instead of k-mers in many bioinformatics applications that require indexing, querying and rapid similarity search, as they can provide better sensitivity. Many of these applications require to compute the hashing of each position in the input sequences with respect to the given spaced seed, or to multiple spaced seeds. While the hashing of k-mers can be rapidly computed by exploiting the large overlap between consecutive k-mers, spaced seeds hashing is usually computed from scratch for each position in the input sequence, thus resulting in slower processing. The method proposed in this paper, fast spaced-seed hashing (FSH), exploits the similarity of the hash values of spaced seeds computed at adjacent positions in the input sequence. In our experiments we compute the hash for each positions of metagenomics reads from several datasets, with respect to different spaced seeds. We also propose a generalized version of the algorithm for the simultaneous computation of multiple spaced seeds hashing. In the experiments, our algorithm can compute the hashing values of spaced seeds with a speedup, with respect to the traditional approach, between 1.6$$\times$$ × to 5.3$$\times$$ × , depending on the structure of the spaced seed. Spaced seed hashing is a routine task for several bioinformatics application. FSH allows to perform this task efficiently and raise the question of whether other hashing can be exploited to further improve the speed up. This has the potential of major impact in the field, making spaced seed applications not only accurate, but also faster and more efficient. The software FSH is freely available for academic use at: https://bitbucket.org/samu661/fsh/overview.	algorithm;bioinformatics;bitbucket;computation;cryptographic hash function;experiment;fasttrack scripting host;indexes;k-mer;marijuana abuse;metagenomics;plant seeds;random seed;reading (activity);spata6 gene;similarity search;speedup;wildcard character	Samuele Girotto;Matteo Comin;Cinzia Pizzi	2018		10.1186/s13015-018-0125-4	bioinformatics;scratch;hash function;structural biology;theoretical computer science;search engine indexing;computer science;nearest neighbor search	ML	-1.824506108296433	-52.837861449678876	33516
be4b06200d024c068830973600f780b8bc3b3fb0	non-coding rna covariance model combination using mixed primary-secondary structure alignment	non coding rna covariance model sequence analysis secondary structure;bepress selected works;non coding rna;secondary structure;sequence analysis;covariance model	Covariance models are very effective for finding new members of non-coding RNA sequence families in genomic data. However, the computation burden of applying CM-based search algorithms can be prohibitive. When an- notating the genome of a newly sequenced organism it is usually desired to search the sequence data using a large number of ncRNA families. Computa- tional burden can be reduced if the families are clustered into statistically similar models and a single cluster-average representative model produced. The database is then searched with the representative model for each cluster at a relatively low detection threshold. The output of this pre-filtered database is then processed with the individual family members of the cluster. A base-pair conflict metric has previously been proposed for use in model clustering. In this work an alternative metric using standard alignment algorithms and a special mixed primary-secondary structure scoring matrix is proposed.		Jennifer A. Smith	2012		10.1007/978-3-642-38342-7_9	biology;bioinformatics;sequence analysis;data mining;non-coding rna;genetics;statistics;protein secondary structure	NLP	1.2481211860320367	-52.953303024382706	33527
b668d730aa2307bff70e47bd7ac415ff79d34890	robustness of g1/s checkpoint pathways in cell cycle regulation based on probability of dna-damaged cells passing as healthy cells	systems biology;kinetic parameter;cell cycle regulation;sensitivity analysis;system biology;mathematical model;robustness;dna damage;checkpoint pathways;in silico	We investigate the robustness and the behaviours of the critical proteins under parameter perturbations of G1/S checkpoint pathways with different levels of DNA-damage, based on a mathematical model of the pathways. We identify the peak times (PTs) of two key proteins as the in silico biomarkers based on the currently established biology, and the results from the local and global sensitivity analyses show the significant kinetic parameters that are associated with the key proteins. The robustness of the G1/S checkpoint pathways with or without DNA-damage is defined based on the probability (beta) of DNA-damaged cells passing as healthy cells under the given perturbation regimes. The results from the global sensitivity analyses based on four defined levels of parameter range reveal that we can accurately distinguish healthy cells from the defective cells when parameter variations are within a range of +/-10%. However, the probability of wrongly identifying damaged cells as healthy cells became very large (more than 0.43) when the level of change of parameters exceeds +/-30%. Provided that there are probably millions of cells that are oncogenically primed at any given time, these dangerous cells are disposed through apoptosis and cellular senescence. However, the very recent experimental findings state that this irreversible process happens not in the pre-tumoral stage but in the pre-malignant tissue where a non-invasive tumor is formed. This points out that a large number of damaged cells undergo proliferation without being caught at DNA-damage checkpoints. Our simulation results, in terms of percentage of damaged cells that pass G1/S checkpoint agree with this possibility.	apoptosis;biological markers;cell aging;cell cycle checkpoints;cell cycle control;greater than;kinetics;mathematical model;mathematics;neoplasms;population parameter;simulation;transaction processing system;positive regulation of response to g1 dna damage checkpoint signaling	Hong Ling;Don Kulasiri;Sandhya Samarasinghe	2010	Bio Systems	10.1016/j.biosystems.2010.07.005	biology;cell biology;bioinformatics;cell cycle;dna damage;mathematical model;genetics;sensitivity analysis;systems biology;robustness	Comp.	8.581973442628001	-66.03434868842457	33552
09be10462fe15b6c450c8d213b2f66168004b5c8	tree-based convolutional neural networks		In this chapter, we provide a whirlwind introduction of the history of deep neural networks (also known as deep learning), positioned in a broader scope of machine learning and artificial intelligence. We then focus on a specific research direction of deep neural networks—incorporating structural information of data into the design of network architectures. This motivates the key contribution of the book, a tree-based convolutional neural network (TBCNN), that performs the convolution operation over tree structures. Finally, we provide an overview of this book.	artificial intelligence;artificial neural network;convolution;convolutional neural network;deep learning;machine learning;neural networks	Lili Mou;Zhi Jin	2018		10.1007/978-981-13-1870-2	convolutional neural network;machine learning;computer science;artificial intelligence	AI	23.987769557869978	-54.845491157038516	33558
7001aea9c43014d3572a8be1d85c6421ddd4e25d	quasarnet: human-level spectral classification and redshifting with deep neural networks		We introduce QuasarNET, a deep convolutional neural network that performs classification and redshift estimation of astrophysical spectra with human-expert accuracy. We pose these two tasks as a feature detection problem: presence or absence of spectral features determines the class, and their wavelength determines the redshift, very much like human-experts proceed. When ran on BOSS data to identify quasars through their emission lines, QuasarNET defines a sample 99.51±0.03% pure and 99.52±0.03% complete, well above the requirements of many analyses using these data. QuasarNET significantly reduces the problem of line-confusion that induces catastrophic redshift failures to below 0.2%. We also extend QuasarNET to classify spectra with broad absorption line (BAL) features, achieving an accuracy of 98.0 ± 0.4% for recognizing BAL and 97.0±0.2% for rejecting non-BAL quasars. QuasarNET is trained on data of low signal-to-noise and medium resolution, typical of current and future astrophysical surveys, and could be easily applied to classify spectra from current and upcoming surveys such as eBOSS, DESI and 4MOST.	artificial neural network;catastrophic interference;convolutional neural network;feature detection (computer vision);feature detection (web development);ibm basic assembly language and successors;neural network software;redshift;requirement;signal-to-noise ratio;stellar classification	Nicolas Busca;Christophe Balland	2018	CoRR		physics;astronomy;convolutional neural network;quasar;stellar classification;spectral line;artificial neural network;wavelength;emission spectrum;redshift;artificial intelligence;pattern recognition	ML	21.360926259355097	-58.81410623972205	33644
22161998461e3878ec56b50f880049c76073247e	a neural network model of parkinson's disease bradykinesia	parietal cortex;basal ganglia;parkinson maladie;modelizacion;vite;da;vta;sp;snc;dvv;bradykinin;bradykinine;gpe;basal ganglion;mn;me;spinal cord;tiempo reaccion;simulation;vlo;snr;simulacion;ppv;emd;rra;sma;temps reaction;cortex;arm movement;γ mn;emg;enk;dv;modelisation;substantia nigra pars compacta;degeneration;nucleo basal;stn;iain;flete;network model;rt;in;ud;led;parkinson s disease;noyau gris central;sn;ro;mptp;bd;α mn;pd;movement time;ibin;parkinson disease;crt;om;neural network model;reseau neuronal;bg;dyn;bradiquinina;dopamine;bradykinesia;modeling;tpv;red neuronal;gpi;pmt;parkinson enfermedad;reaction time;dopamina;model simulation;mt;neural network;ventral tegmental area;cpg	Parkinson's disease (PD) is caused by dopamine (DA) depletion consequent to cell degeneration in the substantia nigra pars compacta (SNc) and the ventral tegmental area (VTA). Although computational analyses of PD have focused on DA depletion in DA-recipient parts of the basal ganglia, there is also extensive DAergic innervation of the frontal and parietal cortex as well as the spinal cord. To understand PD bradykinesia, a comprehensive network model is needed to study how patterns of DA depletion at key cellular sites in the basal ganglia, cortex and spinal cord contribute to disordered neuronal and spinal cord activity and other PD symptoms. We extend a basal ganglia-cortico-spinal circuit for control of voluntary arm movements by incorporating DAergic innervation of cells in the cortical and spinal components of the circuit. The resultant model simulates successfully several of the main reported effects of DA depletion on neuronal, electromyographic (EMG), and movement parameters of PD bradykinesia.	artificial neural network;basal (phylogenetics);basal ganglia diseases;bradykinesia;depletion region;depletion-load nmos logic;dopamine;electromyography;movement;network model;parietal lobe;parkinson disease;parkinsonian disorders;pars compacta;resultant;spinal cord;substantia nigra structure;ventral tegmental area;nerve supply	Vassilis Cutsuridis;Stavros J. Perantonis	2006	Neural networks : the official journal of the International Neural Network Society	10.1016/j.neunet.2005.08.016	dopamine;computer science;machine learning;artificial neural network	ML	20.388617351613888	-70.89522956447522	33656
47992f3a29ad1847090b854e53745010947b448d	visual representation of cell subpopulation from flow cytometry data	algorithms;cluster analysis;computer graphics;flow cytometry	Flow cytometric systems are useful for protein identification and expression analysis, especially characterizing particular lineage or sublineage of cells. We clustered flow cytometry data of bone marrow cells into subpopulations using a clustering algorithm with its physical characteristics (cell size and cell granularity) and different molecular composition (cell reactivity with monoclonal antibodies). To display the cell subpopulations, we created a colored map according to the mean of 5 flow cytometry parameters based on a cluster. Such a map can reveal subpopulation properties that are not evident in the widely used scatter plot.	algorithm;cluster analysis;flow cytometry;lineage (evolution);statistical cluster	Eun-Young Kim;Qing Zeng-Treitler;Frank C. Kuo;James Rawn;Steven J. Mentzer	2003	AMIA ... Annual Symposium proceedings. AMIA Symposium		scatter plot;bone marrow;flow cytometry;cluster analysis;cell;molecular biology;monoclonal antibody;biology;bioinformatics	Embedded	3.383944002721846	-57.44472282206276	33735
781afa37b6324a7140d6d3f3016adfb338c19a05	the impact of censoring drug switching in medication adherence measures of chronic single ingredient oral drugs.	antihypertensive agents;hypertension;medication adherence	We explored how drug switching impacts adherence measures for common chronic oral medications. Switching between ingredients with the same indication was detected within a 30-day grace period. The proportion of days covered (PDC) and adherent status (cutoff 0.8) for each ingredient was calculated and compared between different censoring approaches: censoring drug switching (PDCswitch), censoring the end of dispensing (PDCend), and fixed 365-day period (PDC365). Overall, 854,380 (15.9%) patients in the Optum ClinFormatics (Optum) and 150,785 (22.0%) patients in the MarketScan Multi-state Medicaid (MDCD) had at least one switch within one year. Compared with PDC365 in Optum, PDCswitch means were higher: 0.85 vs. 0.41 for antihypertensive, 0.82 vs. 0.46 for antihyperglycemics, and 0.84 vs. 0.33 for antihyerlipidemia. Further, the percentages of adherent patients were higher: 95.8% vs. 17.9% for antihypertensive, 85.5% vs. 18.9% for antihyperglycemics, and 72.1% vs. 5.3% for antihyerlipidemia. Significant and modest changes were observed between PDCswitch and PDCend.		Vivienne J. Zhu;J. Marc Overhage;Qianli Ma;Patrick B. Ryan	2017	Studies in health technology and informatics	10.3233/978-1-61499-830-3-1200	drug;ingredient;pharmacology;censoring (statistics);medicine	Arch	9.023516917364043	-75.0311002902909	33780
641784df5360f779e8dd29c0f858266937360cc7	pavis: a tool for peak annotation and visualization	software;genomics;high throughput nucleotide sequencing;sequence analysis dna;internet;chromatin immunoprecipitation;chromatin assembly and disassembly;gene expression regulation;humans;oligonucleotide array sequence analysis	We introduce a web-based tool, Peak Annotation and Visualization (PAVIS), for annotating and visualizing ChIP-seq peak data. PAVIS is designed with non-bioinformaticians in mind and presents a straightforward user interface to facilitate biological interpretation of ChIP-seq peak or other genomic enrichment data. PAVIS, through association with annotation, provides relevant genomic context for each peak, such as peak location relative to genomic features including transcription start site, intron, exon or 5'/3'-untranslated region. PAVIS reports the relative enrichment P-values of peaks in these functionally distinct categories, and provides a summary plot of the relative proportion of peaks in each category. PAVIS, unlike many other resources, provides a peak-oriented annotation and visualization system, allowing dynamic visualization of tens to hundreds of loci from one or more ChIP-seq experiments, simultaneously. PAVIS enables rapid, and easy examination and cross-comparison of the genomic context and potential functions of the underlying genomic elements, thus supporting downstream hypothesis generation.	annotation;base sequence;categories;dna microarray chip;downstream (software development);experiment;gene ontology term enrichment;graphics visualization;imagery;introns;sequence number;transcription (software);transcription initiation site;user interface device component;web application	Weichun Huang;Rasiah Loganantharaj;Bryce Schroeder;David Fargo;Leping Li	2013	Bioinformatics	10.1093/bioinformatics/btt520	biology;genomics;chromatin immunoprecipitation;the internet;regulation of gene expression;bioinformatics;world wide web;genetics	Visualization	-1.6946884037159975	-58.44283575552461	33783
1c866bc6bbc29b704b54754b9247790f9b1522e5	dialign p: fast pair-wise and multiple sequence alignment using parallel processors	software;computational biology bioinformatics;large scale;genome;parallel computer;algorithms;sequence alignment;multiple sequence alignment;combinatorial libraries;computational biology;computer appl in life sciences;genome sequence;multiple alignment;microarrays;bioinformatics	Parallel computing is frequently used to speed up computationally expensive tasks in Bioinformatics. Herein, a parallel version of the multi-alignment program DIALIGN is introduced. We propose two ways of dividing the program into independent sub-routines that can be run on different processors: (a) pair-wise sequence alignments that are used as a first step to multiple alignment account for most of the CPU time in DIALIGN. Since alignments of different sequence pairs are completely independent of each other, they can be distributed to multiple processors without any effect on the resulting output alignments. (b) For alignments of large genomic sequences, we use a heuristics by splitting up sequences into sub-sequences based on a previously introduced anchored alignment procedure. For our test sequences, this combined approach reduces the program running time of DIALIGN by up to 97%. By distributing sub-routines to multiple processors, the running time of DIALIGN can be crucially improved. With these improvements, it is possible to apply the program in large-scale genomics and proteomics projects that were previously beyond its scope.	analysis of algorithms;bioinformatics;cpu (central processing unit of computer system);central processing unit;computation (action);emoticon;heuristics;list of sequence alignment software;multiple sequence alignment;numerous;parallel computing;proteomics;time complexity	Martin Schmollinger;Kay Nieselt;Michael Kaufmann;Burkhard Morgenstern	2004	BMC Bioinformatics	10.1186/1471-2105-5-128	computational biology;biology;multiple sequence alignment;computer science;bioinformatics;theoretical computer science;alignment-free sequence analysis	Comp.	-1.3498055534542652	-52.121412398725234	33860
98dc71628222c8b4ec18520b2a4df8769f5f67e8	network-based filtering of unreliable markers in genome mapping	dna;software;cluster algorithm;genomics;filtering;network theory graphs crops dna genetics genomics molecular biophysics;network based filtering dna markers chromosome genome sequencing sequenced genome assembly genome mapping network based approach pairwise similarities radiation hybrid mapping data wheat genome;neighborhood matrix;genetics;biological cells;molecular biophysics;clustering algorithms;software algorithms;crops;biological cells clustering algorithms genomics bioinformatics software algorithms filtering software;similarity network;genome mapping;network theory graphs;radiation hybrid;neighborhood matrix similarity network unreliable marker lod score;dna marker;genome sequence;lod score;bioinformatics;unreliable marker	Genome mapping, or the experimental determination of the ordering of DNA markers on a chromosome, is an important step in genome sequencing and ultimate assembly of sequenced genomes. The presented research addresses the problem of identifying markers that cannot be placed reliably. If such markers are included in standard mapping procedures they can result in an overall poor mapping. Traditional techniques for identifying markers that cannot be placed consistently are based on resampling, which requires an already computationally expensive process to be done for a large ensemble of resampled populations. We propose a network-based approach that uses pair wise similarities between markers and demonstrate that the results from this approach largely match the more computationally expensive conventional approaches. The evaluation of the proposed approach is done on data from the radiation hybrid mapping of the wheat genome.	analysis of algorithms;baseline (configuration management);cluster analysis;dijkstra's algorithm;map;population;resampling (statistics);run time (program lifecycle phase);whole genome sequencing	Omar Al Azzam;Loai Al Nimer;Charith Chitraranjan;Anne M. Denton;Ajay Kumar;Filippo M. Bassi;Muhammad Javed Iqbal;Shahryar F. Kianian	2011	2011 10th International Conference on Machine Learning and Applications and Workshops	10.1109/ICMLA.2011.103	filter;crop;genomics;whole genome sequencing;gene mapping;genetic linkage;bioinformatics;genetic marker;cluster analysis;dna;molecular biophysics	Visualization	1.1873622012790224	-52.63753529006312	33874
a1593086345af973ec7bc6e76944cf5af4d430d6	ptmtreesearch: a novel two-stage tree-search algorithm with pruning rules for the identification of post-translational modification of proteins in ms/ms spectra	qh301 biology biologia;qa76 computer software programozas	MOTIVATION Tandem mass spectrometry has become a standard tool for identifying post-translational modifications (PTMs) of proteins. Algorithmic searches for PTMs from tandem mass spectrum data (MS/MS) tend to be hampered by noisy data as well as by a combinatorial explosion of search space. This leads to high uncertainty and long search-execution times.   RESULTS To address this issue, we present PTMTreeSearch, a new algorithm that uses a large database of known PTMs to identify PTMs from MS/MS data. For a given peptide sequence, PTMTreeSearch builds a computational tree wherein each path from the root to the leaves is labeled with the amino acids of a peptide sequence. Branches then represent PTMs. Various empirical tree pruning rules have been designed to decrease the search-execution time by eliminating biologically unlikely solutions. PTMTreeSearch first identifies a relatively small set of high confidence PTM types, and in a second stage, performs a more exhaustive search on this restricted set using relaxed search parameter settings. An analysis of experimental data shows that using the same criteria for false discovery, PTMTreeSearch annotates more peptides than the current state-of-the-art methods and PTM identification algorithms, and achieves this at roughly the same execution time. PTMTreeSearch is implemented as a plugable scoring function in the X!Tandem search engine.   AVAILABILITY The source code of PTMTreeSearch and a demo server application can be found at http://net.icgeb.org/ptmtreesearch	amino acids;bioinformatics resource centers;brute-force search;cations;chamaecyparis lawsoniana;editorial;ephrin type-b receptor 1, human;false discovery rate;genetic translation process;hungarian language;informatics;ions;maturity onset diabetes mellitus in young;peptide sequence;phentolamine;plug (physical object);plug-in (computing);polynomial texture mapping;population parameter;post-translational protein processing;relaxation;rule (guideline);run time (program lifecycle phase);score;scoring functions for docking;search algorithm;server (computer);server (computing);signal-to-noise ratio;solutions;source code;stage level 2;tandem mass spectrometry;tracer;tree traversal;trie;web search engine;x tandem scoring engine;format;funding grant	Attila Kertész-Farkas;Beáta Reiz;Roberto Vera;Michael P. Myers;Sándor Pongor	2014	Bioinformatics	10.1093/bioinformatics/btt642	biology;computer science;bioinformatics;machine learning;data mining	Comp.	-0.7940427020407489	-52.99436832645436	33891
fa09646f53a33d9c6df24971e8a1de27a9e1b8fc	a health care information system for neonatology support	image features;plantar region;post birth evaluation;newborn children;medical image retrieval;pediatrics;information systems;logical relationships health care information system neonatology support gestational age determination newborn children survival possibility evaluation qualified pre natal attendance post birth evaluation medical image retrieval system footscan dermatoglyphics plantar region foot sole knowledge level patient information image features;image databases;information retrieval;health care information system;skin;footscan;logical relationships;knowledge level;qualified pre natal attendance;biomedical imaging;patient information;medical image retrieval system;medical services;skin paediatrics obstetrics health care medical information systems image retrieval visual databases;paediatrics;medical information systems;gestational age;survival possibility evaluation;foot sole;digital image;gestational age determination;medical treatment;dermatoglyphics;digital images;obstetrics;medical diagnostic imaging;medical services information systems pediatrics biomedical imaging medical diagnostic imaging image retrieval medical treatment digital images image databases information retrieval;neonatology support;visual databases;health care;image retrieval	The determination of gestational age in newborn children is fundamental to the evaluation of their survival possibilities. In many cases, when the qualified pre-natal attendance has not occurred, the post-birth evaluation of the gestational age becomes the only alternative. This paper presents a medical image retrieval system whose goal is to help to confirm a new method (called FootScan) for gestational age determination, through the digital image of the dermatoglyphics from the plantar (sole of the foot) region of the newborn. The system includes a level of knowledge, associated with the database, which stores information from the patients, together with image features and their logical relationships.	information system	C. N. Gorga;J. N. Marchaukoski;Marcos Sfair Sunyé;Olga R. P. Bellon;Luciano Silva;Mônica N. L. Cat	2002		10.1109/CBMS.2002.1011350	medical imaging;computer vision;medicine;image retrieval;computer science;pediatrics;digital image	HCI	0.985758634593736	-78.32926451426657	33929
256721237b692bf142efa37ff7971cd8483ce231	accounting for seasonal patterns in syndromic surveillance data for outbreak detection	emergency department;forecasting;health informatics;detection probability;data interpretation statistical;seasonal variation;data collection;new mexico;syndrome;seasons;hospitals university;information systems and communication service;population surveillance;moving average;seasonal pattern;likelihood functions;sequential test;respiration disorders;seasonality;syndromic surveillance;management of computing and information systems;predictive value of tests;true positive;models statistical;risk assessment;emergency service hospital;humans;model fitting;computer simulation;seasonal effect;hierarchical model;forecasting method;performance assessment;disease outbreaks	"""BACKGROUND Syndromic surveillance (SS) can potentially contribute to outbreak detection capability by providing timely, novel data sources. One SS challenge is that some syndrome counts vary with season in a manner that is not identical from year to year. Our goal is to evaluate the impact of inconsistent seasonal effects on performance assessments (false and true positive rates) in the context of detecting anomalous counts in data that exhibit seasonal variation.   METHODS To evaluate the impact of inconsistent seasonal effects, we injected synthetic outbreaks into real data and into data simulated from each of two models fit to the same real data. Using real respiratory syndrome counts collected in an emergency department from 2/1/94-5/31/03, we varied the length of training data from one to eight years, applied a sequential test to the forecast errors arising from each of eight forecasting methods, and evaluated their detection probabilities (DP) on the basis of 1000 injected synthetic outbreaks. We did the same for each of two corresponding simulated data sets. The less realistic, nonhierarchical model's simulated data set assumed that """"one season fits all,"""" meaning that each year's seasonal peak has the same onset, duration, and magnitude. The more realistic simulated data set used a hierarchical model to capture violation of the """"one season fits all"""" assumption.   RESULTS This experiment demonstrated optimistic bias in DP estimates for some of the methods when data simulated from the nonhierarchical model was used for DP estimation, thus suggesting that at least for some real data sets and methods, it is not adequate to assume that """"one season fits all.""""   CONCLUSION For the data we analyze, the """"one season fits all """" assumption is violated, and DP performance claims based on simulated data that assume """"one season fits all,"""" for the forecast methods considered, except for moving average methods, tend to be optimistic. Moving average methods based on relatively short amounts of training data are competitive on all three data sets, but are particularly competitive on the real data and on data from the hierarchical model, which are the two data sets that violate the """"one season fits all"""" assumption."""	assumed;estimated;estimation of distribution algorithm;evaluation procedure;fits;hierarchical database model;one thousand;onset (audio);prism (surveillance program);probability;projections and predictions;public health surveillance;respiratory distress syndrome, adult;seasonality;sensor;synthetic data;synthetic intelligence	Tom Burr;Todd L. Graves;Richard Klamann;Sarah Ellen Michalak;Richard Picard;Nicolas W. Hengartner	2006	BMC Medical Informatics and Decision Making	10.1186/1472-6947-6-40	computer simulation;health informatics;simulation;medicine;data mining;operations research;seasonality;statistics	ML	6.588931447582024	-72.77234057604441	34023
02d6df9e7d1c857fd55287caf9a8c703806470d3	gril: genome rearrangement and inversion locator	site web;phylogeny;bacterie;genome rearrangement;phylogenese;secuencia nucleotido;nucleotide sequence;sequence nucleotide;algorithme;algorithm;descripcion;identification;filogenesis;genome;identificacion;bacteria;genoma;sitio web;multiple;description;web site;algoritmo	UNLABELLED GRIL is a tool to automatically identify collinear regions in a set of bacterial-size genome sequences. GRIL uses three basic steps. First, regions of high sequence identity are located. Second, some of these regions are filtered based on user-specified criteria. Finally, the remaining regions of sequence identity are used to define significant collinear regions among the sequences. By locating collinear regions of sequence, GRIL provides a basis for multiple genome alignment using current alignment systems. GRIL also provides a basis for using current inversion distance tools to infer phylogeny.   AVAILABILITY GRIL is implemented in C++ and runs on any x86-based Linux or Windows platform. It is available from http://asap.ahabs.wisc.edu/gril	c++;dna sequence rearrangement;inference;linux;microsoft windows;online locator service;phylogenetics;sequence alignment	Aaron E. Darling;Bob Mau;Frederick R. Blattner;Nicole T. Perna	2004	Bioinformatics	10.1093/bioinformatics/btg378	identification;biology;bacteria;nucleic acid sequence;bioinformatics;genetics;multiple;phylogenetics;genome	Comp.	-3.998045940715623	-56.1528563210126	34081
4102ccf74cd23e64275462fd926d6a814c875290	composite module analyst: a fitness-based tool for identification of transcription factor binding site combinations	gene expression profile;causal analysis;gene regulation;transcription factor binding site;gene expression data;genetics;gene expression;transcription factor;fitness function	MOTIVATION Functionally related genes involved in the same molecular-genetic, biochemical or physiological process are often regulated coordinately. Such regulation is provided by precisely organized binding of a multiplicity of special proteins [transcription factors (TFs)] to their target sites (cis-elements) in regulatory regions of genes. Cis-element combinations provide a structural basis for the generation of unique patterns of gene expression.   RESULTS Here we present a new approach for defining promoter models based on the composition of TF binding sites and their pairs. We utilize a multicomponent fitness function for selection of the promoter model that fits best to the observed gene expression profile. We demonstrate examples of successful application of the fitness function with the help of a genetic algorithm for the analysis of functionally related or co-expressed genes as well as testing on simulated and permutated data.   AVAILABILITY The CMA program is freely available for non-commercial users. URL http://www.gene-regulation.com/pub/programs.html#CMAnalyst. It is also a part of the commercial system ExPlain (www.biobase.de) designed for causal analysis of gene expression data..	binding sites;cma-es;causal filter;certified medical assistant (occupation);commercial software;contribution;curie;dna binding site;elsevier biobase;emoticon;experiment;fits;fitness function;gene expression profiling;genetic algorithm;genetics, biochemical;mathematical optimization;microarray;physiological processes;published database;regulated rewriting;regulatory sequences, nucleic acid;science;scientific publication;software system;transcription factor;the matrix;transcription (software);transcriptional regulation;transistor;uniform resource locator;word lists by frequency;chaperone-mediated autophagy;multiplicity;promoter	Alexander E. Kel;Tatiana Konovalova;T. Waleev;Evgeny Cheremushkin;Olga V. Kel-Margoulis;Edgar Wingender	2006	Bioinformatics	10.1093/bioinformatics/btl041	biology;cis-regulatory element;molecular biology;regulation of gene expression;gene expression;bioinformatics;cis-regulatory module;fitness function;genetics;promoter;dna binding site;transcription factor	Comp.	1.9489335250683022	-58.73384533078432	34108
dfe4ab56778e7866ec6a7657598ba955f370f0fd	characterization of three new snrnas from saccharomyces cerevisiae: snr34, snr35 and snr36	alleles;blotting northern;sequence homology;saccharomyces cerevisiae;rna caps;cloning molecular;immunosorbent techniques;conserved sequence;dna restriction enzymes;cell nucleolus;rna small nuclear;molecular sequence data;rna ribosomal;chromosomal proteins non histone;base sequence;mutagenesis;rna fungal	Genes for three novel snRNAs of Saccharomyces cerevisiae have been isolated, sequenced and tested for essentiality. The RNAs encoded by these genes are designated snR34, snR35 and snR36 respectively and contain 203, 204 and 182 nucleotides. Each RNA is derived from a single copy gene and all three RNAs are believed to be nucleolar, i.e. snoRNAs, based on extraction properties and association with fibrillarin. SnR34 and snR35 contain a trimethylguanosine cap, but this feature is absent from snR36. The novel RNAs lack elements conserved among several other snoRNAs, including box C, box D and long sequence complementarities with rRNA. Genetic disruption analyses showed each of the RNAs to be dispensable and a haploid strain lacking all three RNAs and a previously characterized fourth snoRNA (snR33) is also viable. No differences in the levels of precursors or mature rRNAs were apparent in the four gene knock-out strain. Possible roles for the new RNAs in ribosome biogenesis are discussed.	complementarity theory;denial-of-service attack;fbl gene;haploidy;nucleotides;rna;ribosomes	Dmitry A. Samarsky;A. G. Balakin;Maurille J. Fournier	1995	Nucleic acids research	10.1093/nar/23.13.2548	allele;biology;mutagenesis;molecular biology;bioinformatics;small nucleolar rna;conserved sequence;nucleolus;long non-coding rna;genetics	Comp.	4.449388667634936	-62.2120422121964	34116
1b85fcc509e2c761cfa6016633fd029ba5cd5883	laneruler: automated lane tracking for dna electrophoresis gel images	dna;genomics bioinformatics dna feature extraction;analisis imagen;genomics;tiempo iniciacion;agua abajo;control de calidad;pistage;lane keeping;image processing;gel electrophoresis;analisis datos;image processing automation electrophoresis image analysis;calidad de logical;etude experimentale;electrophoresis;gel fisico;heuristic method;dna fingerprinting;biologia molecular;rastreo;procesamiento imagen;physical gel;bioinformatique;electroforesis gel;hombre;automatisation;metodo heuristico;gene rearrangement;mantenimiento dentro del carril;temps mise en route;automatizacion;traitement image;redisposicion genica;data analysis;setup time;analyse tâche;analisis de tareas;feature extraction;molecular biology;task analysis;genome;human;electrophorese gel;dna electrokinetics bioinformatics genomics image analysis humans data mining inspection laboratories automation;controle qualite;completitud;analyse donnee;aval;image analysis;downstream;gel physique;methode heuristique;genoma;bioinformatica;completeness;suivi de voie;quality control;completude;analyse image;estudio experimental;qualite logiciel;software quality;tracking;agarose electrophoretic lanes laneruler automated lane tracking dna electrophoresis gel images;homme;bioinformatics;rearrangement genique;biologie moleculaire;automation	We present a novel method for correctly identifying and straightening one dimensional agarose electrophoretic lanes. Our method has been shown to yield comparable accuracy with manual lane tracking results, and to successfully process 98% of DNA fingerprinting gels with no human intervention.	dna barcoding;dna profiling;fingerprint (computing)	R. T. F. Wong;Stephane Flibotte;Richard Corbett;P. Saeedi;Steven J. M. Jones;Marco A. Marra;Jacqueline E. Schein;Inanç Birol	2010	IEEE Transactions on Automation Science and Engineering	10.1109/TASE.2009.2035437	downstream;quality control;genomics;dna profiling;image analysis;electrophoresis;image processing;feature extraction;completeness;computer science;bioinformatics;automation;gel electrophoresis;task analysis;tracking;data analysis;dna;software quality;genome	Visualization	-4.325026621470497	-55.91433502142477	34179
f7d440d2ff12e349635293e5d8790d53b9795d2c	risk feature assessment of readmission for diabetes	machine learning algorithms;hospitals;diabetes;vegetation;logistics;diseases;medical diagnostic imaging	About 382 million people have Diabetes in 2013, and the International Diabetes Federation estimated that there are 4.9 million people died from Diabetes in 2014. Diabetes continues to be a chronic disease plagued by frequent hospital readmissions. In order to better understand the risk features impacting readmissions for future prevention and management, in this study, we programmatically analyzed a large clinical dataset containing more than 100,000 clinical records for diabetes patients from 130 US hospitals. Specifically, we developed three different machine learning algorithms, Logistic Regression, Random Forest and manipulated Random Forest to identify and prioritize the most significant risk features. By comparing the results generated by these three methods, the manipulated Random Forest illustrates greater capacity of generating a more complete and concrete list of readmission related risk features. Such method is generalizable and can be applied in other disease oriented studies.	algorithm;list of code lyoko episodes;logistic regression;machine learning;random forest	Qian Zhu;Anirudh Akkati;Pornpoh Hongwattanakul	2016	2016 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)	10.1109/BIBM.2016.7822578	biology;logistics;simulation;data mining;vegetation	DB	4.5555664140796726	-75.71712829525728	34192
316e98bbf208482eb98c22208a9f4535d2d290a4	paidb v2.0: exploration and analysis of pathogenicity and resistance islands	drug resistance microbial;databases nucleic acid;virulence;internet;genome microbial;genomic islands	Pathogenicity is a complex multifactorial process confounded by the concerted activity of genetic regions associated with virulence and/or resistance determinants. Pathogenicity islands (PAIs) and resistance islands (REIs) are key to the evolution of pathogens and appear to play complimentary roles in the process of bacterial infection. While PAIs promote disease development, REIs give a fitness advantage to the host against multiple antimicrobial agents. The Pathogenicity Island Database (PAIDB, http://www.paidb.re.kr) has been the only database dedicated to providing comprehensive information on all reported PAIs and candidate PAIs in prokaryotic genomes. In this study, we present PAIDB v2.0, whose functionality is extended to incorporate REIs. PAIDB v2.0 contains 223 types of PAIs with 1331 accessions, and 88 types of REIs with 108 accessions. With an improved detection scheme, 2673 prokaryotic genomes were analyzed to locate candidate PAIs and REIs. With additional quantitative and qualitative advancements in database content and detection accuracy, PAIDB will continue to facilitate pathogenomic studies of both pathogenic and non-pathogenic organisms.	access network;bacterial infections;brain diseases, metabolic;colony count, microbial;communicable diseases;computation;experiment;genome;metagenomics;microbicides;nar 2;pathogenic organism;pathogenicity islands;project resistance;sensor;thyroid hormone resistance syndrome;usability;virulence;web application	Sung Ho Yoon;Young Kyu Park;Jihyun F. Kim	2015		10.1093/nar/gku985	biology;the internet;bioinformatics;virulence;genetics	Vision	1.413756519524545	-59.862074102673084	34221
844b1123b5876f2230fbe3260b20d5f888f225cd	measuring prediction capacity of individual verbs for the identification of protein interactions	web pages;information extraction;text mining;text processing;protein protein interaction;protein interaction;semantic relations	"""MOTIVATION The identification of events such as protein-protein interactions (PPIs) from the scientific literature is a complex task. One of the reasons is that there is no formal syntax to denote such relations in the scientific literature. Nonetheless, it is important to understand such relational event representations to improve information extraction solutions (e.g., for gene regulatory events). In this study, we analyze publicly available protein interaction corpora (AIMed, BioInfer, BioCreAtIve II) to determine the scope of verbs used to denote protein interactions and to measure their predictive capacity for the identification of PPI events. Our analysis is based on syntactical language patterns. This restriction has the advantage that the verb mention is used as the independent variable in the experiments enabling comparability of results in the usage of the verbs. The initial selection of verbs has been generated from a systematic analysis of the scientific literature and existing corpora for PPIs. We distinguish modifying interactions (MIs) such as posttranslational modifications (PTMs) from non-modifying interactions (NMIs) and assumed that MIs have a higher predictive capacity due to stronger scientific evidence proving the interaction. We found that MIs are less frequent in the corpus but can be extracted at the same precision levels as PPIs. A significant portion of correct PPI reportings in the BioCreAtIve II corpus use the verb """"associate"""", which semantically does not prove a relation. The performance of every monitored verb is listed and allows the selection of specific verbs to improve the performance of PPI extraction solutions. Programmatic access to the text processing modules is available online (www.ebi.ac.uk/webservices/whatizit/info.jsf) and the full analysis of Medline abstracts will be made through the Web pages of the Rebholz group."""	abstract summary;assumed;biocreative;body of uterus;experiment;formal grammar;information extraction;medline;nmi gene;non-maskable interrupt;page (document);pixel density;post-translational protein processing;proton pump inhibitors;soap;scientific literature;solutions;text corpus;web page;world wide web;non-t, non-b childhood acute lymphoblastic leukemia;protein protein interaction;verbs	Dietrich Rebholz-Schuhmann;Antonio Jimeno-Yepes;Miguel Arregui;Harald Kirsch	2010	Journal of biomedical informatics	10.1016/j.jbi.2009.09.007	protein–protein interaction;natural language processing;text mining;computer science;bioinformatics;artificial intelligence;machine learning;web page;data mining;database;information extraction;information retrieval	NLP	-2.402263418685924	-64.1983312718828	34222
18b6a0a8f2c5071f901905f2da65b815677d440c	decomposing the neural mechanisms of visual search through model-based analysis of fmri: top-down excitation, active ignoring and the use of saliency by the right tpj	unilateral neglect;activation function;top down;model based approach;visual search;clinical study	Despite being studied intensively over the past 30 years, the neural processes underlying visual search are not yet fully understood. In the current study we extend prior work using model-based analysis to decompose fMRI data. fMRI data on human search were assessed using activation functions predicted from the spiking Search over Time and Space model (sSoTS; Mavritsaki et al., 2006). Going beyond previous work, we show for the first time that activity in a central location map in the model, which computes the saliency of a target relative to distractors, correlated with the BOLD response in the right temporo-parietal junction (TPJ)--a key region implicated in clinical studies of unilateral neglect. This is consistent with the right TPJ responding to the relative saliency of visual stimuli. In addition, a re-analysis of search performance, with a larger participant set and a psychologically plausible response rule, showed distinct neural regions in parietal and occipital cortices linked to top-down excitation and the to active ignoring of distractors. The results indicate that excitatory and inhibitory circuits for visual selection can be separated, and that the right TPJ may be critical for responding to salient targets. The value of using a model-based approach is discussed.	excitation;large;parietal lobe;p–n junction;top-down and bottom-up design;fmri	Eirini Mavritsaki;Harriet A. Allen;Glyn W. Humphreys	2010	NeuroImage	10.1016/j.neuroimage.2010.03.044	psychology;computer vision;visual search;top-down and bottom-up design;activation function;communication;social psychology	ML	17.930379663456982	-74.36598959174343	34246
e6d92933575cd182f3c7264323525c1d93c6a8df	quantifiable comparative analysis of vaccinated versus unvaccinated patients in dermatologic applications		Chickenpox is caused by the varicella-zoster virus (a member of the herpes virus family), which can be spread through the air or by direct contact with an infected person. It produces an itchy, blistery rash that typically lasts about a week and is sometimes accompanied by a fever or other symptoms but primarily manifested by numerous blisters. A single attack of chickenpox almost always brings lifelong immunity against the disease. Safe and effective vaccination represents good protection against chickenpox. The developed algorithm for a quantifiable visual symptoms of varicella evaluation was applied for a comparative assessment of the degree of disease manifestations in two groups of patients. This process demonstrates the levels of vaccination effectiveness and can be applied having images taken under different clinical conditions. This effective technique can be extended to other dermatologic applications with similar visual symptoms.	algorithm;qualitative comparative analysis;trusted computer system evaluation criteria	Vesna Zeljkovic;Claude Tameze;Christopher Druzgalski;Pedro Mayorga	2017	2017 IEEE 30th Canadian Conference on Electrical and Computer Engineering (CCECE)	10.1109/CCECE.2017.7946735	control engineering;computer science;dermatology;immune system;rash;disease;immunity;chickenpox;virus;visual symptoms;vaccination	Visualization	10.851778704567476	-77.78011083914235	34251
02fa751a3956bfa126847f7b2d8626b7dae0b9e3	generalized fragment-substructure based property prediction method		The need for fast and accurate predictors of pharmaceutically important properties has been increasing due to pressure from high-throughput screening, in-silico screening, and the need to more rapidly identify potential pharmacokinetic issues before drugs advance to the more expensive clinical development stages. A novel method for making predictive models based on decomposing 2D structure into component structural fragments is used to model logP, water solubility, and melting point. The fragment orientation of the method facilitates understanding of how molecules might be altered to improve the desired properties. The 2D structure-based descriptor is computed by analysis of the target molecules with a substructure searching algorithm and a set of fragments selected for chemical and pharmaceutical relevance. These are combined with partial least squares to create predictive models. The correlation coefficients achieved are 0.86 for logP (SE = 0.68), 0.73 for logS (SE = 0.89), and 0.64 (SE = 48.9 degrees) for melting point over diverse data sets of 11,447, 2427, and 5598 molecules, respectively. The models were verified via test sets of compounds not included in the training set.		Matthew Clark	2005	Journal of chemical information and modeling	10.1021/ci049744c	bioinformatics;substructure;partial least squares regression;search algorithm;computer science	ML	10.807480505198663	-58.436436027392126	34285
2fab82996cc90284b350ab41e0079157b1501c0e	lcrs in diseases: analysis of human hypothetical proteins	low complexity region;lcr;hypothetical proteins;drug targets;diseases	Low complexity regions (LCRs) in proteins are sequences containing regular repeats, cryptic repeats and single amino acid repetitions, recognised by their compositional bias. These sequences are structurally disordered, and are found to participate in signalling and post-translational modifications, mediating protein-protein and protein-RNA interactions. Apart from their normal roles, LCRs are observed in diseased proteins as well. Presence of LCRs in proteins sequences also reduces the certainty to decipher their possible functions, thereby classifying them as ‘hypothetical proteins’. An insilico attempt has been carried out to investigate these LCRs in hypothetical proteins from human genome to establish their relationships with diseases.	hypothetical protein	N. Rathankar;Vaibhav Asthana;Tapan Pancholi;K. A. Nirmala;Holenarasipur GunduRao Nagendra	2011	IJMEI	10.1504/IJMEI.2011.041234	bioinformatics	NLP	5.724744141964774	-62.6304815981071	34321
762025e495c02f215d0133eb82691d20358ea12c	sequence-structure specificity of a knowledge based energy function at the secondary structure level	sequence specificity;prediccion;computer program;proteine;fonction energie;structure secondaire;estructura terciaria;amino acid sequence;energy function;estructura secundaria;secondary structure;ornl;funcion energia;proteina;protein;programa computador;prediction;structure tertiaire;espicificidad secuencia;programme ordinateur;specificite sequence;tertiary structure;knowledge base	MOTIVATION This paper investigates the sequence-structure specificity of a representative knowledge based energy function by applying it to threading at the level of secondary structures of proteins. Assessing the strengths and weaknesses of an energy function at this fundamental level provides more detailed and insightful information than at the tertiary structure level and the results obtained can be useful in tertiary level threading.   RESULTS We threaded each of the 293 non-redundant proteins onto the secondary structures contained in its respective native protein (host template). We also used 68 pairs of proteins with similar folds and low sequence identity. For each pair, we threaded the sequence of one protein onto the secondary structures of the other protein. The discerning power of the total energy function and its one-body, pairwise, and mutation components is studied. We then applied our energy function to a recent study which demonstrated how a designed 11-amino acid sequence can replace distinct segments (one segment is an alpha-helix, the other is a beta-sheet) of a protein without changing its fold. We conducted random mutations of the designed sequence to determine the patterns for favorable mutations. We also studied the sequence-structure specificity at the boundaries of a secondary structure. Finally, we demonstrated how to speed up tertiary level threading by filtering out alignments found to be energetically unfavorable during the secondary structure threading.   AVAILABILITY The program is available on request from the authors.   CONTACT xud@ornl.gov	amino acid metabolism, inborn errors;amino acid sequence;clinical use template;contain (action);mathematical optimization;mutation;numerical analysis;sensitivity and specificity;sequence alignment;staphylococcal protein a;thread (computing);threading (protein sequence);weakness;tertiary	Dong Xu;Michael A. Unseren;Ying Xu;Edward C. Uberbacher	2000	Bioinformatics	10.1093/bioinformatics/16.3.257	biology;knowledge base;protein tertiary structure;prediction;computer science;bioinformatics;artificial intelligence;peptide sequence;protein secondary structure	Comp.	8.38285105715225	-60.41911712379886	34389
25cfdf37ee49225da9302a4377f8df4a3bbfb794	mapping the 3d structures of small molecule binding sites	binding site prediction;binding site comparison;computer applications in chemistry;journal article;theoretical and computational chemistry;computational biology bioinformatics;protein structure;mapping binding site space;documentation and information in chemistry	Background: Analysis of the 3D structures of protein–ligand binding sites can provide valuable insights for drug discovery. Binding site comparison (BSC) studies can be employed to elucidate the function of orphan proteins or to predict the potential for polypharmacology. Many previous binding site analyses only consider binding sites surrounding an experimentally observed bound ligand. Results: To encompass potential protein–ligand binding sites that do not have ligands known to bind, we have incorporated fpocket cavity detection software and assessed the impact of this inclusion on BSC performance. Using fpocket, we generated a database of ligand-independent potential binding sites and applied the BSC tool, SiteHopper, to analyze similarity relationships between protein binding sites. We developed a method for clustering potential binding sites using a curated dataset of structures for six therapeutically relevant proteins from diverse protein classes in the protein data bank. Two clustering methods were explored; hierarchical clustering and a density-based method adept at excluding noise and outliers from a dataset. We introduce circular plots to visualize binding site structure space. From the datasets analyzed in this study, we highlight a structural relationship between binding sites of cationic trypsin and prothrombin, protein targets known to bind structurally similar small molecules, exemplifying the potential utility of objectively and holistically mapping binding site space from the structural proteome. Conclusions: We present a workflow for the objective mapping of potential protein–ligand binding sites derived from the currently available structural proteome. We show that ligand-independent binding site detection tools can be introduced without excessive penalty on BSC performance. Clustering combined with intuitive visualization tools can be applied to map relationships between the 3D structures of protein binding sites.	binary symmetric channel;cluster analysis;dna binding site;experiment;hierarchical clustering;holism;protein data bank	Joshua Meyers;Nathan Brown;Julian Blagg	2016		10.1186/s13321-016-0180-0	protein structure;biophysics;bioinformatics	Comp.	4.111667974956689	-57.26955033328268	34425
74acfb8b90521a3b76f0d52a78c172aef8bbcc33	region of attraction estimation of biological continuous boolean models	lyapunov methods;lyapunov stability;boolean functions;lyapunov stability region of attraction continuous boolean modeling hill functions interval analysis;continuous boolean modeling;hillcube continuous boolean approximation biological continuous boolean model quantitative analysis day health problem environmental problem model analysis approach modelling development approach biological process continuous approximation biochemical pathway inferred dependency relationship nonlinear equation nonlinear dynamics roa estimation region of attraction biosystems modeling computational technique rb e2f signaling pathway continuous boolean function;biological system modeling;hill functions;biology;approximation theory;computational modeling;trajectory;estimation;nonlinear equations approximation theory biology boolean functions;mathematical model;biological systems;nonlinear equations;region of attraction;biological system modeling lyapunov methods mathematical model estimation trajectory computational modeling biological systems;interval analysis	Quantitative analysis of biological systems has become an increasingly important research field as scientists look to solve current day health and environmental problems. The development of modeling and model analysis approaches that are specifically geared toward biological processes is a rapidly growing research area. Continuous approximations of Boolean models, for example, have been identified as a viable method for modeling such systems. This is because they are capable of generating dynamic models of biochemical pathways using inferred dependency relationships between components. The resulting nonlinear equations and therefore nonlinear dynamics, however, can present a challenge for most system analysis approaches such as region of attraction (ROA) estimation. Continued progress in the area of biosystems modeling will require that computational techniques used to analyze simple nonlinear systems can still be applied to nonlinear equations typically used to model the dynamics associated with biological processes. In this paper, we assess the applicability of a state of the art ROA estimation technique based on interval arithmetic to a subnetwork of the Rb-E2F signaling pathway modeled using continuous Boolean functions. We show that this method can successfully be used to provide an estimate of the ROA for dynamic models described using Hillcube continuous Boolean approximations.	algorithm;approximation;biological system;boolean algebra;gene regulatory network;interval arithmetic;lyapunov fractal;newton's method;nonlinear system;resource-oriented architecture;subnetwork;system analysis	Michelle Matthews;C. M. Williams	2012	2012 IEEE International Conference on Systems, Man, and Cybernetics (SMC)	10.1109/ICSMC.2012.6377982	mathematical optimization;estimation;combinatorics;discrete mathematics;nonlinear system;trajectory;machine learning;mathematical model;control theory;mathematics;boolean function;computational model;statistics;approximation theory	Robotics	10.089634515810621	-68.05188261200138	34446
a64774241f0ef08b2d605f7f5ceb16763dd5c6c6	a bayesian approach using covariance of single nucleotide polymorphism data to detect differences in linkage disequilibrium patterns between groups of individuals	software;sample size;linkage equilibrium;dato;covariancia;bayesian approach;genotype;deteccion;methode bayes;nucleotido;data;liaison genetique;genome wide association study;bayes theorem;polimorfismo mononucleotido;grupo ligamiento;covariance;equilibre linkage;detection;individu;genetic mapping;groupe liaison;individual;nucleotide;polymorphisme mononucleotide;genetic linkage;donnee;genome;linkage group;carte genetique;humans;equilibrio ligazon;mapa genetico;individuo;linkage disequilibrium;polymorphism single nucleotide;single nucleotide polymorphism;ligamiento genetico	MOTIVATION Quantifying differences in linkage disequilibrium (LD) between sub-groups can highlight genetic regions or sites under selection and/or associated with disease, and may have utility in trans-ethnic mapping studies.   RESULTS We present a novel pseudo Bayes factor (PBF) approach that assess differences in covariance of genotype frequencies from single nucleotide polymorphism (SNP) data from a genome-wide study. The magnitude of the PBF reflects the strength of evidence for a difference, while accounting for the sample size and number of SNPs, without the requirement for permutation testing to establish statistical significance. Application of the PBF to HapMap and Gambian malaria SNP data reveals regional LD differences, some known to be under selection.   AVAILABILITY AND IMPLEMENTATION The PBF approach has been implemented in the BALD (Bayesian analysis of LD differences) C++ software, and is available from http://homepages.lshtm.ac.uk/tgclark/downloads.	bayes factor;c++;international hapmap project;linkage disequilibrium;nucleotides;p-value;pseudo brand of pseudoephedrine;sex factors;single nucleotide polymorphism;single-chain antibodies;source-to-source compiler	Taane G. Clark;Susana G. Campino;Elisa Anastasi;Sarah Auburn;Yik Y. Teo;Kerrin S. Small;Kirk A. Rockett;Dominic Kwiatkowski;Christopher C. Holmes	2010	Bioinformatics	10.1093/bioinformatics/btq327	linkage disequilibrium;biology;bioinformatics;genetics	Comp.	4.604434372309042	-52.65118240070795	34571
10779f436e2f2be888c7c0d123564d18acf497d1	computational complementation: a modelling approach to study signalling mechanisms during legume autoregulation of nodulation	cotyledon;computational complementation approach;plant physiological phenomena;genetic complementation test;nodule number;structural modelling;systems biology;signal transduction;soybean proteins;autoregulation of nodulation aon;models biological;root nodules plant;computer modelling;plos computational biology;transport;long distance;glycine max;receptor kinase;real plant experimentation;auxin;soybean;root;empirical model;in silico plant;soybeans;shoot derived inhibitor sdi;legume plants;wild type;architecture;computer simulation;distance;plant shoots	"""Autoregulation of nodulation (AON) is a long-distance signalling regulatory system maintaining the balance of symbiotic nodulation in legume plants. However, the intricacy of internal signalling and absence of flux and biochemical data, are a bottleneck for investigation of AON. To address this, a new computational modelling approach called """"Computational Complementation"""" has been developed. The main idea is to use functional-structural modelling to complement the deficiency of an empirical model of a loss-of-function (non-AON) mutant with hypothetical AON mechanisms. If computational complementation demonstrates a phenotype similar to the wild-type plant, the signalling hypothesis would be suggested as """"reasonable"""". Our initial case for application of this approach was to test whether or not wild-type soybean cotyledons provide the shoot-derived inhibitor (SDI) to regulate nodule progression. We predicted by computational complementation that the cotyledon is part of the shoot in terms of AON and that it produces the SDI signal, a result that was confirmed by reciprocal epicotyl-and-hypocotyl grafting in a real-plant experiment. This application demonstrates the feasibility of computational complementation and shows its usefulness for applications where real-plant experimentation is either difficult or impossible."""	angular defect;class diagram;color gradient;complement system proteins;computation;cotyledon plant;fabaceae;homeostasis;hypocotyl;biological signaling;nodulation	Liqi Han;Jim Hanan;Peter M. Gresshoff	2010		10.1371/journal.pcbi.1000685	computer simulation;biology;transport;botany;cotyledon;biotechnology;architecture;root;agronomy;distance;wild type;systems biology;signal transduction;auxin	NLP	7.009269453594361	-59.68587583206244	34604
f0a204098382c128d094d02db5dd3ee7a0fb011e	transient versus asymptotic dynamics of cam kinase ii: possible roles of phosphatase	long term potentiation;cam kinase ii;enzyme;transient dynamics;computational enzymology;frequency sensitivity;quantitative analysis;signaling pathway;calmodulin;protein kinase;enzyme kinetics;protein phosphatase 1	Calmodulin-dependent protein kinase II (CaMKII) is known to play a key role during induction of long-term potentiation (LTP). Given the dependence of LTP on the frequency of synaptic activation, several previous modeling efforts have proposed that biochemical properties of CaMKII itself might be in part responsible for this dependence. Recently, De Koninck and Schulman (1998) have provided direct experimental evidence that the enzyme itself is sensitive to the frequency of Ca2+ activation. Here we demonstrate the ability of a detailed biophysical model constructed solely on enzyme kinetics of purified proteins to generate the frequency sensitivity demonstrated by De Koninck and Schulman. Quantitative analysis of the model reveals that this frequency sensitivity is provided by a mechanism different from those previously postulated. This analysis leads to specific predictions concerning the effects of mutations on this process. We further employ the model to examine the asymptotic behavior of CaMKII-phosphatase system during longer simulated periods of stimulation. The analyses of the model suggest that the transient and asymptotic frequency sensitivity of this enzyme are dependent on different biochemical mechanisms. These results may be applicable to Ca2+/calmodulin signaling pathways in general.	asymptote;calcium ion;enzyme kinetics (discipline);kinetics internet protocol;long-term potentiation;mutation;protein kinases;synaptic package manager;calmodulin-dependent protein kinase ii;chemosensitization/potentiation	Yoshihisa Kubota;James M. Bower	2001	Journal of Computational Neuroscience	10.1023/A:1013727331979	enzyme;long-term potentiation;quantitative analysis;enzyme kinetics;calmodulin;protein kinase a;signal transduction	Comp.	8.117892245119549	-64.57121711493114	34609
fdea5bf5f09946b621b3585241e0d7e84b71e476	detecting changes in dna copy number: reviewing signal processing techniques	dna;genomics;cancer;biological signal dna copy number signal processing techniques genome natural genetic diversity cancer genetic diseases microarray technology severe noise degradation measurement;molecular biophysics genomics genetics medical diagnosis biomedical signal processing proteomics;genetic diversity;noise measurement;copy number;signal processing;very high resolution;diseases;high throughput;dna copy number;noise measurement biochemistry biomedical measurement cancer diseases dna genomics medical signal processing;biomedical measurement;medical signal processing;biochemistry;measurement noise;genetic disease	Alterations in the number of DNA copies of portions of a genome are both a process that contributes to natural genetic diversity in healthy individuals and also a driving cause for cancer and other genetic diseases. Even though recent advances in microarray technology and high throughput sequencing now allow very high resolution scans for very large cohorts of samples, small alterations remain particularly difficult to detect, especially under severe noise degradation conditions. Thus, estimation of the DNA copy number remains a challenging problem. Some of the core challenges in copy number estimation can be seen as essentially signal processing problems, where it is necessary to exploit fundamentally different characteristics between the desired underlying biological signal and the measurement noise. Indeed, some of the most successful methods used to address this problem have been inspired by well-known signal processing techniques.	elegant degradation;microarray;sensor;signal processing;throughput	Roger Pique-Regi;Antonio Ortega;Ahmed H. Tewfik;Shahab Asgharzadeh	2012	IEEE Signal Processing Magazine	10.1109/MSP.2011.943010	high-throughput screening;genomics;bioinformatics;noise measurement;signal processing;copy-number variation;genetic diversity;dna;cancer	Comp.	2.96013813709036	-53.94019631567953	34630
f3317b98195fe0be4acf7b450f015c1abca13ab9	learning and example selection for object and pattern detection	example based learning;ai;active learning;computer vision;electrical engineering and computer science;pattern detection;thesis;artificial intelligence;mit;face detection;object detection	This thesis presents a learning based approach for detecting classes of objects and patterns with variable image appearance but highly predictable image boundaries. It consists of two parts. In part one, we introduce our object and pattern detection approach using a concrete human face detection example. The approach rst builds a distribution-based model of the target pattern class in an appropriate feature space to describe the target's variable image appearance. It then learns from examples a similarity measure for matching new patterns against the distribution-based target model. The approach makes few assumptions about the target pattern class and should therefore be fairly general, as long as the target class has predictable image boundaries. Because our object and pattern detection approach is very much learning-based, how well a system eventually performs depends heavily on the quality of training examples it receives. The second part of this thesis looks at how one can select high quality examples for function approximation learning tasks. We propose an active learning formulation for function approximation, and show for three speci c approximation function classes, that the active example selection strategy learns its target with fewer data samples than random sampling. We then simplify the original active learning formulation, and show how it leads to a tractable example selection paradigm, suitable for use in many object and pattern detection problems. Copyright c Massachusetts Institute of Technology, 1995 This report describes research done at the Arti cial Intelligence Laboratory and within the Center for Biological and Computational Learning. This research is sponsored by grants from the O ce of Naval Research under contracts N00014-91-J-1270 and N00014-92-J-1879; by a grant from the National Science Foundation under contract ASC-9217041. Support for the A.I. Laboratory's arti cial intelligence research is provided by ONR contract N00014-91-J-4038. Learning and Example Selection for Object and Pattern Detection	active learning (machine learning);approximation;cbcl (mit);cobham's thesis;computation;display resolution;face detection;feature vector;pattern recognition;programming paradigm;sampling (signal processing);sensor;similarity measure	Kah Kay Sung	1995			computer vision;state pattern;object-class detection;computer science;artificial intelligence;viola–jones object detection framework;machine learning	Vision	22.27290233779828	-60.96398163271848	34679
181d16d268b93e4fd1ab6e24cb2321f8eff54a37	predictive modeling of anti-malarial molecules inhibiting apicoplast formation	drug discovery;computational biology bioinformatics;plasmodium falciparum;artificial intelligence;algorithms;antimalarials;combinatorial libraries;computer appl in life sciences;computer simulation;high throughput screening assays;microarrays;bioinformatics	Malaria is a major healthcare problem worldwide resulting in an estimated 0.65 million deaths every year. It is caused by the members of the parasite genus Plasmodium. The current therapeutic options for malaria are limited to a few classes of molecules, and are fast shrinking due to the emergence of widespread resistance to drugs in the pathogen. The recent availability of high-throughput phenotypic screen datasets for antimalarial activity offers a possibility to create computational models for bioactivity based on chemical descriptors of molecules with potential to accelerate drug discovery for malaria. In the present study, we have used high-throughput screen datasets for the discovery of apicoplast inhibitors of the malarial pathogen as assayed from the delayed death response. We employed machine learning approach and developed computational predictive models to predict the biological activity of new antimalarial compounds. The molecules were further evaluated for common substructures using a Maximum Common Substructure (MCS) based approach. We created computational models using state-of-the-art machine learning algorithms. The models were evaluated based on multiple statistical criteria. We found Random Forest based approach provides for better accuracy as assessed from ROC curve analysis. We further evaluated the active molecules using a substructure based approach to identify common substructures enriched in the active set. We argue that the computational models generated could be effectively used to screen large molecular datasets to prioritize them for phenotypic screens, drastically reducing cost while improving the hit rate.	active set method;algorithm;antimalarials;apicoplasts;cessation of life;class;common bile duct calculi;computation;computational model;drug discovery;emergence;high-throughput computing;machine learning;malaria;pathogenic organism;predictive modelling;random forest;receiver operator characteristics;receiver operating characteristic;thrombocytopenia;throughput	Salma Jamal;Vinita Periwal;Vinod Scaria	2012		10.1186/1471-2105-14-55	computer simulation;biology;dna microarray;toxicology;computer science;bioinformatics;drug discovery	ML	8.104640397818565	-57.536398142151235	34779
508dfe30a36a01ec1cc62c88db2a44c07993c0a4	toward a comprehensive framework for the spatiotemporal statistical analysis of longitudinal shape data	health research;uk clinical guidelines;time warp;biological patents;europe pubmed central;citation search;spatiotemporal registration;uk phd theses thesis;life sciences;statistics;growth;uk research reports;shape regression;longitudinal data;medical journals;europe pmc;biomedical research;bioinformatics	This paper proposes an original approach for the statistical analysis of longitudinal shape data. The proposed method allows the characterization of typical growth patterns and subject-specific shape changes in repeated time-series observations of several subjects. This can be seen as the extension of usual longitudinal statistics of scalar measurements to high-dimensional shape or image data. The method is based on the estimation of continuous subject-specific growth trajectories and the comparison of such temporal shape changes across subjects. Differences between growth trajectories are decomposed into morphological deformations, which account for shape changes independent of the time, and time warps, which account for different rates of shape changes over time. Given a longitudinal shape data set, we estimate a mean growth scenario representative of the population, and the variations of this scenario both in terms of shape changes and in terms of change in growth speed. Then, intrinsic statistics are derived in the space of spatiotemporal deformations, which characterize the typical variations in shape and in growth speed within the studied population. They can be used to detect systematic developmental delays across subjects. In the context of neuroscience, we apply this method to analyze the differences in the growth of the hippocampus in children diagnosed with autism, developmental delays and in controls. Result suggest that group differences may be better characterized by a different speed of maturation rather than shape differences at a given age. In the context of anthropology, we assess the differences in the typical growth of the endocranium between chimpanzees and bonobos. We take advantage of this study to show the robustness of the method with respect to change of parameters and perturbation of the age estimates.	anatomical maturation;anthropology;autistic disorder;estimated;musculoskeletal diseases;neuroscience discipline;pan paniscus;pan troglodytes;spatiotemporal pattern;time series	Stanley Durrleman;Xavier Pennec;Alain Trouvé;José Braga;Guido Gerig;Nicholas Ayache	2012	International Journal of Computer Vision	10.1007/s11263-012-0592-x	computer vision;econometrics;medical research;computer science;data science;data mining;mathematics;statistics	Vision	22.973476602683828	-79.51185316531836	34854
f5510e9334806b1e86638e020c7b5b25d0ae348b	a simulation model for stem cells differentiation into specialized cells of non-connective tissues	population balance;growth factor;cell differentiation;connective tissue;astrocyte;stem cell;non connective tissue;stem cell differentiation;sensitivity analysis;mathematical model;cell growth;connective tissue growth factor;simulation model	A novel mathematical model to simulate stem cells differentiation into specialized cells of non-connective tissues is proposed. The model is based upon material balances for growth factors coupled with a mass-structured population balance describing cell growth, proliferation and differentiation. The proposed model is written in a general form and it may be used to simulate a generic cell differentiation pathway during in vitro cultivation when specific growth factors are used. Literature experimental data concerning the differentiation of central nervous stem cells into astrocytes are successfully compared with model results, thus demonstrating the validity of the proposed model as well as its predictive capability. Finally, sensitivity analysis of model parameters is also performed in order to clarify what mechanisms most strongly influence differentiation and cell types distribution.	cell (microprocessor);cell differentiation process;connective tissue;gene regulatory network;growth factor;logical connective;mathematical model;mathematics;simulation;stem cells;cell growth	Massimo Pisu;Alessandro Concas;Sarah Fadda;Alberto Cincotti;Giacomo Cao	2008	Computational biology and chemistry	10.1016/j.compbiolchem.2008.06.001	biology;immunology;genetics;cellular differentiation;anatomy	Comp.	7.8939249015771695	-65.8604863393136	34911
4ebb2061be505c800d78d99b2c0f7a881fd9cdf1	ibd-groupon: an efficient method for detecting group-wise identity-by-descent regions simultaneously in multiple individuals based on pairwise ibd relationships	genetics population;alleles;algorithms;humans;pedigree;polymorphism single nucleotide;markov chains	MOTIVATION Detecting IBD tracts is an important problem in genetics. Most of the existing methods focus on detecting pairwise IBD tracts, which have relatively low power to detect short IBD tracts. Methods to detect IBD tracts among multiple individuals simultaneously, or group-wise IBD tracts, have better performance for short IBD tracts detection. Group-wise IBD tracts can be applied to a wide range of applications, such as disease mapping, pedigree reconstruction and so forth. The existing group-wise IBD tract detection method is computationally inefficient and is only able to handle small datasets, such as 20, 30 individuals with hundreds of SNPs. It also requires a previous specification of the number of IBD groups, or partitions of the individuals where all the individuals in the same partition are IBD with each other, which may not be realistic in many cases. The method can only handle a small number of IBD groups, such as two or three, because of scalability issues. What is more, it does not take LD (linkage disequilibrium) into consideration.   RESULTS In this work, we developed an efficient method IBD-Groupon, which detects group-wise IBD tracts based on pairwise IBD relationships, and it is able to address all the drawbacks aforementioned. To our knowledge, our method is the first practical group-wise IBD tracts detection method that is scalable to very large datasets, for example, hundreds of individuals with thousands of SNPs, and in the meanwhile, it is powerful to detect short IBD tracts. Our method does not need to specify the number of IBD groups, which will be detected automatically. And our method takes LD into consideration, as it is based on pairwise IBD tracts where LD can be easily incorporated.	algorithm;beagle;chamaecyparis lawsoniana;depth-first search;hidden markov model;ion beam deposition;irritable bowel syndrome;linkage (software);olfactory tract;scalability;sensor;short;shortest path problem;single nucleotide polymorphism;specification;thomason collection of civil war tracts;tract (literature);genetic pedigree	Dan He	2013		10.1093/bioinformatics/btt237	allele;biology;markov chain;bioinformatics;genetics;statistics	Comp.	2.5314864965840873	-52.4651892466082	34965
c4e9c1f199d4d1e07830489ec617099dfb8f8bac	assessing protein resilience via a complex network approach	graph theory;proteins biology complex networks graph theory network theory graphs;complex networks;biology;proteins;protein folding principles protein resilience structural properties dynamical properties topological index complex network theory amino acid residues graph vertices noncovalent contacts topological structure primary sequence protein sequence protein contact networks topological indicators human serum albumin progressive giant component desegregation analysis;network theory graphs;proteins resilience indexes complex networks amino acids protein engineering degradation	In recent years the topological study of proteins is gaining momentum rapidly, and several studies are providing more and more insights on the structural and dynamical properties of proteins by exploiting topological indexes based on Complex Network Theory. To this end the amino acid residues play the role of graph vertices, while non-covalent contacts are the arcs. Topological structure of proteins can be imagined as resulting by folding a thread of pearls (primary sequence of aminoacids) in which amino acid (nodes) relatively distant along the sequence come into contact thanks to the folding process. The result is a configuration sharing some properties with Complex Networks. In this work we derive insights on the resilience of protein contact networks by evaluating the degradation in the size of the giant component with respect to iterated node removal. Specifically, several strategies based on topological indicators (e.g., removing nodes in descending order of clustering coefficient) are exploited, considering the human serum albumin as case study. The analysis of progressive giant component desegregation offered some interesting hints about protein folding principles and suggested some strategies to locate the amino acids most relevant for stability of the studied molecule.	arcs (computing);clustering coefficient;complex network;elegant degradation;giant component;iteration;network theory;sorting;topological quantum computer	Gabriele Oliva;Luisa Di Paola;Alessandro Giuliani;Federica Pascucci;Roberto Setola	2013	2013 IEEE 2nd Network Science Workshop (NSW)	10.1109/NSW.2013.6609209	combinatorics;bioinformatics;nanotechnology;mathematics	Comp.	9.322189543889376	-63.659864640402375	35022
ac8c407fd1178b4b3db9d8594a8a4d9e676db87e	competition between protein aggregation and protein complex formation	protein complex;protein aggregation;computational biology bioinformatics;algorithms;combinatorial libraries;computer appl in life sciences;microarrays;bioinformatics	Background Interactions between proteins are vital for essentially every process in a living cell. Physico-chemical complementarity, which can be considered as the driving force for molecular recognition, has been found to not consistently explain protein-ligand interactions. As aberrant interactions should be avoided in order to maintain cell viability, promoting complex formation and preventing protein aggregation are two opposite requirements on the physico-chemical properties of protein surfaces.	complementarity theory;interaction;requirement	Sebastian Pechmann;Emmanuel D. Levy;Gian Gaetano Tartaglia;Michele Vendruscolo	2008	BMC Bioinformatics	10.1186/1471-2105-9-S10-O2	computational biology;biology;dna microarray;bioinformatics;multiprotein complex;protein aggregation	Comp.	8.294874545574626	-62.29750794245126	35101
29531389d17963a91bc624dacdd90f075154bcb3	entorhinal grid cells may facilitate pattern separation in the hippocampus		The dentate gyrus (DG) in the hippocampus of the mammalian brain is known to exhibit strong pattern separation. However, how this pattern separation arises in the DG is not well understood. Here we offer a novel hypothesis regarding this problem by demonstrating that pattern separation can already be performed by entorhinal grid cells, which are located just one synapse upstream of the DG. For our simulations we utilize a recently introduced grid cell model that interprets the behavior of grid cells as just one instance of a general information processing scheme. The obtained results challenge the established view that pattern separation occurs primarily in the DG, and they uncover a common misconception regarding the specificity of ensemble activity in grid cells.	discontinuous galerkin method;emoticon;information processing;mnist database;multimodal interaction;prototype;sensitivity and specificity;simulation;synapse	Jochen Kerdels;Gabriele Peters	2017		10.5220/0006514601410148	parallel computing;grid;hippocampus;computer science	HPC	18.458580020272716	-72.85617741827276	35119
32b9cbb1dbfbe05d0a16b949afc93a215de3e217	a study of the effect of noise injection on the training of artificial neural networks	belief networks;histograms;radiology;kernel;computer aided diagnosis;cancer;application software;training;training process;bayesian methods;computer aided diagnosis application;artificial neural networks;computer aided diagnosis application noise injection training process weight decay bayesian artificial neural networks;automatic voltage control;learning artificial intelligence belief networks data handling;artificial neural networks radiology sampling methods histograms application software lesions cancer biopsy computer aided diagnosis bayesian methods;lesions;biopsy;bayesian artificial neural networks;weight decay;simulation study;noise injection;data handling;learning artificial intelligence;sampling methods;artificial neural network;noise	We studied the effect of noise injection in overcoming the problem of overtraining in the training of artificial neural networks (ANNs) in comparison with other common approaches for overcoming this problem such as early stopping of the ANN training process and weight decay (which is similar to Bayesian artificial neural networks). We found from simulation studies and studies of a computer-aided diagnosis application that noise injection is effective in overcoming overtraining and is as effective as, or even more effective than, early stopping and weight decay.	artificial neural network;early stopping;simulation;synaptic weight	Yulei Jiang;Richard M. Zur;Lorenzo L. Pesce;Karen Drukker	2009	2009 International Joint Conference on Neural Networks	10.1109/IJCNN.2009.5178981	sampling;application software;kernel;speech recognition;bayesian probability;computer science;noise;artificial intelligence;machine learning;group method of data handling;histogram;artificial neural network;cancer	AI	19.609703956554302	-62.33345541043854	35148
88afb87ed69dbf684749c7bfa799de08df2c804b	codon preference and its use in identifying protein coding regions in long dna sequences	dna;computers;mathematics;methods;rna messenger;codon;genetic code;proteins;statistics as topic;base sequence;dna sequence	This paper describes a computer method that uses codon preference to help find protein coding regions in long DNA sequences. The method can distinguish between introns and exons and can help to detect sequencing errors.	biopolymer sequencing;codon (nucleotide sequence);exons;introns;open reading frames	Rodger Staden;A. D. McLachlan	1982	Nucleic acids research	10.1093/nar/10.1.141	open reading frame;biology;human genome;molecular biology;dna codon table;codon usage bias;coding region;bioinformatics;genetic code;genetics	Comp.	3.439352117597467	-63.07076235502028	35177
9320488d5fd3cedf316c56812050820631153f7c	on cooperative quasi-equilibrium models of transcriptional regulation	partition function;transcription complex;feed forward;time scale;transcriptional regulation;statistical mechanics;feed forward neural network;binding site;quasi equilibrium;transcription regulation;gene regulation network;cooperative activation;transcription factor;mechanistic model;experimental measurement;free energy;artificial neural network;neural network	Mechanistic models for transcriptional regulation are derived using the methods of equilibrium statistical mechanics, to model equilibrating processes that occur at a fast time scale. These processes regulate slower changes in the synthesis and expression of transcription factors that feed back and cooperatively regulate transcription, forming a gene regulation network (GRN). We rederive and extend two previous quasi-equilibrium models of transcriptional regulation, and demonstrate circumstances under which they can be approximated at each transcription complex by feed-forward artificial neural network (ANN) models. A single-level mechanistic model can be approximated by a successfully applied phenomenological model of GRNs which is based on single-layer analog-valued ANNs. A two-level hierarchical mechanistic model, with separate activation states for modules and for the whole transcription complex, can be approximated by a two-layer feed-forward ANN in several related ways. The sufficient conditions demonstrated for the ANN approximations correspond biologically to large numbers of binding sites each of which have a small effect. A further extension to the single-level and two-level models allows one-dimensional chains of overlapping and/or energetically interacting binding sites within a module. Partition functions for these models can be constructed from stylized diagrams that indicate energetic and logical interactions between binary-valued state variables. All parameters in the mechanistic models, including the two approximations, can in principle be related to experimentally measurable free energy differences, among other observables.	analog;approximation algorithm;artificial neural network;binary data;binding sites;diagram;experiment;grn gene;gene regulatory network;interaction;kind of quantity - equilibrium;multi-level cell;name binding;observable;phenomenological model;statistical mechanics;transcription factor;transcription (software);transcription, genetic;transcriptional regulation;free energy	Eric Mjolsness	2007	Journal of bioinformatics and computational biology	10.1142/S0219720007002874	biology;computer science;bioinformatics;artificial intelligence;machine learning;genetics;artificial neural network;transcriptional regulation	Comp.	7.145259737886111	-64.86493292611013	35236
20c169f663d6a8e8a32ff4f74596b92a61e487ea	a predictor for toxin-like proteins exposes cell modulator candidates within viral genomes	toxins biological;animals;genomics;peptides;proteome;amino acid sequence;viral proteins;genomes;conotoxins;metagenomics;protein structure tertiary;toxins;artificial intelligence;algorithms;protein folding;molecular sequence data;base sequence	MOTIVATION Animal toxins operate by binding to receptors and ion channels. These proteins are short and vary in sequence, structure and function. Sporadic discoveries have also revealed endogenous toxin-like proteins in non-venomous organisms. Viral proteins are the largest group of quickly evolving proteomes. We tested the hypothesis that toxin-like proteins exist in viruses and that they act to modulate functions of their hosts.   RESULTS We updated and improved a classifier for compact proteins resembling short animal toxins that is based on a machine-learning method. We applied it in a large-scale setting to identify toxin-like proteins among short viral proteins. Among the approximately 26 000 representatives of such short proteins, 510 sequences were positively identified. We focused on the 19 highest scoring proteins. Among them, we identified conotoxin-like proteins, growth factors receptor-like proteins and anti-bacterial peptides. Our predictor was shown to enhance annotation inference for many 'uncharacterized' proteins. We conclude that our protocol can expose toxin-like proteins in unexplored niches including metagenomics data and enhance the systematic discovery of novel cell modulators for drug development.   AVAILABILITY ClanTox is available at http://www.clantox.cs.huji.ac.il.	annotation;computer virus;conotoxin;inference;ion channel;ions;kerrison predictor;largest;machine learning;metagenomics;modulation;modulator device component;name binding;proteome;receptors, mitogen;toxin;viral genome;drug development	Guy Naamati;Manor Askenazi;Michal Linial	2010		10.1093/bioinformatics/btq375	protein folding;biology;genomics;molecular biology;bioinformatics;proteome;conotoxin;peptide sequence;genetics;metagenomics;genome	Comp.	3.638654950499986	-60.283541282750114	35258
0150635d0d29f8328cf85e0813bcfc9632f15355	auditory overshadowing in preschoolers: a preference for the input, the system, or both?		Auditory overshadowing occurs when the presence of an auditory stimulus interferes with visual processing. The current study tested whether this occurs due to a privileged attentional status of auditory input or due to the dynamic characteristics of auditory input. To address these questions, preschoolers completed one of four discrimination tasks. In the sound, motion, and item baseline conditions, children discriminated these single information types by judging whether paired stimuli were the same or different. In the combined condition, children discriminated changing sounds, motions, or items in the face of competing input in the other two dimensions. Although children’s discrimination of all information types attenuated in the combined condition relative to baseline, motion and item discrimination attenuated more than auditory discrimination. This provides evidence that early in development auditory information receives privileged processing in the face of competing input.	baseline (configuration management);ibm notes;item response theory;modality (human–computer interaction)	Allison O'Leary;Vladimir M. Sloutsky	2013			selective auditory attention;psychology;stimulus modality;social psychology;visual processing;multisensory integration;cognitive psychology;visual space;stimulus (physiology);cognition;visual perception	HCI	15.582923933446374	-76.97920992293881	35308
dd90d05b0c5d3098649dcf104c35d164c39a92e5	critical echo state networks that anticipate input using morphable transfer functions		The paper investigates a new type of truly critical echo state networks where individual transfer functions for every neuron can be modified to anticipate the expected next input. Deviations from expected input are only forgotten slowly in power law fashion. The paper outlines the theory, numerically analyzes a one neuron model network and finally discusses technical and also biological implications of this type of approach.	biological neuron model;echo state network;numerical analysis	Norbert Michael Mayer	2017		10.1007/978-3-319-59072-1_49	machine learning;lyapunov exponent;biological neuron model;artificial intelligence;computer science;power law;transfer function;recurrent neural network;echo state network	Theory	17.42689364459643	-69.24924618033319	35324
0618e9843bb4833516bf29b80aa401d956990aa0	modeling the impact of white-plague coral disease in climate change scenarios	animals;northern florida keys;ocean temperature;climate change;nutrient enrichment;communicable diseases;black band disease;models biological;mass mortality;seasons;anthozoa;causative agent;us virgin islands;coral reefs;infectious diseases;disease dynamics;great barrier reef;acropora palmata;temperature;computational biology;spatial epidemiology;red sea;infectious disease epidemiology;corals;puerto rico;environmental monitoring	Coral reefs are in global decline, with coral diseases increasing both in prevalence and in space, a situation that is expected only to worsen as future thermal stressors increase. Through intense surveillance, we have collected a unique and highly resolved dataset from the coral reef of Eilat (Israel, Red Sea), that documents the spatiotemporal dynamics of a White Plague Disease (WPD) outbreak over the course of a full season. Based on modern statistical methodologies, we develop a novel spatial epidemiological model that uses a maximum-likelihood procedure to fit the data and assess the transmission pattern of WPD. We link the model to sea surface temperature (SST) and test the possible effect of increasing temperatures on disease dynamics. Our results reveal that the likelihood of a susceptible coral to become infected is governed both by SST and by its spatial location relative to nearby infected corals. The model shows that the magnitude of WPD epidemics strongly depends on demographic circumstances; under one extreme, when recruitment is free-space regulated and coral density remains relatively constant, even an increase of only 0.5°C in SST can cause epidemics to double in magnitude. In reality, however, the spatial nature of transmission can effectively protect the community, restricting the magnitude of annual epidemics. This is because the probability of susceptible corals to become infected is negatively associated with coral density. Based on our findings, we expect that infectious diseases having a significant spatial component, such as Red-Sea WPD, will never lead to a complete destruction of the coral community under increased thermal stress. However, this also implies that signs of recovery of local coral communities may be misleading; indicative more of spatial dynamics than true rehabilitation of these communities. In contrast to earlier generic models, our approach captures dynamics of WPD both in space and time, accounting for the highly seasonal nature of annual WPD outbreaks.	capacitor plague;communicable diseases;community;coral - body part;coral reefs;epidemiology;hematological disease;parkinson disease;wavelet packet decomposition	Assaf Zvuloni;Yael Artzy-Randrup;Guy Katriel;Yossi Loya;Lewi Stone	2015		10.1371/journal.pcbi.1004151	biology;sea surface temperature;coral reef;temperature;spatial epidemiology;environmental monitoring;climate change;ecology	ML	6.636595060654698	-72.09272963871291	35390
0e9695643acd37752d48db09175975527560555a	neural network model of spatial memory: associative recall of maps	simulation ordinateur;modelizacion;use of piled;architecture systeme;memoire associative;matriz correlacion;cross correlation;spatial memory;pattern;spatial mapping;associative recall of maps;memoria espacial;modelisation;use of piled pattern;associative memory;memoria asociativa;arquitectura sistema;matrice correlation;shift invariant recall;memory of fragmentary maps;seamless recall of a wide map;simulacion computadora;neural network model;reseau neuronal;correlation matrix;system architecture;modeling;memoire spatiale;computer simulation;correlation matrix memory;red neuronal;shift invariant;neural network	"""This paper offers a neural network model that can memorize and recall spatial maps. When driving through a place we have been before, we can recall and imagine the scenery that we cannot see yet but shall see soon. Triggered by the newly recalled image, we can also recall other scenery further ahead of us. The model emulates such a chain process of recalling using a correlation matrix memory. A correlation matrix memory by itself, however, does not accept shifts in location of stimulus patterns, and each stimulus pattern has to be placed accurately at the location of one of the memorized patterns. We propose adjusting the location of the stimulus pattern using the cross-correlation between the stimulus pattern and the """"piled pattern"""", which is the sum of all patterns memorized in the correlation matrix. A map of Europe is divided into a number of overlapping segments, and these segments are memorized in the proposed model. Triggered by an input image, say a map around Scotland, the model can recall maps of other parts of Europe sequentially up to Italy, for example. Copyright 1997 Elsevier Science Ltd."""		Kunihiko Fukushima;Yoshio Yamaguchi;Masato Okada	1997	Neural networks : the official journal of the International Neural Network Society	10.1016/S0893-6080(97)00024-5	spatial memory;covariance matrix;systems modeling;computer science;artificial intelligence;cross-correlation;machine learning;pattern;artificial neural network;shift-invariant system;statistics	ML	22.318832061285384	-68.94680647212088	35401
098d37b0fcd41505d2c67ab84ecfa50c30888e23	adaptation to dynamic environments displays local generalization for voluntary reaching movements	electronic mail;training force neurophysiology adaptation models neuroscience electronic mail force measurement;training;biomechanics;force;adaptation physiological arm humans learning movement;neuroscience;dynamic environment;force field;force measurement;generating function;asymptotic adaptation dynamic environments displays local generalization voluntary reaching movements directional generalization function viscous force field environment;neurophysiology;adaptation models;reaching movement	The shape of the directional generalization function for adaptation to a viscous force-field environment has been controversial. Some studies have suggested wide, essentially global generalization and others have suggested narrow, local generalization. Here, we show definitively that motor adaptation displays narrow generalization with a minimal global component and a peak at the trained movement direction for both single-trial and asymptotic adaptation. Furthermore, we find that reaching movements in opposite directions do not interfere with one another during force-field learning.	acclimatization;generalization (psychology);movement;reaching	Luis Nicolas Gonzalez Castro;Howard G. Wu;Maurice A. Smith	2011	2011 Annual International Conference of the IEEE Engineering in Medicine and Biology Society	10.1109/IEMBS.2011.6091006	psychology;generating function;neuroscience;simulation;artificial intelligence;biomechanics;force field;communication;neurophysiology;force;physics	Visualization	14.27372835178775	-72.4152163778962	35492
1fade842151248ce0e5d565b3f8ecc684946b410	biomarker discovery using statistically significant gene sets	data interpretation statistical;multivariate analysis;databases genetic;tumor markers biological;gene expression;gene interaction;models statistical;algorithms;microarray;humans;cancer classification;computational biology;phenotype;gene selection;computer simulation;oligonucleotide array sequence analysis	Analysis of large gene expression data sets in the presence and absence of a phenotype can lead to the selection of a group of genes serving as biomarkers jointly predicting the phenotype. Among gene selection methods, filter methods derived from ranked individual genes have been widely used in existing products for diagnosis and prognosis. Univariate filter approaches selecting genes individually, although computationally efficient, often ignore gene interactions inherent in the biological data. On the other hand, multivariate approaches selecting gene subsets are known to have a higher risk of selecting spurious gene subsets due to the overfitting of the vast number of gene subsets evaluated. Here we propose a framework of statistical significance tests for multivariate feature selection that can reduce the risk of selecting spurious gene subsets. Using three existing data sets, we show that our proposed approach is an essential step to identify such a gene set that is generated by a significant interaction of its members, even improving classification performance when compared to established approaches. This technique can be applied for the discovery of robust biomarkers for medical diagnosis.	algorithm;algorithmic efficiency;biological markers;biological system;characterization test;computation;feature selection;forecast of outcome;gene expression profiling;interaction;microarray;mutual information;overfitting;p-value;relevance;single nucleotide polymorphism;statistical test;statistical classification;mixture	Hoon Kim;John Watkinson;Dimitris Anastassiou	2011	Journal of computational biology : a journal of computational molecular cell biology	10.1089/cmb.2010.0085	computer simulation;gene-centered view of evolution;biology;gene expression;bioinformatics;phenotype;microarray;data mining;multivariate analysis;genetics	Comp.	6.494308856066351	-52.967202593836994	35590
fb577673fc492db5a2a9edb7a309a76c90346229	gene expression and genetic networks - session introduction	gene expression		gene regulatory network	Roland Somogyi;Hiroaki Kitano	1999			genetics;gene expression;bioinformatics;biology	Logic	1.236111613619565	-63.91255978658525	35606
5115b9807a6fc33c2b37bf669b7013ca6dc95f3b	accurate identification of significant aberrations in contaminated cancer genome	copy number alterations;tumours bayes methods cancer cellular biophysics data analysis genetics genomics identification medical computing statistical analysis;glioblastoma multiforme significant aberration somatic copy number alterations human cancer significant copy number aberration identification cancer genomes cancer associated genes advanced genomic technologies snp array technology genome wide scale intensity signal copy number signal mixture tumor cell normal cell genetic heterogeneity copy number analysis sca detection statistical method bayesian analysis of copy number mixtures normal tissue contamination fraction true copy number profile genome wide identification significant aberrations in cancer genome simulation data peer methods gistic;significant copy number aberrations;normal tissue contamination;significant copy number aberrations copy number alterations normal tissue contamination	Somatic Copy Number Alterations (CNAs) are quite common in human cancers. Identifying CNAs and Significant Copy number Aberrations (SCAs) in cancer genomes is a critical task in searching for cancer-associated genes. The advanced genomic technologies, such as SNP array technology, facilitate copy number study at a genome-wide scale with high resolution. However, in reality, due to normal tissue contamination, the observed intensity signals are actually the mixture of copy number signals contributed from both tumor cells and normal cells. This genetic heterogeneity could significantly affect the subsequent copy number analysis and SCAs detection. In order to accurately identify significant aberrations in contaminated cancer genome, we devise an approach including two major steps. We first use a statistical method, Bayesian Analysis of Copy number Mixtures (BACOM) to estimate the normal tissue contamination fraction and recover the “true” copy number profile. Then, based on the recovered profiles, we detect SCAs using Genome-wide Identification of Significant Aberrations in Cancer Genome (SAIC). We comprehensively evaluate the performance of the proposed algorithm on a large number of simulation data. The results show that the algorithm has higher detection power than peer methods including the most popular GISTIC. We then apply the method to the real copy number data of Glioblastoma Multiforme and successfully identified majority of SCAs reported by GISTIC, and some novel SCAs that contain some cancer-associated genes.	algorithm;image resolution;mesa;snp array;simulation	Xuchu Hou;Guoqiang Yu;Xiguo Yuan;Bai Zhang;Ie-Ming Shih;Zhen Zhang;Robert Clarke;Subha Madhavan	2012	Proceedings 2012 IEEE International Workshop on Genomic Signal Processing and Statistics (GENSIPS)	10.1109/GENSIPS.2012.6507730	biology;copy number analysis;bioinformatics;genetics	Comp.	3.589880886846598	-54.06690336316685	35637
a65f905ca99379ae623b459f8845e7b3d6b5de07	activity in the visual cortex is modulated by top-down attention locked to reaction time	atencion;via visual;change detection;systeme nerveux central;voie visuelle;stimulus change;top down;tiempo reaccion;blood oxygen level dependent;hombre;percepcion;attention;encefalo;temps reaction;primary visual cortex;corteza visual;sistema nervioso central;encephale;changement stimulus;cognition;spatial attention;human;cognicion;visual pathway;encephalon;perception;caltech library services;cambio estimulo;vision;cortex visuel;visual cortex;central nervous system;reaction time;homme	We studied the correlation between perception and hemodynamic activity in the visual cortex in a change detection task. Whenever the observer perceived the location of a change, rightly or wrongly, the blood oxygenation level-dependent signal increased in the primary visual cortex and the nearby extrastriate areas above the baseline activity caused by the visual stimulation. This non-sensory-evoked activity was localized and corresponded to the perceived location of the change. When a change was missed, or when observers attended to a different task, the change failed to evoke such a response. The latency of the nonsensory component increased linearly with subjects' reaction time, with a slope of one, and its amplitude was independent of contrast. Control experiments are compatible with the hypothesis that the nonsensory hemodynamic signal is mediated by top-down spatial attention, linked to (but separate from) awareness of the change.	area striata structure;baseline (configuration management);cell respiration;cerebral cortex;experiment;hemodynamics;modulation;photic stimulation;top-down and bottom-up design;visual cortex;observers	Farshad Moradi;Constanze Hipp;Christof Koch	2007	Journal of Cognitive Neuroscience	10.1162/jocn.2007.19.2.331	psychology;cognitive psychology;mental chronometry;vision;neuroscience;cognition;developmental psychology;attention;visual system;central nervous system;top-down and bottom-up design;communication;n2pc;perception;change detection	ML	16.795799581230323	-76.8409759100257	35638
1da9c537caccc75ecb5026e5d74d0cb75f73fe42	case-centred multidimensional scaling for classification visualisation in medical diagnosis	article	Computer-based decision support can assist a medical doctor to find the right diagnosis. The knowledge and experience of the medical doctor is enhanced by a much larger data set of patients than the doctor will ever see in her or his life. The decision support system can derive possible diagnoses for a new patient based on a suitable classifier built on the patients in the patient database. However, since such a system cannot replace a medical doctor and should only support her or him, it should also provide information about the certainty of its recommendation. In this paper, we propose to visualise how close or similar the new patient is to others in the database by a modified multidimensional scaling technique that focuses on the correct positioning of the new patient in the visualisation. In this way, the medical doctor can easily see whether the diagnosis recommended by the system is reliable when all patients close to the new patient have the same diagnosis or whether it is quite uncertain when the new patient is surrounded by patients with different diagnoses.	algorithm;clinical decision support system;data mining;decision support system;feedback;image scaling;multidimensional scaling;relevance;vagueness	Frank Klawonn;Werner Lechner;Lorenz Grigull	2013		10.1007/978-3-642-37899-7_12	medicine;data mining;biological engineering	ML	4.2598520212454805	-78.86414741217578	35822
69946e6c8ac7ac3ec7943392819633d142d6bc08	modelling patterns of evidence in bayesian networks: a case-study in classical swine fever	bayesian network;classical swine fever;early detection	Upon engineering a Bayesian network for the early detection of Classical Swine Fever in pigs, we found that the commonly used approach of separately modelling the relevant observable variables would not suffice to arrive at satisfactory performance of the network: explicit modelling of combinations of observations was required to allow identifying and reasoning about patterns of evidence. In this paper, we outline a general approach to modelling relevant patterns of evidence in a Bayesian network. We demonstrate its application for our problem domain and show that it served to significantly improve our network’s performance.	bayesian network;best practice;experience;observable;persistence (computer science);problem domain	Linda C. van der Gaag;Janneke H. Bolt;Willie Loeffen;Armin Elbers	2010		10.1007/978-3-642-14049-5_69	econometrics;variable-order bayesian network;computer science;machine learning;bayesian network;statistics	AI	6.634496591738282	-73.95657385842091	35823
2cfc5752a7ee3358e74c810fee2209517a945450	svgmap: configurable image browser for experimental data	spatial data visualization;java application;singular data item;biological data;expression pattern;precompiled java package;biological condition;different image;recent web browser;different tissue	SUMMARY Spatial data visualization is very useful to represent biological data and quickly interpret the results. For instance, to show the expression pattern of a gene in different tissues of a fly, an intuitive approach is to draw the fly with the corresponding tissues and color the expression of the gene in each of them. However, the creation of these visual representations may be a burdensome task. Here we present SVGMap, a java application that automatizes the generation of high-quality graphics for singular data items (e.g. genes) and biological conditions. SVGMap contains a browser that allows the user to navigate the different images created and can be used as a web-based results publishing tool.   AVAILABILITY SVGMap is freely available as precompiled java package as well as source code at http://bg.upf.edu/svgmap. It requires Java 6 and any recent web browser with JavaScript enabled. The software can be run on Linux, Mac OS X and Windows systems.   CONTACT nuria.lopez@upf.edu	body tissue;data visualization;graphics;image viewer;imagery;internet;java programming language;java package;javascript;linux;microsoft windows;operating system;singular;source code;system 7;web application	Xavier Rafael Palou;Michael P. Schroeder;Núria López-Bigas	2012	Bioinformatics	10.1093/bioinformatics/btr581	computer science;bioinformatics;data mining;world wide web	Comp.	-3.9836757270934244	-58.578974959276856	35838
0eb95c8a5c541aeadce80fa31f3a780f5d535c77	robust network topologies for generating switch-like cellular responses	ultrasensitivity;switching;signaling network;saccharomyces cerevisiae;building block;hybrid network;systems biology;signal transduction;synthetic biology;enzyme;transcription factors;models biological;gene network;network topology;feedback physiological;enzymes;random parameters;cell cycle control;arabidopsis;bistability;computational biology	Signaling networks that convert graded stimuli into binary, all-or-none cellular responses are critical in processes ranging from cell-cycle control to lineage commitment. To exhaustively enumerate topologies that exhibit this switch-like behavior, we simulated all possible two- and three-component networks on random parameter sets, and assessed the resulting response profiles for both steepness (ultrasensitivity) and extent of memory (bistability). Simulations were used to study purely enzymatic networks, purely transcriptional networks, and hybrid enzymatic/transcriptional networks, and the topologies in each class were rank ordered by parametric robustness (i.e., the percentage of applied parameter sets exhibiting ultrasensitivity or bistability). Results reveal that the distribution of network robustness is highly skewed, with the most robust topologies clustering into a small number of motifs. Hybrid networks are the most robust in generating ultrasensitivity (up to 28%) and bistability (up to 18%); strikingly, a purely transcriptional framework is the most fragile in generating either ultrasensitive (up to 3%) or bistable (up to 1%) responses. The disparity in robustness among the network classes is due in part to zero-order ultrasensitivity, an enzyme-specific phenomenon, which repeatedly emerges as a particularly robust mechanism for generating nonlinearity and can act as a building block for switch-like responses. We also highlight experimentally studied examples of topologies enabling switching behavior, in both native and synthetic systems, that rank highly in our simulations. This unbiased approach for identifying topologies capable of a given response may be useful in discovering new natural motifs and in designing robust synthetic gene networks.	arabic numeral 0;artificial gene synthesis;binocular disparity;bistability;class;cluster analysis;commitment scheme;computer simulation;enumerated type;exhibits as topic;experiment;gene regulatory networks;gene regulatory network;lineage (evolution);network topology;nonlinear system;population parameter;robustness of complex networks;synthetic intelligence;transcription, genetic;statistical cluster	Najaf A. Shah;Casim A. Sarkar	2011		10.1371/journal.pcbi.1002085	biology;biochemistry;enzyme;bioinformatics;synthetic biology;systems biology	ML	5.843205851575563	-59.10725756706155	35839
8c39a1721a2c26e9671c84bf2bc2c7732e7b327e	application of in silico positional cloning and bioinformatic mutation analysis to the study of eye diseases	329999 medical and health sciences not elsewhere classified;mutation analysis;eye disease;positional cloning;in silico	A vast amount of DNA and protein sequence is now available and a plethora of programs have been developed to analyse the data. The bewildering variety of analyses that can be performed via the World-Wide Web can deter researchers from applying bioinformatics to augment their traditional genetic research. Focusing on the inherited eye diseases, this paper provides a guide to the appropriate software required for identification of candidate genes through to the detection and analysis of mutations.	bioinformatics;candidate disease gene;clone cells;cloning vectors;disorder of eye;hereditary diseases;mutation testing;world wide web	Agnieszka M. Lichanska;D. A. C. Simpson	2002	Briefings in bioinformatics	10.1093/bib/3.1.59	biology;molecular biology;bioinformatics;mutation testing;genetics	Comp.	1.3220596948180616	-60.13759025700224	35852
c4cf0e4d24e6c45b5672c44ec4232df7a338c3da	metagenomic composition analysis of sedimentary ancient dna from the isle of wight		The DNA from several organisms is sequenced conjointly in metagenomics. This allows searching for exogenous microorganisms contained in the samples, with the goal of studying the evolution and co-evolution of host-pathogen, namely for building better diagnostics and therapeutics. However, the quantity and quality of the DNA present in the samples is very poor, pushing the responsibility of analysis improvements into the development of better computational methods. Here, we develop a new processing paradigm to infer the metagenomic composition analysis based on the relative compression of whole genome sequences. Using this method, we present the metagenomic composition analysis of a sedimentary ancient DNA sample, dated to 8,000 years before the present, from the Isle of Wight, United Kingdom. The results show several viruses and bacteria expressing high levels of similarity relative to the samples, namely a circular virus similar to the Avon-Heathcote estuary virus 14 sequenced in New Zealand.	compression;computation;computational chemistry;contain (action);dna, ancient;estuaries;inference;metagenomics;microorganism;pathogenic organism;programming paradigm;therapeutic procedure	Diogo Pratas;Armando J. Pinho	2018	2018 26th European Signal Processing Conference (EUSIPCO)	10.23919/EUSIPCO.2018.8553297		Comp.	2.5820520927914563	-62.66051715161694	35879
717ce03b3c565af600599fdb1a08a1e69bd86e16	a differential simulator using past clinical trial data to run simulated clinical trials	diabetes;blood;medical computing digital simulation diseases;pancreas;insulin sugar diabetes pancreas data models clinical trials blood;insulin;artificial pancreas controllers differential simulator past clinical trial data simulated clinical trials type 1 diabetes mellitus t1dm blood glucose concentrations continuous glucose monitor signal medical devices exhaustive simulation based clinical trials physiologic processes simple linear insulin glucose model insulin glucose test data fda accepted simulator modified insulin dosing patient background insulin delivery rates;sugar;data models;clinical trials	Individuals with type 1 Diabetes Mellitus (T1DM) must inject insulin to regulate blood glucose concentrations. The artificial pancreas project seeks to automate the delivery of insulin in response to continuous glucose monitor (sensor) signals. Most medical devices must go through extensive animal studies before human studies can be conducted, but regulatory authorities (FDA, in the United States) have allowed investigators to skip animal trials for the artificial pancreas project by conducting exhaustive simulation-based (in silico) clinical trials. Still, current simulators only provide a rough evaluation of prospective algorithms because they cannot accurately model all physiologic processes. In this paper we propose an alternative simulation approach that works directly from clinical data, reducing the number of required assumptions. This approach calculates changes to real data based on changes in the inputs rather than calculating the effect of the entire input. Here, we choose a simple, linear, insulin-glucose model based on published insulin-glucose test data. The simulator with the linear insulin glucose model is validated against an FDA-accepted simulator for various magnitudes of modified insulin dosing. The scenarios include a 0-200% step change to the patients' background insulin delivery rates (basal rates), and a 50-150% scaling of their meal insulin doses (boluses). These studies show that the differential simulator induces less error than patient variability when using other simulators. We also show two illustrative test cases for testing revision to artificial pancreas controllers.	algorithm;basal (phylogenetics);heart rate variability;image scaling;prospective search;simulation;test case;test data	Fraser Cameron;Nihat Baysal;B. Wayne Bequette	2015	2015 American Control Conference (ACC)	10.1109/ACC.2015.7172135	data modeling;computer science;biological engineering;proinsulin	SE	9.651871052530597	-71.41011591552416	35894
f543cc0fe9ec43f3e59f520bb36d1f3392de003a	mapping heritability and molecular genetic associations with cortical features using probabilistic brain atlases	environmental influence;brain atlases;linkage analysis;three dimensional;genetics;genetic linkage;genetic association;factor x;molecular genetics;brain structure;gray matter;brain imaging;a;brain atlas;dna polymorphism;twin study;mielenterveys	There is an urgent need to decipher the complex nature of genotype-phenotype relationships within the multiple dimensions of brain structure and function that are compromised in neuropsychiatric syndromes such as schizophrenia. Doing so requires sophisticated methodologies to represent population variability in neural traits and to probe their heritable and molecular genetic bases. We have recently developed and applied computational algorithms to map the heritability of, as well as genetic linkage and association to, neural features encoded using brain imaging in the context of three-dimensional (3D), population-based, statistical brain atlases. One set of algorithms builds on our prior work using classical twin study methods to estimate heritability by fitting biometrical models for additive genetic, unique, and common environmental influences. Another set of algorithms performs regression-based (Haseman-Elston) identical-bydescent linkage analysis and genetic association analysis of DNA polymorphisms in relation to neural traits of interest in the same 3D population-based brain atlas format. We demonstrate these approaches using samples of healthy monozygotic (MZ) and dizygotic (DZ) twin pairs, as well as MZ and DZ twin pairs discordant for schizophrenia, but the methods can be generalized to other classes of relatives and to other diseases. The results confirm prior evidence of genetic influences on gray matter density in frontal brain regions. They also provide converging evidence that the chromosome 1q42 region is relevant to schizophrenia by demonstrating linkage and association of markers of the Transelin-Associated-Factor-X and Disrupted-In-Schizophrenia-1 genes with prefrontal cortical gray matter deficits in twins discordant for schizophrenia.	1q42;atlases;base;brain atlas;cervical atlas;class;computation;convergence (action);decipher prostate cancer test;dimensions;eaf2 gene;genetic polymorphism;gray matter;hereditary diseases;mental association;midazolam;molecular genetics (discipline);schizophrenia;sharp mz;spatial variability;statistical machine translation;syndrome;trait;twin;utility functions on indivisible goods;algorithm;genetic linkage	Tyrone D. Cannon;Paul M. Thompson;Theo G. M. van Erp;Matti Huttunen;Jouko Lönnqvist;Jaakko Kaprio;Arthur W. Toga	2006	Neuroinformatics	10.1385/NI:4:1:5	molecular genetics;genetic linkage;bioinformatics;genetics	ML	23.85892828019047	-79.01658346784662	35962
85ba93fc666168c29b8102396a31cd504cc31c3b	matchtm: a tool for searching transcription factor binding sites in dna sequences	dna;libraries;software;transcription factor binding site;transcription factors;sequence analysis dna;binding sites;internet;transcription factor;gene expression regulation;algorithms;user computer interface;dna sequence;neural stem cell;regulatory sequences nucleic acid	Match is a weight matrix-based tool for searching putative transcription factor binding sites in DNA sequences. Match is closely interconnected and distributed together with the TRANSFAC database. In particular, Match uses the matrix library collected in TRANSFAC and therefore provides the possibility to search for a great variety of different transcription factor binding sites. Several sets of optimised matrix cut-off values are built in the system to provide a variety of search modes of different stringency. The user may construct and save his/her specific user profiles which are selected subsets of matrices including default or user-defined cut-off values. Furthermore a number of tissue-specific profiles are provided that were compiled by the TRANSFAC team. A public version of the Match tool is available at: http://www.gene-regulation.com/pub/programs.html#match. The same program with a different web interface can be found at http://compel.bionet.nsc.ru/Match/Match.html. An advanced version of the tool called Match Professional is available at http://www.biobase.de.	binding sites;compiler;default;interface device component;the matrix;transcription (software);user interface;user profile;transcription factor binding	Alexander E. Kel;Ellen Gößling;Ingmar Reuter;Evgeny Cheremushkin;Olga V. Kel-Margoulis;Edgar Wingender	2001	Nucleic acids research	10.1093/nar/gkg585	biology;bioinformatics;genetics;transfac;dna binding site;transcription factor	Comp.	-0.38637346210293505	-59.11116302247503	35974
1e6256b19ce4e44a1c7d59471654dccda5f2a1af	predicting overlapping protein complexes based on core-attachment and a local modularity structure	core-attachment and local modularity structure;node betweenness;overlapping node;protein complex;protein-protein interaction networks;seed-extension paradigm	BACKGROUND In recent decades, detecting protein complexes (PCs) from protein-protein interaction networks (PPINs) has been an active area of research. There are a large number of excellent graph clustering methods that work very well for identifying PCs. However, most of existing methods usually overlook the inherent core-attachment organization of PCs. Therefore, these methods have three major limitations we should concern. Firstly, many methods have ignored the importance of selecting seed, especially without considering the impact of overlapping nodes as seed nodes. Thus, there may be false predictions. Secondly, PCs are generally supposed to be dense subgraphs. However, the subgraphs with high local modularity structure usually correspond to PCs. Thirdly, a number of available methods lack handling noise mechanism, and miss some peripheral proteins. In summary, all these challenging issues are very important for predicting more biological overlapping PCs.   RESULTS In this paper, to overcome these weaknesses, we propose a clustering method by core-attachment and local modularity structure, named CALM, to detect overlapping PCs from weighted PPINs with noises. Firstly, we identify overlapping nodes and seed nodes. Secondly, for a node, we calculate the support function between a node and a cluster. In CALM, a cluster which initially consists of only a seed node, is extended by adding its direct neighboring nodes recursively according to the support function, until this cluster forms a locally optimal modularity subgraph. Thirdly, we repeat this process for the remaining seed nodes. Finally, merging and removing procedures are carried out to obtain final predicted clusters. The experimental results show that CALM outperforms other classical methods, and achieves ideal overall performance. Furthermore, CALM can match more complexes with a higher accuracy and provide a better one-to-one mapping with reference complexes in all test datasets. Additionally, CALM is robust against the high rate of noise PPIN.   CONCLUSIONS By considering core-attachment and local modularity structure, CALM could detect PCs much more effectively than some representative methods. In short, CALM could potentially identify previous undiscovered overlapping PCs with various density and high modularity.	attachments;cluster analysis;handling (psychology);image noise;local optimum;name;node - plant part;noise-induced hearing loss;one-to-one (data model);picalm gene;peripheral;recursion;sensor;weakness;protein protein interaction;statistical cluster	Rongquan Wang;Guixia Liu;Caixia Wang;Lingtao Su;Liyan Sun	2018		10.1186/s12859-018-2309-9	genetics;theoretical computer science;clustering coefficient;modularity;biology	ML	4.892686024885381	-55.65148252168469	35991
54d2dbd81ff046011c27929b4785b93f8f4e1b06	the idp-specific force field ff14idpsff improves the conformer sampling of intrinsically disordered proteins		Intrinsically disordered proteins (IDPs) or intrinsically disordered regions do not have a fixed tertiary structure but play key roles in signal regulation, molecule recognition, and drug targeting. However, it is difficult to study the structure and function of IDPs by traditional experimental methods because of their diverse conformations. Limitations of current generic protein force fields and solvent models were reported in the previous simulations of IDPs. We have also explored overcoming these limitations by developing the ff99IDPs and ff14IDPs force fields to correct the dihedral distribution for eight disorder-promoting residues often observed in IDPs and found encouraging improvements. Here we extend our correction of backbone dihedral terms to all 20 naturally occurring amino acids in the IDP-specific force field ff14IDPSFF to further improve the quality of the modeling of IDPs. Extensive tests of seven IDPs and 14 unstructured short peptides show that the simulated Cα chemical shifts obtained with the ff14IDPSFF force field are in quantitative agreement with those from NMR experiments and are more accurate than those obtained with the base generic force field and also our previous ff14IDPs that only corrects the eight disorder-promoting amino acids. The influence of the solvent model was also investigated and found to be less important. Finally, our explicit-solvent MD simulations further show that ff14IDPSFF can still be used to model structural and dynamical properties of two tested folded proteins, with a slightly better agreement in the loop regions for both structural and dynamical properties. These findings confirm that the newly developed IDP-specific force field ff14IDPSFF can improve the conformer sampling of intrinsically disordered proteins.	amino acid metabolism, inborn errors;amino acids;attention deficit hyperactivity disorder;drug delivery systems;dynamical system;experiment;force field (chemistry);internet backbone;intrinsically disordered proteins;promotion (action);sampling (signal processing);sampling - surgical action;simulation;solvent models;vertebral column;water model;cellular targeting;tertiary	Dong Song;Ray Luo;Hai-Feng Chen	2017	Journal of chemical information and modeling	10.1021/acs.jcim.7b00135	crystallography;chemistry;analytical chemistry;nanotechnology	Comp.	9.770650606743198	-62.348425271800956	35992
1cfde05c5197b0fac6c6f860984ae6761e2da9b3	a database of thermodynamic properties of the reactions of glycolysis, the tricarboxylic acid cycle, and the pentose phosphate pathway	animals;uncertainty;models biological;citric acid cycle;thermodynamics;databases as topic;pentose phosphate pathway;kinetics;glycolysis	A database of thermodynamic properties is developed, which extends a previous database of glycolysis and tricarboxylic acid cycle by adding the reactions of the pentose phosphate pathway. The raw data and documented estimations of solution properties are made electronically available. The database is determined by estimation of a set of parameters representing species-level free energies of formation. The resulting calculations provide thermodynamic and network-based estimates of thermodynamic properties for six reactions of the pentose phosphate pathway for which estimates are not available in the preexisting literature. Optimized results are made available in ThermoML format. Because calculations depend on estimated hydrogen and metal cation dissociation constants, an uncertainty and sensitivity analysis is performed, revealing 23 critical dissociation constants to which the computed thermodynamic properties are particularly sensitive. DATABASE URL: http://www.biocoda.org/thermo	cations;citric acid cycle;database;document completion status - documented;energy, physics;estimated;estimation theory;gene regulatory network;glycolysis;hydrogen;pentose phosphate pathway;pentosephosphates;pentoses;thermodynamics;tricarboxylic acids;uniform resource locator	Xin Li;Fan Wu;Feng Qi;Daniel A. Beard	2011		10.1093/database/bar005	citric acid cycle;biochemistry;glycolysis;uncertainty;pentose phosphate pathway;kinetics	Vision	8.416066323270007	-64.04410139152763	35995
3ab2c9b946801fe579b2f559a09ebd897a2e066d	an effective risk factor detection and disease prediction (rfd-dp) model applied to hypertension		Never before in history is the data growing at such a high volume, variety and velocity. It not only provides multi-sources of information for people to discover useful, important and valuable nuggets of information, but also increases the difficulty in finding such nuggets in almost all fields. Particularly, the field of healthcare is known for its dominical or ontological complexity and variety of clinical data or medical data regarding its variable data standards and data quality and so as the high data dimensionality. In order to effectively use the data at the hand to improve healthcare outcomes and processes, this paper illustrates a model called Risk Factor Detection and Disease Prediction (RFD-DP) model. The model incorporates statistics, data mining and MapReduce techniques on high dimensional clinical data to detect risk factors and generate predicator for a specified disease, hypertension disease. The experimental results indicate that the proposed model outperforms traditional feature selection and classification methods in terms of accuracy, F-score, and AUC. Consequently, the proposed model is promising to be applied to healthcare system.	algorithm;big data;data mining;data quality;f1 score;feature selection;mapreduce;non-standard raid levels;velocity (software development)	Dingkun Li;Yaning Li;Zhou Ye;Ibrahim Musa;Keun Ho Ryu;Seon-Phil Jeong	2018	J. UCS			ML	4.9299534968046155	-76.66018458585363	36037
d7b37d861951bbbaecbd62bdfebf3bfc5112b7bf	growing functional modules from a seed protein via integration of protein interaction and gene expression data	microarray data;cluster algorithm;protein complex;saccharomyces cerevisiae;computer graphics;systems biology;saccharomyces cerevisiae proteins;reliability function;models biological;gene expression data;computational biology bioinformatics;gene expression;cluster analysis;proteins;protein protein interaction;artificial intelligence;algorithms;pattern recognition automated;weighted graph;combinatorial libraries;protein interaction;protein interaction mapping;proteomics;computer appl in life sciences;gene expression profiling;oligonucleotide array sequence analysis;databases protein;microarrays;bioinformatics	Nowadays modern biology aims at unravelling the strands of complex biological structures such as the protein-protein interaction (PPI) networks. A key concept in the organization of PPI networks is the existence of dense subnetworks (functional modules) in them. In recent approaches clustering algorithms were applied at these networks and the resulting subnetworks were evaluated by estimating the coverage of well-established protein complexes they contained. However, most of these algorithms elaborate on an unweighted graph structure which in turn fails to elevate those interactions that would contribute to the construction of biologically more valid and coherent functional modules. In the current study, we present a method that corroborates the integration of protein interaction and microarray data via the discovery of biologically valid functional modules. Initially the gene expression information is overlaid as weights onto the PPI network and the enriched PPI graph allows us to exploit its topological aspects, while simultaneously highlights enhanced functional association in specific pairs of proteins. Then we present an algorithm that unveils the functional modules of the weighted graph by expanding a kernel protein set, which originates from a given 'seed' protein used as starting-point. The integrated data and the concept of our approach provide reliable functional modules. We give proofs based on yeast data that our method manages to give accurate results in terms both of structural coherency, as well as functional consistency.	cluster analysis;coherence (physics);contain (action);dna integration;estimated;gene expression;graph - visual representation;kernel;kripke semantics;microarray;pixel density;proton pump inhibitors;seed;algorithm;protein protein interaction;statistical cluster	Ioannis A. Maraziotis;Konstantina Dimitrakopoulou;Anastasios Bezerianos	2007	BMC Bioinformatics	10.1186/1471-2105-8-408	protein–protein interaction;biology;microarray analysis techniques;molecular biology;gene expression;dna microarray;computer science;bioinformatics;multiprotein complex;gene expression profiling;cluster analysis;proteomics;computer graphics;genetics;systems biology	Comp.	4.629472069135317	-56.801369482581045	36038
ab325d874800a32b995e9aba20adac2c1b698b7e	preassemble: a tool for automatic sequencer trace data processing	dna;software;animals;data interpretation statistical;database management systems;computer graphics;data processing;sequence analysis dna;journal article;computational biology bioinformatics;large scale;quality assessment;cluster analysis;operating system;parameter tuning;genome;algorithms;sequence alignment;combinatorial libraries;computational biology;dna sequence;computer appl in life sciences;automatic data processing;chromatography;salmon;microarrays;bioinformatics;automation	Trace or chromatogram files (raw data) are produced by automatic nucleic acid sequencing equipment or sequencers. Each file contains information which can be interpreted by specialised software to reveal the sequence (base calling). This is done by the sequencer proprietary software or publicly available programs. Depending on the size of a sequencing project the number of trace files can vary from just a few to thousands of files. Sequencing quality assessment on various criteria is important at the stage preceding clustering and contig assembly. Two major publicly available packages – Phred and Staden are used by preAssemble to perform sequence quality processing. The preAssemble pre-assembly sequence processing pipeline has been developed for small to large scale automatic processing of DNA sequencer chromatogram (trace) data. The Staden Package Pregap4 module and base-calling program Phred are utilized in the pipeline, which produces detailed and self-explanatory output that can be displayed with a web browser. preAssemble can be used successfully with very little previous experience, however options for parameter tuning are provided for advanced users. preAssemble runs under UNIX and LINUX operating systems. It is available for downloading and will run as stand-alone software. It can also be accessed on the Norwegian Salmon Genome Project web site where preAssemble jobs can be run on the project server. preAssemble is a tool allowing to perform quality assessment of sequences generated by automatic sequencing equipment. preAssemble is flexible since both interactive jobs on the preAssemble server and the stand alone downloadable version are available. Virtually no previous experience is necessary to run a default preAssemble job, on the other hand options for parameter tuning are provided. Consequently preAssemble can be used as efficiently for just several trace files as for large scale sequence processing.	biopolymer sequencing;cluster analysis;download;laryngeal web;linux;microsequencer;nucleic acids;occupations;operating system;phred base calling;population parameter;server (computer);server (computing);staden package;unix;web site;explanation;statistical cluster	Alexei A. Adzhubei;Jon Kristen Laerdahl;Anna V. Vlasova	2005	Bmc Bioinformatics [Electronic Resource]	10.1186/1471-2105-7-22	biology;dna sequencing;dna microarray;data processing;computer science;bioinformatics;data science;automation;sequence alignment;data mining;cluster analysis;computer graphics;genetics;dna;genome	Comp.	-1.9555910329692332	-57.56105529548161	36051
fd11993d5e993b3c91abd3da530645122012302f	haplogrep 2: mitochondrial haplogroup classification in the era of high-throughput sequencing		Mitochondrial DNA (mtDNA) profiles can be classified into phylogenetic clusters (haplogroups), which is of great relevance for evolutionary, forensic and medical genetics. With the extensive growth of the underlying phylogenetic tree summarizing the published mtDNA sequences, the manual process of haplogroup classification would be too time-consuming. The previously published classification tool HaploGrep provided an automatic way to address this issue. Here, we present the completely updated version HaploGrep 2 offering several advanced features, including a generic rule-based system for immediate quality control (QC). This allows detecting artificial recombinants and missing variants as well as annotating rare and phantom mutations. Furthermore, the handling of high-throughput data in form of VCF files is now directly supported. For data output, several graphical reports are generated in real time, such as a multiple sequence alignment format, a VCF format and extended haplogroup QC reports, all viewable directly within the application. In addition, HaploGrep 2 generates a publication-ready phylogenetic tree of all input samples encoded relative to the revised Cambridge Reference Sequence. Finally, new distance measures and optimizations of the algorithm increase accuracy and speed-up the application. HaploGrep 2 can be accessed freely and without any registration at http://haplogrep.uibk.ac.at.	biopolymer sequencing;classification;dna computing;dna, mitochondrial;digeorge syndrome;generic drugs;graphical user interface;handling (psychology);haplogroup;high-throughput computing;imaging phantom;medical genetics specialty;mitochondrial inheritance;multiple sequence alignment;mutation;phantoms, imaging;phylogenetic tree;phylogenetics;recombinants;relevance;revision procedure;rule-based system;scientific publication;sensor;specimen source codes - quality control;throughput;variant call format;algorithm;mitochondrial dna location;registration - actclass	Hansi Weißensteiner;Dominic Pacher;Anita Kloss-Brandstätter;Lukas Forer;Günther Specht;Hans-Jürgen Bandelt;Florian Kronenberg;Antonio Salas;Sebastian Schönherr	2016		10.1093/nar/gkw233	biology;bioinformatics;genetics	Comp.	1.034601732768798	-55.03972106948352	36059
bfea37d624c49b440b0393072064a30dc00f132b	dna-based nanobiosensors as an emerging platform for detection of disease	dna;nanoparticles;molecular diagnostic techniques;electrochemical and optical sensing;cancer;biosensing techniques;dna nanobiosensors;precision medicine;humans;genetic and infectious diseases	Detection of disease at an early stage is one of the biggest challenges in medicine. Different disciplines of science are working together in this regard. The goal of nanodiagnostics is to provide more accurate tools for earlier diagnosis, to reduce cost and to simplify healthcare delivery of effective and personalized medicine, especially with regard to chronic diseases (e.g., diabetes and cardiovascular diseases) that have high healthcare costs. Up-to-date results suggest that DNA-based nanobiosensors could be used effectively to provide simple, fast, cost-effective, sensitive and specific detection of some genetic, cancer, and infectious diseases. In addition, they could potentially be used as a platform to detect immunodeficiency, and neurological and other diseases. This review examines different types of DNA-based nanobiosensors, the basic principles upon which they are based and their advantages and potential in diagnosis of acute and chronic diseases. We discuss recent trends and applications of new strategies for DNA-based nanobiosensors, and emphasize the challenges in translating basic research to the clinical laboratory.	affinity analysis;amplifier;biochip;biological markers;british informatics olympiad;cardiovascular diseases;chronic disease;communicable diseases;delivery of health care;diabetes mellitus;doping (semiconductor);gnu nano;hl7publishingsubsection <operations>;immunologic deficiency syndromes;interaction;interface device component;limited stage (cancer stage);microorganism;microsoft outlook for mac;miniaturization;multiplexing;nanomedicine;nanostructured materials;nanotechnology;neoplasms;oxides;personalization;precision medicine;reagents;sensitivity and specificity;therapeutic procedure;analyte	Khalid M. Abu-Salah;Mohammed Zourob;Fouzi Mouffouk;Salman A. Alrokayan;Manal A. Alaamery;Anees A. Ansari	2015		10.3390/s150614539	nanotechnology;nanoparticle;biological engineering;precision medicine;dna;cancer	ML	2.619322174059751	-68.36699777937378	36086
dbc3f26b6890f5cb57587b0b3e59679c006f7459	assigning functional linkages to proteins using phylogenetic profiles and continuous phenotypes	fenotipo;proteine;phylogeny;phylogenese;liaison genetique;en continu;bioinformatique;en continuo;genetic mapping;genome size;optimal growth;protein function prediction;genetic linkage;filogenesis;carte genetique;proteina;mapa genetico;bioinformatica;protein;phenotype;continuous process;bioinformatics;ligamiento genetico	MOTIVATION A class of non-homology-based methods for protein function prediction relies on the assumption that genes linked to a phenotypic trait are preferentially conserved among organisms that share the trait. These methods typically compare pairs of binary strings, where one string encodes the phylogenetic distribution of a trait and the other of a protein. In this work, we extended the approach to automatically deal with continuous phenotypes.   RESULTS Rather than use a priori rules, which can be very subjective, to construct binary profiles from continuous phenotypes, we propose to systematically explore thresholds which can meaningfully separate the phenotype values. We illustrate our method by analyzing optimal growth temperatures, and demonstrate its usefulness by automatically retrieving genes which have been associated with thermophilic growth. We also apply the general approach, for the first time, to optimal growth pH, and make novel predictions. Finally, we show that our method can also be applied to other properties which may not be classically considered as phenotypes. Specifically, we studied correlations between genome size and the distribution of genes.	assumed;coenzyme a;complement (complexity);complement system proteins;dna repair;gene regulatory network;generalized pustular psoriasis;genes, vif;genetic algorithm;genome size;graph partition;hl7publishingsubsection <query>;homologous gene;homology (biology);ligase;matching;mental association;nucleotides;ppcs gene;phenotype;phylogenetic tree;phylogenetics;protein function prediction;rule (guideline)	Orland R. Gonzalez;Ralf Zimmer	2008	Bioinformatics	10.1093/bioinformatics/btn106	biology;gene mapping;genetic linkage;bioinformatics;phenotype;genome size;protein function prediction;genetics;phylogenetics	Comp.	3.695109907287323	-59.340386826078095	36094
08e9332daaea5746c78433b9ce91a59ab61b7118	a croc stronger than roc	software;drug discovery;area under curve;roc curve;models statistical;algorithms;computational biology	MOTIVATION The performance of classifiers is often assessed using Receiver Operating Characteristic ROC [or (AC) accumulation curve or enrichment curve] curves and the corresponding areas under the curves (AUCs). However, in many fundamental problems ranging from information retrieval to drug discovery, only the very top of the ranked list of predictions is of any interest and ROCs and AUCs are not very useful. New metrics, visualizations and optimization tools are needed to address this 'early retrieval' problem.   RESULTS To address the early retrieval problem, we develop the general concentrated ROC (CROC) framework. In this framework, any relevant portion of the ROC (or AC) curve is magnified smoothly by an appropriate continuous transformation of the coordinates with a corresponding magnification factor. Appropriate families of magnification functions confined to the unit square are derived and their properties are analyzed together with the resulting CROC curves. The area under the CROC curve (AUC[CROC]) can be used to assess early retrieval. The general framework is demonstrated on a drug discovery problem and used to discriminate more accurately the early retrieval performance of five different predictors. From this framework, we propose a novel metric and visualization-the CROC(exp), an exponential transform of the ROC curve-as an alternative to other methods. The CROC(exp) provides a principled, flexible and effective way for measuring and visualizing early retrieval performance with excellent statistical power. Corresponding methods for optimizing early retrieval are also described in the Appendix.   AVAILABILITY Datasets are publicly available. Python code and command-line utilities implementing CROC curves and metrics are available at http://pypi.python.org/pypi/CROC/ CONTACT: pfbaldi@ics.uci.edu	command-line interface;concentrate dosage form;drug discovery;gene ontology term enrichment;imagery;information retrieval;mathematical optimization;receiver operator characteristics;receiver operating characteristic;smoothing;tree accumulation;exponential;receptor operated channel	Sanjay Joshua Swamidass;Chloé-Agathe Azencott;Kenny Daily;Pierre Baldi	2010	Bioinformatics	10.1093/bioinformatics/btq140	integral;computer science;bioinformatics;machine learning;data mining;receiver operating characteristic;drug discovery;statistics	Web+IR	-0.5874985115734069	-62.6673936689636	36120
193a23c613eed5561259b8822114361f49be3a17	the accurate prediction of protein family from amino acid sequence by measuring features of sequence fragments	protein family;amino acid sequence;protein feature;recognition;sequence;prediction	The rapid advances in proteomic analyses coupled with the completion of multiple genomes have led to an increased demand for determining protein functions. The first step is classification or prediction into families. A method was developed for the prediction of protein family based only on protein sequence using support vector machine (SVM) models. In these models, the amino acids were classified into three categories (apolar, polar, and charged). Consecutive fragments ranging from one to five were annotated by amino acid type to define the protein features of each protein. SVM models were constructed based on the protein features of a training set of proteins and then examined with an independent set of proteins. The approach was tested for 20 protein families from the iProClass database of Protein Information Resources (PIR). For two-class SVM models, an average prediction accuracy of 0.9985 was achieved, while for multi-class SVM models an accuracy of 0.9941 was achieved. This study demonstrates that SVM based methods can accurately recognize and predict the protein family to which a sequence belongs based solely on its primary amino acid sequence.		Huixiao Hong;Qilong Hong;Roger Perkins;Leming Shi;Hong Fang;Zhenqiang Su;Yvonne P. Dragan;James C. Fuscoe;Weida Tong	2009	Journal of computational biology : a journal of computational molecular cell biology	10.1089/cmb.2008.0115	biology;biochemistry;prediction;bioinformatics;pattern recognition;protein structure prediction;sequence;mathematics;peptide sequence;protein family	Comp.	10.141782141953236	-55.637198457247564	36129
f596586272fee75d9560176585b772a8cf2190f9	a unique geometry of the active site of angiotensin-converting enzyme consistent with structure-activity studies	zinc;point of view;molecular mechanics;functional group;angiotensin converting enzyme;active site;ace inhibitor	Previous structure-activity studies of captopril and related active angiotensin-converting enzyme (ACE) inhibitors have led to the conclusion that the basic structural requirements for inhibition of ACE involve (a) a terminal carboxyl group; (b) an amido carbonyl group; and (c) different types of effective zinc (Zn) ligand functional groups. Such structural requirements common to a set of compounds acting at the same receptor have been used to define a pharmacophoric pattern of atoms or groups of atoms mutually oriented in space that is necessary for ACE inhibition from a stereochemical point of view. A unique pharmacophore model (within the resolution of approximately 0.15 A) was observed using a method for systematic search of the conformational hyperspace available to the 28 structurally different molecules under study. The method does not assume a common molecular framework, and, therefore, allows comparison of different compounds that is independent of their absolute orientation. Consequently, by placing the carboxyl binding group, the binding site for amido carbonyl, and the Zn atom site in positions determined by ideal binding geometry with the inhibitors' functional groups, it was possible to clearly specify a geometry for the active site of ACE.	ace;angiotensin-converting enzyme inhibitors;angiotensins;atom;captopril;carbonyl cyanide p-trifluoromethoxyphenylhydrazone;carboxyl group;emoticon;ligands;peptidyl-dipeptidase a;pharmacophore;requirement	Dorica Mayer;Christopher B. Naylor;Ioan Motoc;Garland R. Marshall	1987	Journal of computer-aided molecular design	10.1007/BF01680553	biochemistry;stereochemistry;chemistry;molecular mechanics;active site;organic chemistry;zinc	Comp.	10.68919852478712	-61.46716699648573	36139
012b36c11a95c6000666036b6d705f724eb2ee2f	spike timing and the coding of naturalistic sounds in a central auditory area of songbirds	high dimensionality;zebra finch;information access;neural code;data analysis;spike timing;temporal pattern;spike train;visual system	In nature, animals encounter high dimensional sensory stim uli that have complex statistical and dynamical structure. Attempts to study the neural coding of these natural signals face challenges both in the selection of the signal ensemble and in the analys is of the resulting neural responses. For zebra finches, naturalistic stimuli can be defined as soun ds that they encounter in a colony of conspecific birds. We assembled an ensemble of these sounds b y recording groups of 10-40 zebra finches, and then analyzed the response of single neurons in t he songbird central auditory area (field L) to continuous playback of long segments from this ensembl . Following methods developed in the fly visual system, we measured the information that spike tra ins provide about the acoustic stimulus without any assumptions about which features of the stimulu s are relevant. Preliminary results indicate that large amounts of information are carried by spike timin g, with roughly half of the information accessible only at time resolutions better than 10 ms; addit ional information is still being revealed as time resolution is improved to 2 ms. Information can be decom p sed into that carried by the locking of individual spikes to the stimulus (or modulations of spik e rate) vs. that carried by timing in spike patterns. Initial results show that in field L, temporal patt erns give at least ∼ 20% extra information. Thus, single central auditory neurons can provide an inform ative representation of naturalistic sounds, in which spike timing may play a significant role.	acoustic cryptanalysis;avid ds;code;design pattern;encode;experiment;high-level programming language;information theory;l (complexity);lock (computer science);neural coding;sed;songbird;spike-triggered average;transponder timing	B. D. Wright;Kamal Sen;William Bialek;A. J. Doupe	2001			neuroscience;speech recognition;visual system;computer science;machine learning;neural coding;data analysis	ML	18.163041379384982	-75.05967664349217	36172
d9eb7e4470b2dc96b32d0c76289438a42a79d53f	dynamics of evolving feed-forward neural networks and their topological invariants		The evolution of a simulated feed-forward neural network with recurrent excitatory connections and inhibitory forward connections is studied within the framework of algebraic topology. The dynamics includes pruning and strengthening of the excitatory connections. The invariants that we define are based on the connectivity structure of the underlying graph and its directed clique complex. The computation of this complex and of its Euler characteristic are related with the dynamical evolution of the network. As the network evolves dynamically, its network topology changes because of the pruning and strengthening of the onnections and algebraic topological invariants can be computed at different time steps providing a description of the process. We observe that the initial values of the topological invariant computed on the network before it evolves can predict the intensity of the activity.	artificial neural network;computation;directed graph;dynamical system;euler characteristic;feedforward neural network;linear algebra;network topology	Paolo Masulli;Alessandro E. P. Villa	2016		10.1007/978-3-319-44778-0_12	algebraic topology;graph theory;clique complex;euler characteristic;artificial neural network;computer science;invariant (mathematics);network topology;synfire chain;topology	ML	17.629230859444554	-69.16532066016086	36210
d2829a8d2ca45f94bb1a78636e3c5198771d8d7d	a new protocol of analyzing isotope-coded affinity tag data from high-resolution lc-ms spectrometry	high resolution;mass spectrometry;mass spectrometry data analysis;tandem ms triggering;ratio estimator;quantitative proteomics;data analysis;isotope labeling;isotope coded affinity tag	Isotope-coded affinity tags (ICAT) is a labeling technique that provides insights into quantitative molecular changes. In this paper, we propose a new protocol to identify and analyze ICAT labeled peak pairs in high-resolution LC-MS data. Our major contributions are: (1) we use isotope distance constraint, ICAT distance constraint, and LC-span constraint to identify ICAT labeled peak pairs and (2) we propose to trigger tandem MS/MS scanning based on the ratio estimation value of identified ICAT peak pairs instead of the peak intensity values. Compared with current approaches that choose peaks with high intensity values for tandem MS/MS scanning, the new protocol can improve the scanning efficiency and accuracy.	idog;image resolution;isotope-coded affinity tag protein analysis;isotopes;processor affinity;radionuclide imaging;span distance;tags (device);tandem mass spectrometry;tracer	Weichuan Yu;Junfeng Liu;Christopher M. Colangelo;Erol E. Gulcicek;Hongyu Zhao	2007	Computational biology and chemistry	10.1016/j.compbiolchem.2007.03.001	chromatography;ratio estimator;chemistry;image resolution;mass spectrometry;isotope-coded affinity tag;bioinformatics;quantitative proteomics;analytical chemistry;data analysis	Comp.	3.42026219764066	-54.85073861454885	36276
46fa26e75092d68349c8799253eb27095f0e2863	analyzing the robustness of redundant population codes in sensory and feature extraction systems	neural code;feature space;redundant representations;feature extraction;noise reduction;population coding;spike train;sensory system;population codes	Sensory systems often use groups of redundant neurons to represent stimulus information both during transduction and population coding of features. This redundancy makes the system more robust to corruption in the representation. We approximate neural coding as a projection of the stimulus onto a set of vectors, with the result encoded by spike trains. We use the formalism of frame theory to quantify the inherent noise reduction properties of such population codes. Additionally, computing features from the stimulus signal can also be thought of as projecting the coefficients of a sensory representation onto another set of vectors specific to the feature of interest. The conditions under which a combination of different features form a complete representation for the stimulus signal can be found through a recent extension to frame theory called “frames of subspaces.” We extend the frame of subspaces theory to quantify the noise reduction properties of a collection of redundant feature spaces.	approximation algorithm;code;coefficient;feature extraction;neural coding;noise reduction;semantics (computer science);transduction (machine learning)	Christopher J. Rozell;Don H. Johnson	2005	Neurocomputing	10.1016/j.neucom.2005.12.079	computer vision;computer science;machine learning;pattern recognition;mathematics;neural coding	ML	23.078878283252827	-71.90787502562948	36334
85865699dc82eb6a3d01ff8b8cda2a18c18f3961	picking out polymorphs: h-bond prediction and crystal structure stability	health research;uk clinical guidelines;biological patents;europe pubmed central;citation search;computer applications in chemistry;theoretical and computational chemistry;computational biology bioinformatics;uk phd theses thesis;polymorphism;life sciences;crystal structure;uk research reports;medical journals;europe pmc;documentation and information in chemistry;biomedical research;bioinformatics	A methodology has been developed to predict the propensity for hydrogen bonds to form in crystal structures, treating each potential H-bond as a binary response variable, and modelling its likelihood using a set of relevant chemical descriptors [1]. Modelling is tailored to a target using chemically similar known structures, from e.g. the Cambridge Structural Database [2], making it accessible to the complete spectrum of organic structures, including solvates, hydrates and cocrystals. Recent work has developed the approach to predicting interand intramolecular H-bonds when either type can occur. By way of a comparison between possible and observed H-bonds, the method has been applied to assess structural stability, which shows much promise in the domain of polymorph screening in the pharmaceutical industry. We will introduce the methodology and illustrate its application using a selection of pharmaceutical compounds, one of which will be Abbott’s wellpublicised anti-HIV medication ritonavir (NorvirTM). Owing to a hidden, more stable form II with much lower bioavailability, ritonavir was temporarily withdrawn from the market with significant financial impact [3]. Our method quickly suggests a real threat of polymorphism in this compound, and strongly supports the relative stability of form II over form I. For all examples, the high predictivity of the method is emphasised.	cambridge structural database;crystal structure;hydrogen;tagged union;virtual screening	Peter T. A. Galek;Frank H. Allen;László Fábián	2010		10.1186/1758-2946-2-S1-P26	biology;polymorphism;medicine;computer science;bioinformatics;crystal structure	ML	9.503244832457575	-60.98806232283601	36338
eb67af02d99c2491658eb45215cf72bc98714d0a	elman topology with sigma-pi units: an application to the modeling of verbal hallucinations in schizophrenia	modelizacion;produit kronecker;tratamiento lenguaje;sigma pi unit;modelisation;schizophrenia;hallucination;language processing;esquizofrenia;simple recurrent network;traitement langage;producto kronecker;schizophrenie;alucinacion;neural network model;reseau neuronal;modeling;red neuronal;kronecker product;srn;neural network	The development of neural network models has greatly enhanced the comprehension of cognitive phenomena. Here, we show that models using multiplicative processing of inputs are both powerful and simple to train and understand. We believe they are valuable tools for cognitive explorations. Our model can be viewed as a subclass of networks built on sigma-pi units and we show how to derive the Kronecker product representation from the classical sigma-pi unit. We also show how the connectivity requirements of the Kronecker product can be relaxed considering statistical arguments. We use the multiplicative network to implement what we call an Elman topology, that is, a simple recurrent network (SRN) that supports aspects of language processing. As an application, we model the appearance of hallucinated voices after network damage, and show that we can reproduce results previously obtained with SRNs concerning the pathology of schizophrenia.	anatomy, regional;cognition disorders;global serializability;hallucinations;neural network simulation;recurrent neural network;relaxation;requirement;schizophrenia;voice;subclass	Juan C. Valle-Lisboa;Florencia Reali;Héctor Anastasía;Eduardo Mizraji	2005	Neural networks : the official journal of the International Neural Network Society	10.1016/j.neunet.2005.03.009	computer science;artificial intelligence;machine learning;schizophrenia;kronecker product;artificial neural network	ML	21.689069111363445	-70.39669387963012	36374
ffef48237cbc65ce19c78c063c8f4d3e0e3a049d	wide range multiscale entropy changes through development	development;multiscale entropy;complexity;eeg	How variability in the brain’s neurophysiologic signals evolves during development is important for a global, system-level understanding of brain maturation and its disturbance in neurodevelopmental disorders. In the current study, we use multiscale entropy (MSE), a measure that has been related to signal complexity, to investigate how this variability evolves during development across a broad range of temporal scales. We computed MSE, standard deviation (STD) and standard spectral analyses on resting EEG from 188 healthy individuals aged 8–22 years old. We found age-related increases in entropy at lower scales (<~20 ms) and decreases in entropy at higher scales (~60–80 ms). Decreases in the overall signal STD were anticorrelated with entropy, especially in the lower scales, where regression analyses showed substantial covariation of observed changes. Our findings document for the first time the scale dependency of developmental changes from childhood to early adulthood, challenging a parsimonious MSE-based account of brain maturation along a unidimensional, complexity measure. At the level of analysis permitted by electroencephalography (EEG), MSE could capture critical spatiotemporal variations in the role of noise in the brain. However, interpretations critically rely on defining how signal STD affects MSE properties.	blum axioms;electroencephalography;entropy (information theory);heart rate variability;information processing;metastability in electronics;occam's razor;population;rényi entropy;std bus;spatial variability	Nicola Riccardo Polizzotto;Tetsuya Takahashi;Christopher P. Walker;Raymond Y. Cho	2016	Entropy	10.3390/e18010012	econometrics;complexity;mathematics;statistics	HCI	20.334280006542567	-76.9384135760783	36419
3beac2b4aac13cc4ec0064cc476f56ab096fade7	a system to project injury and illness incidence during military operations	pediatrics;medical simulation;operations research;data mining;statistical distributions;medical information systems;blood;injuries;injuries blood data mining medical simulation diseases pediatrics medical information systems operations research statistical distributions predictive models;diseases;predictive models;technical report;statistical distribution;historical data	Modeling of medical resource requirements during military operations requires projections of disease and non-battle injury (DNBI) and wounded-in-action (WIA) rates. Historical data were extracted from unit diaries of infantry and support troop deployed during four previous combat engagements. A planning tool (FORECAS) was developed that uses the statistical distributions of DNBI and WIA incidence from previous operations to simulate injury and illness arrival rates for future scenarios. Output of the simulated data reflects the nuances of the empirical data.	diaries;extraction;hl7publishingsubsection <operations>;illness (finding);incidence matrix;projections and predictions;requirement;simulation;statistical distributions	Christopher G. Blood;Ed O'Donnell;Dan Rotblatt	1995	Journal of medical systems	10.1145/256562.256845	probability distribution;medical simulation;simulation;computer science;engineering;data mining;operations research;statistics	ML	5.975957867148427	-73.89333397730917	36430
8dd7fc68369ee36aa39910d6d9603ac91549c236	neural mechanisms which discriminate events on the skin	tactile system nervous system pattern classification skin;tactile system;nervous system;skin;space time;skin pain nervous system psychology optical fiber sensors muscles biomedical optical imaging optical sensors central nervous system telephony;pattern classification;sensory system	This review examines the historical development of concepts of nervous system organization with special reference to the skin sensory system. The commonly held view that the modalities of sensation are produced solely by the initial filtering action of the receptor organs is shown not to fit the observed physiology of the first and second cells in the sensory pathway. Instead, it is proposed that every discriminably different cutaneous perception is produced by a unique space-time pattern of nerve impulses. The mechanisms employed by the nervous system for generating and analyzing space-time patterns of impulses are discussed.		Patrick D. Wall;Ronald Melzack	1962	IRE Trans. Information Theory	10.1109/TIT.1962.1057689	sensory system;space time;skin;nervous system	ECom	17.987338083937335	-74.88944486291065	36447
3203a4d8a95ec6d5f705fd5304b4fc4094756186	convergence of prefrontal and parietal anatomical projections in a connectional hub in the striatum	corticostriatal connectivity;monkey anatomy;parietal;prefrontal;resting-state functional connectivity;striatum	Visual attentional bias forms for rewarding and punishing stimuli in the environment. While this attentional bias is adaptive in healthy situations, it is maladaptive in disorders such as drug addiction or PTSD. In both these disorders, the ability to exert control over this attentional bias is associated with drug abstinence rates or reduced PTSD symptoms, indicating the interaction of visual attention, cognitive control, and stimulus association. The inferior parietal lobule (IPL) is central to attention, while the prefrontal cortex (PFC) is critical for reward, cognitive control, and attention. Importantly, regions of the IPL and PFC commonly project to the rostral dorsal caudate (rdCaud) of the striatum. We propose an anatomical network architecture in which IPL projections converge with PFC projections in a connectional hub in the rdCaud, providing an anatomical substrate for the interaction of these projections and their competitive influence on striatal processing. To investigate this, we mapped the dense projections from the caudal IPL and prefrontal (dlPFC, vlPFC, OFC, dACC, and dmPFC) regions that project to the medial rdCaud with anatomical tract-tracing tracer injections in monkeys. These inputs converge in a precise site in the medial rdCaud, rostral to the anterior commissure. Small retrograde tracer injections confirmed these inputs to the medial rdCaud and showed that a proximal ventral striatal location has a very different pattern of cortical inputs. We next used human resting-state functional connectivity MRI (fcMRI) to examine whether a striatal hub exists in the human medial rdCaud. Seed regions in the human medial rdCaud revealed cortical correlation maps similar to the monkey retrograde injection results. A subsequent analysis of these correlated cortical regions showed that their peak correlation within the striatum is in the medial rdCaud, indicating that this is a connectional hub. In contrast, this peak striatal correlation was not found in the ventral striatal location, suggesting that this site is not a connectional hub of cortical regions. Taken together, this work uses the precision of monkey anatomy to identify a connectional hub of IPL and PFC projections in the medial rdCaud. It also translates this anatomical precision to humans, demonstrating that, guided by anatomy, connectional hubs can be identified in humans with fcMRI. These connectional hubs provide more specific treatment targets for drug addiction, PTSD, and other neurological and psychiatric disorders involving the striatum.	addictive behavior;anatomic structures;attention deficit hyperactivity disorder;attentional bias;bias–variance tradeoff;cfp gene;cfp wt allele;caudal;converge;drug dependence;ethernet hub;functional connectivity magnetic resonance imaging;http 404;homophobia;inferior parietal lobule;map;medial graph;mental disorders;neostriatum;network architecture;orofacial cleft 1;post-traumatic stress disorder;powerbuilder foundation classes;prefrontal cortex;projection defense mechanism;projections and predictions;rest;resting state fmri;retrograde tracing;rewards;spinal cord stimulator;structure of anterior commissure;tracer;tract (literature);usb hub;dorsal raphe nucleus;physical hard work	Eun Young Choi;Yoko Tanimura;Priti R. Vage;Ellen H. Yates;Suzanne N. Haber	2017	NeuroImage	10.1016/j.neuroimage.2016.09.037	psychology;neuroscience;developmental psychology;social psychology	ML	19.35071504241388	-78.9034837642359	36521
de05e59b80aca550a012969dd67dcfd1b2dd1fa1	a client-server architecture for remotely controlling a robot using a closed-loop system with a biological neuroprocessor	remote control;client server architecture;remote robotic control;neuroprocessor;client server;robot control;multielectrode array;cultured neural network;neural network;open source;real time systems	This paper introduces an open-source real-time system that remotely controls a robot using human neuroblastoma cultures and a client-server architecture. Multielectrode array set-ups have been designed for direct culturing of neural cells over silicon or glass substrates, providing the capability simultaneously to stimulate and record populations of neural cells. However, it is very difficult to attach these neural cells to the robot structure due to the special conditions of the biological material. The main objective of this research is to build a client-server system for remotely connecting a robot to a neural culture in a closed-loop experimentation. The robot sensors will feed the biological neuroprocessor, while the neural activity will be used for guiding the robot, controlling in this way the robotic behaviour.	client–server model;robot;server (computing)	Daniel de Santos;Victor Lorente;Félix de la Paz;José Manuel Cuadra Troncoso;José R. Álvarez;Eduardo Fernández;José Manuel Ferrández	2010	Robotics and Autonomous Systems	10.1016/j.robot.2010.09.003	embedded system;simulation;computer science;artificial intelligence;artificial neural network;client–server model	Robotics	15.39003813555047	-67.32105437512419	36563
49b57911945c35761263d27bf9e3e9d6981bbe9f	adaptive olfactory encoding in agents controlled by spiking neural networks	neural network control;firing rate;high concentrate;temporal coincidence;spiking neural network;neural encoding;article	We created a neural architecture that can use two different types of information encoding strategies depending on the environment. The goal of this research was to create a simulated agent that could react to two different overlapping chemicals having varying concentrations. The neural network controls the agent by encoding its sensory information as temporal coincidences in a low concentration environment, and as firing rates at high concentration. With such an architecture, we could study synchronization of firing in a simple manner and see its effect on the agent’s behaviour.	artificial neural network;code;gradient;neural coding;neural network software;sensor;sensory neuroscience;spiking neural network;synaptic package manager;synaptic weight	Nicolas Oros;Volker Steuber;Neil Davey;Lola Cañamero;Rod Adams	2008		10.1007/978-3-540-69134-1_15	computer science;artificial intelligence;machine learning;time delay neural network;spiking neural network	AI	18.642565910220327	-69.12344334775574	36579
3ac50595bd05e467cc824943692eda215a0955ae	protein expression data improves gene function prediction	proteins	Biological science has stepped into systems biology era, but many genes function is still unknown. With the development of high throughput experiment, large biological information(RNA-Seq, interaction network) is fully used to predict gene function. As the main biological actor, protein expression is closer with the gene functions. The human protein expression obtained from mass spectrometry[1], together with multiple omics data, can improve genes functions prediction.	functional genomics;gene prediction;interaction network;omics;systems biology;throughput	Huadong Yang;Xiaofeng Song;Xuejiang Guo	2016	2016 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)	10.1109/BIBM.2016.7822803	biology;fox proteins;molecular biology;computer science;bioinformatics;protein function prediction;genetics	Comp.	4.510593619729997	-58.41163702665004	36598
db911bdbe325f9759f4544856a776d4905561716	estimation of population allele frequencies from small samples containing multiple generations	population genetics;monte carlo simulation;allele frequency;genetic distance	Estimations of population genetic parameters like allele frequencies, heterozygosities, inbreeding coefficients and genetic distances rely on the assumption that all sampled genotypes come from a randomly interbreeding population or sub-population. Here we show that small cross-generational samples may severely affect estimates of allele frequencies, when a small number of progenies dominate the next generation or the sample. A new estimator of allele frequencies is developed for such cases when the kin structure of the focal sample is unknown and has to be assessed simultaneously. Using Monte Carlo simulations it was demonstrated that the new estimator delivered significant improvement over the conventional allele-counting estimator.	coefficient;focal (programming language);genetic distance;microsoft kin;monte carlo method;randomness;simulation	Dmitry A. Konovalov;Dik Heg	2008			biology;genetic distance;allele frequency;genotype frequency;population genetics;genetics;statistics;monte carlo method	Vision	2.92142470098266	-52.6427554312357	36700
be837eb673211bbfd5531ac1bfec1bf450719184	visual attention, visual saliency, and eye movements during the inspection of natural scenes	modelizacion;teoria cognitiva;complex objects;saliency map;ingenierie connaissances;movimiento ocular;cognitive theory;intelligence artificielle;atencion visual;theorie cognitive;modelisation;eye movement;cognition;scene naturelle;bf psychology;visual control;cognicion;artificial intelligence;controle visuel;attention visuelle;inteligencia artificial;mouvement oculaire;visual attention;institutional repository research archive oaister;modeling;natural scenes;control visual;knowledge engineering	How does visual saliency determine the attention given to objects in a scene? Viewers’ eye movements were recorded during the inspection of pictures of natural office scenes containing two objects of interest. According to the Itti and Koch algorithm one object had lower visual saliency relative to the other that was visually complex. We varied the purpose of picture inspection to determine whether visual saliency is invariably dominant in determining the pattern of fixations, or whether task demands can provide a cognitive override that renders saliency as of secondary importance. When viewers inspected the scene in preparation for a memory task, the more complex objects were potent in attracting early fixations, in support of a saliency map model of scene inspec-tion. When the viewers were set the task of search for the lower-saliency target the effect of the distractor was negligible, requiring the saliency map to be built with cognitive influences.	algorithm;image;koch snowflake;rendering (computer graphics)	Geoffrey M. Underwood;Tom Foulsham;Editha van Loon;Jean Underwood	2005		10.1007/11499305_47	computer vision;systems modeling;cognition;computer science;artificial intelligence;knowledge engineering;eye movement	ML	23.292041206309584	-66.1366294742506	36733
e6a1e018294f9544244a7d320d6a82a8ce6b6daa	(tutorial on) dna structure, replication, transcription, and protein synthesis	protein synthesis;dna structure		medical transcription	M. Sapiyan	1998	Educational Technology & Society		control of chromosome duplication;computer science;knowledge management;eukaryotic dna replication;dna-binding domain;hmg-box;replication factor c;molecular biology;origin recognition complex;ter protein;seqa protein domain	Logic	1.1195507122259631	-63.639050874998325	36770
dd623923f6c858a4f8a32fb26ed1f440dd4a8ff8	what we think before a voluntary movement	female;brain;thinking;male;adult;predictive value of tests;volition;humans;young adult;electroencephalography;movement	A central feature of voluntary movement is the sense of volition, but when this sense arises in the course of movement formulation and execution is not clear. Many studies have explored how the brain might be actively preparing movement before the sense of volition; however, because the timing of the sense of volition has depended on subjective and retrospective judgments, these findings are still regarded with a degree of scepticism. EEG events such as beta event-related desynchronization and movement-related cortical potentials are associated with the brain's programming of movement. Using an optimized EEG signal derived from multiple variables, we were able to make real-time predictions of movements in advance of their occurrence with a low false-positive rate. We asked participants what they were thinking at the time of prediction: Sometimes they were thinking about movement, and other times they were not. Our results indicate that the brain can be preparing to make voluntary movements while participants are thinking about something else.	electroencephalography;judgment;movement;preparation;real-time transcription;volition	Logan Schneider;Elise Houdayer;Ou Bai;Mark Hallett	2013	Journal of Cognitive Neuroscience	10.1162/jocn_a_00360	psychology;movement;developmental psychology;young adult;electroencephalography;thought;predictive value of tests;communication;social psychology	HCI	15.601214360576277	-78.11249982305914	36820
92ff1fc9319c672ecfb4d41bdd5f723b5a295e26	a cellular automaton model for chromosome interlocking in meiotic pairing	markov chain model;homology search;probability distribution;cell division;stochastic model;cellular automaton	Abstract   In order to simulate the process of homology searching and interlocking of chromosomes in the meiotic cell nucleus we develop a cellular automaton model which reflects both the spatial and the temporal behaviour of chromosomes during meiotic pairing. To choose the simulation parameters reasonably we orientate ourselves by experimental data from yeast. We find an interlocking probability of about 11% per pair of chromosomes and of about 61% per cell nucleus, provided that the search of the chromosomes takes place mainly on the surface of the nuclear membrane. In case of a search within the nucleus the corresponding probabilities turn out to be 16% per pair and 77% per nucleus. This means that interlocking can be expected with nearly eight out of ten meiotic cell divisions. Moreover, we compare the outcome of our simulations to results obtained by a stochastic model describing pairing times and interlocking probability distributions analytically. Thus we achieve a general description of chromosomal behaviour which relies on both simulation and analytic considerations.	cellular automaton	Dietmar Dorninger;Günther Karigl;Josef Loidl	1998	Simul. Pr. Theory	10.1016/S0928-4869(96)00029-8	cellular automaton;probability distribution;markov chain;combinatorics;discrete mathematics;bioinformatics;stochastic modelling;mathematics;cell division;statistics	Logic	8.698078444906137	-65.12713054508652	36836
c111914bfd4798030410ac01ffae79609b7591fd	sparse decomposition of gene expression data to infer transcriptional modules guided by motif information	gene expression profile;integrated approach;estrogen receptor binding;gene regulatory networks;motif analysis;regulatory element;transcriptional modules;gene expression data;sparse component analysis;transcription factor;clustering method;sequence analysis;estrogen receptor;computational biology;gene regulatory network;breast cancer	An important topic in computational biology is to identify transcriptional modules through sequence analysis and gene expression profiling. A transcriptional module is formed by a group of genes under control of one or several transcription factors (TFs) that bind to cis-regulatory elements in the promoter regions of those genes. In this paper, we develop an integrative approach, namely motif-guided sparse decomposition (mSD), to uncover transcriptional modules by combining motif information and gene expression data. The method exploits the interplay of co-expression and co-regulation to find regulated gene patterns guided by TF binding information. Specifically, a motif-guided clustering method is first developed to estimate transcription factor binding activities (TFBAs); sparse component analysis is then followed to further identify TFs’ target genes. The experimental results show that the mSD approach can successfully help uncover condition-specific transcriptional modules that may have important implications in endocrine therapy of breast cancer.	cluster analysis;computational biology;gene expression profiling;motif;sequence analysis;sparse matrix;transcription (software)	Ting Gong;Jianhua Xuan;Li Chen;Rebecca B. Riggins;Yue Joseph Wang;Eric P. Hoffman;Robert Clarke	2008		10.1007/978-3-540-79450-9_23	biology;gene regulatory network;molecular biology;bioinformatics;genetics	Comp.	4.750239319485658	-57.660408264440775	36981
069ec14ffe75dcca84f54a6f3e941ec0d844767e	performance of computational tools in evaluating the functional impact of laboratory-induced amino acid mutations	software;molecular sequence annotation;mutagenesis site directed;proteins;amino acids;computational biology;mutation;databases protein	Site-directed mutagenesis is frequently used by scientists to investigate the functional impact of amino acid mutations in the laboratory. Over 10,000 such laboratory-induced mutations have been reported in the UniProt database along with the outcomes of functional assays. Here, we explore the performance of state-of-the-art computational tools (Condel, PolyPhen-2 and SIFT) in correctly annotating the function-altering potential of 10,913 laboratory-induced mutations from 2372 proteins. We find that computational tools are very successful in diagnosing laboratory-induced mutations that elicit significant functional change in the laboratory (up to 92% accuracy). But, these tools consistently fail in correctly annotating laboratory-induced mutations that show no functional impact in the laboratory assays. Therefore, the overall accuracy of computational tools for laboratory-induced mutations is much lower than that observed for the naturally occurring human variants. We tested and rejected the possibilities that the preponderance of changes to alanine and the presence of multiple base-pair mutations in the laboratory were the reasons for the observed discordance between the performance of computational tools for natural and laboratory mutations. Instead, we discover that the laboratory-induced mutations occur predominately at the highly conserved positions in proteins, where the computational tools have the lowest accuracy of correct prediction for variants that do not impact function (neutral). Therefore, the comparisons of experimental-profiling results with those from computational predictions need to be sensitive to the evolutionary conservation of the positions harboring the amino acid change.	alanine;amino acids;computation (action);conserved sequence;mutation;scale-invariant feature transform;uniprot	Vanessa E. Gray;Kimberly R. Kukurba;Sudhir Kumar	2012		10.1093/bioinformatics/bts336	mutation;biology;molecular biology;bioinformatics;genetics	Comp.	8.210129626565836	-58.36379632388475	37081
634ff16a32448a11eea64cdf08f3971d5bc07c3c	carcinogenesis: alterations in reciprocal interactions of normal functional structure of biologic systems	signal image and speech processing;biological patents;biomedical journals;text mining;europe pubmed central;systems biology;citation search;citation networks;computational biology bioinformatics;biomedical engineering;research articles;abstracts;open access;life sciences;clinical guidelines;full text;rest apis;orcids;europe pmc;biomedical research;bioinformatics;literature search	"""The evolution of biologic systems (BS) includes functional mechanisms that in some conditions may lead to the development of cancer. Using mathematical group theory and matrix analysis, previously, it was shown that normally functioning BS are steady functional structures regulated by three basis regulatory components: reciprocal links (RL), negative feedback (NFB) and positive feedback (PFB). Together, they form an integrative unit maintaining system's autonomy and functional stability. It is proposed that phylogenetic development of different species is implemented by the splitting of """"rudimentary"""" characters into two relatively independent functional parts that become encoded in chromosomes. The functional correlate of splitting mechanisms is RL. Inversion of phylogenetic mechanisms during ontogenetic development leads cell differentiation until cells reach mature states. Deterioration of reciprocal structure in the genome during ontogenesis gives rise of pathological conditions characterized by unsteadiness of the system. Uncontrollable cell proliferation and invasive cell growth are the leading features of the functional outcomes of malfunctioning systems. The regulatory element responsible for these changes is RL. In matrix language, pathological regulation is represented by matrices having positive values of diagonal elements (TrA > 0) and also positive values of matrix determinant (detA > 0). Regulatory structures of that kind can be obtained if the negative entry of the matrix corresponding to RL is replaced with the positive one. To describe not only normal but also pathological states of BS, a unit matrix should be added to the basis matrices representing RL, NFB and PFB. A mathematical structure corresponding to the set of these four basis functional patterns (matrices) is a split quaternion (coquaternion). The structure and specific role of basis elements comprising four-dimensional linear space of split quaternions help to understand what changes in mechanism of cell differentiation may lead to cancer development."""	autonomy;carcinogenesis;cell (microprocessor);cell differentiation process;cell proliferation;chromosomes;interaction;link building;mathematical structure;mathematics;matrix analysis;negative feedback;neoplasms;neurofeedback;paroxysmal reciprocal tachycardia;personality character;phylogenetics;positive feedback;reln wt allele;the matrix;x-ray intensifying screens;biology (field);cell growth;diethyltoluamide	Garri Davydyan	2015	EURASIP journal on bioinformatics & systems biology	10.1186/s13637-015-0030-9	biology;text mining;medical research;computer science;bioinformatics;engineering;artificial intelligence;biological engineering;systems biology	Comp.	5.085192738553674	-62.25474250981346	37100
2c4ef91de655ecf3d2499e4484561d4d8e135be6	pharmacophore-driven identification of pparγ agonists from natural sources	drug discovery;pparγ agonist;natural product;pharmacophore model;virtual screening;biological activity;natural compounds;folk medicine	In a search for more effective and safe anti-diabetic compounds, we developed a pharmacophore model based on partial agonists of PPARγ. The model was used for the virtual screening of the Chinese Natural Product Database (CNPD), a library of plant-derived natural products primarily used in folk medicine. From the resulting hits, we selected methyl oleanonate, a compound found, among others, in Pistacia lentiscus var. Chia oleoresin (Chios mastic gum). The acid of methyl oleanonate, oleanonic acid, was identified as a PPARγ agonist through bioassay-guided chromatographic fractionations of Chios mastic gum fractions, whereas some other sub-fractions exhibited also biological activity towards PPARγ. The results from the present work are two-fold: on the one hand we demonstrate that the pharmacophore model we developed is able to select novel ligand scaffolds that act as PPARγ agonists; while at the same time it manifests that natural products are highly relevant for use in virtual screening-based drug discovery.		Rasmus K. Petersen;Kathrine B. Christensen;Andreana N. Assimopoulou;Xavier Fretté;Vassilios P. Papageorgiou;Karsten Kristiansen;Irene Kouskoumvekaki	2011	Journal of computer-aided molecular design	10.1007/s10822-010-9398-5	pharmacology;chemistry;virtual screening;bioinformatics;biological activity;combinatorial chemistry;drug discovery	Comp.	9.532049434084799	-60.974033018503754	37155
1ac9487a40c1fcb2878a55d693d393e8df1e0fe8	evaluating gene expression dynamics using pairwise rna fish data	saccharomyces cerevisiae;maximum likelihood;rna messenger;saccharomyces cerevisiae proteins;prior knowledge;dynamic program;gene expression;cluster analysis;single cell;gene expression regulation fungal;principal component analysis;algorithms;cell cycle;parameter estimation;in situ hybridization fluorescence;computational biology;wild type;computer simulation;fluorescent in situ hybridization;gene expression profiling;global gene expression;rna fungal	"""Recently, a novel approach has been developed to study gene expression in single cells with high time resolution using RNA Fluorescent In Situ Hybridization (FISH). The technique allows individual mRNAs to be counted with high accuracy in wild-type cells, but requires cells to be fixed; thus, each cell provides only a """"snapshot"""" of gene expression. Here we show how and when RNA FISH data on pairs of genes can be used to reconstruct real-time dynamics from a collection of such snapshots. Using maximum-likelihood parameter estimation on synthetically generated, noisy FISH data, we show that dynamical programs of gene expression, such as cycles (e.g., the cell cycle) or switches between discrete states, can be accurately reconstructed. In the limit that mRNAs are produced in short-lived bursts, binary thresholding of the FISH data provides a robust way of reconstructing dynamics. In this regime, prior knowledge of the type of dynamics--cycle versus switch--is generally required and additional constraints, e.g., from triplet FISH measurements, may also be needed to fully constrain all parameters. As a demonstration, we apply the thresholding method to RNA FISH data obtained from single, unsynchronized cells of Saccharomyces cerevisiae. Our results support the existence of metabolic cycles and provide an estimate of global gene-expression noise. The approach to FISH data presented here can be applied in general to reconstruct dynamics from snapshots of pairs of correlated quantities including, for example, protein concentrations obtained from immunofluorescence assays."""	cellular phone;dynamical system;estimation theory;gene expression profiling;immunofluorescence assay;in situ hybridization;metabolic process, cellular;network switch;nucleic acid hybridization;population parameter;rna;real-time clock;snapshot (computer storage);switch device component;thresholding (image processing);triplet state	Matthieu Wyart;David Botstein;Ned S. Wingreen	2010		10.1371/journal.pcbi.1000979	computer simulation;biology;molecular biology;gene expression;bioinformatics;cell cycle;maximum likelihood;gene expression profiling;cluster analysis;estimation theory;genetics;wild type;principal component analysis	Comp.	4.637980331126928	-59.34006631557477	37197
f7d222319830fbd8d06330377209c01626099bd0	analysis of clinical prognostic variables for chronic lymphocytic leukemia decision-making problems	autoimmune disease development;machine learning;chemotherapy treatment;chronic lymphocytic leukemia	INTRODUCTION Chronic Lymphocytic Leukemia (CLL) is a disease with highly heterogeneous clinical course. A key goal is the prediction of patients with high risk of disease progression, which could benefit from an earlier or more intense treatment. In this work we introduce a simple methodology based on machine learning methods to help physicians in their decision making in different problems related to CLL.   MATERIAL AND METHODS Clinical data belongs to a retrospective study of a cohort of 265 Caucasians who were diagnosed with CLL between 1997 and 2007 in Hospital Cabueñes (Asturias, Spain). Different machine learning methods were applied to find the shortest list of most discriminatory prognostic variables to predict the need of Chemotherapy Treatment and the development of an Autoimmune Disease.   RESULTS Autoimmune disease occurrence was predicted with very high accuracy (>90%). Autoimmune disease development is currently an unpredictable severe complication of CLL. Chemotherapy Treatment has been predicted with a lower accuracy (80%). Risk analysis showed that the number of false positives and false negatives are well balanced.   CONCLUSIONS Our study highlights the importance of prognostic variables associated with the characteristics of platelets, reticulocytes and natural killers, which are the main targets of the autoimmune haemolytic anemia and immune thrombocytopenia for autoimmune disease development, and also, the relevance of some clinical variables related with the immune characteristics of CLL patients that are not taking into account by current prognostic markers for predicting the need of chemotherapy. Because of its simplicity, this methodology could be implemented in spreadsheets.	anemia;autoimmune diseases;autoimmune reaction;chemotherapy;chronic lymphocytic leukemia;color gradient;decision making;disease progression;eighty;genetic heterogeneity;high risk acute leukemia;machine learning;paget's disease, mammary;patients;platelet count measurement;prognostic variable;relevance;short;spreadsheet;thrombocytopenia	Enrique J. deAndrés-Galiana;Juan Luis Fernández Martínez;Oscar Luaces;Juan J. del Coz;Leticia Huergo-Zapico;Andrea Acebes-Huerta;Segundo González;Ana P. González-Rodríguez	2016	Journal of biomedical informatics	10.1016/j.jbi.2016.02.017	medicine;pathology;computer science;machine learning;immunology;surgery	ML	6.9891026014003215	-75.93880444979372	37207
8a47540e2b277dfa76cd95ecdb35cea5fe4ac079	drug target identification in sphingolipid metabolism by computational systems biology tools: metabolic control analysis and metabolic pathway analysis	ceramide;cancer;metabolic network;drug targeting;systems biology;enzyme;metabolic control analysis;drug design;cancer therapy;system biology;sphingolipid metabolism;computational systems biology;metabolic pathway;metabolic pathway analysis;long chain	Sphingolipids regulate cellular processes that are critically important in cell's fate and function in cancer development and progression. This fact underlies the basics of the novel cancer therapy approach. The pharmacological manipulation of the sphingolipid metabolism in cancer therapeutics necessitates the detailed understanding of the pathway. Two computational systems biology tools are used to identify potential drug target enzymes among sphingolipid pathway that can be further utilized in drug design studies for cancer therapy. The enzymes in sphingolipid pathway were ranked according to their roles in controlling the metabolic network by metabolic control analysis. The physiologically connected reactions, i.e. biologically significant and functional modules of network, were identified by metabolic pathway analysis. The final set of candidate drug target enzymes are selected such that their manipulation leads to ceramide accumulation and long chain base phosphates depletion. The mathematical tools' efficiency for drug target identification performed in this study is validated by clinically available drugs.	20-methylcholanthrene;3-mercaptopropionic acid;3-hydroxy-3-methylglutaryl-coenzyme a;acetyl-coa c-acyltransferase;activation action;acyltransferase;brain diseases, metabolic;cdp-diacylglycerol-inositol 3-phosphatidyltransferase;ceramides;coenzymes;color gradient;depletion region;drug delivery systems;drug design;drug discovery;functional derivative;gpr17 protein, human;gene regulatory network;general-purpose input/output;information;inhibition;ligase;mathematics;metabolic control analysis;micro channel architecture;neoplasms;pathway analysis;pharmacology;rose cluster 4;rose cluster 5;rose cluster 6;sphingolipids;systems biology;transferase;tree accumulation;acyl-coa dehydrogenase;cancer therapy;cellular targeting;ceramide catabolic process;inorganic phosphate;sphingolipid metabolic process	Fatma Betül Kavun Özbayraktar;Kutlu Ö. Ülgen	2010	Journal of biomedical informatics	10.1016/j.jbi.2010.03.006	metabolic control analysis;enzyme;metabolic pathway;targeted drug delivery;bioinformatics;systems biology;drug design;metabolic network;cancer	Comp.	8.083931215396833	-61.93070674394017	37272
05b19ba1ab5c25cdbfb0d436779293d98bc58b84	multi-assay-based structure-activity relationship models: improving structure-activity relationship models by incorporating activity information from related targets	classifier ensemble;protein family;drug discovery;receiver operator characteristic;semi supervised learning;protein targeting;structure activity relationship;machine learning;multi task learning	Structure-activity relationship (SAR) models are used to inform and to guide the iterative optimization of chemical leads, and they play a fundamental role in modern drug discovery. In this paper, we present a new class of methods for building SAR models, referred to as multi-assay based, that utilize activity information from different targets. These methods first identify a set of targets that are related to the target under consideration, and then they employ various machine learning techniques that utilize activity information from these targets in order to build the desired SAR model. We developed different methods for identifying the set of related targets, which take into account the primary sequence of the targets or the structure of their ligands, and we also developed different machine learning techniques that were derived by using principles of semi-supervised learning, multi-task learning, and classifier ensembles. The comprehensive evaluation of these methods shows that they lead to considerable improvements over the standard SAR models that are based only on the ligands of the target under consideration. On a set of 117 protein targets, obtained from PubChem, these multi-assay-based methods achieve a receiver-operating characteristic score that is, on the average, 7.0 -7.2% higher than that achieved by the standard SAR models. Moreover, on a set of targets belonging to six protein families, the multi-assay-based methods outperform chemogenomics-based approaches by 4.33%.	chemogenomics;computer multitasking;drug discovery;iterative method;ligands;machine learning;mathematical optimization;multi-task learning;naive bayes classifier;numerous;protein family;pubchem;receiver operating characteristic;semi-supervised learning;semiconductor industry;supervised learning	Xia Ning;Huzefa Rangwala;George Karypis	2009	Journal of chemical information and modeling	10.1021/ci900182q	semi-supervised learning;multi-task learning;structure–activity relationship;chemistry;computer science;machine learning;pattern recognition;data mining;protein family;receiver operating characteristic;drug discovery;protein targeting	ML	9.633554008388993	-52.40009739251527	37301
0e2734d6c3277c61409c380eba9586c75f70de8a	separate encoding of model-based and model-free valuations in the human brain	systems;brain;judgment;vmpfc;uncertainty;reinforcement learning;bayesian inference;frames;bayes theorem;striatum;biases;rewards;prefrontal cortex;subjective value;image interpretation;brain mapping;concurrent systems;anterior cingulate cortex;dual systems;magnetic resonance imaging;humans;computer assisted;globus pallidus;human brain;orbitofrontal cortex;inference;problem solving	Behavioral studies have long shown that humans solve problems in two ways, one intuitive and fast (System 1, model-free), and the other reflective and slow (System 2, model-based). The neurobiological basis of dual process problem solving remains unknown due to challenges of separating activation in concurrent systems. We present a novel neuroeconomic task that predicts distinct subjective valuation and updating signals corresponding to these two systems. We found two concurrent value signals in human prefrontal cortex: a System 1 model-free reinforcement signal and a System 2 model-based Bayesian signal. We also found a System 1 updating signal in striatal areas and a System 2 updating signal in lateral prefrontal cortex. Further, signals in prefrontal cortex preceded choices that are optimal according to either updating principle, while signals in anterior cingulate cortex and globus pallidus preceded deviations from optimal choice for reinforcement learning. These deviations tended to occur when uncertainty regarding optimal values was highest, suggesting that disagreement between dual systems is mediated by uncertainty rather than conflict, confirming recent theoretical proposals.	choice behavior;cingulate cortex;concurrency (computer science);dual;globus pallidus;lateral thinking;prefrontal cortex;problem solving (mental process);reinforcement learning;value (ethics)	Ulrik R. Beierholm;Cedric Anen;Steven Quartz;Peter Bossaerts	2011	NeuroImage	10.1016/j.neuroimage.2011.06.071	psychology;cognitive psychology;judgment;developmental psychology;uncertainty;magnetic resonance imaging;bias;system;bayes' theorem;brain mapping;bayesian inference;social psychology;reinforcement learning;statistics	AI	14.22165787163315	-74.83556011578024	37310
abc970c91161b3ffc627c82c177b040ebbc300e5	impairment of energy metabolism in cardiomyocytes caused by 5-fu catabolites can be compensated by administration of amino acids	enzymes cancer cardiology cellular biophysics drugs;side effect treatment cardiomyocyte 5 fluorouracil catabolite amino acid administration 5 fluorouracil related toxicity cancer treatment dihydropyrimidine dehydrogenase dpyd deficiency dpyd activity fluoroacetate tca cycle enzyme mitochondrial energy metabolism 5 fluorouracil related cardiac side effect aconitase inhibition mitochondrial model atp production citrate accumulation valine uptake arginine uptake proline uptake glutamate uptake cardiac adverse effect biomarker identification;production cancer amino acids mathematical model medical treatment yttrium	Identification of patients with increased risk of 5-fluorouracil (5-FU)-related toxicity is an important challenge for cancer treatment. Research often focus on dihydropyrimidine dehydrogenase (DPYD) deficiency in this context. However, patients with normal DPYD activity may also develop life-threatening 5-FU adverse effects. DPYD initiates the catabolic route of 5-FU generating metabolites such as fluoroacetate (FAC). The catabolite FAC is known to inhibit the TCA cycle enzyme aconitase, which is supposed to impair mitochondrial energy metabolism. Therefore, we aim for a systems understanding of the association of 5-FU-related cardiac side effects with aconitase inhibition caused by FAC. Using a mitochondrial model of cardiomyocytes we found strong depletion of ATP production and citrate accumulation as main effects of aconitase inhibition. Shadow price analysis revealed that the uptakes of valine, arginine, proline and glutamate are most effective in compensating the impairment of energy metabolism. Our findings suggest that 5-FU catabolism contributes to the occurrence of cardiac adverse effects and are the basis for further biomarker identifications and development of side effect treatment.	aconitate hydratase;adenosine triphosphate;advanced telecommunications computing architecture;adverse reaction to drug;amino acids;angular defect;arginine;biological markers;citric acid cycle;cyclic amp receptor protein;dpyd gene;depletion region;energy metabolism;fluoroacetates;fluorouracil;fly-by-wire;glutamic acid;hla-g gene;myocytes, cardiac;neoplasms;patients;proline;shadow price;tree accumulation;uptake;valine;catabolites;sodium citrate	Julia Lischke;Christine Lang;Oliver Sawodny;Ronny Feuer	2015	2015 37th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)	10.1109/EMBC.2015.7319603	pharmacology;biology;biochemistry	SE	8.22623423327887	-69.46918586435858	37441
7e60f8c2b30bb9d22902dd4768058cd23c6059c4	golorize: a cytoscape plug-in for network visualization with gene ontology-based layout and coloring	network visualization;graph layout;gene ontology	UNLABELLED We have implemented a graph layout algorithm that exposes Gene Ontology (GO) class structure on the network nodes. It can be used in conjunction with BiNGO plug-in to Cytoscape, which finds the GO categories over-represented in a given network. Our plug-in, named GOlorize, first highlights the class members with category-specific color-coding and then constructs an enhanced visualization of the network using a class-directed layout algorithm.   AVAILABILITY http://www.cytoscape.org/plugins2.php.   SUPPLEMENTARY INFORMATION Installation instructions and tutorial at http://www.cytoscape.org/plugins/GOlorize/GOlorizeUserGuide.pdf.	algorithm;categories;color-coding;cytoscape;force-directed graph drawing;gene ontology;graph coloring;imagery;meconium plug syndrome;name;plug (physical object);plug-in (computing)	Olivier Garcia;Cosmin Saveanu;Melissa S. Cline;Micheline Fromont-Racine;Alain Jacquier;Benno Schwikowski;Tero Aittokallio	2007	Bioinformatics	10.1093/bioinformatics/btl605	computer science;bioinformatics;database;graph drawing;world wide web	Comp.	-3.9435173692002228	-58.59048023246385	37512
32c03c287580a223fc56998e1436c8ccfa065f68	computer vision for systems biology	overview computer vision systems biology;reviews computer vision medical image processing;computer vision;medical image processing;system biology;computer vision systems biology biological information theory genomics bioinformatics cells biology organisms proteins genetics biological processes;reviews	This short paper introduces the scope of our special emphasis session on computer vision for systems biology. It attempts to define the needs for computer vision based readouts in systems biological research and to shed light on some of the challenges computer vision researchers should tackle for the systems biology community. Finally, it will give a short overview of the invited and contributed papers that will be presented in this session	computer vision;systems biology	Gaudenz Danuser	2006	3rd IEEE International Symposium on Biomedical Imaging: Nano to Macro, 2006.	10.1109/ISBI.2006.1624897	computational biology;computer vision;computer science;bioinformatics;physiology;systems biology;vision science	Vision	2.7205612282090237	-67.59989481476747	37587
1e6b6522a5a4612427e6fe9a55f25e6c48769c83	integrative analysis of multi-modal correlated imaging-genomics data in glioblastoma	genomics;tumours bioinformatics biomedical imaging data analysis genomics;integrative genomic analysis;imaging genomics;tumours;biomedical imaging;specificity bayesian analysis imaging genomics integrative genomic analysis lasso penalization multiple outcomes sensitivity;lasso penalization;sensitivity;data analysis;multiple outcomes;specificity;imaging bioinformatics genomics biological system modeling cancer tumors data models;patients imaging outcomes integrative analysis multimodal correlated imaging genomics data multiple correlated imaging outcomes two stage hierarchical model relevant genes identification cancer genome atlas glioblastoma multiforme dataset microrna regulated genes;bayesian analysis;bioinformatics	We propose a method to integrate high-dimensional genomics datasets across multiple platforms with multiple correlated imaging outcomes. This framework uses a hierarchical model to integrate biological relationships across platforms to identify genes that associate with correlated outcomes. Our two-stage hierarchical model uses the information shared across the platforms and increases the predictive power to identify the relevant genes. We assess the performance of our proposed method through simulations and apply to data obtained from the Cancer Genome Atlas Glioblastoma Multiforme dataset. Our proposed method discovers multiple copy number and microRNA regulated genes that are related to patients' imaging outcomes in glioblastoma.	hierarchical database model;modal logic;simulation	Rolando J. Olivares;Arvind U. K. Rao;Ganesh Rao;Jeffrey S. Morris;Veerabhadran Baladandayuthapani	2013	2013 IEEE International Workshop on Genomic Signal Processing and Statistics	10.1109/GENSIPS.2013.6735914	biology;genomics;medicine;sensitivity;bayesian probability;computer science;bioinformatics;data mining;mathematics;data analysis;genetics	ML	6.695668843210952	-54.7247409640383	37596
bfaad171de5b688d0e3679370c734efc6cb6d8c8	evolutionary pareto-optimization of stably folding peptides	evolution molecular;610 medizin;peptides;amino acid sequence;neurofilament proteins;proof of concept;computational biology bioinformatics;peptide fragments;nuclear magnetic resonance spectroscopy;structural protein;circular dichroism;protein structure tertiary;ddc 610;sequence homology amino acid;algorithms;protein folding;molecular sequence data;evolutionary algorithm;combinatorial libraries;computer appl in life sciences;wild type;3d structure;basic research;pareto optimality;microarrays;bioinformatics	As a rule, peptides are more flexible and unstructured than proteins with their substantial stabilizing hydrophobic cores. Nevertheless, a few stably folding peptides have been discovered. This raises the question whether there may be more such peptides that are unknown as yet. These molecules could be helpful in basic research and medicine. As a method to explore the space of conformationally stable peptides, we have developed an evolutionary algorithm that allows optimization of sequences with respect to several criteria simultaneously, for instance stability, accessibility of arbitrary parts of the peptide, etc. In a proof-of-concept experiment we have perturbed the sequence of the peptide Villin Headpiece, known to be stable in vitro. Starting from the perturbed sequence we applied our algorithm to optimize peptide stability and accessibility of a loop. Unexpectedly, two clusters of sequences were generated in this way that, according to our criteria, should form structures with higher stability than the wild-type. The structures in one of the clusters possess a fold that markedly differs from the native fold of Villin Headpiece. One of the mutants predicted to be stable was selected for synthesis, its molecular 3D-structure was characterized by nuclear magnetic resonance spectroscopy, and its stability was measured by circular dichroism. Predicted structure and stability were in good agreement with experiment. Eight other sequences and structures, including five with a non-native fold are provided as bona fide predictions. The results suggest that much more conformationally stable peptides may exist than are known so far, and that small fold classes could comprise well-separated sub-folds.	accessibility;circular dichroism;class;evolutionary algorithm;fold (higher-order function);magnetic resonance spectroscopy;mathematical optimization;pareto efficiency;smilax bona-nox;spectroscopy, nuclear magnetic resonance;vil1 gene;mutant	Wolfram Gronwald;Tim Hohm;Daniel Hoffmann	2007	BMC Bioinformatics	10.1186/1471-2105-9-109	circular dichroism;protein folding;nuclear magnetic resonance spectroscopy;biology;molecular biology;dna microarray;computer science;bioinformatics;evolutionary algorithm;peptide sequence;proof of concept;genetics;wild type	Comp.	6.878281003017977	-61.46328852883519	37615
f08418f698b35ddbde2f4bc2318d0d6c66ee77bd	locating the initial stages of speech–sound processing in human temporal cortex	fmri;auditory pathway;functional mri;auditory system;speech;internal structure;auditory processing;cortex;right handed;auditory cortex;temporal cortex;hearing;hierarchical model;superior temporal sulcus;auditory	It is commonly assumed that, in the cochlea and the brainstem, the auditory system processes speech sounds without differentiating them from any other sounds. At some stage, however, it must treat speech sounds and nonspeech sounds differently, since we perceive them as different. The purpose of this study was to delimit the first location in the auditory pathway that makes this distinction using functional MRI, by identifying regions that are differentially sensitive to the internal structure of speech sounds as opposed to closely matched control sounds. We analyzed data from nine right-handed volunteers who were scanned while listening to natural and synthetic vowels, or to nonspeech stimuli matched to the vowel sounds in terms of their long-term energy and both their spectral and temporal profiles. The vowels produced more activation than nonspeech sounds in a bilateral region of the superior temporal sulcus, lateral and inferior to regions of auditory cortex that were activated by both vowels and nonspeech stimuli. The results suggest that the perception of vowel sounds is compatible with a hierarchical model of primate auditory processing in which early cortical stages of processing respond indiscriminately to speech and nonspeech sounds, and only higher regions, beyond anatomically defined auditory cortex, show selectivity for speech sounds.	acoustic cryptanalysis;assumed;audio signal processing;auditory perception;auditory area;auditory pathway structure;auditory system;bilateral filter;brain stem;cochlear structure;gene regulatory network;groove;hierarchical database model;lateral thinking;primates;scanning;selectivity (electronic);structure of superior temporal sulcus;synthetic intelligence;temporal lobe	Stefan Uppenkamp;Ingrid S. Johnsrude;Dennis Norris;William D. Marslen-Wilson;Roy D. Patterson	2006	NeuroImage	10.1016/j.neuroimage.2006.01.004	psychology;speech;cortex;communication;audiology;hierarchical database model	ML	18.28892164648966	-76.74568524297597	37632
a9af2bd8868913d177b33e2cabb35f5dd0e7c57e	altered working memory process in the manganese-exposed brain	healthy control;welder;functional mri;memory testing;memory deficit;verbal working memory;manganese mn;functional magnetic resonance images;functional magnetic resonance imaging fmri;working memory;brain activation;cognitive function	Chronic manganese (Mn) exposure often leads to impairments in fine motor and cognitive functions, particularly memory. However, the neural correlates of Mn-induced alterations in memory remain unclear. In the present study, we performed functional MRI (fMRI) with 2-back memory tests to assess the neural correlates of Mn-induced memory impairment in response to subclinical dysfunction in the working memory networks in welders exposed to Mn for extended periods of time. Within-group and between-group analyses revealed that brain activity in working memory networks was increased in welders with chronic Mn exposure during the 2-back verbal working memory task compared to healthy control individuals. Therefore, our fMRI findings indicate that welders might require more neural resources in working memory networks to compensate for subtle deficits in working memory and altered working memory processes, even if they performed the tasks at the same level as healthy control individuals.	chronic lymphocytic leukemia;cognition disorders;consciousness;electroencephalography;memory disorders;fmri	Yongmin Chang;Jae-Jun Lee;Jee-Hye Seo;Hui-Jin Song;Joo-Hyun Kim;Sung-Jin Bae;Joon-Ho Ahn;Sin-Jae Park;Kyoung Sook Jeong;Young Joo Kwon;Suk Hwan Kim;Yangho Kim	2010	NeuroImage	10.1016/j.neuroimage.2010.07.001	psychology;cognitive psychology;neuroscience;cognition;developmental psychology;working memory;methods used to study memory	ML	17.55112863390372	-78.75686106929965	37770
e4d24417a938b23a365bcb403d55eff69af8db15	augmenting sses with structural properties for rapid protein structure comparison	databases;libraries;drugs;biology computing;genomics;protein structure comparison;three dimensions;dissimilar proteins filtering protein structures comparison 3 d structural properties scale algorithm three dimensional structure protein comparison 3d structural properties similarity score sequence alignment problem known protein structures library;protein comparison;molecular configurations;filters;drives;3d structural properties;similarity score;scale algorithm;known protein structures library;protein structure;biology computing proteins molecular biophysics molecular configurations;proteins;3 d structural properties;secondary structure;molecular biophysics;dissimilar proteins filtering;sequence alignment;computer science;three dimensional structure;sequence alignment problem;protein structures comparison;proteins bioinformatics libraries databases computer science genomics drives costs filters drugs;3d structure;structural properties;bioinformatics	Comparing protein structures in three dimensions is a computationally expensive process that makes a full scan of a protein against a library of known protein structures impractical. To reduce the cost, we can use an approximation of the three dimensional structure that allows protein comparison to be performed quickly to filter away dissimilar proteins. In this paper we present a new algorithm, called SCALE, for protein structure comparison. In SCALE, a protein is represented as a sequence of secondary structure elements (SSEs) augmented with 3D structural properties such as the distances and angles between the SSEs. As such, the comparison between two proteins is reduced to a sequence alignment problem between their corresponding sequences of SSEs. The 3-D structural properties of the proteins contribute to the similarity score between the two sequences. We have implemented SCALE, and compared its performance against existing schemes. Our performance study shows that SCALE outperforms existing methods in terms of both efficiency and effectiveness (measured in terms of precision and recall).		Chern-Hooi Chionh;Zhiyong Huang;Kian-Lee Tan;Zhen Yao	2003		10.1109/BIBE.2003.1188972	biology;three-dimensional space;biochemistry;protein structure;genomics;computer science;bioinformatics;sequence alignment;protein secondary structure;molecular biophysics	Comp.	-2.326970883922243	-52.5641441010147	37774
a2c3a43ef644febdf70d8837d8aef12401d3b934	a supervised extreme learning committee for food recognition	extreme learning machines;software;food recognition;1707;signal processing;structural svm	Food recognition is an emerging topic in computer vision. The problem is being addressed especially in health-oriented systems where it is used as a support for food diary applications. The goal is to improve current food diaries, where the users have to manually insert their daily food intake, with an automatic recognition of the food type, quantity and consequent calories intake estimation. In addition to the classical recognition challenges, the food recognition problem is characterized by the absence of a rigid structure of the food and by large intra-class variations. To tackle such challenges, a food recognition system based on a committee classification is proposed. The aim is to provide a system capable of automatically choosing the optimal features for food recognition out of the existing plethora of available ones (e.g., color, texture, etc.). Following this idea, each committee member, i.e., an Extreme Learning Machine, is trained to specialize on a single feature type. Then, a Structural Support Vector Machine is exploited to produce the final ranking of possible matches by filtering out the irrelevant features and thus merging only the relevant ones. Experimental results show that the proposed system outperforms state-of-the-art works on four publicly available benchmark datasets. © 2016 Elsevier Inc. All rights reserved.	benchmark (computing);computer vision;online diary;relevance;supervised learning;support vector machine	Niki Martinel;Claudio Piciarelli;Christian Micheloni	2016	Computer Vision and Image Understanding	10.1016/j.cviu.2016.01.012	computer vision;feature;computer science;artificial intelligence;machine learning;signal processing;data mining	AI	24.55169297345208	-57.64933626033587	37776
1bdd7cc561c93613f894372402a54e802348f5cf	random forest based ensemble classifiers for predicting healthcare-associated infections in intensive care units		Surveillance and prevention of infections acquired in the hospital environment is an important challenge in the current health systems given the great impact of these kind of infections on patient mortality as well as on sanitary costs. Data analysis can contribute to make easier these tasks by means of identification of risk factors and prediction of infection acquisition. This work is focused on the study of infections acquired in intensive care units by means of data mining models. In this context we have to deal with the problem of building reliable classifiers from imbalanced datasets. This is addressed with an ensemble based approach. The aim of the proposal is to overcome some drawbacks presented by other usual strategies.		María N. Moreno García;Juan Carlos Ballesteros Herráez;Mercedes Sánchez Barba;Fernando Sánchez Hernández	2016		10.1007/978-3-319-40162-1_33	machine learning;pattern recognition;data mining	NLP	6.197035168285884	-77.19019278247357	37825
11af3e9c7165bf06a4d84447a30650ebf6e0d33f	generation of the exact distribution and simulation of matched nucleotide sequences on a phylogenetic tree	multinomial distribution;approximation method;nucleotides;nucleotide sequence;phylogenetic tree;molecular evolution;markov process;computer application;exact distribution;monte carlo simulation;program development;embedded markov chain	Nucleotide sequences are often generated by Monte Carlo simulations to address complex evolutionary or analytic questions but the simulations are rarely described in sufficient detail to allow the research to be replicated. Here we briefly review the Markov processes of substitution in a pair of matching (homologous) nucleotide sequences and then extend it to k matching nucleotide sequences. We describe calculation of the joint distribution of nucleotides of two matching sequences. Based on this distribution, we give a method for simulation of the divergence matrix for n sites using the multinomial distribution. This is then extended to the joint distribution for k nucleotide sequences and the corresponding 4k divergence array, generalizing Felsenstein (Journal of Molecular Evolution, 17, 368–376, 1981), who considered stationary, homogeneous and reversible processes on trees. We give a second method to generate matched sequences that begins with a random ancestral sequence and applies a continuous Markov process to each nucleotide site as in Rambaut and Grassly (Computer Applications in the Biosciences, 13, 235–238, 1997); further, we relate this to an equivalent approach based on an embedded Markov chain. Finally, we describe an approximate method that was recently implemented in a program developed by Jermiin et al. (Applied Bioinformatics, 2, 159–163, 2003). The three methods presented here cater for different computational and mathematical limitations and are shown in an example to produce results close to those expected on theoretical grounds. All methods are implemented using functions in the S-plus or R languages.	phylogenetic tree;phylogenetics;simulation	Faisal Ababneh;Lars S. Jermiin;John Robinson	2006	J. Math. Model. Algorithms	10.1007/s10852-005-9017-y	mathematical optimization;combinatorics;nucleotide;phylogenetic tree;markov chain monte carlo;molecular evolution;nucleic acid sequence;bioinformatics;theoretical computer science;mathematics;markov process;multinomial distribution;statistics;monte carlo method	Theory	2.105707988658251	-54.364163269431884	37828
8c125b843d71abf4718305cfbff4016407b99316	mathematical modeling of biological systems	computational models;mathematical biology;systems biology	Mathematical and computational models are increasingly used to help interpret biomedical data produced by high-throughput genomics and proteomics projects. The application of advanced computer models enabling the simulation of complex biological processes generates hypotheses and suggests experiments. Appropriately interfaced with biomedical databases, models are necessary for rapid access to, and sharing of knowledge through data mining and knowledge discovery approaches.	biological system;computational model;computer simulation;data mining and knowledge discovery;database;experiment;high-throughput computing;mathematical model;mathematics;norm (social);proteomics;throughput	Santo Motta;Francesco Pappalardo	2013	Briefings in bioinformatics	10.1093/bib/bbs061	bioinformatics;biology	Comp.	4.2481237121362	-67.14736677713692	37899
107554275e0f330e3a047993e1c17c51ff0c30a7	exploring risk factors and predicting updrs score based on parkinson's speech signals		The unified Parkinson's disease rating scale (UPDRS) is the most widely employed scale for tracking Parkinson's disease (PD) symptom progression. However, conventional way to achieve UPDRS, mainly based on the physical examinations of clinic patients performed by the trained medical staffs, involves the disadvantages of inconvenience and high medical expense. Hence, in this study, we try to explore some risk factors and accurately predict the UPDRS for PD, using the speech signals of PD patients published on UCI machine-learning archive. More specifically, inspired by the idea of ensemble learning, we firstly construct a framework of ensemble feature selection (EFS) to select a suitable subset of features among numerous speech signals. Subsequently, a personalized predictive model, trained by adopting information from similar patients, is developed to be customized for an individual PD patient. Finally, we employ the personalized predictive model to predict UPDRS score combined with various classical regression algorithms. Compared to conventional models, our study has a potential to capture more relevant risk factors and produces more accurate UPDRS score for individual patient. Experimental results on real-world dataset from UCI machine-learning archive show that our personalized predictive model gets a promising performance.	algorithm;archive;color gradient;deep learning;encrypting file system;ensemble learning;feature selection;machine learning;personalization;rating scale	Jianxin Zhang;Weifeng Xu;Qiang Zhang;Bo Jin;Xiaopeng Wei	2017	2017 IEEE 19th International Conference on e-Health Networking, Applications and Services (Healthcom)	10.1109/HealthCom.2017.8210785	data mining;ensemble learning;cluster analysis;feature extraction;computer science;rating scale;feature selection;artificial intelligence;pattern recognition	ML	5.194690819681157	-76.51974383545883	37937
4c959329ffdce1c4b04a148686f38efabda1ce29	meg source reconstruction constrained by diffusion mri based whole brain dynamical model	brain modeling signal to noise ratio joints delay effects bayes methods indexes image reconstruction;biodiffusion;bayes methods;brain models;magnetoencephalography;magnetic resonance imaging meg source reconstruction method diffusion mri whole brain dynamical model temporal constraint multivariate autoregressive model mar model parameter mar model fitting source space effective connectivity signal to noise ratio nondynamical sparse bayesian method magnetoencephalography;autoregressive processes;image reconstruction;medical image processing;spatiotemporal phenomena;temporal constraint diffusion mri effective connectivity meg source reconstruction;biomedical mri;spatiotemporal phenomena autoregressive processes bayes methods biodiffusion biomedical mri brain models image reconstruction magnetoencephalography medical image processing	Previous studies have shown that MEG source reconstruction is improved by temporal constraints from local current source dynamics. Extending these constraints, we have developed a source reconstruction method that is spatiotemporally constrained by a whole brain dynamical model. The source dynamics are represented by a multivariate autoregressive (MAR) model whose matrix entries are constrained by connectivity estimates based on diffusion MRI. The MAR model parameters are jointly estimated with the source amplitude to infer source-space effective connectivity. Through simulation at low signal-to-noise ratio, we confirmed that the proposed method suppresses spurious sources and, unlike the non-dynamical sparse Bayesian method, can recover a low amplitude source. Furthermore, effective connectivity estimated by the proposed joint approach was more accurate than that obtained from the two stage approach, in which the current sources are first reconstructed by the non-dynamical method, followed by MAR model fitting to the resulting sources.	autoregressive model;current source;curve fitting;dynamical system;magnetoencephalography;signal-to-noise ratio;simulation;sparse matrix	Makoto Fukushima;Okito Yamashita;Thomas R. Knösche;Masa-aki Sato	2013	2013 IEEE 10th International Symposium on Biomedical Imaging	10.1109/ISBI.2013.6556646	iterative reconstruction;computer vision;speech recognition;radiology;medicine;computer science;machine learning;magnetoencephalography	Vision	24.088142829260267	-76.28629356179955	37946
4a702a356442b5d6fd04b46ccc85d3701154bf99	microarray-in-a-tube system in the function of detection human papillomavirus genotypes	dna;disease diagnosis microarray in a tube system hpv polymerase chain reaction pcr microarray technique high throughput detection system human papillomavirus genotype detection human preparation arrays hybridization on chip fluorescence detection general gp5 gp6 premier signal noise ratio snr;high throughput detection;fluorescence;cancer;tube systems;human papillomavirus;fluorescence detection;会议论文;materials;probes;signal noise ratio microarray in a tube system human papillomavirus polymerase chain reaction;signal noise ratio;patient diagnosis diseases fluorescence genetics genomics gynaecology lab on a chip;disease diagnosis;diseases;signal to noise ratio;fluorescence signal to noise ratio probes dna cancer diseases materials;on chips	Patients infected human papillomavirus (HPV) is increasing all over the world, in particular the community of woman. Microarray-in-a-tube system is a novel method of integrating polymerase chain reaction (PCR) with the microarray technique and a simple and high-throughput detection system. In this work, the microarray-in-a-tube system used in the function of detection human papillomavirus genotypes. Detection human papillomavirus genotypes of a microarray-in-a-tube system was composed of the preparation arrays, PCR, hybridization on chip, fluorescence detection, containing general GP5+/GP6+ premier, 30 targets. These results suggest that signal-noise ratio (SNR) of this system was set as SNR ≥ 2.0 at 100 copies. The system was suitable for other disease diagnosis in future.	high-throughput computing;microarray;noise (electronics);signal-to-noise ratio;throughput	Chuanrong Hou;Jingjing Yu;Lingzhi Wu;Dan Mo;Shenglan Zeng;Quanjun Liu	2014	2014 7th International Conference on Biomedical Engineering and Informatics	10.1109/BMEI.2014.7002774	biology;molecular biology;pathology;computer science;bioinformatics;signal-to-noise ratio;genetics	Robotics	2.514526546289783	-64.79229551347441	37955
78651856abcacbdcba06f73d9b0221ea0aebf7d3	computing h/d-exchange speeds of single residues from data of peptic fragments	decision support system;flagellar ontology;inproceedings;data warehouse;combinatorial optimization;data integration;bioinformatics	Determining the hydrogen-deuterium exchange speeds of single residues from data for peptic fragments obtained by FT-ICS MS is currently mainly done by manual interpretation. We provide an automated method based on combinatorial optimization. More precisely, we present an algorithm that enumerates all possible exchange speeds for single residues that explain the observed data of the peptic fragments.	algorithm;combinatorial optimization;hydrogen;mathematical optimization	Ernst Althaus;Stefan Canzar;Mark R. Emmett;Andreas Karrenbauer;Alan G. Marshall;Anke Meyer-Bäse;Huimin Zhang	2008		10.1145/1363686.1363981	decision support system;combinatorial optimization;computer science;bioinformatics;data integration;data warehouse;data mining;database	Comp.	1.26626548515167	-59.93186146316919	38007
e29ee27a176267b7f1bf9e76168d5fb3b73341a0	model-based neural decoding of reaching movements: a maximum likelihood approach	action potentials algorithms arm computer simulation electroencephalography humans likelihood functions models neurological models statistical motor cortex motor neurons movement nerve net reproducibility of results sensitivity and specificity signal processing computer assisted;bioelectric potentials;maximum likelihood;two dimensions;point to point;biomechanics;maximum likelihood decoding;neural plan activity model based neural decoding reaching movements maximum likelihood approach neural signals reconstructed hand trajectories;neurophysiology;bioelectric potentials neurophysiology biomechanics maximum likelihood decoding;reaching movement;maximum likelihood decoding neurons neural prosthesis signal mapping trajectory control systems signal generators brain testing modeling	"""A new paradigm for decoding reaching movements from the signals of an ensemble of individual neurons is presented. This new method not only provides a novel theoretical basis for the task, but also results in a significant decrease in the error of reconstructed hand trajectories. By using a model of movement as a foundation for the decoding system, we show that the number of neurons required for reconstruction of the trajectories of point-to-point reaching movements in two dimensions can be halved. Additionally, using the presented framework, other forms of neural information, specifically neural """"plan"""" activity, can be integrated into the trajectory decoding process. The decoding paradigm presented is tested in simulation using a database of experimentally gathered center-out reaches and corresponding neural data generated from synthetic models."""	database;decoder device component;dimensions;division by two;experiment;greater than;mathematical model;movement;neural decoding;patients;point-to-point protocol;programming paradigm;reaching;simulation;synthetic intelligence	Caleb Kemere;Krishna V. Shenoy;Teresa H. Y. Meng	2004	IEEE Transactions on Biomedical Engineering	10.1109/TBME.2004.826675	two-dimensional space;neural decoding;point-to-point;computer science;artificial intelligence;biomechanics;machine learning;mathematics;maximum likelihood;communication;physiology;neurophysiology;statistics	ML	23.753256879176938	-72.82472343148861	38015
67f21cb004aa38d2e19980b5616b6f9dd9cac9b1	ring closure to form metal chelates in 3d fragment-based de novo design		We describe a method for the design of multicyclic compounds from three-dimensional (3D) molecular fragments. The 3D building blocks are assembled in a controlled fashion, and closable chains of such fragments are identified. Next, the ring-closing conformations of such formally closable chains are identified, and the 3D model of a cyclic or multicyclic molecule is built. Embedding this method in an evolutionary algorithm results in a de novo design tool capable of altering the number and nature of cycles in species such as transition metal compounds with multidentate ligands in terms of, for example, ligand denticity, type and length of bridges, identity of bridgehead terms, and substitution pattern. An application of the method to the design of multidentate nitrogen-based ligands for Fe(II) spin-crossover (SCO) compounds is presented. The best candidates display multidentate skeletons new to the field of Fe(II) SCO yet resembling ligands deployed in other fields of chemistry, demonstrating the capability of the approach to explore structural variation and to suggest unexpected and realistic molecules, including structures with cycles not found in the building blocks.		Marco Foscato;Benjamin J. Houghton;Giovanni Occhipinti;Robert J. Deeth;Vidar R. Jensen	2015	Journal of chemical information and modeling	10.1021/acs.jcim.5b00424	stereochemistry;chemistry;organic chemistry	Comp.	11.670648595474036	-60.909762346030284	38025
c3375b7ce67ae443527dc2632d30caa18d2178cf	a crossmodal crossover: opposite effects of visual and auditory perceptual load on steady-state evoked potentials to irrelevant visual stimuli	distractor interference;frequency tagging;perceptual load;neural oscillations;selective attention	Mechanisms of attention are required to prioritise goal-relevant sensory events under conditions of stimulus competition. According to the perceptual load model of attention, the extent to which task-irrelevant inputs are processed is determined by the relative demands of discriminating the target: the more perceptually demanding the target task, the less unattended stimuli will be processed. Although much evidence supports the perceptual load model for competing stimuli within a single sensory modality, the effects of perceptual load in one modality on distractor processing in another is less clear. Here we used steady-state evoked potentials (SSEPs) to measure neural responses to irrelevant visual checkerboard stimuli while participants performed either a visual or auditory task that varied in perceptual load. Consistent with perceptual load theory, increasing visual task load suppressed SSEPs to the ignored visual checkerboards. In contrast, increasing auditory task load enhanced SSEPs to the ignored visual checkerboards. This enhanced neural response to irrelevant visual stimuli under auditory load suggests that exhausting capacity within one modality selectively compromises inhibitory processes required for filtering stimuli in another.	acoustic evoked brain stem potentials;modality (human–computer interaction);relevance;steady state	Oscar Jacoby;Sarah E. Hall;Jason B. Mattingley	2012	NeuroImage	10.1016/j.neuroimage.2012.03.040	psychology;cognitive psychology;computer vision;neuroscience;attention;communication	ML	15.821860164607395	-76.65290719842602	38027
95a3a491947b6082e8f5deee9f17a37bce6e7a05	binding of proteins to the minor groove of dna: what are the structural and energetic determinants for kinking a basepair step?	protein dna interactions;minor groove binding proteins;molecular dynamics;potential of mean force	The structural and energetic determinants for kinking a basepair step by minor groove-insertion of the protein side chains of PurR, LacI, LEF-1, IHF, Sac7d, and Sso7d, have been calculated by molecular dynamics/potential of mean force simulations. The structural determinants of the kinked structures are: two contiguous furanose rings achieve different conformations, in the region of C3'endo (A-DNA) and C2'endo (B-DNA); the chi torsion angle always takes values characteristic of the C2'endo conformation of B-DNA, independently of sugar puckering; and protein side chain insertion increases slide (from negative to positive values), rise, and roll, and decreases twist. The energetic determinants of DNA kinking are: the conformational transition of the sugar-phosphate backbone is not energetically demanding; the relative importance of the interbase parameters in the free energy penalty is slide, followed by twist and rise, and concluding with shift and roll; and the characteristic increase of roll and decrease of twist, upon side chain insertion, tends to stabilize the process of DNA kinking.	base;bending - changing basic body position;carbamoyl-phosphate synthase i deficiency disease;clinical act of insertion;dna computing;duoxa1 gene;gromacs;groove;herman ring;immobiliser;insertion mutation;interbase;interaction;internet backbone;large;manea gene;minor lymphocyte stimulatory antigens;molecular dynamics;polynomial ring;pseudocoarctation;ring device;simulation;sugar;sugars;torsion (gastropod);vertebral column;cell surface furrow;dna binding;free energy;inorganic phosphate;kilocalorie;lymphoid enhancer-binding factor 1	David Bosch;Mercedes Campillo;Leonardo Pardo	2003	Journal of computational chemistry	10.1002/jcc.10200	crystallography;stereochemistry;molecular dynamics;chemistry;computational chemistry;potential of mean force;physics;quantum mechanics	Comp.	9.4150015602668	-63.24443435014683	38074
c78da42db6d9dacb858042ac8c2ace62312224c3	reconstructing latex source files from generated pdfs - a neural network approach		Deep neural networks (DNN) have been successfully used to solve classification problems for many years. DNN has found variety of applications in recent years beyond classification, including generative tasks. In this paper, we present a neural network architecture suited for generating LaTeX source code which reconstructs a given PDF file. Although a challenging problem to solve, the network performs reasonably well, achieving approximately 70% accuracy rate on validation data.	application programming interface;artificial neural network;autoencoder;convolution;deep learning;experiment;latex;mathematical optimization;network architecture;portable document format;python;tensorflow;test set	Patrice Isabella;Gongzhu Hu	2018	2018 IEEE 16th International Conference on Industrial Informatics (INDIN)	10.1109/INDIN.2018.8472050	probability density function;generative grammar;real-time computing;artificial neural network;machine learning;engineering;architecture;source code;recurrent neural network;convolution;artificial intelligence	Robotics	17.28314700799075	-52.58312159717399	38162
5112772aff8ab7032076ba63da60b6ab8a6b8d34	ecg simulation with improved model of cell action potentials	action potential	An improved model of action potentials (AP) is proposed to increase the accuracy of simulated electrocardiograms (ECGs). ECG simulator is based on a spatial model of a left ventricle, composed of cubic cells. Three distinct APs, modeled with functions proposed by Wohlfard, have been assigned to the cells, forming epicardial, mid, and endocardial layers. Identification of exact parameter values for AP models has been done through optimization of the simulated ECGs. Results have shown that only through an introduction of a minor extension to the AP model, simulator is able to produce realistic ECGs. The same extension also proves essential for achieving a good fit between the measured and modeled APs.	action potential;cubic function;mathematical optimization;simulation	Roman Trobec;Matjaz Depolli;Viktor Avbelj	2009			computer science;action potential	AI	13.135404743718292	-68.07783127376719	38214
0951e6d9fb864e2f981b74e42178b7dbb2235169	genowap: gwas signal prioritization through integrated analysis of genomic functional annotation		MOTIVATION Genome-wide association study (GWAS) has been a great success in the past decade. However, significant challenges still remain in both identifying new risk loci and interpreting results. Bonferroni-corrected significance level is known to be conservative, leading to insufficient statistical power when the effect size is moderate at risk locus. Complex structure of linkage disequilibrium also makes it challenging to separate causal variants from nonfunctional ones in large haplotype blocks. Under such circumstances, a computational approach that may increase signal replication rate and identify potential functional sites among correlated markers is urgently needed.   RESULTS We describe GenoWAP, a GWAS signal prioritization method that integrates genomic functional annotation and GWAS test statistics. The effectiveness of GenoWAP is demonstrated through its applications to Crohn's disease and schizophrenia using the largest studies available, where highly ranked loci show substantially stronger signals in the whole dataset after prioritization based on a subset of samples. At the single nucleotide polymorphism (SNP) level, top ranked SNPs after prioritization have both higher replication rates and consistently stronger enrichment of eQTLs. Within each risk locus, GenoWAP may be able to distinguish functional sites from groups of correlated SNPs.   AVAILABILITY AND IMPLEMENTATION GenoWAP is freely available on the web at http://genocanyon.med.yale.edu/GenoWAP.		Qiongshi Lu;Xinwei Yao;Yiming Hu;Hongyu Zhao	2016	Bioinformatics	10.1093/bioinformatics/btv610	bioinformatics	Comp.	3.456130239385192	-56.145120053586616	38252
6bddf37df0c948904e393ae7573f01bfdc112230	simulations of learning in a cerebellar cortex model using an optimisation method	optimisation method;cerebellar cortex model		computer simulation;mathematical optimization	Bassam Daya;Gilbert A. Chauvet	1998			machine learning;cortex (botany);computer science;artificial intelligence	ML	20.591174993941483	-69.07364975689005	38340
6a06992d0167fd57ce47f4fd5dbe93edeafe956b	executive function, rule selection, and probability judgment	resonance;brain;decision making humans brain biological neural networks resonance joining processes character generation cognition orbital calculations psychology;reasoning about probability;probability;ratio rules;executive function;brain activation patterns;probability judgment;psychology;data mining;subspace constraints;fmri study;brain modeling;adaptation model;intuitive heuristics;character generation;cognition;anterior cingulate;joining processes;rule selection;orbital calculations;humans;brain activation;neurophysiology;art neural nets;probabilistic logic;prefrontal regions;adaptive resonance theory model;amygdala;prefrontal regions rule selection probability judgment fmri study reasoning about probability brain activation patterns ratio rules intuitive heuristics adaptive resonance theory model amygdala;probability art neural nets brain neurophysiology;biological neural networks;adaptive resonance theory;data models	Results of fMRI studies show that on tasks involving reasoning about probabilities, brain activation patterns differ between those who make judgments based on ratio rules and those who make judgments based on intuitive heuristics. These results suggest a three-layer adaptive resonance theory model connecting the amygdala and three executive prefrontal regions (orbital, anterior cingulate, and dorsolateral). A simplified version of the model can reproduce ratio bias data and is now being applied to base rate neglect data.	adaptive resonance theory;base rate;heuristic (computer science);molecular orbital;multitier architecture	Daniel S. Levine	2009	2009 International Joint Conference on Neural Networks	10.1109/IJCNN.2009.5178770	data modeling;cognition;resonance;computer science;artificial intelligence;adaptive resonance theory;machine learning;probability;probabilistic logic;neurophysiology	AI	15.413855024711394	-71.54104650085473	38355
4c37b54a57770c7289b09aa981a14366b398bf64	prediction of clinical risks by analysis of preclinical and clinical adverse events	likelihood ratio;drug risk;bayesian;adverse events;animal human concordance;translational medicine	This study examines the ability of nonclinical adverse event observations to predict human clinical adverse events observed in drug development programs. In addition it examines the relationship between nonclinical and clinical adverse event observations to drug withdrawal and proposes a model to predict drug withdrawal based on these observations. These analyses provide risk assessments useful for both planning patient safety programs, as well as a statistical framework for assessing the future success of drug programs based on nonclinical and clinical observations. Bayesian analyses were undertaken to investigate the connection between nonclinical adverse event observations and observations of that same event in clinical trial for a large set of approved drugs. We employed the same statistical methods used to evaluate the efficacy of diagnostic tests to evaluate the ability of nonclinical studies to predict adverse events in clinical studies, and adverse events in both to predict drug withdrawal. We find that some nonclinical observations suggest higher risk for observing the same adverse event in clinical studies, particularly arrhythmias, QT prolongation, and abnormal hepatic function. However the lack of these events in nonclinical studies is found to not be a good predictor of safety in humans. Some nonclinical and clinical observations appear to be associated with high risk of drug withdrawal from market, especially arrhythmia and hepatic necrosis. We use the method to estimate the overall risk of drug withdrawal from market using the product of the risks from each nonclinical and clinical observation to create a risk profile.		Matthew Clark	2015	Journal of biomedical informatics	10.1016/j.jbi.2015.02.008	psychiatry;medicine;translational medicine;adverse effect;likelihood-ratio test;toxicology;bayesian probability;statistics	AI	7.052981649682771	-74.22095002216051	38426
badf6f4bb22f55dcb1cd500dda43ed47bac21147	longitudinal connectome-based predictive modeling for rem sleep behavior disorder from structural brain connectivity		Methods to identify neuroplasticity patterns in human brains are of the utmost importance in understanding and potentially treating neurodegenerative diseases. Parkinson disease (PD) research will greatly benefit and advance from the discovery of biomarkers to quantify brain changes in the early stages of the disease, a prodromal period when subjects show no obvious clinical symptoms. Diffusion tensor imaging (DTI) allows for an in-vivo estimation of the structural connectome inside the brain and may serve to quantify the degenerative process before the appearance of clinical symptoms. In this work, we introduce a novel strategy to compute longitudinal structural connectomes in the context of a whole-brain data-driven pipeline. In these initial tests, we show that our predictive models are able to distinguish controls from asymptomatic subjects at high risk of developing PD (REM sleep behavior disorder, RBD) with an area under the receiving operating characteristic curve of 0.90 (pu003c0.001) and a longitudinal dataset of 46 subjects part of the Parkinson’s Progression Markers Initiative. By analyzing the brain connections most relevant for the predictive ability of the best performing model, we find connections that are biologically relevant to the disease.	connectome;predictive modelling	Luca Giancardo;Timothy M. Ellmore;Jessika Suescun;Laura Ocasio;Arash Kamali;Roy Riascos-Castaneda;Mya C. Schiess	2018		10.1117/12.2293835	neuroscience;asymptomatic;rem sleep behavior disorder;prodromal period;biomarker (medicine);disease;diffusion mri;connectome;neuroplasticity;medicine	Robotics	22.227939416391397	-79.19901638818745	38429
755ed97dfd3d9171569945a8ac383238e6203df6	functional interpretation of microrna-mrna association in biological systems using r	genomics;transcriptional regulation;sequence analysis;microrna;microarrays	The prediction of microRNA targets is a challenging task that has given rise to several prediction algorithms. Databases of predicted targets can be used in a microRNA target enrichment analysis, enhancing our capacity to extract functional information from gene lists. However, the available tools in this field analyze gene sets one by one limiting their use in a meta-analysis. Here, we present an R system for miRNA enrichment analysis that is suitable for systems biology. These collection of R scripts and embedded data allow using predicted targets of public databases or a custom integration of them. As a proof-of-principle, we have successfully performed the challenging analysis of 2158 tumoral samples at a time. The obtained results have been summarized in a network where each cancer disease is linked to enriched miRNAs and overrepresented functions. These network connections have proven to be an invaluable resource for the study of biological and pathological causes and effects of the expression of miRNAs.	algorithm;biological system;database;databases;embedded system;embedding;gene ontology term enrichment;micrornas;paget's disease, mammary	Elizabeth Guruceaga;Victor Segura	2014	Computers in biology and medicine	10.1016/j.compbiomed.2013.11.001	genomics;dna microarray;bioinformatics;sequence analysis;data mining;genetics;transcriptional regulation;microrna	Comp.	1.2049770736854193	-59.31017028440367	38437
8a4a4d426b97a42833295e376e695078e0f1b4df	quasar-mpra: accurate allele-specific analysis for massively parallel reporter assays		Motivation The majority of the human genome is composed of non-coding regions containing regulatory elements such as enhancers, which are crucial for controlling gene expression. Many variants associated with complex traits are in these regions, and may disrupt gene regulatory sequences. Consequently, it is important to not only identify true enhancers but also to test if a variant within an enhancer affects gene regulation. Recently, allele-specific analysis in high-throughput reporter assays, such as massively parallel reporter assays (MPRAs), have been used to functionally validate non-coding variants. However, we are still missing high-quality and robust data analysis tools for these datasets.   Results We have further developed our method for allele-specific analysis QuASAR (quantitative allele-specific analysis of reads) to analyze allele-specific signals in barcoded read counts data from MPRA. Using this approach, we can take into account the uncertainty on the original plasmid proportions, over-dispersion, and sequencing errors. The provided allelic skew estimate and its standard error also simplifies meta-analysis of replicate experiments. Additionally, we show that a beta-binomial distribution better models the variability present in the allelic imbalance of these synthetic reporters and results in a test that is statistically well calibrated under the null. Applying this approach to the MPRA data, we found 602 SNPs with significant (false discovery rate 10%) allele-specific regulatory function in LCLs. We also show that we can combine MPRA with QuASAR estimates to validate existing experimental and computational annotations of regulatory variants. Our study shows that with appropriate data analysis tools, we can improve the power to detect allelic effects in high-throughput reporter assays.   Availability and implementation http://github.com/piquelab/QuASAR/tree/master/mpra.   Contact fluca@wayne.edu or rpique@wayne.edu.   Supplementary information Supplementary data are available online at Bioinformatics.	barcode;bioinformatics;biopolymer sequencing;eaf2 gene;electrolyte imbalance;enhancer of transcription;estimated;experiment;gene expression regulation;geographic information systems;heart rate variability;high-throughput computing;massively-parallel sequencing;null value;paqr7 gene;reading (activity);self-replicating machine;single nucleotide polymorphism;synthetic intelligence;throughput;mpra protein, e coli	Cynthia A. Kalita;Gregory A. Moyerbrailean;Christopher Brown;Xiaoquan Wen;Francesca Luca;Roger Pique-Regi	2018	Bioinformatics	10.1093/bioinformatics/btx598	human genome;single-nucleotide polymorphism;enhancer;allelic imbalance;computer science;replicate;data mining;regulation of gene expression;gene;bioinformatics;regulatory sequence;genetics	Comp.	3.4914538962587143	-53.564430146265494	38448
d457f487b26106953f00087934400e4808aadc8c	a neurocomputational model of anticipation and sustained inattentional blindness in hierarchies	sustained inattentional blindness;anticipation;echo state network;technology;cortical hierarchies;computer and information science;neural modelling;human subjects;teknik;passivity observer;neurocomputation;reservoir systems;association;data och informationsvetenskap;inattentional blindness;prediction;enaction	Anticipation and prediction have been identified as key functions of many brain areas facilitating recognition, perception, and planning. In this paper we present a neurocomputational model in which feedback, effectively predicting or anticipating task-relevant features, leads to sustained inattentional blindness. A psychological experiment on sustained inattentional blindness in human subjects is simulated/replicated to provide visual input to an Echo State Network with separate readouts trained to track the attended object and detect the unexpected object. Feedback from the tracking readouts, is then used to simulate engagement in the task, and compared to results obtained without feedback, simulating passive observation. We find a highly significant effect of feedback, enhancing performance at the task and simultaneously degrading detection of unexpected features, thereby modeling the sustained inattentional blindness effect. We therefore suggest that anticipatory / predictive mechanisms are responsible for inattentional blindness.	echo state network;feedback;simulation	Anthony F. Morse;Robert Lowe;Tom Ziemke	2008		10.1007/978-3-642-02565-5_9	psychology;computer vision;communication;social psychology	HCI	13.6805251433788	-74.81657624201924	38465
c16899eaf57e2d8ad71920974d0a8ea73eb8ca43	in-parallel rare cells identification by high throughput cells self-assembly	self assembly;cell culture in parallel rare cell identification high throughput cell self assembly chip dense monolayer cell array gravity force fluidic force cancer cells mega primary lymphocytes immunofluorescence single cell level fluorescence microscopy;monolayers;fluorescence;cancer;self assembly cancer cellular biophysics fluorescence monolayers optical microscopy;cells array ctc self assembled monolayer;cellular biophysics;optical microscopy;cells biology arrays blood gravity glass cancer	In this study, we present a high density cells self-assembly chip to form a dense monolayer cell array by the employment of gravity force and fluidic force. The cancer cells can be identified in mega primary lymphocytes at the single cell level by immunofluorescence. This chip is compatible with standard fluorescence microscopy equipment and possible to do cell culture after cell array formed.	cell (microprocessor);self-assembly;throughput	Jui-Chia Chang;Tsung-Ju Chen;Yu-Cheng Chang;Fan Gang Tseng	2013	The 8th Annual IEEE International Conference on Nano/Micro Engineered and Molecular Systems	10.1109/NEMS.2013.6559768	fluorescence;analytical chemistry;nanotechnology;optical microscope;monolayer;self-assembly;physics;cancer	Robotics	14.400686541427296	-65.54287757213551	38467
23453fd873a6619c994127e4b741a3e067e21837	from biophysics to evolutionary genetics: statistical aspects of gene regulation	transcription genetic;evolution molecular;biophysics;fitness landscape;data interpretation statistical;proteome;genome analysis;genetic drift;gene regulation;signal transduction;regulatory element;transcription factors;binding site;computational biology bioinformatics;models genetic;evolutionary genetics;gene expression regulation;models statistical;algorithms;combinatorial libraries;computational biology;computer appl in life sciences;computer simulation;gene expression profiling;oligonucleotide array sequence analysis;microarrays;bioinformatics	This is an introductory review on how genes interact to produce biological functions. Transcriptional interactions involve the binding of proteins to regulatory DNA. Specific binding sites can be identified by genomic analysis, and these undergo a stochastic evolution process governed by selection, mutations, and genetic drift. We focus on the links between the biophysical function and the evolution of regulatory elements. In particular, we infer fitness landscapes of binding sites from genomic data, leading to a quantitative evolutionary picture of regulation.	binding sites;biophysics;gene expression regulation;genetic drift;inference;interaction;mutation	Michael Lässig	2007	BMC Bioinformatics	10.1186/1471-2105-8-S6-S7	computer simulation;biology;molecular biology;regulation of gene expression;molecular evolution;bioinformatics;genetics	Comp.	4.76973379173023	-60.70691191987676	38533
ce980afdf4e5cfd95e0f0480e6a0dc45781df33b	a genetic algorithm-support vector machine method with parameter optimization for selecting the tag snps	support vector machine svm;particle swarm optimization pso;single nucleotide polymorphisms snps;tag snps;genetic algorithm ga	SNPs (Single Nucleotide Polymorphisms) include millions of changes in human genome, and therefore, are promising tools for disease-gene association studies. However, this kind of studies is constrained by the high expense of genotyping millions of SNPs. For this reason, it is required to obtain a suitable subset of SNPs to accurately represent the rest of SNPs. For this purpose, many methods have been developed to select a convenient subset of tag SNPs, but all of them only provide low prediction accuracy. In the present study, a brand new method is developed and introduced as GA-SVM with parameter optimization. This method benefits from support vector machine (SVM) and genetic algorithm (GA) to predict SNPs and to select tag SNPs, respectively. Furthermore, it also uses particle swarm optimization (PSO) algorithm to optimize C and γ parameters of support vector machine. It is experimentally tested on a wide range of datasets, and the obtained results demonstrate that this method can provide better prediction accuracy in identifying tag SNPs compared to other methods at present.	experiment;genetic algorithm;genotype determination;mathematical optimization;particle swarm optimization;population parameter;single nucleotide polymorphism;single-chain antibodies;software release life cycle;subgroup;support vector machine;benefit	Ilhan Ilhan;Gülay Tezel	2013	Journal of biomedical informatics	10.1016/j.jbi.2012.12.002	bioinformatics;machine learning;data mining	ML	9.060530336230345	-53.896248618263314	38586
29e1461cef4e3fe7b3e2dc7801382e251e9ac48c	1, 2, 3, many - perceptual integration of motif repetitions				M Katkov;Hila Harris;D. Sagi	2018	Symmetry	10.3390/sym10110661		Vision	-3.062792557491631	-79.13352692310721	38670
813092cdb45144ecca448ea6572f366b09a5e810	changes in neonatal regional brain volume associated with preterm birth and perinatal factors	brain development;brain size;early life factors;newborn infants;parcellation;prematurity	BACKGROUND Preterm birth is associated with altered brain development, with younger gestational age (GA) at birth often associated with greater brain volume reduction. Such volume alterations at term equivalent age (TEA) have been found with differing magnitude across different brain regions, although this has mostly been investigated with regards to whole tissue volumes and large-scale subdivisions. In addition to degree of prematurity, many other perinatal factors have been found to influence brain structure and development in infants born preterm. We aimed to clarify the relationships between degree of prematurity and regional brain volumes at TEA, and between perinatal factors and regional brain volumes at TEA, in finer spatial detail.   METHODS 285 preterm and term-born infants (GA at birth 24.6-42.1 weeks; 145 female; 59 born at term) were scanned at TEA. Data on perinatal factors were obtained by chart review, including sex, multiple birth, birthweight standard deviation (SD) score, postnatal growth and social risk. The Melbourne Children's Regional Infant Brain (M-CRIB) atlas was registered to the current sample, then 100 brain regions were labelled for volumetric analyses. Linear regressions with generalised estimating equations and likelihood ratio tests were performed to investigate whether GA at birth or perinatal factors were associated with regional volumes at TEA.   RESULTS Younger GA at birth was associated with smaller volumes at TEA in some regions including bilateral cerebral white matter, middle temporal gyri, amygdalae, pallidum and brainstem. In other regions, younger GA at birth was associated with larger volumes, including in primary visual, motor and somatosensory cortices. Positive associations between perinatal factors and regional volumes at TEA were found in many brain regions for birthweight SD score, and male sex, independent of GA at birth. These associations were seen on both univariable analyses, and multivariable analyses controlling for other perinatal factors. Social risk and multiple birth were generally not associated with regional brain volumes, and postnatal growth was associated with volume in many regions only after adjusting for other perinatal factors.   CONCLUSIONS These results elucidate regional brain volume differences associated with preterm birth and perinatal factors at a more detailed parcellated level than previously reported, and contribute to understanding of the complex array of correlates of preterm birth.		Bonnie Alexander;Claire E. Kelly;Christopher L. Adamson;Richard Beare;Deanne K. Thompson	2019	NeuroImage	10.1016/j.neuroimage.2018.07.021	obstetrics;psychology;developmental psychology;white matter;current sample;multiple birth;brain size;gestational age	Visualization	20.05931843999395	-80.10839004318473	38735
179d085d37e3fda0a88047305e5953e6efefbb76	thinking about the thoughts of others; temporal and spatial neural activation during false belief reasoning	false belief;inferior frontal gyrus (ifg);magnetoencephalography (meg);precuneus;right temporoparietal junction (rtpj);social cognition;theory of mind	"""Theory of Mind (ToM) is the ability to understand the perspectives, mental states and beliefs of others in order to anticipate their behaviour and is therefore crucial to social interactions. Although fMRI has been widely used to establish the neural networks implicated in ToM, little is known about the timing of ToM-related brain activity. We used magnetoencephalography (MEG) to measure the neural processes underlying ToM, as MEG provides very accurate timing and excellent spatial localization of brain processes. We recorded MEG activity during a false belief task, a reliable measure of ToM, in twenty young adults (10 females). MEG data were recorded in a 151 sensor CTF system (MISL, Coquitlam, BC) and data were co-registered to each participant's MRI (Siemens 3T) for source reconstruction. We found stronger right temporoparietal junction (rTPJ) activations in the false belief condition from 150ms to 225ms, in the right precuneus from 275ms to 375ms, in the right inferior frontal gyrus from 200ms to 300ms and the superior frontal gyrus from 300ms to 400ms. Our findings extend the literature by demonstrating the timing and duration of neural activity in the main regions involved in the """"mentalizing"""" network, showing that activations related to false belief in adults are predominantly right lateralized and onset around 100ms. The sensitivity of MEG will allow us to determine spatial and temporal differences in the brain processes in ToM in younger populations or those who demonstrate deficits in this ability."""	artificial neural network;baseline (configuration management);charge trap flash;data collection;electroencephalography;expectation propagation;frontal lobe gyrus;hla te antigen;ifng wt allele;immunoprecipitation;inference;inferior frontal gyrus;interaction;jack device component;marc (archive);magnetoencephalography;mental state;neural network simulation;onset (audio);population;reasoning;registration;structure of middle temporal gyrus;structure of precuneus;tellurium;test engineer;thinking, function;trial elements domain;units of measure - siemens;xulvi-brunet - sokolov algorithm;fmri;funding grant	Sarah I. Mossad;Michelle AuCoin-Power;Charline Urbain;Mary Lou Smith;Elizabeth W. Pang;Margot J. Taylor	2016	NeuroImage	10.1016/j.neuroimage.2016.03.053	psychology;developmental psychology;communication;social psychology	ML	18.74438920207733	-78.67903681247336	38742
6ddbbf5394bbf162de26a4a1ac75da173997d593	evaluation of label dependency for the prediction of hla genes	label dependency;multi label prediction;human leukocyte antigen;snps;hla imputation	The Human Leukocyte Antigen (HLA) gene system plays a crucial role in hematopoietic stem cell transplantation, where patients and donors are matched with respect to their HLA genes in order to maximize the chances of a successful transplant. It is the most polymorphic region of the human genome with some of the strongest associations with autoimmune, infectious, and inflammatory diseases. The availability of HLA data is, therefore, of high importance to clinicians and researchers. However, due to its high polymorphism, obtaining it is time- and cost-prohibitive. We previously described a method for the prediction of HLA genes from widely available Single Nucleotide Polymorphism (SNP) data. In this paper we show that using HLA gene dependency information improves prediction performance on multiple real-world data sets. More specifically, we propose and evaluate different approaches for integrating HLA gene dependency into the prediction process. The results from experiments on two real data sets show that adding dependency information is a valuable asset for HLA gene prediction, particularly for smaller data sets.	experiment;gene prediction	Vanja Paunic;Michael Steinbach;Abeer Madbouly;Vipin Kumar	2013		10.1145/2506583.2506632	single-nucleotide polymorphism;biology;medicine;bioinformatics;genetics;human leukocyte antigen	ML	7.425927074025796	-54.207664804544656	38820
9952074faf4a0139e7e79110050316a38f7d3507	in-silico predictive mutagenicity model generation using supervised learning approaches	biological patents;biomedical journals;text mining;europe pubmed central;citation search;computer applications in chemistry;citation networks;theoretical and computational chemistry;computational biology bioinformatics;research articles;abstracts;open access;life sciences;clinical guidelines;full text;article;rest apis;orcids;europe pmc;documentation and information in chemistry;biomedical research;bioinformatics;literature search	"""UNLABELLED    BACKGROUND Experimental screening of chemical compounds for biological activity is a time consuming and expensive practice. In silico predictive models permit inexpensive, rapid """"virtual screening"""" to prioritize selection of compounds for experimental testing. Both experimental and in silico screening can be used to test compounds for desirable or undesirable properties. Prior work on prediction of mutagenicity has primarily involved identification of toxicophores rather than whole-molecule predictive models. In this work, we examined a range of in silico predictive classification models for prediction of mutagenic properties of compounds, including methods such as J48 and SMO which have not previously been widely applied in cheminformatics.   RESULTS The Bursi mutagenicity data set containing 4337 compounds (Set 1) and a Benchmark data set of 6512 compounds (Set 2) were taken as input data set in this work. A third data set (Set 3) was prepared by joining up the previous two sets. Classification algorithms including Naïve Bayes, Random Forest, J48 and SMO with 10 fold cross-validation and default parameters were used for model generation on these data sets. Models built using the combined performed better than those developed from the Benchmark data set. Significantly, Random Forest outperformed other classifiers for all the data sets, especially for Set 3 with 89.27% accuracy, 89% precision and ROC of 95.3%. To validate the developed models two external data sets, AID1189 and AID1194, with mutagenicity data were tested showing 62% accuracy with 67% precision and 65% ROC area and 91% accuracy, 91% precision with 96.3% ROC area respectively. A Random Forest model was used on approved drugs from DrugBank and metabolites from the Zinc Database with True Positives rate almost 85% showing the robustness of the model.   CONCLUSION We have created a new mutagenicity benchmark data set with around 8,000 compounds. Our work shows that highly accurate predictive mutagenicity models can be built using machine learning methods based on chemical descriptors and trained using this set, and these models provide a complement to toxicophores based methods. Further, our work supports other recent literature in showing that Random Forest models generally outperform other comparable machine learning methods for this kind of application."""	algorithm;benchmark (computing);chemicals;cheminformatics;complement system proteins;cross reactions;cross-validation (statistics);default;drugbank;machine learning;naive bayes classifier;predictive modelling;random forest;receiver operator characteristics;smox gene;sequential minimal optimization;supervised learning;two-hybrid screening;virtual screening;zinc database	Abhik Seal;Anurag Passi;U. C. Abdul Jaleel;David J. Wild;et al.	2012		10.1186/1758-2946-4-10	text mining;medical research;medicine;computer science;bioinformatics;data science;data mining	ML	10.770605622532251	-55.99652190766141	38926
7bb8d6904ad6ba67be97854e07fc43f5747fdc87	fnsemsim: an improved disease similarity method based on network fusion	disease similarity;semantic association;random walk with restart;function interaction network	Discovering similar diseases is very helpful for revealing the pathogenesis of diseases and making direction in drug use. And related diseases are often triggered by disease-related genes. Therefore, function interaction networks structured by disease-related genes are suitable for measurement of disease similarity, and some methods have utilized the advantage of function interaction of disease-related genes. However, all of them were developed by using a single gene functional network, some of them ignoring the effect of non-neighbour nodes in a functional interaction network. In this study, we propose a new method, FNSemSim, for computing relatedness between diseases by fusing two protein networks, which could be utilized fully based on random walk with restart (RWR). And a benchmark set of similar disease pairs are used to assess the performance of FNSemSim. As a result, FNSemSim achieved a very good performance with a high AUC (area under the receiver operating characteristic curve) reached 98.7%. Furthermore, we further studied the impact of different data sources, including function interaction networks and disease-related genes databases. It was found that the quality of the data sources has a greater impact on the performance of disease similarity calculation than the size of the data source, and utilizing function interaction networks and gene-disease association data could improve the performance of FNSemSim.	benchmark (computing);database;interaction network;receiver operating characteristic;running with rifles	Yongtian Wang;Liran Juan;Yan-Shuo Chu;Rongjie Wang;Tianyi Zang;Yadong Wang	2017	2017 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)	10.1109/BIBM.2017.8217726	machine learning;artificial intelligence;computer science;random walk;receiver operating characteristic;ontology (information science);interaction network;benchmark (computing)	Visualization	6.540043626121843	-56.41799981254749	38974
ec36aeafce6b3cc7bab3eff497be6fcd68884815	unleashing the potential of cnns for interpretable few-shot learning		Convolutional neural networks (CNNs) have been generally acknowledged as one of the driving forces for the advancement of computer vision. Despite their promising performances on many tasks, CNNs still face major obstacles on the road to achieving ideal machine intelligence. One is that CNNs are complex and hard to interpret. Another is that standard CNNs require large amounts of annotated data, which is sometimes very hard to obtain, and it is desirable to be able to learn them from few examples. In this work, we address these limitations of CNNs by developing novel, simple, and interpretable models for few-shot learn- ing. Our models are based on the idea of encoding objects in terms of visual concepts, which are interpretable visual cues represented by the feature vectors within CNNs. We first adapt the learning of visual concepts to the few-shot setting, and then uncover two key properties of feature encoding using visual concepts, which we call category sensitivity and spatial pattern. Motivated by these properties, we present two intuitive models for the problem of few-shot learning. Experiments show that our models achieve competitive performances, while being much more flexible and interpretable than alternative state-of-the-art few-shot learning methods. We conclude that using visual concepts helps expose the natural capability of CNNs for few-shot learning.		Boyang Deng;Qing Liu;Siyuan Qiao;Alan L. Yuille	2017	CoRR		pattern recognition;machine learning;artificial intelligence;convolutional neural network;sensory cue;computer science;feature vector;encoding (memory);ideal machine	NLP	22.92571404141416	-53.18804862035062	38983
09c498eff994919eee20393cd7e7301f7e222ba2	deficits in early-stage face perception in excessive internet users		Excessive Internet use is associated with a limited ability to communicate effectively socially, which depends largely on the capacity for perception of the human face. We used a passive visual detection paradigm to compare the early stages of the processing of face-related information in young excessive Internet users (EIUs) and healthy normal subjects by analyzing event-related potentials (ERPs) elicited by faces and by nonface stimuli (tables), each presented in the upright and inverted position. The P1 and N170 components of the spectrum of ERPs elicited at occipital-temporal sites by the viewing of faces were larger and peaked sooner than the same ERP components elicited by tables, and inverted faces significantly enhanced and delayed the N170 component. EIUs had a generally smaller P1 component than did normal subjects, whether elicited by faces or by tables, and the N170 effect, or difference in amplitude of the N170 component for faces versus tables, was significantly smaller in the EIUs than in normal subjects. However, the N170 inversion effect, or difference in amplitude of the N170 component elicited by upright versus inverted faces, was similar in the EIUs and normal subjects. These data indicate that EIUs have deficits in the early stage of face-perception processing but may have intact holistic/configural processing of faces. Whether some deeper processes of face perception, such as face memory and face identification, are affected in EIUs needs to be investigated further with more specific procedures.	erp;entity handling - upright;face (geometry);face detection;face perception;holism;internet;large;limited stage (cancer stage);mcgurk effect;programming paradigm;small;table - furniture	Jin-bo He;Chia-Ju Liu;Yong-yu Guo;Lun Zhao	2011	Cyberpsychology, behavior and social networking	10.1089/cyber.2009.0333	psychology;developmental psychology;communication;social psychology	HCI	15.39073856931673	-76.95724133156536	39012
fdcef3442ab0e80c1b86cbeabb22542a1255eeb8	optimizing the size of the sequence profiles to increase the accuracy of protein sequence alignments generated by profile-profile algorithms	sensitivity and specificity;fold recognition;secuencia aminoacido;alignement sequence;proteine;sequence aminoacide;aminoacid sequence;genome annotation;protein sequence;bioinformatique;taille;profiles methods;alineacion secuencia;information presentation;algorithme;algorithm;accuracy;large scale;precision;protein classification;talla;detection algorithm;proteina;sequence alignment;bioinformatica;protein;size;bioinformatics;algoritmo	MOTIVATION Profile-based protein homology detection algorithms are valuable tools in genome annotation and protein classification. By utilizing information present in the sequences of homologous proteins, profile-based methods are often able to detect extremely weak relationships between protein sequences, as evidenced by the large-scale benchmarking experiments such as CASP and LiveBench.   RESULTS We study the relationship between the sensitivity of a profile-profile method and the size of the sequence profile, which is defined as the average number of different residue types observed at the profile's positions. We also demonstrate that improvements in the sensitivity of a profile-profile method can be made by incorporating a profile-dependent scoring scheme, such as position-specific background frequencies. The techniques presented in this article are implemented in an alignment algorithm UNI-FOLD. When tested against other well-established methods for fold recognition, UNI-FOLD shows increased sensitivity and specificity in detecting remote relationships between protein sequences.   AVAILABILITY UNI-FOLD web server can be accessed at http://blackhawk.cs.uni.edu	algorithm;amino acid sequence;annotation;casp;experiment;fold (higher-order function);homologous gene;homology (biology);livebench;optimizing compiler;peptide sequence;position weight matrix;score;sensitivity and specificity;sensor;sequence alignment;server (computing);threading (protein sequence);vocal cord paralysis;web server	Aleksandar Poleksic;Mark A. Fienup	2008	Bioinformatics	10.1093/bioinformatics/btn097	biology;bioinformatics;data mining;accuracy and precision;genetics;statistics	Comp.	-3.403382522653127	-55.44868538087259	39019
4bbc6e3269abf36ea2450a8e302ebbc54d3dd97a	applying meta-analysis to genotype-tissue expression data from multiple tissues to identify eqtls and increase the number of egenes		Motivation There is recent interest in using gene expression data to contextualize findings from traditional genome-wide association studies (GWAS). Conditioned on a tissue, expression quantitative trait loci (eQTLs) are genetic variants associated with gene expression, and eGenes are genes whose expression levels are associated with genetic variants. eQTLs and eGenes provide great supporting evidence for GWAS hits and important insights into the regulatory pathways involved in many diseases. When a significant variant or a candidate gene identified by GWAS is also an eQTL or eGene, there is strong evidence to further study this variant or gene. Multi-tissue gene expression datasets like the Gene Tissue Expression (GTEx) data are used to find eQTLs and eGenes. Unfortunately, these datasets often have small sample sizes in some tissues. For this reason, there have been many meta-analysis methods designed to combine gene expression data across many tissues to increase power for finding eQTLs and eGenes. However, these existing techniques are not scalable to datasets containing many tissues, like the GTEx data. Furthermore, these methods ignore a biological insight that the same variant may be associated with the same gene across similar tissues.   Results We introduce a meta-analysis model that addresses these problems in existing methods. We focus on the problem of finding eGenes in gene expression data from many tissues, and show that our model is better than other types of meta-analyses.   Availability and Implementation Source code is at https://github.com/datduong/RECOV .   Contact eeskin@cs.ucla.edu or datdb@cs.ucla.edu.   Supplementary information Supplementary data are available at Bioinformatics online.	addresses (publication format);bioinformatics;body tissue;expression quantitative trait locus;gene expression programming;genome-wide association study;genotype-tissue expression program;geographic information systems;meta analysis (statistical procedure);quantitative trait loci;sample size;scalability;source code	Dat Duong;Lisa Gai;Sagi Snir;Eun Yong Kang;Buhm Han;Jae Hoon Sul;Eleazar Eskin	2017		10.1093/bioinformatics/btx227	biology;bioinformatics;data mining;genetics	Comp.	4.055759374619699	-54.47575956669655	39073
09545eee02ced7d660d57e3ad96e766012ca4003	what you see is what you eat: an ale meta-analysis of the neural correlates of food viewing in children and adolescents	prader willi syndrome;research support non u s gov t;individual differences;brain responses;neurology;meta analysis;journal article;obese individuals;cognitive neuroscience;cognitive control;anterior cingulate;review;high calorie foods;visual cortex;reward sensitivity;orbitofrontal cortex	Food cues are omnipresent and may enhance overconsumption. In the last two decades the prevalence of childhood obesity has increased dramatically all over the world, largely due to overconsumption. Understanding children's neural responses to food may help to develop better interventions for preventing or reducing overconsumption. We aimed to determine which brain regions are concurrently activated in children/adolescents in response to viewing food pictures, and how these relate to adult findings. Two activation likelihood estimation (ALE) meta-analyses were performed: one with studies in normal weight children/adolescents (aged 8-18, 8 studies, 137 foci) and one with studies in normal weight adults (aged 18-45, 16 studies, 178 foci). A contrast analysis was performed for children/adolescents vs. adults. In children/adolescents, the most concurrent clusters were in the left lateral orbitofrontal cortex (OFC), the bilateral fusiform gyrus, and the right superior parietal lobule. In adults, clusters in similar areas were found. Although the number of studies for a direct statistical comparison between the groups was relatively low, there were indications that children/adolescents may not activate areas important for cognitive control. Overall, the number of studies that contributed to the significant clusters was moderate (6-75%). In summary, the brain areas most consistently activated in children/adolescents by food viewing are part of the appetitive brain network and overlap with those found in adults. However, the age range of the children studied was rather broad. This study offers important recommendations for future research; studies making a direct comparison between adults and children in a sufficiently narrow age range would further elucidate how neural responses to food cues change during development.	adolescent (age group);bilateral filter;consciousness;lateral computing;lateral occipitotemporal gyrus;lateral thinking;lobule;meta analysis (statistical procedure);orbitofrontal cortex;pediatric obesity	Floor van Meer;Laura N. van der Laan;Roger A. H. Adan;Max A. Viergever;Paul A. M. Smeets	2015	NeuroImage	10.1016/j.neuroimage.2014.09.069	psychology;neurology;neuroscience;meta-analysis;developmental psychology;cognitive neuroscience;social psychology	HCI	17.887422984767575	-78.81605528595922	39082
474f98a7220d3acac4995b4bddef244867540b44	bayesian ensemble methods for survival prediction in gene expression data	breast neoplasms;female;ensemble method;brain neoplasms;bayes theorem;gene expression data;models genetic;gene expression regulation neoplastic;survival analysis;humans;gene expression profiling;oligonucleotide array sequence analysis	MOTIVATION We propose a Bayesian ensemble method for survival prediction in high-dimensional gene expression data. We specify a fully Bayesian hierarchical approach based on an ensemble 'sum-of-trees' model and illustrate our method using three popular survival models. Our non-parametric method incorporates both additive and interaction effects between genes, which results in high predictive accuracy compared with other methods. In addition, our method provides model-free variable selection of important prognostic markers based on controlling the false discovery rates; thus providing a unified procedure to select relevant genes and predict survivor functions.   RESULTS We assess the performance of our method several simulated and real microarray datasets. We show that our method selects genes potentially related to the development of the disease as well as yields predictive performance that is very competitive to many other existing methods.   AVAILABILITY http://works.bepress.com/veera/1/.	bayesian network;ensemble learning;feature selection;free variables and bound variables;gene expression;microarray;survivors;trees (plant);utility functions on indivisible goods	Vinícius Bonato;Veerabhadran Baladandayuthapani;Bradley M. Broom;Erik P. Sulman;Kenneth D. Aldape;Kim-Anh Do	2011	Bioinformatics	10.1093/bioinformatics/btq660	biology;bioinformatics;data mining;survival analysis;gene expression profiling;bayes' theorem;statistics	Comp.	6.206969676581224	-52.69108419762978	39089
d76425e1ca179d2e2c7abc5aeccee1dd57b9ab38	dolina - docking based on a local induced-fit algorithm: application toward small-molecule binding to nuclear receptors		Docking algorithms allowing for ligand and - to various extent - also protein flexibility are nowadays replacing techniques based on rigid protocols. The algorithm implemented in the Dolina software relies on pharmacophore matching for generating potential ligand poses and treats associated local induced-fit changes by combinatorial rearrangement of side-chains lining the binding site. In Dolina, ligand flexibility is not treated internally, instead a pool of low-energy conformers identified in a conformational search is screened for extended binding-pose candidates. Grouping rearranged residues in sterically independent families and side-chain conformer clustering are employed to achieve efficient use of the computational resources along with a good accuracy of the generated poses. Dolina was applied toward docking of small-molecule ligands to three different nuclear receptor ligand binding domains for which in total 18 high-resolution crystal structures were used as reference. The selected nuclear receptors feature a deeply buried ligand-binding site where local induced-fit is to be expected, particularly for receptor antagonists. For each receptor, a crystal structure with a cocrystallized small steroid ligand (template) was chosen as a target system, to which several synthetic ligands of different sizes were docked. Poses within an RMSD of 2.0 Å from the crystal reference pose were generated in 91% of the cases. In 28%, the pose with the lowest RMSD to the reference pose was ranked as the top one, and in 76% it was ranked among the top five poses. Detailed descriptions of the docking algorithm and observed results are included. Dolina is available free of charge for academic institutions.	boat dock;clinical use template;cluster analysis;computation;computational resource;crystal structure;dna sequence rearrangement;description;dhrystone;docking (molecular);gonadotropin-releasing hormone receptor;image resolution;ligand binding;ligands;muscle rigidity;pharmacophore;projection screen;protocols documentation;receptors, nuclear;steroids;algorithm;statistical cluster	Martin Smiesko	2013	Journal of chemical information and modeling	10.1021/ci400098y	simulation;chemistry;bioinformatics	Comp.	11.763955898397805	-59.93469641500886	39121
98efd105da69c4d0f1227469fd8bb90182356706	cortical and subcortical responses to biological motion	biological motion;life detector;visual perception;fmri	Using fMRI and multivariate analyses we sought to understand the neural representations of articulated body shape and local kinematics in biological motion. We show that in addition to a cortical network that includes areas identified previously for biological motion perception, including the posterior superior temporal sulcus, inferior frontal gyrus, and ventral body areas, the ventral lateral nucleus, a presumably motoric thalamic area is sensitive to both form and kinematic information in biological motion. Our findings suggest that biological motion perception is not achieved as an end-point of segregated cortical form and motion networks as often suggested, but instead involves earlier parts in the visual system including a subcortical network.	cell nucleus;cumulative trauma disorders;frontal lobe gyrus;groove;inferior frontal gyrus;lateral thinking;structure of superior temporal sulcus;thalamic structure;fmri	Dorita H. F. Chang;Hiroshi Ban;Yuji Ikegaya;Ichiro Fujita;Nikolaus F. Troje	2018	NeuroImage	10.1016/j.neuroimage.2018.03.013	ventral lateral nucleus;cognitive psychology;inferior frontal gyrus;kinematics;biological motion;psychology;superior temporal sulcus;biological motion perception	ML	17.33939515834623	-76.34575591032723	39184
92c867fbd19f784205199f707b59da7475ca5160	evolutionary constraints or opportunities?	biological patents;phenotypic plasticity;biomedical journals;text mining;europe pubmed central;units of selection macro evolution;citation search;citation networks;research articles;regulated variation;abstracts;open access;life sciences;multitasking;developmental correlation;clinical guidelines;full text;rest apis;orcids;europe pmc;biomedical research;bioinformatics;literature search	"""Natural selection is traditionally viewed as a leading factor of evolution, whereas variation is assumed to be random and non-directional. Any order in variation is attributed to epigenetic or developmental constraints that can hinder the action of natural selection. In contrast I consider the positive role of epigenetic mechanisms in evolution because they provide organisms with opportunities for rapid adaptive change. Because the term """"constraint"""" has negative connotations, I use the term """"regulated variation"""" to emphasize the adaptive nature of phenotypic variation, which helps populations and species to survive and evolve in changing environments. The capacity to produce regulated variation is a phenotypic property, which is not described in the genome. Instead, the genome acts as a switchboard, where mostly random mutations switch """"on"""" or """"off"""" preexisting functional capacities of organism components. Thus, there are two channels of heredity: informational (genomic) and structure-functional (phenotypic). Functional capacities of organisms most likely emerged in a chain of modifications and combinations of more simple ancestral functions. The role of DNA has been to keep records of these changes (without describing the result) so that they can be reproduced in the following generations. Evolutionary opportunities include adjustments of individual functions, multitasking, connection between various components of an organism, and interaction between organisms. The adaptive nature of regulated variation can be explained by the differential success of lineages in macro-evolution. Lineages with more advantageous patterns of regulated variation are likely to produce more species and secure more resources (i.e., long-term lineage selection)."""	assumed;computer multitasking;lineage (evolution);mutation;natural selection;population;telephone switchboard;study of epigenetics	Alexei A. Sharov	2014	Bio Systems	10.1016/j.biosystems.2014.06.004	biology;text mining;human multitasking;computer science;bioinformatics;artificial intelligence;machine learning;genetics;phenotypic plasticity	Comp.	4.863869814179536	-62.39172934549176	39228
6417170bda7a7f785612fd58c121fda344e36acc	towards scaleable protein structure comparison and database search	protein structure comparison;protein structure;secondary structure;sequence alignment;database search;similarity search;secondary structure elements;structural properties	Comparing protein structures in three dimensions is a computationally expensive process that makes a full scan of a protein against a library of known protein structures impractical. To reduce the cost, we can use an approximation of the three dimensional structure that allows protein comparison to be performed quickly to filter away dissimilar proteins. In this paper, we present a new algorithm, called SCALE, for protein structure comparison. In SCALE, a protein is represented as a sequence of secondary structure elements (SSEs) augmented with 3D structural properties such as the distances and angles between the SSEs. As such, the comparison between two proteins is reduced to a sequence alignment problem between their corresponding sequences of SSEs. The 3-D structural properties of the proteins contribute to the similarity score between the two sequences. We have implemented SCALE, and compared its performance against existing schemes. Our performance study shows that SCALE outperforms existing methods in terms of both efficiency and effectiveness (measured in terms of precision and recall). To avoid exhaustive search, an index based on the structural properties is also proposed. The index prunes away a considerable amount of dissimilar proteins given a query protein.	algorithm;analysis of algorithms;approximation;blast;brute-force search;database;precision and recall;protein structure prediction;scalability;sequence alignment;similarity measure;streaming simd extensions	Chern-Hooi Chionh;Zhiyong Huang;Kian-Lee Tan;Zhen Yao	2005	International Journal on Artificial Intelligence Tools	10.1142/S0218213005002417	protein structure;structural alignment;database search engine;computer science;bioinformatics;sequence alignment;data mining;protein structure database;protein secondary structure	Comp.	-2.3285647724711347	-52.537738648890105	39241
5567648bcbdc40c8f006f682da945618e8124e4c	the use of equivalent electronic circuits in simulating physiological processes	physiological processes simulation equivalent electronic circuits teaching postgraduate medical students pump solute concentration gradient drug distribution extracellular volume measurement simulation graphs analog modeling;computer aided instruction;biological system modeling;indexing terms;equivalent circuits;volume measurement;biomedical education;computer simulation;physiological models;computer aided instruction physiological models equivalent circuits teaching biomedical education;teaching;medical students	This paper is a report on one of the modern approaches to teaching physiology to postgraduate medical students. The aim is to promote qualitative as well as quantitative analog thinking about physiological processes. To meet this aim the concept of equivalent electronic circuits was introduced in teaching. Two examples of simulation of physiological phenomena by equivalent electronic circuits are described: (1) a pump for building-up the concentration gradient of a solute and (2) drug distribution in body compartments after single or repeated administration and extracellular volume measurement. The use of the latter circuit in teaching was tested in two generations of postgraduate medical students. They showed an increasing interest for this type of teaching because simulation graphs were almost identical to those shown in textbooks and physicians manuals.	electronic circuit;simulation	Marjan Rupnik;Franc Runovc;Marjan Kordas	2001	IEEE Trans. Education	10.1109/13.965788	equivalent circuit;computer simulation;simulation;index term;computer science;engineering;electrical engineering;biological engineering;quantum mechanics	EDA	11.25182049418226	-71.18800052839107	39250
61cd66e29722fb345c426e06a028854311a93238	channel interaction and current level affect across-electrode integration of interaural time differences in bilateral cochlear-implant listeners	biological patents;biomedical journals;text mining;europe pubmed central;citation search;citation networks;research articles;abstracts;open access;life sciences;clinical guidelines;full text;rest apis;orcids;europe pmc;biomedical research;bioinformatics;literature search	Sensitivity to interaural time differences (ITDs) is important for sound localization. Normal-hearing listeners benefit from across-frequency processing, as seen with improved ITD thresholds when consistent ITD cues are presented over a range of frequency channels compared with when ITD information is only presented in a single frequency channel. This study aimed to clarify whether cochlear-implant (CI) listeners can make use of similar processing when being stimulated with multiple interaural electrode pairs transmitting consistent ITD information. ITD thresholds for unmodulated, 100-pulse-per-second pulse trains were measured in seven bilateral CI listeners using research interfaces. Consistent ITDs were presented at either one or two electrode pairs at different current levels, allowing for comparisons at either constant level per component electrode or equal overall loudness. Different tonotopic distances between the pairs were tested in order to clarify the potential influence of channel interaction. Comparison of ITD thresholds between double pairs and the respective single pairs revealed systematic effects of tonotopic separation and current level. At constant levels, performance with double-pair stimulation improved compared with single-pair stimulation but only for large tonotopic separation. Comparisons at equal overall loudness revealed no benefit from presenting ITD information at two electrode pairs for any tonotopic spacing. Irrespective of electrode-pair configuration, ITD sensitivity improved with increasing current level. Hence, the improved ITD sensitivity for double pairs found for a large tonotopic separation and constant current levels seems to be due to increased loudness. The overall data suggest that CI listeners can benefit from combining consistent ITD information across multiple electrodes, provided sufficient stimulus levels and that stimulating electrode pairs are widely spaced.	bilateral filter;channel (communications);cochlear implants;cochlear implant;cochlear structure;constant current;distance;intralobular part of terminal lactiferous duct;shortest path problem;sound localization;stimulation (motivation);transmitter;electrode	Katharina Egger;Piotr Majdak;Bernhard Laback	2015	Journal of the Association for Research in Otolaryngology	10.1007/s10162-015-0542-8	text mining;medical research;communication;audiology	HCI	12.174341351668945	-66.92276490716769	39256
6d8e79f0f798adb93781dcdb0511be843099ce11	an integrated approach of gene expression and dna-methylation profiles of wnt signaling genes uncovers novel prognostic markers in acute myeloid leukemia	survival rate;acute myeloid leukemia;leukemia myeloid acute;signal transduction;gene regulatory networks;tumor markers biological;wnt proteins;computational biology bioinformatics;gene expression;promoter regions genetic;adult;dna neoplasm;wingless int wnt;algorithms;dna methylation;humans;combinatorial libraries;computer appl in life sciences;prognostic markers;prognosis;oa fund tu delft;gene expression profiling;data integration;microarrays;bioinformatics	The wingless-Int (WNT) pathway has an essential role in cell regulation of hematopoietic stem cells (HSC). For Acute Myeloid Leukemia (AML), the malignant counterpart of HSC, currently only a selective number of genes of the WNT pathway are analyzed by using either gene expression or DNA-methylation profiles for the identification of prognostic markers and potential candidate targets for drug therapy. It is known that mRNA expression is controlled by DNA-methylation and that specific patterns can infer the ability to differentiate biological differences, thus a combined analysis using all WNT annotated genes could provide more insight in the WNT signaling. We created a computational approach that integrates gene expression and DNA promoter methylation profiles. The approach represents the continuous gene expression and promoter methylation profiles with nine discrete mutually exclusive scenarios. The scenario representation allows for a refinement of patient groups by a more powerful statistical analysis, and the construction of a co-expression network. We focused on 268 WNT annotated signaling genes that are derived from the molecular signature database. Using the scenarios we identified seven prognostic markers for overall survival and event-free survival. Three genes are novel prognostic markers; two with favorable outcome (PSMD2, PPARD) and one with unfavorable outcome (XPNPEP). The remaining four genes (LEF1, SFRP2, RUNX1, and AXIN2) were previously identified but we could refine the patient groups. Three AML risk groups were further analyzed and the co-expression network showed that only the good risk group harbors frequent promoter hypermethylation and significantly correlated interactions with proteasome family members. Our results provide novel insights in WNT signaling in AML, we discovered new and previously identified prognostic markers and a refinement of the patient groups.	cell signaling;disease-free survival;gene expression;gene regulatory network;hematopoietic stem cells;hypermethylation;int 16h;inference;interaction;lef1 gene;leukemia, myelocytic, acute;methylation;molecular profiling;ppard gene;patients;prognostic variable;refinement (computing);sfrp2 gene;wnt signaling pathway involved in midbrain dopaminergic neuron differentiation;acute myeloid leukemia 1 protein	Erdogan Taskesen;Frank J. T. Staal;Marcel J. T. Reinders	2015		10.1186/1471-2105-16-S4-S4	wnt signaling pathway;biology;gene regulatory network;molecular biology;gene expression;dna microarray;bioinformatics;data integration;dna methylation;gene expression profiling;genetics;signal transduction	Comp.	6.608126223966877	-56.35165118735678	39284
54e95fc1a34c0dcdafe5aefddb0b387a8f4a133e	inference of isoforms from short sequence reads	animals;genomics;alternative splicing;mice;high throughput nucleotide sequencing;models genetic;time factors;rna;algorithms;humans;computer simulation;protein isoforms;gene expression profiling;exons	Due to alternative splicing events in eukaryotic species, the identification of mRNA isoforms (or splicing variants) is a difficult problem. Traditional experimental methods for this purpose are time consuming and cost ineffective. The emerging RNA-Seq technology provides a possible effective method to address this problem. Although the advantages of RNA-Seq over traditional methods in transcriptome analysis have been confirmed by many studies, the inference of isoforms from millions of short sequence reads (e.g., Illumina/Solexa reads) has remained computationally challenging. In this work, we propose a method to calculate the expression levels of isoforms and infer isoforms from short RNA-Seq reads using exon-intron boundary, transcription start site (TSS) and poly-A site (PAS) information. We first formulate the relationship among exons, isoforms, and single-end reads as a convex quadratic program, and then use an efficient algorithm (called IsoInfer) to search for isoforms. IsoInfer can calculate the expression levels of isoforms accurately if all the isoforms are known and infer novel isoforms from scratch. Our experimental tests on known mouse isoforms with both simulated expression levels and reads demonstrate that IsoInfer is able to calculate the expression levels of isoforms with an accuracy comparable to the state-of-the-art statistical method and a 60 times faster speed. Moreover, our tests on both simulated and real reads show that it achieves a good precision and sensitivity in inferring isoforms when given accurate exon-intron boundary, TSS, and PAS information, especially for isoforms whose expression levels are significantly high. The software is publicly available for free at http://www.cs.ucr.edu/∼jianxing/IsoInfer.html.	alternative splicing;dna binding site;effective method;exons;gene expression profiling;inference;introns;poly a;protein isoforms;quadratic programming;rna splicing;reading (activity);toxic shock syndrome;transcription (software);transcription initiation site;transcriptome;algorithm	Jianxing Feng;Wei Li;Tao Jiang	2011	Journal of computational biology : a journal of computational molecular cell biology	10.1089/cmb.2010.0243	computer simulation;biology;genomics;molecular biology;rna;exon;bioinformatics;alternative splicing;gene expression profiling;genetics	Comp.	1.3185208983544758	-54.283809104099994	39314
0d284ff075edef0ab949a5a8d5c336d27e06c609	binary image representation of a ligand binding site: its application to efficient sampling of a conformational ensemble	low energy;binary image;ligands;protein ligand interaction;ligand binding;binding sites;computational biology bioinformatics;models molecular;structure activity relationship;proteins;drug design;protein conformation;matrix metalloproteinase;algorithms;crystal structure;combinatorial libraries;crystallography x ray;computer appl in life sciences;active site;exhaustive search;databases protein;microarrays;bioinformatics	Modelling the ligand binding site of a protein is an important component of understanding protein-ligand interactions and is being actively studied. Even if the side chains are restricted to rotamers, a set of commonly-observed low-energy conformations, the exhaustive combinatorial search of ligand binding site conformers is known as NP-hard. Here we propose a new method, ROTAIMAGE, for modelling the plausible conformers for the ligand binding site given a fixed backbone structure. ROTAIMAGE includes a procedure of selecting ligand binding site residues, exhaustively searching rotameric conformers, clustering them by dissimilarities in pocket shape, and suggesting a representative conformer per cluster. Prior to the clustering, the list of conformers generated by exhaustive search can be reduced by pruning the conformers that have near identical pocket shapes, which is done using simple bit operations. We tested our approach by modelling the active-site inhibitor binding pockets of matrix metalloproteinase-1 and -13. For both cases, analyzing the conformers based on their pocket shapes substantially reduced the 'computational complexity' (10 to 190 fold). The subsequent clustering revealed that the pocket shapes of both proteins could be grouped into approximately 10 distinct clusters. At this level of clustering, the conformational space spanned by the known crystal structures was well covered. Heatmap analysis identified a few bit blocks that combinatorially dictated the clustering pattern. Using this analytical approach, we demonstrated that each of the bit blocks was associated with a specific pocket residue. Identification of residues that influenced the shape of the pocket is an interesting feature unique to the ROTAIMAGE algorithm. ROTAIMAGE is a novel algorithm that was efficient in exploring the conformational space of the ligand binding site. Its ability to identify 'key' pocket residues also provides further insight into conformational flexibility with specific implications for protein-ligand interactions.	binary image;binding sites;brute-force search;cluster analysis;combinatorial search;computational complexity theory;crystal structure;hl7publishingsubsection <operations>;heatmap;interaction;internet backbone;interstitial collagenase;ligand binding domain;pocket pc;sampling (signal processing);sampling - surgical action;staphylococcal protein a;vertebral column;algorithm;ligands activity;statistical cluster	Edon Sung;Sangsoo Kim;Whanchul Shin	2009		10.1186/1471-2105-11-256	biology;protein structure;structure–activity relationship;dna microarray;binary image;bioinformatics;crystal structure;binding site;active site;brute-force search;ligand;ligand;matrix metalloproteinase;drug design	Comp.	9.828642160869004	-58.343396877255316	39397
9cd7eaea5a3884d2b2046fe0ac5bf70aa39d5617	decoding the nonstationary neural activity in motor cortex for brain machine interfaces	motor cortex;non stationary;brain machine interfaces bmis;general regression neural network grnn	Previous decoding algorithms used in brain machine interfaces (BMIs) usually seek a static functional mapping between the spatio-temporal neural activity and behavior and assume that the neural spike statistics do not change over time. However, recent work indicates the significant variance in neural activities, which suggests the nonfeasibility of the stationary assumptions on the neural signal sequences. To track the time-changing neural activity during the nonlinear decoding process, we developed a time-varying approach based on general regression neural network (GRNN) with a dynamic pattern layer. Applied on both simulated neural activity and in vivo BMI data extracted from rat's motor cortex, the proposed method reconstructs the movement signals better than the original GRNN algorithm with static pattern layer, which raises the promise of successfully tracking the time-varying neural activity for BMIs decoding. © 2011 Wiley Periodicals, Inc. Int J Imaging Syst Technol, 21, 158–164, 2011#R##N##R##N#(National Natural Science Foundation of China (No. 60873125, 30800287, 61031002, 61001172), the Zhejiang Provincial Natural Science Foundation of China (No. Y2090707) the Fundamental Research Funds for the Central Universities, and Specialized Research Fund for the Doctoral Program of Higher Education.)		Shaomin Zhang;Yuxi Liao;Xiaoxiang Zheng;Weidong Chen;Yiwen Wang	2011	Int. J. Imaging Systems and Technology	10.1002/ima.20281	neural decoding;computer science;artificial intelligence;machine learning;time delay neural network	ML	22.503258319761027	-73.83485562489123	39406
adf06a1cfa4aeebb89a806137b7b4b75f4a4d443	a minimal model of tumor growth inhibition in combination regimens under the hypothesis of no interaction between drugs	pharmacodynamic models;drugs;drugs tumors mathematical model compounds probability density function equations mice;mice;compounds;cancer;tumours cancer drugs;probability density function;animals antineoplastic agents cell line tumor drug discovery drug interactions humans mice models biological neoplasms experimental xenograft model antitumor assays;tumours;simeoni tgi model tumor growth inhibition combination regimen anticancer drug xenograft mice synergic compounds antagonist compounds;xenograft mice anticancer drug discovery drug combination regimen pharmacodynamic models poisson models preclinical studies stochastic models tumor growth models;tumor growth models;preclinical studies;tumors;mathematical model;drug combination regimen;anticancer drug discovery;poisson models;xenograft mice;stochastic models	One important issue in the preclinical development of an anticancer drug is the assessment of the compound under investigation when administered in combination with other drugs. Several experiments are routinely conducted in xenograft mice to evaluate if drugs interact or not. Experimental data are generally qualitatively analyzed on empirical basis. The ability of deriving from single drug experiments a reference response to the joint administrations, assuming no interaction, and comparing it to real responses would be key to recognize synergic and antagonist compounds. Therefore, in this paper, the minimal model of tumor growth inhibition (TGI), previously developed for a single drug, is reformulated to account for the effects of noninteracting drugs and simulate, under this hypothesis, combination regimens. The model is derived from a minimal set of basic assumptions that include and extend those formulated at cellular level for the single drug administration. The tumor growth dynamics is well approximated by the deterministic evolution of its expected value that is obtained through the solution of an ordinary and several partial differential equations. Under suitable assumptions on the cell death process, the model reduces to a lumped parameter model that represents the extension of the very popular Simeoni TGI model to the combined administration of noninteracting drugs.	approximation algorithm;cell death;cessation of life;experiment;lumped element model;neoplasms;population parameter;simulation;synergy;xenograft type of graft;pediatric intracranial germ cell brain tumor	Paolo Magni;Nadia Terranova;Francesca Del Bene;Massimiliano Germani;Giuseppe De Nicolao	2012	IEEE Transactions on Biomedical Engineering	10.1109/TBME.2012.2197680	pharmacology;probability density function;medicine;toxicology;stochastic modelling;pre-clinical development;mathematical model;mathematics;biological engineering;statistics;cancer	Comp.	10.150139710034082	-69.44267735206523	39416
5203d51042cbe23c8a9510d8b000ca8b404ce6db	machine learning techniques and the existence of variant processes in humans declarative memory		This work uses supervised machine learning methods over fMRI brain scans to establish the existence of two different encoding procedures for human declarative memory. Declarative knowledge refers to the memory for facts and events and initially depends on the hippocampus. Recent studies which used patients with hippocampal lesions and neuroimaging data, suggested the existence of an alternative process to form declarative memories. This process is triggered by learning mechanism called “Fast Mapping (FM)”, as opposed to the ‘standard’ “Explicit Encoding (EE)” learning procedure. The present work gives a clear biomarker on the existence of two distinct encoding procedures as we can accurately predict which of the processes is being used directly from voxel activity in fMRI scans. The scans are taken during retrieval of information wherein the tasks are identical regardless of which procedure was used for acquisition and by that reflect conclusive prediction. This is an identification of a more subtle cognitive task than direct perceptual cognitive tasks as it requires some encoding and processing in the brain.	declarative programming;fm broadcasting;machine learning;supervised learning;voxel	Alex Frid;Hananel Hazan;Ester Koilis;Larry M. Manevitz;Maayan Merhav;Gal Star	2015	2015 7th International Joint Conference on Computational Intelligence (IJCCI)		support vector machine;radial basis function kernel;biological classification;computer science;artificial intelligence;machine learning;pattern recognition;declarative memory;feature selection	AI	18.430979693072537	-74.74220837192121	39438
7bc6c9b3d966b4f294bf72af9a12018f6fc0d31a	autonomous robot navigation based on clustering across images		The aim of this paper is to present a novel approach to the autonomous robot navigation based on clustering of image descriptors. The descriptor called Speeded-Up Robust Features (SURF) is a scale- and rotation-invariant detector, which can visually navigate a robot in a large outdoor and indoor environment. By incorporating several clustering methods, which are derived from fuzzy set theory and inspired with biological background, such as Fuzzy C-mean (FCM), Kohonen’s Self-Organizing Map (SOM) and Neural Gas algorithm (NG), we detect center positions of natural clusters crosswise the recorded images. Center positions represented by vector prototypes are used as reference points in the decision making of the robot navigation.		Tomas Vintr;Lukáš Pastorek;Hana Rezanková	2011		10.1007/978-3-642-21975-7_27	computer vision;avm navigator;mobile robot navigation	Robotics	24.404765440167026	-63.5201679597111	39443
863e87519a0cdaca978efe467d047ffd8ddab05b	finding the region of pseudo-periodic tandem repeats in biological sequences	health research;uk clinical guidelines;biological patents;europe pubmed central;citation search;physiological cellular and medical topics;computational biology bioinformatics;uk phd theses thesis;human genome;life sciences;tandem repeat;algorithms;sequence analysis;uk research reports;medical journals;europe pmc;biomedical research;bioinformatics	The genomes of many species are dominated by short sequences repeated consecutively. It is estimated that over 10% of the human genome consists of tandemly repeated sequences. Finding repeated regions in long sequences is important in sequence analysis. We develop a software, LocRepeat, that finds regions of pseudo-periodic repeats in a long sequence. We use the definition of Li et al. [1] for the pseudo-periodic partition of a region and extend the algorithm that can select the repeated region from a given long sequence and give the pseudo-periodic partition of the region. LocRepeat is available at http://www.cs.cityu.edu.hk/~lwang/software/LocRepeat	genome;lithium;pseudo brand of pseudoephedrine;sequence analysis;tandem repeat sequences;algorithm	Xiaowen Liu;Lusheng Wang	2006	Algorithms for Molecular Biology	10.1186/1748-7188-1-2	biology;human genome;bioinformatics;direct repeat;sequence analysis;tandem repeat	Comp.	0.7291331411987204	-56.13515428618943	39471
3f6ad13025612db3931c5aedb38eb2bbe63c2be5	recoverable one-dimensional encoding of three-dimensional protein structures	estructura 3 dimensiones;proteine;structure secondaire;amino acid sequence;simulation;molecular dynamics;simulacion;taille;simulated annealing;satisfiability;three dimensional;molecular dynamic simulation;structure 3 dimensions;dynamique moleculaire;protein structure;estructura secundaria;structure moleculaire;protein structure prediction;secondary structure;talla;time use;number;proteina;three dimensional structure;dinamica molecular;nombre;protein;estructura molecular;size;3d structure;numero;molecular structure	One-dimensional (1D) structures of proteins such as secondary structure and contact number provide intuitive pictures to understand how the native three-dimensional (3D) structure of a protein is encoded in the amino acid sequence. However, it is still not clear whether a given set of 1D structures contains sufficient information for recovering the underlying 3D structure. Here we show that the 3D structure of a protein can be recovered from a set of three types of 1D structures, namely, secondary structure, contact number and residue-wise contact order which is introduced here for the first time. Using simulated annealing molecular dynamics simulations, the structures satisfying the given native 1D structural restraints were sought for 16 proteins of various structural classes and of sizes ranging from 56 to 146 residues. By selecting the structures best satisfying the restraints, all the proteins showed a coordinate RMS deviation of <4 A from the native structure, and, for most of them, the deviation was even <2 A. The present result opens a new possibility to protein structure prediction and our understanding of the sequence-structure relationship.	amino acid sequence;amino acids;class;contact order;molecular dynamics;protein structure prediction;schedule (computer science);simulated annealing;simulation;staphylococcal protein a	Akira R. Kinjo;Ken Nishikawa	2005	Bioinformatics	10.1093/bioinformatics/bti330	threading;biology;three-dimensional space;protein structure;molecular dynamics;combinatorics;simulated annealing;numero sign;molecule;bioinformatics;protein structure prediction;mathematics;peptide sequence;size;grammatical number;algorithm;protein secondary structure;satisfiability	Comp.	11.964993688508521	-61.69689657583183	39481
3e3d54c5d5c6a0bdda665565e64d9f6bb0b13d7e	plantqtl-ge: a database system for identifying candidate genes in rice and arabidopsis by gene expression and qtl information	genes;microarray data;quantitative trait loci;database system;plants;web interface;databases genetic;gene expression data;oryza sativa;arabidopsis thaliana;genetic marker;gene expression;internet;system integration;genome;arabidopsis;genes plant;user computer interface;candidate disease gene;gene function;genetic markers;expressed sequence tag;gene expression profiling;expressed sequence tags;candidate gene;rice	We have designed and implemented a web-based database system, called PlantQTL-GE, to facilitate quantitatine traits locus (QTL) based candidate gene identification and gene function analysis. We collected a large number of genes, gene expression information in microarray data and expressed sequence tags (ESTs) and genetic markers from multiple sources of Oryza sativa and Arabidopsis thaliana. The system integrates these diverse data sources and has a uniform web interface for easy access. It supports QTL queries specifying QTL marker intervals or genomic loci, and displays, on rice or Arabidopsis genome, known genes, microarray data, ESTs and candidate genes and similar putative genes in the other plant. Candidate genes in QTL intervals are further annotated based on matching ESTs, microarray gene expression data and cis-elements in regulatory sequences. The system is freely available at http://www.scbit.org/qtl2gene/new/.	accessibility;candidate disease gene;candidate gene identification;data sources;database;eaf2 gene;expressed sequence tags;gene expression;genetic markers;interface device component;locus;matching;microarray;oryza (plant);quantitative trait loci;user interface;web application	Huazong Zeng;Lijun Luo;Weixiong Zhang;Jie Zhou;Zuofeng Li;Hongyan Liu;Tiansheng Zhu;Xiangqian Feng;Yang Zhong	2007		10.1093/nar/gkl814	biology;molecular biology;family-based qtl mapping;bioinformatics;genetic marker;genetics;expressed sequence tag	Comp.	-1.7583288959620138	-59.46261942219009	39530
9a42f59c7fd25d71c426bec9dae38efacf7ddc87	brain as a self-predictor: sparse full-brain auto-regressive modeling in fmri	brain;fmri;granger causality;brain models;active region;sparse full brain autoregressive modeling;auto regressive;fmri data;autoregressive model;physiological models biomedical mri brain data acquisition medical image processing neurophysiology;default mode networks self predictor sparse full brain autoregressive modeling fmri data baseline methods general linear model complex interactions;accuracy;functional connectivity;computational modeling;maximum likelihood estimate;baseline methods;medical image processing;self predictor;probability distribution;complex interactions;general linear model;predictive models;default mode network;functional connectivity autoregressive modeling fmri granger causality prediction;neurophysiology;autoregressive modeling;system of equations;predictive models accuracy data models computational modeling brain models;data acquisition;prediction;physiological models;default mode networks;data models;biomedical mri	We demonstrate a method to build an autoregressive model for the whole brain without carrying out any aggregation of the fMRI data. The model gives biologically meaningful results and has several desirable properties. We show that the model gives significantly improved prediction on unseen data as compared to baseline methods. The voxels with better prediction are distributed throughout the brain, including the task positive and task negative regions. In addition to the active regions identified by the general linear model (GLM), our analysis also uncovers complex interactions among the regions involved in the default mode networks.	autoregressive model;baseline (configuration management);general linear model;generalized linear model;interaction;kerrison predictor;voxel	Rahul Garg;Guillermo A. Cecchi;A. Ravishankar Rao	2011	2011 IEEE International Symposium on Biomedical Imaging: From Nano to Macro	10.1109/ISBI.2011.5872704	econometrics;computer science;machine learning;mathematics;autoregressive model;neurophysiology;statistics	Vision	24.285486367535373	-76.92833306327816	39585
38aae84d78b111692c2a90ac7bf679b576a294ee	metabolic networks analysis using convex optimization	genomics;optimisation;control theory;metabolic network;bepress selected works;cellular system;biological system modeling;minimal knockout problem metabolic networks analysis convex optimization biochemical reactions chemical substances metabolites concentrations minimal network problem;enzyme;genetic regulatory network;reaction rate;convex optimization;product line;biochemistry production systems biology bioinformatics genomics cells biology biological system modeling cellular networks organisms steady state;chemical substances;minimal network problem;optimisation biochemical reactions chemical substances convex optimization metabolic networks analysis metabolites concentrations minimal knockout problem minimal network problem;metabolic networks analysis;large scale;standard model;molecular biology;requirement engineering;protein protein interaction;system biology;mathematical model;production;minimal knockout problem;optimization;biochemical reactions;convex relaxation;network structure;gene regulatory network;biochemistry;metabolites concentrations;biological process;bioinformatics	Metabolic networks map the biochemical reactions in a living cell to the flow of various chemical substances in the cell, which are called metabolites. A standard model of a metabolic network is given as a linear map from the reaction rates to the change in metabolites concentrations. We study two problems related to the analysis of metabolic networks, the minimal network problem and the minimal knockout problem.	convex optimization;knockout;mathematical optimization;regular expression	Anak Agung Julius;Marcin Imielinski;George J. Pappas	2008	2008 47th IEEE Conference on Decision and Control	10.1109/CDC.2008.4739111	protein–protein interaction;standard model;enzyme;gene regulatory network;genomics;convex optimization;bioinformatics;reaction rate;mathematical model;biological process;metabolic network	Vision	6.260056198727996	-61.135819970254495	39727
498643d26c61828b168b5cfa2d17b02a78401d77	translational bioinformatics and computational systems medicine	animals;systems biology;translational medical research;humans;computational biology	Copyright © 2013 Bairong Shen et al. This is an open access article distributed under the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited. This special issue is dedicated to Translational bioinformatics and Computational Systems Medicine. Translational biomed-ical informatics is a rapidly emerging discipline to integrate data from medical research, biotechnologies, and electronic medical records, and computational systems medicine is to apply computational and systems biology approaches to solve complex problems in medical research, aiming to improve the diagnosis, prognosis, and treatment of complex diseases. It is also well known that their development needs an integration of mathematical models, statistical methods, and computer algorithms. Complex diseases such as cancers are coursed by a combination of genetic, environmental, and lifestyle factors, and thus the research of complex diseases at a system level like gene sets, pathway level, or static/dynamic network is a necessity. T. Holden et al. present an exploratory bioinformat-ics study of long noncoding RNA in Alzheimer's disease. The authors also discuss the model for drug development based on fractal dimension and entropy correlation in this study consistent with a zebrafish model and a mouse model. M. Ding et al. explore the genome-wide chromatin localization of Estrogen receptor-DNA binding regions by analyzing ChIP-Seq data from MCF-7 breast cancer cell line. It reveals novel Estrogen receptor-regulated genes pathways for further experimental validation. Y.-w. Lv et al. perform gene ontology category and pathways analysis for relationships among statistically significant genes in Kawasaki disease. The importance of compelling immune pathway of NF-AT signal and leukocyte interactions combined with another transcription factor NF-í µí¼B in the pathogenesis of KD is investigated by network analysis. J. Chen et al. perform two case studies on colorectal and prostate cancer microarray datasets to proof two hypotheses that (1) the expression signatures of different cancer microarray datasets are more similar at pathway level than at gene level; (2) the comparability of the cancer molecular mechanisms of different individuals is related to their genetic similarities. The concept of entropy suggests that systems naturally progress from order to disorder. Entropy-based methods provide a novel insight into understanding many phenomena in biological systems. V. Oswal et al. present an automated entropy-based thresholding system for segmentation and quantification of cell nuclei from histologically stained images. The contributions to the application of this entropy-based system to detect cancerous cell nuclei …	alzheimer's disease;antivirus software;bioinformatics;biological system;biomed 101;biotechnology;cell nucleus;copyright;electronic health records;entity–relationship model;entropy (information theory);estrogens;fractal dimension;gene ontology;gene regulatory network;informatics (discipline);interaction;leukocytes;license;malignant neoplasms;mammary neoplasms;mathematical model;mathematics;medical records systems, computerized;microarray;network theory;paget's disease, mammary;prostatic neoplasms;quantitation;statistical model;sudoku solving algorithms;systems biology;systems medicine;transcription factor;thresholding (image processing);transcription (software);word lists by frequency;algorithm;cancer cell;dna binding;drug development;ical	Bairong Shen;Hong-Bin Shen;Tianhai Tian;Qiang Lv;Guang Hu	2013		10.1155/2013/375641	psychology;computational biology;biology;simulation;medicine;pathology;computer science;bioinformatics;machine learning;nanotechnology;mathematics;genetics;systems biology;algorithm	Comp.	5.058695759064803	-67.7409315922429	39740
ca55335deca20eca9e7ab67d732ce621820caf60	pulse-type neuro devices with spike timing dependent synaptic plasticity	time dependent;synaptic plasticity	Even though the neurons in the human brain are sensitive to noises, human central nervous systems can operate correctly under a noisy environment. Since neural networks have superior information processing functions, many investigators have attemptted to model biological neurons and neural networks. A number of recent studies of neural networks have been conducted with the purpose of applying engineering to the brain. Especially, neuro devices have been created that focus on how to have a learning function. Here, we focus on spike timing dependent synaptic plasticity (STDP) and construct pulse-type neuro devices with STDP using analog VLSI technology. We show that it is possible to extract phase differences representing the reinforcement part of the synaptic weight by using pulse-type neuro devices with STDP. Moreover, we investigate noise tolerance for thermal noise and fluctuation of time.	artificial neural network;information processing;integrated circuit;johnson–nyquist noise;quantum fluctuation;synaptic package manager;synaptic weight;very-large-scale integration;white noise	Katsutoshi Saeki;Yugo Hayashi;Yoshifumi Sekine	2008			synaptic fatigue;synaptic plasticity;developmental plasticity;homosynaptic plasticity;neuroscience;synaptic augmentation;computer science;homeostatic plasticity;neural facilitation;metaplasticity;nonsynaptic plasticity;synaptic scaling	ML	19.29163477892509	-70.35640257045881	39774
08edf3d5a787b9f6a4caf27b29a51b5815cb7774	pattern recognition with figure-ground separation by generation of coherent oscillations	oscillations;synchronization;pattern recognition;figure and ground;dynamical linking	For elucidating the computation theory underlying flexible recognition of visual patterns by an oscillating neural network of the brain, a model with two dynamical centers was presented and the capability of the model was demonstrated with computer experiments. One of the two dynamical centers, the center for figure organization, organizes figures from elementary visual signals by self-organizing coherent dynamics of neural oscillators, being separated from background represented by incoherent dynamics. The other center, the center for symbol formation, provides symbolic constraints to the dynamics of the former center to define the boundaries of the figures according to memory. Synchronized oscillations also emerge in the latter center by neural oscillators encoding elementary symbols constituting memory items. The linkers connecting the two centers are dynamically gated to generate correspondence between the symbol and the figure. Information circulation emerges between the two centers due to synchronization through linkers. It enables the pattern recognition in the presence of background independent of size, position, and some deformation.	coherence (physics);pattern recognition	Yoko Yamaguchi;Hiroshi Shimizu	1994	Neural Networks	10.1016/0893-6080(94)90055-8	synchronization;computer science;artificial intelligence;theoretical computer science;figure–ground;oscillation	ML	20.34919385881691	-68.19202360998372	39783
f523e8a14e6e305e699a92e846d245a08c73e538	computer programs for eukaryotic gene prediction	computer program;gene prediction	Seven popular programs for gene prediction in eukaryotic organisms are described and evaluated on the basis of availability for in-house and on-line use and prediction accuracy. This report outlines generally applicable approaches to computational gene prediction and known limitations in this field.	gene prediction;online and offline;outlines (document)	V. Makarov	2002	Briefings in bioinformatics	10.1093/bib/3.2.195	biology;computer science;bioinformatics;data science;data mining;gene prediction	Comp.	0.01698801390758857	-57.64252728452965	39792
913125e41344fe3dd5fe6c2c93ca0df8d5a62ba6	compression of nucleotide databases for fast searching	dna;optimisation;base donnee;data compression;optimizacion;homology search;computerized processing;tratamiento informatico;nucleotides;database;base dato;secuencia nucleotido;nucleotide sequence;sequence nucleotide;algorithme;algorithm;optimization;compresion dato;traitement informatique;data retrieval;high speed;compression donnee;algoritmo	MOTIVATION International sequencing efforts are creating huge nucleotide databases, which are used in searching applications to locate sequences homologous to a query sequence. In such applications, it is desirable that databases are stored compactly, that sequences can be accessed independently of the order in which they were stored, and that data can be rapidly retrieved from secondary storage, since disk costs are often the bottleneck in searching.   RESULTS We present a purpose-built direct coding scheme for fast retrieval and compression of genomic nucleotide data. The scheme is lossless, readily integrated with sequence search tools, and does not require a model. Direct coding gives good compression and allows faster retrieval than with either uncompressed data or data compressed by other methods, thus yielding significant improvements in search times for high-speed homology search tools.	alistair sinclair;auxiliary memory;biopolymer sequencing;canonical huffman code;computer data storage;data compression;databases;homologous gene;homology (biology);huffman coding;in-memory database;lossless compression;megabyte;nucleotides;overhead (computing);personality character;published database;question (inquiry);requirement;the australian;wildcard character	Hugh E. Williams;Justin Zobel	1997	Computer applications in the biosciences : CABIOS	10.1093/bioinformatics/13.5.549	data compression;biology;nucleotide;nucleic acid sequence;computer science;bioinformatics;theoretical computer science;genetics;data retrieval;dna;algorithm	DB	-3.6949897650799572	-53.573762125980274	39841
16a9221efdf0db86e7024d91f17edb185bf6603f	scalability of a genomic data analysis in the biotest platform		BioTest platform is dedicated for the processing of biomedical data that originate from various measurement techniques. This includes next-generation sequencing (NGS), that focuses the attention of researchers all of the world due to its broad possibilities in determining the structure of the DNA and RNA. However, the analysis of data provided by NGS requires large disk space, and is time-consuming, becoming a challenge for the data processing systems. In this paper, we have analyzed the possibility of scaling the BioTest platform in terms of genomic data analysis and platform architecture. Scalability tests were carried out using next-generation sequencing data and relied on methods for detection of somatic mutations and polymorphisms in the human DNA. Our results show that the platform is scalable, allowing to significantly reduce the execution time of performed calculations. However, the scalability capabilities depend on the experiment methodology and homogeneity of resources required by each task, which in NGS studies can be highly variable.	scalability	Krzysztof Psiuk-Maksymowicz;Dariusz Mrozek;Roman Jaksik;Damian Borys;Krzysztof Fujarewicz;Andrzej Swierniak	2017		10.1007/978-3-319-54430-4_71	data mining;homogeneity (statistics);architecture;scalability;computer science;data processing system;data analysis;bioinformatics	Theory	-2.0711389890337397	-54.151527400338836	39881
4d8bb9f72e93edfbe544d4f687d38f281c9a6249	the failure of the law of brevity in two new world primates. statistical caveats		Ramon Ferrer-i-Cancho Antoni Hernández-Fernández Abstract: Parallels of Zipf’s law of brevity, the tendency of more frequent words to be shorter, have been found in bottlenose dolphins and Formosan macaques. Although these findings suggest that behavioral repertoires are shaped by a general principle of compression, common marmosets and golden-backed uakaris do not exhibit the law. However, we argue that the law may be impossible or difficult to detect statistically in a given species if the repertoire is too small, a problem that could be affecting golden backed uakaris, and show that the law is present in a subset of the repertoire of common marmosets. We suggest that the visibility of the law will depend on the subset of the repertoire under consideration or the repertoire size.	parallels desktop for mac;zipf's law	Ramon Ferrer-i-Cancho;Antoni Hernández-Fernández	2012	CoRR	10.1524/glot.2013.0004	communication	HCI	3.1966240258458316	-62.015963242386334	39901
d4cbc0d7e54754eef78133ecf3893f448baa65d4	unsupervised learning of spatio-temporal patterns using spike timing dependent plasticity		This paper presents an unsupervised approach for learning of patterns with spatial and temporal information from a very small number of training samples. The method employs a spiking network with axonal conductance delays that learns the encoding of individual patterns as sets of polychronous neural groups, which emerge as a result of training. A similarity metric between sets, based on a modified version of the Jaccard index, is used for pattern classification. Two different neural connectivity models are evaluated on a data set consisting of hand-drawn digits that encode temporal information (i.e., from the starting to the end point of the digit). The results demonstrate that the approach can successfully generalize these patterns from a significantly small number of training samples.	conductance (graph);encode;jaccard index;unsupervised learning	Banafsheh Rekabdar;Monica N. Nicolescu;Richard Kelley;Mircea Nicolescu	2014		10.1007/978-3-319-09274-4_28	artificial intelligence;machine learning;synaptic plasticity;computer science;encoding (memory);conductance;jaccard index;small number;unsupervised learning;spike-timing-dependent plasticity	ML	19.945447006059293	-66.38538433372572	39912
3d2e0451e21f6b6aae7da81f09ac836338926d50	a radically new theory of how the brain represents and computes with probabilities		It is widely acknowledged that the brain i) implements probabilistic reasoning, and ii) represents information via population/distributed coding. Most previous population-based probabilistic (PPC) theories share several basic properties: 1) continuous (graded) neurons; 2) fully/densely-distributed coding, i.e., all/most coding field neurons formally participate in every code; 3) graded synapses; 4) rate coding; individual neurons are assumed to 5) have unimodal, e.g., bell-shaped, tuning functions (TFs) and 6) be fundamentally noisy; and 7) noise/correlation are generally viewed as problems requiring mitigation. In contrast, our theory assumes: 1) binary neurons; 2) only a small subset of neurons, i.e., a sparse distributed code (SDC), comprises any individual code; 3) binary synapses; 4) signaling formally requires only single, i.e., first, spikes; individual neurons 5) initially have completely flat TFs (all weights zero) and 6) are not noisy; and 7) noise is a resource generated and used to achieve the crucial property that more similar inputs map to more similar codes, which controls a tradeoff between storage capacity and embedding the statistics of the input space in the pattern of intersections over the codes, indirectly yielding particular correlation patterns. The theory, Sparsey, was introduced 20 years ago as a canonical cortical circuit/algorithm model, but its interpretation as a probabilistic model was not emphasized. Sparsey’s efficient similarity preserving mechanism yields fixed-time learning and best-match retrieval (inference), i.e., time independent of the number of stored hypotheses (memories). Assuming input similarity correlates with likelihood, which is quite reasonable over large regions of natural input spaces, the active SDC code simultaneously represents both the most probable hypothesis and the probability distribution over all stored hypotheses. We show this for spatial and spatiotemporal (sequential) cases. In the latter case, the entire distribution is updated, on each sequence item, in fixed time. Finally, consistent with moving beyond the Neuron Doctrine to the view that the SDC (cell assembly, ensemble) is the fundamental neural unit of representation/thought, Sparsey suggests that classical unimodal TFs emerge as an artifact of a single/few-trial learning process in which SDC codes are laid down in superposition.	algorithm;artificial neuron;code;hebbian theory;neural coding;secure digital container;smart data compression;sparse matrix;statistical model	Gerard Rinkus	2017	CoRR		combinatorics;discrete mathematics;computer science;theoretical computer science;machine learning;mathematics;statistics	ML	22.836787047738465	-71.87038814420816	39933
def7c45b253228e3f82b306dfdd0a7c6a304390c	retrieval from episodic memory: neural mechanisms of interference resolution	episodic memory;150 psychologie;brain;inhibitory control;long term memory;ddc 150;dorsolateral prefrontal cortex;functional magnetic resonance images;recall psychology;inhibition;cognitive tests;cognitive processes	Selectively retrieving a target memory among related memories requires some degree of inhibitory control over interfering and competing memories, a process assumed to be supported by inhibitory mechanisms. Evidence from behavioral studies suggests that such inhibitory control can lead to subsequent forgetting of the interfering information, a finding called retrieval-induced forgetting [Anderson, M. C., Bjork, R. A., & Bjork, E. L. Remembering can cause forgetting: Retrieval dynamics in long-term memory. Journal of Experimental Psychology: Learning, Memory & Cognition, 20, 1063–1087, 1994]. In the present functional magnetic resonance imaging study, we investigated the neural processes underlying retrieval-induced forgetting and, in particular, examined the extent to which these processes are retrieval (i.e., selection) specific. Participants actively retrieved a subset of previously studied material (selection condition), or were re-exposed to the same material for relearning (nonselection condition). Replicating prior behavioral work, selective retrieval caused significant forgetting of the nonretrieved items on a delayed recall test, relative to the re-exposure condition. Selective retrieval was associated with increased BOLD responses in the posterior temporal and parietal association cortices, in the bilateral hippocampus, and in the dorsolateral prefrontal cortex. Medial and lateral prefrontal areas showed a strong negative linear relationship between selection-related neural activity and subsequent forgetting of competitors. These findings suggest reduced demands on inhibitory control processes when interference is successfully resolved during early selective retrieval from episodic memory.	assumed;bilateral filter;codependency (psychology);cognition disorders;inhibitory nerve control;interference (communication);lateral thinking;magnetic resonance imaging;medial graph;memory disorders;memory, long-term;prefrontal cortex;subgroup;fmri	Maria Wimber;Roland Marcus Rutschmann;Mark W. Greenlee;Karl-Heinz Bäuml	2009	Journal of Cognitive Neuroscience	10.1162/jocn.2009.21043	psychology;cognitive psychology;interference theory;spatial memory;long-term memory;cognition;developmental psychology;childhood memory;semantic memory;explicit memory;memory errors;cognitive test;episodic memory;retrieval-induced forgetting;social psychology;forgetting;reconstructive memory	ML	17.051581750791403	-77.32688329332416	39934
9e436402c2e3d109ebd6d6243e82a9f2e9af1f51	model approach to neurological variants of visuo-spatial neglect	vestibular cortex;visuo spatial neglect;modeling;visual cortex	Neglect is a neurological disorder of spatial attention with reduced awareness of visual stimuli in the hemifield contralateral to an acute temporo-parietal lesion mainly of the right hemisphere. There is a close association of multisensory orientation centers (MSO) and vestibular tonus imbalance. A lesion of the dominant right MSO causes a left-sided neglect due to a lack of ipsilateral activation of the visual cortex, which is further enhanced by increasing inhibition from the contralateral visual cortex. The nondominant MSO in the left hemisphere might be involved in the manifestation of the less frequent and more transient right-sided neglect and in the plastic mechanisms of gradual recovery from left-sided neglect or extinction. There is evidence that a vestibular tonus inbalance due to peripheral or central vestibular pathway lesions may also induce a neglect. In a first model approach using an attractor network and assuming that there is only one MSO in the right hemisphere, it is possible to simulate attentional shifts into a visual hemifield and to induce a neglect. The neural network model consists of four layers of neurons: retina, MSO, visual cortex V1, and superior colliculus. The superior colliculus layer is modeled as a recurrent attractor network with one inhibitory interneuron and synaptic weights chosen to implement a winner-take-all network that centers the hill of activity on the strongest input. We are well aware of the simplifications used in the conceptual drawings and the computational model, but nevertheless hope that they will serve as an inspiration for further modeling and clinical studies.	artificial neural network;cerebral cortex;cervical squamous intraepithelial neoplasia;computation;computational model;corpora quadrigemina, superior colliculus;drawings (art);extinction, psychological;flaccid hemiplegia and hemiparesis affecting nondominant side;gene regulatory network;interneurons;muscle tonus;network model;neurons;peripheral neuropathy;retina;simulation;synaptic package manager;synaptic weight;vestibular diseases;anatomical layer;nervous system disorder;vestibular pathway	Thomas Brandt;Marianne Dieterich;Michael Strupp;Stefan Glasauer	2012	Biological Cybernetics	10.1007/s00422-012-0517-3	psychology;neuroscience;systems modeling;developmental psychology;communication	ML	19.352351804417804	-76.47859739727097	39947
35d965fa4a93cf3ff47fda6b0c234a12ef2bb4fd	a pooling approach to modelling spatial relations for image retrieval and annotation	cs cv;computer science;computer vision and pattern recognition	Over the last two decades we have witnessed strong progress on modeling visual object classes, scenes and attributes that have significantly contributed to automated image understanding. On the other hand, surprisingly little progress has been made on incorporating a spatial representation and reasoning in the inference process. In this work, we propose a pooling interpretation of spatial relations and show how it improves image retrieval and annotations tasks involving spatial language. Due to the complexity of the spatial language, we argue for a learning-based approach that acquires a representation of spatial relations by learning parameters of the pooling operator. We show improvements on previous work on two datasets and two different tasks as well as provide additional insights on a new dataset with an explicit focus on spatial relations.	computer vision;experiment;image retrieval;logic programming;robotics;spatial–temporal reasoning	Mateusz Malinowski;Mario Fritz	2014	CoRR		computer vision;computer science;machine learning;pattern recognition;data mining	Vision	23.752280696150397	-53.932495211024744	39948
ea663efd8b8a5408c36fa439caca20290b3700ed	approaches to the analysis of proteomics and transcriptomics data based on statistical methodology			proteomics	Marcin Siatkowski	2014				EDA	1.0055969141307803	-64.15450169393834	40066
00370c4baf2a570f2ca812c37d1ee299bc77a89f	am i safe? the ventrolateral prefrontal cortex ‘detects’ when an unpleasant event does not occur	somatosensory event related potential;contingency establishment;source analysis;high resolution;pedestrian safety;poison control;time course;current source density;injury prevention;somatosensory system;safety literature;event related potential;traffic safety;injury control;home safety;prefrontal cortex;injury research;safety abstracts;human factors;occupational safety;safety;lateralization;safety research;accident prevention;violence prevention;bicycle safety;electroencephalography;ventrolateral prefrontal cortex;poisoning prevention;falls;ergonomics;suicide prevention	"""The ventrolateral prefrontal cortex (VLPFC) is implicated in contingency detection and the evaluation of emotionally significant stimuli. However, the mechanisms whereby an individual can effectively avoid painful or unpleasant events are not well understood. We therefore examined whether the absence of an unpleasant somatosensory stimulus could evoke a response in the human VLPFC as a correlate of contingency detection (the feeling that """"I am safe"""") without any immediately preceding stimulus. In a differential trace-conditioning paradigm, the unpleasant stimulus followed the partially reinforced stimulus in 50% of trials after 3 s; it never occurred after the nonreinforced stimulus. High-resolution DC electroencephalography, current source density mapping, and spatio-temporal source analysis were performed. After the nonreinforced stimulus, a highly significant negativity over the VLPFC began about a second after the time for the unpleasant stimulus to occur had passed. We concluded that the VLPFC can be activated merely by a sequence of stimuli (with long interstimulus intervals) without any directly preceding stimulus, provided that this sequence creates the expectation that at a certain time an unpleasant stimulus might occur. This mechanism might allow for the detection of conditions under which harmful events could be avoided. Moreover, in reinforced trials, we found a highly significantly lateralized negativity (N700) that outlasted the strong, unpleasant somatosensory stimulus for about a second. Topography and source analysis pointed to prolonged activation of the somatosensory system. This processing stage preceded activation of the VLPFC. We concluded that N700 might provide important insights into the time course of somatosensory memory traces."""	appendix;conditioning (psychology);current source device component;electroencephalography;memory disorders;modality (human–computer interaction);negativity (quantum mechanics);programming paradigm;topography;tracing (software);unpleasant horse;ventrolateral prefrontal cortex	Stephan Bender;Stefanie Hellwig;Franz Resch;Matthias Weisbrod	2007	NeuroImage	10.1016/j.neuroimage.2007.07.044	psychology;event-related potential;neutral stimulus;neuroscience;image resolution;lateralization of brain function;electroencephalography;suicide prevention;human factors and ergonomics;injury prevention;stimulus control;communication;social psychology;somatosensory system	ML	15.963986235885908	-78.37243336309812	40083
5dce3e1ba8a1093461998c6849c531e502d87f8d	replacing supervised classification learning by slow feature analysis in spiking neural networks	unsupervised learning;supervised learning;supervised classification;fixed point;spiking neural network;neural system;recurrent network;limit cycle;spike train;firing pattern;slow feature analysis	It is open how neurons in the brain are able to learn without supervision to discriminate between spatio-temporal firing patterns of presynaptic neurons. We show that a known unsupervised learning algorithm, Slow Feature Analysis (SFA), is able to acquire the classification capability of Fisher’s Linear Discriminant (FLD), a powerful algorithm for supervised learning, if temporally adjacent samples are likely to be from the same class. We also demonstrate that it enables linear readout neurons of cortical microcircuits to learn the detection of repeating firing patterns within a stream of spike trains with the same firing statistics, as well as discrimination of spoken digits, in an unsupervised manner.	algorithm;artificial neural network;linear discriminant analysis;spiking neural network;supervised learning;unsupervised learning	Stefan Klampfl;Wolfgang Maass	2009			semi-supervised learning;unsupervised learning;computer science;artificial intelligence;machine learning;linear classifier;pattern recognition;fixed point;supervised learning;limit cycle;spiking neural network	ML	19.65776288931159	-66.06632477830057	40130
1d45cb8d601fa2f8410c2b4b3f3cb34b75389484	investigating the association between sociodemographic factors and lung cancer risk using cyber informatics	computers;cancer;linkedin;lungs;maintenance engineering;indexes	Openly available online sources can be very valuable for executing in silico case-control epidemiological studies. Adjustment of confounding factors to isolate the association between an observing factor and disease is essential for such studies. However, such information is not always readily available online. This paper suggests natural language processing methods for extracting socio-demographic information from content openly available online. Feasibility of the suggested method is demonstrated by performing a case-control study focusing on the association between age, gender, and income level and lung cancer risk. The study shows stronger association between older age and lower socioeconomic status and higher lung cancer risk, which is consistent with the findings reported in traditional cancer epidemiology studies.	carcinoma of lung;epidemiologic studies;informatics (discipline);natural language processing;neoplasms;cancer epidemiology	Hong-Jun Yoon;Georgia D. Tourassi	2016	2016 IEEE-EMBS International Conference on Biomedical and Health Informatics (BHI)	10.1109/BHI.2016.7455958	medicine;pathology;data mining;biological engineering	SE	5.006006627721818	-72.5367841875599	40132
c944acb393686fbc2fdad729d06c004e01cd2ef6	phenopolis: an open platform for harmonization and analysis of genetic and phenotypic data		Summary Phenopolis is an open-source web server providing an intuitive interface to genetic and phenotypic databases. It integrates analysis tools such as variant filtering and gene prioritization based on phenotype. The Phenopolis platform will accelerate clinical diagnosis, gene discovery and encourage wider adoption of the Human Phenotype Ontology in the study of rare genetic diseases.   Availability and Implementation A demo of the website is available at https://phenopolis.github.io . If you wish to install a local copy, source code and installation instruction are available at https://github.com/phenopolis . The software is implemented using Python, MongoDB, HTML/Javascript and various bash shell scripts.   Contact n.pontikos@ucl.ac.uk.   Supplementary information Supplementary data are available at Bioinformatics online.		Nikolas Pontikos;Jing Yu;Ismail Moghul;Lucy Withington;Fiona Blanco-Kelly;Tom Vulliamy;Tsz Lun Ernest Wong;Cian Murphy;Valentina Cipriani;Alessia Fiorentino;Gavin Arno;Daniel Greene;Julius O. B. Jacobsen;Tristan Clark;David S. Gregory;Andrea M. Nemeth;Stephanie Halford;Chris F. Inglehearn	2017	Bioinformatics	10.1093/bioinformatics/btx147	world wide web;data mining;javascript;shell script;source code;open platform;software;python (programming language);bioinformatics;human phenotype ontology;computer science;web server	Comp.	-3.6839913167194753	-59.45025432974352	40134
50ed971a2b05f303251f9d373856652aa303fdb7	organization of the core respiratory network: insights from optogenetic and modeling studies		The circuit organization within the mammalian brainstem respiratory network, specifically within and between the pre-Bötzinger (pre-BötC) and Bötzinger (BötC) complexes, and the roles of these circuits in respiratory pattern generation are continuously debated. We address these issues with a combination of optogenetic experiments and modeling studies. We used transgenic mice expressing channelrhodopsin-2 under the VGAT-promoter to investigate perturbations of respiratory circuit activity by site-specific photostimulation of inhibitory neurons within the pre-BötC or BötC. The stimulation effects were dependent on the intensity and phase of the photostimulation. Specifically: (1) Low intensity (≤ 1.0 mW) pulses delivered to the pre-BötC during inspiration did not terminate activity, whereas stronger stimulations (≥ 2.0 mW) terminated inspiration. (2) When the pre-BötC stimulation ended in or was applied during expiration, rebound activation of inspiration occurred after a fixed latency. (3) Relatively weak sustained stimulation (20 Hz, 0.5-2.0 mW) of pre-BötC inhibitory neurons increased respiratory frequency, while a further increase of stimulus intensity (> 3.0 mW) reduced frequency and finally (≥ 5.0 mW) terminated respiratory oscillations. (4) Single pulses (0.2-5.0 s) applied to the BötC inhibited rhythmic activity for the duration of the stimulation. (5) Sustained stimulation (20 Hz, 0.5-3.0 mW) of the BötC reduced respiratory frequency and finally led to apnea. We have revised our computational model of pre-BötC and BötC microcircuits by incorporating an additional population of post-inspiratory inhibitory neurons in the pre-BötC that interacts with other neurons in the network. This model was able to reproduce the above experimental findings as well as previously published results of optogenetic activation of pre-BötC or BötC neurons obtained by other laboratories. The proposed organization of pre-BötC and BötC circuits leads to testable predictions about their specific roles in respiratory pattern generation and provides important insights into key circuit interactions operating within brainstem respiratory networks.	apnea;brain stem;channelrhodopsin;computation;computational biology;computational model;computer simulation;conductance (graph);congenital disorder of glycosylation type 1k;cytology;diphtheria-tetanus vaccine;electric capacitance;experiment;expiration, function;fractal dimension;generalized anxiety disorder;hertz (hz);ik gene;inspiration function;interaction;international unit;intrinsic drive;inverse kinematics;ionic;matlab;mammals;maximal set;membrane potentials;molecular biology;nfkbiz gene;npm1 wt allele;neural ensemble;neuron;neurons;nonlinear system;optogenetics;persistent data structure;population parameter;potassium;rectifier device component;respiratory rate;revision procedure;slc32a1 gene;schematic;scientific publication;sodium;solver;synapse;synaptic package manager;synaptic weight;terminate (software);tissue membrane;xfig;endodeoxyribonuclease syni;glycoprotein gl, varicella-zoster virus;isonitrosoacetophenone;voltage	Jessica Ausborn;Hidehiko Koizumi;William H. Barnett;Tibin T. John;Ruli Zhang;Yaroslav I. Molkov;Jeffrey C. Smith;Ilya A. Rybak	2018		10.1371/journal.pcbi.1006148	biology;neuroscience;bioinformatics;stimulus (physiology);photostimulation;brainstem;respiratory system;population;inhibitory postsynaptic potential;optogenetics;stimulation	ML	17.82051828595273	-72.29144556137025	40141
8ceac8d93d101326342050cf6e41948411b62c53	discover gene specific local co-regulations from time-course gene expression data		Discovering gene co-regulatory relationships is one of most important research in DNA microarray data analysis. The problem of gene specific co-regulation discovery is to, for a particular gene of interest (called target gene), identify the condition subsets where strong gene co-regulations of the target gene are observed and its co-regulated genes in these condition subsets. The co-regulations are local in the sense that they occur in some subsets of full experimental conditions. The study on this problem can contribute to better understanding and characterizing the target gene during the biological activity involved. In this paper, we propose an innovative method for finding gene specific co-regulations using genetic algorithm (GA). A sliding window is used to delimit the allowed length of conditions in which gene co-regulations occur and an ad hoc GA, called the progressive GA, is performed in each window position to find those condition subsets having high fitness. It is called progressive because the initial population for the GA in a window position inherits the top-ranked individuals obtained in its preceding window position, enabling the GA to achieve a better accuracy than the nonprogressive algorithm. kNN Lookup Table is utilized to substantially speed up fitness evaluation in the GA. Experimental results with a real-life gene expression data demonstrate the efficiency and effectiveness of our technique in discovering gene specific co-regulations.	black box;blowout;cluster analysis;computation;computational biology;computer science;dna microarray;evolutionary algorithm;experiment;general-purpose modeling;genetic algorithm;hoc (programming language);lookup table;performance evaluation;programming paradigm;progressive scan;random search;real life;scalability;software release life cycle	Ji Zhang;Qigang Gao;Hai H. Wang	2008	Scientific Programming	10.3233/SPR-2008-0243	bioinformatics;data mining	Comp.	2.1629556312246616	-55.03728816328885	40154
24e8101f7e946a5c2f66c3bfceb4c7e9751f3283	atp hydrolysis activity of the dead box protein rok1p is required for in vivo rok1 function	rna helicases;escherichia coli;saccharomyces cerevisiae;protein family;amino acid;amino acid sequence;saccharomyces cerevisiae proteins;dead box rna helicases;single stranded;enzyme activation;adenosine triphosphate;escherichia coli proteins;rna ribosomal;rna binding domain;rna helicase a;mutation;ion exchange;fungal proteins	The yeast ROK1 gene has been initially identified as a high copy plasmid suppressor of the kem1 null mutation and implicated in microtubule-mediated functions. Based on the deduced amino acid sequence of the ROK1 gene, Rok1p has been classified in the DEAD protein family of ATP-dependent RNA helicases. A subsequent report has suggested that Rok1p is required for rRNA processing. We report here the first study on the biochemical activity associated with Rok1p. The MBP-Rok1 hybrid protein was synthesized in Escherichia coli and purified by amylose affinity column and ion exchange chromatography. Rok1p has ATP hydrolysis activity. The significance of the conserved ATPase domains was addressed by generating a series of amino acid substitution mutations in these domains. Both in vivo lethality tests of the mutations and biochemical characterization of the mutant proteins suggest that ATP hydrolysis activity of Rok1p is essential for ROK1 function. The ATPase activity of Rok1p appears to be independent of single-stranded RNA. Furthermore, replacement of the first Arg in the HRIGR domain, the known RNA-binding domain, with Thr, Ile or Lys has no detectable effect on in vivo ROK1 function. The lack of RNA dependency and some of the mutational phenotypes of ROK1 differentiate this gene from other members of the family.	atp citrate (pro-s)-lyase;atp hydrolysis;adenosine triphosphate;amino acid sequence;amino acid substitution;amino acids;amylose;automated theorem proving;biochemical activity;classification;ddx52 gene;ddx52 wt allele;dna helicases;ion exchange;ion-exchange chromatography procedure;ions;isoleucine;lysine;microtubules;million book project;mutation;myelin basic proteins;null value;phenotype;processor affinity;protein family;rna;reflow soldering;threonine;video-in video-out;emotional dependency	Jae-Young Oh;Jinmi Kim	1999	Nucleic acids research	10.1093/nar/27.13.2753	mutation;biology;biochemistry;molecular biology;amino acid;rna helicase a;peptide sequence;protein family;escherichia coli;genetics;enzyme activator;ion exchange	ML	5.174290454836534	-63.21957796839781	40282
856ad2ffd86b46aed9c15e9b6a278345ffe433b6	designing logical rules to model the response of biomolecular networks with complex interactions: an application to cancer modeling	microarray data;cell cycle physiology;regulatory network;web pages;posttranslational effects;cancer;sarcoma ewing;systems biology;signal transduction;gene regulatory networks;biological system modeling;protein interaction mapping methods;automatic reasoning;tumours;models biological;interaction network;regulatory networks;medical computing;network topology;python library logical rules biomolecular networks complex interactions cancer modeling constraints propagation eukaryotic interaction networks model prediction critical pathway identification posttranslational interactions proteins rna microarray lacunar information logical constraints cell cycle progression ewing tumor development;proteins;tumours cancer cellular biophysics macromolecules medical computing molecular biophysics physiological models proteins;cell line tumor;molecular biophysics;sarcoma ewing genetics metabolism;system biology;macromolecules;in silico analysis;systems biology methods;algorithms;cell cycle;predictive models;humans;prediction model;protein interaction mapping;algorithms cell cycle cell line tumor computer simulation gene expression profiling gene regulatory networks humans linear models models biological oligonucleotide array sequence analysis phenotype protein interaction mapping sarcoma ewing signal transduction systems biology;computational biology;phenotype;linear models;proteins biological system modeling bioinformatics predictive models network topology computational biology;computer simulation;physiological models;gene expression profiling methods;cellular biophysics;cancer systems biology regulatory networks posttranslational effects in silico analysis automatic reasoning;gene expression profiling;oligonucleotide array sequence analysis;systems biology regulatory networks posttranslational effects in silico analysis automatic reasoning cancer transcription factors regulatory networks escherichia coli microarray data e2f family proliferation roles;bioinformatics;in silico	We discuss the propagation of constraints in eukaryotic interaction networks in relation to model prediction and the identification of critical pathways. In order to cope with posttranslational interactions, we consider two types of nodes in the network, corresponding to proteins and to RNA. Microarray data provides very lacunar information for such types of networks because protein nodes, although needed in the model, are not observed. Propagation of observations in such networks leads to poor and nonsignificant model predictions, mainly because rules used to propagate information—usually disjunctive constraints—are weak. Here, we propose a new, stronger type of logical constraints that allow us to strengthen the analysis of the relation between microarray and interaction data. We use these rules to identify the nodes which are responsible for a phenotype, in particular for cell cycle progression. As the benchmark, we use an interaction network describing major pathways implied in Ewing's tumor development. The Python library used to obtain our results is publicly available on our supplementary web page.	accessory atrioventricular bundle (disorder);benchmark (computing);biomarkers, tumor;cell (microprocessor);cell cycle progression;cellular phone;color gradient;disjunctive normal form;interaction network;microarray;neoplasms;python;rule (guideline);software propagation;web page	Carito Guziolowski;Sylvain Blachon;Tatiana Baumuratova;Gautier Stoll;Ovidiu Radulescu;Anne Siegel	2011	IEEE/ACM Transactions on Computational Biology and Bioinformatics	10.1109/TCBB.2010.71	biology;cell biology;computer science;bioinformatics;predictive modelling;genetics;systems biology	Comp.	6.462589632549824	-59.99401483805873	40287
3993d187ba77e4728a176825e49893223177be87	knowledge extraction about atrial arrhythmias through networks of biologically inspired artificial cardiac cells		A network of biologically inspired artificial cardiac cells for simulating atrial arrhythmia is presented. The net comprises a recurrent layer of artificial myocytes, followed by a trainable feed-forward linear layer. The response of the cells is stochastic, and dependent on the variability of the refractory period and the conduction speed. The learning algorithm seeks that the statistical properties in the frequency domain of the network output match those of actual patients. The net can be hand-tuned to anticipate the evolution in time of the heart rhythm anomalies. The results of this study are validated with a selection of intra-cardiac electrocardiograms from patients wearing pacemakers.	algorithm;artificial cardiac pacemaker;heart rate variability;simulation;stochastic process	Jesús Fernández;Luciano Sánchez;Julián Velasco	2018		10.1145/3230905.3230912	frequency domain;knowledge extraction;atrial arrhythmias;refractory period;reservoir computing;heart rhythm;internal medicine;cardiology;computer science	ML	21.429293167656528	-72.09067937262324	40302
cc2360ecc6d45770cccb0334fa308eda40942567	cerealsdb 3.0: expansion of resources and data integration	genomic selection;database;computational biology bioinformatics;snps;wheat;algorithms;single nucleotide polymorphisms;cerealsdb;computer appl in life sciences;microarrays;bioinformatics	The increase in human populations around the world has put pressure on resources, and as a consequence food security has become an important challenge for the 21st century. Wheat (Triticum aestivum) is one of the most important crops in human and livestock diets, and the development of wheat varieties that produce higher yields, combined with increased resistance to pests and resilience to changes in climate, has meant that wheat breeding has become an important focus of scientific research. In an attempt to facilitate these improvements in wheat, plant breeders have employed molecular tools to help them identify genes for important agronomic traits that can be bred into new varieties. Modern molecular techniques have ensured that the rapid and inexpensive characterisation of SNP markers and their validation with modern genotyping methods has produced a valuable resource that can be used in marker assisted selection. CerealsDB was created as a means of quickly disseminating this information to breeders and researchers around the globe. CerealsDB version 3.0 is an online resource that contains a wide range of genomic datasets for wheat that will assist plant breeders and scientists to select the most appropriate markers for use in marker assisted selection. CerealsDB includes a database which currently contains in excess of a million putative varietal SNPs, of which several hundreds of thousands have been experimentally validated. In addition, CerealsDB also contains new data on functional SNPs predicted to have a major effect on protein function and we have constructed a web service to encourage data integration and high-throughput programmatic access. CerealsDB is an open access website that hosts information on SNPs that are considered useful for both plant breeders and research scientists. The recent inclusion of web services designed to federate genomic data resources allows the information on CerealsDB to be more fully integrated with the WheatIS network and other biological databases.	agricultural crops;biological database;cooperative breeding;experiment;federated identity;genotype determination;high-throughput computing;nitroprusside;offset binary;polygenic inheritance;population;single nucleotide polymorphism;throughput;trait;triticum;web service	Paul A. Wilkinson;Mark O. Winfield;Gary Barker;Simon Tyrrell;Xingdong Bian;Alexandra M. Allen;Amanda Burridge;Jane A. Coghill;Christy Waterfall;Mario Caccamo;Robert P. Davey;Keith J. Edwards	2016		10.1186/s12859-016-1139-x	single-nucleotide polymorphism;biology;biotechnology;computer science;bioinformatics;genetics	Comp.	0.7665979931967277	-60.635414222134465	40406
35d61c4125fe6b347cc668e1184fb8bc3512c25c	evolutionary computation, combined with support vector machines, for gene structure prediction	genomics evolutionary computation encoding support vector machines bioinformatics genetic algorithms training;support vector machines bioinformatics evolutionary computation genetics;evolutionary computation;score function;support vector machines;search space;genetics;molecular processes;gene structure;support vector machine;search space evolutionary computation support vector machines gene structure prediction genomic sequence gene recognition bioinformatics eukaryotes;genome sequence;evolutionary computing;bioinformatics	Gene structure prediction consists of determining which parts of a genomic sequence of the cell are coding, and constructing the whole gene from its start site to its stop codon. Gene recognition is one of the most important open problems in bioinformatics. The subtle sources of evidence and the many pitfalls of the problem make gene recognition in eukaryotes one of the most challenging tasks in this field. Gene recognition may be considered as a search problem, where many evidence sources are combined in a scoring function that must be maximized to obtain the structure of a probable gene. Using an intrinsic method, we propose a combination of evolutionary computation and support vector machines for gene structure prediction. Specifically, we use support vector machines (SVMs) to localize and score the functional sites along the genomic sequence, reducing the search space. Evolutionary computation is used to evolve a population where the individuals are correct gene structures. The flexibility of evolutionary computation can be used to account for the complexities of the problem, which are growing as our knowledge of the molecular processes of transcription and translation deepens. Our results show that with a very simple program we are able to achieve very good accuracies in the recognition of genes in human chromosome 19.	a new kind of science;bioinformatics;evolutionary algorithm;evolutionary computation;gene expression programming;gene prediction;genetic algorithm;information;programming paradigm;scoring functions for docking;search problem;support vector machine;systems design;transcription (software)	Javier Pérez-Rodríguez;Nicolás García-Pedrajas	2011	2011 11th International Conference on Intelligent Systems Design and Applications	10.1109/ISDA.2011.6121849	evolutionary programming;support vector machine;interactive evolutionary computation;human-based evolutionary computation;computer science;bioinformatics;machine learning;evolutionary computation	Comp.	0.5499043187904505	-53.73398310050418	40419
a545b6a52f7f19c2135db9c4f0ec53715b6d0e63	fractal image perception provides novel insights into hierarchical cognition		"""Hierarchical structures play a central role in many aspects of human cognition, prominently including both language and music. In this study we addressed hierarchy in the visual domain, using a novel paradigm based on fractal images. Fractals are self-similar patterns generated by repeating the same simple rule at multiple hierarchical levels. Our hypothesis was that the brain uses different resources for processing hierarchies depending on whether it applies a """"fractal"""" or a """"non-fractal"""" cognitive strategy. We analyzed the neural circuits activated by these complex hierarchical patterns in an event-related fMRI study of 40 healthy subjects. Brain activation was compared across three different tasks: a similarity task, and two hierarchical tasks in which subjects were asked to recognize the repetition of a rule operating transformations either within an existing hierarchical level, or generating new hierarchical levels. Similar hierarchical images were generated by both rules and target images were identical. We found that when processing visual hierarchies, engagement in both hierarchical tasks activated the visual dorsal stream (occipito-parietal cortex, intraparietal sulcus and dorsolateral prefrontal cortex). In addition, the level-generating task specifically activated circuits related to the integration of spatial and categorical information, and with the integration of items in contexts (posterior cingulate cortex, retrosplenial cortex, and medial, ventral and anterior regions of temporal cortex). These findings provide interesting new clues about the cognitive mechanisms involved in the generation of new hierarchical levels as required for fractals."""	broca aphasia;cerebral cortex;cingulate cortex;cognition;computation;domain-specific language;embedding;fractal;groove;internationalization and localization;iteration;medial graph;parietal lobe;prefrontal cortex;programming paradigm;recursion (computer science);rule (guideline);self-similarity;structure of intraparietal sulcus;temporal lobe;cell transformation;fmri	M. J. Martins;Florian Ph. S. Fischmeister;E. Puig-Waldmüller;Jiwon Oh;Alexander Geissler;Simon Robinson;W. Tecumseh Fitch;Roland Beisteiner	2014	NeuroImage	10.1016/j.neuroimage.2014.03.064	psychology;cognitive psychology;developmental psychology;communication	ML	18.216173831733055	-75.46755109552629	40421
5ad8be2d96eaf80ae5692e2aa2fe27861fc90542	feasibility of single-input tracer kinetic modeling with continuous-time formalism in liver 4-phase dynamic contrast-enhanced ct	biological patents;biomedical journals;text mining;europe pubmed central;citation search;citation networks;research articles;abstracts;open access;life sciences;clinical guidelines;full text;rest apis;orcids;europe pmc;biomedical research;bioinformatics;literature search	The modeling of tracer kinetics with use of low-temporal-resolution data is of central importance for patient dose reduction in dynamic contrast-enhanced CT (DCE-CT) study. Tracer kinetic models of the liver vary according to the physiologic assumptions imposed on the model, and they can substantially differ in the ways how the input for blood supply and tissue compartments are modeled. In this study, single-input flow-limited (FL), Tofts-Kety (TK), extended TK (ETK), Hayton-Brady (HB), two compartment exchange (2CX), and adiabatic approximation to the tissue homogeneity (AATH) models were applied to the analysis of liver 4-phase DCE-CT data with fully continuous-time parameter formulation, including the bolus arrival time. The bolus arrival time for the 2CX and AATH models was described by modifying the vascular transport operator theory. Initial results indicate that single-input tracer kinetic modeling is feasible for distinguishing between hepatocellular carcinoma and normal liver parenchyma.		Sang Ho Lee;Yasuji Ryu;Koichi Hayano;Hiroyuki Yoshida	2014	Abdominal imaging : computational and clinical applications : 6th International Workshop, ABDI 2014, held in conjunction with MICCAI 2014, Cambridge, MA, USA, September 14, 2014. ABDI (Workshop)	10.1007/978-3-319-13692-9_6	computer science;bioinformatics;data mining;biological engineering	ML	11.32870239710665	-67.40163843829093	40429
c6f31d481dfcbe03c7334a980bb0dd634695167b	dynamic outlier exclusion training algorithm for sequence based predictions in proteins using neural network	neural networks;sequence information;protein sequence;binding site;binding sites;machine learning;structure and function;outliers;training algorithm;neural network	Many structural and functional properties of proteins can be described as a one-dimensional one-to-one mapping between residues of protein sequence and target structure or function. These residue level properties (RLPs) have been frequently predicted using neural networks and other machine learning algorithms. Here we present an algorithm to dynamically exclude from the neural network training, examples which are most difficult to separate. This algorithm automatically filters out statistical outliers causing noise and makes training faster without losing network ability to generalize. Different methods of sampling data for neural network training have been tried and their impact on learning has been analyzed.	algorithm;artificial neural network;image noise;machine learning;one-to-one (data model);rl (complexity);sampling (signal processing)	Shandar Ahmad	2007		10.1007/978-3-540-75286-8_14	computer science;bioinformatics;binding site;machine learning;pattern recognition;deep learning;artificial neural network	ML	9.757126379639667	-54.68829489104527	40512
bf409e9ccd678248606d2cb6266fda104663ebfc	tracking rhythmicity in nonstationary quasi-periodic biomedical signals using adaptive time-varying covariance	nonstationary persistent signals;quantization;oscillations;time varying;cuantificacion;high resolution;mammalia;systeme nerveux central;spinal cord;etude experimentale;frequence;time variation;autocovariance;frequency estimation;exploracion;vertebrata;oscillation;variation temporelle;quantification;medula espinal;rodentia;moelle epiniere;animal;adaptive window;sistema nervioso central;frecuencia;time frequency representation;autocovarianza;exploration;evaluation;rat;oscilacion;rata;evaluacion;central pattern generator;frequency;variacion temporal;estudio experimental;time frequency analysis;central nervous system;in vitro	A time-varying covariance method for detecting and quantifying the evolution of rhythmicity (frequency) in persistently varying quasi-periodic nonstationary signals is presented. The basic method, evaluated using chirp signals, utilizes a shifting window of fixed length. A substantial reduction in estimation bias and variability are obtained by utilizing an adaptive window whose length is dependent on past frequency estimates. The adaptive window yields estimates that are comparable in accuracy to those obtained using high-resolution time-frequency representation but with lower computation requirements and the potential for on-line application. Finally, an example of the application of the method for analyzing a neural recording is also illustrated.		Dan Li;Ranu Jung	2002	Computers in biology and medicine	10.1016/S0010-4825(02)00022-7	telecommunications;oscillation;quantum mechanics;statistics	ML	21.300844566893574	-72.05003810837307	40553
45c404de0716a4ff05587e34abded1d65bf2e086	a multi-modal graph-based semi-supervised pipeline for predicting cancer survival	manifolds;support vector machines;cancer;laplace equations;pipelines;semisupervised learning;data models	Cancer survival prediction is an active area of research that can help prevent unnecessary therapies and improve patient's quality of life. Gene expression profiling is being widely used in cancer studies to discover informative biomarkers that aid predict different clinical endpoint prediction. We use multiple modalities of data derived from RNA deep-sequencing (RNA-seq) to predict survival of cancer patients. Despite the wealth of information available in expression profiles of cancer tumors, fulfilling the aforementioned objective remains a big challenge, for the most part, due to the paucity of data samples compared to the high dimension of the expression profiles. As such, analysis of transcriptomic data modalities calls for state-of-the-art big-data analytics techniques that can maximally use all the available data to discover the relevant information hidden within a significant amount of noise. In this paper, we propose a pipeline that predicts cancer patients' survival by exploiting the structure of the input (manifold learning) and by leveraging the unlabeled samples using Laplacian support vector machines, a graph-based semi supervised learning (GSSL) paradigm. We show that under certain circumstances, no single modality per se will result in the best accuracy and by fusing different models together via a stacked generalization strategy, we may boost the accuracy synergistically. We apply our approach to two cancer datasets and present promising results. We maintain that a similar pipeline can be used for predictive tasks where labeled samples are expensive to acquire.	big data;communication endpoint;ensemble learning;gene expression profiling;information;modal logic;modality (human–computer interaction);nonlinear dimensionality reduction;programming paradigm;semi-supervised learning;semiconductor industry;supervised learning;support vector machine;synergy	Hamid Reza Hassanzadeh;John H. Phan;May D. Wang	2016	2016 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)	10.1109/BIBM.2016.7822516	data modeling;support vector machine;manifold;computer science;bioinformatics;machine learning;data mining;pipeline transport;statistics;cancer	Visualization	3.860059008411309	-72.88263166913185	40604
361367838ee5d9d5c9a77c69c1c56b1c309ab236	salient object detection: a survey		Detecting and segmenting salient objects in natural scenes, often referred to as salient object detection, has attracted a lot of interest in computer vision. While many models have been proposed and several applications have emerged, yet a deep understanding of achievements and issues is lacking. We aim to provide a comprehensive review of the recent progress in salient object detection and situate this field among other closely related areas such as generic scene segmentation, object proposal generation, and saliency for fixation prediction. Covering 228 publications, we survey i) roots, key concepts, and tasks, ii) core techniques and main modeling trends, and iii) datasets and evaluation metrics in salient object detection. We also discuss open problems such as evaluation metrics and dataset bias in model performance and suggest future research directions.	collision detection;computer vision;object detection;sensor;situated cognition	Ali Borji;Ming-Ming Cheng;Huaizu Jiang;Jia Li	2014	CoRR		computer vision;simulation;data mining	Vision	24.227583536453835	-56.33438912118982	40685
b67088d8e5619f84e32be392e2f9e4fc6e6feda9	formation of a direction map by projection learning using kohonen's self-organization map	primary visual cortex;learning methods;self organized map	 In this paper, we propose a modification of Kohonen's self-organization map (SOM) algorithm. When the input signal space is not convex, some reference vectors of SOM can protrude from it. The input signal space must be convex to keep all the reference vectors fixed on it for any updates. Thus, we introduce a projection learning method that fixes the reference vectors onto the input signal space. This version of SOM can be applied to a non-convex input signal space. We applied SOM with projection learning to a direction map observed in the primary visual cortex of area 17 of ferrets, and area 18 of cats. Neurons in those areas responded selectively to the orientation of edges or line segments, and their directions of motion. Some iso-orientation domains were subdivided into selective regions for the opposite direction of motion. The abstract input signal space of the direction map described in the manner proposed by Obermayer and Blasdel [(1993) J Neurosci 13: 4114–4129] is not convex. We successfully used SOM with projection learning to reproduce a direction-orientation joint map.	algorithm;area striata structure;convex function;ferrets;iso 3166;isoproterenol;self-organization;self-organizing map;teuvo kohonen;visual cortex	Hayaru Shouno;Koji Kurata	2001	Biological Cybernetics	10.1007/s004220100255	computer vision;self-organizing map;artificial intelligence;machine learning;mathematics	ML	19.870792000819357	-66.61936357561386	40707
432b7f1ed55989c73d51981fb5c83c7219ba9cd5	discovering latent healthy nutritional dietary patterns with association rule mining and constraint handling rules	association rule mining		association rule learning;constraint handling rules	Chendong Li;Yichen Liu	2010			association rule learning;data mining;constraint handling rules;pattern recognition;computer science;artificial intelligence	ML	3.3574216790818165	-75.83954046137562	40709
ad3377faf21f0fb48df93a00b15853046a8341b4	bink: biological binary keypoint descriptor	applications;bio-inspired;cortical cells;descriptor;keypoints	Learning robust keypoint descriptors has become an active research area in the past decade. Matching local features is not only important for computational applications, but may also play an important role in early biological vision for disparity and motion processing. Although there were already some floating-point descriptors like SIFT and SURF that can yield high matching rates, the need for better and faster descriptors for real-time applications and embedded devices with low computational power led to the development of binary descriptors, which are usually much faster to compute and to match. Most of these descriptors are based on purely computational methods. The few descriptors that take some inspiration from biological systems are still lagging behind in terms of performance. In this paper, we propose a new biologically inspired binary keypoint descriptor: BINK. Built on responses of cortical V1 cells, it significantly outperforms the other biologically inspired descriptors. The new descriptor can be easily integrated with a V1-based keypoint detector that we previously developed for real-time applications.		Mário Saleiro;Kasim Terzic;João Fabrício Mota Rodrigues;J. M. Hans du Buf	2017	Bio Systems	10.1016/j.biosystems.2017.10.007		Vision	23.128621739809056	-56.28489548915124	40711
eeb00a79e8cfb2f9f7415f3a10f7c82da8f8819a	fmri of pain processing in the brain: a within-animal comparative study of bold vs. cbv and noxious electrical vs. noxious mechanical stimulation in rat	cerebral blood volume;mechanical stimulation;bold;electrical stimulation;rat;pain fmri	This study aims to identify fMRI signatures of nociceptive processing in whole brain of anesthetized rats during noxious electrical stimulation (NES) and noxious mechanical stimulation (NMS) of paw. Activation patterns for NES were mapped with blood oxygen level dependent (BOLD) and cerebral blood volume (CBV) fMRI, respectively, to investigate the spatially-dependent hemodynamic responses during nociception processing. A systematic evaluation of fMRI responses to varying frequencies of electrical stimulus was carried out to optimize the NES protocol. Both BOLD and CBV fMRI showed widespread activations, but with different spatial characteristics. While BOLD and CBV showed well-localized activations in ipsilateral dorsal column nucleus, contralateral primary somatosensory cortex (S1), and bilateral caudate putamen (CPu), CBV fMRI showed additional bilateral activations in the regions of pons, midbrain and thalamus compared to BOLD fMRI. CBV fMRI that offers higher sensitivity compared to BOLD was then used to compare the nociception processing during NES and NMS in the same animal. The activations in most regions were similar. In the medulla, however, NES induced a robust activation in the ipsilateral dorsal column nucleus while NMS showed no activation. This study demonstrates that (1) the hemodynamic response to nociception is spatial-dependent; (2) the widespread activations during nociception in CBV fMRI are similar to what have been observed in (14)C-2-deoxyglucose (2DG) autoradiography and PET; (3) the bilateral activations in the brain originate from the divergence of neural responses at supraspinal level; and (4) the similarity of activation patterns suggests that nociceptive processing in rats is similar during NES and NMS.	antivirus software;autoradiography;bilateral filter;cell nucleus;cerebral blood volume;cerebral cortex;deoxyglucose;dorsal funiculus;electric stimulation therapy;electric stimulation technique;functional electrical stimulation;hemodynamics;mechlorethamine;midbrain structure;neostriatum;nes (fish);neuroleptic malignant syndrome;no man's sky;nociception;pain;paw;pontine structure;resting state fmri;structure of putamen;thalamic structure;blood oxygen level dependent	Fuqiang Zhao;Denise C. Welsh;Mangay Williams;Alexandre Coimbra;Mark O. Urban;Richard Hargreaves;Jeffrey L. Evelhoch;Donald S. Williams	2012	NeuroImage	10.1016/j.neuroimage.2011.08.002	psychology;neuroscience;anesthesia;surgery	ML	19.761252202865872	-79.95118642353417	40725
9483620e9d151468f27862b68ce4d42294c77cea	towards the utilization of eeg as a brain imaging tool	source localization;evoked;serveur institutionnel;topography;induced;brain mapping;archive institutionnelle;erp;open access;brain imaging;multimodal;eeg;archive ouverte unige;cybertheses;frequency;institutional repository	Recent advances in signal analysis have engendered EEG with the status of a true brain mapping and brain imaging method capable of providing spatio-temporal information regarding brain (dys)function. Because of the increasing interest in the temporal dynamics of brain networks, and because of the straightforward compatibility of the EEG with other brain imaging techniques, EEG is increasingly used in the neuroimaging community. However, the full capability of EEG is highly underestimated. Many combined EEG-fMRI studies use the EEG only as a spike-counter or an oscilloscope. Many cognitive and clinical EEG studies use the EEG still in its traditional way and analyze grapho-elements at certain electrodes and latencies. We here show that this way of using the EEG is not only dangerous because it leads to misinterpretations, but it is also largely ignoring the spatial aspects of the signals. In fact, EEG primarily measures the electric potential field at the scalp surface in the same way as MEG measures the magnetic field. By properly sampling and correctly analyzing this electric field, EEG can provide reliable information about the neuronal activity in the brain and the temporal dynamics of this activity in the millisecond range. This review explains some of these analysis methods and illustrates their potential in clinical and experimental applications.	base;brain mapping;conductance (graph);electroconvulsive therapy;electroencephalography;epilepsy, temporal lobe;imaging device;imaging techniques;inspiration function;large scale brain networks;magnetic fields;magnetoencephalography;medical device incompatibility problem;microsoft outlook for mac;neural oscillation;neuroimaging;occur (action);onset (audio);oscilloscopes;population;programming paradigm;real life;relocation of home or business;renaissance;sampling (signal processing);signal processing;spatial analysis;spatio-temporal analysis;spontaneous order;electric field;electrode;fmri	Christoph M. Michel;Micah M. Murray	2012	NeuroImage	10.1016/j.neuroimage.2011.12.039	psychology;neuroscience;radiology;artificial intelligence;topography;frequency;multimodal interaction;brain mapping;communication	ML	20.247864188132773	-76.99719945644371	40875
7a2d315506a6f8f20b0ed46173bf35cc7ffe3568	feasability of yeast and bacteria identification using uv-vis-swnir difusive reflectance spectroscopy		UV-VIS spectroscopy is a powerfull qualitative and quantitative technique used in analytical chemistry, which gives information about electronic transitions of electrons in molecular orbitals. As in UV-VIS spectra there is no direct information on characteristic organic groups, vibrational spectroscopy (e.g. infrared) has been preferred for biological applications. In this research, we try to use state-of-the-art fiber optics probes to obtain UV-VIS-SWNIR diffusive reflectance measurements of yeasts and bacteria colonies on plate count agar in the region of 200-1200nm; in order to discriminate the following microorganisms: i) yeasts: Saccharomyces cerevisiae, Saccharomyces bayanus , Candida albicans , Yarrowia lipolytica; and ii) bacteria:Micrococcus luteus , Pseudomonas fluorescens , Escherichia coli , Bacillus cereus . Spectroscopy results show that UV-VIS-SWNIR has great potential for identifying microorganisms on plate count agar. Scattering artifacts of both colonies and plate count agar can be significantly removed using a robust mean scattering algorithm, allowing also better discriminations between the scores obtained by singular value decomposition. Hierarchical clustering analysis of UV-VIS and VIS-SWNIR decomposed spectral scores lead to the conclusion that the use of VISSWNIR light source produces higher discrimination ratios for all the studied microorganisms, presenting great potential for developing biotechnology applications.	algorithm;cluster analysis;hierarchical clustering;lambertian reflectance;molecular orbital;optical fiber;signal processing;singular value decomposition;uv mapping;visual instruction set	J. S. Silva;Rui Costa Martins;António Augusto Vicente;José António Couto Teixeira	2008			voltage;computer vision;computer science;ultraviolet visible spectroscopy;artificial intelligence;spectroscopy;optics;singular value decomposition;reflectivity	Vision	16.103606764804574	-57.03834509431889	40922
adbf61dda3fd82699c1d92640b1d794e3109c57b	hpd: an online integrated human pathway database enabling systems biology studies	software;human disease;systems biology;gene regulation;web interface;enzyme;relational database;data model;computational biology bioinformatics;internet;proteins;indexation;data warehousing;system biology;algorithms;humans;databases factual;combinatorial libraries;computational biology;computer appl in life sciences;breast cancer;databases protein;microarrays;bioinformatics	Pathway-oriented experimental and computational studies have led to a significant accumulation of biological knowledge concerning three major types of biological pathway events: molecular signaling events, gene regulation events, and metabolic reaction events. A pathway consists of a series of molecular pathway events that link molecular entities such as proteins, genes, and metabolites. There are approximately 300 biological pathway resources as of April 2009 according to the Pathguide database; however, these pathway databases generally have poor coverage or poor quality, and are difficult to integrate, due to syntactic-level and semantic-level data incompatibilities. We developed the Human Pathway Database (HPD) by integrating heterogeneous human pathway data that are either curated at the NCI Pathway Interaction Database (PID), Reactome, BioCarta, KEGG or indexed from the Protein Lounge Web sites. Integration of pathway data at syntactic, semantic, and schematic levels was based on a unified pathway data model and data warehousing-based integration techniques. HPD provides a comprehensive online view that connects human proteins, genes, RNA transcripts, enzymes, signaling events, metabolic reaction events, and gene regulatory events. At the time of this writing HPD includes 999 human pathways and more than 59,341 human molecular entities. The HPD software provides both a user-friendly Web interface for online use and a robust relational database backend for advanced pathway querying. This pathway tool enables users to 1) search for human pathways from different resources by simply entering genes/proteins involved in pathways or words appearing in pathway names, 2) analyze pathway-protein association, 3) study pathway-pathway similarity, and 4) build integrated pathway networks. We demonstrated the usage and characteristics of the new HPD through three breast cancer case studies. HPD http://bio.informatics.iupui.edu/HPD is a new resource for searching, managing, and studying human biological pathways. Users of HPD can search against large collections of human biological pathways, compare related pathways and their molecular entity compositions, and build high-quality, expanded-scope disease pathway models. The current HPD software can help users address a wide range of pathway-related questions in human disease biology studies.	composition;computation;data model;entity;gene regulatory network;genetic heterogeneity;hpd gene;index;interface device component;kegg;metabolic process, cellular;nc (complexity);name;pid;relational database;schematic;systems biology;transcript;tree accumulation;usability;recurrent childhood visual pathway glioma	Sudhir R. Chowbina;Xiaogang Wu;Fan Zhang;Peter M. Li;Ragini Pandey;Harini N. Kasamsetty;Jake Yue Chen	2009		10.1186/1471-2105-10-S11-S5	biology;enzyme;the internet;regulation of gene expression;dna microarray;data model;relational database;computer science;bioinformatics;data science;breast cancer;biological pathway;data mining;user interface;systems biology	Comp.	-1.4770453783250723	-62.26383339248826	40935
9ec9a01cb6f91f499d27fcef6ca7e5915dbad4bf	cbir on big data by use of deep learning			big data;content-based image retrieval;deep learning	Mahmoud Saeidi;Ali Ahmadi	2017		10.3233/978-1-61499-882-2-71	data science;big data;deep learning;computer science;artificial intelligence	ML	0.06372521893525501	-70.46413429001096	40962
595993fce80b7460cf160900c3e815fe0971cef4	shared genetic architecture in autoimmune disease - preliminary analysis	genetics blood cellular biophysics diseases drugs;drug targets shared genetic architecture autoimmune disease preliminary analysis genetic risk components disease based on sets blood sugar genetic contributions type ii diabetes type i diabetes insulin resistance immune cells insulin producing cells genetic data genetic causative drivers autoimmune diseases genetic susceptibility information human phenotype ontology nci thesaurus disease ontology;diseases diabetes insulin immune system thesauri	Diseases that have different underlying genetic risk component(s) may share similar phenotypes. Traditionally, disease classifications have focused on characterizing diseases based on sets of related phenotypes. As an example, type I diabetes and type II diabetes are both classified as a type of diabetes based on patients having high blood sugar over long periods of time. However, as our understanding of genetic contributions to disease susceptibility and progression evolves, we start noticing that diseases with similar symptoms may have completely different causes. For example, type II diabetes is due to insulin resistance while type I diabetes is caused by immune cells attacking insulin producing cells. As genetic data becomes more highly available, it becomes possible to classify diseases based on their genetic causative drivers instead of their phenotypes. In this study, we have (1) explored the relationship between 10 autoimmune diseases along with type II diabetes based on their genetic susceptibility information and compared such classifications to existing disease categorizations based on disease symptoms/phenotypes from Human Phenotype Ontology, NCI-thesaurus and the Disease Ontology, and (2) developed automated scripts to compute similarities and cluster diseases based on the specified criteria. Categorization based on genetic susceptibility can help identify diseases that share similar drug targets and benefit from similar diagnosis technologies. We hope to further develop our system to apply it to more disease categories.	categorization;color gradient;disease ontology;human phenotype ontology;nc (complexity);thesaurus	Leqi Liu;Jia Tao;Ziyan Yang;Fadi Towfic	2015	2015 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)	10.1109/BIBM.2015.7359789	biology;bioinformatics;immunology	Comp.	-1.3471542743017373	-64.03173180854314	41009
e252a9c3ac5c8ade275f8f252fd1e7b476b75912	incorporating key position and amino acid residue features to identify general and species-specific ubiquitin conjugation sites		MOTIVATION Systematic dissection of the ubiquitylation proteome is emerging as an appealing but challenging research topic because of the significant roles ubiquitylation play not only in protein degradation but also in many other cellular functions. High-throughput experimental studies using mass spectrometry have identified many ubiquitylation sites, primarily from eukaryotes. However, the vast majority of ubiquitylation sites remain undiscovered, even in well-studied systems. Because mass spectrometry-based experimental approaches for identifying ubiquitylation events are costly, time-consuming and biased toward abundant proteins and proteotypic peptides, in silico prediction of ubiquitylation sites is a potentially useful alternative strategy for whole proteome annotation. Because of various limitations, current ubiquitylation site prediction tools were not well designed to comprehensively assess proteomes.   RESULTS We present a novel tool known as UbiProber, specifically designed for large-scale predictions of both general and species-specific ubiquitylation sites. We collected proteomics data for ubiquitylation from multiple species from several reliable sources and used them to train prediction models by a comprehensive machine-learning approach that integrates the information from key positions and key amino acid residues. Cross-validation tests reveal that UbiProber achieves some improvement over existing tools in predicting species-specific ubiquitylation sites. Moreover, independent tests show that UbiProber improves the areas under receiver operating characteristic curves by ~15% by using the Combined model.   AVAILABILITY The UbiProber server is freely available on the web at http://bioinfo.ncu.edu.cn/UbiProber.aspx. The software system of UbiProber can be downloaded at the same site.   SUPPLEMENTARY INFORMATION Supplementary data are available at Bioinformatics online.		Xiang Chen;Jianding Qiu;Shao-Ping Shi;Sheng-Bao Suo;Shu-Yun Huang;Ru-Ping Liang	2013	Bioinformatics	10.1093/bioinformatics/btt196	biology;biochemistry;bioinformatics	Comp.	2.4567341770712323	-57.60977423137944	41039
b9c15a9333694bbe80b5468a4d1342d9df23fc66	the emergence of long-lasting transients of activity in simple neural networks	kinetics;tissue culture;neural network;critical point	The question was investigated whether longlasting transients of activity, observed to occur in the intact cerebral cortex (EEG slow (δ) waves and ‘K’ complexes) as well as in isolated tissues cultured in vitro, can also emerge in a model network of excitatory and inhibitory cells. We show that such transients can indeed occur even if the cells do not have built-in slow kinetics. For certain parameter settings, the network is in a bistable state in which periods of increased activity (long-lasting transients) alternate with minimal activity. Transients are triggered by spontaneously firing cells (‘noise’), which, rather than via a build-up of recurrent synaptic inhibition, also initiate their termination. During a transient, the network continually makes transitions from one equilibrium to another as a result of spontaneous firing until it is switched back to the quiescent state, i.e., after a variable period of time of noise-induced transitions the transient is terminated. If the network is small, activity can terminate even without inhibition. In large networks, inhibition keeps the network sensitive to spontaneously firing cells by holding it in the neighbourhood of a critical point between active and quiescent state.	artificial neural network;bistability;canonical account;critical point (network science);electroencephalography;emergence;kinetics internet protocol;spontaneous order;synaptic package manager;terminate (software)	A. van Ooytien;J. van Pelt;M. A. Corner;F. H. Lopes da Silva	1992	Biological Cybernetics	10.1007/BF00204400	computer science;physical neural network;time delay neural network;artificial neural network;spiking neural network	ML	17.943979064604843	-71.09213036202411	41065
6323b74cc04143452d5ef30a625b34fbf2095f50	arraylasso: a network-based approach to microarray interconversion	journal article;oligonucleotide probes;linear models;gene expression profiling;oligonucleotide array sequence analysis	UNLABELLED Robust conversion between microarray platforms is needed to leverage the wide variety of microarray expression studies that have been conducted to date. Currently available conversion methods rely on manufacturer annotations, which are often incomplete, or on direct alignment of probes from different platforms, which often fail to yield acceptable genewise correlation. Here, we describe aRrayLasso, which uses the Lasso-penalized generalized linear model to model the relationships between individual probes in different probe sets. We have implemented aRrayLasso in a set of five open-source R functions that allow the user to acquire data from public sources such as Gene Expression Omnibus, train a set of Lasso models on that data and directly map one microarray platform to another. aRrayLasso significantly predicts expression levels with similar fidelity to technical replicates of the same RNA pool, demonstrating its utility in the integration of datasets from different platforms.   AVAILABILITY AND IMPLEMENTATION All functions are available, along with descriptions, at https://github.com/adam-sam-brown/aRrayLasso.   CONTACT chirag_patel@hms.harvard.edu.   SUPPLEMENTARY INFORMATION Supplementary data are available at Bioinformatics online.	bioinformatics;description;generalized linear model;lasso;microarray;open-source software;partial;rna	Adam S. Brown;Chirag J. Patel	2015		10.1093/bioinformatics/btv469	biology;molecular biology;bioinformatics;linear model;data mining;gene expression profiling;microarray databases;statistics	Comp.	4.007360555595578	-52.124866443630886	41074
d9d6319a2f6b015e684eaaf9dd8a499081c0d1bd	mirandb: a resource of online services for mirna research	web-accessible databases;meta-database;mirna;online databases	Recent discovery of thousands of small and large noncoding RNAs, in parallel to technical improvements enabling scientists to study the transcriptome in much higher depth, has resulted in massive data generation. This burst of information prompts the development of easily accessible resources for storage, retrieval and analysis of raw and processed data, and hundreds of Web-based tools dedicated to these tasks have been made available. However, the increasing number and diversity of bioinformatics tools, each covering a specific and specialized area, as well as their redundancies, represent potential sources of complication for end users. To overcome these issues, we are introducing an easy-to-follow classification of microRNA (miRNA)-related bioinformatics tools for biologists interested in studying this important class of small noncoding RNAs. We also developed our miRNA database miRNA algorithmic network database (miRandb) that is a meta-database, which presents a survey of > 180 Web-based miRNA databases. These include miRNA sequence, discovery, target prediction, target validation, expression and regulation, functions and their roles in diseases, interactions in cellular pathways and networks and deep sequencing. miRandb recapitulates the diverse possibilities and facilitates that access to the different categories of miRNA resources. Researchers can easily select the category of miRNA information and desired organism, in result eligible databases with their features are presented. This database introducing an easy-to-follow classification of available resources that can facilitate selection of appropriate resources for miRNA-related bioinformatics tools. Finally, we described current shortages and future necessities that assist researchers to use these tools easily. Our database is accessible at http://mirandb.ir.		Seyed Hamid Aghaee-Bakhtiari;Ehsan Arefian;Pierre Lau	2018	Briefings in bioinformatics	10.1093/bib/bbw109	bioinformatics;biology	Comp.	-0.9557550250718619	-61.096162603425775	41147
513979e5c97de6426648cf65c6805826f5c11c86	characterization of aberrant pathways across human cancers	simulation and modeling;systems biology;physiological cellular and medical topics;computational biology bioinformatics;fi artikkeli aikakauslehdessa en journal article;algorithms;humans;neoplasms;gene expression profiling;bioinformatics	Cancer is a broad group of genetic diseases which account for millions of deaths worldwide each year. Cancers are classified by various clinical, pathological and molecular methods, but even within a well-characterized disease, there is a significant inter-patient variability in survival, response to treatment, and other parameters. Especially in molecular level, tumours of the same category can appear significantly dissimilar due to complex combinations of genetic aberrations leading to a similar malignancy. We extended the current classification methods by studying tumour heterogeneity at pathway level. We computed the rate of alterations in 1994 pathways and 2210 tumours consisting of eight different cancers. Using gene set enrichment analysis, each sample was computed a pathway aberration profile that reflected its molecular state. The profiles were analysed together to infer the characteristic aberration rates for each pathway within each cancer. Subgroups of tumours defined by similar pathway aberrations were identified using clustering analyses. The pathway aberration and gene expression profiles of the subgroups were consecutively compared across all eight cancer types to search for similar tumours crossing the standard classification. We identified pathways and processes that were common to all cancers as well as traits that are unique to a cancer type or closely related cancers. Studying the gene expression patterns within the pathway context suggested potential alteration mechanisms. Clustering analysis revealed five clinically relevant subgroups of tumours in four cancers that exhibited significant differences in survival compared to others. The cross-cancer analysis of the subgroups resulted in the identification of tumours that shared potentially significant alterations. This study represents the first effort to extend the molecular characterizations towards pathway level descriptions across the family of cancers. In addition to providing a proof-of-concept for single sample pathway aberration analysis in this context, we present a comprehensive pathway aberration dataset that can be used to study pathway aberration patterns within or across cancers. Significant similarities between subgroups of different cancers on pathway and gene expression levels provide interesting hypotheses for understanding variable drug response, or transferring treatments across diseases by identifying common druggable pathways or genes, for example.	cessation of life;classification;cluster analysis;description;gene expression;gene ontology term enrichment;gene co-expression network;gene regulatory network;heart rate variability;hereditary diseases;inference;malignant neoplasms;molecular genetic technique;patients;semantic heterogeneity;silo (dataset);trait;drug response;statistical cluster	Antti Ylipää;Olli P. Yli-Harja;Wei Zhang;Matti Nykter	2013		10.1186/1752-0509-7-S1-S1	biology;bioinformatics;gene expression profiling;systems biology	Comp.	6.31568924347454	-56.020397588879696	41161
66b1daa6436411606a2058e86e7745b1ea4cfbdf	functional connectivity analysis for thalassemia disease based on a graphical lasso model	graphical lasso method fmri resting state connectivity thalassemia disease graph theory;graph theory;brain modeling covariance matrices correlation data models diseases magnetic resonance imaging blood;neurophysiology biomedical mri blood brain graph theory maximum likelihood estimation medical disorders medical image processing;fmri;resting state;thalassemia disease;maximum likelihood sense functional connectivity analysis thalassemia disease graphical lasso model congenital disorder hemoglobin synthesis thromboembolic events stroke brain diseased subjects functional magnetic resonance imaging blood oxygenation level spatially distant areas abnormal neuronal activation biomarker hyperparameter cross validation scheme thalassemic patient group;graphical lasso method;connectivity	Thalassemia is a congenital disorder of hemoglobin synthesis which can lead to thromboembolic events and stroke in the brain. In this work we propose to use a functional connectivity model to discriminate between control and diseased subjects. Our connectivity measure is based on functional magnetic resonance imaging, and hence common variations of the blood oxygenation level in spatially distant areas. Analyzing this connectivity could highlight abnormal neuronal activation and provide us with a descriptor (bio-marker) of the disease. To estimate the connectivity, we propose a robust learning scheme based on the graphical lasso model, whose hyperparameter is validated within a cross-validation scheme. To analyze model fit, we transfer the mean connectivity from the control group to the thalassemic patient group. Our null hypothesis is that the model learned on control subjects is perfectly adequate (in the maximum likelihood sense) to describe the patients. The results of the permutation test suggest that the some patients with thalassemia do not have the same connectivity structure as the control.	british informatics olympiad;cell respiration;cerebrovascular accident;congenital disorders;cross-validation (statistics);data validation;graphical user interface;lasso;parkinson disease;patients;resampling (statistics);resonance;resting state fmri;thalassemia;thromboembolism;hemoglobin biosynthetic process;triangulation	Julie Coloigner;Ronald Phlypo;Adam Bush;Natasha Lepore;John Wood	2016	2016 IEEE 13th International Symposium on Biomedical Imaging (ISBI)	10.1109/ISBI.2016.7493504	pathology;bioinformatics;connectivity;graph theory;mathematics;resting state fmri;statistics	ML	23.772358123239727	-78.45838465207554	41162
9f8df069f5ca9ccf86478af3de7be1406df97265	bugs, guts and fat - a systems approach to the metabolic 'axis of evil'		Rapidly growing evidence suggests that complex and variable interactions between host genetic and systems factors, diet, activity and lifestyle choices, and intestinal microbes control the incidence, severity and complexity of metabolic diseases. The dramatic increase in the world-wide incidence of these diseases, including obesity, diabetes, hypertension, heart disease, and fatty liver disease, raises the need for new ways to maintain health despite inherited and environmental risks. We are pursuing a comprehensive approach based on diet-induced models of metabolic disease. During the course of these studies, new and challenging statistical, analytical and computational problems were discovered. We pioneered a new paradigm for genetic studies based on chromosome substitution strains of laboratory mice. These strains involve systematically substituting each chromosome in a host strain with the corresponding chromosome from a donor strain. A genome survey with these strains therefore involves testing a panel of individual, distinct and non-overlapping genotypes, in contrast to conventional studies of heterogeneous populations. Studies of diet-induced metabolic disease with these strains have already led to striking observations. We discovered that most traits are controlled by a many genetic variants each of which has unexpectedly large phenotypic effects and that act in a highly non-additive manner. The non-additive nature of these variants challenges conventional models of the architecture of complex traits. At every level of resolution from the entire genome to very small genetic intervals, we discovered comparable levels of genetic complexity, suggesting a fractal property of complex traits. Another remarkable property of these large-effect variants is their ability to switch complex systems between alternative phenotypic states such as obese to lean and high to low cholesterol, suggesting that biological traits might be organized in a small number of stable states rather than continuous variability. Moreover, by studying correlations between non-genetic variation in pairs of traits (the genetic control of non-genetic variation), we discovered a new way to dissect the functional architecture of biological systems. Finally, a neglected aspect of these studies of metabolic disease involves the intestingal microbes. Early studies suggest that diet and host physiology affect the numbers and kinds of microbes, and that these microbes in turn affect host metabolism. These interactions between ’bugs, guts and fat’ extend systems studies from conventional aspects of genetics and biology to population considerations of the functional interactions between hosts, diet and our microbial passengers. With these models of diet-induced metabolic disease in chromosome substitution strains, we are now positioned find ways to tip complex systems from disease to health.	apache axis;biological system;complex systems;computation;computational problem;fractal;genetic algorithm;heart rate variability;incidence matrix;interaction;population;programming paradigm;software bug;utility functions on indivisible goods	Joseph H. Nadeau	2007			zoology;axis of evil;paleontology;bioinformatics;biology	Comp.	3.106546253235796	-61.91197773779017	41163
3b60fc20e58f812471a0eb700054b227458f295e	single-point mutation with a rotamer library toolkit: toward protein engineering	biological patents;biomedical journals;text mining;europe pubmed central;citation search;citation networks;research articles;abstracts;open access;life sciences;clinical guidelines;full text;rest apis;orcids;europe pmc;biomedical research;bioinformatics;literature search	Protein engineers have long been hard at work to harness biocatalysts as a natural source of regio-, stereo-, and chemoselectivity in order to carry out chemistry (reactions and/or substrates) not previously achieved with these enzymes. The extreme labor demands and exponential number of mutation combinations have induced computational advances in this domain. The first step in our virtual approach is to predict the correct conformations upon mutation of residues (i.e., rebuilding side chains). For this purpose, we opted for a combination of molecular mechanics and statistical data. In this work, we have developed automated computational tools to extract protein structural information and created conformational libraries for each amino acid dependent on a variable number of parameters (e.g., resolution, flexibility, secondary structure). We have also developed the necessary tool to apply the mutation and optimize the conformation accordingly. For side-chain conformation prediction, we obtained overall average root-mean-square deviations (RMSDs) of 0.91 and 1.01 Å for the 18 flexible natural amino acids within two distinct sets of over 3000 and 1500 side-chain residues, respectively. The commonly used dihedral angle differences were also evaluated and performed worse than the state of the art. These two metrics are also compared. Furthermore, we generated a family-specific library for kinases that produced an average 2% lower RMSD upon side-chain reconstruction and a residue-specific library that yielded a 17% improvement. Ultimately, since our protein engineering outlook involves using our docking software, Fitted/Impacts, we applied our mutation protocol to a benchmarked data set for self- and cross-docking. Our side-chain reconstruction does not hinder our docking software, demonstrating differences in pose prediction accuracy of approximately 2% (RMSD cutoff metric) for a set of over 200 protein/ligand structures. Similarly, when docking to a set of over 100 kinases, side-chain reconstruction (using both general and biased conformation libraries) had minimal detriment to the docking accuracy.		Joshua Pottel;Nicolas Moitessier	2015	Journal of chemical information and modeling	10.1021/acs.jcim.5b00525	biology;text mining;medical research;chemistry;computer science;bioinformatics;data science;machine learning;data mining	Comp.	12.05867712658423	-59.85887120963753	41232
7a1341444c8c3f92b2e9a67b56d2c048d33e5836	visual attention-driven spatial pooling for image memorability	visual saliency;image level representation visual attention driven spatial pooling image memorability object level saliency maps bottom up saliency maps fixed spatial pyramid structure feature extraction;image classification;image memorability;visualization layout image color analysis vectors computational modeling computer vision feature extraction;image representation;feature extraction;spatial pooling;spatial pooling visual saliency image memorability;image representation feature extraction image classification	In daily life, humans demonstrate astounding ability to remember images they see on magazines, commercials, TV, the web and so on, but automatic prediction of intrinsic memorability of images using computer vision and machine learning techniques was not investigated until a few years ago. However, despite these recent advances, none of the available approaches makes use of any attentional mechanism, a fundamental aspect of human vision, which selects relevant image regions for higher-level processing. Our goal in this paper is to explore the role of visual attention in understanding memorability of images. In particular, we present an attention-driven spatial pooling strategy for image memorability and show that the regions estimated by bottom-up and object-level saliency maps are more effective in predicting memorability than considering a fixed spatial pyramid structure as in the previous studies.	bottom-up parsing;computer vision;machine learning;map	Bora Celikkale;Aykut Erdem;Erkut Erdem	2013	2013 IEEE Conference on Computer Vision and Pattern Recognition Workshops	10.1109/CVPRW.2013.142	computer vision;contextual image classification;feature detection;feature extraction;computer science;machine learning;pattern recognition	Vision	22.908229651540037	-65.73696403683827	41318
e3831e01a7c38ac19804d02b8c4b9edd51200fe7	evolutionary design principles of modules that control cellular differentiation: consequences for hysteresis and multistationarity	evolution moleculaire;diferenciacion celular;cell differentiation;evolutionary design;bioinformatique;conception;cytodifferenciation;evolucion molecular;differentiation;differenciation;molecular evolution;diseno;design;diferenciacion;bioinformatica;cellular differentiation;bioinformatics	MOTIVATION Gene regulatory networks (GRNs) govern cellular differentiation processes and enable construction of multicellular organisms from single cells. Although such networks are complex, there must be evolutionary design principles that shape the network to its present form, gaining complexity from simple modules.   RESULTS To isolate particular design principles, we have computationally evolved random regulatory networks with a preference to result either in hysteresis (switching threshold depending on current state), or in multistationarity (having multiple steady states), two commonly observed dynamical features of GRNs related to differentiation processes. We have analyzed the resulting evolved networks and compared their structures and characteristics with real GRNs reported from experiments.   CONCLUSION We found that the artificially evolved networks have particular topologies and it was notable that these topologies share important features and similarities with the real GRNs, particularly in contrasting properties of positive and negative feedback loops. We conclude that the structures of real GRNs are consistent with selection to favor one or other of the dynamical features of multistationarity or hysteresis.   SUPPLEMENTARY INFORMATION Supplementary data are available at Bioinformatics online.	bioinformatics;cell differentiation process;continuous design;dynamical system;experiment;gene regulatory networks;gene regulatory network;histopathologic grade differentiation;hysteresis;negative feedback	Junil Kim;Tae-Geon Kim;Sung Hoon Jung;Jeong-Rae Kim;Taesung Park;Pat Heslop-Harrison;Kwang-Hyun Cho	2008	Bioinformatics	10.1093/bioinformatics/btn229	biology;bioinformatics;artificial intelligence;genetics;cellular differentiation	Comp.	5.660662379501446	-59.6198531894607	41364
a1092248e470e5226d436aac2f69ae64c99cc9ee	spectral graph theory and graph energy metrics show evidence for the alzheimer's disease disconnection syndrome in apoe-4 risk gene carriers	graph theory;biological patents;energy;biomedical journals;measurement;measurement graph theory alzheimer s disease genetics optical fiber networks optical fiber theory;text mining;europe pubmed central;optical fiber theory;neurophysiology biodiffusion biomedical mri brain diseases genetics graph theory image reconstruction medical disorders medical image processing;citation search;optical fiber networks;citation networks;genetics;magnetic flux density 3 t spectral graph theory graph energy metrics alzheimer s disease disconnection syndrome apoe 4 risk gene carriers network breakdown advanced mathematical descriptors structural connectivity diffusion weighted images connectivity network reconstruction whole brain tractography cortical disconnection graph spectrum link density nodal strength apoe 4 genetic risk factor late onset ad disconnected cortical regions dysfunctional networks weakened connections abnormal connections;research articles;apoe 4;abstracts;disconnection syndrome graph spectrum energy alzheimer s disease apoe 4;graph spectrum;open access;life sciences;alzheimer s disease;clinical guidelines;disconnection syndrome;full text;rest apis;orcids;europe pmc;biomedical research;bioinformatics;literature search	Our understanding of network breakdown in Alzheimer's disease (AD) is likely to be enhanced through advanced mathematical descriptors. Here, we applied spectral graph theory to provide novel metrics of structural connectivity based on 3-Tesla diffusion weighted images in 42 AD patients and 50 healthy controls. We reconstructed connectivity networks using whole-brain tractography and examined, for the first time here, cortical disconnection based on the graph energy and spectrum. We further assessed supporting metrics - link density and nodal strength - to better interpret our results. Metrics were analyzed in relation to the well-known APOE-4 genetic risk factor for late-onset AD. The number of disconnected cortical regions increased with the number of copies of the APOE-4 risk gene in people with AD. Each additional copy of the APOE-4 risk gene may lead to more dysfunctional networks with weakened or abnormal connections, providing evidence for the previously hypothesized “disconnection syndrome”.	alzheimer's disease;catabolism;copy (object);graph - visual representation;graph energy;mathematics;onset (audio);patients;spectral graph theory;stiff-person syndrome;whole earth 'lectronic link	Madelaine Daianu;Adam Mezher;Neda Jahanshad;Derrek P. Hibar;Talia M. Nir;Clifford R. Jack;Michael Weiner;Matt A. Bernstein;Paul M. Thompson	2015	2015 IEEE 12th International Symposium on Biomedical Imaging (ISBI)	10.1109/ISBI.2015.7163910	disconnection syndrome;text mining;energy;computer science;artificial intelligence;graph theory;theoretical computer science;machine learning;apolipoprotein e;mathematics;measurement	Comp.	21.848468094377996	-78.7807632889104	41428
352f75d026fbd0a7941875c98f8ee11e1ec8793c	large-scale extraction of accurate drug-disease treatment pairs from biomedical literature for drug repurposing	knowledge bases;drug discovery;medline;pharmaceutical preparations;drug repositioning;computational biology bioinformatics;drug therapy;artificial intelligence;algorithms;humans;combinatorial libraries;computer appl in life sciences;microarrays;bioinformatics	A large-scale, highly accurate, machine-understandable drug-disease treatment relationship knowledge base is important for computational approaches to drug repurposing. The large body of published biomedical research articles and clinical case reports available on MEDLINE is a rich source of FDA-approved drug-disease indication as well as drug-repurposing knowledge that is crucial for applying FDA-approved drugs for new diseases. However, much of this information is buried in free text and not captured in any existing databases. The goal of this study is to extract a large number of accurate drug-disease treatment pairs from published literature. In this study, we developed a simple but highly accurate pattern-learning approach to extract treatment-specific drug-disease pairs from 20 million biomedical abstracts available on MEDLINE. We extracted a total of 34,305 unique drug-disease treatment pairs, the majority of which are not included in existing structured databases. Our algorithm achieved a precision of 0.904 and a recall of 0.131 in extracting all pairs, and a precision of 0.904 and a recall of 0.842 in extracting frequent pairs. In addition, we have shown that the extracted pairs strongly correlate with both drug target genes and therapeutic classes, therefore may have high potential in drug discovery. We demonstrated that our simple pattern-learning relationship extraction algorithm is able to accurately extract many drug-disease pairs from the free text of biomedical literature that are not captured in structured databases. The large-scale, accurate, machine-understandable drug-disease treatment knowledge base that is resultant of our study, in combination with pairs from structured databases, will have high potential in computational drug repurposing tasks.	abstract summary;biomedical research;class;drug delivery systems;drug discovery;drug repositioning;knowledge base;medline;paget's disease, mammary;published database;relationship extraction;resultant;scientific publication;algorithm	Rong Xu;QuanQiu Wang	2012		10.1186/1471-2105-14-181	pharmacotherapy;biology;dna microarray;drug repositioning;computer science;bioinformatics;data science;drug discovery	NLP	-2.753112440036862	-64.97361357610056	41452
d474131121e434714c242cce0ec165e06df62e0e	human brain white matter atlas: identification and assignment of common anatomical structures in superficial white matter	female;white matter;diffusion tensor images;medical illustration;middle aged;adolescent;male;magnetic resonance image;association fiber;healthy subjects;brain mapping;image interpretation computer assisted;adult;magnetic resonance imaging;human;anatomy artistic;atlas;cerebral cortex;humans;human brain;diffusion tensor;diffusion magnetic resonance imaging	Structural delineation and assignment are the fundamental steps in understanding the anatomy of the human brain. The white matter has been structurally defined in the past only at its core regions (deep white matter). However, the most peripheral white matter areas, which are interleaved between the cortex and the deep white matter, have lacked clear anatomical definitions and parcellations. We used axonal fiber alignment information from diffusion tensor imaging (DTI) to delineate the peripheral white matter, and investigated its relationship with the cortex and the deep white matter. Using DTI data from 81 healthy subjects, we identified nine common, blade-like anatomical regions, which were further parcellated into 21 subregions based on the cortical anatomy. Four short association fiber tracts connecting adjacent gyri (U-fibers) were also identified reproducibly among the healthy population. We anticipate that this atlas will be useful resource for atlas-based white matter anatomical studies.	anatomic structures;assignment (computer science);cervical atlas;diffusion tensor imaging;peripheral;the superficial;tissue fiber;white matter	Kenichi Oishi;Karl Zilles;Katrin Amunts;Andreia Faria;Hangyi Jiang;Xin Li;Kazi Akhter;Kegang Hua;Roger P. Woods;Arthur W. Toga;G. Bruce Pike;Pedro Rosa-Neto;Alan C. Evans;Jiangyang Zhang;Hao Huang;Michael I. Miller;Peter C. M. van Zijl;John C. Mazziotta;Susumu Mori	2008	NeuroImage	10.1016/j.neuroimage.2008.07.009	psychology;diffusion mri;neuroscience;radiology;medicine;pathology;atlas;magnetic resonance imaging;nuclear medicine;brain mapping	ML	20.624900221895214	-78.70249233929512	41490
c7236f11eae1bc01b49d5701dc6d465de99809b8	a tree ensemble-based two-stage model for advanced-stage colorectal cancer survival prediction		Abstract Classification techniques have widely been applied to cancer survival prediction for predicting survival or death of patients. However, little attention has been paid to patients who are predicted to die. In this work, we consider survival prediction as a two-stage task, where the first stage is to predict whether the outcome is survival or not, and the second stage is to predict the remaining lifespan for patients whose predicted outcome is death. To this end, we propose a two-stage machine learning model to enhance cancer survival prediction. At the first stage, a tree-based imbalanced ensemble classification method is proposed for classification of the survivability of advanced-stage cancer patients. At the second stage, a selective ensemble regression method is proposed for survival time prediction, where a priori knowledge is adopted for feature selection and the mean proportion of error interval is proposed for selecting base learners. Extensive computational studies performed on colorectal cancer data from SEER database demonstrate that the proposed two-stage model can achieve a more accurate prediction compared to the one-stage regression model. The results show that the proposed classification approach can effectively handle the imbalanced survivability data, and the proposed regression method outperforms several state-of-the-art regression models.		Yuyan Wang;Dujuan Wang;Xin Ye;Yanzhang Wang;Yunqiang Yin;Yaochu Jin	2019	Inf. Sci.	10.1016/j.ins.2018.09.046	regression analysis;mathematics;machine learning;artificial intelligence;feature selection;cancer;colorectal cancer	AI	6.766791424745276	-76.87433055630326	41576
3804110830e5892c93398d6097e6362549192401	using ensemble models in the histological examination of tissue abnormalities		Classification models for the automatic detection of abnormalities on histological samples do exists, with an active debate on the cost associated with false negative diagnosis (underdiagnosis) and false positive diagnosis (overdiagnosis). Current models tend to underdiagnose, failing to recognize a potentially fatal disease. The objective of this study is to investigate the possibility of automatically identifying abnormalities in tissue samples through the use of an ensemble model on data generated by histological examination and to minimize the number of false negative cases. Keywords—Histology, data mining, CART, logistic regression, ensemble model, classification, breast cancer	data mining;decision tree learning;ensemble forecasting;failure;logistic regression	Giancarlo Crocetti;Michael Coakley;Phil Dressner;Wanda Kellum;Tamba Lamin	2014	CoRR		pattern recognition;artificial intelligence;computer science;ensemble forecasting;overdiagnosis	AI	6.521534801766235	-77.05084661530688	41634
728391eff09450f4fe425e7f2c8ae7a7cac70ccb	the secret lives of experiments: methods reporting in the fmri literature	experimental design;analysis methods;fmri;statistical power;methods reporting;reproducibility	Replication of research findings is critical to the progress of scientific understanding. Accordingly, most scientific journals require authors to report experimental procedures in sufficient detail for independent researchers to replicate their work. To what extent do research reports in the functional neuroimaging literature live up to this standard? The present study evaluated methods reporting and methodological choices across 241 recent fMRI articles. Many studies did not report critical methodological details with regard to experimental design, data acquisition, and analysis. Further, many studies were underpowered to detect any but the largest statistical effects. Finally, data collection and analysis methods were highly flexible across studies, with nearly as many unique analysis pipelines as there were studies in the sample. Because the rate of false positive results is thought to increase with the flexibility of experimental designs, the field of functional neuroimaging may be particularly vulnerable to false positives. In sum, the present study documented significant gaps in methods reporting among fMRI studies. Improved methodological descriptions in research reports would yield significant benefits for the field.	chamaecyparis lawsoniana;choice behavior;data collection;data acquisition;description;design of experiments;document completion status - documented;experiment;functional neuroimaging;journal;largest;neuritis, autoimmune, experimental;pipeline (computing);research report;self-replication;benefit;fmri	Joshua Carp	2012	NeuroImage	10.1016/j.neuroimage.2012.07.004	computer science;reproducibility;statistical power;data mining;design of experiments;social psychology;statistics	HCI	-2.6339547819259264	-68.79772826119353	41641
b835b09f35b565a1421ad4faf73921ef4aaececb	transferability of tag snps to capture common genetic variation in dna repair genes across multiple populations	dna repair;single nucleotide polymorphism;cost effectiveness;linkage disequilibrium;comparative analysis;human genome;genetic variation;genetic association	Genetic association studies can be made more cost-effective by exploiting linkage disequilibrium patterns between nearby single-nucleotide polymorphisms (SNPs). The International HapMap Project now offers a dense SNP map across the human genome in four population samples. One question is how well tag SNPs chosen from a resource like HapMap can capture common variation in independent disease samples. To address the issue of tag SNP transferability, we genotyped 2,783 SNPs across 61 genes (with a total span of 6 Mb) involved in DNA repair in 466 individuals from multiple populations. We picked tag SNPs in samples with European ancestry from the Centre d'Etude du Polymorphisme Humain, and evaluated coverage of common variation in the other samples. Our comparative analysis shows that common variation in non-African samples can be captured robustly with only marginal loss in terms of the maximum r2. We also evaluated the transferability of specified multi-marker haplotypes as predictors for untyped SNPs, and demonstrate that they provide equivalent coverage compared to single-marker tests (pairwise tags) while requiring fewer SNPs for genotyping. The efficacy of a tagging-based approach in studying genotype-phenotype correlations in complex traits is strongly supported by our empirical results.	dna repair;genetic association studies;genetic polymorphism;haplotypes;hearing loss, high-frequency;hereditary diseases;international hapmap project;linkage (software);marginal model;nitroprusside;numerous;population;qualitative comparative analysis;single nucleotide polymorphism;tag (metadata);trait	Paul I. W. de Bakker;Robert R. Graham;David Altshuler;Brian E. Henderson;Christopher A. Haiman	2006	Pacific Symposium on Biocomputing. Pacific Symposium on Biocomputing		single-nucleotide polymorphism;tag snp;linkage disequilibrium;snp array;qualitative comparative analysis;biology;human genome;molecular biology;cost-effectiveness analysis;human genetic variation;dna repair;bioinformatics;genetic association;genetic variation;genetics	Comp.	3.05883047353052	-52.948618945084675	41684
2d686f478e028bff259b982f088ab926eaf4984a	pep-fold: an updated de novo structure prediction server for both linear and disulfide bonded cyclic peptides	software;peptides;disulfides;internet;protein conformation;peptides cyclic	In the context of the renewed interest of peptides as therapeutics, it is important to have an on-line resource for 3D structure prediction of peptides with well-defined structures in aqueous solution. We present an updated version of PEP-FOLD allowing the treatment of both linear and disulphide bonded cyclic peptides with 9-36 amino acids. The server makes possible to define disulphide bonds and any residue-residue proximity under the guidance of the biologists. Using a benchmark of 34 cyclic peptides with one, two and three disulphide bonds, the best PEP-FOLD models deviate by an average RMS of 2.75 Å from the full NMR structures. Using a benchmark of 37 linear peptides, PEP-FOLD locates lowest-energy conformations deviating by 3 Å RMS from the NMR rigid cores. The evolution of PEP-FOLD comes as a new on-line service to supersede the previous server. The server is available at: http://bioserv.rpbs.univ-paris-diderot.fr/PEP-FOLD.	amino acids;benchmark (computing);cyclic peptides;de novo protein structure prediction;de novo transcriptome assembly;fold (higher-order function);magnetic resonance imaging;muscle rigidity;online and offline;phosphoenolpyruvate;server (computer);server (computing);vocal cord paralysis	Pierre Thévenet;Yimin Shen;Julien Maupetit;Frédéric Guyon;Philippe Derreumaux;Pierre Tufféry	2012		10.1093/nar/gks419	biochemistry;protein structure;the internet;bioinformatics	Theory	11.227563400490922	-61.259175790259064	41712
5910b21adfc228961e73bfb6d760090835db2a12	a variant of tnfr2-fc fusion protein exhibits improved efficacy in treating experimental rheumatoid arthritis	cell fusion;animals;histocytochemistry;mice;tumor necrosis factor alpha;arthritis experimental;rats;collagen induced arthritis;cell survival;no response;immunoglobulin g;dissociation constant;receptors tumor necrosis factor;arthritis;site directed mutagenesis;ligand binding;autoimmune disease;collagens;surface plasmon resonance;rat model;inflammation;fusion protein;protein binding;computational protein design;crystal structure;computational biology;mutagenesis;mutation;rheumatoid arthritis;cell line	Etanercept, a TNF receptor 2-Fc fusion protein, is currently being used for the treatment of rheumatoid arthritis (RA). However, 25% to 38% of patients show no response which is suspected to be partially due to insufficient affinity of this protein to TNFalpha. By using computational protein design, we found that residue W89 and E92 of TNFR2 were critical for ligand binding. Among several mutants tested, W89Y/E92N displayed 1.49-fold higher neutralizing activity to TNFalpha, as compared to that of Etanercept. Surface plasmon resonance (SPR) based binding assay revealed that the equilibrium dissociation constant of W89Y/E92N to TNFalpha was 3.65-fold higher than that of Etanercept. In a rat model of collagen-induced arthritis (CIA), W89Y/E92N showed a significantly better ability than Etanercept in reducing paw swelling and improvement of arthritic joint histopathologically. These data demonstrate that W89Y/E92N is potentially a better candidate with improved efficacy in treating RA and other autoimmune diseases.	autoimmune diseases;edema;etanercept;exhibits as topic;ligands;patients;processor affinity;randall–selitto test;rheumatoid arthritis;surface plasmon resonance;traffic collision avoidance system;tree rearrangement;tumor necrosis factor-alpha;chimeric protein;mutant	Tong Yang;Zheng Wang;Fang Wu;Jingwei Tan;Yijun Shen;Erguang Li;Jingzhi Dai;Ronghai Shen;Gang Li;Jinsong Wu;Luochun Wang;Haibo Wang;Yanjun Liu	2010		10.1371/journal.pcbi.1000669	mutation;dissociation constant;biology;plasma protein binding;mutagenesis;surface plasmon resonance;site-directed mutagenesis;crystal structure;fusion protein;cell fusion;tumor necrosis factor alpha;ligand;immunology;genetics;cell culture	Comp.	9.037224687898567	-61.18616691927275	41722
69093b48473f9fd6838cd4dab308bcddbe5880f9	development of a detailed model of calcium dynamics at the postsynaptic spine of an excitatory synapse	magnesium;ions;biological system modeling;calcium;transient analysis;computational modeling;mathematical model	Postsynaptic calcium dynamics play a critical role in synaptic plasticity, but are often difficult to measure in experimental protocols due to their relatively fast rise and decay times, and the small spine dimensions. To circumvent these limitations, we propose to develop a computational model of calcium dynamics in the postsynaptic spine. This model integrates the main elements that participate in calcium concentration influx, efflux, diffusion and buffering. These consist of (i) spine geometry; (ii) calcium influx through NMDA receptors and voltage-dependent calcium channels (VDCC); (iii) calcium efflux with plasma membrane calcium pumps (PMCA) and sodium-calcium exchangers (NCX); (iv) intracellular calcium stores; and (v) calcium buffers. We herein present computational results we obtained and compare them with experimentally measured data, thereby validating the proposed model. Overall the development of such postsynaptic calcium model may help us better understand the intricacies of interplay between the different elements that shape calcium dynamics and impact synaptic plasticity in normal functions and pathologies. This model also constitutes a first step in the development of a nonlinear input-output calcium dynamics model for multi-scale, large scale neuronal simulations.	buffers;calcium channel;computation;computational model;emoticon;excitatory amino acids;experiment;n-methyl-d-aspartate receptors;n-methylaspartate;neuronal plasticity;nonlinear system;numerous;plasma active;plasma membrane calcium-transporting atpases;protocols documentation;simulation;sodium;synapse;synaptic package manager	Eric Y. Hu;Jean-Marie Bouteiller;Dong Song;Theodore W. Berger	2016	2016 38th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)	10.1109/EMBC.2016.7592121	neuroscience;calcium;mathematical model;magnesium;anatomy	DB	12.079225576722614	-68.24825775762146	41761
03da7c6e947ccd8506712652d8b3e2eeeffd5ad9	single-cycle image recognition using an adaptive granularity associative memory network	image recognition;computational grid;binary image;wireless sensor network;computer network;large scale;distributed hierarchical graph neuron dhgn;pattern recognition;associative memory;load balance;coarse grained;complexity estimation	Pattern recognition involving large-scale associative memory applications, generally constitutes tightly coupled algorithms and requires substantial computational resources. Thus these schemes do not work well on large coarse grained systems such as computational grids and are invariably unsuited for fine grained environments such as wireless sensor networks (WSN). Distributed Hierarchical Graph Neuron (DHGN) is a single-cycle pattern recognising algorithm, which can be implemented from coarse to fine grained computational networks. In this paper we describe a two-level enhancement to DHGN, which enables it to act as a standard binary image recogniser. This paper demonstrates that our single-cycle learning approach can be successfully applied to denser patterns, such as black and white images. Additionally we are able to load-balance the pattern recognition processes, irrespective of the granularity of the underlying computational network.	computer vision;content-addressable memory	Anang Hudaya Muhamad Amin;Asad I. Khan	2008		10.1007/978-3-540-89378-3_39	wireless sensor network;binary image;computer science;load balancing;theoretical computer science;machine learning;distributed computing	Vision	22.32414552851977	-54.49484608169319	41777
d64fc1d09557eac469cdf66e8b167281fe21c4ef	computational methods for gene orthology inference	evolution molecular;animals;genomics;phylogeny;genome;algorithms;humans;computational biology;synteny	Accurate inference of orthologous genes is a pre-requisite for most comparative genomics studies, and is also important for functional annotation of new genomes. Identification of orthologous gene sets typically involves phylogenetic tree analysis, heuristic algorithms based on sequence conservation, synteny analysis, or some combination of these approaches. The most direct tree-based methods typically rely on the comparison of an individual gene tree with a species tree. Once the two trees are accurately constructed, orthologs are straightforwardly identified by the definition of orthology as those homologs that are related by speciation, rather than gene duplication, at their most recent point of origin. Although ideal for the purpose of orthology identification in principle, phylogenetic trees are computationally expensive to construct for large numbers of genes and genomes, and they often contain errors, especially at large evolutionary distances. Moreover, in many organisms, in particular prokaryotes and viruses, evolution does not appear to have followed a simple 'tree-like' mode, which makes conventional tree reconciliation inapplicable. Other, heuristic methods identify probable orthologs as the closest homologous pairs or groups of genes in a set of organisms. These approaches are faster and easier to automate than tree-based methods, with efficient implementations provided by graph-theoretical algorithms enabling comparisons of thousands of genomes. Comparisons of these two approaches show that, despite conceptual differences, they produce similar sets of orthologs, especially at short evolutionary distances. Synteny also can aid in identification of orthologs. Often, tree-based, sequence similarity- and synteny-based approaches can be combined into flexible hybrid methods.	analysis of algorithms;annotation;conserved sequence;distance;gene duplication abnormality;genome;genomics;graph theory;heuristic;homology (biology);inference;phylogenetic tree;phylogenetics;probability;prokaryote;sequence homology;synteny;trees (plant);virus;algorithm	David M. Kristensen;Yuri I. Wolf;Arcady R. Mushegian;Eugene V. Koonin	2011	Briefings in bioinformatics	10.1093/bib/bbr030	biology;genomics;bioinformatics;computational phylogenetics;tree rearrangement;synteny;genetics;genome	Comp.	1.4391364515596454	-53.81479749532979	41811
c2bda4872d4c119f92fe06a77e1a079d9d0b7980	dynamic causal modelling of seizure activity in a rat model	computational neuroscience;model;rat;connectivity;epilepsy	This paper presents a physiological account of seizure activity and its evolution over time using a rat model of induced epilepsy. We analyse spectral activity recorded in the hippocampi of three rats who received kainic acid injections in the right hippocampus. We use dynamic causal modelling of seizure activity and Bayesian model reduction to identify the key synaptic and connectivity parameters that underlie seizure onset. Using recent advances in hierarchical modelling (parametric empirical Bayes), we characterise seizure onset in terms of slow fluctuations in synaptic excitability of specific neuronal populations. Our results suggest differences in the pathophysiology - of seizure activity in the lesioned versus the non-lesioned hippocampus - with pronounced changes in excitation-inhibition balance and temporal summation on the lesioned side. In particular, our analyses suggest that marked reductions in the synaptic time constant of the deep pyramidal cells and the self-inhibition of inhibitory interneurons (in the lesioned hippocampus) are sufficient to explain changes in spectral activity. Although these synaptic changes are consistent over rats, the resulting electrophysiological phenotype can be quite diverse.	biological markers;causal filter;causal model;dynamical system;electroencephalography;epilepsy;excitation;interneurons;kainic acid;onset (audio);parasitic diseases, animal;population;post-ictal memory loss;pyramidal cells;seizures;synaptic package manager	Margarita Papadopoulou;Gerald K. Cooray;Richard E Rosch;Rosalyn J. Moran;Daniele Marinazzo;Karl J. Friston	2017	NeuroImage	10.1016/j.neuroimage.2016.08.062	psychology;neuroscience;developmental psychology;connectivity;machine learning;computational neuroscience	ML	19.498863196504814	-74.89786608635926	41815
5bdc5529568dacd959254195d09911d8a3aba67c	mrmprobs suite for metabolomics using large-scale mrm assays		UNLABELLED We developed new software environment for the metabolome analysis of large-scale multiple reaction monitoring (MRM) assays. It supports the data format of four major mass spectrometer vendors and mzML common data format. This program provides a process pipeline from the raw-format import to high-dimensional statistical analyses. The novel aspect is graphical user interface-based visualization to perform peak quantification, to interpolate missing values and to normalize peaks interactively based on quality control samples. Together with the software platform, the MRM standard library of 301 metabolites with 775 transitions is also available, which contributes to the reliable peak identification by using retention time and ion abundances.   AVAILABILITY AND IMPLEMENTATION MRMPROBS is available for Windows OS under the creative-commons by-attribution license at http://prime.psc.riken.jp.	global variable;graphical user interface;imagery;interactivity;interpolation;ions;mass spectrometers (device);mass spectrometry data format;metabolite;metabolome;metabolomics;microsoft windows;missing data;multiple myeloma;normalize;operating system;quantitation;register machine;standard library;user interface device component;attribution	Hiroshi Tsugawa;Mitsuhiro Kanazawa;Atsushi Ogiwara;Masanori Arita	2014	Bioinformatics	10.1093/bioinformatics/btu203	bioinformatics;data mining	Visualization	-2.6638367074939997	-57.79071993223226	41878
9314ce75d089c8d643ff6d8d6c8138c59ce5ab88	ancac: amino acid, nucleotide, and codon analysis of cogs – a tool for sequence bias analysis in microbial orthologs	software;base composition;phylogeny;archaea;nucleotides;codon;computational biology bioinformatics;proteins;archaeal proteins;amino acids;algorithms;sequence analysis;temperature;combinatorial libraries;computer appl in life sciences;databases protein;microarrays;bioinformatics	The COG database is the most popular collection of orthologous proteins from many different completely sequenced microbial genomes. Per definition, a cluster of orthologous groups (COG) within this database exclusively contains proteins that most likely achieve the same cellular function. Recently, the COG database was extended by assigning to every protein both the corresponding amino acid and its encoding nucleotide sequence resulting in the NUCOCOG database. This extended version of the COG database is a valuable resource connecting sequence features with the functionality of the respective proteins. Here we present ANCAC, a web tool and MySQL database for the analysis of amino acid, nucleotide, and codon frequencies in COGs on the basis of freely definable phylogenetic patterns. We demonstrate the usefulness of ANCAC by analyzing amino acid frequencies, codon usage, and GC-content in a species- or function-specific context. With respect to amino acids we, at least in part, confirm the cognate bias hypothesis by using ANCAC’s NUCOCOG dataset as the largest one available for that purpose thus far. Using the NUCOCOG datasets, ANCAC connects taxonomic, amino acid, and nucleotide sequence information with the functional classification via COGs and provides a GUI for flexible mining for sequence-bias. Thereby, to our knowledge, it is the only tool for the analysis of sequence composition in the light of physiological roles and phylogenetic context without requirement of substantial programming-skills.	amino acids;base sequence;cell physiology;codon (nucleotide sequence);genome;genome, microbial;graphical user interface;homology (biology);largest;mysql;nucleotides;phylogenetics;sequence homology;silo (dataset)	Arno Meiler;Claudia Klinger;Michael Kaufmann	2012		10.1186/1471-2105-13-223	biology;nucleotide;dna microarray;temperature;bioinformatics;sequence analysis;genetic code;genetics;archaea;phylogenetics	Comp.	0.8637097891936809	-58.912288719570114	41892
3681f1a4e296bc3cc80d3f62fc4a40cbf83a4591	cortical hypercolumns and the topology of random orientation maps	random orientation distributions;topology;pinwheels;primate visual cortex topology random orientation maps smoothing orientation vortices orientation tuning monkey visual cortex pinwheels continuous orientation maps random orientation distributions cortical hypercolumn patterns puff extra structure monkey v 1 visually excitable neural tissue null hypothesis cat visual cortex area 18;art;orientation vortices;random orientation maps;band pass filters;puff extra structure;monkey visual cortex;orientation map;monkey v 1;primate visual cortex;neuroscience;smoothing methods;computational modeling;cortical hypercolumn patterns;stochastic processes;smoothing;continuous orientation maps;visually excitable neural tissue;lifting equipment;topology neurons neuroscience smoothing methods stochastic processes computational modeling band pass filters white noise lifting equipment art;neurons;hypothesis;vision;computer simulation;orientation tuning;visual cortex;white noise;cat visual cortex area 18	"""Smoothing a random pattern of orientations causes the appearance of orientation """"vortices."""" These patterns are similar to the hypercolumn pattern of orientation tuning in monkey visual cortex, and to the """"pinwheels"""" that have been observed in cat area 18. The generic presence of such patterns in continuous orientation maps is a consequence of a basic topological theorem (nonretraction of R/sup 2/->S/sup 1/), together with the stochastic properties of random orientation distributions. There as a close correspondence between experimental results from cat area 18 and computer simulations based on smoothed random orientations. Several of the qualitative features of cortical hypercolumn patterns, including the """"puff-extra"""" structure of monkey V-1, are evident in our simulations. There are two important conclusions from this work. (1) Experimental observation of orientation """"vortex"""" structure in any visually excitable neural tissue must be evaluated in the light of the null hypothesis that these patterns are readily formed from smoothed, random orientation distributions, (2) The underlying explanation for the """"vortex"""" patterns which likely exist in primate and cat visual cortex is fundamentally topological, and follows directly from the definition of orientation, and the existence of local correlation of orientation in cortex."""	map	Eric L. Schwartz;Alan S. Rojer	1994		10.1109/ICPR.1994.576893	computer simulation;vision;computer vision;hypothesis;computer science;machine learning;mathematics;band-pass filter;white noise;computational model;statistics;smoothing;lifting equipment	Crypto	19.76217360882694	-69.15039336035828	41931
bab8096e8e8a35845db2606264819ca45aaded3e	spectral kernels for probabilistic analysis and clustering of shapes		We propose a framework for probabilistic shape clustering based on kernel-space embeddings derived from spectral signatures. Our root motivation is to investigate practical yet principled clustering schemes that rely on geometrical invariants of shapes rather than explicit registration. To that end we revisit the use of the Laplacian spectrum and introduce a parametric family of reproducing kernels for shapes, extending WESD [12] and shape DNA [20] like metrics. Parameters provide control over the relative importance of local and global shape features, can be adjusted to emphasize a scale of interest or set to uninformative values. As a result of kernelization, shapes are embedded in an infinite-dimensional inner product space. We leverage this structure to formulate shape clustering via a Bayesian mixture of kernel-space Principal Component Analysers. We derive simple variational Bayes inference schemes in Hilbert space, addressing technicalities stemming from the infinite dimensionality. The proposed approach is validated on tasks of unsupervised clustering of sub-cortical structures, as well as classification of cardiac left ventricles w.r.t. pathological groups.	antivirus software;cluster analysis;embedded system;hilbert space;kernelization;laplacian matrix;probabilistic analysis of algorithms;spectral method;spectral shape analysis;stemming;user space;variational principle	Loïc Le Folgoc;Aditya V. Nori;Antonio Criminisi	2017		10.1007/978-3-319-59050-9_6	probabilistic analysis of algorithms;parametric family;inner product space;algorithm;principal component analysis;kernelization;probabilistic logic;cluster analysis;curse of dimensionality;computer science	ML	16.450604928143804	-54.57058877924833	41938
b4968e70305f64e16d5d8ccd0bdb2e51a29f5152	ddig-in: detecting disease-causing genetic variations due to frameshifting indels and nonsense mutations employing sequence and structural properties at nucleotide and protein levels	qh426 genetics;r medicine general	MOTIVATION Frameshifting (FS) indels and nonsense (NS) variants disrupt the protein-coding sequence downstream of the mutation site by changing the reading frame or introducing a premature termination codon, respectively. Despite such drastic changes to the protein sequence, FS indels and NS variants have been discovered in healthy individuals. How to discriminate disease-causing from neutral FS indels and NS variants is an understudied problem.   RESULTS We have built a machine learning method called DDIG-in (FS) based on real human genetic variations from the Human Gene Mutation Database (inherited disease-causing) and the 1000 Genomes Project (GP) (putatively neutral). The method incorporates both sequence and predicted structural features and yields a robust performance by 10-fold cross-validation and independent tests on both FS indels and NS variants. We showed that human-derived NS variants and FS indels derived from animal orthologs can be effectively employed for independent testing of our method trained on human-derived FS indels. DDIG-in (FS) achieves a Matthews correlation coefficient (MCC) of 0.59, a sensitivity of 86%, and a specificity of 72% for FS indels. Application of DDIG-in (FS) to NS variants yields essentially the same performance (MCC of 0.43) as a method that was specifically trained for NS variants. DDIG-in (FS) was shown to make a significant improvement over existing techniques.	1,5-dideoxy-1,5-iminogalactitol;amino acid sequence;codon, nonsense;cross reactions;cross-validation (statistics);downstream (software development);hereditary diseases;homology (biology);machine learning;matthews correlation coefficient;nonsense mutation;nucleotides;one thousand;open reading frames;reading frames (nucleotide sequence);reason applied by forcast logic to project this vaccine:finding:point in time:^patient:nominal;sensitivity and specificity;sensor;variation (genetics)	Lukas Folkman;Yuedong Yang;Zhixiu Li;Bela Stantic;Abdul Sattar;Matthew E. Mort;David N. Cooper;Yunlong Liu;Yaoqi Zhou	2015	Bioinformatics	10.1093/bioinformatics/btu862	biology;molecular biology;bioinformatics;genetics	Comp.	2.403088909502621	-56.03351560004927	41944
1b9bfe7d677237cba583779aa61a1b9447c0aea2	using mechanistic bayesian networks to identify downstream targets of the sonic hedgehog pathway	bayesian network;genetic background;signal transduction;gene regulatory networks;bayes theorem;gene expression data;data type;journal article;computational biology bioinformatics;bayesian learning;analytical method;algorithms;hedgehog proteins;combinatorial libraries;computational biology;sonic hedgehog;computer appl in life sciences;gene expression profiling;oligonucleotide array sequence analysis;open source;microarrays;bioinformatics	The topology of a biological pathway provides clues as to how a pathway operates, but rationally using this topology information with observed gene expression data remains a challenge. We introduce a new general-purpose analytic method called Mechanistic Bayesian Networks (MBNs) that allows for the integration of gene expression data and known constraints within a signal or regulatory pathway to predict new downstream pathway targets. The MBN framework is implemented in an open-source Bayesian network learning package, the Python Environment for Bayesian Learning (PEBL). We demonstrate how MBNs can be used by modeling the early steps of the sonic hedgehog pathway using gene expression data from different developmental stages and genetic backgrounds in mouse. Using the MBN approach we are able to automatically identify many of the known downstream targets of the hedgehog pathway such as Gas1 and Gli1, along with a short list of likely targets such as Mig12. The MBN approach shown here can easily be extended to other pathways and data types to yield a more mechanistic framework for learning genetic regulatory models.	anatomy, regional;bayesian network;downstream (software development);erinaceidae;gli1 protein, human;gene expression;gene regulatory network;general-purpose modeling;open-source software;prtn3 wt allele;python;sonic hedgehog pathway;the psychology experiment building language (pebl)	Abhik Shah;Toyoaki Tenzen;Andrew P. McMahon;Peter J. Woolf	2009		10.1186/1471-2105-10-433	biology;gene regulatory network;dna microarray;data type;computer science;bioinformatics;bayesian network;gene expression profiling;bayes' theorem;bayesian inference;genetics;signal transduction	Comp.	4.032426607946841	-57.18634241491678	42013
c7310107007b9db15d79f02cf1aa7b2bb7bb0dfb	spatiotemporally optimal fractionation in radiotherapy	linear quadratic model;convex programming;intensity modulated radiation therapy	We present a spatiotemporally integrated formulation of the optimal fractionation problem using the standard log-linear-quadratic survival model. Our objective is to choose a fluencemap and a number of fractions so as to maximize the biological effect of tumor dose averaged over its voxels subject to maximum dose, mean dose, and dose-volume constraints for various normal tissues. Constrains are expressed in biologically effective dose equivalents. We propose an efficient convex programming method to approximately solve the resulting computationally difficult model. Through extensive computer simulations on ten head-and-neck and prostate cancer test cases with a broad range of radiobiological parameters, we compare the biological effect on tumor obtained by our integrated approach relative to that from two other models. The first is a traditional IMRT fluence-map optimization model that does not optimize the number of fractions. The second assumes that a fluence-map is available a priori from a traditional IMRT optimization model and then optimizes the number of fractions, thus separating the spatial and temporal components. The improvements in tumor biological effect over IMRT were 9%-52% with average 22%, and 53%-108% with average 69%, for head-and-neck and prostate, respectively. The improvements in tumor biological effect over the spatiotemporally separated model were 15%-45% with average 27%, and 17%-23% with average 21%, for head-and-neck and prostate, respectively. This suggests that integrated optimization of the fluence-map and the number of fractions could improve treatment efficacy as measured within the linear-quadratic framework.	computer simulation;convex optimization;effective dose (radiation);function (biology);log-linear model;mathematical optimization;test case;voxel	Fatemeh Saberian;Archis Ghate;Minsun Kim	2017	INFORMS Journal on Computing	10.1287/ijoc.2016.0740	mathematical optimization;convex optimization;simulation;mathematics	Comp.	13.53221491866517	-53.31269348837765	42070
5d4d26453fac2928e821c4700309074bdfd31c5c	haplotype phasing by multi-assembly of shared haplotypes: phase-dependent interactions between rare variants		In this paper we propose algorithmic strategies, Lander-Waterman-like statistical estimates, and genome-wide software for haplotype phasing by multi-assembly of shared haplotypes. Specifically, we consider four types of results which together provide a comprehensive workflow of GWAS data sets: (1) statistics of multi-assembly of shared haplotypes (2) graph theoretic algorithms for haplotype assembly based on conflict graphs of sequencing reads (3) inference of pedigree structure through haplotype sharing via tract finding algorithms and (4) multi-assembly of shared haplotypes of cases, controls, and trios. The input for the workflows that we consider are any of the combination of: (A) genotype data (B) next generation sequencing (NGS) (C) pedigree information. (1) We present Lander-Waterman-like statistics for NGS projects for the multi-assembly of shared haplotypes. Results are presented in Sec. 2. (2) In Sec. 3, we present algorithmic strategies for haplotype assembly using NGS, NGS + genotype data, and NGS + pedigree information. (3) This work builds on algorithms presented in Halldórsson et al. and are part of the same library of tools co-developed for GWAS workflows. (4) Section 3.3.1 contains algorithmic strategies for multi-assembly of GWAS data. We present algorithms for assembling large data sets and for determining and using shared haplotypes to more reliably assemble and phase the data. Workflows 1-4 provide a set of rigorous algorithms which have the potential to identify phase-dependent interactions between rare variants in linkage equilibrium which are associated with cases. They build on our extensive work on haplotype phasing, haplotype assembly, and whole genome assembly comparison.	biopolymer sequencing;communications satellite;estimated;genome assembly sequence;genome-wide association study;graph - visual representation;haplotypes;inference;interaction;linkage (software);lunar lander (video game series);massively-parallel sequencing;numerous;reading (activity);smith–waterman algorithm;theory;tract (literature);whole genome sequencing;genetic linkage;genetic pedigree	Bjarni V. Halldórsson;Derek Aguiar;Sorin Istrail	2011	Pacific Symposium on Biocomputing. Pacific Symposium on Biocomputing		bioinformatics;sequence assembly;haplotype;genome-wide association study;linkage disequilibrium;data set;dna sequencing;genotype;biology;graph	Comp.	2.3631558022147194	-52.685904325661646	42085
411627e348afe1bfb182c09a467de21a9563e1dd	multi-connection pattern analysis: decoding the representational content of neural communication	decoding;functional connectivity;functional magnetic resonance imaging (fmri);intracranial electroencephalography (ieeg);multivariate statistical analysis;representation similarity analysis	The lack of multivariate methods for decoding the representational content of interregional neural communication has left it difficult to know what information is represented in distributed brain circuit interactions. Here we present Multi-Connection Pattern Analysis (MCPA), which works by learning mappings between the activity patterns of the populations as a factor of the information being processed. These maps are used to predict the activity from one neural population based on the activity from the other population. Successful MCPA-based decoding indicates the involvement of distributed computational processing and provides a framework for probing the representational structure of the interaction. Simulations demonstrate the efficacy of MCPA in realistic circumstances. In addition, we demonstrate that MCPA can be applied to different signal modalities to evaluate a variety of hypothesis associated with information coding in neural communications. We apply MCPA to fMRI and human intracranial electrophysiological data to provide a proof-of-concept of the utility of this method for decoding individual natural images and faces in functional connectivity data. We further use a MCPA-based representational similarity analysis to illustrate how MCPA may be used to test computational models of information transfer among regions of the visual processing stream. Thus, MCPA can be used to assess the information represented in the coupled activity of interacting neural circuits and probe the underlying principles of information transformation between regions.	2-methyl-4-chlorophenoxyacetic acid;computational model;face;interaction;map;neural ensemble;population;representation (action);resting state fmri;synapse	Yuanning Li;R. Mark Richardson;Avniel Singh Ghuman	2017	NeuroImage	10.1016/j.neuroimage.2017.08.033	coding (social sciences);visual processing;computational model;decoding methods;population;artificial intelligence;information transfer;biological neural network;machine learning;computer science;mcpa	ML	19.386945734059687	-69.36455805524538	42185
0ed65c2a0627e86ded057b7d60b977f5cbdb35d3	peptide detectability following esi mass spectrometry: prediction using genetic programming	auroc;genetic program;mass spectrometry;genetic programming;classification;physico chemical properties;objective function;prediction accuracy;input selection;proteomics;mass spectrometric;cell biology	The accurate quantification of proteins is important in several areas of cell biology, biotechnology and medicine. Both relative and absolute quantification of proteins is often determined following mass spectrometric analysis of one or more of their constituent peptides. However, in order for quantification to be successful, it is important that the experimenter knows which peptides are readily detectable under the mass spectrometric conditions used for analysis. In this paper, genetic programming is used to develop a function which predicts the detectability of peptides from their calculated physico-chemical properties. Classification is carried out in two stages: the selection of a good classifier using the AUROC objective function and the setting of an appropriate threshold. This allows the user to select the balance point between conflicting priorities in an intuitive way. The success of this method is found to be highly dependent on the initial selection of input parameters. The use of brood recombination and a modified version of the multi-objective FOCUS method are also investigated. While neither has a significant effect on predictive accuracy, the use of the FOCUS method leads to considerably more compact solutions.	focus;genetic programming;loss function;optimization problem;peptide-mass fingerprint;receiver operating characteristic	David C. Wedge;Simon J. Gaskell;Simon J. Hubbard;Douglas B. Kell;King Wai Lau;Claire E Eyers	2007		10.1145/1276958.1277382	genetic programming;mass spectrometry;biological classification;computer science;bioinformatics;machine learning;proteomics;receiver operating characteristic	ML	10.800952791464209	-56.6089323478063	42226
531867906a449f27d71ec944cfed88208e9363c1	quantitative analysis of genetic and neuronal multi-perturbation experiments	network inference;gene deletion;animals;gene knockout;bayesian network;caenorhabditis elegans;game theory;saccharomyces cerevisiae;neural model;systems biology;dna polymerase;signal transduction;models biological;system performance;chemotaxis;genetics;shapley value;machine learning;system identification;chemical elements;boolean network;perturbation analysis;quantitative analysis;biological systems;algorithms;dna repair;molecular sequence data;neurons;phenotype;dna recombination;mutagenesis;reverse engineering	Perturbation studies, in which functional performance is measured after deletion, mutation, or lesion of elements of a biological system, have been traditionally employed in many fields in biology. The vast majority of these studies have been qualitative and have employed single perturbations, often resulting in little phenotypic effect. Recently, newly emerging experimental techniques have allowed researchers to carry out concomitant multi-perturbations and to uncover the causal functional contributions of system elements. This study presents a rigorous and quantitative multi-perturbation analysis of gene knockout and neuronal ablation experiments. In both cases, a quantification of the elements' contributions, and new insights and predictions, are provided. Multi-perturbation analysis has a potentially wide range of applications and is gradually becoming an essential tool in biology.	ablation;biological system;causal filter;deletion mutation;design of experiments;experiment;gene knockout techniques;numerous;perturbation theory;quantitation	Alon Kaufman;Alon Keinan;Isaac Meilijson;Martin Kupiec;Eytan Ruppin	2005	PLoS Computational Biology	10.1371/journal.pcbi.0010064	biology;game theory;mutagenesis;boolean network;dna repair;system identification;recombinant dna;bioinformatics;quantitative analysis;phenotype;perturbation theory;bayesian network;shapley value;dna polymerase;chemotaxis;genetics;gene knockout;systems biology;signal transduction;chemical element;reverse engineering	Comp.	6.357134063512693	-60.16482962535843	42250
d9cef4b090c3aa6949358694c73fbc4502e6e454	sapin: a framework for the structural analysis of protein interaction networks	cytoscape web;protein part;structural superimpositions;eu supplementary information;physical binary interaction;bioinformatics online;protein interaction network;structural analysis;sapin server;exclusive interaction	SUMMARY Protein interaction networks are widely used to depict the relationships between proteins. These networks often lack the information on physical binary interactions, and they do not inform whether there is incompatibility of structure between binding partners. Here, we introduce SAPIN, a framework dedicated to the structural analysis of protein interaction networks. SAPIN first identifies the protein parts that could be involved in the interaction and provides template structures. Next, SAPIN performs structural superimpositions to identify compatible and mutually exclusive interactions. Finally, the results are displayed using Cytoscape Web.   AVAILABILITY The SAPIN server is available at http://sapin.crg.es.   CONTACT jae-seong.yang@crg.eu or christina.kiel@crg.eu.   SUPPLEMENTARY INFORMATION Supplementary data are available at Bioinformatics Online.	bioinformatics;clinical use template;cytoscape;server (computing);software incompatibility;structural analysis;protein protein interaction	Jae-Seong Yang;Anne Campagna;Javier Delgado Blanco;Peter Vanhee;Luis Serrano;Christina Kiel	2012	Bioinformatics	10.1093/bioinformatics/bts539	biology;bioinformatics;data mining;world wide web	Comp.	-0.16345604502788055	-59.49805999865532	42298
063176ed0f263047f718f492fd29c2b1879cfcb5	tmpdb: a database of experimentally-characterized transmembrane topologies	prediction method;animals;x ray crystallography;protein structure secondary;protein sequence;eukaryotic cells;prokaryotic cells;gene fusion;access method;databases protein;membrane proteins	TMPDB is a database of experimentally-characterized transmembrane (TM) topologies. TMPDB release 6.2 contains a total of 302 TM protein sequences, in which 276 are alpha-helical sequences, 17 beta-stranded, and 9 alpha-helical sequences with short pore-forming helices buried in the membrane. The TM topologies in TMPDB were determined experimentally by means of X-ray crystallography, NMR, gene fusion technique, substituted cysteine accessibility method, N-linked glycosylation experiment and other biochemical methods. TMPDB would be useful as a test and/or training dataset in improving the proposed TM topology prediction methods or developing novel methods with higher performance, and as a guide for both the bioinformaticians and biologists to better understand TM proteins. TMPDB and its subsets are freely available at the following web site: http://bioinfo.si.hirosaki-u.ac.jp/~TMPDB/.	accessibility;amino acid sequence;anatomy, regional;crystallography;database;experiment;gene fusion;peptide sequence;silo (dataset);tissue membrane	Masami Ikeda;Masafumi Arai;Toshikatsu Okuno;Toshio Shimizu	2003	Nucleic acids research	10.1093/nar/gkg020	biology;molecular biology;bioinformatics;fusion gene;protein sequencing;access method;membrane protein;genetics;x-ray crystallography	Comp.	9.727889093905855	-59.807175443287996	42308
4c30d124c20fea45350abeb88fdb5997e8c138ed	short-term prediction of low kidney function in icu patients		Intensive care treatment presents unique challenges in the medical world. When treating patients, their wide variety leave care providers with few past examples to draw on. Instead of operating in a pure knowledge discovery capacity, decision support systems can be developed to help predict short-term and long-term patient outcome, based upon available data. One area in which generalized severity scoring systems have consistently performed poorly is among patients admitted intensive care units (ICU) who then develop acute kidney injury. Urine output is used to guide fluid resuscitation and is one of the criteria for the diagnosis of acute kidney injury. This paper provides an example application for predicting short-term critical kidney function in an intensive care unit. Feature construction is performed to extract important aspects of the clinical evolution of the patient. Feature selection is performed on several patient features. Classifiers based on support vector machines and Takagi-Sugeno fuzzy models are developed to predict short-term drops in patient urine output rate. Both types of models showed comparable results, with an AUC of 78%. This shows potential in using similar classifiers to build an ICU decision support system with the goal of predicting short-term complication in the patient and augment current guidelines by anticipating treatment.	decision support system;feature selection;international components for unicode;support vector machine;the hitchhiker's guide to the galaxy	Ricardo Pacheco;Cátia M. Salgado;Rodrigo Octávio Deliberato;Leo Anthony Celi;Susana M. Vieira	2017	2017 IEEE International Conference on Fuzzy Systems (FUZZ-IEEE)	10.1109/FUZZ-IEEE.2017.8015658	artificial intelligence;machine learning;decision support system;renal function;feature selection;medical emergency;computer science;resuscitation;acute kidney injury;intensive care unit	Robotics	6.667903918963802	-76.80454536621335	42353
038faf4f7f77452025fb7d2d350c1a9f0719fc53	intelligent dna-based molecular diagnostics using linked genetic markers	dna;molecular diagnostics;molecular diagnosis;knowledge based system;probability;chromosomal aberrations;genetics;genetic marker;data analysis;blood sampling;biology and medicine basic studies;images;hereditary diseases;knowledge base;mathematics computers information science management law miscellaneous;automation	This paper describes a knowledge-based system for molecular diagnostics, and its application to fully automated diagnosis of X-linked genetic disorders. Molecular diagnostic information is used in clinical practice for determining genetic risks, such as carrier determination and prenatal diagnosis. Initially, blood samples are obtained from related individuals, and PCR amplification is performed. Linkage-based molecular diagnosis then entails three data analysis steps. First, for every individual, the alleles (i.e., DNA composition) are determined at specified chromosomal locations. Second, the flow of genetic material among the individuals is established. Third, the probability that a given individual is either a carrier of the disease or affected by the disease is determined. The current practice is to perform each of these three steps manually, which is costly, time consuming, labor-intensive, and error-prone. As such, the knowledge-intensive data analysis and interpretation supersede the actual experimentation effort as the major bottleneck in molecular diagnostics. By examining the human problem solving for the task, we have designed and implemented a prototype knowledge-based system capable of fully automating linkage-based molecular diagnostics in X-linked genetic disorders, including Duchenne Muscular Dystrophy (DMD). Our system uses knowledge-based interpretation of gel electrophoresis images to determine individual DNA marker labels, a constraint satisfaction search for consistent genetic flow among individuals, and a blackboard-style problem solver for risk assessment. We describe the system's successful diagnosis of DMD carrier and affected individuals from raw clinical data.	architecture as topic;artificial intelligence;bayesian network;blood specimen;chromosome mapping;cognitive dimensions of notations;color vision defect;constraint satisfaction;endocrine system diseases;experiment;gel electrophoresis (lab technique);genotype determination;hereditary diseases;high-throughput computing;inference;interpretation (logic);knowledge-based systems;labor (childbirth);laboratory;linkage (software);molecular biology;muscular dystrophy, duchenne;nucleic acid hybridization;problem solving (mental process);prototype;risk assessment;rule-based system;self-replicating machine;solver;tetrahydrocannabinol;the jerry lewis mda labor day telethon;throughput;x-linked combined immunodeficiency diseases;dystrophy	Dhiraj K. Pathak;Eric P. Hoffman;Mark W. Perlin	1994	Proceedings. International Conference on Intelligent Systems for Molecular Biology		biology;knowledge base;computer science;bioinformatics;automation;probability;genetic marker;data analysis;molecular diagnostics;genetics;dna	AI	1.628387449592681	-66.78939153062387	42372
0b694c84abd539417c5ab04976d726a5d78896d4	neuronal tuning: to sharpen or broaden?	espiga positiva;correlacion;learning algorithm;ruido;informacion fisher;algorithme apprentissage;pointe positive;spike;accord frequence;codificacion;tuning;theoretical analysis;population coding;probability distribution;bruit;coding;sintonizacion frecuencia;correlation;reseau neuronal;algoritmo aprendizaje;information fisher;red neuronal;codage;noise;fisher information;neural network	Sensory and motor variables are typically represented by a population of broadly tuned neurons. A coarser representation with broader tuning can often improve coding accuracy, but sometimes the accuracy may also improve with sharper tuning. The theoretical analysis here shows that the relationship between tuning width and accuracy depends crucially on the dimension of the encoded variable. A general rule is derived for how the Fisher information scales with the tuning width, regardless of the exact shape of the tuning function, the probability distribution of spikes, and allowing some correlated noise between neurons. These results demonstrate a universal dimensionality effect in neural population coding.	fisher information;neural coding;neural ensemble;width	Kechen Zhang;Terrence J. Sejnowski	1999	Neural Computation	10.1162/089976699300016809	probability distribution;noise;artificial intelligence;fisher information;mathematics;coding;neural coding;correlation;artificial neural network;algorithm;statistics	ML	21.396475196116548	-71.20917043920039	42378
ed2434c5fe9737419f609686afd67bc0e29b8f25	chemical library subset selection algorithms: a unified derivation using spatial statistics	experimental design;response function;subset selection;spatial statistics	If similar compounds have similar activity, rational subset selection becomes superior to random selection in screening for pharmacological lead discovery programs. Traditional approaches to this experimental design problem fall into two classes: (i) a linear or quadratic response function is assumed (ii) some space filling criterion is optimized. The assumptions underlying the first approach are clear but not always defendable; the second approach yields more intuitive designs but lacks a clear theoretical foundation. We model activity in a bioassay as realization of a stochastic process and use the best linear unbiased estimator to construct spatial sampling designs that optimize the integrated mean square prediction error, the maximum mean square prediction error, or the entropy. We argue that our approach constitutes a unifying framework encompassing most proposed techniques as limiting cases and sheds light on their underlying assumptions. In particular, vector quantization is obtained, in dimensions up to eight, in the limiting case of very smooth response surfaces for the integrated mean square error criterion. Closest packing is obtained for very rough surfaces under the integrated mean square error and entropy criteria. We suggest to use either the integrated mean square prediction error or the entropy as optimization criteria rather than approximations thereof and propose a scheme for direct iterative minimization of the integrated mean square prediction error. Finally, we discuss how the quality of chemical descriptors manifests itself and clarify the assumptions underlying the selection of diverse or representative subsets.	algorithm;approximation;assumed;biological assay;chemical library;class;dicom derivation;design of experiments;frequency response;genetic selection;iteration;mathematical optimization;mean squared error;pharmacology;rational set;response surface methodology;sampling (signal processing);set packing;software framework;spatial analysis;stochastic process;subgroup;vector quantization	Fred A. Hamprecht;Walter Thiel;Wilfred F. van Gunsteren	2002	Journal of chemical information and computer sciences	10.1021/ci010376b	minimum mean square error;econometrics;mathematical optimization;combinatorics;artificial intelligence;machine learning;mathematics;spatial analysis;design of experiments;algorithm;statistics	ML	13.718111664858126	-54.20321705472415	42383
7849c77e54ce4d87fdf4d28f14845066596ef524	correlations between theoretical and experimental determination of heat of formation of certain aliphatic nitro compounds	experimental analysis;weighted least square;empirical method;aliphatic nitro compound;multivariable linear regression;weighted least squares method;prediction interval;heat of formation;nitrogen;semi empirical method;multivariate linear regression;molecular structure	Heats of formation of energetic materials were calculated by Dewar's AM1 and Stewart's PM3 methods. In order to compare the theoretical results with the experimental ones, some correlation models were proposed in this study. Correlations were evaluated by multivariable linear regression method, considering the number of nitro groups and the use of quadratic relations involving the number of carbon, hydrogen, nitrogen, and oxygen atoms. Results indicated very precise correlations. Based on these correlations, heats of formation of some aliphatic nitro compounds can be predicted at 95% predictive interval without experimental analysis.	austin model 1;dewar (device);heat (physical force);heterocyclic compounds, 2-ring;hydrogen;linear iga bullous dermatosis;ng-nitroarginine methyl ester;nitro (wireless networking);nitro compounds;oxygen;regression analysis	P. C. Chen;Jicheng Wu;S. C. Chen	2001	Computers & chemistry	10.1016/S0097-8485(00)00105-4	econometrics;chemistry;prediction interval;molecule;standard enthalpy of formation;organic chemistry;bayesian multivariate linear regression;nitrogen;mathematics;empirical research;physics;statistics;experimental analysis of behavior	AI	13.136224410463742	-57.58520653839365	42415
ef3e95cce50fd2a48600f863adafbb0734360dd2	based on bioinformatics approach to explore the novel targets and activity of multiple ingredients in shuang-huang-lian (using bioinformatics approach to explore the machanisms of a modern formula)	shl development bioinformatics approach drug target exploration drug activity exploration multiple shl ingredient shuang huang lian formula modern formula mechanism shl formula preparation medicinal herb flos lonicerae radix scutellariae fructus forsythiae shl dosage form clinical efficacy pharmacological mechanism shl preparation relevant data integration biological information integration topological parameter characterization ppi network scale free property ppi network modular architecture drug target network shl functional cluster pharmacological effect distribution antitumor effect durg target prediction pharmacological activity distribution shl research;databases;drugs;databases drugs educational institutions bioinformatics proteins diseases;drug target network shuang huang lian ppi network;proteins;tumours biochemistry bioinformatics data analysis data integration data mining drugs feature extraction medical computing molecular biophysics molecular configurations proteins topology;diseases;bioinformatics	Shuang-Huang-Lian (SHL) is a famous modern formula prepared from three medicinal herbs including Flos Lonicerae, Radix Scutellariae and Fructus Forsythiae. Currently, SHL has been developed a variety of dosage forms due to its proved clinical efficacy. However, the in-depth research on targets and pharmacological mechanisms of SHL preparations was scarce. In the presented study, the bioinformatics approaches were adopted to integrate relevant data and biological information. As a result, a PPI network was built and the common topological parameters were characterized. The reuslts suggested that the PPI network of SHL exhibited a scale-free property and modular architecture. The drug target network of SHL was structured with 21 functional clusters as modules naturally. According to certain modules and pharmacological effects distribution, an anti-tumor effect and protented durg targets were predicted. In conclutions, a bioinformatics approach was established for exploring the drug targets and pharmacological activity distribution. The results offered a novel anti-tumor effect of SHL and provide a clue for further research and development.	bioinformatics;hilbert–huang transform;pixel density;split-radix fft algorithm	Hao Gu;Qi Zhang;Qiang Li;Miao Jiang;Aiping Lu;Chengke Cai;Yun Wang	2014	2014 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)	10.1109/BIBM.2014.6999318	pharmacology;fox proteins;computer science;bioinformatics	Visualization	2.026626621456489	-67.55293190837605	42419
e7274519a4841f618423d7ca2802d5ebaae9bee9	spatiotemporal localization of significant activation in meg using permutation tests	temporal correlation;multiple testing;qa mathematics;statistical computing;error rate;rc0321 neuroscience biological psychiatry neuropsychiatry;current density;permutation test	We describe the use of non-parametric permutation tests to detect activation in cortically-constrained maps of current density computed from MEG data. The methods are applicable to any inverse imaging method that maps event-related MEG to a coregistered cortical surface. To determine an appropriate threshold to apply to statistics computed from these maps, it is important to control for the multiple testing problem associated with testing 10's of thousands of hypotheses (one per surface element). By randomly permuting pre- and post-stimuius data from the collection of individual epochs in an event related study, we develop thresholds that control the familywise (type 1) error rate. These thresholds are based on the distribution of the maximum intensity, which implicitly accounts for spatial and temporal correlation in the cortical maps. We demonstrate the method in application to simulated data and experimental data from a somatosensory evoked response study.	database normalization;deny (action);family-wise error rate;magnetoencephalography;map;propylene glycol;random permutation;randomness;rejection sampling;resampling (statistics)	Dimitrios Pantazis;Thomas E. Nichols;Sylvain Baillet;Richard M. Leahy	2003	Information processing in medical imaging : proceedings of the ... conference	10.1007/978-3-540-45087-0_43	econometrics;word error rate;resampling;computer science;machine learning;mathematics;fitness approximation;multiple comparisons problem;computational statistics;current density;statistics	ML	23.796543330400638	-76.30403678021378	42427
9ff2d0491675aa8c6bb0d2790e912a98fce34a8e	significant deviations in the configurations of homologous tandem repeats in prokaryotic genomes	prokaryote;kullback leibler divergence;statistical analysis;whole genome duplication;tandem repeat;shintaro hirayama satoshi mizuta 串联重复序列 核基因组 大偏差 同源性 配置 染色体检测 统计分析 重复顺序 significant deviations in the configurations of homologous tandem repeats in prokaryotic genomes	We explored the possibilities of whole-genome duplication (WGD) in prokaryotic species, where we performed statistical analyses of the configurations of the central angles between homologous tandem repeats (TRs) on the circular chromosomes. At first, we detected TRs on their chromosomes and identified equivalent tandem repeat pairs (ETRPs); here, an ETRP is defined as a pair of tandem repeats sequentially similar to each other. Then we carried out statistical analyses of the central angle distributions of the detected ETRPs on each circular chromosome by way of comparisons between the detected distributions and those generated by null models. In the analyses, we estimated a P value by a simulation using the Kullback-Leibler divergence as a distance measure between two distributions. As a result, the central angle distributions for 8 out of the 203 prokaryotic species showed statistically significant deviations (P<0.05). In particular, we found out the characteristic feature of one round of WGD in Photorhabdus luminescens genome and that of two rounds of WGD in Escherichia coli K12.	chromosomes;gene duplication abnormality;genome;genomic structural variation;homology (biology);kullback–leibler divergence;null value;simulation;tandem computers;tandem repeat sequences;threonine-trna ligase activity	Shintaro Hirayama;Satoshi Mizuta	2009		10.1016/S1672-0229(08)60046-7	biology;bioinformatics;kullback–leibler divergence;genetics;tandem repeat	Comp.	3.559790902170447	-60.05425809588928	42533
cbab171d674f7ce7be269521fd3fc77181abc2c6	geometric analysis of neuronal firing patterns in network models with fast inhibitory synapses	oscillations;dynamic system;singular perturbation;synchronization;network model;inhibition;firing pattern;hodgkin huxley	We demonstrate how geometric dynamical systems techniques can yield insight into network behavior in models of coupled neurons. Such an approach is useful for understanding general mechanisms by which firing patterns, such as synchrony and clustering, arise and for computing how cells’ intrinsic and synaptic properties shape network behavior. We focus here on biophysical models, based on the Hodgkin–Huxley formalism, relevant to thalamic activity during sleep and paroxysmal discharges and especially on the role of fast inhibitory coupling in synchronous oscillations. A key finding is that qualitative differences in synchronization mechanisms appear in models with different complexity levels.	action potential;geometric analysis	Jonathan E. Rubin;David Terman	1999	Neurocomputing	10.1016/S0925-2312(99)00039-9	singular perturbation;synchronization;computer science;dynamical system;network model;machine learning;control theory;mathematics;oscillation;hodgkin–huxley model	ML	17.730327681813414	-70.79753294943781	42623
b951944235626d582d9d89bc8b79b84edddc63bf	secondary structure preferences of mn2+ binding sites in bacterial proteins	health research;uk clinical guidelines;biological patents;europe pubmed central;citation search;uk phd theses thesis;life sciences;uk research reports;medical journals;europe pmc;biomedical research;bioinformatics	"""3D structures of proteins with coordinated Mn(2+) ions from bacteria with low, average, and high genomic GC-content have been analyzed (149 PDB files were used). Major Mn(2+) binders are aspartic acid (6.82% of Asp residues), histidine (14.76% of His residues), and glutamic acid (3.51% of Glu residues). We found out that the motif of secondary structure """"beta strand-major binder-random coil"""" is overrepresented around all the three major Mn(2+) binders. That motif may be followed by either alpha helix or beta strand. Beta strands near Mn(2+) binding residues should be stable because they are enriched by such beta formers as valine and isoleucine, as well as by specific combinations of hydrophobic and hydrophilic amino acid residues characteristic to beta sheet. In the group of proteins from GC-rich bacteria glutamic acid residues situated in alpha helices frequently coordinate Mn(2+) ions, probably, because of the decrease of Lys usage under the influence of mutational GC-pressure. On the other hand, the percentage of Mn(2+) sites with at least one amino acid in the """"beta strand-major binder-random coil"""" motif of secondary structure (77.88%) does not depend on genomic GC-content."""	4-dichlorobenzene;abbreviations;amino acids;arginine;asparagine;aspartate;aspartic acid;bch code;benign hereditary chorea;binder, device;binding sites;bioinformatics;c++builder;coil gene;coil device component;cysteine;cytosine;ethanol 0.62 ml/ml topical gel;file binder;genes, vif;glutamic acid;glutamine;glycine;guanine;habitat;hexachlorobenzene;histidine;hypochondroplasia (disorder);interaction;ions;isoleucine;leucine;lysine;manganese cation (2+);motif;phenylalanine;proline;protein data bank;protein data bank;reflow soldering;serine;situated;strand (programming language);symmetric multiprocessing;threonine;tryptophan;tyrosine;valine;xfree86 acceleration architecture;algorithm;interest;type i interferon receptor	Tatyana Aleksandrovna Khrustaleva	2014		10.1155/2014/501841	biology;biochemistry;medical research;biotechnology;computer science;bioinformatics	Comp.	5.567997361236742	-63.80889136026791	42663
285b89b9a4958060e42ac93d3ddf86ade11f3f5c	enhancing interacting residue prediction with integrated contact matrix prediction in protein-protein interaction	signal image and speech processing;systems biology;computational biology bioinformatics;biomedical engineering	"""Identifying the residues in a protein that are involved in protein-protein interaction and identifying the contact matrix for a pair of interacting proteins are two computational tasks at different levels of an in-depth analysis of protein-protein interaction. Various methods for solving these two problems have been reported in the literature. However, the interacting residue prediction and contact matrix prediction were handled by and large independently in those existing methods, though intuitively good prediction of interacting residues will help with predicting the contact matrix. In this work, we developed a novel protein interacting residue prediction system, contact matrix-interaction profile hidden Markov model (CM-ipHMM), with the integration of contact matrix prediction and the ipHMM interaction residue prediction. We propose to leverage what is learned from the contact matrix prediction and utilize the predicted contact matrix as """"feedback"""" to enhance the interaction residue prediction. The CM-ipHMM model showed significant improvement over the previous method that uses the ipHMM for predicting interaction residues only. It indicates that the downstream contact matrix prediction could help the interaction site prediction."""	cardiomyopathies;downstream (software development);hidden markov model;markov chain;protein structure prediction;regular expression;staphylococcal protein a;protein protein interaction	Tianchuan Du;Li Liao;Cathy H. Wu	2016		10.1186/s13637-016-0051-z	biology;computer science;bioinformatics;engineering;machine learning;data mining;biological engineering;systems biology	Comp.	8.79893361383315	-58.5304466368146	42723
93b9984c0351760411625ed43e3d9ed39d81057b	point-wise convolutional neural network		Deep learning with 3D data such as reconstructed point clouds and CAD models has received great research interests recently. However, the capability of using point clouds with convolutional neural network has been so far not fully explored. In this technical report, we present a convolutional neural network for semantic segmentation and object recognition with 3D point clouds. At the core of our network is point-wise convolution, a new convolution operator that can be applied at each point of a point cloud. Our fully convolutional network design, while being surprisingly simple to implement, can yield competitive accuracy in both semantic segmentation and object recognition task.	artificial neural network;computer-aided design;convolution;convolutional neural network;deep learning;hash table;input/output;network planning and design;outline of object recognition;point cloud;sparse matrix	Binh-Son Hua;Minh-Khoi Tran;Sai-Kit Yeung	2017	CoRR		computer science;convolutional neural network;pattern recognition;artificial intelligence;machine learning;point cloud;deep learning;network planning and design;convolution;cognitive neuroscience of visual object recognition;technical report	Vision	23.597602506420465	-52.44556848234636	42772
6aa9c443ba933cc402ca8aa18b41909bc6335672	finite element procedures for enzyme, chemical reaction and 'in-silico' genome scale networks		The capacity to predict and control bioprocesses is perhaps one of the most important objectives of biotechnology. Computational simulation is an established methodology for the design and optimization of bioprocesses, where the finite elements method (FEM) is at the state-of-art engineering multi-physics simulation system, with tools such as Finite Element Analysis (FEA) and Computational Fluid Dynamics (CFD). Although FEA and CFD are currently applied to bioreactor design, most simulations are restricted to the multi-physics capabilities of the existing sofware packages. This manuscript is a contribution for the consolidation of FEM in computational biotechnology, by presenting a comprehensive review of finite element procedures of the most common enzymatic mechanisms found in biotechnological processes, such as, enzyme activation, Michaelis Menten, competitive inhibition, non-competitive inhibition, anti-competitive inhibition, competition by substrate, sequential random mechanism, ping-pong bi-bi and Theorel-Chance. Most importantly, the manuscript opens the possibility for the use of FEM in conjunction with in-silico models of metabolic networks, as well as, chemical networks in order to simulate complex bioprocesses in biotechnology, putting emphasis into flux balance analysis, pheno-metabolomics space exploration in time and space, overcoming the limitations of assuming chemostat conditions in systems biology computations.	computation;computational fluid dynamics;dynamical simulation;federal enterprise architecture;finite element method;flux balance analysis;mathematical optimization;metabolomics;semiconductor consolidation;systems biology	Rui Costa Martins;Nuno Fachada	2015	CoRR		bioinformatics	HPC	13.90793129497826	-63.443016259241	42801
fa29b79605966df4b312a16584259ef21894b5b1	image clustering with spiking neuron network	biology computing;pattern clustering;image segmentation;representation capacity image clustering spiking neuron network image segmentation automatic image analysis artificial neural networks neural networks 3 rd generation biological stimuli sigmoidal units threshold units temporal axis;neural networks;representation capacity;neural nets;spiking neuron network;training;biological system modeling;nerve fibers;neurons image segmentation artificial neural networks training pixel encoding firing;image clustering;polynomials;computer networks;firing;artificial neural networks;temporal axis;spiking neurons;image representation;threshold units;pixel;3rd generation;automatic image analysis;image analysis;neurons;sigmoidal units;pattern clustering image representation image segmentation neural nets;encoding;neural networks 3 rd generation;artificial neural network;neural network;biological stimuli	The process of segmenting images is one of the most critical ones in automatic image analysis whose goal can be regarded as to find what objects are presented in images. Artificial neural networks have been well developed. First two generations of neural networks have a lot of successful applications. Spiking neuron networks (SNNs) are often referred to as the 3rd generation of neural networks which have potential to solve problems related to biological stimuli. They derive their strength and interest from an accurate modeling of synaptic interactions between neurons, taking into account the time of spike emission. SNNs overcome the computational power of neural networks made of threshold or sigmoidal units. Moreover, SNNs add a new dimension, the temporal axis, to the representation capacity and the processing abilities of neural networks. In this paper, we present how SNN can be applied with efficacy in image segmentation.	apache axis;artificial neural network;cluster analysis;image analysis;image segmentation;interaction;neuron;pixel;quantization (signal processing);sigmoid function;spike-triggered average;synaptic package manager	Boudjelal Meftah;Abdelkader Benyettou;Olivier Lézoray;W. QingXiang	2008	2008 IEEE International Joint Conference on Neural Networks (IEEE World Congress on Computational Intelligence)	10.1109/IJCNN.2008.4633868	winner-take-all;computer vision;types of artificial neural networks;computer science;artificial intelligence;machine learning;image segmentation;artificial neural network;pixel;encoding;polynomial;spiking neural network	ML	21.97160783111153	-64.07438159403603	42809
334745b35819773d8b69a9964d6240e01fb4fc9d	fused regression for multi-source gene regulatory network inference	gene regulation;gene regulatory networks;transcription factors;bacillus subtilis;genetic networks;gene expression;bacillus anthracis;operons	Understanding gene regulatory networks is critical to understanding cellular differentiation and response to external stimuli. Methods for global network inference have been developed and applied to a variety of species. Most approaches consider the problem of network inference independently in each species, despite evidence that gene regulation can be conserved even in distantly related species. Further, network inference is often confined to single data-types (single platforms) and single cell types. We introduce a method for multi-source network inference that allows simultaneous estimation of gene regulatory networks in multiple species or biological processes through the introduction of priors based on known gene relationships such as orthology incorporated using fused regression. This approach improves network inference performance even when orthology mapping and conservation are incomplete. We refine this method by presenting an algorithm that extracts the true conserved subnetwork from a larger set of potentially conserved interactions and demonstrate the utility of our method in cross species network inference. Last, we demonstrate our method's utility in learning from data collected on different experimental platforms.	gene expression regulation;gene regulatory network;global network;histopathologic grade differentiation;inference;interaction;large;multi-source;numerous;partial;subnetwork;algorithm;cell type	Kari Y. Lam;Zachary M. Westrick;Christian L. Müller;Lionel A Christiaen;Richard Bonneau	2016		10.1371/journal.pcbi.1005157	biological network inference;biology;gene regulatory network;regulation of gene expression;gene expression;bioinformatics;operon;genetics;transcription factor	ML	5.126667307557644	-57.511712334965424	42812
bd97c7c0678e978e9f84e20f5c66888417523ff3	the cell-free expression of ion channels and electrophysiological measurements in interdroplet bilayers	qa75 electronic computers computer science;qh301 biology	Ion channels are membrane proteins of interest for medical research and drug discovery, however a major bottleneck in obtaining functional measurements is the requirement to over-express the channel in-vivo. Cell-free (CF) protein expression is an alternative in-vitro approach capable of expressing proteins from a supplied DNA template - the method is fast, requires minimal apparatus and can be stabilised for the expression of membrane proteins by the addition of lipids or detergents. One drawback is the expense of commercial CF systems, however this can be economised by performing the reaction in microdroplets. This is attractive as microdroplets immersed in lipid-oil can be manipulated into contact to form a lipid bilayer, potentially allowing for ion channel expression and characterisation to be fully coupled. This study addresses the feasibility of achieving this goal by first investigating the stability of interdroplet bilayers formed in the presence of pre-incubated CF systems. Under these conditions the bilayers failed in  30 min. The CF expression of the small prokaryotic potassium channel KcsA was then verified, in addition to the pore domain region of the eukaryotic hERG channel, where 20 ng/ul-74 ng/ul was expressed depending on the reaction conditions. Single-channel currents were subsequently obtained in interdroplet bilayers formed directly from the CF mixture, indicating that the channels were capable of self-inserting into the bilayer for measurements in both cases. The findings of this study support the feasibility of coupling the CF expression and electrical characterisation of ion channels in microdroplets and represent a progression toward the development of a high-throughput platform for screening novel pharmaceutical compounds.		Mark Samuel Friddin	2014			chemistry;analytical chemistry;nanotechnology	Logic	8.403385755486832	-62.116589008029926	42837
f1e2f730e27e545c12cb2929025c970517f3a474	an effective method to optimize docking-based virtual screening in a clustered fully-flexible receptor model deployed on cloud platforms		The use of conformations obtained from molecular dynamics trajectories in the molecular docking experiments is the most accurate approach to simulate the behavior of receptors and ligands in molecular environments. However, such simulations are computationally expensive and their execution may become an infeasible task due to the large number of structural information, typically considered to represent the explicit flexibility of receptors. In addition, the computational demand increases when Fully-Flexible Receptor (FFR) models are routinely applied for screening of large compounds libraries. This study presents a novel method to optimize docking-based virtual screening of FFR models by reducing the size of FFR models at docking runtime, and scaling docking workflow invocations out onto virtual machines from cloud platforms. For this purpose, we developed e-FReDock, a cloud-based scientific workflow that assists in faster high-throughput docking simulations of flexible receptors and ligands. e-FReDock is based on a free-parameter selective method to perform ensemble docking experiments with multiple ligands from a clustered FFR model. The e-FReDock input data was generated by applying six clustering methods for partitioning conformations with different features in their substrate-binding cavities, aiming at identifying groups of snapshots with favorable interactions for specific ligands at docking runtime. Experimental results show the high quality Reduced Fully-Flexible Receptor (RFFR) models achieved by e-FReDock in two distinct sets of analyses. The first analysis shows that e-FReDock is able to preserve the quality of the FFR model between 84.00% and 94.00%, while its dimensionality reduces on average 49.68%. The second analysis reports that resulting RFFR models are able to reach better docking results than those obtained from the rigid version of the FFR model in 97.00% of the ligands tested.		Renata De Paris	2016			docking (molecular);molecular dynamics;machine learning;virtual screening;curse of dimensionality;cluster analysis;cloud computing;artificial intelligence;virtual machine;effective method;bioinformatics;computer science	HPC	12.921348054878834	-60.36015728790334	42858
60850bca77b3cdcd55ad2c9eb2d547125e0d2832	dual skipping networks		Inspired by the recent neuroscience studies on the left-right asymmetry of the human brain in processing low and high spatial frequency information, this paper introduces a dual skipping network which carries out coarse-to-fine object categorization. Such a network has two branches to simultaneously deal with both coarse and fine-grained classification tasks. Specifically, we propose a layer-skipping mechanism that learns a gating network to predict which layers to skip in the testing stage. This layer-skipping mechanism endows the network with good flexibility and capability in practice. Evaluations are conducted on several widely used coarse-to-fine object categorization benchmarks, and promising results are achieved by our proposed network model.		Changmao Cheng;Yanwei Fu;Yu-Gang Jiang;Wei Liu;Wenlian Lu;Jianfeng Feng;Xiangyang Xue	2018	2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition	10.1109/CVPR.2018.00428	visualization;task analysis;machine learning;categorization;pattern recognition;artificial intelligence;network model;gating;spatial frequency;computer science	Vision	23.58661705398982	-54.808698992490676	42860
59e4076e1ab805797935083e4340aa551cd73af2	a switching hybrid control method for automatic blood glucose regulation in diabetic göttingen minipigs	blood glucose control;impulsive control process;diabetic gottingen minipigs;switching control method	A new hybrid control method for blood glucose concentration is developed which switches between two operation modes. The effects of meal-induced disturbances on blood glucose concentrations are expected to be more serious than the time-varying behaviour of glucose metabolism during nocturnal phases. Thus, the control method determines insulin impulses (boli) as a manipulated variable during the day and calculates continuous insulin infusion (basal rates) at night. To test the controller-based insulin therapy in vivo, animal trials with diabetic Göttingen minipigs are used as a proxy for human studies. The controller parameters are selected by in silico studies based on mathematical minipig models, and the resulting individualised controllers are experimentally verified. For this, two control performance iabetic Göttingen minipigs requirements must be taken into account: blood glucose concentrations below the critical threshold of 50 mg/dl have to be avoided, and blood glucose peaks caused by ingestion of minipig diet have to be quickly counteracted. Results from these animal experiments show that the closed-loop system satisfies both control requirements and improves insulin therapy compared with a standard therapeutic protocol. © 2014 Elsevier Ltd. All rights reserved.	basal (phylogenetics);experiment;network switch;requirement;stigler diet;video-in video-out	Katrin Lunze;Marian Walter;Steffen Leonhardt	2014	Biomed. Signal Proc. and Control	10.1016/j.bspc.2014.05.004	endocrinology;diabetes mellitus	Robotics	9.981387949651598	-71.5910464060819	42870
16e2744741c793a7103a3f72e46d746f2e1637d6	gene-l'expo: a tool to extract knowledge from transcriptomes and find 'literature-sparse' relationships between genes and tissues		The increasing volume and diversity of transcriptome data in the public domain offer an opportunity to advance new questions and hypotheses. We anticipate that tools that can visualize the gap in the distribution of information between the scientific literature and actual data would prompt such questions. We focused on the roles played by various genes in tissues, and have developed a database that contrasts information on gene expression in tissues with PubMed text and transcriptome data. Data pairs of tissues and the genes that might be expressed there were automatically extracted from text with vocabularies for the genes and tissues. The anatomical categories of various expressed sequence tag (EST) libraries were also automatically determined. These types of information were linked using the hierarchical structure of the Metathesaurus in UMLS.	body tissue;categories;expressed sequence tags;extraction;gene expression;gene ontology;libraries;pierre robin syndrome;pubmed;scientific literature;sparse;transcriptome;umls metathesaurus;unified medical language system;vocabulary	Teruyoshi Hishiki;Issei Tamada;Kousaku Okubo	2008	AMIA ... Annual Symposium proceedings. AMIA Symposium			Comp.	-1.7053937729605453	-63.055200758359014	42898
a282b059bf5e2c301125a82c480185d4b5d155f6	an integrated system for genetic analysis	dna;genetic analysis;database management systems;computer graphics;integrable system;genetic map;chromosome mapping;sequence analysis dna;model complexity;association study;computational biology bioinformatics;large scale;internet;algorithms;sequence alignment;user computer interface;combinatorial libraries;high throughput;pedigree;computer appl in life sciences;systems integration;data management system;linkage disequilibrium;microarrays;bioinformatics	Large-scale genetic mapping projects require data management systems that can handle complex phenotypes and detect and correct high-throughput genotyping errors, yet are easy to use. We have developed an Integrated Genotyping System (IGS) to meet this need. IGS securely stores, edits and analyses genotype and phenotype data. It stores information about DNA samples, plates, primers, markers and genotypes generated by a genotyping laboratory. Data are structured so that statistical genetic analysis of both case-control and pedigree data is straightforward. IGS can model complex phenotypes and contain genotypes from whole genome association studies. The database makes it possible to integrate genetic analysis with data curation. The IGS web site http://bioinformatics.well.ox.ac.uk/project-igs.shtml contains further information.	archive;ascogrammitis david-smithii;bioinformatics;cns disorder;data curation;database schema;digital curation;genetic algorithm;genotype determination;https;hereditary diseases;high-throughput computing;html link type - copyright;license;manuscripts;microsoft sql server;neoplasms;paper;peer review;phenotype;portable document format;pubmed central;requirement;scientific publication;server (computer);stored procedure;structured query language;throughput;tom duff;web site;x image extension;citation;genetic pedigree	Simon Fiddy;David Cattermole;Dong Xie;Xiao Yuan Duan;Richard Mott	2005	BMC Bioinformatics	10.1186/1471-2105-7-210	linkage disequilibrium;high-throughput screening;biology;integrable system;the internet;dna microarray;computer science;bioinformatics;theoretical computer science;sequence alignment;computer graphics;genetics;genetic analysis;dna;system integration	Comp.	-2.9951840552309603	-60.554342129430665	42904
3792896ef233f679795ed26b34a18eac2ba3cfdd	classification research on syndromes of tcm based on svm	clinical data;heart disease;cross validation method;kernel;heart;traditional chinese medicine;support vector machines;radial basis function syndromes traditional chinese medicine support vector machine heart disease optimal kernel function cross validation method pathology stepwise regression neural network;neural nets;cardiology;training;kernel function;stepwise regression;satisfiability;support vector machines biological techniques cardiology diseases neural nets regression analysis;accuracy;radial basis function;support vector machines support vector machine classification medical diagnostic imaging cardiac disease neural networks biomedical imaging kernel pathology mechatronics testing;classification algorithms;diseases;regression analysis;binary classification;cross validation;support vector machine;biological techniques;pathology;optimal kernel function;syndromes;neural network	Syndrome is a unique TCM concept, which is an abstractive collection of symptoms and signs. Several modern algorithms have been applied to classify syndromes, but no satisfied results have been obtained because of the complexity of diagnosis procedure. Support vector machine (SVM) has been found to be very efficient to solve the classification problems, especially for binary classification with good generalization properties. In this paper, firstly patients’ clinic data of heart disease were preprocessed, then chose the optimal kernel function and used the cross-validation method to find the best parameters for SVM model, finally, the accuracy of testing different syndromes in accordance with pathology of heart disease was obtained. The results indicated that SVM was the best identifier with 81.08% accuracy on samples than the stepwise regression with 77.30% and the neural network with 73.72%. In addition, by comparing with four different kernel functions of SVM, radial basis function (RBF) was the best identifier than the others. Keywords-Syndrome; Traditional Chinese Medicine; Support Vector Machine	algorithm;artificial neural network;binary classification;cross-validation (statistics);identifier;radial (radio);radial basis function;software diagnosis;stepwise regression;support vector machine;toolkit for conceptual modeling	Chunming Xia;Feng Deng;Yiqin Wang;Zhaoxia Xu;Guoping Liu;Jin Xu;Helge Gewiss	2009	2009 2nd International Conference on Biomedical Engineering and Informatics	10.1109/BMEI.2009.5305418	support vector machine;computer science;machine learning;pattern recognition;data mining;artificial neural network	ML	7.301689755141756	-77.75657230088443	42916
5b96f72d0dc28d07f27c5a418cd303276fa80966	quantifying slow evolutionary dynamics in rna fitness landscapes	fitness landscape;evolutionary dynamics;genotype;rna secondary structure;systems biology;rna neutral networks;rna structure;classification description;direction selectivity;slow relaxation;evolutionary process;phenotype;stabilizing selection;evolution	We re-examine the evolutionary dynamics of RNA secondary structures under directional selection towards an optimum RNA structure. We find that the punctuated equilibria lead to a very slow approach to the optimum, following on average an inverse power of the evolutionary time. In addition, our study of the trajectories shows that the out-of-equilibrium effects due to the evolutionary process are very weak. In particular, the distribution of genotypes is close to that arising during equilibrium stabilizing selection. As a consequence, the evolutionary dynamics leave almost no measurable out-of-equilibrium trace, only the transition genotypes (close to the border between different periods of stasis) have atypical mutational properties.	evolutionary algorithm;genotype;nash equilibrium;rna;stasis	Petr Sulc;Andreas Wagner;Olivier C. Martin	2010	Journal of bioinformatics and computational biology	10.1142/S0219720010005075	biology;fitness landscape;bioinformatics;phenotype;stabilizing selection;genotype;evolution;evolutionary dynamics;genetics;systems biology	Comp.	6.807897220760804	-63.99674041031837	42955
b182a76f33109c65045a1a8b42fa2cdac46bdfb7	quantifying and visualizing uncertainties in molecular models		Computational molecular modeling and visualization has seen significant progress in recent years with several molecular modeling and visualization software systems in use today. Nevertheless the molecular biology community lacks techniques and tools for the rigorous analysis, quantification and visualization of the associated errors in molecular structure and its associated properties. This paper attempts at filling this vacuum with the introduction of a systematic statistical framework where each source of structural uncertainty is modeled as a random variable (RV) with a known distribution, and properties of the molecules are defined as dependent RVs. The framework consists of a theoretical basis, and an empirical implementation where the uncertainty quantification (UQ) analysis is achieved by using Chernoff-like bounds. The framework enables additionally the propagation of input structural data uncertainties, which in the molecular protein world are described as B-factors, saved with almost all X-ray models deposited in the Protein Data Bank (PDB). Our statistical framework is also able and has been applied to quantify and visualize the uncertainties in molecular properties, namely solvation interfaces and solvation free energy estimates. For each of these quantities of interest (QOI) of the molecular models we provide several novel and intuitive visualizations of the input, intermediate, and final propagated uncertainties. These methods should enable the end user achieve a more quantitative and visual evaluation of various molecular PDB models for structural and property correctness, or the lack thereof.	chernoff bound;computation;computational chemistry;correctness (computer science);molecular modelling;protein data bank;software propagation;software system;uncertainty quantification;visualization software	Muhibur Rasheed;Nathan Clement;Abhishek Bhowmick;Chandrajit L. Bajaj	2015	CoRR		computer science;bioinformatics;data mining;nanotechnology;statistics	Visualization	15.741231333383254	-61.29376932939099	42971
355396ad4af6dfb820737b8324880eb88bb7ee56	bayesian analysis of fmri data with ica based spatial prior	sensitivity and specificity;brain;data interpretation statistical;evoked potentials;spatial coherence;regression to the mean;bayes theorem;statistical significance;prior knowledge;independent component analysis;activity pattern;image enhancement;brain mapping;image interpretation computer assisted;principal component analysis;magnetic resonance imaging;reproducibility of results;general linear model;algorithms;humans;brain activation;bayesian analysis;spatial model;spatial information	Spatial modeling is essential for fMRI analysis due to relatively high noise in the data. Earlier approaches have been primarily concerned with the spatial coherence of the BOLD response in local neighborhoods. In addition to a smoothness constraint, we propose to incorporate prior knowledge of brain activation patterns learned from training samples. This spatially informed prior can significantly enhance the estimation process by inducing sensitivity to task related regions of the brain. As fMRI data exhibits intersubject variability in functional anatomy, we design the prior using Independent Component Analysis (ICA). Due to the non-Gaussian assumption, ICA does not regress to the mean activation pattern and thus avoids suppressing intersubject differences. Results from a real fMRI experiment indicate that our approach provides statistically significant improvement in estimating activation compared to the standard general linear model (GLM) based methods.		Deepti R. Bathula;Hemant D. Tagare;Lawrence H. Staib;Xenophon Papademetris;Robert T. Schultz;James S. Duncan	2008	Medical image computing and computer-assisted intervention : MICCAI ... International Conference on Medical Image Computing and Computer-Assisted Intervention	10.1007/978-3-540-85990-1_30	independent component analysis;bayesian probability;computer science;regression toward the mean;magnetic resonance imaging;machine learning;pattern recognition;mathematics;spatial analysis;statistical significance;bayes' theorem;brain mapping;statistics;general linear model;principal component analysis	ML	21.837162189214023	-79.00232284972272	42972
637b095af18a386bfdc65c586ba9debbd3b4655d	blowout bifurcation and on-off intermittency in pulse neural networks with multiplec modules	blowout bifurcation;synchronization;on off intermittency;pulse neural network;neural network	To study the mechanism by which high-dimensional chaos emerges in neural systems, the synchronization of chaotic firings in class 1 pulse neural networks composed of excitatory and inhibitory ensembles was analyzed. In the system with two modules (i.e., two pulse neural networks), blowout bifurcation and on-off intermittency were observed when the inter-module connection strengths were reduced from large values. In the system with three modules, rearrangement of synchronized clusters and chaotic itinerancy were observed. Such dynamics may be one of the mechanisms through which high-dimensional chaos is generated in neural systems.	bifurcation theory;blowout;chaos theory;neural networks;switch	Takashi Kanamaru	2006	I. J. Bifurcation and Chaos	10.1142/S021812740601680X	synchronization;simulation;control theory;artificial neural network	ML	17.497653721356887	-70.2623270195792	43011
92952993146e6ff19a77c86bec4e2ca2d098fd29	chaos and synchrony in a model of a hypercolumn in visual cortex	mean field theory;international organizations;oscillations;cross correlation function;cross correlation;temporal variability;spatial structure;spike train;orientation selectivity;neuronal network;potassium current;cortical neurons;orientation tuning;visual cortex;neuronal activity;hodgkin huxley;numerical simulation;voltage clamp	Neurons in cortical slices emit spikes or bursts of spikes regularly in response to a suprathreshold current injection. This behavior is in marked contrast to the behavior of cortical neurons in vivo, whose response to electrical or sensory input displays a strong degree of irregularity. Correlation measurements show a significant degree of synchrony in the temporal fluctuations of neuronal activities in cortex. We explore the hypothesis that these phenomena are the result of the synchronized chaos generated by the deterministic dynamics of local cortical networks. A model of a “hypercolumn” in the visual cortex is studied. It consists of two populations of neurons, one inhibitory and one excitatory. The dynamics of the neurons is based on a Hodgkin-Huxley type model of excitable voltage-clamped cells with several cellular and synaptic conductances. A slow potassium current is included in the dynamics of the excitatory population to reproduce the observed adaptation of the spike trains emitted by these neurons. The pattern of connectivity has a spatial structure which is correlated with the internal organization of hypercolumns in orientation columns. Numerical simulations of the model show that in an appropriate parameter range, the network settles in a synchronous chaotic state, characterized by a strong temporal variability of the neural activity which is correlated across the hypercolumn. Strong inhibitory feedback is essential for the stabilization of this state. These results show that the cooperative dynamics of large neuronal networks are capable of generating variability and synchrony similar to those observed in cortex. Auto-correlation and cross-correlation functions of neuronal spike trains are computed, and their temporal and spatial features are analyzed. In other parameter regimes, the network exhibits two additional states: synchronized oscillations and an asynchronous state. We use our model to study cortical mechanisms for orientation selectivity. It is shown that in a suitable parameter regime, when the input is not oriented, the network has a continuum of states, each representing an inhomogeneous population activity which is peaked at one of the orientation columns. As a result, when a weakly oriented input stimulates the network, it yields a sharp orientation tuning. The properties of the network in this regime, including the appearance of virtual rotations and broad stimulus-dependent cross-correlations, are investigated. The results agree with the predictions of the mean field theory which was previously derived for a simplified model of stochastic, two-state neurons. The relation between the results of the model and experiments in visual cortex are discussed.	acclimatization;action potential;cerebral cortex;chaos theory;column (database);cross-correlation;excitable medium;exhibits as topic;experiment;heart rate variability;huxley: the dystopia;neuron;neurons;numerical linear algebra;performance tuning;population parameter;potassium;quantum field theory;selectivity (electronic);simulation;spatial variability;synaptic package manager;the spike (1997);triune continuum paradigm;video-in video-out;voltage	David Hansel;Haim Sompolinsky	1996	Journal of Computational Neuroscience	10.1007/BF00158335	psychology;computer simulation;biological neural network;neuroscience;cross-correlation;machine learning;mathematics;communication	ML	17.984148331276177	-71.23740074766695	43031
2549ff19d27df05a1ee150a5172f96f69564ee57	segway 2.0: gaussian mixture models and minibatch training		Summary Segway performs semi-automated genome annotation, discovering joint patterns across multiple genomic signal datasets. We discuss a major new version of Segway and highlight its ability to model data with substantially greater accuracy. Major enhancements in Segway 2.0 include the ability to model data with a mixture of Gaussians, enabling capture of arbitrarily complex signal distributions, and minibatch training, leading to better learned parameters.   Availability and implementation Segway and its source code are freely available for download at http://segway.hoffmanlab.org. We have made available scripts (https://doi.org/10.5281/zenodo.802939) and datasets (https://doi.org/10.5281/zenodo.802906) for this paper's analysis.   Contact michael.hoffman@utoronto.ca.   Supplementary information Supplementary data are available at Bioinformatics online.	bioinformatics;download;geographic information systems;mixture model;normal statistical distribution;semiconductor industry;source code	Rachel C. W. Chan;Maxwell W. Libbrecht;Eric G. Roberts;Jeffrey A. Bilmes;William Stafford Noble;Michael M. Hoffman	2018		10.1093/bioinformatics/btx603	data mining;mixture model;source code;computer science;machine learning;artificial intelligence;bioinformatics;scripting language;download	Comp.	3.178362713649348	-52.10339607928072	43085
c374b213de465eab560adceaa3de478d64f2c36e	is the human sex odds at birth distorted in the vicinity of nuclear facilities (nf)? a preliminary geo-spatial-temporal approach		""" Risk assessment – qualification and quantification of risks  The focus in this presentation is on ionizing radiation (IR) and possible radiation induced changes in the human sex odds at birth (SO) near Nuclear Facilities (NF)  Traditionally, the SR is the pertinent term for the number of newborn boys divided by the number of newborn girls SR = boys/girls = m/f  However, considering the male probability p male = boys/(girls + boys) = m/(m+f) leads to considering the important and methodologically more appropriate sex odds SO = p male /(1-p male) = boys/girls = SR  Comparing two SO leads to the obvious and natural measure Sex Odds Ratio SOR = SO exposed /SO nonexposed  The inconvenient term """" sex ratio ratio """" is avoided"""	radiation hardening;relevance;risk assessment	Ralf Kusmierz;Kristina Voigt;Hagen Scherb	2010			demography;odds;geography	AI	7.27316046912957	-71.26275239672391	43138
393b5c70c2cd8a6a9a608842efbab08f381b2ffa	exploring the desumoylation process of senp1: a study combined md simulations with qm/mm calculations on senp1-sumo1-rangap1		The small ubiquitin-related modifier (SUMO)-specific protease (SENP) processes SUMOs to mature forms and deconjugates them from various modified substrates. Loss of the equilibrium from desumoylation catalyzed by abnormal SENP1 is associated with cancers and transcription factor activity. In spite of the significant role of SENP1, the molecular basis of its desumoylation remains unclear. Here, MD simulations and QM/MM methods are combined to investigate the catalytic mechanism of desumoylation. The results showed that substrate SUMO1-RanGAP1 fitted into the catalytic pocket of SENP1 by the break of internal hydrophobic interactions and the isomerization of isopeptide from trans to cis. After that, the nucleophilic sulfur anion of Cys603 in SENP1 attacked the carbonyl carbon of Gly97 of SUMO1 to trigger the reaction, and then a tetrahedral intermediate and an acyl-enzyme intermediate were generated in turn, leading to the final release of enzyme SENP1 and two products, free SUMO1 and RanGAP1. In the process, nucleophilic attack was identified as the rate-determining step with a potential energy barrier of 20.2 kcal/mol. These results are in agreement with experimental data from mutagenesis and other experiments. Our findings elucidate the catalytic mechanism of SENP1 with its substrate and may provide a better understanding of SENP desumoylation. In particular, we have identified key residues in SENP1 needed for desumoylation that might be beneficial for the design of novel inhibitors of SENP1-related diseases.	anions;chemical modifier;computer simulation;duoxa1 gene;endopeptidases;experiment;hematological disease;interaction;kind of quantity - equilibrium;malignant neoplasms;modifier key;molecular dynamics;qm/mm;rangap1 gene;senp1 gene;sumo-1 protein;seizures;source-to-source compiler;transcription factor;transcription (software);kilocalorie;protein desumoylation;sulfoenolpyruvate	Ting Shi;Yuhui Han;Weihua Li;Yanlong Zhao;Yaqin Liu;Zhimin Huang;Shaoyong Lu;Jian Zhang	2013	Journal of chemical information and modeling	10.1021/ci4002487	senp1;nucleophile;hydrophobic effect;substrate (chemistry);qm/mm;tetrahedral carbonyl addition compound;isomerization;stereochemistry;catalysis;chemistry	Comp.	8.985286096906226	-62.79258765525054	43209
e71d2d332716f3d738dff7ce7148ce5de5e783b1	an algorithm for the prediction of proteasomal cleavages	algorithm;prediction;proteasome;mhc class i	Proteasomes, major proteolytic sites in eukaryotic cells, play an important part in major histocompatibility class I (MHC I) ligand generation and thus in the regulation of specific immune responses. Their cleavage specificity is of outstanding interest for this process. In order to generalize previously determined cleavage motifs of 20 S proteasomes, we developed network-based model proteasomes trained by an evolutionary algorithm with experimental cleavage data of yeast and human 20 S proteasomes. A window of ten flanking amino acid residues proved sufficient for the model proteasomes to reproduce the experimental results with 98-100 % accuracy. Actual experimental data were reproduced significantly better than randomly selected cleavage sites, suggesting that our model proteasomes were able to extract rules inherent to proteasomal cleavage data. The affinity parameters of the model, which decide for or against cleavage, correspond with the cleavage motifs determined experimentally. The predictive power of the model was verified for unknown (to the program) test conditions: the prediction of cleavage numbers in proteins and the generation of MHC I ligands from short peptides. In summary, our model proteasomes reproduce and predict proteasomal cleavages with high degree of accuracy. They present a promising approach for predicting proteasomal cleavage products in future attempts and, in combination with existing algorithms for MHC I ligand prediction, will be tested to improve cytotoxic T lymphocyte epitope prediction.		Christina Kuttler	2000	Journal of molecular biology		experimental data;cleavage (embryo);cytotoxic t cell;proteasome;amino acid;mhc class i;histocompatibility;epitope;molecular biology;algorithm;biology	ML	9.362116178386543	-56.46326031865128	43259
102077fe17c0ff3684b611b1b7727aa65eb0c263	optimally fuzzy temporal memory	forecasting long range correlated time series;temporal information compression	Any learner with the ability to predict the future of a structured time-varying signal must maintain a memory of the recent past. If the signal has a characteristic timescale relevant to future prediction, the memory can be a simple shift register—a moving window extending into the past, requiring storage resources that linearly grows with the timescale to be represented. However, an independent general purpose learner cannot a priori know the characteristic prediction-relevant timescale of the signal. Moreover, many naturally occurring signals show scale-free long range correlations implying that the natural prediction-relevant timescale is essentially unbounded. Hence the learner should maintain information from the longest possible timescale allowed by resource availability. Here we construct a fuzzy memory system that optimally sacrifices the temporal accuracy of information in a scale-free fashion in order to represent prediction-relevant information from exponentially long timescales. Using several illustrative examples, we demonstrate the advantage of the fuzzy memory system over a shift register in time series forecasting of natural signals. When the available storage resources are limited, we suggest that a general purpose learner would be better off committing to such a fuzzy memory system.	shift register;time series	Karthik H. Shankar;Marc W. Howard	2013	Journal of Machine Learning Research		simulation;computer science;artificial intelligence;machine learning	ML	16.9642182134767	-65.38506672531891	43286
a8dec90da481edde4ad6b25ec18e5ea6ca1ad51b	current limitations to protein threading approaches	protein threading	A short review of the threading approach to protein structure prediction, including presentation of some open statistical problems. Also discussed is one of the likely sources of the current limited success, that being the form of the pairwise potentials used in most threading approaches.	protein structure prediction;thread (computing);threading (protein sequence)	Temple F. Smith;Loredana Lo Conte;Jadwiga R. Bienkowska;Chrysanthe Gaitatzes;Robert G. Rogers;Richard H. Lathrop	1997	Journal of computational biology : a journal of computational molecular cell biology	10.1089/cmb.1997.4.217	threading;biology;computer science;bioinformatics;theoretical computer science	Comp.	1.0138054194315207	-57.84150453850345	43346
291ff962c541ab5fa84dde08b2cc7ca16c475390	topological approach to drug design. [ erratum to document cited in ca122: 177672]	drug design			Jorge Gálvez;Ramón García-Domenech;Jesús Vicente de Julián-Ortiz;Rosa Soler	1995	Journal of Chemical Information and Computer Sciences	10.1021/ci00027a022	pharmacology;chemistry;computer science;combinatorial chemistry;information retrieval;drug design	Theory	0.517011662761975	-64.42172999329799	43349
dbe4066db7137553aabe8015f0b2a98cca2e02cd	effective connectivity inferred from fmri transition dynamics during movie viewing points to a balanced reconfiguration of cortical interactions		Our behavior entails a flexible and context-sensitive interplay between brain areas to integrate information according to goal-directed requirements. However, the neural mechanisms governing the entrainment of functionally specialized brain areas remain poorly understood. In particular, the question arises whether observed changes in the regional activity for different cognitive conditions are explained by modifications of the inputs to the brain or its connectivity? We observe that transitions of fMRI activity between areas convey information about the tasks performed by 19 subjects, watching a movie versus a black screen (rest). We use a model-based framework that explains this spatiotemporal functional connectivity pattern by the local variability for 66 cortical regions and the network effective connectivity between them. We find that, among the estimated model parameters, movie viewing affects to a larger extent the local activity, which we interpret as extrinsic changes related to the increased stimulus load. However, detailed changes in the effective connectivity preserve a balance in the propagating activity and select specific pathways such that high-level brain regions integrate visual and auditory information, in particular boosting the communication between the two brain hemispheres. These findings speak to a dynamic coordination underlying the functional integration in the brain.	brainwave entrainment;context-sensitive grammar;functional integration;high- and low-level;inference;interaction;large;requirement;resting state fmri;spatial variability	Matthieu Gilson;Gustavo Deco;Karl J. Friston;Patric Hagmann;Dante Mantini;Viviana Betti;Gian Luca Romani;Maurizio Corbetta	2018	NeuroImage	10.1016/j.neuroimage.2017.09.061	psychology;artificial intelligence;communication;social psychology	ML	18.801807712182043	-75.76997041421613	43356
4ec44ad86e76658e576ac7e00fc05b9561780c2b	information extraction in molecular biology	protein function;information extraction;molecular biology;evaluation criteria;protein structure prediction;protein protein interaction;document retrieval	Information extraction has become a very active field in bioinformatics recently and a number of interesting papers have been published. Most of the efforts have been concentrated on a few specific problems, such as the detection of protein-protein interactions and the analysis of DNA expression arrays, although it is obvious that there are many other interesting areas of potential application (document retrieval, protein functional description, and detection of disease-related genes to name a few). Paradoxically, these exciting developments have not yet crystallised into general agreement on a set of standard evaluation criteria, such as the ones developed in fields such as protein structure prediction, which makes it very difficult to compare performance across these different systems. In this review we introduce the general field of information extraction, we outline the status of the applications in molecular biology, and we then discuss some ideas about possible standards for evaluation that are needed for the future development of the field.	bioinformatics;concentrate dosage form;dna microarray;document retrieval;information extraction;molecular biology;paper;protein structure prediction;scientific publication;protein protein interaction;standards characteristics	Christian Blaschke;Lynette Hirschman;Alfonso Valencia	2002	Briefings in bioinformatics	10.1093/bib/3.2.154	protein–protein interaction;document retrieval;biology;computer science;bioinformatics;data science;protein structure prediction;data mining;protein structure database;information extraction	Comp.	-1.9912552883423322	-65.93964055341904	43401
9d30e98aef50878b3d86867f9621811650bd6c87	design of novel rho kinase inhibitors using energy based pharmacophore modeling, shape-based screening, in silico virtual screening, and biological evaluation		Rho-associated protein kinase (ROCK) plays a key role in regulating a variety of cellular processes, and dysregulation of ROCK signaling or expression is implicated in numerous diseases and infections. ROCK proteins have therefore emerged as validated targets for therapeutic intervention in various pathophysiological conditions such as diabetes-related complications or hepatitis C-associated pathogenesis. In this study, we report on the design and identification of novel ROCK inhibitors utilizing energy based pharmacophores and shape-based approaches. The most potent compound 8 exhibited an IC50 value of 1.5 μM against ROCK kinase activity and inhibited methymercury-induced neurotoxicity of IMR-32 cells at GI50 value of 0.27 μM. Notably, differential scanning fluorometric analysis revealed that ROCK protein complexed with compound 8 with enhanced stability relative to Fasudil, a validated nanomolar range ROCK inhibitor. Furthermore, all compounds exhibited ≥96 μM CC50 (50% cytotoxicity) in Huh7 hepatoma cells, while 6 compounds displayed anti-HCV activity in HCV replicon cells. The identified lead thus constitutes a prototypical molecule for further optimization and development as anti-ROCK inhibitor.	chemical and drug induced liver injury;complications of diabetes mellitus;fluorometry;hepatitis c virus;hepatitis c, chronic;infection;inhibitory concentration 50;mathematical optimization;neurotoxicity syndromes;pharmacophore;replicon;virtual screening;fasudil	Ram Kumar Mishra;Reshma Alokam;Sarthak Mohan Singhal;Geethasai Srivathsav;Dharamarajan Sriram;Neerja Kaushik-Basu;Dinesh Manvar;Perumal Yogeeswari	2014	Journal of chemical information and modeling	10.1021/ci5004703	biology;biochemistry;stereochemistry;bioinformatics	Comp.	8.260752720747991	-61.906438689151095	43420
e2d3e6f00f84a33f9f01542c665db9346dae8107	a methodology for clustering transient biomedical signals by variable				Pimwadee Chaovalit	2012	IJCMAM	10.4018/jcmam.2012010103	data mining;cluster analysis;medicine	Metrics	2.746095537834473	-74.79261900808305	43421
054d7d95ca61622a851df89298b737399a4b79a3	genequiz: a workbench for sequence analysis	sequence analysis;rule based system;software systems;protein sequence	"""We present the prototype of a software system, called GeneQuiz, for large-scale biological sequence analysis. The system was designed to meet the needs that arise in computational sequence analysis and our past experience with the analysis of 171 protein sequences of yeast chromosome III. We explain the cognitive challenges associated with this particular research activity and present our model of the sequence analysis process. The prototype system consists of two parts: (i) the database update and search system (driven by perl programs and rdb, a simple relational database engine also written in perl) and (ii) the visualization and browsing system (developed under C++/ET++). The principal design requirement for the first part was the complete automation of all repetitive actions: database updates, efficient sequence similarity searches and sampling of results in a uniform fashion. The user is then presented with """"hit-lists"""" that summarize the results from heterogeneous database searches. The expert's primary task now simply becomes the further analysis of the candidate entries, where the problem is to extract adequate information about functional characteristics of the query protein rapidly. This second task is tremendously accelerated by a simple combination of the heterogeneous output into uniform relational tables and the provision of browsing mechanisms that give access to database records, sequence entries and alignment views. Indexing of molecular sequence databases provides fast retrieval of individual entries with the use of unique identifiers as well as browsing through databases using pre-existing cross-references. The presentation here covers an overview of the architecture of the system prototype and our experiences on its applicability in sequence analysis.(ABSTRACT TRUNCATED AT 250 WORDS)"""	amino acid sequence;computation;cross-reference;data table;database engine;experience;genetic heterogeneity;heterogeneous database system;imagery;indexes;peptide sequence;perl;pierre robin syndrome;prototype;published database;question (inquiry);relational database;research activities;sampling (signal processing);sequence alignment;sequence analysis;sequence database;software system;thrombocytopenia;unique identifier;workbench	Michael Scharf;Reinhard Schneider;Georg Casari;Peer Bork;Alfonso Valencia;Christos A. Ouzounis;Chris Sander	1994	Proceedings. International Conference on Intelligent Systems for Molecular Biology		artificial intelligence;computer science;machine learning;software system;bioinformatics;sequence profiling tool;perl;search engine indexing;database;data mining;relational database;architecture;sequence analysis;protein structure database	DB	-2.427525970995929	-59.65688802927963	43448
19b471a7b8e2e218fcb1a7dfc2c5058ac90578fb	honey authentication based on physicochemical parameters and phenolic compounds	physicochemical properties;authentication;chemometrics;honey;phenolics	The aim of this study is to assess the usefulness of physicochemical parameters (pH, water activity, free acidity, refraction index, Brix, moisture content and ash content), color parameters (L⁄, a⁄, b⁄, chroma, hue angle and yellow index) and phenolics (quercetin, apigenin, myricetin, isorhamnetin, kaempherol, caffeic acid, chrysin, galangin, luteolin, p-coumaric acid, gallic acid and pinocembrin) in view of classifying honeys according to their botanical origin (acacia, tilia, sunflower, honeydew and polyfloral). Thus, the classification of honeys has been made using the principal component analysis (PCA), linear discriminant analysis (LDA) and artificial neural networks (ANN). The multilayer perceptron network with 2 hidden layers classified correctly 94.8% of the cross validated samples. 2017 Elsevier B.V. All rights reserved.	artificial neural network;authentication;chemical library;chemometrics;linear discriminant analysis;memory-level parallelism;multilayer perceptron;phenol formaldehyde resin;principal component analysis;quad flat no-leads package	Mircea Oroian;Sorina Ropciuc	2017	Computers and Electronics in Agriculture	10.1016/j.compag.2017.04.020	botany;computer science;chemometrics;authentication	ML	14.323612933484121	-56.64237020528641	43494
ac7b0254587ebb4ed4d76c6a9b66db85402dcd4c	principal component 2-d long short-term memory for font recognition on single chinese characters	convolution;recurrent neural nets character recognition image classification principal component analysis;optical character recognition;principal component 2d long short term memory;recurrent neural networks rnns;chinese character font recognition;2dlstm;character trajectory;character recognition accuracy convolution vectors principal component analysis signal to noise ratio noise measurement;image classification;sequence classification problem;noise measurement;ccfr;neurodynamic models;accuracy;vectors;principal component analysis;recurrent neural nets;recurrent neural networks;signal to noise ratio;single chinese characters;character trajectory principal component 2d long short term memory single chinese characters chinese character font recognition ccfr sequence classification problem recurrent neural networks principal component convolution layer 2dlstm;character recognition;principal component convolution layer;font recognition;long short term memory;recurrent neural networks rnns font recognition long short term memory neurodynamic models optical character recognition	Chinese character font recognition (CCFR) has received increasing attention as the intelligent applications based on optical character recognition becomes popular. However, traditional CCFR systems do not handle noisy data effectively. By analyzing in detail the basic strokes of Chinese characters, we propose that font recognition on a single Chinese character is a sequence classification problem, which can be effectively solved by recurrent neural networks. For robust CCFR, we integrate a principal component convolution layer with the 2-D long short-term memory (2DLSTM) and develop principal component 2DLSTM (PC-2DLSTM) algorithm. PC-2DLSTM considers two aspects: 1) the principal component layer convolution operation helps remove the noise and get a rational and complete font information and 2) simultaneously, 2DLSTM deals with the long-range contextual processing along scan directions that can contribute to capture the contrast between character trajectory and background. Experiments using the frequently used CCFR dataset suggest the effectiveness of PC-2DLSTM compared with other state-of-the-art font recognition methods.	algorithm;artificial neural network;cardiac lymphoma;cerebrovascular accident;cinnamomum cassia;complexity;convolution;experiment;long short-term memory;neural network simulation;optical character recognition;pcl message structure;personality character;principal component analysis;printer command language;recurrent neural network;service layer;signal-to-noise ratio;statistical classification;text-based (computing)	Dapeng Tao;Xu Lin;Lianwen Jin;Xuelong Li	2016	IEEE Transactions on Cybernetics	10.1109/TCYB.2015.2414920	contextual image classification;speech recognition;computer science;noise measurement;recurrent neural network;machine learning;pattern recognition;accuracy and precision;convolution;optical character recognition;signal-to-noise ratio;principal component analysis;long short term memory	Vision	21.56687923385861	-59.742690918382934	43512
81f0f9570752f5caf66c7a07de8c1b6dee5e96ad	prospective coding by spiking neurons	learning;neuronal plasticity;synaptic plasticity;neurons;coding mechanisms;action potentials;neuronal dendrites;synapses	Animals learn to make predictions, such as associating the sound of a bell with upcoming feeding or predicting a movement that a motor command is eliciting. How predictions are realized on the neuronal level and what plasticity rule underlies their learning is not well understood. Here we propose a biologically plausible synaptic plasticity rule to learn predictions on a single neuron level on a timescale of seconds. The learning rule allows a spiking two-compartment neuron to match its current firing rate to its own expected future discounted firing rate. For instance, if an originally neutral event is repeatedly followed by an event that elevates the firing rate of a neuron, the originally neutral event will eventually also elevate the neuron's firing rate. The plasticity rule is a form of spike timing dependent plasticity in which a presynaptic spike followed by a postsynaptic spike leads to potentiation. Even if the plasticity window has a width of 20 milliseconds, associations on the time scale of seconds can be learned. We illustrate prospective coding with three examples: learning to predict a time varying input, learning to predict the next stimulus in a delayed paired-associate task and learning with a recurrent network to reproduce a temporally compressed version of a sequence. We discuss the potential role of the learning mechanism in classical trace conditioning. In the special case that the signal to be predicted encodes reward, the neuron learns to predict the discounted future reward and learning is closely related to the temporal difference learning algorithm TD(λ).	algorithm;anatomical compartments;conditioning (psychology);learning rule;mental association;multi-compartment model;neuron;neuronal plasticity;prospective search;recurrent neural network;synaptic package manager;temporal difference learning;window function;chemosensitization/potentiation;width	Johanni Brea;Alexisz Tamás Gaál;Robert Urbanczik;Walter Senn	2016		10.1371/journal.pcbi.1005003	synaptic plasticity;neuroplasticity;neuroscience;anti-hebbian learning;synapse;artificial intelligence;machine learning;metaplasticity;action potential	ML	17.0855808583247	-73.43531606849615	43545
d20aaddbcaf233baf133f514eaa25fea4d9a6454	trivalent influenza vaccine adverse symptoms analysis based on meddra terminology using vaers data in 2011	data mining and knowledge discovery;vaers;trivalent influenza virus vaccine;computational biology bioinformatics;meddra;algorithms;combinatorial libraries;computer appl in life sciences;bioinformatics	Background: Trivalent Influenza Virus Vaccine (FLU3) is a traditional flu vaccine to protect people against three different flu viruses, including influenza A H1N1 virus, an influenza A H3N2 virus and one B virus. Methods: We searched Vaccine Adverse Event Reporting System (VAERS) for US reports after FLU3 vaccination in the year of 2011. We conducted descriptive analyses on symptoms from serious reports (i.e., death, life-threatening illness, hospitalization, prolonged hospitalization, or permanent disability). We then further grouped these symptoms to the System Organ Classes (SOC) based on the MedDRA Terminology using NCBO Web Services. We fitted zero-truncated Poisson regression models to estimate the average number of symptoms per subject and compared it across different age groups and between genders. In addition, we compared the risk of occurrence for an SOC across different age groups and between genders by using logistic regression models. Finally, we constructed the pairwise correlation matrix of the SOCs by calculating Spearman’s rank correlation coefficients. Results: We identified 638 unique serious FLU3 reports from year 2011. There are 1410 unique symptoms from these reports. Descriptive statistics shows that the most common symptom and symptom pair are Pyrexia and Guillain-Barre syndrome – Hypoesthesia respectively. The estimated average number of symptoms per subject in the study cohort is 8.74 (95 % CI 6.76, 10.73). There are statistically significant differences in number of symptoms among four age groups and between genders. Age category and gender are significantly associated with several individual SOCs. Pairwise correlation matrix shows that “Endocrine disorders” and “Neoplasms benign, malignant and unspecified (incl cysts and polyps)” are strongly correlated. Conclusions: This paper reports a novel method that combining statistical analyses with terminology grouping using VAERS data. The analyses revealed differences of reactions among different age groups and between genders and correlation on both symptoms and System Organ Class level independently. The results may lead to additional studies to uncover factors contributing to the individual differences in susceptibility to influenza infection. This method can also be applied to other vaccine types and conduct similar analysis.	coefficient;logistic regression;meddra;national center for biomedical ontology;poisson regression;system on a chip;xslt/muenchian grouping	Jingcheng Du;Yi Cai;Yong Chen;Cui Tao	2016		10.1186/s13326-016-0056-2	toxicology;computer science;bioinformatics;virology;immunology;meddra;algorithm	AI	3.917156874718982	-75.2154131173092	43589
266cc38c1b6afec5933af0e0e39810eb91bcdb43	spatiotemporal coupling between speech and manual motor actions	health research;uk clinical guidelines;biological patents;europe pubmed central;citation search;uk phd theses thesis;life sciences;uk research reports;medical journals;europe pmc;biomedical research;bioinformatics	Much evidence has been found for pervasive links between the manual and speech motor systems, including evidence from infant development, deictic pointing, and repetitive tapping and speaking tasks. We expand on the last of these paradigms to look at intra- and cross-modal effects of emphatic stress, as well as the effects of coordination in the absence of explicit rhythm. In this study, subjects repeatedly tapped their finger and synchronously repeated a single spoken syllable. On each trial, subjects placed an emphatic stress on one finger tap or one spoken syllable. Results show that both movement duration and magnitude are affected by emphatic stress regardless of whether that stress is in the same domain (e.g., effects on the oral articulators when a spoken repetition is stressed) or across domains (e.g., effects on the oral articulators when a tap is stressed). Though the size of the effects differs between intra-and cross-domain emphases, the implementation of stress affects both motor domains, indicating a tight connection. This close coupling is seen even in the absence of stress, though it is highlighted under stress. The results of this study support the idea that implementation of prosody is not domain-specific but relies on general aspects of the motor system.	articulators;domain-specific language;loose coupling;modal logic;pervasive informatics;semantic prosody;speaking (activity);speech;syllable	Benjamin Parrell;Louis Goldstein;Sungbok Lee;Dani Byrd	2014	Journal of phonetics	10.1016/j.wocn.2013.11.002	psychology;medical research;speech recognition;developmental psychology;computer science;linguistics;communication	HCI	16.205687837234926	-77.99821600583627	43612
1d743d530882953431bde5e9773eaf5b5a71947c	efficient computation based on stochastic spikes	adaptacion;calcul neuronal;neural computation;population;fiabilidad;reliability;neurone impulsionnel;learning;62p30;efficiency;performance;pertinencia;modele calcul;percepcion;action;algorithme;aprendizaje;spike;algorithm;speed;eficacia;apprentissage;spiking neurons;spiking neuron;vitesse deplacement;fiabilite;adaptation;pertinence;velocidad desplazamiento;poblacion;efficacite;relevance;rendimiento;perception;reseau neuronal;accion;62n05;action potential;red neuronal;computacion neuronal;potentiel action;neural network;algoritmo	The speed and reliability of mammalian perception indicate that cortical computations can rely on very few action potentials per involved neuron. Together with the stochasticity of single-spike events in cortex, this appears to imply that large populations of redundant neurons are needed for rapid computations with action potentials. Here we demonstrate that very fast and precise computations can be realized also in small networks of stochastically spiking neurons. We present a generative network model for which we derive biologically plausible algorithms that perform spike-by-spike updates of the neuron's internal states and adaptation of its synaptic weights from maximizing the likelihood of the observed spike patterns. Paradigmatic computational tasks demonstrate the online performance and learning efficiency of our framework. The potential relevance of our approach as a model for cortical computation is discussed.	acclimatization;action potentials;action potential;algorithm;computation (action);mammals;network model;neuron;neurons;population;relevance;spiking neural network;synaptic package manager	Udo Ernst;David Rotermund;Klaus Pawelzik	2007	Neural Computation	10.1162/neco.2007.19.5.1313	psychology;neuroscience;relevance;performance;artificial intelligence;machine learning;reliability;efficiency;speed;perception;action potential;artificial neural network;models of neural computation;adaptation;population	ML	20.981282284521594	-70.48973198134905	43619
b047172aef87d61f71c2f304bcb72ca25daf91ef	visual assessment of endemic nephropathy markers relationship	endemic nephropathy;. visualization;multivariate analysis;markers;missing data;goodness of fit;data analysis	The aim of this paper was to assess relationship between possible endemic nephropathy (EN) markers visually by the CoPlot methodology, and to illustrate this promising data analysis approach. From 912 screened persons in 3 Croatian endemic villages, 25 persons were diagnosed as confirmed EN patients, 371 as non-EN, and the remainder were classified as suspected of having EN, or at risk. Data on 25 confirmed EN patients were matched with appropriate non-EN examinees. All records with missing data were excluded, resulting in 35 subjects with complete data on the 13 key EN variables for CoPlot mapping. CoPlot solution met the accepted goodness of fit measure thresholds. Result showed relationship between EN markers, identifying some nearly duplicated variables, and possible outliers needing some subsequent analysis.	aristolochic acid nephropathy;classification;exclusion;kidney diseases;missing data;patients;projection screen	Zdenko Sonicki;Ante Cvitkovic;Karen L. Edwards;Marica Miletic-Medved;Dubravka CvorisCec;Vladimir BabuS;Bojan Jelakovic	2009	Studies in health technology and informatics	10.3233/978-1-60750-044-5-836	goodness of fit;data mining;missing data;multivariate analysis;statistics;outlier;endemic nephropathy;medicine	ML	2.8791645627245135	-76.74662669664025	43661
6961820171bbba1b683762660d26e635a260dbec	the mutation process of microsatellites during the polymerase chain reaction	poly merase chain reaction;estimation method;quasi likelihood;mutation rate;genotyping;polymerase chain reaction;microsatellites;branching process;mathematical model;branching processes	We build a mathematical model for the mutation process of microsatellites during polymerase chain reaction (PCR) using the theory of branching processes. Based on the model, we develop a method to estimate the mutation rate of microsatellites per PCR cycle and the probability of expansion by maximizing a quasi-likelihood of the observed data. We show by simulations that the proposed estimation method can accurately recover the relationship between the mutation rate and number of repeat units. The theoretical basis for the proposed method is also given. We apply the method to experimental data on poly-A and poly-CA repeats.	mathematical model;mathematics;mutation;poly a;polymerase chain reaction;short tandem repeat;simulation;poly iclc	Yinglei Lai;Deepali Shinde;Norman Arnheim;Fengzhu Sun	2003	Journal of computational biology : a journal of computational molecular cell biology	10.1089/106652703321825937	genotyping;biology;mutation rate;branching process;quasi-likelihood;molecular biology;bioinformatics;polymerase chain reaction;mathematical model;microsatellite;genetics;statistics	Comp.	3.5122522509327907	-63.0769864557329	43694
ef502010c0318d99bc1b3926cc63cb272e31273e	object-oriented regression for building predictive models with high dimensional omics data from translational studies	lung cancer;clustering analysis;penalized regression;gene expression;big data;high dimensional data;generalized linear model;nearest neighbor approach;lasso	Maturing omics technologies enable researchers to generate high dimension omics data (HDOD) routinely in translational clinical studies. In the field of oncology, The Cancer Genome Atlas (TCGA) provided funding support to researchers to generate different types of omics data on a common set of biospecimens with accompanying clinical data and has made the data available for the research community to mine. One important application, and the focus of this manuscript, is to build predictive models for prognostic outcomes based on HDOD. To complement prevailing regression-based approaches, we propose to use an object-oriented regression (OOR) methodology to identify exemplars specified by HDOD patterns and to assess their associations with prognostic outcome. Through computing patient's similarities to these exemplars, the OOR-based predictive model produces a risk estimate using a patient's HDOD. The primary advantages of OOR are twofold: reducing the penalty of high dimensionality and retaining the interpretability to clinical practitioners. To illustrate its utility, we apply OOR to gene expression data from non-small cell lung cancer patients in TCGA and build a predictive model for prognostic survivorship among stage I patients, i.e., we stratify these patients by their prognostic survival risks beyond histological classifications. Identification of these high-risk patients helps oncologists to develop effective treatment protocols and post-treatment disease management plans. Using the TCGA data, the total sample is divided into training and validation data sets. After building up a predictive model in the training set, we compute risk scores from the predictive model, and validate associations of risk scores with prognostic outcome in the validation data (P-value=0.015).	clinical data;complement system proteins;continuance of life;disease management;faceted classification;gene expression;genetic translation process;manuscripts;mental association;neoplasms;omics;patients;predictive modelling;prognostic variable;protocols documentation;pyschological bonding;small cell carcinoma of lung;test set;the cancer genome atlas	Lue Ping Zhao;Hamid Bolouri	2016	Journal of biomedical informatics	10.1016/j.jbi.2016.03.001	gene expression;big data;computer science;bioinformatics;data science;machine learning;lasso;generalized linear model;data mining;cluster analysis;statistics;clustering high-dimensional data	ML	5.522788581396421	-74.42991015745788	43702
09bdb14a07f63b17e51c4694e828a514a0d7d3e1	a web server to locate periodicities in a sequence	fourier analysis;dna sequence;quantitative method	Summary : FT is a tool written in C++, which implements the Fourier analysis method to locate periodicities in aminoacid or DNA sequences. It is provided for free public use on a WWW server with a Java interface. Availability : The server address is http://o2.db. uoa.gr/FT Contact : shamodr@atlas.uoa.gr	amino acids;c++;contact order;fourier analysis;interface (java);interface device component;java programming language;server (computer);server (computing);www;web server	C. M. Pasquier;Vasilis J. Promponas;N. J. Varvayannis;Stavros J. Hamodrakas	1998	Bioinformatics		biology;dna sequencing;repeated sequence;internationalization and localization;quantitative research;telecommunications;nucleic acid sequence;bioinformatics;fourier analysis;genetics;dna	Comp.	-3.017075545305461	-59.39532040640235	43738
8ba8a57698b8eb58e304d15aebcaa8299f660a66	structure clustering features on the sfold web server	structure determination;sequence analysis	UNLABELLED The energy landscape of RNA secondary structures is often complex, and the Boltzmann-weighted ensemble usually contains distinct clusters. Furthermore, the minimum free energy structure often lies outside of the cluster containing the structure determined by comparative sequence analysis. We have developed procedures to characterize and visualize the Boltzmann-weighted ensemble, and have made them available on the Sfold Web server. The new features on the Web server include clustering statistics, ensemble and cluster centroids, multi-dimensional scaling display and energy landscape representation of the Boltzmann-weighted ensemble.   AVAILABILITY http://sfold.wadsworth.org; http://www.bioinfo.rpi.edu/applications/sfold   CONTACT chanc@wadsworth.org.	cluster analysis;image scaling;multidimensional scaling;numerous;sequence analysis;server (computer);server (computing);test scaling;web server;world wide web;free energy;statistical cluster	Chi Yu Chan;Charles E. Lawrence;Ye Ding	2005	Bioinformatics	10.1093/bioinformatics/bti632	biology;computer science;bioinformatics;sequence analysis;data mining;world wide web	Web+IR	0.9202883691943029	-57.581713933983636	43746
0d50f2efa6b82bf908b36a4c1b6f1bec5bd9703a	hiv promoter integration site primarily modulates transcriptional burst size rather than frequency	hiv;transcription genetic;hek293 cells;hiv long terminal repeat;jurkat cells;particle size;virus integration;models genetic;stochastic processes;promoter regions genetic;host pathogen interactions;humans;markov chains	Mammalian gene expression patterns, and their variability across populations of cells, are regulated by factors specific to each gene in concert with its surrounding cellular and genomic environment. Lentiviruses such as HIV integrate their genomes into semi-random genomic locations in the cells they infect, and the resulting viral gene expression provides a natural system to dissect the contributions of genomic environment to transcriptional regulation. Previously, we showed that expression heterogeneity and its modulation by specific host factors at HIV integration sites are key determinants of infected-cell fate and a possible source of latent infections. Here, we assess the integration context dependence of expression heterogeneity from diverse single integrations of a HIV-promoter/GFP-reporter cassette in Jurkat T-cells. Systematically fitting a stochastic model of gene expression to our data reveals an underlying transcriptional dynamic, by which multiple transcripts are produced during short, infrequent bursts, that quantitatively accounts for the wide, highly skewed protein expression distributions observed in each of our clonal cell populations. Interestingly, we find that the size of transcriptional bursts is the primary systematic covariate over integration sites, varying from a few to tens of transcripts across integration sites, and correlating well with mean expression. In contrast, burst frequencies are scattered about a typical value of several per cell-division time and demonstrate little correlation with the clonal means. This pattern of modulation generates consistently noisy distributions over the sampled integration positions, with large expression variability relative to the mean maintained even for the most productive integrations, and could contribute to specifying heterogeneous, integration-site-dependent viral production patterns in HIV-infected cells. Genomic environment thus emerges as a significant control parameter for gene expression variation that may contribute to structuring mammalian genomes, as well as be exploited for survival by integrating viruses.	clone;compact cassette;dna integration;gene expression;gene co-expression network;genetic heterogeneity;genome;genus: lentivirus group;green fluorescent proteins;latent tuberculosis;mammals;modulation;population parameter;sampling - surgical action;semiconductor industry;spatial variability;transcript;transcription, genetic;transcriptional regulation;transcutaneous electric nerve stimulation;virus	Ron Skupsky;John C. Burnett;Jonathan E. Foley;David V. Schaffer;Adam Paul Arkin	2010		10.1371/journal.pcbi.1000952	stochastic process;biology;markov chain;molecular biology;hek 293 cells;bioinformatics;jurkat cells;particle size;genetics;statistics	Comp.	4.595239988117877	-61.74338756297508	43786
703eabd0bf03d206d8d564ee2d866ac2c31736fe	spatiotemporal dynamics of human object recognition processing: an integrated high-density electrical mapping and functional imaging study of “closure” processes	object recognition;source analysis;high density;temporal dynamics;negative association;functional imaging;functional magnetic resonance images;lateral occipital complex	"""Humans are capable of recognizing objects, often despite highly adverse viewing conditions (e.g., occlusion). The term """"perceptual closure"""" has been used to refer to the neural processes responsible for """"filling-in"""" missing information in the visual image under such conditions. Closure phenomena have been linked to a group of object recognition areas, the so-called lateral-occipital complex (LOC). Here, we investigated the spatiotemporal dynamics of perceptual closure processes by coregistering data from high-density electrical recordings (ERPs) and functional magnetic resonance imaging (fMRI) while subjects participated in a perceptual closure task. Subjects were presented with highly fragmented images and control scrambled images. Fragmented images were calibrated to be 'just' recognizable as objects (that is, perceptual closure was necessary), whereas the scrambled images were unrecognizable. Comparison of responses to these two stimulus classes revealed the neural processes underlying perceptual closure. fMRI revealed an object recognition system that mediates these closure processes, the core of which consists of the LOC regions. ERP recordings resulted in the well-characterized N(CL) component (for negativity associated with closure), a robust relative negativity over bilateral occipito-temporal scalp that occurs in the 230-400 ms timeframe. Our investigations further revealed an extended network of dorsal and frontal regions, also involved in perceptual closure processes. Inverse source analysis showed that the major generators of N(CL) localized to the identical regions within LOC revealed by the fMRI recordings and detailed the temporal dynamics across these LOC regions including interactions between LOC and these other nodes of the object recognition circuit."""	altered level of consciousness;bilateral filter;cdisc sdtm anatomical location terminology;class;erp;functional imaging;hidden surface determination;humans;interaction;lateral thinking;magnetic resonance imaging;negativity (quantum mechanics);optic nerve glioma, childhood;outline of object recognition;perceptual closure;physical object;whole earth 'lectronic link;fmri;frontal lobe	Pejman Sehatpour;Sophie Molholm;Daniel C. Javitt;John J. Foxe	2006	NeuroImage	10.1016/j.neuroimage.2005.07.049	psychology;computer vision;radiology;medicine;artificial intelligence;cognitive neuroscience of visual object recognition;functional imaging;communication	ML	17.98521392398817	-76.36253391819554	43801
5228d5c0322866c6b73f81f408ca4e22b8a1874b	efficient and powerful method for combining p-values in genome-wide association studies	genomics;bioinformatics computational modeling additives diseases genomics attention deficit disorder;bioinformatics computational modeling additives diseases genomics correlation;globalevt attention deficit hyperactivity disorder adaptive rank truncated product method cyclophilin domain extreme value theory;proteins data analysis diseases genetics genomics medical computing medical disorders molecular biophysics;info eu repo semantics article;additives;extreme value theory;adaptive rank truncated product method;computational modeling;attention deficit hyperactivity disorder;diseases;globalevt;correlation;genome wide association studies cyclophilin a like domain proteins attention deficit hyperactivity disorder study gene level p values extreme value theory globalevt gene set analysis disease single nucleotide polymorphisms genetic variants;cyclophilin domain;bioinformatics	The goal of Genome-wide Association Studies GWAS is the identification of genetic variants, usually single nucleotide polymorphisms SNPs, that are associated with disease risk. However, SNPs detected so far with GWAS for most common diseases only explain a small proportion of their total heritability. Gene set analysis GSA has been proposed as an alternative to single-SNP analysis with the aim of improving the power of genetic association studies. Nevertheless, most GSA methods rely on expensive computational procedures that make unfeasible their implementation in GWAS. We propose a new GSA method, referred as globalEVT, which uses the extreme value theory to derive gene-level p-values. GlobalEVT reduces dramatically the computational requirements compared to other GSA approaches. In addition, this new approach improves the power by allowing different inheritance models for each genetic variant as illustrated in the simulation study performed and allows the existence of correlation between the SNPs. Real data analysis of an Attention-deficit/hyperactivity disorder ADHD study illustrates the importance of using GSA approaches for exploring new susceptibility genes. Specifically, the globalEVT method is able to detect genes related to Cyclophilin A like domain proteins which is known to play an important role in the mechanisms of ADHD development.	attention deficit hyperactivity disorder;causal filter;computation (action);extreme value theory;gnas wt allele;genetic association studies;genetic polymorphism;genome-wide association study;global storage architecture;hyperactive behavior;marginal model;maxima and minima;nitroprusside;requirement;simulation;single nucleotide polymorphism;time complexity;webserver directory index;algorithm;nervous system disorder	Natàlia Vilor-Tejedor;Juan R. Gonzalez;Malu Luz Calle	2016	IEEE/ACM Transactions on Computational Biology and Bioinformatics	10.1109/TCBB.2015.2509977	biology;genomics;biotechnology;food additive;bioinformatics;extreme value theory;mathematics;computational model;genetics;correlation	Comp.	5.374849530187385	-53.93320649004487	43813
3dc1c2dab197ebd0392da2c9d34dfa90a62d98fb	a neural model of human object recognition development	modelizacion;object recognition;vision ordenador;inelasticite;engineering design;human vision;neural model;plasticite;computer model;neural plasticity;inelasticidad;reconnaissance objet;intelligence artificielle;genetics;computer vision;modelisation;plasticity;inelasticity;neural system;human visual sys tem;plasticidad;pattern recognition;autoorganizacion;aparato visual;artificial intelligence;self organization;appareil visuel;vision ordinateur;inteligencia artificial;reconnaissance forme;reseau neuronal;reconocimiento patron;modeling;visual system;red neuronal;human brain;autoorganisation;neural network	The human capability of recognizing objects visually is here held to be a function emerging as result of interactions between epigenetic influences and basic neural plasticity mechanisms. The model here proposed simulates the development of the main neural processes of the visual system giving rise to the higher function of recognizing objects. It is a hierarchy of artificial neural maps, mainly based on the LISSOM architecture, achieving self-organization through simulated intercortical lateral connections.	computation;explicit modeling;interaction;lateral thinking;level of detail;map;outline of object recognition;self-organization;simulation	Rosaria Grazia Domenella;Alessio Plebe	2005		10.1007/11565123_12	neuroplasticity;computer vision;plasticity;self-organization;systems modeling;visual system;computer science;artificial intelligence;cognitive neuroscience of visual object recognition;machine learning;artificial neural network;engineering design process	AI	21.87754346262704	-68.7201852784339	43818
82e415db1e1151d4337a1dce853fbe4d25458de9	directional pc12 cell migration along plastic nanotracks	cell movement;cell movements;cell cytoskeleton;biological tissues;plastics nanobioscience polarization neurons surfaces extracellular nanotechnology nervous system councils biological materials;nanobioscience;extracellular;cell differentiation;neurophysiology biological tissues cellular biophysics cellular transport nanobiotechnology;nervous system;angular restriction;contact guidance;neuronal migration;neuronal differentiation;polarization;nanograting effect;cell substrate interaction;nanotechnology;topography;plastics;nucleokinesis;nanograting directionality;plastic nanotracks;cell migration;neuronal tissue;directional pc12 cell migration;bipolar cell;councils;biological materials;surfaces;cellular transport;nanograting directionality directional pc12 cell migration plastic nanotracks neuronal tissue nanograting effect neuronal differentiation cell substrate interaction angular restriction cell movements cell cytoskeleton;neurons;neurophysiology;cellular biophysics;topography contact guidance neuronal migration nucleokinesis;animals biocompatible materials cell adhesion cell movement cell polarity guided tissue regeneration materials testing nanostructures nanotechnology neurons pc12 cells plastics rats surface properties;nanobiotechnology	The design of materials to promote the development and/or regeneration of neuronal tissue requires the understanding of the mechanisms by which the underlying substrate topography can modulate neuronal cell differentiation and migration. We recently demonstrated that plastic nanogratings (alternating lines of grooves and ridges of submicrometer size) can effectively change the neuronal polarity state, selecting bipolar cells with aligned neurites. Here, we address the effect of nanogratings on the migration properties of differentiating PC12 cells and correlate their behavior with the polarity state induced by the substrate. During neuronal differentiation, cell-substrate interaction is sufficient to induce directional migration along the nanogratings. Control cells contacting flat substrates migrated freely in all directions, while cells differentiating on nanogratings showed slower migration characterized by an angular restriction that confined cell movements. Finally, we show that directional migration on nanogratings is linked to a specific organization of the cell cytoskeleton reflecting the nanograting directionality.	alignment;angularjs;bipolar disorder;cell differentiation process;cell movement;cellular phone;migration, cell;natural regeneration;neurites;topography;polarity	Aldo Ferrari;Marco Cecchini;Riccardo Degl'Innocenti;Fabio Beltram	2009	IEEE Transactions on Biomedical Engineering	10.1109/TBME.2009.2027424	cell migration;biology;neural development;extracellular;neuroscience;cell biology;polarization;topography;plastic;nanotechnology;nervous system;surface;neurophysiology;nanobiotechnology;cellular differentiation;anatomy	Visualization	13.407720009285988	-68.81632460723992	43826
5f38cdd79ee187693a9154b02437cfcf0b1b8320	discrimination of seismic signals using artificial neural networks	conference;meeting	"""The automatic discrimination of seismic signals is an important practical goal for earth-science observatories due to the large amount of information that they receive continuously. An essential discrimination task is to allocate the incoming signal to a group associated with the kind of physical phenomena producing it. In this paper, two classes of seismic signals recorded routinely in geophysical laboratory of the National Center for Scientific and Technical Research in Morocco are considered. They correspond to signals associated to local earthquakes and chemical explosions. The approach adopted for the development of an automatic discrimination system is a modular system composed by three blocs: 1) Representation, 2) Dimensionality reduction and 3) Classification. The originality of our work consists in the use of a new wavelet called """"modified Mexican hat wavelet"""" in the representation stage. For the dimensionality reduction, we propose a new algorithm based on the random projection and the principal component analysis. Keywords—Seismic signals, Wavelets, Dimensionality reduction, Artificial neural networks, Classification."""	algorithm;artificial neural network;categorization;dimensionality reduction;mexican hat wavelet;neural networks;principal component analysis;random projection	Mohammed Benbrahim;Adil Daoudi;Khalid Benjelloun;Aomar Ibenbrahim	2005			artificial intelligence;data mining;operations research	AI	-0.5390448291713685	-74.34771345908861	43910
61c9c9419c3ad1c1ba0d6fc013a3055be1bfa949	prediction of reacting atoms for the major biotransformation reactions of organic xenobiotics	computer applications in chemistry;theoretical and computational chemistry;computational biology bioinformatics;documentation and information in chemistry	"""BACKGROUND The knowledge of drug metabolite structures is essential at the early stage of drug discovery to understand the potential liabilities and risks connected with biotransformation. The determination of the site of a molecule at which a particular metabolic reaction occurs could be used as a starting point for metabolite identification. The prediction of the site of metabolism does not always correspond to the particular atom that is modified by the enzyme but rather is often associated with a group of atoms. To overcome this problem, we propose to operate with the term """"reacting atom"""", corresponding to a single atom in the substrate that is modified during the biotransformation reaction. The prediction of the reacting atom(s) in a molecule for the major classes of biotransformation reactions is necessary to generate drug metabolites.   RESULTS Substrates of the major human cytochromes P450 and UDP-glucuronosyltransferases from the Biovia Metabolite database were divided into nine groups according to their reaction classes, which are aliphatic and aromatic hydroxylation, N- and O-glucuronidation, N-, S- and C-oxidation, and N- and O-dealkylation. Each training set consists of positive and negative examples of structures with one labelled atom. In the positive examples, the labelled atom is the reacting atom of a particular reaction that changed adjacency. Negative examples represent non-reacting atoms of a particular reaction. We used Labelled Multilevel Neighbourhoods of Atoms descriptors for the designation of reacting atoms. A Bayesian-like algorithm was applied to estimate the structure-activity relationships. The average invariant accuracy of prediction obtained in leave-one-out and 20-fold cross-validation procedures for five human isoforms of cytochrome P450 and all isoforms of UDP-glucuronosyltransferase varies from 0.86 to 0.99 (0.96 on average).   CONCLUSIONS We report that reacting atoms may be predicted with reasonable accuracy for the major classes of metabolic reactions-aliphatic and aromatic hydroxylation, N- and O-glucuronidation, N-, S- and C-oxidation, and N- and O-dealkylation. The proposed method is implemented as a freely available web service at http://www.way2drug.com/RA and may be used for the prediction of the most probable biotransformation reaction(s) and the appropriate reacting atoms in drug-like compounds.Graphical abstract."""	aromatics;aromatic hydroxylation [pk];atom (standard);class;cross reactions;cross-validation (statistics);dealkylation;drug discovery;identifier;limited stage (cancer stage);metabolic biotransformation;metabolic process, cellular;n-entity;probability;protein isoforms;test set;uridine diphosphate;web service;xenobiotics;algorithm;organic substance biosynthetic process;oxidation	Anastasia V. Rudik;Alexander V. Dmitriev;Alexey A Lagunin;Dmitry A Filimonov;Vladimir V Poroikov	2016		10.1186/s13321-016-0183-x	drug discovery;computational chemistry;biotransformation;molecule;metabolite;xenobiotic;bioinformatics;substrate (chemistry);stereochemistry;atom;chemistry;drug metabolism	ML	9.8370349402452	-58.30023767986018	43920
8f7e5013b33fc7c1b5cbc1a9e3e676533f6419df	promoter recognition using dinucleotide features : a case study for e.coli	dna;biology computing;dna segment promoter recognition dinucleotide e coli global signal based method motif search methods global feature methods global feature extraction feed forward neural network classifier;molecular configurations;e coli;feed forward neural network classifier;global feature extraction;motif search methods;molecular configurations biology computing dna feature extraction feedforward neural nets molecular biophysics;feature extraction;dna segment;molecular biophysics;feedforward neural nets;global feature methods;neural networks sequences feature extraction feeds feedforward neural networks dna pulse width modulation bayesian methods computational intelligence search methods;dinucleotide;promoter recognition;global signal based method	Promoter recognition is based upon two complementary methods, a motif based method and a global signal based method. The literature is abound with motif search methods. But as the motifs of a promoter are consensus patterns of very short length and the chance of finding putative promoters is high, global feature methods gain importance. In this paper a simple global feature extraction method is proposed for the recognition of sigma-70 promoters in E.coli. It is shown that a simple feed forward neural network classifier achieves a precision of nearly 80% in contrast to the high end classifiers and heavy features proposed in the literature achieving a similar performance. Additionally, a scheme is proposed for locating promoter regions in a given DNA segment.	algorithm;artificial neural network;experiment;feature extraction;motif;simple features	T. Sobha Rani;S. Durga Bhavani;Raju S. Bapi	2006	9th International Conference on Information Technology (ICIT'06)	10.1109/ICIT.2006.75	feature extraction;computer science;bioinformatics;machine learning;pattern recognition;dna;molecular biophysics	Robotics	9.733158399348298	-54.83697702034289	43950
c91fff86109088f0d19f7443beb43cffe8876e20	a predictive model for acute admission in aged population	acute admission;data science;healthcare;machine learning;predictive model	Acute hospital admission among the elderly population is very common and have a high impact on the health services and the community, as well as on the individuals. Several studies have focused on the possible risk factors, however, predicting who is at risk for acute hospitalization associated with disease and symptoms is still an open research question. In this study, we investigate the use of machine learning algorithms for predicting acute admission in older people based on admission data from individual citizens 70 years and older who were hospitalized in the acute medical unit of Svendborg Hospital in Denmark.		Marjan Mansourvar;Karen Andersen-Ranberg;Christian Nøhr;Uffe Kock Wiil	2018	Studies in health technology and informatics	10.3233/978-1-61499-852-5-96	knowledge management;health care;medical emergency;population;medicine	HCI	6.1229474221467175	-76.0729958920047	44002
af50e3860adda09664dd7f17c0a5d3b5241c3816	genetopics - interpretation of gene sets via literature-driven topic models	myocardium;animals;simulation and modeling;mice;metabolic networks and pathways;disease;systems biology;molecular sequence annotation;physiological cellular and medical topics;databases genetic;data mining;computational biology bioinformatics;reproducibility of results;algorithms;transcriptome;humans;computational biology;bioinformatics	Annotation of a set of genes is often accomplished through comparison to a library of labelled gene sets such as biological processes or canonical pathways. However, this approach might fail if the employed libraries are not up to date with the latest research, don't capture relevant biological themes or are curated at a different level of granularity than is required to appropriately analyze the input gene set. At the same time, the vast biomedical literature offers an unstructured repository of the latest research findings that can be tapped to provide thematic sub-groupings for any input gene set. Our proposed method relies on a gene-specific text corpus and extracts commonalities between documents in an unsupervised manner using a topic model approach. We automatically determine the number of topics summarizing the corpus and calculate a gene relevancy score for each topic allowing us to eliminate non-specific topics. As a result we obtain a set of literature topics in which each topic is associated with a subset of the input genes providing directly interpretable keywords and corresponding documents for literature research. We validate our method based on labelled gene sets from the KEGG metabolic pathway collection and the genetic association database (GAD) and show that the approach is able to detect topics consistent with the labelled annotation. Furthermore, we discuss the results on three different types of experimentally derived gene sets, (1) differentially expressed genes from a cardiac hypertrophy experiment in mice, (2) altered transcript abundance in human pancreatic beta cells, and (3) genes implicated by GWA studies to be associated with metabolite levels in a healthy population. In all three cases, we are able to replicate findings from the original papers in a quick and semi-automated manner. Our approach provides a novel way of automatically generating meaningful annotations for gene sets that are directly tied to relevant articles in the literature. Extending a general topic model method, the approach introduced here establishes a workflow for the interpretation of gene sets generated from diverse experimental scenarios that can complement the classical approach of comparison to reference gene sets.	annotation;complement system proteins;experiment;gene regulatory network;hypertrophy;kegg;libraries;norm (social);paper;relevance;self-replicating machine;semiconductor industry;sinoatrial node;structure of beta cell of islet;subgroup;text corpus;topic model;transcript	Vicky Wang;Li Xi;Ahmed Enayetallah;Eric Fauman;Daniel Ziemek	2013		10.1186/1752-0509-7-S5-S10	computational biology;biology;transcriptome;computer science;bioinformatics;data mining;systems biology	Comp.	4.187369211381281	-55.88123607605005	44176
06713f2a6ea070c8928409a738c21945bfec7c04	a two-stage classifier for identification of protein-protein interface residues	bayesian classifier;protein complex;amino acid;amino acid sequence;signal transduction networks;rational drug design;protein protein interaction;support vector machine;three dimensional structure;protein interaction	MOTIVATION The ability to identify protein-protein interaction sites and to detect specific amino acid residues that contribute to the specificity and affinity of protein interactions has important implications for problems ranging from rational drug design to analysis of metabolic and signal transduction networks.   RESULTS We have developed a two-stage method consisting of a support vector machine (SVM) and a Bayesian classifier for predicting surface residues of a protein that participate in protein-protein interactions. This approach exploits the fact that interface residues tend to form clusters in the primary amino acid sequence. Our results show that the proposed two-stage classifier outperforms previously published sequence-based methods for predicting interface residues. We also present results obtained using the two-stage classifier on an independent test set of seven CAPRI (Critical Assessment of PRedicted Interactions) targets. The success of the predictions is validated by examining the predictions in the context of the three-dimensional structures of protein complexes.	amino acid sequence;amino acids;drug design;interface device component;metabolic process, cellular;naive bayes classifier;processor affinity;scientific publication;sensitivity and specificity;signal transduction;staphylococcal protein a;support vector machine;test set;transduction (machine learning);protein protein interaction	Changhui Yan;Drena Dobbs;Vasant Honavar	2004	Bioinformatics	10.1093/bioinformatics/bth920	protein–protein interaction;biology;support vector machine;naive bayes classifier;amino acid;computer science;bioinformatics;machine learning;pattern recognition;multiprotein complex;peptide sequence;drug design	Comp.	9.75419764121069	-57.12393584457964	44218
252cf86fa42e9382b3ad3691ecbe10958e74f2a9	an in silico platform for the study of epithelial pre-invasive neoplastic development	stochastic modeling;image processing;cancer;preneoplastic lesions;agent based model;quantitative;quantitative analysis;stochastic model;pathology;abm;in silico	To study the possible mechanisms of epithelial preneoplastic development we developed an integrated platform using a 3D agent-based model (ABM). This platform, named idefics, allows for the implementation of normal biological rules at the cell level that interact and generate the usual homeostatic equilibrium of epithelium as well as other abnormal processes that can disrupt this equilibrium. The structure of this model is based on data from multi-scale quantitative analysis of a unique collection of preneoplastic lesions of the lung, cervix, and oral epithelium, that have been collected in our lab in the last 25 years. In this paper, we are describing the different components of this platform and will present results from different simulations generated by the model.		Martial Guillaud;Carole Clem;Calum MacAulay	2010	Bio Systems	10.1016/j.biosystems.2010.07.008	image processing;bioinformatics;quantitative analysis;stochastic modelling;nanotechnology;stochastic;cancer	Robotics	6.692399690357186	-67.91174583581635	44229
954c9d49b27360ce30cc9def8db73e06f3411b37	musical literacy shifts asymmetries in the ventral visual cortex	sight reading;hemispheric specialization;music notation;lateralization	The acquisition of literacy has a profound impact on the functional specialization and lateralization of the visual cortex. Due to the overall lateralization of the language network, specialization for printed words develops in the left occipitotemporal cortex, allegedly inducing a secondary shift of visual face processing to the right, in literate as compared to illiterate subjects. Applying the same logic to the acquisition of high-level musical literacy, we predicted that, in musicians as compared to non-musicians, occipitotemporal activations should show a leftward shift for music reading, and an additional rightward push for face perception. To test these predictions, professional musicians and non-musicians viewed pictures of musical notation, faces, words, tools and houses in the MRI, and laterality was assessed in the ventral stream combining ROI and voxel-based approaches. The results supported both predictions, and allowed to locate the leftward shift to the inferior temporal gyrus and the rightward shift to the fusiform cortex. Moreover, these laterality shifts generalized to categories other than music and faces. Finally, correlation measures across subjects did not support a causal link between the leftward and rightward shifts. Thus the acquisition of an additional perceptual expertise extensively modifies the laterality pattern in the visual system.	area striata structure;categories;causal filter;cerebral cortex;face perception;functional laterality;handedness;high- and low-level;image;partial template specialization;printing;region of interest;structure of inferior temporal gyrus;visual cortex;voxel;notation	Florence Bouhali;Valeria Mongelli;Laurent Cohen	2017	NeuroImage	10.1016/j.neuroimage.2017.04.027	psychology;cognitive psychology;neuroscience;developmental psychology;lateralization of brain function;musical notation;communication	ML	18.08151808571978	-77.63885131638393	44297
5657c2935bb312715ad1207ed8ad408d75fb1aba	degradation of bacterial quorum sensing signaling molecules by the microscopic yeast trichosporon loubieri isolated from tropical wetland waters	n acylhomoserine lactone;rapid resolution liquid chromatography;tropical climate;yeast;lactones;quorum quenching;water microbiology;trichosporon;wetlands;biosensor;quorum sensing;lactonase;basidiomycetous;trichosporon loubieri	Proteobacteria produce N-acylhomoserine lactones as signaling molecules, which will bind to their cognate receptor and activate quorum sensing-mediated phenotypes in a population-dependent manner. Although quorum sensing signaling molecules can be degraded by bacteria or fungi, there is no reported work on the degradation of such molecules by basidiomycetous yeast. By using a minimal growth medium containing N-3-oxohexanoylhomoserine lactone as the sole source of carbon, a wetland water sample from Malaysia was enriched for microbial strains that can degrade N-acylhomoserine lactones, and consequently, a basidiomycetous yeast strain WW1C was isolated. Morphological phenotype and molecular analyses confirmed that WW1C was a strain of Trichosporon loubieri. We showed that WW1C degraded AHLs with N-acyl side chains ranging from 4 to 10 carbons in length, with or without oxo group substitutions at the C3 position. Re-lactonisation bioassays revealed that WW1C degraded AHLs via a lactonase activity. To the best of our knowledge, this is the first report of degradation of N-acyl-homoserine lactones and utilization of N-3-oxohexanoylhomoserine as carbon and nitrogen source for growth by basidiomycetous yeast from tropical wetland water; and the degradation of bacterial quorum sensing molecules by an eukaryotic yeast.	activation action;biological assay;carbon;cell signaling;culture media;data assimilation;elegant degradation;lactones;metabolic process, cellular;microsoft outlook for mac;phenotype;signal transduction;solute carrier organic anion transporter family member 1b1;tencent qq;trichosporon <trichosporonales>;trichosporon pullulans ab.ige:acnc:pt:ser:qn;wetlands;yeasts;potassium oxonate;quorum sensing	Cheng-Siang Wong;Chong-Lek Koh;Choon-Kook Sam;Jian Woon Chen;Yee Meng Chong;Wai-Fong Yin;Kok Gan Chan	2013		10.3390/s131012943	quorum sensing;wetland;nanotechnology;biosensor	Comp.	5.378652110307235	-63.83244350162669	44302
011942bb2e879016846627495e070309bc97fffd	neural network predictions of significant coronary artery stenosis in men	coronary atherosclerosis;coronary arteriogram;angina;coronary artery;artificial neural network;neural network	OBJECTIVE A neural network system was designed to predict whether coronary arteriography on a given patient would reveal any occurrence of significant coronary stenosis (>50%), a degree of stenosis which often leads to coronary intervention.   METHODOLOGY A dataset of 2004 records from male cardiology patients was derived from a national cardiac catheterization database. The catheterizations selected for analysis from the database were first-time and elective, and they were precipitated by chest pain. Eleven patient variables were used as inputs in an artificial neural network system. The network was trained on the earliest 902 records in the dataset. The next 902 records formed a cross-validation file, which was used to optimize the training. A third file composed of the next 100 records facilitated the choice of a cutoff number between 0 and 1. The cutoff number was applied to the last 100 records, which comprised a test file.   RESULTS When a cutoff of 0.25 was compared to the network outputs of all 100 records in the test file, 12 of 46 (specificity=26%) patients without significant stenosis had outputs<or=0.25, but all patients with significant stenosis had outputs>0.25 (sensitivity=100%). Therefore, the network identified a fraction of the patients in the test file who did not have significant coronary artery stenosis, while at the same time the network identified all of the patients in the test file who had significant stenosis capable of causing chest pain.   CONCLUSION Artificial neural networks may be helpful in reducing unnecessary cardiac catheterizations.		Bert A. Mobley;Eliot Schechter;William E. Moore;Patrick A. McKee;June E. Eichner	2005	Artificial intelligence in medicine	10.1016/j.artmed.2004.08.003	computer science;machine learning;artificial neural network	ML	7.438905185869098	-76.1623368835468	44311
16f0dbeb87be85020df7f9641e1934e08820f494	processing of movement information in the early stages of the visual system	early visual system;motion pauses;kernel;eye;movement information processing;neural nets;processing stages;depressive synaptic transmission;visual evoked potentials;synaptic transmission;temporal structure;fast prey capture reactions;beginning movement;movement pattern;retina;neurophysiology neural nets eye visual evoked potentials;movement patterns;neural responses;neurotransmitters;visual system retina delay optical sensors gain control kernel neurotransmitters object detection humans motion detection;optic tectum;humans;optical sensors;neurophysiology;prey capture;visual system;tongue projecting salamanders movement information processing processing stages movement patterns early visual system retina optic tectum temporal structure neural responses gain control depressive synaptic transmission motion pauses beginning movement fast prey capture reactions;motion detection;gain control;object detection;tongue projecting salamanders	We present a model for the processing of different movement patterns in the early visual system. The model consists of two processing stages: retina and optic tectum. The temporal structure of movement patterns is translated into a temporal structure of neural responses. This is accomplished by applying gain control in the retina, depressive synaptic transmission and adaptation in tectum to obtain a model that recovers during low activity in motion pauses. The model is especially sensitive to beginning movement after such pauses, enabling fast prey capture reactions in tongue-projecting salamanders.		Stefan D. Wilke;Andreas Thiel;Christian W. Eurich	2000		10.1109/IJCNN.2000.861506	computer vision;automatic gain control;kernel;visual system;neurophysiology;artificial neural network;neurotransmission	ML	20.954063087005895	-68.13328276600481	44351
a29f522ccb6f4333fe4db3733c6dbfd3b09f1142	quantification of the ionic current contributions to alterations in the action potential repolarization by means of piecewise-linear approximation	indium tin oxide	At cellular level, changes in the cardiac action potential (AP) duration (APD) are relevant proarrhythmic markers. The assessment of single current contributions to APD changes allows the investigation of the complex interplay of ionic mechanisms underlying such repolarization changes. In this paper, we present a new method to quantify the contributions of each membrane current to AP D changes due to a perturbation from the basal to a different condition. To achieve our goal, we used a piecewise-linear approximation of the AP. We tested our method on the O'Hara-Rudy model in case of rate adaptation: from the basal condition (pacing at 60 bpm), two different pacing rates are used as perturbations: 30 bpm, which prolongs APD by 21 ms, and 120 bpm, which shortens APD by -37 ms. At steady state, the most significant current contributions (30 bpm/120 bpm) are: INaK (68/-73 ms), lCaL (-58/51 ms), INaCa (-10/25 ms), IKs (13/-7 ms) and INaL (7/-23 ms). Our method allows also quantifying the dynamic adaptation to rate changes from the perturbation until the steady state. In conclusion, our method enables the quantification of the adaptive and compensatory mechanisms implemented by the (in silico model of) cell in response to a perturbation, such as the pacing rate change.	action potential;auditory processing disorder;basal (phylogenetics);ionic;linear approximation;mathematical model;steady state	Michelangelo Paci;Jari Hyttinen;Stefano Severi	2015	2015 Computing in Cardiology Conference (CinC)	10.1109/CIC.2015.7408607	materials science;electronic engineering;nanotechnology	Mobile	16.767853650579305	-71.77080339959618	44359
8c35ce1f0342e02890899e9a63bc438e205d3e94	synaptic scaling enables dynamically distinct short- and long-term memory formation	models neurological;neuronal plasticity;plos computational biology;memory long term;neurons;memory short term;computational biology;synapses	Memory storage in the brain relies on mechanisms acting on time scales from minutes, for long-term synaptic potentiation, to days, for memory consolidation. During such processes, neural circuits distinguish synapses relevant for forming a long-term storage, which are consolidated, from synapses of short-term storage, which fade. How time scale integration and synaptic differentiation is simultaneously achieved remains unclear. Here we show that synaptic scaling - a slow process usually associated with the maintenance of activity homeostasis - combined with synaptic plasticity may simultaneously achieve both, thereby providing a natural separation of short- from long-term storage. The interaction between plasticity and scaling provides also an explanation for an established paradox where memory consolidation critically depends on the exact order of learning and recall. These results indicate that scaling may be fundamental for stabilizing memories, providing a dynamic link between early and late memory formation processes.		Christian Tetzlaff;Christoph Kolodziejski;Marc Timme;Misha Tsodyks;Florentin Wörgötter	2013	PLoS computational biology	10.1371/journal.pcbi.1003307	neuroplasticity;neuroscience;synapse;artificial intelligence;metaplasticity;synaptic scaling	ML	18.56728057588916	-71.46003096544625	44367
518098a46fa6b7bcd2cf50dab0527b6af83bb785	the detection of chinese herbal rules for gastro-esophageal reflux disease by data mining	text mining approach chinese herbal rules data mining approach chinese biomedical literature service system liver function regulation stomach function regulation gastro esophageal reflux disease treatment;filtering;liver;text mining;diseases text mining liver filtering conferences bioinformatics;diseases;patient treatment data mining diseases liver medical information systems;conferences;regularity of clinical medication gastro esophageal reflux disease text mining;bioinformatics	To explore the regularity of clinical medication of Gastro-esophageal reflux disease (GERD) through text mining approach. Literatures on GERD in SinoMed(Chinese biomedical literature service system) were collected. Results: BANXIA, CHAIHU and HUANGLIAN were commonly used Chinese herbs in sequence from high to low, the network of Chinese herbs, symptoms and patterns could be established. Conclusion: The commonly used Chinese Herbs are coincided with the treatment rules of regulating the function of liver and stomach as well as adjusting cold and heat and the networks are corresponded with each other in treating GERD and could be verified through text mining approach.	chinese room;data mining;text mining	Dan He;Meiling Yao;Miao Jiang;Chi Zhang;Aiping Lu	2014	2014 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)	10.1109/BIBM.2014.6999319	filter;text mining;computer science;bioinformatics	SE	0.5749373624173035	-73.59889540657933	44411
a168ba782bf27ad15ebc0db29945ded22483f614	vistraj: exploring protein conformational space	protein conformation	UNLABELLED VISTRAJ is an application which allows 3D visualization, manipulation and editing of protein conformational space using probabilistic maps of this space called 'trajectory distributions'. Trajectory distributions serve as input to FOLDTRAJ which samples protein structures based on the represented conformational space. VISTRAJ also allows FOLDTRAJ to be used as a tool for homology model creation, and structures may be generated containing post-translationally modified amino acids.   AVAILABILITY Binaries are freely available for non-profit use as part of the FOLDTRAJ package at ftp://ftp.mshri.on.ca/pub/TraDES/foldtraj/.	amino acids;binary file;homologous gene;homology modeling;map;nonprofit organizations	John J. Salama;Howard J. Feldman;Christopher W. V. Hogue	2001	Bioinformatics	10.1093/bioinformatics/17.9.851	biology;protein structure;topology;bioinformatics;mathematics	Comp.	-2.1810258523648196	-59.619379604550566	44420
0245e5e5459a64abb2a4f61d677a959eaa03b3b2	diana-mirgen v3.0: accurate characterization of microrna promoters and their regulators	animals;mice;databases nucleic acid;transcription factors;binding sites;promoter regions genetic;gene expression regulation;humans;micrornas;transcription initiation site;cell line	microRNAs (miRNAs) are small non-coding RNAs that actively fine-tune gene expression. The accurate characterization of the mechanisms underlying miRNA transcription regulation will further expand our knowledge regarding their implication in homeostatic and pathobiological networks. Aim of DIANA-miRGen v3.0 (http://www.microrna.gr/mirgen) is to provide for the first time accurate cell-line-specific miRNA gene transcription start sites (TSSs), coupled with genome-wide maps of transcription factor (TF) binding sites in order to unveil the mechanisms of miRNA transcription regulation. To this end, more than 7.3 billion RNA-, ChIP- and DNase-Seq next generation sequencing reads were analyzed/assembled and combined with state-of-the-art miRNA TSS prediction and TF binding site identification algorithms. The new database schema and web interface facilitates user interaction, provides advanced queries and innate connection with other DIANA resources for miRNA target identification and pathway analysis. The database currently supports 276 miRNA TSSs that correspond to 428 precursors and >19M binding sites of 202 TFs on a genome-wide scale in nine cell-lines and six tissues of Homo sapiens and Mus musculus.	binding sites;biopolymer sequencing;body tissue;diana (intermediate language);dnase-seq;database schema;deoxyribonuclease i;gene expression;gene regulatory network;greater than;homeostasis;interface device component;massively-parallel sequencing;micrornas;muscle;pathway analysis;rafivirumab;transcription factor;toxic shock syndrome;transcription (software);transcription initiation site;transcriptional regulation;user interface;algorithm;promoter;vedolizumab	Georgios Georgakilas;Ioannis S. Vlachos;Konstantinos Zagganas;Thanasis Vergoulis;Maria D. Paraskevopoulou;Ilias Kanellos;Panayiotis Tsanakas;Dimitris Dellis;Athanasios Fevgas;Theodore Dalamagas;Artemis G. Hatzigeorgiou	2016		10.1093/nar/gkv1254	biology;molecular biology;regulation of gene expression;bioinformatics;binding site;genetics;cell culture;microrna;transcription factor	Comp.	0.6801327707192311	-59.59668307667899	44505
16acb5330dc093ff5795aa5865cab4af1c62cdbe	tmrpres2d: high quality visual representation of transmembrane protein models	transmembrane protein;selected works;protein sequence;visual representation;graphical representation;bepress;image modeling;knowledge base	The 'TransMembrane protein Re-Presentation in 2-Dimensions' (TMRPres2D) tool, automates the creation of uniform, two-dimensional, high analysis graphical images/models of alpha-helical or beta-barrel transmembrane proteins. Protein sequence data and structural information may be acquired from public protein knowledge bases, emanate from prediction algorithms, or even be defined by the user. Several important biological and physical sequence attributes can be embedded in the graphical representation.	base;display resolution;embedded system;embedding;graphical user interface;integral membrane proteins;knowledge bases;algorithm	Ioannis C. Spyropoulos;Theodore Liakopoulos;Pantelis G. Bagos;Stavros J. Hamodrakas	2004	Bioinformatics	10.1093/bioinformatics/bth358	biology;knowledge base;transmembrane protein;computer science;bioinformatics;machine learning;protein sequencing;data mining	Comp.	-4.2060685263548825	-61.54081402413442	44529
a5b06f48da9ac8c7e48e8c67c3ba0593cd76d6d4	a practical exact algorithm for the individual haplotyping problem mec	dna;organisms;biology computing;sequences;information science;snp single nucleotide polymorphism;data engineering;genetics;haplotype;dna sequencing practical exact algorithm individual haplotyping problem mec;physics;np hardness;biological cells;biomedical engineering;genetics biology computing dna;error correction;parameterized algorithm;exact algorithm;sequences dna biological cells biomedical engineering information science organisms biomedical informatics data engineering educational institutions physics;dna sequencing;np hardness snp single nucleotide polymorphism haplotype mec minimum error correction;individual haplotyping problem mec;dna sequence;mec minimum error correction;biomedical informatics;single nucleotide polymorphism;practical exact algorithm	The individual haplotyping problem MEC is a computational problem that, given a set of DNA sequence fragment data of an individual, induces the corresponding haplotypes by changing the smallest number of SNPs. MEC problem is NP-hard and there has been no practical exact algorithm to solve the problem. In DNA sequencing experiments, due to technical limits, the maximum length of a fragment sequenced directly is about 1 kb. In consequence, the maximum number k of SNP sites that a fragment covers is usually small. Based on the observation above, the current paper introduces a new parameterized algorithm of running time O(mk3k + mlogm + ink), where m is the number of fragments. The algorithm solves the MEC problem efficiently even if the number of fragments and SNPs are large, and is practical in real biological applications.	computational problem;exact algorithm;experiment;kilobyte;np-hardness;serial digital video out;time complexity	Minzhu Xie;Jianxing Wang;Jianer Chen	2008	2008 International Conference on BioMedical Engineering and Informatics	10.1109/BMEI.2008.122	biology;dna sequencing;information science;bioinformatics;genetics	DB	0.2051016617493319	-52.235116781222075	44561
0013ef09932212c3ce4c9ae529af490dec4a10fe	caomicsv: an r package for visualizing multidimensional cancer genomic data	computational biology bioinformatics;algorithms;combinatorial libraries;computer appl in life sciences;microarrays;bioinformatics	Translational genomics research in cancers, e.g., International Cancer Genome Consortium (ICGC) and The Cancer Genome Atlas (TCGA), has generated large multidimensional datasets from high-throughput technologies. Data analysis at multidimensional level will greatly benefit clinical applications of genomic information in diagnosis, prognosis and therapeutics of cancers. To help, tools to effectively visualize integrated multidimensional data are important for understanding and describing the relationship between genomic variations and cancers. We implemented the R package, caOmicsV, to provide methods under R environment to visualize multidimensional cancer genomic data in two layouts: matrix layout and combined biological network and circular layout. Both layouts support to display sample information, gene expression (e.g., RNA and miRNA), DNA methylation, DNA copy number variations, and summarized data. A set of supplemental functions are included in the caOmicsV package to help users in generation of plot data sets from multiple genomic datasets with given gene names and sample names. Default plot methods for both layouts for easy use are also implemented. caOmicsV package provides an easy and flexible way to visualize integrated multidimensional cancer genomic data under R environment.	biological network;circular layout;consortium;dna copy number variations;gene expression;genomics;high-throughput computing;name;neoplasms;r language;rna;the cancer genome atlas;therapeutic procedure;throughput	Hongen Zhang;Paul S. Meltzer;Sean R. Davis	2016	BMC Bioinformatics	10.1186/s12859-016-0989-6	computational biology;biology;dna microarray;computer science;bioinformatics;data science	Comp.	-2.791088891880951	-58.49365859955286	44573
efd53c9753ddb6f467dbeef1659a007ec7c31c73	evaluation of the effect of input stimuli on the quality of orientation maps produced through self organization	modelizacion;procesamiento informacion;analisis estadistico;image processing;information visuelle;orientation map;procesamiento imagen;hombre;natural images;courbure;probabilistic approach;traitement image;higher order;modelisation;informacion visual;statistical analysis;visual information;enfoque probabilista;approche probabiliste;analyse statistique;information processing;human;autoorganizacion;curvatura;cerebral cortex;self organization;curvature;self organized map;cortex cerebral;traitement information;modeling;corteza cerebral;visual processing;autoorganisation;general line;homme	Self-organized maps have been proposed as a model for the formation of sensory maps in the cerebral cortex. The role of inputs is critical in this process of self-organization. This paper presents a systematic approach to analyzing the relationship between the input ensemble and the quality of self-organization achieved. We present a method for generating an input stimulus set consisting of images of curved lines. The advantage of this approach is that it allows the user the ability to precisely control the statistics of the input stimuli to visual processing algorithms. Since there is considerable scientific interest in the processing of information in the human visual stream, we specifically address the problem of self-organization of cortical areas V1 and V2. We show that the statistics of the curves generated with our algorithm match the statistics of natural images. We develop a measure of self-organization based on the oriented energy contained in the afferent weights to each cortical unit in the map. We show that as the curvature of the generated lines increases, this measure of self-organization decreases. Furthermore, self-organization using curved lines as stimuli is achieved much more rapidly, as the curve images do not contain as much higher order structure as natural images do.	algorithm;computation;computational model;fidelity of quantum states;infomax;map;self-organization;simulation	A. Ravishankar Rao;Guillermo A. Cecchi;Charles C. Peck;James Kozloski	2005		10.1007/11499145_82	computer vision;self-organization;systems modeling;higher-order logic;information processing;image processing;computer science;artificial intelligence;curvature;programming language	ML	22.29208633472197	-68.74244045252222	44617
b389e86818093c096d41aa74bd2720727eb55498	phybase: an r package for species tree analysis	physbase;species trees analysis;species;espece;tree;species tree;arbol;analyse;especie;arbre;analysis;phylogenetic analysis;analisis	MOTIVATION Phybase is an R package for phylogenetic analysis using species trees. It provides functions to read, write, manipulate, simulate, estimate, summarize and plot species trees, which contain not only the topology and branch lengths but also population sizes.   AVAILABILITY The Phybase package is available at the R repository. The manual and supporting materials including source code, sample R code and sample data files for the species tree analysis are available at http://stat.osu.edu/~liuliang/research/phybase.html.	anatomy, regional;phylogenetics;r language;simulation;source code;trees (plant)	Liang Liu;Lili Yu	2010	Bioinformatics	10.1093/bioinformatics/btq062	biology;bioinformatics;analysis;ecology;algorithm	Comp.	-3.1450719169797043	-56.25505634381543	44626
3eef4b290f3a194156f699a1822bbb381dbdd5e2	dna interaction with sperm cells: ode model	simulation and modeling;systems biology;physiological cellular and medical topics;computational biology bioinformatics;algorithms;bioinformatics	Introduction A computer simulation concerning initial events in the sperm/DNA interaction was performed. DNA binding with MHCII and CD4 proteins, DNA internalization into spermatozoa, and DNase activity in sperm were described by first order differential equations (ODE). The dynamics of the system depended on the parameters of the model. The simulation could explain controversial results in sperm mediated gene transfer research and posed this phenomenon to an unknown form of biological evolution.	computer simulation;evolution	Andrew V. Kuznetsov	2007	BMC Systems Biology	10.1186/1752-0509-1-S1-P42	biology;toxicology;computer science;bioinformatics;systems biology	Comp.	7.494575708975869	-65.22424001758804	44638
686c3c05f3ee43f83bcfe2f79872b51ce72ba501	agent-based model of therapeutic adipose-derived stromal cell trafficking during ischemia predicts ability to roll on p-selectin	cell movement;chemokines;monocytes;computational techniques;p selectin;agent based model;models biological;cytokines;adipose tissue;secretion;cell transplantation;skeletal muscles;selectins;adhesion molecules;wall shear stress;adhesion molecule;network architecture;stromal cells;humans;skeletal muscle;critical parameter;ischemia;in silico	Intravenous delivery of human adipose-derived stromal cells (hASCs) is a promising option for the treatment of ischemia. After delivery, hASCs that reside and persist in the injured extravascular space have been shown to aid recovery of tissue perfusion and function, although low rates of incorporation currently limit the safety and efficacy of these therapies. We submit that a better understanding of the trafficking of therapeutic hASCs through the microcirculation is needed to address this and that selective control over their homing (organ- and injury-specific) may be possible by targeting bottlenecks in the homing process. This process, however, is incredibly complex, which merited the use of computational techniques to speed the rate of discovery. We developed a multicell agent-based model (ABM) of hASC trafficking during acute skeletal muscle ischemia, based on over 150 literature-based rules instituted in Netlogo and MatLab software programs. In silico, trafficking phenomena within cell populations emerged as a result of the dynamic interactions between adhesion molecule expression, chemokine secretion, integrin affinity states, hemodynamics and microvascular network architectures. As verification, the model reasonably reproduced key aspects of ischemia and trafficking behavior including increases in wall shear stress, upregulation of key cellular adhesion molecules expressed on injured endothelium, increased secretion of inflammatory chemokines and cytokines, quantified levels of monocyte extravasation in selectin knockouts, and circulating monocyte rolling distances. Successful ABM verification prompted us to conduct a series of systematic knockouts in silico aimed at identifying the most critical parameters mediating hASC trafficking. Simulations predicted the necessity of an unknown selectin-binding molecule to achieve hASC extravasation, in addition to any rolling behavior mediated by hASC surface expression of CD15s, CD34, CD62e, CD62p, or CD65. In vitro experiments confirmed this prediction; a subpopulation of hASCs slowly rolled on immobilized P-selectin at speeds as low as 2 microm/s. Thus, our work led to a fundamentally new understanding of hASC biology, which may have important therapeutic implications.	agent-based model;cell adhesion molecules;ceramide dodecasaccharide;computation;computer simulation;experiment;extravasation;hemodynamics;interaction;matlab;microcirculation;missile guidance;multiple homing;muscle;p-selectin;pycard protein, human;population;processor affinity;rule (guideline);selectins;stromal cells;therapeutic procedure;up-regulation (physiology);verification of theories;cellular targeting;chemokine;monocyte chemoattractant protein-2;shear stress	Alexander M. Bailey;Michael B. Lawrence;Hulan Shang;Adam J. Katz;Shayn M. Peirce	2009	PLoS Computational Biology	10.1371/journal.pcbi.1000294	biology;cell adhesion molecule;network architecture;stromal cell;shear stress;chemokine;p-selectin;secretion;adipose tissue;selectin;ischemia;immunology	Comp.	9.02588061579293	-65.84514513472101	44643
4543a9b4831ab098bab9bf7c0ff40635a6af97ed	in silico analysis of a family of extracellular polysaccharide deacetylases involved in virulence of pathogenic gram-positive cocci	health research;uk clinical guidelines;biological patents;europe pubmed central;citation search;computational biology bioinformatics;uk phd theses thesis;life sciences;algorithms;combinatorial libraries;uk research reports;medical journals;computer appl in life sciences;europe pmc;biomedical research;microarrays;bioinformatics;in silico	Background Pathogenic bacteria incessantly evolve mechanisms to resist their host’s innate immunity. One such mechanism is molecular camouflage: the modification of bacterial surface molecules to make them unrecognizable by the host’s immune system or resistant to its effector molecules. Recently, a peptidoglycan deacetylase (PgdA) was discovered in Streptococcus pneumoniae that renders bacterial peptidoglycan resistant to human lysozyme, thus preventing host-mediated cell wall damage [1-3]. In addition, polysaccharide deacetylases with different substrate specificities were identified in other	rendering (computer graphics);substrate (electronics)	Ramy Karam Aziz	2010		10.1186/1471-2105-11-S4-P8	biology;dna microarray;computer science;bioinformatics;microbiology;genetics	ML	5.270915841981117	-63.93635013246724	44654
c945eb389e2264b8c7e8d8061db6f7f76b39948b	computational algorithms for analysing human immunoglobulin diversity from high-throughput sequencing of rearranged genes			algorithm;computation;high-throughput computing;throughput	Zhiliang Chen	2012				ML	1.2829183206249721	-63.53694214310981	44658
adbda6c4957a51279f409293c279045985b54e8a	interrogating domain-domain interactions with parsimony based approaches	prediction method;amino acid sequence;binding sites;computational biology bioinformatics;proteins;protein structure tertiary;protein binding;algorithms;molecular sequence data;combinatorial libraries;protein interaction;protein interaction mapping;computer appl in life sciences;systems integration;information storage and retrieval;sequence analysis protein;databases protein;microarrays;bioinformatics	"""The identification and characterization of interacting domain pairs is an important step towards understanding protein interactions. In the last few years, several methods to predict domain interactions have been proposed. Understanding the power and the limitations of these methods is key to the development of improved approaches and better understanding of the nature of these interactions. Building on the previously published Parsimonious Explanation method (PE) to predict domain-domain interactions, we introduced a new Generalized Parsimonious Explanation (GPE) method, which (i) adjusts the granularity of the domain definition to the granularity of the input data set and (ii) permits domain interactions to have different costs. This allowed for preferential selection of the so-called """"co-occurring domains"""" as possible mediators of interactions between proteins. The performance of both variants of the parsimony method are competitive to the performance of the top algorithms for this problem even though parsimony methods use less information than some of the other methods. We also examined possible enrichment of co-occurring domains and homo-domains among domain interactions mediating the interaction of proteins in the network. The corresponding study was performed by surveying domain interactions predicted by the GPE method as well as by using a combinatorial counting approach independent of any prediction method. Our findings indicate that, while there is a considerable propensity towards these special domain pairs among predicted domain interactions, this overrepresentation is significantly lower than in the iPfam dataset. The Generalized Parsimonious Explanation approach provides a new means to predict and study domain-domain interactions. We showed that, under the assumption that all protein interactions in the network are mediated by domain interactions, there exists a significant deviation of the properties of domain interactions mediating interactions in the network from that of iPfam data."""	algorithm;familial generalized lipodystrophy;gene ontology term enrichment;interaction;license;maximum parsimony (phylogenetics);occam's razor;pfam;scientific publication;silo (dataset)	Katia S. Guimarães;Teresa M. Przytycka	2007	BMC Bioinformatics	10.1186/1471-2105-9-171	computational biology;biology;plasma protein binding;dna microarray;computer science;bioinformatics;binding site;peptide sequence;system integration	Comp.	9.89388842668207	-59.17804497326119	44682
f3f685c9a2a5f3e421242bde017b193994a7d41c	discovering novel and diverse iron-chelators in silico		"""Specific iron chelation is a validated strategy in anticancer drug discovery. However, only a few chemical classes (4-5 categories) have been reported to date. We discovered in silico five new structurally diverse iron-chelators by screening through models based on previously known chelators. To encompass a larger chemical space and propose newer scaffolds, we used our iterative stochastic elimination (ISE) algorithm for model building and subsequent virtual screening (VS). The ISE models were developed by training a data set of 130 reported iron-chelators. The developed models are statistically significant with area under the receiver operating curve greater than 0.9. The models were used to screen the Enamine chemical database of ∼1.8 million molecules. The top ranked 650 molecules were reduced to 50 diverse structures, and a few others were eliminated due to the presence of reactive groups. Finally, 34 molecules were purchased and tested in vitro. Five compounds were identified with significant iron-chelation activity in Cal-G assay. Intracellular iron-chelation study revealed one compound as equivalent in potency to the iron chelating """"gold standards"""" deferoxamine and deferiprone. The amount of discovered positives (5 out of 34) is expected by the realistic enrichment factor of the model."""	categories;chelating activity;chelating agents;chemical database;chemical space;cheminformatics;deferoxamine;drug discovery;elimination disorders;excretory function;fifty nine;forty nine;gene ontology term enrichment;hemochromatosis;hydrazones;ise;internet;iron chelation;iron man;iron overload;iterative method;journal of chemical information and modeling;large;mandibular right second molar tooth;map;master of business informatics;medicinal chemistry;organic chemistry phenomena;projection screen;receiver operating characteristic;scintimammography;semicarbazones;simplified molecular-input line-entry system;synthetic data;test set;thiosemicarbazones, direct acting antivirals;virtual screening;algorithm;buying;deferiprone;notation;standards characteristics	Arijit Basu;Yang-Sung Sohn;Mohamed Alyan;Rachel Nechushtai;Abraham J. Domb;Amiram Goldblum	2016	Journal of chemical information and modeling	10.1021/acs.jcim.6b00450	chemistry;toxicology;bioinformatics;combinatorial chemistry	ML	8.569828450424701	-57.549137522346165	44703
1ec3d71c63a6f1b3b320fc3565606c0a91830d9a	the patient repository for eeg data + computational tools (pred+ct)	eeg;clinical neuroscience;databases as topic;open data;pattern classification	Electroencephalographic (EEG) recordings are thought to reflect the network-wide operations of canonical neural computations, making them a uniquely insightful measure of brain function. As evidence of these virtues, numerous candidate biomarkers of different psychiatric and neurological diseases have been advanced. Presumably, we would only need to apply powerful machine-learning methods to validate these ideas and provide novel clinical tools. Yet, the reality of this advancement is more complex: the scale of data required for robust and reliable identification of a clinical biomarker transcends the ability of any single laboratory. To surmount this logistical hurdle, collective action and transparent methods are required. Here we introduce the Patient Repository of EEG Data + Computational Tools (PRED+CT: predictsite.com). The ultimate goal of this project is to host a multitude of available tasks, patient datasets, and analytic tools, facilitating large-scale data mining. We hope that successful completion of this aim will lead to the development of novel EEG biomarkers for differentiating populations of neurological and psychiatric disorders.	biological markers;clinical decision support system;computation;data mining;electroencephalography;energy, physics;first draft of a report on the edvac;genesis;hl7publishingsubsection <operations>;logistics;machine learning;mental disorders;national institute of general medical sciences (u.s.);neuroscience discipline;patients;population;interest;nervous system disorder	James F. Cavanagh;Arthur Napolitano;Christopher Wu;Abdullah Mueen	2017		10.3389/fninf.2017.00067	data mining;machine learning;open data;data science;electroencephalography;artificial intelligence;computer science;databases as topic	ML	-1.0783787048670963	-69.61773860706042	44770
3226873c217d3220581134d058526d5fcdd76fee	mri anatomical mapping and direct stereotactic targeting in the subthalamic region: functional and anatomical correspondence in parkinson’s disease	adverse effect;data analysis;brain mapping;biological data;neuronal activity;image guided surgery	Object Relationships between clinical effects, anatomy, and electrophysiology are not fully understood in DBS of the subthalamic region in Parkinson’s disease. We proposed an anatomic study based on direct image-guided stereotactic surgery with a multiple source data analysis. Materials and Methods A manual anatomic mapping was realized on coronal 1.5-Tesla MRI of 15 patients. Biological data were collected under local anesthesia: the spontaneous neuron activities and the clinical efficiency and the appearance of adverse effects. They were related to relevant current values (mA), the benefit threshold (bt, minimal current leading an clear efficiency), the adverse effect threshold (at, minimal current leading an adverse effect) and the stimulation margin (sm =  at − bt); they were matched with anatomy. Results We found consistent relationships between anatomy and biological data. The optimal stimulation parameters (low bt + high sm) were noted in the dorsolateral STN. The highest spontaneous neuron activity was found in the ventromedial STN. Dorsolateral (sensorimotor) STN seems the main DBS effector. The highest spontaneous neuron activity seems related to the anterior (rostral) ventromedial (limbic) STN. Conclusion 1.5 Tesla images provide sufficiently detailed subthalamic anatomy for image-guided stereotactic surgery and may aid in understanding DBS mechanisms.		Jean-Jacques Lemaire;Jérôme Coste;Lemlih Ouchchane;Simone Hemm;Philippe Derost;Miguel Ulla;Séverine Siadoux;Jean Gabrillargues;Franck Durif;Jean Chazal	2007	International Journal of Computer Assisted Radiology and Surgery	10.1007/s11548-007-0124-2	medicine;pathology;biological data;adverse effect;computer science;data analysis;brain mapping;premovement neuronal activity	ML	19.54164681058081	-79.7634130733804	44806
d93dbeab564789da3d32a24e3546f1d52f3c330d	etagenome analysis using megan		In metagenomics, the goal is to analyze the genomic content o f a sample of organisms collected from a common habitat. One approach is to apply large-scale rando m shotgun sequencing techniques to obtain a collection of DNA reads from the sample. This data is then compared against databases of known sequences such as NCBI-nr or NCBI-nt, in an attempt to i dent fy the taxonomical content of the sample. We introduce a new software called MEGAN (Meta Ge nome ANalyzer) that generates species profiles from such sequencing data by assigning read s to taxa of the NCBI taxonomy using a straight-forward assignment algorithm. The approach is i llu trated by application to a number of datasets obtained using both sequencing-by-synthesis and S ger sequencing technology, including metagenomic data from a mammoth bone, a portion of the Sargas so sea data set, and several complete microbial test genomes used for validation proposes.	algorithm;database;habitat;megan;metagenomics;randomness;taxonomy (general)	Daniel H. Huson;Alexander F. Auch;Qi Ji;Stephan C. Schuster	2007			machine learning;genomics;computational biology;sanger sequencing;artificial intelligence;shotgun sequencing;genome project;reference genome;cancer genome sequencing;metagenomics;whole genome sequencing;biology;genetics	Comp.	-0.1501471097640987	-56.46947540797822	44846
57b04b97fe1a93d54781f410eedba9ab87a50b17	an architecture design method of deep convolutional neural network		Deep Convolutional Neural Network (DCNN) is a kind of multi layer neural network models. In these years, the DCNN is attracting the attention since it shows the state-of-the-arts performance in the image and speech recognition tasks. However, the design for the architecture of the DCNN has not so much discussed since we have not found effective guideline to construct. In this research, we focus on within-class variance of SVM histogram proposed in our previous work [8]. We try to apply it as a clue for modifying the architecture of a DCNN, and confirm the modified DCNN shows better performance than that of the original one.	convolutional neural network	Satoshi Suzuki;Hayaru Shouno	2016		10.1007/978-3-319-46675-0_59	machine learning;time delay neural network;deep learning;convolutional neural network	AI	24.38665732351242	-53.371977051997796	44848
8ef3fb775d0d5dfdd277114a5f620abcb22aaf94	ensembl 2005		The Ensembl (http://www.ensembl.org/) project provides a comprehensive and integrated source of annotation of large genome sequences. Over the last year the number of genomes available from the Ensembl site has increased by 7 to 16, with the addition of the six vertebrate genomes of chimpanzee, dog, cow, chicken, tetraodon and frog and the insect genome of honeybee. The majority have been annotated automatically using the Ensembl gene build system, showing its flexibility to reliably annotate a wide variety of genomes. With the increased number of vertebrate genomes, the comparative analysis provided to users has been greatly improved, with new website interfaces allowing annotation of different genomes to be directly compared. The Ensembl software system is being increasingly widely reused in different projects showing the benefits of a completely open approach to software development and distribution.	annotation;anura;apis mellifera;build automation;chickens;ensembl;genome;genome, insect;pan troglodytes;qualitative comparative analysis;software development;software system;tetraodon;web site;benefit	Tim J. P. Hubbard;D. Andrews;Mario Cáccamo;Graham Cameron;Yuan Chen;Michele E. Clamp;Laura Clarke;Guy Coates;Antony Cox;Fiona Cunningham;Val Curwen;Tim Cutts;Thomas A. Down;Richard Durbin;Xosé M. Fernández-Suárez;James G. R. Gilbert;Martin Hammond;Javier Herrero;H. Hotz;Kevin L. Howe;Vivek Iyer	2005	Nucleic Acids Research	10.1093/nar/gki138		Comp.	-1.2538249276665527	-56.95688984827477	44850
00d71fdefb06f098a939a68ae5f38064adbd883e	the post-genomic era of biological network alignment	signal image and speech processing;systems biology;computational biology bioinformatics;biomedical engineering	Biological network alignment aims to find regions of topological and functional (dis)similarities between molecular networks of different species. Then, network alignment can guide the transfer of biological knowledge from well-studied model species to less well-studied species between conserved (aligned) network regions, thus complementing valuable insights that have already been provided by genomic sequence alignment. Here, we review computational challenges behind the network alignment problem, existing approaches for solving the problem, ways of evaluating their alignment quality, and the approaches' biomedical applications. We discuss recent innovative efforts of improving the existing view of network alignment. We conclude with open research questions in comparative biological network research that could further our understanding of principles of life, evolution, disease, and therapeutics.	biological network;open research;sequence alignment	Fazle Elahi Faisal;Lei Meng;Joseph Crawford;Tijana Milenkovi&#x0107;	2015		10.1186/s13637-015-0022-9	computational biology;biology;computer science;bioinformatics;data science;biological engineering;systems biology	Comp.	-1.4526380937990075	-66.3081356572959	44873
19510fb0cddc084118316566a9237a230a576427	similarity searching in databases of flexible 3d structures using smoothed bounded distance matrices	3d structure;similarity search	This paper describes a method for calculating the similarity between pairs of chemical structures represented by 3D molecular graphs. The method is based on a graph matching procedure that accommodates conformational flexibility by using distance ranges between pairs of atoms, rather than fixing the atom pair distances. These distance ranges are generated using triangle and tetrangle bound smoothing techniques from distance geometry. The effectiveness of the proposed method in retrieving other compounds of like biological activity is evaluated, and the results are compared with those obtained from other, 2D-based methods for similarity searching.	2d computer graphics;databases;distance;graph - visual representation;matching (graph theory);molecular graph;smoothing (statistical technique)	John W. Raymond;Peter Willett	2003	Journal of chemical information and computer sciences	10.1021/ci034002p	combinatorics;discrete mathematics;chemistry;topology;computer science;machine learning;normalized compression distance;mathematics;nearest neighbor search;similarity;jaro–winkler distance	Visualization	13.985746053772806	-58.123708320572355	44885
80a97ac78f757a4ef4874e8914f783fe1725d6c2	mandala: a reconfigurable vr environment for studying spatial navigation in humans using eeg		This paper describes a reconfigurable VR environment and a markup language for creating experiments aimed at understanding human spatial navigation. It permits the creation of high-quality virtual environments and the recording of behavioral and brain activity measures while observers navigate these environments. The system is used in studies where the electroencephalographic activity is recorded while observers navigate virtual environments. The results of the study reported here confirmed previous finding that theta oscillations (electroencephalographic activity in the 4-8 Hz band) are linked to the difficulty of spatial navigation. Further, it showed that this activity is likely to occur at points where new rooms come into view, or after navigational mistakes have been realized and are being corrected. This indicates that theta oscillations in humans are related to the encoding and retrieval of spatial information.	electroencephalography;experiment;humans;markup language;neural oscillation;spatial navigation;virtual reality	Pierre Boulanger;Daniel Torres;Walter F. Bischof	2004		10.2312/EGVE/EGVE04/061-070	computer vision;simulation;computer science;communication	HCI	-3.9273423688413733	-78.36337187832464	44926
54fc77b3b3f8ed657437c4048fa6fffea6495b30	a survey of recent developments in theoretical neuroscience and machine vision	unsupervised learning;cognition neuroscience machine vision human vision animal vision unsupervised learning method independent components analysis predictive perceptual model spatial statistical structure temporal statistical structure mammalian visual cortex invariance hierarchical analysis;independent component analysis;computer vision;machine vision;neuroscience machine vision image analysis humans layout organisms animals independent component analysis brain modeling predictive models;cognition;visual perception;neurophysiology;cognition computer vision unsupervised learning independent component analysis visual perception neurophysiology;analysis of covariance;visual cortex	Efforts to explain human and animal vision, and to automate visual function in machines, have found it difficult to account for the view-invariant perception of universals such as environmental objects or processes, and the explicit perception of featural parts and wholes in visual scenes. A handful of unsupservised learning methods, many of which relate directly to independent components analysis (ICA), have been used to make predictive perceptual models of the spatial and temporal statistical structure in natural visual scenes, and to develop principled explanations for several important properties of the architecture and dynamics of mammalian visual cortex. Emerging principles include a new understanding of invariances and part-whole compositions in terms of the hierarchical analysis of covariation in feature subspaces, reminiscent of the processing across layers and areas of visual cortex, and the analysis of view manifolds, which relate to the topologically ordered feature maps in cortex.	computational neuroscience;independent computing architecture;independent component analysis;machine vision;map	Jeffrey B. Colombe	2003		10.1109/AIPR.2003.1284273	computer vision;visual perception;computer science;artificial intelligence;machine learning;human visual system model	ML	21.217896206722912	-67.11399463471174	44937
a5b88f273607daefaa2aec636957078616cbe099	strategies for comparing metabolic profiles: implications for the inference of biochemical mechanisms from metabolomics data	metabolomics diseases biochemistry cancer data mining;purine metabolism cancer mechanisms computational systems biology distance based metrics metabolomics pathway analysis	Background: Large amounts of metabolomics data have been accumulated in recent years and await analysis. Previously, we had developed a systems biology approach to infer biochemical mechanisms underlying metabolic alterations observed in cancers and other diseases. The method utilized the typical Euclidean distance for comparing metabolic profiles. Here, we ask whether any of the numerous alternative metrics might serve this purpose better. Methods and Findings: We used enzymatic alterations in purine metabolism that were measured in human renal cell carcinoma to test various metrics with the goal of identifying the best metrics for discerning metabolic profiles of healthy and diseased individuals. The results showed that several metrics have similarly good performance, but that some are unsuited for comparisons of metabolic profiles. Furthermore, the results suggest that relative changes in metabolite levels, which reduce bias toward large metabolite concentrations, are better suited for comparisons of metabolic profiles than absolute changes. Finally, we demonstrate that a sequential search for enzymatic alterations, ranked by importance, is not always valid. Conclusions: We identified metrics that are appropriate for comparisons of metabolic profiles. In addition, we constructed strategic guidelines for the algorithmic identification of biochemical mechanisms from metabolomics data.	brain diseases, metabolic;computer performance;epithelial cell of renal tubule;euclidean distance;inference;linear search;malignant neoplasms;metabolic process, cellular;metabolic profile;metabolomics;purines;renal cell carcinoma;systems biology	Zhen Qi;Eberhard O. Voit	2017	IEEE/ACM Transactions on Computational Biology and Bioinformatics	10.1109/TCBB.2016.2586065	computational biology;biology;toxicology;computer science;bioinformatics	Comp.	7.253139956125546	-57.59722855307042	44939
caf8df6695813d51ec56db34b486d2ab550ed02c	emergence of oriented cell assemblies associated with spike-timing-dependent plasticity	spike timing dependent plasticity;espiga positiva;feed forward;time dependent;interconnection;sistema temporizado;integrate and fire;simulation;timed system;spike time dependent plasticity;simulacion;random networks;pointe positive;interconexion;spike;sinapsis;synaptic plasticity;interconnexion;systeme temporise;plasticite synaptique;reseau neuronal;plasticidad sinaptica;red neuronal;neural network;synapse	We studied the emergence of cell assemblies out of a locally connected random network of 10,000 integrate-and-fire units distributed on a 100×100 2D lattice. The network was composed of 80% excitatory and 20% inhibitory units with balanced excitatory/inhibitory synaptic weights. Excitatory–excitatory synapses were modified according to a spike-timing-dependent synaptic plasticity (STDP) rule associated with synaptic pruning. In presence of a stimulus and with independent random background noise (5 spikes/s), we observed that after 5 · 10 ms of simulated time, about 8% of the exc–exc connections remained active and were reinforced with respect to the initial strength. The projections that remained active after pruning tended to be oriented following a feed-forward converging–diverging pattern. This result suggests that topologies compatible with synfire chains may appear during unsupervised pruning processes.	biological neuron model;exc code;emergence;hebbian theory;markov chain;random graph;synaptic package manager	Javier Iglesias;Jan Eriksson;Beatriz Pardo;Marco Tomassini;Alessandro E. P. Villa	2005		10.1007/11550822_21	synaptic plasticity;computer science;synapse;artificial intelligence;interconnection;machine learning;spike-timing-dependent plasticity;feed forward;artificial neural network	ML	20.15424631930783	-70.4159484792316	45014
1b29b008e3878df56c1cab4f917856d3bcf714c3	seqatoms: a web tool for identifying missing regions in pdb in sequence context	software;protein sequence;amino acid sequence;catheterization;article letter to editor;protein structure;internet;protein structure tertiary;macromolecule;sequence alignment;basic local alignment search tool;protein data bank;similarity search;sequence analysis protein;databases protein;bioinformatics	With over 46 000 proteins, the Protein Data Bank (PDB) is the most important database with structural information of biological macromolecules. PDB files contain sequence and coordinate information. Residues present in the sequence can be absent from the coordinate section, which means their position in space is unknown. Similarity searches are routinely carried out against sequences taken from PDB SEQRES. However, there no distinction is made between residues that have a known or unknown position in the 3D protein structure. We present a FASTA sequence database that is produced by combining the sequence and coordinate information. All residues absent from the PDB coordinate section are masked with lower-case letters, thereby providing a view of these residues in the context of the entire protein sequence, which facilitates inspecting 'missing' regions. We also provide a masked version of the CATH domain database. A user-friendly BLAST interface is available for similarity searching. In contrast to standard (stand-alone) BLAST output, which only contains upper-case letters, our output retains the lower-case letters of the masked regions. Thus, our server can be used to perform BLAST searching case-sensitively. Here, we have applied it to the study of missing regions in their sequence context. SEQATOMS is available at http://www.bioinformatics.nl/tools/seqatoms/.	amino acid sequence;blast;bioperl;biological science disciplines;biotechnology;blinded;cath;crystallographic information file;fasta;html;keyword;kramer graph;nar 2;protein data bank;protein, organized by structure;sequence database;server (computer);server (computing);similarity search;thrombocytopenia;usability;web server;windows update;xml;macromolecule	Bernd Willem Brandt;Jaap Heringa;Jack A. M. Leunissen	2008		10.1093/nar/gkn237	macromolecule;biology;protein structure;the internet;sequence profiling tool;protein data bank;bioinformatics;protein sequencing;sequence alignment;peptide sequence	Comp.	-1.9378896099887282	-60.33727596518794	45017
8a5af02bc6327032e9cea674345f71b5546bf803	bioesonet: a tool for the generation of personalized human metabolic pathways from 23andme exome data.		The lowering of costs of whole exome sequencing (WES) services registered in the last two years has greatly increased the demand for managing different metabolic diseases, including autism spectrum disorders (ASD). WES allows the detection of a large part of exome single nucleotide polymorphisms (SNPs), whose expression can be in some cases modulated by epigenetics, life style and microbioma changes. However, such raw data usually needs to be manipulated in order to allow useful interpretation and analysis. We present BIOESOnet, a tool for the filtering and visualization of exome 23andMe raw data into a customized methylation pathway. The tool, available at: http://www.bionumeri.org/joomla/restricted-area/onecarbon-tool, enables a fast and extensive overview of possible mutations inside an extended metabolic pathway.		Marzio Pennisi;Gabriele Forzano;Giulia Russo;Barbara Tomasello;Marco Favetta;Marcella Renis;Francesco Pappalardo	2018		10.1007/978-3-319-95933-7_42	raw data;exome sequencing;artificial intelligence;single-nucleotide polymorphism;pattern recognition;computer science;autism;epigenetics;exome;bioinformatics	HCI	-2.9110497906102624	-58.81496364935421	45018
cec86009a5242cbb33a5f5ec24bf77e44791630f	using network context as a filter for mirna target prediction	protein protein interaction network;microrna target prediction;network topology;microrna	Recent discoveries in genetics show that gene expression in igher eukaryotes is regulated in part by small non-coding RNA olecules named microRNAs (miRNAs) (Ambros, 2004; Bartel, 004; Lim et al., 2003). In plants, miRNAs regulate protein xpression by binding to the coding region of the corresponding essenger RNA (mRNA). Plant miRNAs exhibit near-perfect comlementarity with the target sites. In animals, miRNAs usually bind o the 3′ untranslated region (UTR) of the target mRNA and have nly limited complementarity to their target sites (Bartel, 2004). miRNAs are involved in many important cellular processes (Cui t al., 2006) and their dysregulation is related to anomalies such s cancer (He et al., 2005) and heart diseases (Carè et al., 2007; hao et al., 2007). In recent years, several thousand miRNAs were dentified in animals and plants. As of June 2010, miRBase release 15 Griffiths-Jones et al., 2008) contains 14,197 distinct mature miRNA equences. Current major challenges in miRNA research are: (1) identificaion of novel miRNA genes, (2) functional annotation of miRNAs, (3) dentification of genes targeted by miRNAs,1 and (4) high throughut experimental validation of miRNA-target interactions. In this tudy, we focus on the problem of identifying mRNAs targeted by uman miRNAs.	annotation;complementarity theory;dvd region code;expanded memory;gene expression;heart diseases;interaction;jones calculus;micrornas;name binding;non-small cell lung carcinoma;open reading frames;rna;rna, untranslated;untranslated regions;mirbase	M. Sualp;T. Can	2011	Bio Systems	10.1016/j.biosystems.2011.04.002	biology;computer science;bioinformatics;genetics;network topology;microrna	Comp.	3.0319847376808573	-60.707610838470025	45033
bc22c97fe4ec2caeffbc4af1131d632256a48ca7	improving disease prediction using icd-9 ontological features	nhanes database;medical diagnoses;diagnostic imaging;health reporting evaluation;support vector machines;svm disease prediction icd 9 similarity measure ontological features random forest;health insurance;health cost evaluation;disease prediction;diabetes;atherosclerosis;hypertension;fuzzy set theory;ontologies artificial intelligence;medical computing;icd 9 similarity measure;mds database;radio frequency;roc curve disease prediction icd 9 ontological features health insurance tailored health communication public health hcup database nhanes database mds database health reporting evaluation health cost evaluation medical diagnoses diagnose related groups patient diagnoses fuzzy membership features diabetes atherosclerosis hypertension random forest svm;feature extraction;random forest;diagnose related groups;health communication;roc curve;diseases;hcup database;ontological features;svm;patient diagnoses;diseases support vector machines diabetes medical diagnostic imaging radio frequency feature extraction hypertension;support vector machine;tailored health communication;fuzzy membership features;icd 9 ontological features;similarity measure;support vector machines diseases fuzzy set theory health care medical computing ontologies artificial intelligence;public health;medical diagnostic imaging;health care	Disease prediction has become important in a variety of applications such as health insurance, tailored health communication and public health. Disease prediction is usually performed using publically available datasets such as HCUP, NHANES or MDS that were initially designed for health reporting or health cost evaluation but not for disease prediction. In these datasets, medical diagnoses are traditionally arranged in “diagnose-related groups” (DRGs). In this paper we compare the disease prediction based on crisp DRG features with the results obtained employing a new set of features that consist of the fuzzy membership of patient diagnoses in the DRG groups. The fuzzy membership features were computed using an ICD-9 ontological similarity approach. The prediction results obtained on a subset of 9,000 patients from the 2005 HCUP data representing three diseases (diabetes, atherosclerosis and hypertension) using two classifiers (random forest and SVM trained on 21,000 samples) show significant (about 10%) improvement as measured by the area under the ROC curve (AROC).	algorithm;code;digital raster graphic;feature extraction;radio frequency;random forest;receiver operating characteristic;support vector machine	Mihail Popescu;Mohammad Khalilia	2011	2011 IEEE International Conference on Fuzzy Systems (FUZZ-IEEE 2011)	10.1109/FUZZY.2011.6007410	support vector machine;public health;computer science;bioinformatics;data science;machine learning;data mining	Robotics	7.21912508708782	-77.769571352509	45118
45f8bbe1485d6fc26c5c9d4f1a3326b591d2868f	cycml-a language to describe radiological images	radiology;biomedical imaging;medical image processing;computer language medical knowledge radiological images medical experts cyclops medical language diagnostic process human language;languages;languages diagnostic radiography radiology medical image processing;diagnostic radiography	This work considers a methodology to represent medical knowledge about radiological images in order to support medical experts in the interpretation of such images. For this reason they need to express their knowledge in such a way that it can be accessed by the computer. For this purpose a medical language is created that has several levels in order to bridge the gap between computer and human language. Some discussion about validation takes place.	radiology	Eros Comunello;Michael M. Richter;Daniel Duarte Abdala;Thiago R. dos Santos;Aldo von Wangenheim;Paulo Roberto Wille	2003	16th IEEE Symposium Computer-Based Medical Systems, 2003. Proceedings.	10.1109/CBMS.2003.1212780	medical imaging;computer vision;radiology;computer science;multimedia;language;medical physics	Visualization	-0.09635634725098062	-77.60430770450985	45122
6c906acbb0e52a59bf74a4a67fdd042fc45dd54b	neuronal algorithms that detect the temporal order of events	modele hassenstein reichardt;calcul neuronal;inhibicion;neural computation;sensory processing;algorithmique;comportement;multiplication operator;modelo multiplicativo;excitation of sensor;neuronal algorithm;modele multiplicatif;multiplicative model;conducta;algorithmics;algoritmica;retina;excitation capteur;retine;bipolar cell;inhibition;discrepance;reseau neuronal;behavior;algorithme neuronal;temporal order;logic gate;red neuronal;computacion neuronal;ordre temporel;neural network;hassenstein reichardt model	One of the basic operations in sensory processing is the computation of the temporal order of excitation of sensors. Motivated by the discrepancy between models and experiments at high signal contrast, we obtain families of algorithms by solutions of a general set of equations that define temporal order detection as an input-to-output relationship. Delays and nonlinear operations are the basis of all algorithms found, but different algorithmic structures exist when the operations are multiplications, OR gates, different types of AND-NOT logical gates, or concatenated ANDNOT gates. Among others, we obtain the Hassenstein-Reichardt model, a network using a multiplicative operation that has been proposed to explain fly optomotor behavior. We also find extensions of the Barlow-Levick model (based on an AND-NOT gate with delayed inhibition and nondelayed excitation as inputs), originally proposed to explain the bipolar cell response of the rabbit retina to motion stimuli. In the extended models, there are two more steps, another AND-NOT gate, and a subtraction or two subtractions that make the model responsive only to motion. In response to low-contrast inputs, the concatenated AND-NOT gates or the AND-NOT gate followed by a subtraction in these new models act as the multiplicative operation in the Hassenstein-Reichardt model. At high contrast, the new models behave like the Hassenstein-Reichardt model except that they are independent of contrast as observed experimentally.	algorithm;computation;concatenation;discrepancy function;experiment;inverter (logic gate);nor gate;nonlinear system;sensor	Gonzalo G. de Polavieja	2006	Neural Computation	10.1162/neco.2006.18.9.2102	multiplication operator;logic gate;computer science;artificial intelligence;machine learning;mathematics;algorithmics;artificial neural network;algorithm;behavior	ML	20.879444262614452	-70.28906246014267	45145
dcbafb1e306f2c1836e35978d1cb97dfb07327ea	forest-based point process for event prediction from electronic health records		Accurate prediction of future onset of disease from Electronic Health Records (EHRs) has important clinical and economic implications. In this domain the arrival of data comes at semi-irregular intervals and makes the prediction task challenging. We propose a method called multiplicative-forest point processes (MFPPs) that learns the rate of future events based on an event history. MFPPs join previous theory in multiplicative forest continuous-time Bayesian networks and piecewisecontinuous conditional intensity models. We analyze the advantages of using MFPPs over previous methods and show that on synthetic and real EHR forecasting of heart attacks, MFPPs outperform earlier methods and augment off-the-shelf machine learning algorithms.	algorithm;bayesian network;generative model;machine learning;mathematical model;onset (audio);point process;relevance;risk factor (computing);sampling (signal processing);semiconductor industry;synthetic intelligence	Jeremy C. Weiss;David Page	2013		10.1007/978-3-642-40994-3_35	simulation;computer science;artificial intelligence;machine learning;data mining;mathematics;statistics	ML	4.417449685664957	-74.68378624338779	45177
599835219574728228faf1f91fbdbdb33b596114	lab retriever: a software tool for calculating likelihood ratios incorporating a probability of drop-out for forensic dna profiles	dna;dna fingerprinting;computational biology bioinformatics;internet;likelihood functions;algorithms;humans;user computer interface;combinatorial libraries;computer appl in life sciences;forensic genetics;microarrays;bioinformatics	Technological advances have enabled the analysis of very small amounts of DNA in forensic cases. However, the DNA profiles from such evidence are frequently incomplete and can contain contributions from multiple individuals. The complexity of such samples confounds the assessment of the statistical weight of such evidence. One approach to account for this uncertainty is to use a likelihood ratio framework to compare the probability of the evidence profile under different scenarios. While researchers favor the likelihood ratio framework, few open-source software solutions with a graphical user interface implementing these calculations are available for practicing forensic scientists. To address this need, we developed Lab Retriever, an open-source, freely available program that forensic scientists can use to calculate likelihood ratios for complex DNA profiles. Lab Retriever adds a graphical user interface, written primarily in JavaScript, on top of a C++ implementation of the previously published R code of Balding. We redesigned parts of the original Balding algorithm to improve computational speed. In addition to incorporating a probability of allelic drop-out and other critical parameters, Lab Retriever computes likelihood ratios for hypotheses that can include up to four unknown contributors to a mixed sample. These computations are completed nearly instantaneously on a modern PC or Mac computer. Lab Retriever provides a practical software solution to forensic scientists who wish to assess the statistical weight of evidence for complex DNA profiles. Executable versions of the program are freely available for Mac OSX and Windows operating systems.	algorithm;c++;computation;dna profiling;executable;graphical user interface;javascript;microsoft windows;open-source software;operating system;personal computer;programming tool;r language;scientific publication;solutions;user interface device component;version;likelihood ratio;macos	Keith Inman;Norah Rudin;Ken Cheng;Chris Robinson;Adam Kirschner;Luke Inman-Semerau;Kirk E. Lohmueller	2015		10.1186/s12859-015-0740-8	biology;dna profiling;the internet;dna microarray;computer science;bioinformatics;data science;genetics;dna	Comp.	2.7729333253177626	-53.67969259498638	45229
cf051e82d99390d2be7efb4c0010dfa755247121	knowledge extraction from transducer neural networks	analysis of connectionist learning;symbolic interpretation;neural network learning;knowledge extraction;network analysis;srn networks;recurrent network;principal component analysis;networked learning;recurrent neural network;hierarchical cluster analysis;neural network	Previously neural networks have shown interesting performance results for tasks such as classification, but they still suffer from an insufficient focus on the structure of the knowledge represented therein. In this paper, we analyze various knowledge extraction techniques in detail and we develop new transducer extraction techniques for the interpretation of recurrent neural network learning. First, we provide an overview of different possibilities to express structured knowledge using neural networks. Then, we analyze a type of recurrent network rigorously, applying a broad range of different techniques. We argue that analysis techniques, such as weight analysis using Hinton diagrams, hierarchical cluster analysis, and principal component analysis may be useful for providing certain views on the underlying knowledge. However, we demonstrate that these techniques are too static and too low-level for interpreting recurrent network classifications. The contribution of this paper is a particularly broad analysis of knowledge extraction techniques. Furthermore, we propose dynamic learning analysis and transducer extraction as two new dynamic interpretation techniques. Dynamic learning analysis provides a better understanding of how the network learns, while transducer extraction provides a better understanding of what the network represents.	cluster analysis;diagram;hierarchical clustering;high- and low-level;neural networks;principal component analysis;recurrent neural network;transducer	Stefan Wermter	2000	Applied Intelligence	10.1023/A:1008320219610	organizational network analysis;nervous system network models;network analysis;computer science;dynamic network analysis;artificial intelligence;recurrent neural network;machine learning;data mining;time delay neural network;hierarchical clustering;deep learning;knowledge extraction;artificial neural network;principal component analysis	AI	20.86185641846378	-53.999784650944335	45234
e439af84661b114e55f3aeaed3006259b51ff9a4	hematopoietic stem cell and fibroblast proliferation following platelet electrostimulation		The increasing use of activated platelet rich plasma (PRP), or platelet gel, for wound healing has highlighted the disadvantages of using bovine thrombin (BT), an animal derived platelet activator, including high cost and antibody stimulation. This has motivated the exploration of direct (conductive coupling) and indirect (capacitive coupling) electrostimulation for ex vivo PRP activation to similar levels as BT in terms of growth factor release. PRP is a complex biological matrix comprising other blood cell types besides platelets. This paper assesses the impact of electrostimulation on other blood cells, specifically hematopoietic stem cells and fibroblasts. Capacitive coupling induces similar levels of cell viability and proliferation as BT 14 days following electrostimulation, while conductive coupling induces lower viability and proliferation. This indicates the potential tunability of electrostimulation to achieve equivalent efficacy as BT without the associated disadvantages and motivates future experiments to assess the implications on in vivo wound healing.	bovine metabolome database;direct coupling;experiment;parallel redundancy protocol;plasma active;video-in video-out	Jason Castle;Allen L. Garner;Reginald D. Smith;Brian M. Davis;Steve Klopman;Sean R. Dinn;Andrew S. Torres;Vasile Bogdan Neculaes	2018	IEEE Access	10.1109/ACCESS.2018.2872930	growth factor;computer science;hematopoietic stem cell;platelet-rich plasma;viability assay;cell biology;stem cell;ex vivo;distributed computing;fibroblast;wound healing	Visualization	10.92422872943068	-65.87025180693388	45244
54fc1e7aac1898e090f0ef1c00c200838bf4f580	arabidopsis defense response against pseudomonas syringae - effects of major regulatory genes and the impact of coronatine	arabidopsis disease resistance;genomics;salicylic acid;regulatory genes;arabidopsis defense response;transcriptome analysis;data mining;genetics;gene expression;plants biology;proteins;pathogens immune system proteins microorganisms plants biology regulators diseases production genomics bioinformatics;molecular biophysics;innate immunity;immune system;pseudomonas syringae;diseases;production;bacterial pathogen;disease resistance;transcriptional profiling;molecular biophysics diseases genetics;jasmonates sector;microorganisms;jasmonates sector arabidopsis defense response pseudomonas syringae regulatory genes coronatine bacterial pathogen transcriptome analysis arabidopsis disease resistance salicylic acid sector;regulators;salicylic acid sector;bioinformatics;coronatine;pathogens	Arabidopsis defense response against the bacterial pathogen, Pseudomonas syringae, is a complex and highly regulated process. Previous studies have identified many critical genes encoding regulators that govern innate immunity, but comprehensive transcriptome analysis of corresponding mutants is lacking. Using a custom microarray, we profiled the transcriptome of many mutants with mutations in critical regulatory genes affecting Arabidopsis disease resistance. We show that previously identified mutants affecting the salicylic acid (SA) sector of the defense network have similar transcriptional profiles. Surprisingly, jin1, jar1 and dde2 that are involved in jasmonates (JA) sector did not show major transcriptome changes, while coi1 did. Further analysis revealed that the phytotoxin, coronatine, secreted by P. syringae, is responsible for nearly all COI1-mediated responses.	acid;microarray	Lin Wang;Fumiaki Katagiri;Jane Glazebrook	2009	2009 IEEE International Workshop on Genomic Signal Processing and Statistics	10.1109/GENSIPS.2009.5174327	biology;genomics;botany;gene expression;immune system;transcriptome;biotechnology;regulator gene;microorganism;innate immune system;microbiology;genetics;molecular biophysics	Comp.	4.980182969768253	-61.93643007088882	45250
5e1ecadab6802dc99bc7a3810ed25585dfdafa53	kvfinder: steered identification of protein cavities as a pymol plugin	software;ligands;binding sites;computational biology bioinformatics;models molecular;proteins;protein structure tertiary;protein binding;algorithms;combinatorial libraries;computational biology;computer appl in life sciences;microarrays;bioinformatics	The characterization of protein binding sites is a major challenge in computational biology. Proteins interact with a wide variety of molecules and understanding of such complex interactions is essential to gain deeper knowledge of protein function. Shape complementarity is known to be important in determining protein-ligand interactions. Furthermore, these protein structural features have been shown to be useful in assisting medicinal chemists during lead discovery and optimization. We developed KVFinder, a highly versatile and easy-to-use tool for cavity prospection and spatial characterization. KVFinder is a geometry-based method that has an innovative customization of the search space. This feature provides the possibility of cavity segmentation, which alongside with the large set of customizable parameters, allows detailed cavity analyses. Although the main focus of KVFinder is the steered prospection of cavities, we tested it against a benchmark dataset of 198 known drug targets in order to validate our software and compare it with some of the largely accepted methods. Using the one click mode, we performed better than most of the other methods, staying behind only of hybrid prospection methods. When using just one of KVFinder’s customizable features, we were able to outperform all other compared methods. KVFinder is also user friendly, as it is available as a PyMOL plugin, or command-line version. KVFinder presents novel usability features, granting full customizable and highly detailed cavity prospection on proteins, alongside with a friendly graphical interface. KVFinder is freely available on http://lnbio.cnpem.br/bioinformatics/main/software/ .	1-click;benchmark (computing);binding sites;bioinformatics;body cavities;command-line interface;complementarity theory;computational biology;dental caries;drug delivery systems;graphical user interface;interaction;interface device component;ligands;mathematical optimization;plug-in (computing);protein binding;pymol;silo (dataset);usability	Saulo H. P. Oliveira;Felipe A. N. Ferraz;Rodrigo V. Honorato;José Xavier-Neto;Tiago Jose Paschoal Sobreira;Paulo S. L. de Oliveira	2014		10.1186/1471-2105-15-197	biology;plasma protein binding;dna microarray;computer science;bioinformatics;binding site;ligand	Comp.	10.11857899827953	-59.18920616198979	45263
79f7b352010584cc0ed153f94d48ddd6be858dbd	minimus: a fast, lightweight genome assembler	dna;genes;software;genome assembly;chromosome mapping;bac clones;sequence analysis dna;genome sequencing;computational biology bioinformatics;bacterial genomes;software component;modular design;algorithms;viral genomes;minimus;molecular sequence data;sequence alignment;amos;user computer interface;bacterial genome;combinatorial libraries;software design;base sequence;computer appl in life sciences;article;genome sequence;open source software;microarrays;bioinformatics	Genome assemblers have grown very large and complex in response to the need for algorithms to handle the challenges of large whole-genome sequencing projects. Many of the most common uses of assemblers, however, are best served by a simpler type of assembler that requires fewer software components, uses less memory, and is far easier to install and run. We have developed the Minimus assembler to address these issues, and tested it on a range of assembly problems. We show that Minimus performs well on several small assembly tasks, including the assembly of viral genomes, individual genes, and BAC clones. In addition, we evaluate Minimus' performance in assembling bacterial genomes in order to assess its suitability as a component of a larger assembly pipeline. We show that, unlike other software currently used for these tasks, Minimus produces significantly fewer assembly errors, at the cost of generating a more fragmented assembly. We find that for small genomes and other small assembly tasks, Minimus is faster and far more flexible than existing tools. Due to its small size and modular design Minimus is perfectly suited to be a component of complex assembly pipelines. Minimus is released as an open-source software project and the code is available as part of the AMOS project at Sourceforge.	amos;algorithm;assembly language;bacterial artificial chromosomes;batman: arkham city;component-based software engineering;ethanol 0.62 ml/ml topical gel;large;modular design;open-source software;pipeline (computing);software project management;sourceforge;viral genome;whole genome sequencing	Daniel D. Sommer;Arthur L. Delcher;Steven L Salzberg;Mihai Pop	2006	BMC Bioinformatics	10.1186/1471-2105-8-64	biology;bioinformatics;software design;sequence alignment;modular design;genetics;dna;bacterial genome size	Networks	-1.1830737306788828	-56.65880300428108	45297
ea28e15647288d5a3064ed2473752061e46e8ddd	identifying microphone from noisy recordings by using representative instance one class-classification approach	microphones;microphone forensics;one class classification;0801 artificial intelligence and image processing;data mining;machine learning;college of science and engineering;audio forensics	Rapid growth of technical developments has created huge challenges for microphone forensics a subcategory of audio forensic science, because of the availability of numerous digital recording devices and massive amount of recording data. Demand for fast and efficient methods to assure integrity and authenticity of information is becoming more and more important in criminal investigation nowadays. Machine learning has emerged as an important technique to support audio analysis processes of microphone forensic practitioners. However, its application to real life situations using supervised learning is still facing great challenges due to expensiveness in collecting data and updating system. In this paper, we introduce a new machine learning approach which is called One-class Classification (OCC) to be applied to microphone forensics; we demonstrate its capability on a corpus of audio samples collected from several microphones. In addition, we propose a representative instance classification framework (RICF) that can effectively improve performance of OCC algorithms for recording signal with noise. Experiment results and analysis indicate that OCC has the potential to benefit microphone forensic practitioners in developing new tools and techniques for effective and efficient analysis.	algorithm;digital recording;machine learning;microphone;noise (electronics);one-class classification;optimistic concurrency control;real life;sensor;supervised learning	Huy Quan Vu;Shaowu Liu;Xinghua Yang;Zhi Li;Yongli Ren	2012	JNW	10.4304/jnw.7.6.908-917	embedded system;speech recognition;telecommunications;computer science;data science;machine learning;data mining;world wide web;computer security;one-class classification	ML	21.586014965804456	-58.136138577105214	45333
0ba6732bea0d107407278698bb17221fb84b91d5	maximization of learning speed in the motor cortex due to neuronal redundancy	muscle activity;learning;activation function;motor cortex;generating function;neurons;neural network model;impedance control;neural networks computer;motor learning;motor control	Many redundancies play functional roles in motor control and motor learning. For example, kinematic and muscle redundancies contribute to stabilizing posture and impedance control, respectively. Another redundancy is the number of neurons themselves; there are overwhelmingly more neurons than muscles, and many combinations of neural activation can generate identical muscle activity. The functional roles of this neuronal redundancy remains unknown. Analysis of a redundant neural network model makes it possible to investigate these functional roles while varying the number of model neurons and holding constant the number of output units. Our analysis reveals that learning speed reaches its maximum value if and only if the model includes sufficient neuronal redundancy. This analytical result does not depend on whether the distribution of the preferred direction is uniform or a skewed bimodal, both of which have been reported in neurophysiological studies. Neuronal redundancy maximizes learning speed, even if the neural network model includes recurrent connections, a nonlinear activation function, or nonlinear muscle units. Furthermore, our results do not rely on the shape of the generalization function. The results of this study suggest that one of the functional roles of neuronal redundancy is to maximize learning speed.	activation function;artificial neural network;body position;cerebral cortex;characteristic impedance;cyclic redundancy check;expectation–maximization algorithm;generalization (psychology);kinematics;muscle;network model;neural oscillation;neuron;nonlinear system;poor posture;redundancy (engineering);redundancy (information theory);sensorimotor cortex	Ken Takiyama;Masato Okada	2012		10.1371/journal.pcbi.1002348	motor control;generating function;motor learning;computer science;artificial intelligence;machine learning;activation function;artificial neural network	ML	17.49856368493023	-74.24099118402495	45337
9dc697a3a63acbbfc7be22622fe5c384dc21e99c	sciapps: a cloud-based platform for reproducible bioinformatics workflows		Motivation The rapid accumulation of both sequence and phenotype data generated by high-throughput methods has increased the need to store and analyze data on distributed storage and computing systems. Efficient data management across these heterogeneous systems requires a workflow management system to simplify the task of analysis through automation and make large-scale bioinformatics analyses accessible and reproducible.   Results We developed SciApps, a web-based platform for reproducible bioinformatics workflows. The platform is designed to automate the execution of modular Agave apps and support execution of workflows on local clusters or in a cloud. Two workflows, one for association and one for annotation, are provided as exemplar scientific use cases.   Availability and implementation https://www.sciapps.org.   Supplementary information Supplementary data are available at Bioinformatics online.	bioinformatics;cloud computing;clustered file system;data management;genetic heterogeneity;geographic information systems;high-throughput computing;throughput;tree accumulation;web application	Liya Wang;Zhenyuan Lu;Peter Van Buren;Doreen Ware	2018		10.1093/bioinformatics/bty439	workflow management system;data mining;data management;computer science;cloud computing;use case;workflow;distributed data store;modular design;bioinformatics;annotation	HPC	-1.7479272483944628	-57.583087413138344	45339
f9ff1b75c03a497310809eccee0c2a3f26851116	a study on the application of topic models to motif finding algorithms	computational biology bioinformatics;algorithms;computer appl in life sciences;microarrays;bioinformatics	Topic models are statistical algorithms which try to discover the structure of a set of documents according to the abstract topics contained in them. Here we try to apply this approach to the discovery of the structure of the transcription factor binding sites (TFBS) contained in a set of biological sequences, which is a fundamental problem in molecular biology research for the understanding of transcriptional regulation. Here we present two methods that make use of topic models for motif finding. First, we developed an algorithm in which first a set of biological sequences are treated as text documents, and the k-mers contained in them as words, to then build a correlated topic model (CTM) and iteratively reduce its perplexity. We also used the perplexity measurement of CTMs to improve our previous algorithm based on a genetic algorithm and several statistical coefficients. The algorithms were tested with 56 data sets from four different species and compared to 14 other methods by the use of several coefficients both at nucleotide and site level. The results of our first approach showed a performance comparable to the other methods studied, especially at site level and in sensitivity scores, in which it scored better than any of the 14 existing tools. In the case of our previous algorithm, the new approach with the addition of the perplexity measurement clearly outperformed all of the other methods in sensitivity, both at nucleotide and site level, and in overall performance at site level. The statistics obtained show that the performance of a motif finding method based on the use of a CTM is satisfying enough to conclude that the application of topic models is a valid method for developing motif finding algorithms. Moreover, the addition of topic models to a previously developed method dramatically increased its performance, suggesting that this combined algorithm can be a useful tool to successfully predict motifs in different kinds of sets of DNA sequences.	binding sites;cefotiam;coefficient;contain (action);dna binding site;genetic algorithm;k-mer;molecular biology;motif;nucleotides;perplexity;score;transcription factor;topic model;transcription (software);transcriptional regulation	Josep Basha Gutierrez;Kenta Nakai	2016		10.1186/s12859-016-1364-3	biology;dna microarray;computer science;bioinformatics;machine learning;data mining;algorithm	Comp.	2.8196396586892933	-55.21695061053294	45358
4560979eaa65fe8d7fc7684db4c101eba75102b0	functional segregation and integration within fronto-parietal networks	frontal parietal;meta analysis;superior longitudinal fasciculus;diffusion tractography;functional magnetic resonance imaging fmri	Experimental data on monkeys and functional studies in humans support the existence of a complex fronto-parietal system activating for cognitive and motor tasks, which may be anatomically supported by the superior longitudinal fasciculus (SLF). Advanced tractography methods have recently allowed the separation of the three branches of the SLF but are not suitable for their functional investigation. In order to gather comprehensive information about the functional organisation of these fronto-parietal connections, we used an innovative method, which combined tractography of the SLF in the largest dataset so far (129 participants) with 14 meta-analyses of functional magnetic resonance imaging (fMRI) studies. We found that frontal and parietal functions can be clustered into a dorsal spatial/motor network associated with the SLF I, and a ventral non-spatial/motor network associated with the SLF III. Further, all the investigated functions activated a middle network mostly associated with the SLF II. Our findings suggest that dorsal and ventral fronto-parietal networks are segregated but also share regions of activation, which may support flexible response properties or conscious processing. In sum, our novel combined approach provided novel findings on the functional organisation of fronto-parietal networks, and may be successfully applied to other brain connections.	dna integration;fascicle - nerve fibers;largest;magnetic resonance imaging;meta analysis (statistical procedure);monkeys;silo (dataset);structure of superior longitudinal fasciculus;fmri	Valeria Parlatini;Joaquim Radua;Flavio Dell'Acqua;Anoushka Leslie;Andy Simmons;Declan G. M. Murphy;Marco Catani;Michel Thiebaut de Schotten	2017		10.1016/j.neuroimage.2016.08.031	psychology;neuroscience;meta-analysis;developmental psychology;communication;statistics	ML	20.377044880103476	-77.89008877165095	45412
23498208a9aa5280b228ba3314e77b70a3e3efca	computational synteny block: a framework to identify evolutionary events	synteny blocks;genomics bioinformatics software yttrium;tandem repeats;duplications;software tools biology computing genetics genomics molecular biophysics proteins;breakpoints;repeats;computational synteny blocks;duplications synteny blocks breakpoints computational synteny blocks repeats tandem repeats;software behavior computational synteny block evolutionary events genomic rearrangements software tools precomputed nonconflicting high scoring pairs gene annotations protein level	Motivation: The identification and accurate description of large genomic rearrangements is crucial for the study of evolutionary events among species and implicitly defining breakpoints. Although there is a number of software tools available to perform this task, they usually either a) require a collection of pre-computed non-conflicting high-scoring segment pairs (HSPs) and gene annotations; or b) involve working at protein level (what excludes non-coding regions); or c) need many parameters to adjust the software behavior and performance; or d) imply working with duplications, repeats, and tandem repeats, which complicates the identification of rearrangements task. Although there are many programs specialized in the detection of these repetitions, they are not designed for the identification of main genomic rearrangements. Methods: The methodology we envisage starts with the detection of all HSPs by pairwise genome comparison. The second step involves solving conflicts generated by fragments that overlap in both sequences (doubleoverlapped fragments) to end yielding a collection of gapped fragments. In the third step, the quality measures (length, score, identities) of the gapped fragment are refined by using a modified dynamic programming approach. This collection of refined gapped fragments represents the input of a recursive process in which we identify blocks of gapped fragments that maintain co-localization, regardless of them occurring in coding or non-coding regions. The identification of repeats is an important step in the subsequent refinement of these blocks. This step allows for the separation of repeats and the correct identification in turn of longer blocks. Finally, groups of repeats, duplications, inversions and translocations are identified. Results: The set of algorithms presented in this manuscript is able to detect and identify blocks of large rearrangements-taking into account repeats, tandem repeats and duplications-starting with the simple collection of ungapped local alignments. To the best of our knowledge, this is the first method to approach the whole process as a coherent workflow-thus outperforming current state-of-the-art software tools-and additionally allowing to classify the type of rearrangement. The results obtained are an important source of information for breakpoints refinement and featuring, as well as for the estimation of the Evolutionary Events frequencies to be used in inter-genome distance proposals, etc. Data sets and Supplementary Material are available at: http://bitlab-es.com/gecko-csb/.	atrioventricular block;breakpoint;chromosomal translocation;chromosome inversion;coherence (physics);conflict (psychology);dna sequence rearrangement;dynamic programming;electronic supplementary materials;emoticon;gecko;gene annotation;graphic art software;information source;manuscripts;perseveration;precomputation;recursion;refinement (computing);score;sense of identity (observable entity);synteny;tandem repeat sequences;algorithm;quality measures	Jose A. Arjona-Medina;Oswaldo Trelles	2015	IEEE Transactions on NanoBioscience	10.1109/BIBM.2015.7359648	biology;computer science;bioinformatics;synteny;breakpoint;genetics;tandem repeat	Comp.	1.016555952978581	-55.68479273509479	45444
5270d78a11ca94724dc29a1c9ce889287a2c23ae	genome-wide survey for biologically functional pseudogenes	evolution molecular;animals;genomics;mice;bioinformatics and systems biology;bioinformatik och systembiologi;phylogeny;maximum likelihood;rna messenger;pseudogenes;conserved sequence;gene expression;likelihood functions;genome;pan troglodytes;humans;molecular sequence data;sequence alignment;spinocerebellar ataxia;base sequence;potential function	According to current estimates there exist about 20,000 pseudogenes in a mammalian genome. The vast majority of these are disabled and nonfunctional copies of protein-coding genes which, therefore, evolve neutrally. Recent findings that a Makorin1 pseudogene, residing on mouse Chromosome 5, is, indeed, in vivo vital and also evolutionarily preserved, encouraged us to conduct a genome-wide survey for other functional pseudogenes in human, mouse, and chimpanzee. We identify to our knowledge the first examples of conserved pseudogenes common to human and mouse, originating from one duplication predating the human-mouse species split and having evolved as pseudogenes since the species split. Functionality is one possible way to explain the apparently contradictory properties of such pseudogene pairs, i.e., high conservation and ancient origin. The hypothesis of functionality is tested by comparing expression evidence and synteny of the candidates with proper test sets. The tests suggest potential biological function. Our candidate set includes a small set of long-lived pseudogenes whose unknown potential function is retained since before the human-mouse species split, and also a larger group of primate-specific ones found from human-chimpanzee searches. Two processed sequences are notable, their conservation since the human-mouse split being as high as most protein-coding genes; one is derived from the protein Ataxin 7-like 3 (ATX7NL3), and one from the Spinocerebellar ataxia type 1 protein (ATX1). Our approach is comparative and can be applied to any pair of species. It is implemented by a semi-automated pipeline based on cross-species BLAST comparisons and maximum-likelihood phylogeny estimations. To separate pseudogenes from protein-coding genes, we use standard methods, utilizing in-frame disablements, as well as a probabilistic filter based on Ka/Ks ratios.	ataxia;ataxia, spinocerebellar;blast;biologic preservation;copy (object);disabled persons;estimated;existential quantification;function (biology);gene duplication abnormality;ka band;large;mammals;pan troglodytes;phylogenetics;primates;pseudogenes;semiconductor industry;synteny;video-in video-out	Örjan Svensson;Lars Arvestad;Jens Lagergren	2006	PLoS Computational Biology	10.1371/journal.pcbi.0020046	biology;genomics;gene expression;bioinformatics;sequence alignment;maximum likelihood;conserved sequence;genetics;pseudogene;genome	Comp.	2.982896773161259	-59.359106474308376	45472
005b7fdba495522805a78f4323a3d85dc2ec22d4	a visual motion detecting module for dragonfly-controlled robots	robot vision aerospace robotics image motion analysis mobile robots neural nets object detection;visualization neurons robot sensing systems classification algorithms clustering algorithms;software application visual motion detecting module dragonfly controlled robots biological sensors hybrid systems artificial biological components real biological components living sensor early visual information processing neural signal recording neural signal processing neural information processing	When imitating biological sensors, we have not completely understood the early processing of the input to reproduce artificially. Building hybrid systems with both artificial and real biological components is a promising solution. For example, when a dragonfly is used as a living sensor, the early processing of visual information is performed fully in the brain of the dragonfly. The only significant remaining tasks are recording and processing neural signals in software and/or hardware. Based on existing works which focused on recording neural signals, this paper proposes a software application of neural information processing to design a visual processing module for dragonfly hybrid bio-robots. After a neural signal is recorded in real-time, the action potentials can be detected and matched with predefined templates to detect when and which descending neurons fire. The output of the proposed system will be used to control other parts of the robot platform.	action potentials;action potential;architecture as topic;biological system;biorobotics;british informatics olympiad;choose (action);clinical use template;computation;computational biology;electric capacitance;hybrid system;information processing;information processor;network switch;neuroscience discipline;polychlorinated biphenyls;potentiometer;printed circuit board;real-time clock;robot (device);small;sorting algorithm;switch device component;telecommunications network;sensor (device)	Thuy T. Pham;Charles M. Higgins	2014	2014 36th Annual International Conference of the IEEE Engineering in Medicine and Biology Society	10.1109/EMBC.2014.6943926	computer vision;simulation;computer science;machine learning	Robotics	15.957324636049545	-67.38645150232348	45493
de23771ae5b6867c3b2ac7fdd0b3271a9204281b	a new hybrid method based on fuzzy-artificial immune system and k-nn algorithm for breast cancer diagnosis	k;artificial immune system;breast cancer diagnosis;k nearest neighbour classification system;hybrid method;machine learning;classification system;fuzzy weighting;k nearest neighbour;cross validation;wisconsin breast cancer diagnosis data;classification accuracy;breast cancer;artificial immune systems;k fold cross validation;medical diagnosis	The use of machine learning tools in medical diagnosis is increasing gradually. This is mainly because the effectiveness of classification and recognition systems has improved in a great deal to help medical experts in diagnosing diseases. Such a disease is breast cancer, which is a very common type of cancer among woman. As the incidence of this disease has increased significantly in the recent years, machine learning applications to this problem have also took a great attention as well as medical consideration. This study aims at diagnosing breast cancer with a new hybrid machine learning method. By hybridizing a fuzzy-artificial immune system with k-nearest neighbour algorithm, a method was obtained to solve this diagnosis problem via classifying Wisconsin Breast Cancer Dataset (WBCD). This data set is a very commonly used data set in the literature relating the use of classification systems for breast cancer diagnosis and it was used in this study to compare the classification performance of our proposed method with regard to other studies. We obtained a classification accuracy of 99.14%, which is the highest one reached so far. The classification accuracy was obtained via 10-fold cross validation. This result is for WBCD but it states that this method can be used confidently for other breast cancer diagnosis problems, too.		Seral Sahan;Kemal Polat;Halife Kodaz;Salih Günes	2007	Computers in biology and medicine	10.1016/j.compbiomed.2006.05.003	medicine;computer science;artificial intelligence;machine learning;data mining;artificial immune system	AI	6.702900360761198	-77.6302854618994	45523
ae1c6f11e56dfee952b11e181322b747dfd93839	understanding dynamics of biological macromolecular complexes by estimating a mechanical model via statistical mechanics from cryo electron microscopy images	equilibrium statistical mechanics;thermal fluctuation;cryo electron microscopy;statistical mechanics;stochastic processes biomechanics biomedical optical imaging electron microscopy enzymes molecular biophysics springs mechanical statistical mechanics;image understanding;biological system modeling;3 d image understanding;biomechanics;scattering;spring constants;springs mechanical;springs;computational modeling;electron microscopy;virus structure equilibrium statistical mechanics 3 d image understanding cryo electron microscopy;enzymes;stochastic processes;biological complexes;biological macromolecular complexes;cryo electron microscopy images;molecular biophysics;normal modes;computational modeling scattering springs biological system modeling electron microscopy;virus structure;statistical variability;stochastic model;biological complexes biological macromolecular complexes mechanical model cryo electron microscopy images statistical variability thermal fluctuations equilibrium statistical mechanics spring mass mechanical model spring constants;synthetic data;biomedical optical imaging;thermal fluctuations;spring mass mechanical model;mechanical model	Cryo electron microscopy (cryo EM) imaging experiments can lead to stochastic models for biological macromolecular complexes. However, interpreting the statistical variability is difficult. In some situations, the variability in the original complexes is due primarily to thermal fluctuations which are snap frozen in place during the preparation of the specimen. In this case the images are images of samples of the equilibrium statistical mechanics ensemble of the complex. Based on representing the complex by a spring-mass mechanical model, an estimation problem for determining the masses and spring constants is described and demonstrated on synthetic data. With a model, quantities such as normal modes can be computed, which provide insight into the dynamics of biological complexes.	biological specimen;electron tomography;experiment;normal mode;spatial variability;stochastic process;synthetic data	Kang Wang;Peter C. Doerschuk	2011	2011 IEEE International Symposium on Biomedical Imaging: From Nano to Macro	10.1109/ISBI.2011.5872788	statistical physics;enzyme;biophysics;cryo-electron microscopy;normal mode;thermal fluctuations;statistical mechanics;stochastic modelling;biomechanics;scattering;hooke's law;computational model;electron microscope;synthetic data;molecular biophysics	Vision	10.39432176261795	-66.98242809447197	45531
c7c9f2cab3b83a267d400a08db04cea6fc72ab81	human reading and the curse of dimensionality	curse of dimensionality	"""Whereas optical character recognition (OCR) systems learn to classify single characters; people learn to classify long character strings in parallel, within a single fixation . This difference is surprising because high dimensionality is associated with poor classification learning. This paper suggests that the human reading system avoids these problems because the number of to-be-classified images is reduced by consistent and optimal eye fixation positions, and by character sequence regularities. An interesting difference exists between human reading and optical character recognition (OCR) systems. The input/output dimensionality of character classification in human reading is much greater than that for OCR systems (see Figure 1) . OCR systems classify one character at time; while the human reading system classifies as many as 8-13 characters per eye fixation (Rayner, 1979) and within a fixation, character category and sequence information is extracted in parallel (Blanchard, McConkie, Zola, and Wolverton, 1984; Reicher, 1969). OCR (Low Dbnensionality) I Dorothy lived In the .... I [Q] ... _ ................................. .. """"D"""" ~ ................................. .. """"0"""" o ~ """"R"""" HUnlan Reading (High Dbnensionality) I Dorothy lived In the midst of the ..... I Dorothy lil Ilived In the I ....... I midst of the I .............. """"DOROTHY LI"""" .. . .. )00 """"LIVED IN THE"""" ... """"MIDST OF THE"""" Figure 1: Character classification versus character sequence classification. This is an interesting difference because high dimensionality is associated with poor classification learning-the so-called curse of dimensionality (Denker, et ali 1987; Geman, Bienenstock, & Doursat, 1992). OCR systems are designed to classify single characters to minimize such problems. The fact that most people learn to read quite well even with the high dimensional inputs and outputs, implies that variance"""	curse of dimensionality;input/output;optical character recognition;statistical classification	Gale Martin	1995			curse of dimensionality;computer science;artificial intelligence;machine learning;pattern recognition;mathematics	AI	-3.1935534676961193	-76.4056366258238	45641
410b720fa82e5dbcae86938d394ec77470bc546d	a feature-based approach to modeling protein–dna interactions	motif finder;position specific scoring matrix;probabilistic graphical models;probabilistic method;transcription factor binding site;transcription factor binding sites;binding site;probabilistic graphical model;chip;chromatin immunoprecipitation;transcription factor;protein dna interaction;markov network;synthetic data;high throughput;dna sequence;dna sequence motifs;log linear model;markov networks	Transcription factor (TF) binding to its DNA target site is a fundamental regulatory interaction. The most common model used to represent TF binding specificities is a position specific scoring matrix (PSSM), which assumes independence between binding positions. However, in many cases, this simplifying assumption does not hold. Here, we present feature motif models (FMMs), a novel probabilistic method for modeling TF-DNA interactions, based on log-linear models. Our approach uses sequence features to represent TF binding specificities, where each feature may span multiple positions. We develop the mathematical formulation of our model and devise an algorithm for learning its structural features from binding site data. We also developed a discriminative motif finder, which discovers de novo FMMs that are enriched in target sets of sequences compared to background sets. We evaluate our approach on synthetic data and on the widely used TF chromatin immunoprecipitation (ChIP) dataset of Harbison et al. We then apply our algorithm to high-throughput TF ChIP data from mouse and human, reveal sequence features that are present in the binding specificities of mouse and human TFs, and show that FMMs explain TF binding significantly better than PSSMs. Our FMM learning and motif finder software are available at http://genie.weizmann.ac.il/.	algorithm;alignment;approximation algorithm;dna binding site;de novo transcriptome assembly;fast multipole method;foundations;gene regulatory network;graph (discrete mathematics);graphical model;high-throughput computing;inference;interaction;linear model;log-linear model;loss function;markov chain;markov random field;mathematics;medical transcription;motif;optimization problem;position weight matrix;position-specific scoring matrices;score;silo (dataset);synthetic data;synthetic intelligence;transcription factor;throughput;transcription (software);transcription, genetic;benefit;chromatin immunoprecipitation;lapatinib	Eilon Sharon;Shai Lubliner;Eran Segal	2008	PLoS Computational Biology	10.1371/journal.pcbi.1000154	biology;bioinformatics;machine learning;pattern recognition;genetics;dna binding site	Comp.	8.552828404997785	-58.14350532503693	45647
aae8f2eb71b3105d169ae70f286c44eedab8bc25	relationship between hippocampal structure and memory function in elderly humans	potentiel evoque cognitif;memoire;limbic system;volumetrie;event evoked potential;systeme nerveux central;elderly;morfometria;hippocampus;adulte jeune;personne âgee;hombre;electrophysiology;encefalo;anciano;hipocampo;morphometry;sistema nervioso central;memoria;voxel based morphometry;hippocampe;encephale;cognition;human;potencial evocado cognitivo;gray matter;cognicion;volumetric analysis;adulto joven;volumetria;electrofisiologia;encephalon;young adult;event related potential erp;electrophysiologie;central nervous system;morphometrie;memory;homme	With progressing age, the ability to recollect personal events declines, whereas familiarity-based memory remains relatively intact. It has been hypothesized that age-related hippocampal atrophy may contribute to this pattern because of its critical role for recollection in younger humans and after acute injury. Here, we show that hippocampal volume loss in healthy older persons correlates with gray matter loss (estimated with voxel-based morphometry) of the entire limbic system and shows no correlation with an electrophysiological (event-related potential [ERP]) index of recollection. Instead, it covaries with more substantial and less specific electrophysiological changes of stimulus processing. Age-related changes in another complementary structural measure, hippocampal diffusion, on the other hand, seemed to be more regionally selective and showed the expected correlation with the ERP index of recollection. Thus, hippocampal atrophy in older persons accompanies limbic atrophy, and its functional impact on memory is more fundamental than merely affecting recollection.	atrophic;erp;gray matter;hmn (hereditary motor neuropathy) proximal type i;hippocampal replay;humans;juvenile spinal muscular atrophy;limbic system;memory disorders;mental recall;morphometric analysis;morphometrics;sensorineural hearing loss (disorder);voxel;hearing impairment	Kolja Schiltz;A. Szentkuti;S. Guderian;J. Kaufmann;Thomas F. Münte;Hans-Jochen Heinze;Emrah Düzel	2006	Journal of Cognitive Neuroscience	10.1162/jocn.2006.18.6.990	psychology;titration;electrophysiology;neuroscience;cognition;developmental psychology;young adult;central nervous system;morphometrics;hippocampus;limbic system;memory;communication;voxel-based morphometry	Vision	18.371049020379267	-79.1950236707404	45654
e91ada6b0dcb4c565f54758161b9040042fa5fd7	epimetheus - a multi-profile normalizer for epigenomic sequencing data	computational biology bioinformatics;algorithms;computer appl in life sciences;microarrays;bioinformatics	Exponentially increasing numbers of NGS-based epigenomic datasets in public repositories like GEO constitute an enormous source of information that is invaluable for integrative and comparative studies of gene regulatory mechanisms. One of today’s challenges for such studies is to identify functionally informative local and global patterns of chromatin states in order to describe the regulatory impact of the epigenome in normal cell physiology and in case of pathological aberrations. Critically, the most preferred Chromatin ImmunoPrecipitation-Sequencing (ChIP-Seq) is inherently prone to significant variability between assays, which poses significant challenge on comparative studies. One challenge concerns data normalization to adjust sequencing depth variation. Currently existing tools either apply linear scaling corrections and/or are restricted to specific genomic regions, which can be prone to biases. To overcome these restrictions without any external biases, we developed Epimetheus, a genome-wide quantile-based multi-profile normalization tool for histone modification data and related datasets. Epimetheus has been successfully used to normalize epigenomics data in previous studies on X inactivation in breast cancer and in integrative studies of neuronal cell fate acquisition and tumorigenic transformation; Epimetheus is freely available to the scientific community.	ab initio quantum chemistry methods;biopolymer sequencing;cell physiology;communications satellite;epigenomics;heart rate variability;histones;image scaling;information source;mammary neoplasms;neoplastic cell transformation;normalize;numerous;repository;x chromosome inactivation function;physiological aspects	Mohamed-Ashick M. Saleem;Marco-Antonio Mendoza-Parra;Pierre-Etienne Cholley;Matthias Blum;Hinrich Gronemeyer	2017		10.1186/s12859-017-1655-3	biology;dna microarray;computer science;bioinformatics;data mining;genetics	Comp.	3.363328864673602	-54.91028230319275	45657
c4fdfd4d3567330d99f869b16192160672bda647	theoretical search for rna folding nuclei	rna folding;stability;hairpin;phi value;pseudoknot;rna domain;mutant	The functions of RNA molecules are defined by their spatial structure, whose folding is regulated by numerous factors making RNA very similar to proteins. Prediction of RNA folding nuclei gives the possibility to take a fresh look at the problems of the multiple folding pathways of RNA molecules and RNA stability. The algorithm previously developed for prediction of protein folding nuclei has been successfully applied to ~150 various RNA structures: hairpins, tRNAs, structures with pseudoknots, and the large structured P4-P6 domain of the Tetrahymena group I intron RNA. The calculated Φ-values for tRNA structures agree with the experimental data obtained earlier. According to the experiment the nucleotides of the D and T hairpin loops are the last to be involved in the tRNA tertiary structure. Such agreement allowed us to do a prediction for an example of large structured RNA, the P4-P6 RNA domain. One of the advantages of our method is that it allows us to make predictions about the folding nucleus for nontrivial RNA motifs: pseudoknots and tRNA.	algorithm;langton's loops	Leonid B. Pereyaslavets;Oxana V. Galzitskaya	2015	Entropy	10.3390/e17117827	stem-loop;nucleic acid tertiary structure;phi value analysis;stability;mutant;bioinformatics;nucleic acid secondary structure;pseudoknot;statistics	Comp.	7.601297521860312	-63.81400858060359	45659
940bf2da4034d47f911e090d0eb686bda819b7fa	how to identify essential genes from molecular networks?	simulation and modeling;data interpretation statistical;saccharomyces cerevisiae;metabolic network;systems biology;signal transduction;saccharomyces cerevisiae proteins;physiological cellular and medical topics;models biological;statistical significance;essential gene;computational biology bioinformatics;models statistical;algorithms;network structure;computer simulation;bioinformatics	The prediction of essential genes from molecular networks is a way to test the understanding of essentiality in the context of what is known about the network. However, the current knowledge on molecular network structures is incomplete yet, and consequently the strategies aimed to predict essential genes are prone to uncertain predictions. We propose that simultaneously evaluating different network structures and different algorithms representing gene essentiality (centrality measures) may identify essential genes in networks in a reliable fashion. By simultaneously analyzing 16 different centrality measures on 18 different reconstructed metabolic networks for Saccharomyces cerevisiae, we show that no single centrality measure identifies essential genes from these networks in a statistically significant way; however, the combination of at least 2 centrality measures achieves a reliable prediction of most but not all of the essential genes. No improvement is achieved in the prediction of essential genes when 3 or 4 centrality measures were combined. The method reported here describes a reliable procedure to predict essential genes from molecular networks. Our results show that essential genes may be predicted only by combining centrality measures, revealing the complex nature of the function of essential genes.	algorithm;aurora;bmc systems biology;ctcfl wt allele;centrality;code;effective method;gene regulatory network;genes, essential;intelligent platform management interface;linear algebra;manuscripts;plxnb1 gene;slc26a3 wt allele;symantec endpoint protection;technical support;thrombocythemia, essential;algorithm;funding grant;mecarzole	Gabriel del Rio;Dirk Koschützki;Gerardo Coello	2009	BMC Systems Biology	10.1186/1752-0509-3-102	computer simulation;biology;computer science;bioinformatics;data science;machine learning;statistical significance;systems biology;signal transduction;metabolic network	ML	5.510229240220887	-56.397781109134534	45679
79f7720a7742fa0133faa95974b01fc78c57df41	on the stability and dynamics of stochastic spiking neuron models: nonlinear hawkes process and point process glms		Point process generalized linear models (PP-GLMs) provide an important statistical framework for modeling spiking activity in single-neurons and neuronal networks. Stochastic stability is essential when sampling from these models, as done in computational neuroscience to analyze statistical properties of neuronal dynamics and in neuro-engineering to implement closed-loop applications. Here we show, however, that despite passing common goodness-of-fit tests, PP-GLMs estimated from data are often unstable, leading to divergent firing rates. The inclusion of absolute refractory periods is not a satisfactory solution since the activity then typically settles into unphysiological rates. To address these issues, we derive a framework for determining the existence and stability of fixed points of the expected conditional intensity function (CIF) for general PP-GLMs. Specifically, in nonlinear Hawkes PP-GLMs, the CIF is expressed as a function of the previous spike history and exogenous inputs. We use a mean-field quasi-renewal (QR) approximation that decomposes spike history effects into the contribution of the last spike and an average of the CIF over all spike histories prior to the last spike. Fixed points for stationary rates are derived as self-consistent solutions of integral equations. Bifurcation analysis and the number of fixed points predict that the original models can show stable, divergent, and metastable (fragile) dynamics. For fragile models, fluctuations of the single-neuron dynamics predict expected divergence times after which rates approach unphysiologically high values. This metric can be used to estimate the probability of rates to remain physiological for given time periods, e.g., for simulation purposes. We demonstrate the use of the stability framework using simulated single-neuron examples and neurophysiological recordings. Finally, we show how to adapt PP-GLM estimation procedures to guarantee model stability. Overall, our results provide a stability framework for data-driven PP-GLMs and shed new light on the stochastic dynamics of state-of-the-art statistical models of neuronal spiking activity.	action potential;approximation;bifurcation theory;computational neuroscience;control theory;crystallographic information file;fixed point (mathematics);generalized linear model;neuron;nonlinear system;pancreatic polypeptide;pancreatic polypeptide-secreting cells;point process;sampling (signal processing);server message block;simian t-lymphotropic virus-pp;simulation;software brittleness;stationary process;statistical model;stem cell self-renewal;stochastic process;thyroid gland spindle cell tumor with thymus-like differentiation;unstable medical device problem	Felipe Gerhard;Moritz Deger;Wilson A. Truccolo	2017		10.1371/journal.pcbi.1005390	machine learning;statistics	ML	20.471564104969065	-72.88785198493063	45820
b4815b1d6c1d70667f99c463a0a647826e391c00	arabidopsis thaliana regulatory element analyzer	cruciferae;spermatophyta;angiospermae;regulatory element;bioinformatique;regulatory sequence;analisis automatico;arabidopsis thaliana;secuencia reguladora;automatic analysis;sequence regulatrice;analyse automatique;dicotyledones;bioinformatica;bioinformatics	UNLABELLED In the Arabidopsis thaliana regulatory element analyzer (AtREA) server, we have integrated sequence data, genome-wide expression data and functional annotation data in three application modules which will be useful to identify major regulatory targets of a user-provided cis-regulatory element (CRE), study different features of CRE distribution and evaluate the role of a set of CREs in the regulation of gene expression--independently as well as in combination with other user-provided CREs.   AVAILABILITY AtREA is freely available at http://www.bioinformatics.org/grn/atrea.html.	analyzer device component;annotation;carcinoma in situ;gene expression regulation;pik3r3 protein;regulatory sequences, nucleic acid;server (computing)	Ananyo Choudhury;Ansuman Lahiri	2008	Bioinformatics	10.1093/bioinformatics/btn417	biology;botany;bioinformatics;regulatory sequence;data mining	Comp.	-1.1699853809898255	-58.77919937309779	45850
a2af16ae5e46a0d00ad076d92d4bbc68649e1f39	pynbs: a python implementation for network-based stratification of tumor mutations		Summary We present pyNBS: a modularized Python 2.7 implementation of the network-based stratification (NBS) algorithm for stratifying tumor somatic mutation profiles into molecularly and clinically relevant subtypes. In addition to release of the software, we benchmark its key parameters and provide a compact cancer reference network that increases the significance of tumor stratification using the NBS algorithm. The structure of the code exposes key steps of the algorithm to foster further collaborative development.   Availability and implementation The package, along with examples and data, can be downloaded and installed from the URL https://github.com/idekerlab/pyNBS.	benchmark (computing);diploid cell;neoplasms;netbeans ide;python;somatic mutation;stratification;subtype (attribute);url data type;algorithm	Justin K. Huang;Tongqiu Jia;Daniel E. Carlin;Trey Ideker	2018	Bioinformatics	10.1093/bioinformatics/bty186	computer science;bioinformatics;python (programming language)	Comp.	-3.0707070408766213	-58.88312520046431	45883
55bcf74d0cbe1bf2296bb62b6c8464906900d60b	optimal number of spacers in crispr arrays		Prokaryotic organisms survive under constant pressure of viruses. CRISPR-Cas system provides its prokaryotic host with an adaptive immune defense against viruses that have been previously encountered. It consists of two components: Cas-proteins that cleave the foreign DNA and CRISPR array that suits as a virus recognition key. CRISPR array consists of a series of spacers, short pieces of DNA that originate from and match the corresponding parts of viral DNA called protospacers. Here we estimate the number of spacers in a CRISPR array of a prokaryotic cell which maximizes its protection against a viral attack. The optimality follows from a competition between two trends: too few distinct spacers make host vulnerable to an attack by a virus with mutated corresponding protospacers, while an excessive variety of spacers dilutes the number of the CRISPR complexes armed with the most recent and thus most useful spacers. We first evaluate the optimal number of spacers in a simple scenario of an infection by a single viral species and later consider a more general case of multiple viral species. We find that depending on such parameters as the concentration of CRISPR-Cas interference complexes and its preference to arm with more recently acquired spacers, the rate of viral mutation, and the number of viral species, the predicted optimal number of spacers lies within a range that agrees with experimentally-observed values.	accidental falls;appendix;crispr spacers;crispr-cas systems;clustered regularly interspaced short palindromic repeats;computational biology;cytology;dvb-s2;experiment;interference (communication);mutation;point of view (computer hardware company);portable document format;prokaryote;spacer device component;spacer gif;virus;viral capsid secondary envelopment	Alexander Martynov;Konstantin Severinov;Iaroslav Ispolatov	2017		10.1371/journal.pcbi.1005891	biology;bioinformatics;genetics	Comp.	3.7567308612588075	-62.43097054658754	45886
5c89d99f8754462bfec84335a2545f5bc6e2effc	ketamine modulates theta and gamma oscillations	gamma oscillation;n methyl d aspartate;power reduction;nmda receptor	Ketamine, an N-methyl-d-aspartate (NMDA) receptor glutamatergic antagonist, has been studied as a model of schizophrenia when applied in subanesthetic doses. In EEG studies, ketamine affects sensory gating and alters the oscillatory characteristics of neuronal signals in a complex manner. We investigated the effects of ketamine on in vivo recordings from the CA3 region of mouse hippocampus referenced to the ipsilateral frontal sinus using a paired-click auditory gating paradigm. One issue of particular interest was elucidating the effect of ketamine on background network activity, poststimulus evoked and induced activity. We find that ketamine attenuates the theta frequency band in both background activity and in poststimulus evoked activity. Ketamine also disrupts a late, poststimulus theta power reduction seen in control recordings. In the gamma frequency range, ketamine enhances both background and evoked power, but decreases relative induced power. These findings support a role for NMDA receptors in mediating the balance between theta and gamma responses to sensory stimuli, with possible implications for dysfunction in schizophrenia.	aspartic acid;ca3 field;electroencephalography;frequency band;frontal sinus;information processing;ketamine;n-methyl-d-aspartate receptors;n-methylaspartate;nasal sinus;neural oscillation;programming paradigm;schizophrenia;sensory gating;video-in video-out	Maciej T. Lazarewicz;Richard S. Ehrlichman;Christina R. Maxwell;Michael J. Gandal;Leif H. Finkel;Steven J. Siegel	2010	Journal of Cognitive Neuroscience	10.1162/jocn.2009.21305	psychology;nmda receptor;neuroscience;developmental psychology	HCI	17.63854540916763	-77.15849021834033	45918
7594842e874d223baa8ac4545d71274a20d0d84a	finding consistent disease subnetworks using pfsnet		MOTIVATION Microarray data analysis is often applied to characterize disease populations by identifying individual genes linked to the disease. In recent years, efforts have shifted to focus on sets of genes known to perform related biological functions (i.e. in the same pathways). Evaluating gene sets reduces the need to correct for false positives in multiple hypothesis testing. However, pathways are often large, and genes in the same pathway that do not contribute to the disease can cause a method to miss the pathway. In addition, large pathways may not give much insight to the cause of the disease. Moreover, when such a method is applied independently to two datasets of the same disease phenotypes, the two resulting lists of significant pathways often have low agreement.   RESULTS We present a powerful method, PFSNet, that identifies smaller parts of pathways (which we call subnetworks), and show that significant subnetworks (and the genes therein) discovered by PFSNet are up to 51% (64%) more consistent across independent datasets of the same disease phenotypes, even for datasets based on different platforms, than previously published methods. We further show that those methods which initially declared some large pathways to be insignificant would declare subnetworks detected by PFSNet in those large pathways to be significant, if they were given those subnetworks as input instead of the entire large pathways.   AVAILABILITY http://compbio.ddns.comp.nus.edu.sg:8080/pfsnet/	expanded memory;fuzzy set;gene expression;gene regulatory network;microarray;phenotype;population;relaxation;scientific publication;small;subnetwork	Kevin Lim;Limsoon Wong	2014	Bioinformatics	10.1093/bioinformatics/btt625	biology;bioinformatics;data mining;statistics	Comp.	4.9183730462444535	-56.22997547678834	45938
3073eee71f3fc420216d41057777160e00fbfab6	integrating quantitative proteomics and metabolomics with a genome-scale metabolic network model	escherichia coli;metabolomics;metabolic networks and pathways;metabolic network;genome;proteomics	MOTIVATION The availability of modern sequencing techniques has led to a rapid increase in the amount of reconstructed metabolic networks. Using these models as a platform for the analysis of high throughput transcriptomic, proteomic and metabolomic data can provide valuable insight into conditional changes in the metabolic activity of an organism. While transcriptomics and proteomics provide important insights into the hierarchical regulation of metabolic flux, metabolomics shed light on the actual enzyme activity through metabolic regulation and mass action effects. Here we introduce a new method, termed integrative omics-metabolic analysis (IOMA) that quantitatively integrates proteomic and metabolomic data with genome-scale metabolic models, to more accurately predict metabolic flux distributions. The method is formulated as a quadratic programming (QP) problem that seeks a steady-state flux distribution in which flux through reactions with measured proteomic and metabolomic data, is as consistent as possible with kinetically derived flux estimations.   RESULTS IOMA is shown to successfully predict the metabolic state of human erythrocytes (compared to kinetic model simulations), showing a significant advantage over the commonly used methods flux balance analysis and minimization of metabolic adjustment. Thereafter, IOMA is shown to correctly predict metabolic fluxes in Escherichia coli under different gene knockouts for which both metabolomic and proteomic data is available, achieving higher prediction accuracy over the extant methods. Considering the lack of high-throughput flux measurements, while high-throughput metabolomic and proteomic data are becoming readily available, we expect IOMA to significantly contribute to future research of cellular metabolism.	biopolymer sequencing;flux balance analysis;high-throughput computing;kinetics;mass action law (electronics);metabolic process, cellular;metabolomics;network model;omics;proteomics;quadratic programming;simulation;steady state;throughput;enzyme activity	Keren Yizhak;Tomer Benyamini;Wolfram Liebermeister;Eytan Ruppin;Tomer Shlomi	2010		10.1093/bioinformatics/btq183	biology;biochemistry;biotechnology;bioinformatics;metabolomics;fluxomics;proteomics;escherichia coli;metabolic network modelling;genetics;metabolic network;genome	Comp.	6.508688696771908	-59.56740164922137	45968
275a773b6d162d53644407250dc95b122cf7aea9	hyphy: hypothesis testing using phylogenies	programming language design;evolutionary model;phylogeny;heterodox economics;phylogenese;climate change;software systems;bioinformatique;statistical method;data analysis;ecological economics;filogenesis;general equilibrium analysis;graphic user interface;binary classification;bioinformatica;evolutionary process;bioinformatics;hypothesis test	UNLABELLED The HyPhypackage is designed to provide a flexible and unified platform for carrying out likelihood-based analyses on multiple alignments of molecular sequence data, with the emphasis on studies of rates and patterns of sequence evolution.   AVAILABILITY http://www.hyphy.org   CONTACT muse@stat.ncsu.edu   SUPPLEMENTARY INFORMATION HyPhydocumentation and tutorials are available at http://www.hyphy.org.	hyphy;phylogenetics	Sergei L. Kosakovsky Pond;Simon D. W. Frost;Spencer V. Muse	2005	Bioinformatics	10.1093/bioinformatics/bti079	binary classification;biology;heterodox economics;statistical hypothesis testing;simulation;computer science;bioinformatics;data mining;graphical user interface;data analysis;climate change;ecological economics;statistics;software system	Comp.	-2.8263435480452985	-56.264119270984324	45971
0ac9ab6e09d0997693bd4cc627d149397244e3f0	feature selection through validation and un-censoring of endovascular repair survival data for predicting the risk of re-intervention	censoring;cox’s hazard proportional model;endovascular aortic aneurysm repair;factor analysis;feature selection;model selection;survival analysis	BACKGROUND Feature selection (FS) process is essential in the medical area as it reduces the effort and time needed for physicians to measure unnecessary features. Choosing useful variables is a difficult task with the presence of censoring which is the unique characteristic in survival analysis. Most survival FS methods depend on Cox's proportional hazard model; however, machine learning techniques (MLT) are preferred but not commonly used due to censoring. Techniques that have been proposed to adopt MLT to perform FS with survival data cannot be used with the high level of censoring. The researcher's previous publications proposed a technique to deal with the high level of censoring. It also used existing FS techniques to reduce dataset dimension. However, in this paper a new FS technique was proposed and combined with feature transformation and the proposed uncensoring approaches to select a reduced set of features and produce a stable predictive model.   METHODS In this paper, a FS technique based on artificial neural network (ANN) MLT is proposed to deal with highly censored Endovascular Aortic Repair (EVAR). Survival data EVAR datasets were collected during 2004 to 2010 from two vascular centers in order to produce a final stable model. They contain almost 91% of censored patients. The proposed approach used a wrapper FS method with ANN to select a reduced subset of features that predict the risk of EVAR re-intervention after 5 years to patients from two different centers located in the United Kingdom, to allow it to be potentially applied to cross-centers predictions. The proposed model is compared with the two popular FS techniques; Akaike and Bayesian information criteria (AIC, BIC) that are used with Cox's model.   RESULTS The final model outperforms other methods in distinguishing the high and low risk groups; as they both have concordance index and estimated AUC better than the Cox's model based on AIC, BIC, Lasso, and SCAD approaches. These models have p-values lower than 0.05, meaning that patients with different risk groups can be separated significantly and those who would need re-intervention can be correctly predicted.   CONCLUSION The proposed approach will save time and effort made by physicians to collect unnecessary variables. The final reduced model was able to predict the long-term risk of aortic complications after EVAR. This predictive model can help clinicians decide patients' future observation plan.	aicardi's syndrome;akaike information criterion;aortic valve insufficiency;area under curve;artificial neural network;bayesian information criterion;censor;clinical trial censoring;concordance (publishing);deficiency of butyryl-coa dehydrogenase;feature selection;high-level programming language;lasso;learning disorders;machine learning;openscad;patients;predictive modelling;silo (dataset);stable model semantics;subgroup;survival analysis;imidazole mustard	Omneya Attallah;Alan Karthikesalingam;Peter J. E. Holt;Matthew M. Thompson;Rob Sayers;Matthew J. Bown;Eddie C. Choke;Xianghong Ma	2017		10.1186/s12911-017-0508-3	proportional hazards model;model selection;lasso (statistics);data mining;akaike information criterion;censoring (statistics);scad;feature selection;bayesian information criterion;medicine	ML	6.241857903931378	-76.02761718971799	46012
1a139f0d5917cbcfdb5eee77b72930efbba87c60	spike train correlation visualization	biology computing;bioelectric potentials;medical signal processing data visualisation neurophysiology filtering theory data analysis neural nets bioelectric potentials;multidimensional spike train dataset;neural nets;nervous system;systems biology;information filtering;learning and memory;filters;data filtering;basic brain function;correlation grid method;neural activity;multi dimensional;data visualisation;data analysis;statistical sorting method;adaptive systems;spike train correlation visualization;details on demand;data visualization;data overview;production systems;statistical sorting method spike train correlation visualization neural activity basic brain function data analysis innovative method multidimensional spike train dataset correlation grid method information visualisation data overview details on demand data filtering;spike train;neurons;neurophysiology;brain function;neurons data visualization data analysis biology computing filters nervous system adaptive systems systems biology production systems information filtering;medical signal processing;filtering theory;innovative method;information visualisation	The current ability to record neural activity within the brains of mammals has led to the production of a large body of experimental data. The analysis and comprehension of this data is key to the understanding of many basic brains functions, for example learning and memory. The main constituent of this data is multi-dimensional spike train recordings. As the analysis of these datasets, by traditional means, becomes more complex and time consuming the need for better methods of data analysis increases. This paper presents an innovative method for analysis of the relationships within large multi-dimensional spike train datasets. This method, called the ‘Correlation Grid,’ is based on the Information Visualisation principles; overview the data, filter and zoom the data and obtain details-on-demand [1]. The features of the Correlation Grid are described, including filtering and statistical sorting methods.	action potential;information visualization;sorting	Martin A. Walter;Liz J. Stuart;Roman Borisyuk	2003		10.1109/IV.2003.1218040	computer science;theoretical computer science;machine learning;data mining	ML	21.227072892169673	-74.16194975969469	46020
8c35717656314de27799d4ae8f8ecf96a7894ee2	evodesign: de novo protein design based on structural and evolutionary profiles	evolution molecular;software;internet;protein conformation;monte carlo method;protein engineering;sequence analysis protein	Protein design aims to identify new protein sequences of desirable structure and biological function. Most current de novo protein design methods rely on physics-based force fields to search for low free-energy states following Anfinsen's thermodynamic hypothesis. A major obstacle of such approaches is the inaccuracy of the force field design, which cannot accurately describe the atomic interactions or distinguish correct folds. We developed a new web server, EvoDesign, to design optimal protein sequences of given scaffolds along with multiple sequence and structure-based features to assess the foldability and goodness of the designs. EvoDesign uses an evolution-profile-based Monte Carlo search with the profiles constructed from homologous structure families in the Protein Data Bank. A set of local structure features, including secondary structure, torsion angle and solvation, are predicted by single-sequence neural-network training and used to smooth the sequence motif and accommodate the physicochemical packing. The EvoDesign algorithm has been extensively tested in large-scale protein design experiments, which demonstrate enhanced foldability and structural stability of designed sequences compared with the physics-based designing methods. The EvoDesign server is freely available at http://zhanglab.ccmb.med.umich.edu/EvoDesign.	algorithm;amino acid sequence;artificial neural network;de novo protein structure prediction;de novo transcriptome assembly;experiment;force field (chemistry);function (biology);homology (biology);interaction;monte carlo method;monte carlo tree search;peptide sequence;protein data bank;sequence motif;server (computing);set packing;thermodynamics;torsion (gastropod);web server	Pralay Mitra;David Shultis;Yonghui Zhang	2013		10.1093/nar/gkt384	biology;protein structure;the internet;bioinformatics;protein engineering;protein structure database;genetics;protein design;monte carlo method	Comp.	11.174565169006893	-60.024944836803094	46038
e412bd6a9246c84bf34c6a8e124eea10affb6491	rst: a connectionist architecture to deal with spatiotemporal relationships	simulation ordinateur;traitement signal;refractory period;arquitectura red;logica temporal;estimation mouvement;modele mathematique;image processing;connectionism;etude experimentale;conexionismo;temporal logic;estimacion movimiento;procesamiento imagen;motion estimation;modelo matematico;architecture reseau;traitement image;three dimensional;connexionnisme;signal processing;image sequence;mathematical model;pattern recognition;secuencia imagen;network architecture;simulacion computadora;integrate and fire neuron;reconnaissance forme;reseau neuronal;reconocimiento patron;procesamiento senal;computer simulation;estudio experimental;motion detection;logique temporelle;red neuronal;sequence image;neural network	In the past decade, connectionism has proved its efficiency in the field of static pattern recognition. The next challenge is to deal with spatiotemporal problems. This article presents a new connectionist architecture, RST (eseau spatio temporel [spatio temporal network]), with such spatiotemporal capacities. It aims at taking into account at the architecture level both spatial relationships (e.g., as between neighboring pixels in an image) and temporal relationships (e.g., as between consecutive images in a video sequence). Concerning the spatial aspect, the network is embedded in actual space (two-or three-dimensional), the metrics of which directly influence its structure through a connection distribution function. For the temporal aspect, we looked toward biology and used a leaky-integrator neuron model with a refractory period and postsynaptic potentials. The propagation of activity by spatiotemporal synchronized waves enables RST to perform motion detection and localization in sequences of video images.	biological neuron model;connectionism;embedded system;embedding;intel matrix raid;internationalization and localization;pattern recognition;pixel;postsynaptic potentials;software propagation	Jean-Cédric Chappelier;Alain Grumbach	1998	Neural Computation	10.1162/089976698300017548	computer simulation;three-dimensional space;computer vision;connectionism;network architecture;temporal logic;image processing;computer science;artificial intelligence;signal processing;motion estimation;mathematical model;artificial neural network;refractory period	Vision	22.536651641728266	-68.83891495725557	46063
308003985a1cbeed5272d3302c21cac7211d2ece	map-o-mat: internet-based linkage mapping	bioinformatique;internet;human genome;polymorphism;linkage map;bioinformatica;physical map;dna marker;bioinformatics	UNLABELLED MAP-O-MAT is a web-based server for automated linkage mapping of human polymorphic DNA markers. MAP-O-MAT facilitates the verification of order and map distances for custom mapping sets using genotype data from the CEPH database, and from the Marshfield, SNP Consortium and Rutgers linkage maps (exclusive to the deCODE genotyping data). The CRI-MAP program is used for likelihood calculations and some mapping algorithms, and physical map positions are provided from the human genome assembly.   AVAILABILITY MAP-O-MAT is located at http://compgen.rutgers.edu/mapomat/   CONTACT matise@biology.rutgers.edu.	algorithm;chromosome mapping;consortium;distance;genotype determination;internet;linkage (software);map;object-relational mapping;server (computing);verification of theories;web application;genetic linkage	X. Kong;Tara Cox Matise	2005	Bioinformatics	10.1093/bioinformatics/bti024	biology;polymorphism;human genome;the internet;genetic linkage;bioinformatics;genetic marker;genetics	Comp.	-2.1995693250946946	-59.413397457939865	46064
00023c0b102c20ca743d2676054cd456c19ac1b9	drug-class specific impact of antivirals on the reproductive capacity of hiv	hiv;hiv infection;population biology;drug discovery;drug targeting;dynamic model;models biological;clinical trial;life cycles;development process;mode of action;viral load;drug interactions;drug therapy;drug research and development;pharmacology;mathematical modelling;immune system;clinical outcome;viral replication;virus replication;macrophages;applied mathematics;computer simulation;virology;anti hiv agents	Predictive markers linking drug efficacy to clinical outcome are a key component in the drug discovery and development process. In HIV infection, two different measures, viral load decay and phenotypic assays, are used to assess drug efficacy in vivo and in vitro. For the newly introduced class of integrase inhibitors, a huge discrepancy between these two measures of efficacy was observed. Hence, a thorough understanding of the relation between these two measures of drug efficacy is imperative for guiding future drug discovery and development activities in HIV. In this article, we developed a novel viral dynamics model, which allows for a mechanistic integration of the mode of action of all approved drugs and drugs in late clinical trials. Subsequently, we established a link between in vivo and in vitro measures of drug efficacy, and extract important determinants of drug efficacy in vivo. The analysis is based on a new quantity-the reproductive capacity-that represents in mathematical terms the in vivo analog of the read-out of a phenotypic assay. Our results suggest a drug-class specific impact of antivirals on the total amount of viral replication. Moreover, we showed that the (drug-)target half life, dominated by immune-system related clearance processes, is a key characteristic that affects both the emergence of resistance as well as the in vitro-in vivo correlation of efficacy measures in HIV treatment. We found that protease- and maturation inhibitors, due to their target half-life, decrease the total amount of viral replication and the emergence of resistance most efficiently.	discrepancy function;drug discovery;emergence;imperative programming;in vitro [publication type];reproduction;serotonin uptake inhibitors;video-in video-out;virus diseases;virus replication	Max von Kleist;Stephan Menz;Wilhelm Huisinga	2010		10.1371/journal.pcbi.1000720	computer simulation;population biology;pharmacology;biology;toxicology;virology;viral replication	ML	7.906859992173999	-61.64278173626783	46117
ba522ad43164e74e3daa35eeb04dd8ce3d515bdf	de novo design and pharmacophore prediction of aadc (aromatic l-amino acid decarboxylase) inhibitors	amino acid;ligands;aromatic l amino acid decarboxylase;aadc inhibitors;lyase enzymes;pharmacophore;drug targets;pharmacophoric features;neurological disorders;ludi;de novo design	AADC (Aromatic L-amino acid decarboxylase) is a lyase enzyme. It is a well known potential drug target for neurological disorders. Selective AADC inhibitors are used in the treatment of neurological disorders such as Parkinson's. The aim of this work is to develop specific inhibitors, which may overcome the side effects that the existing inhibitors suffer from. In the light of these facts, AADC enzyme has been modelled and ligands have been generated from AADC enzyme with its known binding site using LUDI. Also, binding affinity of the ligand towards the enzyme has been enhanced. The number of ligands was selected based on the intermolecular h-bonds with receptor, polar surface area, molecular volume, Lipinski's rule of five and docking studies. Finally, pharmacophoric features present in the selected ligands were predicted.	pharmacophore	J. Jayanthi;V. Usha	2008	IJMEI	10.1504/IJMEI.2008.019471	amino acid;pharmacophore;ligand;aromatic l-amino acid decarboxylase	EDA	9.519192696363964	-61.78918038865771	46162
79f60b7e7a812c06244fd6cc45f86ce63630e991	database searching with dna and protein sequences: an introduction	protein sequence;database search	This review of sequence database searching aims to set out current practice in the area, in order to give practical guidelines to the experimental biologist. It describes the basic principles behind the programs and enumerates the range of databases available in the public domain. Of these, the most important are the equivalent DNA databases European Molecular Biology Laboratory (EMBL), GenBank and DNA Databank of Japan (DDBJ), and the protein databases Swiss-Prot and TrEMBL. The commonly used BLAST and FASTA algorithms are described in detail and alternative approaches mentioned briefly. Scoring matrices used to compare amino acid types during protein database searches are compared, with an emphasis on the PAM and BLOSUM series of observed substitution matrices.	algorithm;amino acids;blast;blosum;dna data bank ofjapan;dna barcoding;fasta;genbank;potassium aggravated myotonia;swiss-model;sequence database;substitution matrix;switzerland;uniprot	Clare Sansom	2000	Briefings in bioinformatics	10.1093/bib/1.1.22	biology;database search engine;computer science;bioinformatics;protein sequencing;sequence database;refseq;conserved domain database;information retrieval	Comp.	-2.274009510056283	-61.61166412327636	46168
db7f580662a8095fd219427ed83b0674c187336b	algorithms for global protein–protein interaction network alignment		Protein–protein interaction creates a complex relation among molecular organs. The pivotal functionalities among cells depend on these interactions. In the light of computational biology (CB), it is possible to retrieve the exact information regarding these relationships. The global alignments among proteins are more important. Toward the development of the PPI network analysis, various methods such as heuristics, evolutionary, probabilistic, semi-probabilistic, spectral graph analysis and mapping methods have been developed and this is an ongoing process of progress. Some remarkable contributions to the PPI global network alignments are Common neighbors-based global GRAph (C-GRAAL), GRAph ALigner (GRAAL), Hungarian algorithm-based GRAAL (H-GRAAL), Matching-based GRAph aligner (M-GRAAL), IsoRankN, IsoRank, Scalable Global alignment algorithm, SMETENA, (software package) and GraphCrunch 2 (software package). All the mentioned algorithms and software package mentioned above have tried to address the best illustration and mapping between protein networks for global protein network alignment. For simplicity we avoid local sequence alignment methods and algorithms. For experimental data analysis, five eukaryotic species such as C. elegans (CE), D. melanogaster (DM), S. cerevisiae (SC), H. sapiens (HS) and M. musculus (MM) have been considered.	complex network;computational biology;global network;graph isomorphism;graphcrunch;heuristic (computer science);hungarian algorithm;interaction network;loop (graph theory);np-completeness;network topology;pixel density;probabilistic automaton;protein structure prediction;self-replication;semiconductor industry;sequence alignment	Sonia Farhana Nimmy;Mohammad Shohelur Rahman	2014	Network Modeling Analysis in Health Informatics and Bioinformatics	10.1007/s13721-014-0065-y	computer science;bioinformatics;theoretical computer science;machine learning	Comp.	4.448415616553277	-57.865257333667074	46180
aa0d9e6ea70e55dc8797d71f634a88a2e875db92	classifying cardiac arrhythmic episodes via data compression		Abstract The rapid development of the cloud computing technology is favoring the emergence of new platforms offering a new broad range of possibilities for data analytics. An example of this is SCOOP, a scientific cloud computing platform designed to massively collect data from Implantable Cardioverter Defibrillators (ICDs) generating cooperatively new knowledge in the cardiac electrophysiology field. In this work, we propose a new automatic and computationally fast methodology for classifying the cardiac arrhythmic episodes recorded by current ICDs into 8 and 3 arrhythmic categories (8 and 3-class schemes, respectively). Similarity among episodes is determined via data compression based techniques. Then, a statistical classifier is designed by using previous similarities as a kernel. Our proposal is characterized by: (1) requiring minimal signal preprocessing; (2) dealing with episodes of different duration with blank intervals; and (3) considering simultaneously heart activation events and signal waveform as its underlying clinical criterion. To avoid bias in the classification of new episodes, performance was evaluated without considering previous patient information on the training stage. A set of 6233 arrhythmic episodes from 599 patients extracted from the SCOOP platform were considered in this work. Test accuracy rates (and kappa coefficients) close to 78% (0.6) and 90% (0.8) were achieved in both 8 and 3-class schemes, respectively. This fact shows that our methodology can be used as a data analytics cardiology tool supporting physicians in their cardiac diagnosis, forecasting its future use in ICDs and related systems.	data compression	José María Lillo-Castellano;José Luis Rojo-Álvarez;Fernando Chavarría-Asso;Arcadio García-Alberola;María Martín-Méndez;I. Mora-Jiménez	2018	Neurocomputing	10.1016/j.neucom.2018.03.010	machine learning;cardiac electrophysiology;artificial intelligence;scoop;data compression;cloud computing;data analysis;waveform;mathematics;pattern recognition	ML	4.72718750078524	-77.56182134007462	46223
1d2e80f3af3b8b968577f160ae61eeed3387858a	extracting state transition dynamics from multiple spike trains with correlated poisson hmm	spike train;state transition	Neural activity is non-stationary and varies across time. Hidden Markov Models (HMMs) have been used to track the state transition among quasi-stationary discrete neural states. Within this context, independent Poisson models have been used for the output distribution of HMMs; hence, the model is incapable of tracking the change in correlation without modulating the firing rate. To achieve this, we applied a multivariate Poisson distribution with correlation terms for the output distribution of HMMs. We formulated a Variational Bayes (VB) inference for the model. The VB could automatically determine the appropriate number of hidden states and correlation types while avoiding the overlearning problem. We developed an efficient algorithm for computing posteriors using the recursive relationship of a multivariate Poisson distribution. We demonstrated the performance of our method on synthetic data and a real spike train recorded from a songbird.	action potential;algorithm;hidden markov model;markov chain;neural oscillation;recursion;songbird;state transition table;stationary process;synthetic data;variational principle	Kentaro Katahira;Jun Nishikawa;Kazuo Okanoya;Masato Okada	2008			speech recognition;computer science;machine learning;statistics	ML	21.78801888750344	-73.88122976135492	46225
b5434ab7d729b0ec8b260b13d56d0c231a4aebfd	3d scientific data mining in ion trajectories	temporal correlation;physics computing data mining data structures data visualisation;software;time varying;scientific datasets;glass trajectories;3d timeline event visual mining;ions;scientific data;visual representation spatial temporal application colour scale coding theory;data mining;physics computing;three dimensional;data mining atomic measurements data visualization biomedical imaging shape solid modeling deformable models physics computing glass statistical analysis;surface based visualisation schemes;qa75 electronic computers computer science;data visualisation;data statistical analysis;visualization;trajectory;statistical analysis;coding theory;visual representation;colour scale;three dimensional displays;image color analysis;data structures;3d visual representation;data visualization;chaotic atom movements 3d scientific data mining ion trajectories glass trajectories data statistical analysis computer simulation structure transport relationships surface based visualisation schemes scientific datasets simulated 3d time varying model temporal correlation 3d visual representation 3d timeline event visual mining complex atom movements;chaotic atom movements;experimental measurement;structure transport relationships;3d scientific data mining;simulated 3d time varying model;ion trajectories;computer simulation;tk electrical engineering electronics nuclear engineering;spatial temporal application;complex atom movements;local time	In physics, structure of glass and ion trajectories are essentially based on statistical analysis of data acquired through experimental measurement and computer simulation [1, 2]. Invariably, the details of the structure-transport relationships in the data have been mistreated in favour of ensemble average [3-5]. In this study, we demonstrate a visual approach of such relationship using surface-based visualisation schemes. In particular, we demonstrate a scientific datasets of simulated 3D time-varying model and examine the temporal correlation among ion trajectories. We propose a scheme that uses a three dimensional visual representation with colour scale for depicting the timeline events in ion trajectories and this scheme could be divided into two major part such as global and local time scale. With a collection of visual examples from this study, we demonstrate that this scheme may offer an effective tool for visually mining 3D timeline events of the ion trajectories. This work will potentially form a basis of a novel analysis tool for measuring the effectiveness of visual representation to assist physicist in identifying possible temporal association among complex and chaotic atom movements in ion trajectories.	computer simulation;data mining;timeline	Johan Mohamad Sharif;M. Mahadi Abdul Jamil;Md. Asri Ngadi;M. Shafie Latiff	2010	2010 Third International Conference on Knowledge Discovery and Data Mining	10.1109/WKDD.2010.114	three-dimensional space;computer vision;visualization;computer science;data science;trajectory;machine learning;local time;data mining;data visualization;statistics;coding theory;data;ion	ML	16.148696645074846	-62.8501025541121	46233
01e4d2237ccd169635be15400ee3df31e01bd7b9	when inhibition not excitation synchronizes neural firing	model generation;integrate and fire;action potential;hodgkin huxley	Excitatory and inhibitory synaptic coupling can have counter-intuitive effects on the synchronization of neuronal firing. While it might appear that excitatory coupling would lead to synchronization, we show that frequently inhibition rather than excitation synchronizes firing. We study two identical neurons described by integrate-and-fire models, general phase-coupled models or the Hodgkin-Huxley model with mutual, non-instantaneous excitatory or inhibitory synapses between them. We find that if the rise time of the synapse is longer than the duration of an action potential, inhibition not excitation leads to synchronized firing.	action potential;biological neuron model;excitation;hodgkin–huxley model;huxley: the dystopia;rise time;synapse;synapses	Carl Vreeswijk;L. F. Abbott;Bard Ermentrout	1994	Journal of Computational Neuroscience	10.1007/BF00961879	psychology;neuroscience;excitatory synapse;telecommunications;communication;action potential;hodgkin–huxley model	ML	17.723262647166667	-71.21609084414547	46289
8775cbb9a58aec4d31655bf50a0eac7d10e0b6f9	inferring serum proteolytic activity from lc-ms/ms data	serum;proteolysis;mass spectrometry;computational biology bioinformatics;tandem mass spectrometry;chromatography liquid;models statistical;algorithms;peptide hydrolases;humans;combinatorial libraries;computer appl in life sciences;colorectal neoplasms;markov chains;microarrays;bioinformatics	In this paper we deal with modeling serum proteolysis process from tandem mass spectrometry data. The parameters of peptide degradation process inferred from LC-MS/MS data correspond directly to the activity of specific enzymes present in the serum samples of patients and healthy donors. Our approach integrate the existing knowledge about peptidases' activity stored in MEROPS database with the efficient procedure for estimation the model parameters. Taking into account the inherent stochasticity of the process, the proteolytic activity is modeled with the use of Chemical Master Equation (CME). Assuming the stationarity of the Markov process we calculate the expected values of digested peptides in the model. The parameters are fitted to minimize the discrepancy between those expected values and the peptide activities observed in the MS data. Constrained optimization problem is solved by Levenberg-Marquadt algorithm. Our results demonstrates the feasibility and potential of high-level analysis for LC-MS proteomic data. The estimated enzyme activities give insights into the molecular pathology of colorectal cancer. Moreover the developed framework is general and can be applied to study proteolytic activity in different systems.	colorectal carcinoma;computational complexity theory;constrained optimization;discrepancy function;elegant degradation;genetic algorithm;high- and low-level;inference;merops;mathematical optimization;molecular pathology (discipline);optimization problem;patients;peptide hydrolases;proteomics;seizures;stationary process;stochastic process;tandem mass spectrometry;peptide catabolic process	Piotr Dittwald;Jerzy Ostrowski;Jakub Karczmarski;Anna Gambin	2011		10.1186/1471-2105-13-S5-S7	tandem mass spectrometry;markov chain;dna microarray;mass spectrometry;bioinformatics	Comp.	7.639984140261528	-58.96100409613225	46340
a983f6a903c589ef421be041e59a87a5630f13a4	universal sequence map (usm) of arbitrary discrete sequences	software;statistical mechanics;sequence similarity;sequence analysis dna;distance estimation;computational biology bioinformatics;statistical properties;models genetic;sequence homology nucleic acid;chaos game representation;state space;algorithms;sequence analysis;sequence alignment;combinatorial libraries;computational biology;computer appl in life sciences;markov chains;microarrays;bioinformatics;markov chain	For over a decade the idea of representing biological sequences in a continuous coordinate space has maintained its appeal but not been fully realized. The basic idea is that any sequence of symbols may define trajectories in the continuous space conserving all its statistical properties. Ideally, such a representation would allow scale independent sequence analysis – without the context of fixed memory length. A simple example would consist on being able to infer the homology between two sequences solely by comparing the coordinates of any two homologous units. We have successfully identified such an iterative function for bijective mappingψ of discrete sequences into objects of continuous state space that enable scale-independent sequence analysis. The technique, named Universal Sequence Mapping (USM), is applicable to sequences with an arbitrary length and arbitrary number of unique units and generates a representation where map distance estimates sequence similarity. The novel USM procedure is based on earlier work by these and other authors on the properties of Chaos Game Representation (CGR). The latter enables the representation of 4 unit type sequences (like DNA) as an order free Markov Chain transition table. The properties of USM are illustrated with test data and can be verified for other data by using the accompanying web-based tool: http://bioinformatics.musc.edu/~jonas/usm/ . USM is shown to enable a statistical mechanics approach to sequence analysis. The scale independent representation frees sequence analysis from the need to assume a memory length in the investigation of syntactic rules.	bioinformatics;chaos game;data interpretation, statistical;estimated;homologous gene;homology (biology);inference;iterated function;iterative method;markov chain;mechanics;name;physical object;pierre robin syndrome;rule (guideline);sequence alignment;sequence analysis;state space;state transition table;string (computer science);test data;unit type;web application	Jonas S. Almeida;Susana Vinga	2001		10.1186/1471-2105-3-6	biology;markov chain;statistical mechanics;computer science;bioinformatics;theoretical computer science;algorithm	Comp.	-1.3335423645798394	-55.48555039938698	46350
97ae97139882c3940d6d4f63e227096f6ee80f98	studies in the extensively automatic construction of large odds-based inference networks from structured data. examples from medical, bioinformatics, and health insurance claims data	anomaly detection;bayes net;big data;bioinformatics;clinical decision support;data mining;fraud detection;hyperbolic dirac net;inference net;machine learning	"""Theoretical and methodological principles are presented for the construction of very large inference nets for odds calculations, composed of hundreds or many thousands or more of elements, in this paper generated by structured data mining. It is argued that the usual small inference nets can sometimes represent rather simple, arbitrary estimates. Examples of applications in clinical and public health data analysis, medical claims data and detection of irregular entries, and bioinformatics data, are presented. Construction of large nets benefits from application of a theory of expected information for sparse data and the Dirac notation and algebra. The extent to which these are important here is briefly discussed. Purposes of the study include (a) exploration of the properties of large inference nets and a perturbation and tacit conditionality models, (b) using these to propose simpler models including one that a physician could use routinely, analogous to a """"risk score"""", (c) examination of the merit of describing optimal performance in a single measure that combines accuracy, specificity, and sensitivity in place of a ROC curve, and (d) relationship to methods for detecting anomalous and potentially fraudulent data."""		Barry Robson;Srinidhi Boray	2018	Computers in biology and medicine	10.1016/j.compbiomed.2018.02.013	conditionality;fraudulent data;sparse matrix;data model;computer science;inference;odds;bioinformatics;bra–ket notation	ML	0.29391110616946714	-71.69825035349191	46462
3909bb8f6d03eb05b628fbc0d4668514f7497b1a	bio-inspired visual memory for robot cognitive map building and scene recognition	histograms;robot vision cartography image recognition information retrieval mobile robots;image recognition;information retrieval;mobile robots;visualization neurons histograms robots buildings subspace constraints cognition;subspace constraints;visualization;robot vision;robots;cognition;cartography;neurons;cognitive representation bio inspired visual memory robot cognitive map building scene recognition robotics spatial cognition visual information extraction visual memory building fuzzy art architecture bio inspired model mobile robot;buildings	In this paper, we investigate the feasibility of building a visual memory for robotics spatial cognition without saving visual information. The proposed approach captures some properties of primate brain and especially the view cells. Our bio-inspired visual memory for cognitive map building consists of two main parts. One part is visual information extraction and the other part is the visual memory building using the Fuzzy Art architecture. The results of the current study could contribute to the development of bio-inspired model for cognitive map building which enables the mobile robot to localize itself and build a cognitive representation of its environment simultaneously like primates and humans.	british informatics olympiad;cognition;cognitive map;color space;geographic information system;information extraction;mobile robot;robotics	Karima Rebai;Ouahiba Azouaoui;Nouara Achour	2012	2012 IEEE/RSJ International Conference on Intelligent Robots and Systems	10.1109/IROS.2012.6385493	robot;mobile robot;computer vision;cognition;visualization;computer science;artificial intelligence;histogram	Robotics	24.20777996245215	-63.603851781277534	46478
703bba9670a30b78c012737f03b558be34dfb0d0	rehybridization as a general mechanism for maximizing chemical and supramolecular bonding and a driving force for chemical reactions	cycloaromatization;driving force;stereoelectronic effects;rehybridization;hydrogen bonding;hybridization;chemical reaction;strain;s character	Dynamic variations in hybridization patterns (rehybridization) were analyzed at B3LYP/6-31G** and MP2/6-31+G* levels. Computations clearly illustrate the generality of rehybridization in a variety of chemical phenomena, which involve structural reorganization in hydrogen-bonded complexes, nonhyperconjugative stereoelectronic effects in saturated heterocycles, Mills-Nixon effect, and contrasting substituent effects in cycloaromatization reactions.	chemical phenomena;crossbreeding;hydrogen;mandibular right second molar tooth;nucleic acid hybridization;pyschological bonding	Igor V. Alabugin;Mariappan Manoharan	2007	Journal of computational chemistry	10.1002/jcc.20524	orbital hybridisation;stereochemistry;chemistry;chemical reaction;organic chemistry;computational chemistry;strain;hydrogen bond	Comp.	8.001218519332477	-63.47685754275428	46480
1a3141d51aa822dd0028c3142828bdbf6840ba19	a temperature-dependent quantum mechanical/neural net model for vapor pressure	vapor pressure;temperature dependence;neural net;quantum mechanics	We present a temperature-dependent model for vapor pressure based on a feed-forward neural net and descriptors calculated using AM1 semiempirical MO-theory. This model is based on a set of 7681 measurements at various temperatures performed on 2349 molecules. We employ a 10-fold cross-validation scheme that allows us to estimate errors for individual predictions. For the training set we find a standard deviation of the error s = 0.322 and a correlation coefficient (R(2)) of 0.976. The corresponding values for the validation set are s = 0.326 and R(2) = 0.976. We thoroughly investigate the temperature-dependence of our predictions to ensure that our model behaves in a physically reasonable manner. As a further test of temperature-dependence, we also examine the accuracy of our vapor pressure model in predicting the related physical properties, the boiling point, and the enthalpy of vaporization.	artificial neural network;austin model 1;coefficient;computational chemistry;cross reactions;cross-validation (statistics);data validation;ephrin type-b receptor 1, human;laser ablation;morphology findings domain;physical phenomenon or property;quantum mechanics;semi-empirical quantum chemistry method;standard deviation;test set;vapor	Andrew J. Chalk;Bernd Beck;Timothy Clark	2001	Journal of chemical information and computer sciences	10.1021/ci0103222	chemistry;computer science;machine learning;computational chemistry;physical chemistry;thermodynamics;vapor pressure;artificial neural network;quantum mechanics	ML	12.985452087426092	-57.36900972537821	46509
5c7d83ffac42bbcb6326c5234238a45258822f99	simulations numériques de systèmes biologiques complexes : dynamique, structure et fonction de transporteurs, canaux et enzymes. (numerical simulations of complex biological systems: dynamics, structure and function of transporters, channels and enzymes)			biological system;computer simulation;numerical linear algebra	Marc Baaden	2010				Comp.	3.602329036788673	-65.86105444652537	46516
04b0bc8b6948a8d36b3f86a447f43204947d9277	a comparative study of data fusion for rgb-d based visual recognition		Data fusion from different modalities has been extensively studied for a better understanding of multimedia contents. On one hand, the emergence of new devices and decreasing storage costs cause growing amounts of data being collected. Though bigger data makes it easier to mine information, methods for big data analytics are not well investigated. On the other hand, new machine learning techniques, such as deep learning, have been shown to be one of the key elements in achieving state-of-the-art inference performances in a variety of applications. Therefore, some of the old questions in data fusion are in need to be addressed again for these new changes. These questions are: What is the most effective way to combine data for various modalities? Does the fusion method affect the performance with different classifiers? To answer these questions, in this paper, we present a comparative study for evaluating early and late fusion schemes with several types of SVM and deep learning classifiers on two challenging RGB-D based visual recognition tasks: hand gesture recognition and generic object recognition. The findings from this study provide useful policy and practical guidance for the development of visual recognition systems.		Jordi Sanchez-Riera;Kai-Lung Hua;Yuan-Sheng Hsiao;Tekoing Lim;Shintami Chusnul Hidayati;Wen-Huang Cheng	2016	Pattern Recognition Letters	10.1016/j.patrec.2015.12.006	computer vision;computer science;artificial intelligence;machine learning;pattern recognition;data mining	Vision	24.03653596218382	-57.72976089341021	46558
87fdf9b9423511b7aa2fabbc765a6fe4304f48ef	gene expression-based cross species tissue mapping	computational biology bioinformatics;gene expression;algorithms;combinatorial libraries;computer appl in life sciences;microarrays;bioinformatics	Step 1 – is to get the 28 stages representing the mouse embryo anatomy Step 2 – is to get the expressed genes in these 'tissues', excluding 'house Keeping' genes. This will be somehow based on a score to be decided later for a gene to be classified as 'Expressed gene'. Step 3 – is to look for homologous genes which are expressed in developmental fly. Step 4 – is to find the mapping of tissues in developmental fly. Step 5 – is to establish and save the mapping (if any) in a database.	computational anatomy;database;homology (biology)	Ajit Kumar Gopee	2005	BMC Bioinformatics	10.1186/1471-2105-6-S3-P16	computational biology;biology;gene expression;dna microarray;bioinformatics;genetics	Comp.	2.173199472992661	-61.13616651264409	46573
bacc6a9a4425411da40fe5db12671f317e43ff99	a mathematical model of the gac/rsm quorum sensing network in pseudomonas fluorescens	gene expression network;hysteresis;signal transduction;environmental conditions;time series;quorum sensing;pseudomonas fluorescens;gene expression;information processing;mathematical model;post transcriptional regulation;post transcriptionalregulation;binding protein;network structure;high sensitivity;reporter gene	I present a deterministic model of the dynamics of signal transduction and gene expression in the Gac/Rsm network of the soil-dwelling bacterium Pseudomonas fluorescens. The network is involved in quorum sensing and governs antifungal production in this important biocontrol agent. A central role is played by small untranslated RNAs, which sequester regulatory mRNA-binding proteins. The model provides a reasonable match to the available data, which consists primarily of time series from reporter gene fusions. I use the model to investigate the information-processing properties of the Gac/Rsm network, in part by comparing it to a simplified model capable of quorum sensing. The results suggest that the complexity and redundancy of the Gac/Rsm network have evolved to meet the conflicting requirements of high sensitivity to environmental conditions and a conservative, robust response to variability in parameter values. Similar systems exist in a wide variety of bacteria, where they control a diverse set of population-dependent behaviors. This makes them important subjects for mathematical models that can help link empirical understanding of network structure to theoretical insights into how these networks have evolved to function under natural conditions.		David Brown	2010	Bio Systems	10.1016/j.biosystems.2010.07.004	biology;reporter gene;quorum sensing;gene expression;information processing;hysteresis;bioinformatics;post-transcriptional regulation;time series;mathematical model;microbiology;ecology;genetics;binding protein;signal transduction	Networks	5.779134701925735	-61.051569624656985	46586
1612ef3a0924f55108cea2d84348e6c863f9ecd7	identifying regulational alterations in gene regulatory networks by state space representation of vector autoregressive models and variational annealing	models theoretical;gene regulatory networks;animal genetics and genomics;quinazolines;lung;life sciences general;models statistical;receptor epidermal growth factor;humans;microbial genetics and genomics;proteomics;computational biology;microarrays;plant genetics genomics	In the analysis of effects by cell treatment such as drug dosing, identifying changes on gene network structures between normal and treated cells is a key task. A possible way for identifying the changes is to compare structures of networks estimated from data on normal and treated cells separately. However, this approach usually fails to estimate accurate gene networks due to the limited length of time series data and measurement noise. Thus, approaches that identify changes on regulations by using time series data on both conditions in an efficient manner are demanded. We propose a new statistical approach that is based on the state space representation of the vector autoregressive model and estimates gene networks on two different conditions in order to identify changes on regulations between the conditions. In the mathematical model of our approach, hidden binary variables are newly introduced to indicate the presence of regulations on each condition. The use of the hidden binary variables enables an efficient data usage; data on both conditions are used for commonly existing regulations, while for condition specific regulations corresponding data are only applied. Also, the similarity of networks on two conditions is automatically considered from the design of the potential function for the hidden binary variables. For the estimation of the hidden binary variables, we derive a new variational annealing method that searches the configuration of the binary variables maximizing the marginal likelihood. For the performance evaluation, we use time series data from two topologically similar synthetic networks, and confirm that our proposed approach estimates commonly existing regulations as well as changes on regulations with higher coverage and precision than other existing approaches in almost all the experimental settings. For a real data application, our proposed approach is applied to time series data from normal Human lung cells and Human lung cells treated by stimulating EGF-receptors and dosing an anticancer drug termed Gefitinib. In the treated lung cells, a cancer cell condition is simulated by the stimulation of EGF-receptors, but the effect would be counteracted due to the selective inhibition of EGF-receptors by Gefitinib. However, gene expression profiles are actually different between the conditions, and the genes related to the identified changes are considered as possible off-targets of Gefitinib. From the synthetically generated time series data, our proposed approach can identify changes on regulations more accurately than existing methods. By applying the proposed approach to the time series data on normal and treated Human lung cells, candidates of off-target genes of Gefitinib are found. According to the published clinical information, one of the genes can be related to a factor of interstitial pneumonia, which is known as a side effect of Gefitinib.	autoregressive model;calculus of variations;estimated;gene regulatory network;interstitial webpage;marginal model;mathematical model;mathematics;performance evaluation;pneumonia;pneumonia, interstitial;regulation;scientific publication;simulated annealing;state space;state-space representation;structure of parenchyma of lung;synthetic data;time series;vector autoregression;cancer cell;gefitinib	Kaname Kojima;Seiya Imoto;Rui Yamaguchi;André Fujita;Mai Yamauchi;Noriko Gotoh;Satoru Miyano	2012		10.1186/1471-2164-13-S1-S6	functional genomics;biology;gene regulatory network;dna microarray;bioinformatics;proteomics;genetics;computational and statistical genetics	Comp.	5.92526816379628	-57.80499086791163	46595
348c69499e220b29a319cd977deee05fc42775b6	r2dgc: threshold-free peak alignment and identification for 2d gas chromatography-mass spectrometry in r		Summary Comprehensive 2D gas chromatography-mass spectrometry is a powerful method for analyzing complex mixtures of volatile compounds, but produces a large amount of raw data that requires downstream processing to align signals of interest (peaks) across multiple samples and match peak characteristics to reference standard libraries prior to downstream statistical analysis. Very few existing tools address this aspect of analysis and those that do have shortfalls in usability or performance. We have developed an R package that implements retention time and mass spectra similarity threshold-free alignments, seamlessly integrates retention time standards for universally reproducible alignments, performs common ion filtering and provides compatibility with multiple peak quantification methods. We demonstrate that our package's performance compares favorably to existing tools on a controlled mix of metabolite standards separated under variable chromatography conditions and data generated from cell lines.   Availability and implementation R2DGC can be downloaded at https://github.com/rramaker/R2DGC or installed via the Comprehensive R Archive Network (CRAN).   Contact sjcooper@hudsonalpha.org.   Supplementary information Supplementary data are available at Bioinformatics online.	align (company);alignment;archive;bioinformatics;complex mixtures;computer performance;cultured cell line;downstream (software development);gas chromatography;gas chromatography-mass spectrometry;geographic information systems;ions;libraries;medical device incompatibility problem;neural network simulation;quantitation;r language;reference standards;standard library;usability;mixture;standards characteristics	Ryne C. Ramaker;Emily R. Gordon;Sara J. Cooper	2018	Bioinformatics	10.1093/bioinformatics/btx825	downstream processing;mass spectrum;computer science;filter (signal processing);gas chromatography–mass spectrometry;two-dimensional gas;bioinformatics;mass spectrometry	Comp.	-2.4937743625859574	-57.641075688221136	46597
5de40904962abbcd320fa9012603e523befa574e	parameter estimation of kinetic rates in stochastic reaction networks by the em method	parameter estimation kinetic theory stochastic processes maximum likelihood estimation testing random variables computational modeling biomedical engineering biomedical informatics iterative algorithms;expectation maximisation method parameter estimation kinetic rate constants stochastic reaction networks em method gillespie s algorithm;em method;iterative algorithms;maximum likelihood;parameter estimation stochastic reaction network kinetic rate constants;random variables;testing;maximum likelihood estimation;discrete observation;stochastic reaction networks;reaction rate constants;kinetic rate constants;computational modeling;kinetic theory;biomedical engineering;rate constant;stochastic processes;expectation maximisation method;stochastic reaction network;stochastic processes biochemistry parameter estimation reaction rate constants;parameter estimation;kinetics;gillespie s algorithm;biomedical informatics;biochemistry	Gillespie's algorithm serves to simulate a network of stochastic reactions with given initial quantities and kinetic rate constants. In this paper we consider the estimation of the kinetic rate constants of the reactions based on a set of discrete observations generated by Gillespie's algorithm. In particular, we present an Expectation Maximisation (EM) method to perform maximum likelihood estimation of the rate constants. Applicability of the method is tested on a simple reaction network.	estimation theory;expectation–maximization algorithm;gillespie algorithm;hoc (programming language);ms-dos;mathematical optimization;simulation	András Horváth;Daniele Manini	2008	2008 International Conference on BioMedical Engineering and Informatics	10.1109/BMEI.2008.237	health informatics;stochastic process;econometrics;mathematical optimization;computer science;tau-leaping;mathematics;kinetic monte carlo;maximum likelihood;statistics	Robotics	10.559853294441265	-67.818321833789	46621
667ee46b4bba48085e869a2a326777f1b77aa07b	efficient bayesian detection of disease onset in truncated medical data		This paper describes a principled statistical methodof preprocessing incidentally collected electronic medical recordsto facilitate short-term predictions of disease onset withoutexplicit interaction with patients (e.g., medical tests, questionnaires). The model is also applicable to detection of remission. In incidentally collected data, records are possibly left and righttruncated - the first time an event of interest is seen in a patient'sdata may not be the first time in the patient's history that ithappened. It is therefore difficult to know if a disease onsethappens in a given history. If we are unable to determine ifand when the onset occurs, supervised learning and regressionapproaches cannot be applied.Our method determines if an onset occurs in a set of sparseand incomplete patient records, calculates the time of this onsetand provides a principled measure of confidence. It combinesindividual patient history with expectations computed from areference population. We compare the proposed method againststandard change detection algorithms on generated data withrealistic event sparsity and show that it can reliably detect onsetswhere traditional methods fail. We then go on to apply thealgorithm to a large corpus of U.S. Medicare data and show thatthe algorithm scales to large datasets efficiently. The algorithmis currently in trials at a large medical informatics company.	algorithm;disease ontology;informatics;onset (audio);preprocessor;sparse matrix;supervised learning;text corpus	Bob Price;Lottie Price;Dylan Cashman;Marzieh Nabi	2017	2017 IEEE International Conference on Healthcare Informatics (ICHI)	10.1109/ICHI.2017.10	medical history;supervised learning;preprocessor;change detection;data mining;disease;health informatics;machine learning;population;artificial intelligence;medicine;bayesian probability	ML	4.2568627878569565	-75.09031644718831	46667
f852114247361f1755d3789fef0899eba8f63ed3	detection of m-sequences from spike sequence in neuronal networks	animals;models neurological;rats;hippocampus;time factors;cells cultured;rats wistar;nerve net;neurons;action potentials	"""In circuit theory, it is well known that a linear feedback shift register (LFSR) circuit generates pseudorandom bit sequences (PRBS), including an M-sequence with the maximum period of length. In this study, we tried to detect M-sequences known as a pseudorandom sequence generated by the LFSR circuit from time series patterns of stimulated action potentials. Stimulated action potentials were recorded from dissociated cultures of hippocampal neurons grown on a multielectrode array. We could find several M-sequences from a 3-stage LFSR circuit (M3). These results show the possibility of assembling LFSR circuits or its equivalent ones in a neuronal network. However, since the M3 pattern was composed of only four spike intervals, the possibility of an accidental detection was not zero. Then, we detected M-sequences from random spike sequences which were not generated from an LFSR circuit and compare the result with the number of M-sequences from the originally observed raster data. As a result, a significant difference was confirmed: a greater number of """"0-1"""" reversed the 3-stage M-sequences occurred than would have accidentally be detected. This result suggests that some LFSR equivalent circuits are assembled in neuronal networks."""	5' untranslated regions;action potentials;action potential;arabic numeral 0;brain–computer interface;cell culture techniques;computation;error-tolerant design;large;linear-feedback shift register;multiple endocrine neoplasia;network analysis (electrical circuits);pseudorandom binary sequence;pseudorandom number generator;pseudorandomness;raster data;shift register device component;smart-m3;time series;physiological aspects	Yoshi Nishitani;Chie Hosokawa;Yuko Mizuno-Matsumoto;Tomomitsu Miyoshi;Hajime Sawai;Shinichi Tamura	2012		10.1155/2012/862579	psychology;neuroscience;theoretical computer science;hippocampus;mathematics;action potential;algorithm	ML	16.812767137744665	-71.23620768088288	46689
fcaa1d7b5a03609ad376bdd6421669e194fe2409	beyond human recognition: a cnn-based framework for handwritten character recognition	training;error analysis;distortion;machine learning;neurons;character recognition	Because of the various appearance (different writers, writing styles, noise, etc.), the handwritten character recognition is one of the most challenging task in pattern recognition. Through decades of research, the traditional method has reached its limit while the emergence of deep learning provides a new way to break this limit. In this paper, a CNN-based handwritten character recognition framework is proposed. In this framework, proper sample generation, training scheme and CNN network structure are employed according to the properties of handwritten characters. In the experiments, the proposed framework performed even better than human on handwritten digit (MNIST) and Chinese character (CASIA) recognition. The advantage of this framework is proved by these experimental results.	computation;computational resource;computer vision;deep learning;emergence;experiment;handwriting recognition;human reliability;image resolution;mnist database;machine learning;optical character recognition;pattern recognition	Li Chen;Song Wang;Wei Fan;Jun Sun;Satoshi Naoi	2015	2015 3rd IAPR Asian Conference on Pattern Recognition (ACPR)	10.1109/ACPR.2015.7486592	speech recognition;intelligent character recognition;computer science;artificial intelligence;intelligent word recognition;communication;neocognitron	Vision	22.857045242493506	-53.779386848026334	46696
b2fb830f83d62960bb2153d5f7e4097208039669	novel h/aca box snorna mining and secondary structure prediction algorithms	secondary structure prediction;h aca box snorna;ensemble learning;mfe minimum free energy;class imbalance;minimum free energy;learning methods;cross validation;gene mining;bioinformatics	In this paper we propose a novel H/ACA box snoRNA gene mining algorithm, which is based on ensemble learning and a special secondary structure prediction algorithm. Three contributions are made to improve current mining methods, including enriching the negative training set, using the ensemble classifiers for the class imbalance data, and developing a special secondary structure prediction algorithm for extracting features with high quality. The performance of learning method is proved by cross validation and the mining method is proved by the experiments on genome data.	algorithm;american cryptogram association	Quan Zou;Maozu Guo;Chun-yu Wang;Yingpeng Han;Wenbin Li	2009		10.1007/978-3-642-02962-2_68	computer science;bioinformatics;machine learning;data mining;ensemble learning;cross-validation	ML	10.108670944373133	-53.65521119930697	46746
8b5edf826341220306badbe2ee3c6712d74b1950	discovering aberrant patterns of human connectome in alzheimer's disease via subgraph mining	subgraph mining human connectome diffusion tensor imaging alzheimer s disease;graph theory;brain;tensile stress;biodiffusion;humans data mining dementia tensile stress imaging;data mining;medical image processing biodiffusion biomedical mri brain data mining diseases graph theory;medical image processing;human connectome;imaging;subgraph mining;alzheimer s disease;diseases;dementia;fiber connectivity based way human connectome aberrant pattern discovery alzheimer disease subgraph mining age related dementia diffusion weighted imaging dwi white matter fiber human brain disrupted spatial patterns data mining framework diffusion tractography fiber density fractional anisotropy structural brain connectivity patterns unweighted graph series disrupted subgraph patterns data driven approach grey matter changes large scale structural brain networks;humans;diffusion tensor imaging;biomedical mri	Alzheimer's disease (AD) is the most common cause of age-related dementia, which prominently affects the human connectome. Diffusion weighted imaging (DWI) provides a promising way to explore the organization of white matter fiber tracts in the human brain in a non-invasive way. However, the immense amount of data from millions of voxels of a raw diffusion map prevent an easy way to utilizable knowledge. In this paper, we focus on the question how we can identify disrupted spatial patterns of the human connectome in AD based on a data mining framework. Using diffusion tractography, the human connectomes for each individual subject were constructed based on two diffusion derived attributes: fiber density and fractional anisotropy, to represent the structural brain connectivity patterns. Then, these humanconnectomes were further mapped into a series of unweighted graphs by discretization. After frequent sub graph mining, the abnormal score was finally defined to identify disrupted sub graph patterns in patients. Experiments demonstrated that our data-driven approach, for the first time, allows identifying selective spatial pattern changes of the human connectome in AD that perfectly matched grey matter changes of the disease. Our findings further bring new insights into how AD propagates and disrupts the regional integrity of large-scale structural brain networks in a fiber connectivity-based way.	algorithm;alzheimer's disease neuroimaging initiative;data mining;diffusion map;discretization;experiment;fractional anisotropy;human connectome project;spatiotemporal pattern;structure mining;voxel	Junming Shao;Qinli Yang;Afra M. Wohlschläger;Christian Sorg	2012	2012 IEEE 12th International Conference on Data Mining Workshops	10.1109/ICDMW.2012.9	diffusion mri;bioinformatics;artificial intelligence;graph theory;data mining;mathematics;stress	ML	23.05608105290975	-78.38238380197703	46747
25205d79297cabb3000466f0b28fb59f33a7b0ba	unraveling adaptation in eukaryotic pathways: lessons from protocells	escherichia coli;evolutionary adaptation;signal transduction;intracellular receptors;models biological;chemotaxis;methylation;eukaryota;adaptation physiological;membrane receptor signaling;dictyostelium;transmembrane receptors;computational biology;sensory receptors;artificial cells	Eukaryotic adaptation pathways operate within wide-ranging environmental conditions without stimulus saturation. Despite numerous differences in the adaptation mechanisms employed by bacteria and eukaryotes, all require energy consumption. Here, we present two minimal models showing that expenditure of energy by the cell is not essential for adaptation. Both models share important features with large eukaryotic cells: they employ small diffusible molecules and involve receptor subunits resembling highly conserved G-protein cascades. Analyzing the drawbacks of these models helps us understand the benefits of energy consumption, in terms of adjustability of response and adaptation times as well as separation of cell-external sensing and cell-internal signaling. Our work thus sheds new light on the evolution of adaptation mechanisms in complex systems.	acclimatization;complex systems;conserved sequence;protocells;benefit	Giovanna De Palo;Robert G. Endres	2013		10.1371/journal.pcbi.1003300	biology;cell biology;bioinformatics;methylation;escherichia coli;chemotaxis;genetics;signal transduction;adaptation	ML	6.766711753689767	-63.834825246115955	46766
0dae493162d7de27916f62593a27d6cf9c3de432	summary measurements and screening procedures in clinical trials: a large simulation study	clinical trial		simulation	Morton B. Brown;Camil Fuchs	1998	Sci. Ann. Cuza Univ.		biomedical engineering;theoretical computer science;clinical trial;computer science	ML	2.6054627493403313	-71.7964463543708	46787
aecba9fd48e3172e640eb4515dcf9d1e684e342c	methods and strategies for construction of a phylogeny-adaptive hormone response element consensus model	dna;biology computing;sex steroids;regulation of gene expression;sex steroid hormones;biochemistry dna predictive models biological system modeling sequences proteins gene expression nuclear facility regulation erbium humans;nucleotides;receptor binding;training;statistical model;genetics;gene expression;sensitivity;adaptation model;proteins;statistical analysis;machine learning;hormone response element;transcription factor;molecular biophysics;experimental validation;statistical analysis biology computing genetics learning artificial intelligence molecular biophysics proteins;predictive models;phylogeny adaptive model;learning artificial intelligence;false positive;phylogenetic relationship;statistical model phylogeny adaptive model sex steroid hormones hormone receptors dna gene expression transcription factor nucleotides machine learning hormone response element;hormone receptors;pulse width modulation;biochemistry	Sex steroid hormones receptors bind to regions of the DNA called hormone response elements (HREs), in order to facilitate the regulation of gene expression. While the biological, functional and molecular basis of this interaction between the response elements and their corresponding transcription factor is not fully understood, the sequences of these HREs are known to be conserved for certain nucleotides. Machine learning processes have enabled researchers to predict and identify HREs in a quick and efficient manner. We had previously constructed a statistical model for HRE prediction from approximately 700 experimentally validated HRE sequences. To see if we can improve the performance of our statistical model for HRE prediction, we propose a phylogeny-adaptive model for HRE detection which takes into account the phylogenetic relationship of the sequences. The results of our analysis show that the new model ensures minimal false positive predictions.	experiment;machine learning;phylogenetics;statistical model;transcription (software)	Jesslyn Saw;Maria Stepanova;Lin Feng	2008	2008 IEEE Symposium on Computational Intelligence in Bioinformatics and Computational Biology	10.1109/CIBCB.2008.4675774	hormone receptor;hormone response element;statistical model;biology;nucleotide;regulation of gene expression;gene expression;type i and type ii errors;sensitivity;bioinformatics;pulse-width modulation;predictive modelling;ligand;genetics;dna;transcription factor;molecular biophysics	Comp.	6.825176622554883	-57.955280328619544	46819
232a41375a15523f20e5aa5b66f341f002e7aefc	characterization of binding sites of eukaryotic transcription factors	promoter;gene regulation;binding site;jiang qian jimmy lin donald j zack 真核细胞 生物信息学 转录因子 基因序列 characterization of binding sites of eukaryotic transcription factors;transcription factor;bioinformatics	"""To explore the nature of eukaryotic transcription factor (TF) binding sites and determine how they differ from surrounding DNA sequences, we examined four features associated with DNA-binding sites: G+C content, pattern complexity, palindromic structure, and Markov sequence ordering. Our analysis of the regulatory motifs obtained from the TRANSFAC database, using yeast intergenic sequences as background, revealed that these four features show variable enrichment in motif sequences. For example, motif sequences were more likely to have palindromic structure than were background sequences. In addition, these features were tightly localized to the regulatory motifs, indicating that they are a property of the motif sequences themselves and are not shared by the general promoter """"environment"""" in which the regulatory motifs reside. By breaking down the motif sequences according to the TF classes to which they bind, more specific associations were identified. Finally, we found that some correlations, such as G+C content enrichment, were species-specific, while others, such as complexity enrichment, were universal across the species examined. The quantitative analysis provided here should increase our understanding of protein-DNA interactions and also help facilitate the discovery of regulatory motifs through bioinformatics."""	binding sites;bioinformatics;class;gene ontology term enrichment;interaction;markov chain;medical transcription;mental association;motif;reside;transcription factor;transcription (software)	Jiang Qian;C. Jimmy Lin;Donald J. Zack	2006		10.1016/S1672-0229(06)60019-3	biology;molecular biology;regulation of gene expression;bioinformatics;binding site;genetics;transfac;promoter;dna binding site;transcription factor	Comp.	3.8297025711966493	-60.141131275276344	46865
ed25e0ab3e05ae0356273726bd8378e41c8c2c23	a model-based optimization framework for the inference of regulatory interactions using time-course dna microarray expression data	transcription genetic;regulatory network;rna messenger;time course;spores bacterial;heuristic method;non linear model;genetics;computational biology bioinformatics;models genetic;bacillus anthracis;genetic network;gene expression regulation;models statistical;time varying data;algorithms;dna microarray data;dna microarray;combinatorial libraries;mrna expression;kinetics;genes bacterial;computer appl in life sciences;gene expression profiling;oligonucleotide array sequence analysis;bacterial proteins;microarrays;protein biosynthesis;bioinformatics;dynamic behavior	"""Proteins are the primary regulatory agents of transcription even though mRNA expression data alone, from systems like DNA microarrays, are widely used. In addition, the regulation process in genetic systems is inherently non-linear in nature, and most studies employ a time-course analysis of mRNA expression. These considerations should be taken into account in the development of methods for the inference of regulatory interactions in genetic networks. We use an S-system based model for the transcription and translation process. We propose an optimization-based regulatory network inference approach that uses time-varying data from DNA microarray analysis. Currently, this seems to be the only model-based method that can be used for the analysis of time-course """"relative"""" expressions (expression ratios). We perform an analysis of the dynamic behavior of the system when the number of experimental samples available is varied, when there are different levels of noise in the data and when there are genes that are not considered by the experimenter. Our studies show that the principal factor affecting the ability of a method to infer interactions correctly is the similarity in the time profiles of some or all the genes. The less similar the profiles are to each other the easier it is to infer the interactions. We propose a heuristic method for resolving networks and show that it displays reasonable performance on a synthetic network. Finally, we validate our approach using real experimental data for a chosen subset of genes involved in the sporulation cascade of Bacillus anthracis. We show that the method captures most of the important known interactions between the chosen genes. The performance of any inference method for regulatory interactions between genes depends on the noise in the data, the existence of unknown genes affecting the network genes, and the similarity in the time profiles of some or all genes. Though subject to these issues, the inference method proposed in this paper would be useful because of its ability to infer important interactions, the fact that it can be used with time-course DNA microarray data and because it is based on a non-linear model of the process that explicitly accounts for the regulatory role of proteins."""	bacillus anthracis;cascade device component;dna microarray format;dhrystone;gene regulatory network;genetic translation process;genetic algorithm;heuristic;image noise;inference;interaction;linear model;mathematical optimization;nonlinear system;regulatory feedback network;subgroup;transcription (software);sporulation	Reuben Thomas;Carlos J. Paredes;Sanjay Mehrotra;Vassily Hatzimanikatis;Eleftherios T. Papoutsakis	2006	BMC Bioinformatics	10.1186/1471-2105-8-228	biology;molecular biology;dna microarray;bioinformatics;genetics	Comp.	6.467454032458214	-58.63707512127339	46868
8bbc9424f6f54d0d5a8c061052f8057cc47af8d3	exploring the potential therapeutic mechanism of da-fang-feng-tang for rheumatoid arthritis	databases;arthritis;rheumatoid arthritis traditional chinese medicine da fang feng tang molecular mechanism;chemical compounds;proteins chemical compounds databases arthritis diseases protein engineering immune system;proteins;immune system;diseases;potential therapeutic mechanism disease specified proteins disease specified genes system level regulation chinese herbal formula therapeutic effects signal transduction immune system pathway hierarchies ra omim genes target protein chemical compound compositional herbal medicine potential molecular mechanism bioinformatics analysis knowledge databases molecule mechanism clinical practises clinical effect feng han shi bi syndrome treatment rheumatoid arthritis da fang feng tang;protein engineering;proteins bioinformatics diseases genetics molecular biophysics patient treatment	Da-Fang-Feng-Tang is a Chinese herbal formula designed to treat syndrome Feng-Han-Shi-Bi for rheumatoid arthritis (RA). Although it's clinical effect have been accepted through 1000 years' clinical practises, its molecule mechanism is still obscure. In this study, by integrating powerful knowledge databases, though bioinformatics analysis, we explored the potential molecular mechanism of Da-Fang-Feng-Tang for RA. The molecule mechanism analysis includes compositional herbal medicine, chemical compound, target protein, RA OMIM genes, and enriched pathways. As a result, Da-Feng-Feng-Tang's 7 target proteins were matched in RA's OMIM genes. What's more, these 7 genes are mainly involved in three pathway hierarchies e.g., disease, immune system, and signal transduction. This research demonstrates that Da-Feng-Feng-Tang's target proteins can regulate a wide range of systems associated with RA. This might indicate that Chinese herbal formula's therapeutic effects are taken effects through system-level regulation rather than targeting only disease specified genes or proteins.	bioinformatics;database;gene regulatory network;han unification;online mendelian inheritance in man;risk assessment;traffic collision avoidance system;transduction (machine learning)	Guang Zheng;Huanhuan Shi;Xiaolie Yi;Lingru Wang;Mengmeng Song;Xiaojuan He;Aiping Lu	2014	2014 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)	10.1109/BIBM.2014.6999280	pharmacology;biology;immune system;protein engineering	Comp.	7.460246465719835	-60.62523087394692	46949
5511c33b36c7427a11528301287603e75fc05301	a better oscillation detection method robustly extracts eeg rhythms across brain state changes: the human alpha rhythm as a test case	oscillations;functional form;oscillation;spectrum;power spectrum;human;brain rhythm;time series data;electroencephalography;alpha;modes of operation;independent component	Oscillatory activity is a principal mode of operation in the brain. Despite an intense resurgence of interest in the mechanisms and functions of brain rhythms, methods for the detection and analysis of oscillatory activity in neurophysiological recordings are still highly variable across studies. We recently proposed a method for detecting oscillatory activity from time series data, which we call the BOSC (Better OSCillation detection) method. This method produces systematic, objective, and consistent results across frequencies, brain regions and tasks. It does so by modeling the functional form of the background spectrum by fitting the empirically observed spectrum at the recording site. This minimizes bias in oscillation detection across frequency, region and task. Here we show that the method is also robust to dramatic changes in state that are known to influence the shape of the power spectrum, namely, the presence versus absence of the alpha rhythm, and can be applied to independent components, which are thought to reflect underlying sources, in addition to individual raw signals. This suggests that the BOSC method is an effective tool for measuring changes in rhythmic activity in the more common research scenario wherein state is unknown.	alpha rhythm;bioinformatics open source conference;block cipher mode of operation;documentation;electroencephalography;eye;higher-order function;independence day: resurgence;neural oscillation;normal mode;sensor;spectral density;test case;time series;electrode	Tara A. Whitten;Adam M. Hughes;Clayton T. Dickson;Jeremy B. Caplan	2011	NeuroImage	10.1016/j.neuroimage.2010.08.064	artificial intelligence;control theory;mathematics;communication;oscillation	ML	19.753727895638743	-75.95807741685603	46975
c13d8765aee9fd0b9492b5804edeb83ec7fc347b	the mintact project—intact as a common curation platform for 11 molecular interaction databases	software;ucl;settore bio 18 genetica;discovery;datasets;theses;conference proceedings;binding molecular function;open data movement;digital web resources;internet;ucl discovery;open access;genus mentha;ucl library;book chapters;open access repository;protein interaction mapping;quality control;databases protein;ucl research	IntAct (freely available at http://www.ebi.ac.uk/intact) is an open-source, open data molecular interaction database populated by data either curated from the literature or from direct data depositions. IntAct has developed a sophisticated web-based curation tool, capable of supporting both IMEx- and MIMIx-level curation. This tool is now utilized by multiple additional curation teams, all of whom annotate data directly into the IntAct database. Members of the IntAct team supply appropriate levels of training, perform quality control on entries and take responsibility for long-term data maintenance. Recently, the MINT and IntAct databases decided to merge their separate efforts to make optimal use of limited developer resources and maximize the curation output. All data manually curated by the MINT curators have been moved into the IntAct database at EMBL-EBI and are merged with the existing IntAct dataset. Both IntAct and MINT are active contributors to the IMEx consortium (http://www.imexconsortium.org).	binding (molecular function);database;databases;digital curation;external bus interface;interactome;merge;mint;mimix;open-source software;population;silo (dataset);supply appropriate;web application	Sandra E. Orchard;Mais G. Ammari;Bruno Aranda;Lionel Breuza;Leonardo Briganti;Fiona Broackes-Carter;Nancy H. Campbell;Gayatri Chavali;Carol Chen;Noemi del-Toro;Margaret Duesbury;Marine Dumousseau;Eugenia Galeota;Ursula Hinz;Marta Iannuccelli;Sruthi Jagannathan;Rafael C. Jimenez;Jyoti Khadake	2014		10.1093/nar/gkt1115	quality control;the internet;data curation;bioinformatics	DB	-2.913452720182874	-60.83945737701066	47034
2332f5981b160e7283ed8b66ad93019104c20ac1	absidconvert: an absolute approach for converting genetic identifiers at different granularities	animals;genomics;culicidae;molecular sequence annotation;chromosome mapping;computational biology bioinformatics;internet;genome;algorithms;plasmodium;humans;combinatorial libraries;computational biology;computer appl in life sciences;microarrays;bioinformatics	High-throughput molecular biology techniques yield vast amounts of data, often by detecting small portions of ribonucleotides corresponding to specific identifiers. Existing bioinformatic methodologies categorize and compare these elements using inferred descriptive annotation given this sequence information irrespective of the fact that it may not be representative of the identifier as a whole. All annotations, no matter the granularity, can be aligned to genomic sequences and therefore annotated by genomic intervals. We have developed AbsIDconvert, a methodology for converting between genomic identifiers by first mapping them onto a common universal coordinate system using an interval tree which is subsequently queried for overlapping identifiers. AbsIDconvert has many potential uses, including gene identifier conversion, identification of features within a genomic region, and cross-species comparisons. The utility is demonstrated in three case studies: 1) comparative genomic study mapping plasmodium gene sequences to corresponding human and mosquito transcriptional regions; 2) cross-species study of Incyte clone sequences; and 3) analysis of human Ensembl transcripts mapped by Affymetrix®; and Agilent microarray probes. AbsIDconvert currently supports ID conversion of 53 species for a given list of input identifiers, genomic sequence, or genome intervals. AbsIDconvert provides an efficient and reliable mechanism for conversion between identifier domains of interest. The flexibility of this tool allows for custom definition identifier domains contingent upon the availability and determination of a genomic mapping interval. As the genomes and the sequences for genetic elements are further refined, this tool will become increasingly useful and accurate. AbsIDconvert is freely available as a web application or downloadable as a virtual machine at: http://bioinformatics.louisville.edu/abid/ .	affymetrix;alignment;annotation;bioinformatics;categorization;clone;contingency (philosophy);culicidae;description;ensembl;genome;identifier;inference;interval tree;microarray;molecular biology;ribonucleotides;sensor;throughput;transcript;transcription, genetic;virtual machine;web application	Fahim Mohammad;Robert M. Flight;Benjamin J. Harrison;Jeffrey C. Petruska;Eric C. Rouchka	2012		10.1186/1471-2105-13-229	computational biology;biology;genomics;the internet;dna microarray;bioinformatics;genetics;genome	Comp.	-1.1938112672104466	-58.43840486230992	47037
34199a5a406939db0061a32cc9aad2211d3ce53a	ipd - the immuno polymorphism database	database	The Immuno Polymorphism Database (IPD) (http://www.ebi.ac.uk/ipd/) is a set of specialist databases related to the study of polymorphic genes in the immune system. IPD currently consists of four databases: IPD-KIR, contains the allelic sequences of Killer-cell Immunoglobulin-like Receptors; IPD-MHC, a database of sequences of the Major Histocompatibility Complex of different species; IPD-HPA, alloantigens expressed only on platelets; and IPD-ESTAB, which provides access to the European Searchable Tumour Cell-Line Database, a cell bank of immunologically characterized melanoma cell lines. The IPD project works with specialist groups or nomenclature committees who provide and curate individual sections before they are submitted to IPD for online publication. The IPD project stores all the data in a set of related databases. Those sections with similar data, such as IPD-KIR and IPD-MHC share the same database structure. The sharing of a common database structure makes it easier to implement common tools for data submission and retrieval. The data are currently available online from the website and ftp directory; files will also be made available in different formats to download from the website and ftp server. The data will also be included in SRS, BLAST and FASTA search engines at the European Bioinformatics Institute.		James Robinson;Matthew J. Waller;Peter Stoehr;Steven G. E. Marsh	2005	Nucleic acids research	10.1093/nar/gki032		DB	-2.4639233275306194	-61.04916905998961	47056
7eb328ae74215cc564f51b4e30db32f9205ded50	a rule-based method applied to the imbalanced classification of radiation toxicity		This paper describes a rule-based classifier (DEQAR-C), which is set up by the combination of selected rules after a two-phase process. In the first phase, the rules are generated and sorted for each class, and then a selection is performed to obtain a final list of rules. A real imbalanced dataset regarding the toxicity during and after radiation therapy for prostate cancer has been employed in a comparison with other predictive methods (rule-based, artificial neural networks, trees, Bayesian and logistic regression). DEQAR-C produced excellent results in an evaluation regarding several performance measures (accuracy, Matthews correlation coefficient, sensitivity, specificity, precision, recall and F-measure) and by using crossvalidation. Therefore, it was employed to obtain a predictive model using the full data. The resultant model is easily interpretable, combining three rules with two variables, and suggesting conditions that are mostly confirmed by the medical literature.	artificial neural network;f1 score;logic programming;logistic regression;matthews correlation coefficient;numerical analysis;predictive modelling;resultant;sensitivity and specificity;two-phase commit protocol	Juan L. Domínguez-Olmedo;Jacinto Mata Vázquez;Victoria Pachón;Jose Luis Lopez-Guerra	2018		10.5220/0006586401470155	toxicity;data mining;computer science;rule-based system;radiation	ML	7.860322965572018	-77.33867664139193	47091
1505a9cdba22645f7416cca206db92bfa010aae1	using fixed point theorems to model the binding in protein-protein interactions	mining methods and algorithms;genetique;biology computing;base donnee;interaction proteine proteine;fixed point theorem;genetica;fonction generatrice;mining methods fixed point theorem protein protein interaction biochemical stability protein motif pair bioinformatics genome;database;biochimie;base dato;bioinformatique;biology;biologia;indexing terms;data mining;journal article;genetics;theoreme point fixe;teorema punto fijo;proteins dna stability sequences amino acids genomics bioinformatics biochemistry nuclear magnetic resonance convergence;biology and genetics index terms bioinformatics genome or protein database mining methods and algorithms generating functions stability and instability;fixed point;stability;instability;proteins;fouille donnee;biology and genetics;biology computing proteins genetics data mining;funcion generatriz;protein protein interaction;instabilite;generating function;bioinformatica;inestabilidad;stabilite;protein motif;protein interaction;bioinformatics genome or protein database;index terms bioinformatics genome or protein database;bioquimica;busca dato;biochemistry;stability and instability;estabilidad;biologie;generating functions;bioinformatics;stabilite biochimique	The binding in protein-protein interactions exhibits a kind of biochemical stability in cells. The mathematical notion of fixed points also describes stability. A point is a fixed point if it remains unchanged after a transformation by a function. Many points may not be a fixed point, but they may approach a stable status after multiple steps of transformation. In this paper, we define a point as a protein motif pair consisting of two traditional protein motifs. We propose a function and propose a method to discover stable motif pairs of this function from a large protein interaction, sequence data set. There are many interesting properties for this function (for example, the convergence). Some of them are useful for gaining much efficiency in the discovery of those stable motif pairs; some are useful for explaining why our proposed fixed point theorems are a good way to model the binding of protein interactions. Our results are also compared to biological results to elaborate the effectiveness, of our method.	experiment;fixed point (mathematics);fixed-point theorem;interaction;motif;real life	Jinyan Li;Haiquan Li	2005	IEEE Transactions on Knowledge and Data Engineering	10.1109/TKDE.2005.134	generating function;bioinformatics;algorithm	ML	2.3860807760256555	-60.60443548305379	47115
e37773c2891333e1476f4fa084d0757ffe89ac14	modeling gene regulation and spatial organization of sequence based motifs	time dependent;expression profile;regulatory network;molecular biophysics bioinformatics genetics microorganisms;s cerevisiae;systems biology;gene regulation;gene regulatory networks;regulatory element;transcription factors;sequence based motifs;dynamic program;biology;data type;computational method;motif presence;genetics;gene expression;distance measurement;hill climber;proteins;cluster membership;transcription factor;pipelines;molecular biophysics;system biology;s cerevisiae gene regulation spatial organization sequence based motifs bioinformatics systems biology transcription factors cis regulatory motifs cluster membership gene regulatory networks motif presence spatial motif arrangement transcription start site hill climber inferelator approach;bioinformatics systems biology proteins sequences genomics biological system modeling biology computing dna rna data analysis;computer analysis;transcription start site;correlation;cis regulatory motifs;spatial organization;spatial motif arrangement;gene regulatory network;inferelator approach;microorganisms;dynamic properties;bioinformatics	Reconstructing and modeling regulatory networks is an active area of research in bioinformatics and systems biology. Hence, various computational methods have been published, often successfully modeling one aspect of regulatory control. Gene regulation, however, is a process that depends on many different components such as transcription factors (TFs), cis-regulatory motifs and their temporal and spatial coordination. Accordingly, a promising new direction for computational analysis is the incorporation of multiple data types to discover, for instance, cluster membership, the spatial organization of cis-regulatory motifs and TFs that bind to these motifs. Here, we present such a data-driven framework, comprising four stages, to infer gene regulatory networks (GRNs) by modeling: 1. Motif presence in the promoter; 2. Spatial motif arrangement in co-regulated genes; 3. TFs that bind the respective motifs, and: 4. Dynamic properties of the GRN. A novel method is presented in stage 2, where we optimize for the spatial motif properties: orientation, occurrence of multiple motifs, relative distance between two motifs and distance to the transcription start site (TSS). To find optimal distance based properties in efficient time we describe a dynamic programming approach. To combine multiple motif properties that are shared by genes with similar expression profiles a Hill-climber is employed. Subsequently, in stage 3 and 4, we infer GRNs by assigning TFs to the derived motifs and model time-dependent regulatory relationships between them with the inferelator approach. None of the stages require the user to manually adjust any parameter, and thus derived properties can be analyzed without the bias introduced by parametrization. We applied this approach to S. cerevisiae data and obtained insight into individual and general properties of the spatial assembly of regulatory elements and inferred the corresponding GRN.	bioinformatics;climber (beam);dynamic programming;gene regulatory network;sequence motif;spatial organization;systems biology;transcription (software)	Jochen Supper;C. A. Kampe;Dierk Wanke;Kenneth W. Berendzen;Klaus Harter;R. Bonneau;Andreas Zell	2008	2008 8th IEEE International Conference on BioInformatics and BioEngineering	10.1109/BIBE.2008.4696696	biology;gene regulatory network;bioinformatics;genetics;systems biology;transcription factor	Comp.	4.491374007539449	-59.82140403771388	47205
9bba5800e777f9ea8a3712e74e351b44d36f83da	discriminative bag-of-cells for imaging-genomics		Connecting genotypes to image phenotypes is crucial for a comprehensive understanding of cancer. To learn such connections, new machine learning approaches must be developed for the better integration of imaging and genomic data. Here we propose a novel approach called Discriminative Bag-of-Cells (DBC) for predicting genomic markers using imaging features, which addresses the challenge of summarizing histopathological images by representing cells with learned discriminative types, or codewords. We also developed a reliable and efficient patch-based nuclear segmentation scheme using convolutional neural networks from which nuclear and cellular features are extracted. Applying DBC on TCGA breast cancer samples to predict basal subtype status yielded a class-balanced accuracy of 70% on a separate test partition of 213 patients. As data sets of imaging and genomic data become increasingly available, we believe DBC will be a useful approach for screening histopathological images for genomic markers. Source code of nuclear segmentation and DBC are available at: https://github.com/bchidest/DBC.	extraction;genomics;mammary neoplasms;neural network simulation;patients;phenotype;source code;the cancer genome atlas	Benjamin Chidester;Minh N. Do;Jian Ma	2018	Pacific Symposium on Biocomputing. Pacific Symposium on Biocomputing		genomics;bioinformatics;discriminative model;biology	Comp.	7.992465438119997	-53.008315195163526	47208
02130490af3153110c37e859beee8cc4c8e79f55	quantification of dna by a thermal-durable biosensor modified with conductive poly(3,4-ethylenedioxythiophene)	dna biosensor;electron transfer mediate;gold nanoparticle;poly(3;4-ethylenedioxythiophene)	The general clinical procedure for viral DNA detection or gene mutation diagnosis following polymerase chain reaction (PCR) often involves gel electrophoresis and DNA sequencing, which is usually time-consuming. In this study, we have proposed a facile strategy to construct a DNA biosensor, in which the platinum electrode was modified with a dual-film of electrochemically synthesized poly(3,4-ethylenedioxythiophene) (PEDOT) resulting in immobilized gold nanoparticles, with the gold nanoparticles easily immobilized in a uniform distribution. The DNA probe labeled with a SH group was then assembled to the fabricated electrode and employed to capture the target DNA based on the complementary sequence. The hybridization efficiency was evaluated with differential pulse voltammetry (DPV) in the presence of daunorubicin hydrochloride. Our results demonstrated that the peak current in DPV exhibited a linear correlation the concentration of target DNA that was complementary to the probe DNA. Moreover, the electrode could be reused by heating denaturation and re-hybridization, which only brought slight signal decay. In addition, the addition of the oxidized form of nicotinamide adenine dinucleotide (NAD⁺) could dramatically enhance the sensitivity by more than 5.45-fold, and the limit-of-detection reached about 100 pM.		Yesong Gu;Po-Yuan Tseng;Xiang Bi;Jason H. C. Yang	2018		10.3390/s18113684		Comp.	10.865156794457443	-64.63241319748775	47210
14cf0c6fc1762afac68826ee8a290e47ae645fda	a de novo metagenomic assembly program for shotgun dna reads	high-quality assembly;supplementary data;metagenomic assembly program;assembly approach;sanger sequencing;simulated data;metagenomic data;metagenome project;shotgun sequencing;map program;shotgun dna	MOTIVATION A high-quality assembly of reads generated from shotgun sequencing is a substantial step in metagenome projects. Although traditional assemblers have been employed in initial analysis of metagenomes, they cannot surmount the challenges created by the features of metagenomic data.   RESULT We present a de novo assembly approach and its implementation named MAP (metagenomic assembly program). Based on an improved overlap/layout/consensus (OLC) strategy incorporated with several special algorithms, MAP uses the mate pair information, resulting in being more applicable to shotgun DNA reads (recommended as >200 bp) currently widely used in metagenome projects. Results of extensive tests on simulated data show that MAP can be superior to both Celera and Phrap for typical longer reads by Sanger sequencing, as well as has an evident advantage over Celera, Newbler and the newest Genovo, for typical shorter reads by 454 sequencing.   AVAILABILITY AND IMPLEMENTATION The source code of MAP is distributed as open source under the GNU GPL license, the MAP program and all simulated datasets can be freely available at http://bioinfo.ctb.pku.edu.cn/MAP/	biopolymer sequencing;de novo protein structure prediction;de novo transcriptome assembly;gnu;il31ra gene;metagenome;metagenomics;name;newbler;open-source software;phrap;reading (activity);shotgun sequencing;source code;viral sequencing:prid:pt:ser:nom:sequencing;algorithm;interferon alfacon-1	Binbin Lai;Ruogu Ding;Yang Li;Li Ping Duan;Huaiqiu Zhu	2012	Bioinformatics	10.1093/bioinformatics/bts162	biology;bioinformatics;data mining;sequence assembly;world wide web;hybrid genome assembly	Comp.	-0.1917974729823362	-55.25943062606696	47328
d3cfae0dd3299fd7c0a7b2bca9b36822c4e9e892	deep learning with evolutionary and genomic profiles for identifying cancer subtypes		Cancer subtype identification is an unmet need in precision diagnosis. Recently, evolutionary conservation has been indicated containing understandable signatures for functional significance in cancers. However, the importance of evolutionary conservation in distinguishing cancer subtypes remains unclear. Here, we identified the evolutionarily conserved genes (i.e., core gene) and observed that they are mainly involved in the pathways relevant to cell growth and metabolisms. By using these core genes, we integrated their evolutionary and genomic profiles with deep learning to develop a feature-based strategy (FES) and an image-based strategy (IMS). In comparison with FES using the random set and the strategy using the PAM50 classifier, core gene set-based FES has higher accuracy for identifying breast cancer subtypes. Moreover, the IMS with data augmentation yields better performance than the other strategies. Comprehensive analysis of eight TCGA cancer data demonstrates that our evolutionary conservation-based models provide a valid and helpful approach to identify cancer subtypes and the core gene set offers distinguishable clues of cancer subtypes.		Chun-Yu Lin;Peiying Ruan;Ruiming Li;Jinn-Moon Yang;Simon See;Tatsuya Akutsu	2018	2018 IEEE 18th International Conference on Bioinformatics and Bioengineering (BIBE)	10.1109/BIBE.2018.00035	bioinformatics;conserved sequence;breast cancer;cancer;computer science;computational biology;deep learning;gene;copy number alteration;artificial intelligence	Comp.	7.9987938560258875	-54.60510441619092	47347
0db392d0193b8f2683bf6094bdd71e4fd45d23f5	geometry shapes evolution of early multicellularity	health research;uk clinical guidelines;biological patents;europe pubmed central;citation search;uk phd theses thesis;life sciences;uk research reports;medical journals;europe pmc;biomedical research;bioinformatics	"""Organisms have increased in complexity through a series of major evolutionary transitions, in which formerly autonomous entities become parts of a novel higher-level entity. One intriguing feature of the higher-level entity after some major transitions is a division of reproductive labor among its lower-level units in which reproduction is the sole responsibility of a subset of units. Although it can have clear benefits once established, it is unknown how such reproductive division of labor originates. We consider a recent evolution experiment on the yeast Saccharomyces cerevisiae as a unique platform to address the issue of reproductive differentiation during an evolutionary transition in individuality. In the experiment, independent yeast lineages evolved a multicellular """"snowflake-like"""" cluster formed in response to gravity selection. Shortly after the evolution of clusters, the yeast evolved higher rates of cell death. While cell death enables clusters to split apart and form new groups, it also reduces their performance in the face of gravity selection. To understand the selective value of increased cell death, we create a mathematical model of the cellular arrangement within snowflake yeast clusters. The model reveals that the mechanism of cell death and the geometry of the snowflake interact in complex, evolutionarily important ways. We find that the organization of snowflake yeast imposes powerful limitations on the available space for new cell growth. By dying more frequently, cells in clusters avoid encountering space limitations, and, paradoxically, reach higher numbers. In addition, selection for particular group sizes can explain the increased rate of apoptosis both in terms of total cell number and total numbers of collectives. Thus, by considering the geometry of a primitive multicellular organism we can gain insight into the initial emergence of reproductive division of labor during an evolutionary transition in individuality."""	apoptosis;autonomous robot;biological evolution;cell count;cessation of life;complexity;emergence;entity;labor (childbirth);mathematical model;mathematics;mechanism of cell death;organism;premature obstetric labor;reproduction;saccharomyces cerevisiae;subgroup;benefit;cell growth	Eric Libby;William Ratcliff;Michael Travisano;Ben Kerr	2014		10.1371/journal.pcbi.1003803	biology;medical research;computer science;bioinformatics;genetics	ML	4.7981141283677635	-62.31120474546491	47349
805f83c0d2f4cf01863a45feec62de34e4ac7b66	evidential data mining for length of stay (los) prediction problem	patient traces evidential data mining los prediction problem healthcare planning optimization healthcare organization cost minimization itemset support association rule confidence evidential length of stay prediction algorithm elosa hospital resource management hospital resource planning hospital dataset;association rules hospitals itemsets prediction algorithms;association rule;evidential data mining;evidential data mining los association rule evidential database;medical information systems data mining hospitals inference mechanisms;los;evidential database	Hospitals need to optimize their healthcare planning and organization to minimize costs. The indicator that is often used to measure the efficiency in hospital is the average length of stay. Many studies show a strong and obvious correlation between the costs of patients and the impatient Length Of Stay (LOS). In this paper, We propose to apply data mining techniques to predict the LOS. An evidential variant of data mining, called also evidential data mining, have been used to reduce the impact of uncertainty and missing data. New measures of itemset support and association rule confidence are applied. We introduce the Evidential Length Of Stay prediction Algorithm (ELOSA) that allow the prediction of the length of stay of a new patient. Therefore, the inpatient length of stay (LOS) can be predicted efficiently, the planning and management of hospital resources can be greatly enhanced. The proposal is evaluated on a real hospital dataset using 270 patient traces.	algorithm;association rule learning;data mining;database;experiment;futures studies;missing data;operations research;scheduling (computing);tracing (software)	Issam Nouaouri;Ahmed Samet;Hamid Allaoui	2015	2015 IEEE International Conference on Automation Science and Engineering (CASE)	10.1109/CoASE.2015.7294296	engineering;data science;pattern recognition;data mining	Robotics	4.587907451735431	-76.91624315198266	47385
b357576afb70465e47144aef96955b1e4b9cc1f7	oriented response networks		Deep Convolution Neural Networks (DCNNs) are capable of learning unprecedentedly effective image representations. However, their ability in handling significant local and global image rotations remains limited. In this paper, we propose Active Rotating Filters (ARFs) that actively rotate during convolution and produce feature maps with location and orientation explicitly encoded. An ARF acts as a virtual filter bank containing the filter itself and its multiple unmaterialised rotated versions. During back-propagation, an ARF is collectively updated using errors from all its rotated versions. DCNNs using ARFs, referred to as Oriented Response Networks (ORNs), can produce within-class rotation-invariant deep features while maintaining inter-class discrimination for classification tasks. The oriented response produced by ORNs can also be used for image and object orientation estimation tasks. Over multiple state-of-the-art DCNN architectures, such as VGG, ResNet, and STN, we consistently observe that replacing regular filters with the proposed ARFs leads to significant reduction in the number of network parameters and improvement in classification performance. We report the best results on several commonly used benchmarks.	acoustic radiation force;artificial neural network;backpropagation;baseline (configuration management);benchmark (computing);convolution;encode;experiment;filter bank;ibm notes;map;software propagation;super-twisted nematic display	Yanzhao Zhou;Qixiang Ye;Qiang Qiu;Jianbin Jiao	2017	2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)	10.1109/CVPR.2017.527	computer vision;machine learning;convolutional code;artificial neural network;residual neural network;pattern recognition;artificial intelligence;filter bank;active filter;convolution;computer science;object-orientation	Vision	20.931013216667978	-52.12120207627405	47389
dcbd00c2051a60274d55c6dc11e79274e52ef533	fluctuation of population in penna model	sexual reproduction;asexual reproduction;gaussian peak;male breeding;typical realisation	In this communication, the fluctuation of the population of a colony is studied for three processes of reproduction: cloning, meiotic parthenogenesis and sexual reproduction. We find that the magnitude of fluctuation is nearly the same for the three cases. Also, for cloning and sexual reproduction, the fluctuation of population for a particular realisation of a colony is much smaller than the fluctuation of the mean population for different realisations, while for meiotic parthenogenesis the two fluctuations are closer in magnitude.	quantum fluctuation	Subinay Dasgupta	2001	Theory in Biosciences	10.1007/s12064-001-0029-5	biology;zoology;sexual reproduction;ecology;genetics	DB	3.584565345514811	-62.510495442658836	47415
4e2e07158c19e4a4596ed66bd252d9d05eb601ba	pattern recognition by labeled graph matching	graph matching;pattern recognition	"""-A model for position invariant pattern recognition is presented. Although not demonstrated here, the system is insensitive to distortions. Recognition is based on labeled graph matching. The system consists of two layers of neurons, an input layer, and a memory and recognition layer. The latter consists of subnets to represent individual patterns. In both layers, patterns are represented by labeled graphs. Nodes are """"'neurons,"""" labels are local feature types, links are implemented by excitatory connections and represent topology. Recognition is driven by spontaneous dynamic activations of local clusters in the input layer. Network dynamics is able to selectively activate with good reliability corresponding clusters in memory layer Few cluster activations suffice to identify the subnet and pattern corresponding to the graph in the input layer The system has been implemented and tested with the help of simulations. One of the driving forces for the present wave of interest in neural networks is the prospect of practical applications. Classical concepts of computer science and artificial intelligence need further development in the direction of self-organization and massive parallelism. This is what neural networks seem to be offering. The availability of cheap processing power on massively parallel machines will permit the expansion of scale of neural networks from demonstrations of principle to more realistic applications. In this process of expansion a number of difficulties with neural systems will surface. One of these has to do with the great variability of natural scenes which are to be processed as input. If neural systems are to absorb information from one scene and apply it to another, they have to be capable of generalization. Important types of generalization can be based on the decomposition of scenes into standard objects and on object recognition invariant under certain transformations. Speaking of the visual modality, important transformations are translation, dilatation, rotation, and distortion, the latter mainly due to changes in perspective. The solution of these and other problems involved in scene analysis may necessitate new conceptual developments or even modifications to neural architecture. This paper tries to contribute to Requests for reprints should be sent to Christoph vonder Malsburg, Computer Science Department, University of Southern California, Los Angeles, CA 90089-0782. 141 that goal. It presents a specific kind of neural architecture to solve the problem of invariant object recognition. It is a further development of a model presented earlier (Bienenstock, 1988; von der Malsburg & Bienenstock, 1987). INVARIANT PATTERN RECOGNITION IN NEURAL ARCHITECTURE Associative Memory (Anderson, 1970; Cooper, 1974; Hopfield, 1982; Kohonen, 1977; Palm, 1980; Steinbuch, 1961; Willshaw, Buneman, & Longuet-Higgins, 1969) has a number of properties which qualify it as an important neural paradigm. Among these is its ability to generalize over Hamming distance. One aspect of this is pattern completion. Translation invariance, on the other hand, is not among these properties. It is not feasible to solve this problem by exhaustively storing all different transformed representations of a given object. This is extremely uneconomical and it is unclear how this multiplicity of patterns could be stored. Either all transformed versions of the object would have to be shown to the system, a ridiculous proposal, or else all transformed versions somehow would have to be automatically produced within the system after it has seen a single representative. A way out of the difficulty is the introduction of multilayer structures in which input data are preprocessed. This has first been proposed by Rosenblatt ( 1961 ) in the form of his """"four-layer perceptron."""" This"""	artificial intelligence;artificial neural network;bidirectional associative memory;computer memory;computer science;distortion;frank rosenblatt;graph (discrete mathematics);graph labeling;hamming distance;higgins;hopfield network;matching (graph theory);modality (human–computer interaction);outline of object recognition;parallel computing;pattern recognition;perceptron;programming paradigm;self-organization;simulation;spatial variability;spontaneous order;subnetwork;teuvo kohonen	Christoph von der Malsburg	1988	Neural Networks	10.1016/0893-6080(88)90016-0	computer science;theoretical computer science;machine learning;pattern recognition;mathematics;matching	ML	21.477912408972145	-65.85778784071925	47476
8167c11fa2ee8ca55201a4c74c99283d360436bf	proteome analysis of bronchoalveolar lavage in pulmonary langerhans cell histiocytosis	health research;uk clinical guidelines;biological patents;health informatics;europe pubmed central;citation search;uk phd theses thesis;life sciences;uk research reports;medical journals;europe pmc;biomedical research;biomedicine general;bioinformatics	Pulmonary Langerhans-cell histiocytosis (PLCH) is a rare interstitial lung disease characterized by clusters of Langerhans cells, organized in granulomas, in the walls of distal bronchioles. It is a diffuse lung disease related to tobacco smoking but otherwise of unknown etiopathogenesis. In this study we used a proteomic approach to analyze BAL protein composition of patients with PLCH and of healthy smoker and non-smoker controls to obtain insights into the pathogenetic mechanisms of the disease, to study the effect of cigarette smoking on susceptibility to PLCH and to identify potential new biomarkers. Two-dimensional electrophoresis and image analysis revealed proteins that were differently expressed (quantitatively and qualitatively) in the three groups of subjects. The proteins were identified by mass spectrometry and have various functions (antioxidant, proinflammatory, antiprotease) and origins (plasma, locally produced, etc.). Many, such as protease inhibitors (human serpin B3) and antioxidant proteins (glutathione peroxidase and thioredoxin) are already linked to PLCH pathogenesis, whereas other proteins have never been associated with the disease. Interestingly, numerous proteolytic fragments of plasma proteins (including kininogen-1 N fragments and haptoglobin) were also identified and suggest increased proteolytic activity in this inflammatory lung disease. Differences in protein expression were found between the three groups and confirmed by Principal Component Analysis (PCA). Analysis of BAL proteomes of PLCH patients and of smoker and non-smoker controls also proved to be useful for researching the pathogenetic mechanisms and for identifying biomarkers of this rare diffuse lung disease.	biological markers;bronchioles;cell (microprocessor);cigarette smoke (substance);electrophoresis;endopeptidases;glutathione peroxidase;granuloma;haptoglobins;histiocytosis;ibm basic assembly language and successors;image analysis;interstitial webpage;irrigation;kininogen-1, human;leukemia, b-cell;lung diseases;national origin;patients;plasma active;principal component analysis;protease inhibitors;proteome;proteomics;serpins;spectrometry;tobacco smoking behavior;walls of a building	Claudia Landi;Elena Bargagli;Barbara Magi;Antje Prasse;Joachim Muller-Quernheim;Luca Bini;Paola Rottoli	2011		10.1186/2043-9113-1-31	health informatics;medical research;medicine;pathology;bioinformatics;nursing;immunology	Comp.	5.686362648002362	-61.41827054890247	47480
ae2ba0455219ed12579d1e6a556e032480a9613d	relating tribological stimuli to somatosensory electroencephalographic responses	tribology biomechanics electroencephalography touch physiological;tribological stimuli tactile stimulation human fingertip tribometer electroencephalographic data somatosensory cortex signal to noise ratio 2d anisotropic denoising schemes gabor frames erp extraction event related single trials p100 component brain responses lateral forces somatosensory electroencephalographic responses;correlation electroencephalography force noise reduction friction electrodes signal to noise ratio	The present study deals with the extraction of neural correlates evoked by tactile stimulation of the human fingertip. A reciprocal sliding procedure was performed using a home-built tribometer while simultaneously electroencephalographic (EEG) data from the somatosensory cortex was recorded. The tactile stimuli were delivered by a sliding block with equidistant, perpendicular ridges. The experiments were designed and performed in a fully passive way to prevent attentional locked influences from the subjects. In order to improve the signal-to-noise ratio (SNR) of event related single-trials (ERPs), nonlocal means in addition to 2D-anisotropic denoising schemes based on tight Gabor frames were applied. This novel approach allowed for an easier extraction of ERP alternations. A negative correlation between the latency of the P100 component of the resulting brain responses and the intensity of the underlying lateral forces was found. These findings lead to the conclusion that an increasing stimulus intensity results in a decreasing latency of the brain responses.	consciousness;erp;electroencephalography;experiment;fingertip dosing unit;frame (physical object);gabor filter;lateral thinking;noise reduction;nonlocal lagrangian;signal-to-noise ratio;somatosensory cortex;video denoising	Novaf Oezguen;J. Kristof Schubert;Ronny Bergmann;Roland Bennewitz;Daniel J. Strauss	2015	2015 37th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)	10.1109/EMBC.2015.7320277	psychology;computer vision;neuroscience;communication	Robotics	16.985391089319545	-80.00524449065777	47496
05eb3a2aa8be1a93e56fcd6d99de259dacfda31d	method for adult cardiomyocyte long-term viability monitoring using confocal microscopy techniques	optical microscopy biomedical optical imaging calcium cardiology cellular biophysics fluorescence image classification medical image processing;fluorescence lifetime measurement adult cardiomyocyte long term viability monitoring confocal microscopy myocytes cell viability cell functionality periodic time intervals viability kits live dead cell imaging kit calcein photobleaching calcium degradation;image resolution monitoring	Freshly isolated myocytes lose their viability and functionality very early, from single hours to single days. So their viability is usually tested before the experiments or monitored continuously in periodic time intervals. But simple observations using viability kits (e. g. LIVE / DEAD Cell Imaging Kit, Life Technologies) for this purpose are not sufficient because of Calcein photobleaching and furthermore repeated testing is not possible. In this paper we tested advanced methods based on Calcium degradation and fluorescence lifetime measurement or cardiomyocyte shape properties calculations.	elegant degradation;experiment	Vratislav Cmiel;Jan Odstrcilík;Ondrej Svoboda;Larisa Baiazitova;Ivo Provazník	2015	2015 Computing in Cardiology Conference (CinC)	10.1109/CIC.2015.7411072	biology;analytical chemistry;nanotechnology;biological engineering	Robotics	12.487552134898907	-65.7159005626255	47577
b2187197279a763b00aedf62bab48b7e1003f328	a comparative study of the feature selection influence on diagnosis in traditional chinese medicine	databases;bayesian network;learning algorithm;comparative analysis;markov processes accuracy bayesian methods databases classification algorithms machine learning algorithm design and analysis;decision tree;high dimensionality;traditional chinese medicine;bayesian methods;accuracy;quantitative diagnosis traditional chinese medicine feature selection syndrome differentiation;machine learning;feature selection algorithm;diagnostic model;learning algorithm traditional chinese medicine diagnostic model decision tree bayesian network feature selection algorithm;syndrome differentiation;classification algorithms;prediction accuracy;medicine;feature selection;markov processes;decision trees;medicine decision trees;quantitative method;quantitative diagnosis;algorithm design and analysis	As a complementary and alternative system to Western medicine, traditional Chinese medicine (TCM) forms an integrated and unique approach to treat diseases. In response to the subjectivity and fuzziness of TCM, quantitative methods are needed. In TCM, the symptoms are often high dimensional and the redundant and irrelevant symptoms may degrade the performance of classifiers. Therefore, a critical procedure in syndrome differentiation is identifying a representative set of features from which to construct a diagnostic model. Then one central problem in diagnosis is how the feature selection can influence the predictive accuracy. This problem was addressed in this work and a comparative analysis of seven important different feature selection methods is performed incorporating with learning algorithms. Two machine learning algorithms were used: decision tree (DT) and Bayesian networks (BNs). We utilize feature selection algorithm prior to the learning phase. The conclusions were evaluated by experiments on a clinical sample database for diagnosing apoplexy syndrome.	bayesian network;decision tree;experiment;feature selection;genetic algorithm;machine learning;qualitative comparative analysis;relevance;selection algorithm;toolkit for conceptual modeling	Hui-Yan Wang	2010	2010 International Conference on Machine Learning and Cybernetics	10.1109/ICMLC.2010.5581014	traditional chinese medicine;computer science;machine learning;decision tree;pattern recognition;data mining;feature selection;statistics	AI	6.112692570838263	-76.59277533159892	47613
50fc59278ce1f2b6c5d42e13e5c002f9fefd7718	using chemical reaction kinetics to predict optimal antibiotic treatment strategies		Identifying optimal dosing of antibiotics has proven challenging-some antibiotics are most effective when they are administered periodically at high doses, while others work best when minimizing concentration fluctuations. Mechanistic explanations for why antibiotics differ in their optimal dosing are lacking, limiting our ability to predict optimal therapy and leading to long and costly experiments. We use mathematical models that describe both bacterial growth and intracellular antibiotic-target binding to investigate the effects of fluctuating antibiotic concentrations on individual bacterial cells and bacterial populations. We show that physicochemical parameters, e.g. the rate of drug transmembrane diffusion and the antibiotic-target complex half-life are sufficient to explain which treatment strategy is most effective. If the drug-target complex dissociates rapidly, the antibiotic must be kept constantly at a concentration that prevents bacterial replication. If antibiotics cross bacterial cell envelopes slowly to reach their target, there is a delay in the onset of action that may be reduced by increasing initial antibiotic concentration. Finally, slow drug-target dissociation and slow diffusion out of cells act to prolong antibiotic effects, thereby allowing for less frequent dosing. Our model can be used as a tool in the rational design of treatment for bacterial infections. It is easily adaptable to other biological systems, e.g. HIV, malaria and cancer, where the effects of physiological fluctuations of drug concentration are also poorly understood.	antibiotics;bacterial infections;biological system;experiment;hiv;kinesiology;kinetics (discipline);malaria;mathematical model;mathematics;onset (audio);population;explanation	Pia Abel zur Wiesch;Fabrizio Clarelli;Ted Cohen	2017		10.1371/journal.pcbi.1005321	genetics;biology;socioeconomics;arctic	ML	8.476943321042377	-66.61748548385881	47653
93caeb4585f3ecbd2f106b63a369b7976bf6698c	a kinetic mechanism inducing oscillations in simple chemical reactions networks	eigenvalues and eigenfunctions;oscillations;functional form;bifurcation;chemical reaction network;oscillators;cofactor action oscillations chemical reactions networks kinetic reaction network;cofactor action;chemical reactions networks;kinetic theory;kinetic reaction network;kinetic theory chemicals eigenvalues and eigenfunctions steady state bifurcation biological materials circadian rhythm fungi genetics oscillators;oscillations chemical reactions;chemical reactions;kinetics;jacobian matrices;article;inhibitors;steady state	It is known that a kinetic reaction network in which one or more secondary substrates are acting as cofactors may exhibit an oscillatory behavior. The aim of this work is to provide a description of the functional form of such a cofactor action guaranteeing the onset of oscillations in sufficiently simple reaction networks.	higher-order function;onset (audio)	Julien Coatléven;Claudio Altafini	2008	2008 47th IEEE Conference on Decision and Control	10.1109/CDC.2008.4739206	oscillation	Vision	7.926418555310847	-65.88418407003748	47800
266bf6f1890ec7f7a247c24ced823af1cb504b93	cabs-dock web server for the flexible docking of peptides to proteins without prior knowledge of the binding site	software;peptides;binding sites;internet;proteins;protein conformation;molecular docking simulation	Protein-peptide interactions play a key role in cell functions. Their structural characterization, though challenging, is important for the discovery of new drugs. The CABS-dock web server provides an interface for modeling protein-peptide interactions using a highly efficient protocol for the flexible docking of peptides to proteins. While other docking algorithms require pre-defined localization of the binding site, CABS-dock does not require such knowledge. Given a protein receptor structure and a peptide sequence (and starting from random conformations and positions of the peptide), CABS-dock performs simulation search for the binding site allowing for full flexibility of the peptide and small fluctuations of the receptor backbone. This protocol was extensively tested over the largest dataset of non-redundant protein-peptide interactions available to date (including bound and unbound docking cases). For over 80% of bound and unbound dataset cases, we obtained models with high or medium accuracy (sufficient for practical applications). Additionally, as optional features, CABS-dock can exclude user-selected binding modes from docking search or to increase the level of flexibility for chosen receptor fragments. CABS-dock is freely available as a web server at http://biocomp.chem.uw.edu.pl/CABSdock.	binding sites;boat dock;cell physiology;docking (molecular);docking -molecular interaction;elsevier biobase;internet backbone;largest;peptide sequence;server (computer);server (computing);silo (dataset);simulation;staphylococcal protein a;vertebral column;web server;algorithm;bleomycin/doxorubicin/lomustine/streptozocin protocol;receptor	Mateusz Kurcinski;Michal Jamróz;Maciej Blaszczyk;Andrzej Kolinski;Sebastian Kmiecik	2015		10.1093/nar/gkv456	biology;protein structure;the internet;searching the conformational space for docking;bioinformatics;binding site	Comp.	9.94719575849693	-58.95694143566076	47825
e3453eec99e5a0b3b239c206f93dc7e35e6f3830	informing brain connectivity with optogenetic functional magnetic resonance imaging	connectome;fmri;optogenetics;ofmri;connectivity	Optogenetic functional magnetic resonance imaging (ofMRI) is a novel approach that combines optogenetic control of neural circuits with high-field functional MRI. Optogenetics is a neuro-modulation technology in which light-activated trans-membrane conductance regulators are introduced into specifically targeted cell types to allow temporally precise, millisecond-scale activity modulation in vivo. By combining optogenetic control with fMRI readout, neural activity arising from specific circuit elements defined by genetic identity, cell body location, and axonal projection targets can be monitored in vivo across the whole brain. These unique features of ofMRI open new vistas for in vivo characterization of the dense plexus of neural connections according to their type and functionality.	anatomic structures;bridging (networking);conductance (graph);delta-sigma modulation;dynamic connectivity;futures studies;genetic distance;global network;interaction;magnetic resonance imaging;optogenetics;plexus;reporting;sensitivity and specificity;source-to-source compiler;tissue membrane;video-in video-out;cell body;fmri;neuronal signal transduction	Jin Hyung Lee	2012	NeuroImage	10.1016/j.neuroimage.2012.01.116	psychology;neuroscience;connectivity;connectome;optogenetics	ML	19.54649352253908	-75.58048225495035	47831
69e4702d0123b35079d1333fd616b4e200b2334c	insights into molecular basis of cytochrome p450 inhibitory promiscuity of compounds		Cytochrome P450 inhibitory promiscuity of a drug has potential effects on the occurrence of clinical drug-drug interactions. Understanding how a molecular property is related to the P450 inhibitory promiscuity could help to avoid such adverse effects. In this study, an entropy-based index was defined to quantify the P450 inhibitory promiscuity of a compound based on a comprehensive data set, containing more than 11,500 drug-like compounds with inhibition against five major P450 isoforms, 1A2, 2C9, 2C19, 2D6, and 3A4. The results indicated that the P450 inhibitory promiscuity of a compound would have a moderate correlation with molecular aromaticity, a minor correlation with molecular lipophilicity, and no relations with molecular complexity, hydrogen bonding ability, and TopoPSA. We also applied an index to quantify the susceptibilities of different P450 isoforms to inhibition based on the same data set. The results showed that there was a surprising level of P450 inhibitory promiscuity even for substrate specific P450, susceptibility to inhibition follows the rank-order: 1A2 > 2C19 > 3A4 > 2C9 > 2D6. There was essentially no correlation between P450 inhibitory potency and specificity and minor negative trade-offs between P450 inhibitory promiscuity and catalytic promiscuity. In addition, classification models were built to predict the P450 inhibitory promiscuity of new chemicals using support vector machine algorithm with different fingerprints. The area under the receiver operating characteristic curve of the best model was about 0.9, evaluated by 5-fold cross-validation. These findings would be helpful for understanding the mechanism of P450 inhibitory promiscuity and improving the P450 inhibitory selectivity of new chemicals in drug discovery.		Feixiong Cheng;Yue Yu;Yadi Zhou;Zhonghua Shen;Wen Xiao;Guixia Liu;Weihua Li;Philip W. Lee;Yun Tang	2011	Journal of chemical information and modeling	10.1021/ci200317s	biochemistry;stereochemistry;chemistry	ML	9.155603402575348	-60.030990142071865	47838
4c0656195b5efcdd3aa7bdcb55fc95a957c150aa	egene: a configurable pipeline generation system for automated sequence analysis	use;lenguaje programacion;programming language;automatisation;methode;automatizacion;utilisation;element is;is element;construccion;elemento is;documentacion;uso;langage programmation;sequence analysis;metodo;method;construction;lenguaje formal;formal language;documentation;automation;langage formel	UNLABELLED EGene is a generic, flexible and modular pipeline generation system that makes pipeline construction a modular job. EGene allows for third-party programs to be used and integrated according to the needs of distinct projects and without any previous programming or formal language experience being required. EGene comes with CoEd, a visual tool to facilitate pipeline construction and documentation. A series of components to build pipelines for sequence processing is provided.   AVAILABILITY http://www.lbm.fmvz.usp.br/egene/   CONTACT alan@ime.usp.br; argruber@usp.br   SUPPLEMENTARY INFORMATION http://www.lbm.fmvz.usp.br/egene/	documentation;formal language;generic drugs;pipeline (computing);sequence analysis	Alan M. Durham;André Yoshiaki Kashiwabara;Fernando T. G. Matsunaga;Paulo H. Ahagon;Flávia Rainone;Leonardo Varuzza;Arthur Gruber	2005	Bioinformatics	10.1093/bioinformatics/bti424	formal language;method;construction;documentation;computer science;automation;sequence analysis;algorithm	PL	-4.541039115080722	-56.1470979903938	47839
55b90b9cfe31b7d65fbbd7ff7b970b214414d66d	slider—maximum use of probability information for alignment of short sequence reads and snp detection	probability;databases nucleic acid;base pair mismatch;time factors;algorithms;humans;sequence alignment;base sequence;computational biology;polymorphism single nucleotide	MOTIVATION A plethora of alignment tools have been created that are designed to best fit different types of alignment conditions. While some of these are made for aligning Illumina Sequence Analyzer reads, none of these are fully utilizing its probability (prb) output. In this article, we will introduce a new alignment approach (Slider) that reduces the alignment problem space by utilizing each read base's probabilities given in the prb files.   RESULTS Compared with other aligners, Slider has higher alignment accuracy and efficiency. In addition, given that Slider matches bases with probabilities other than the most probable, it significantly reduces the percentage of base mismatches. The result is that its SNP predictions are more accurate than other SNP prediction approaches used today that start from the most probable sequence, including those using base quality.	alignment;base;curve fitting;gene prediction;nitroprusside;probability;problem domain;reading (activity);retinoblastoma protein	Nawar Malhis;Yaron S. N. Butterfield;Martin Ester;Steven J. M. Jones	2009	Bioinformatics	10.1093/bioinformatics/btn565	biology;multiple sequence alignment;computer science;bioinformatics;sequence alignment;probability;data mining;genetics;alignment-free sequence analysis;statistics	Comp.	0.026748693251764284	-54.25244801203316	47863
97f202a8a37ac731fd4b2c1ca1c06c7ce4b10c8d	eulerian path methods for multiple sequence alignment	dna;biology computing;sequences;sequences genetics biology computing dna;dna sequence determination eulerian path method multiple sequence alignment genome sequence database heuristic algorithm;sequences dna bioinformatics assembly biology mathematics genomics databases heuristic algorithms computational modeling;genetics;de bruijn graph;multiple sequence alignment;dna sequence;heuristic algorithm;genome sequence	With the rapid increase in the size of genome sequence databases, the multiple sequence alignment problem is increasingly important and often requires the alignment of a large number of sequences. Beginning in 1975, many heuristic algorithms have been created to improve the speed of computation and the quality of alignment. We introduce a novel approach that is fundamentally distinct from all currently available methods. Our motivation comes from the Eulerian method for fragment assembly in DNA sequence determination, that transforms all the DNA sequencing fragments into a de Bruijn graph and then reduces sequence assembly to a Eulerian path problem. This lecture focuses on global multiple alignment of DNA sequences, where entire sequences are aligned into one configuration. The main result is an algorithm with almost linear computational speed with respect to the total size (number of letters) of sequences to be aligned. In a simulation, 500 sequences (averaging 500 bases per sequence and as low as 70% pairwise identity) have been aligned within 3 minutes on a personal computer while the quality of alignment is satisfactory. As a result, accurately and simultaneously aligning thousands of long sequences within a reasonable amount of time becomes possible. Data from an Arabidopsis sequencing project is used to demonstrate the performance. Proceedings of the Computational Systems Bioinformatics (CSB’03) 0-7695-2000-6/03 $17.00 © 2003 IEEE	algorithm;bioinformatics;computation;database;de bruijn graph;euler method;eulerian path;heuristic;multiple sequence alignment;personal computer;sequence assembly;simulation	Michael S. Waterman;Yu Zhang	2003		10.1109/CSB.2003.1227296	heuristic;biology;de bruijn graph;dna sequencing;whole genome sequencing;multiple sequence alignment;bioinformatics;theoretical computer science;sequence analysis;k-mer;sequence alignment;dna sequencing theory;sequence;genetics;dna;alignment-free sequence analysis	Comp.	-1.1896149718633606	-52.3930130053722	47904
01f7d898bb536d3d47fd952dc53f5e1eaf25ff10	development of exposome correlations globes to map out environment-wide associations		"""The environment plays a major role in influencing diseases and health. The phenomenon of environmental exposure is complex and humans are not exposed to one or a handful factors but potentially hundreds factors throughout their lives. The exposome, the totality of exposures encountered from birth, is hypothesized to consist of multiple inter-dependencies, or correlations, between individual exposures. These correlations may reflect how individuals are exposed. Currently, we lack methods to comprehensively identify robust and replicated correlations between environmental exposures of the exposome. Further, we have not mapped how exposures associated with disease identified by environment-wide association studies (EWAS) are correlated with other exposures. To this end, we implement methods to describe a first """"exposome globe"""", a comprehensive display of replicated correlations between individual exposures of the exposome. First, we describe overall characteristics of the dense correlations between exposures, showing that we are able to replicate 2,656 correlations between individual exposures of 81,937 total considered (3%). We document the correlation within and between broad a priori defined categories of exposures (e.g., pollutants and nutrient exposures). We also demonstrate utility of the exposome globe to contextualize exposures found through two EWASs in type 2 diabetes and all-cause mortality, such as exposure clusters putatively related to smoking behaviors and persistent pollutant exposure. The exposome globe construct is a useful tool for the display and communication of the complex relationships between exposure factors and between exposure factors related to disease status."""	behavior;categories;diabetes mellitus;diabetes mellitus, non-insulin-dependent;environmental exposure;humans;mental association;nsa product types;self-replication;virtual globe;pollutant	Chirag J. Patel;Arjun K. Manrai	2015	Pacific Symposium on Biocomputing. Pacific Symposium on Biocomputing			HCI	6.386949942535052	-71.40715130686281	47932
d449eeb30aff498c2e375915e70d479048f0766f	scaling-up perception-action links: evidence from synchronization with individual and joint action	article letter to editor	How do we map joint actions we participate in onto joint actions we observe others performing, such as when a couple dancing tango observes another couple dancing tango? We investigated this question using a task in which participants were instructed to perform individual or joint movements in synchrony with individual or joint movements observed on a computer screen. The observed movements started slowly and then continuously increased in tempo (from 1.75 Hz to 3 Hz). The results showed that, with regard to spatial parameters, joint performance was more accurate when observing joint action than when observing individual action (Experiments 1, 1a, and 1b). Individual performance was more accurate when observing individual action than when observing joint action (Experiments 3 and 4). There were no systematic differences with regard to timing parameters. These results suggest that mechanisms of temporal coordination may be less susceptible to differences between individual and joint action than mechanisms of spatial matching.	computer monitor;experiment;hertz (hz);maxillary right third molar abutment;movement;tango;test scaling	Verónica C. Ramenzoni;Natalie Sebanz;Günther Knoblich	2013	Journal of experimental psychology. Human perception and performance	10.1037/a0036925	psychology;communication	Robotics	15.449658646645954	-77.25845495519981	48024
c9eb3e4f310edf46a4c0633da1999b68f21a0b1f	webqtl - web-based complex trait analysis		WebQTL is a website that combines databases of complex traits with fast software for mapping quantitative trait loci (QTLs) and for searching for correlations among traits. WebQTL also includes well-curated genotype data for five sets of mouse recombinant inbred (RI) lines. Thus, to identify QTLs, users need provide only quantitative trait data from one of the supported populations. The WebQTL databases include both biological traits--neuroanatomical, pharmacological, and behavioral traits--and microarray-based gene expression data from BXD RI lines. A search function finds correlations between RNA expression and biological traits, and mapping functions find QTLs for either type of trait. The WebQTL service is available at http://www.webqtl.org/.		Jintao Wang;Robert W. Williams;Kenneth F. Manly	2003	Neuroinformatics	10.1385/NI:1:4:299		Comp.	1.284381590642999	-59.43216612289361	48036
937e0a54a7f9c72fb580266d2e831ffd3c5baa06	evaluation of placement techniques for dna probe array layout	cost effectiveness;nucleotides;greedy algorithm;dna;vlsi;dna chip;gene expression;genetic engineering;combinatorial chemistry;single nucleotide polymorphism;photolithography	"""DNA probe arrays have emerged as a core genomic technology thatenables cost-effective gene expression monitoring, mutation detection,single nucleotide polymorphism analysis and other genomicanalyses. DNA chips are manufactured through a highly scalableprocess, Very Large-Scale Immobilized Polymer Synthesis (VL-SIPS),that combines photolithographic technologies adapted fromthe semiconductor industry with combinatorial chemistry. Commerciallyavailable DNA chips contain more than a half millionprobes and are expected to exceed one hundred million probes inthe next generation. This paper is one of the first attempts to applyVLSI CAD methods to the problem of probe placement in DNAchips, where the main objective is to minimize total border cost(i.e., the number of nucleotide mismatches between adjacent sites).We make the following contributions. First, we propose severalpartitioning-based algorithms for DNA probe placement thatimprove solution quality by over 4% compared to best previouslyknown methods. Second, we give a simple in-place probe re-embeddingalgorithm with solution quality better than previous""""chessboard"""" and batched greedy algorithms. Third, we experimentallyevaluate scalability and suboptimality of existing and newlyproposed probe placement algorithms. Interestingly, we find thatDNA placement algorithms appear to have better suboptimalityproperties than those recently reported for VLSI placement algorithms."""		Andrew B. Kahng;Ion I. Mandoiu;Sherief Reda;Xu Xu;Alex Zelikovsky	2003		10.1145/996070.1009901	single-nucleotide polymorphism;genetic engineering;electronic engineering;greedy algorithm;nucleotide;gene expression;cost-effectiveness analysis;dna microarray;bioinformatics;very-large-scale integration;photolithography;dna	EDA	-0.5315875553746147	-53.895557801986385	48104
4b2298bb52979670cf4581c60db8f4d653e26f45	on the distinguishability of hrf models in fmri	experimental paradigm;model selection;fmri;bold fmri;hrf;distinguishability	The problem of model falsification or model invalidation appears in several areas where we are interested in distinguishing among an eligible set of dynamic systems. In the context of fMRI studies of brain activity, modeling the haemodynamic response function (HRF) is a critical step. The estimation of the dynamic system describing a biophysical model of the HRF may leave much uncertainty on the exact values of the parameters. Moreover, the high noise levels in the data may hinder the model identification task. Therefore, this paper proposes a systematic tool to address the problem of the distinguishability among a set of physiologically plausible HRF models. The concept of absolutely input distinguishable systems is introduced and applied to the HRF model, by exploiting the structure of the underlying nonlinear dynamic system. A strategy to model uncertainty in the input time delay and magnitude is developed and its impact on the distinguishability of two physiologically plausible HRF models is determined, in terms of the maximum noise amplitude above which it is not possible to guarantee the falsification of one model in relation to the other. Finally, a methodology is proposed for the choice of the input sequence, or experimental paradigm, that should be used in order to maximize the distinguishability of the HRF models under investigation. The proposed approach may be used to assess the performance of HRF model identification techniques from fMRI data.	broadcast delay;design of experiments;dynamical system;electroencephalography;expectation–maximization algorithm;experiment;experimental design;frequency response;hemodynamics;mathematical optimization;noise (electronics);nonlinear dynamics;nonlinear system;programming paradigm;system identification;fmri	Paulo Andre Nobre Rosa;Patricia Figueiredo;Carlos Silvestre	2010		10.3389/fncom.2015.00054	computer science;artificial intelligence;data mining;model selection;statistics	SE	21.63550912494281	-73.55673603812203	48183
0b836498e9e76e88a65faadb547b6588df03ceee	a general definition and nomenclature for alternative splicing events	5 utr;software;dna transcription;relative position;animals;genomics;alternative splicing;caenorhabditis elegans;mice;rna splice sites;rats;genome annotation;introns;dogs;bees;invertebrate genomics;databases genetic;graphs;info eu repo semantics article;terminology as topic;cluster analysis;zebrafish;cattle;chickens;drosophila melanogaster;pan troglodytes;xenopus;humans;sequence alignment;sequence analysis rna;molecular mechanics;gene expression profiling;science biology grn;species specificity	"""Understanding the molecular mechanisms responsible for the regulation of the transcriptome present in eukaryotic cells is one of the most challenging tasks in the postgenomic era. In this regard, alternative splicing (AS) is a key phenomenon contributing to the production of different mature transcripts from the same primary RNA sequence. As a plethora of different transcript forms is available in databases, a first step to uncover the biology that drives AS is to identify the different types of reflected splicing variation. In this work, we present a general definition of the AS event along with a notation system that involves the relative positions of the splice sites. This nomenclature univocally and dynamically assigns a specific """"AS code"""" to every possible pattern of splicing variation. On the basis of this definition and the corresponding codes, we have developed a computational tool (AStalavista) that automatically characterizes the complete landscape of AS events in a given transcript annotation of a genome, thus providing a platform to investigate the transcriptome diversity across genes, chromosomes, and species. Our analysis reveals that a substantial part--in human more than a quarter-of the observed splicing variations are ignored in common classification pipelines. We have used AStalavista to investigate and to compare the AS landscape of different reference annotation sets in human and in other metazoan species and found that proportions of AS events change substantially depending on the annotation protocol, species-specific attributes, and coding constraints acting on the transcripts. The AStalavista system therefore provides a general framework to conduct specific studies investigating the occurrence, impact, and regulation of AS."""	alternative splicing;annotation;astalavista.box.sk;chromosomes;code;contribution;database;databases;greater than;intrinsic drive;pipeline (computing);rna splicing;rodent nomenclature name;splice (system call);splicing rule;transcript;transcriptome;notation	Michael Sammeth;Sylvain Foissac;Roderic Guigó	2008	PLoS Computational Biology	10.1371/journal.pcbi.1000147	biology;intron;five prime untranslated region;genomics;zebrafish information network genome database;molecular mechanics;bioinformatics;alternative splicing;sequence alignment;gene expression profiling;cluster analysis;graph;genome project;transcription;genetics	Comp.	3.3079414075865565	-59.94977464370925	48198
8f26cc4d2c138ce05dab3a3bd05c0c814e256ece	information decomposition in bivariate systems: theory and application to cardiorespiratory dynamics	heart rate variability;transfer entropy;information dynamics;dynamical systems;cardiorespiratory interactions;multivariate autoregressive processes;causality	In the framework of information dynamics, the temporal evolution of coupled systems can be studied by decomposing the predictive information about an assigned target system into amounts quantifying the information stored inside the system and the information transferred to it. While information storage and transfer are computed through the known self-entropy (SE) and transfer entropy (TE), an alternative decomposition evidences the so-called cross entropy (CE) and conditional SE (cSE), quantifying the cross information and internal information of the target system, respectively. This study presents a thorough evaluation of SE, TE, CE and cSE as quantities related to the causal statistical structure of coupled dynamic processes. First, we investigate the theoretical properties of these measures, providing the conditions for their existence and assessing the meaning of the information theoretic quantity that each of them reflects. Then, we present an approach for the exact computation of information dynamics based on the linear Gaussian approximation, and exploit this approach to characterize the behavior of SE, TE, CE and cSE in benchmark systems with known dynamics. Finally, we exploit these measures to study cardiorespiratory dynamics measured from healthy subjects during head-up tilt and paced breathing protocols. Our main result is that the combined evaluation of the measures of information dynamics allows to infer the causal effects associated with the observed OPEN ACCESS Entropy 2015, 17 278 dynamics and to interpret the alteration of these effects with changing experimental conditions.	approximation;benchmark (computing);bivariate data;causal filter;causality;computation;cross entropy;dual total correlation;entropy (information theory);information theory;self-information;systems theory;test engineer;transfer entropy	Luca Faes;Alberto Porta;Giandomenico Nollo	2015	Entropy	10.3390/e17010277	dynamical systems theory;heart rate variability;simulation;causality;transfer entropy;artificial intelligence;machine learning;mathematics;statistics	ML	21.891697727284182	-75.324669608027	48215
f26b0a719286b9685c4ac686996357e9da2a6201	evolutionary computation-based memetic algorithm against genetic algorithm to improve pcr-rflp assay primers of snp genotyping		A genetic algorithm (GA) combines the restriction enzyme mining core of single nucleotide polymorphism (SNP) restriction fragment length polymorphism (RFLP) to design polymerase chain reaction (PCR)-RFLP primer pairs for SNP-based genotyping with feasible estimated GA parameters. However, this GA method is easily trapped into local optima. An improved design of PCR-RFLP assay primers for SNP genotyping is needed. A memetic algorithm (MA) was used to design more robust primers for the PCR-RFLP assay to enable SNP genotyping. The novel restriction enzymes hunting (REHUNT) package was embedded into the MA method to provide available restriction enzymes. A formula to calculate more accurate thermodynamic primer melting temperatures was also introduced. Using the criteria of the GA method, in silico simulations for the MA method under different parameter settings were performed with the SNPs of SLC6A4, and results were compared. Appropriate MA parameter settings were superior in providing robust PCR-RFLP primers to achieve SNP genotyping compared with the GA method. Improvements included an accurate thermodynamic SantaLucia’s formula for the calculation of melting temperature, use of the novel REHUNT for restriction enzymes mining, and selection of primers that better conformed to the primer constraints. The appropriate parameter settings for the proposed MA method were identified and carefully evaluated to design robust PCR-RFLP primers for SNP genotyping. Compared with the former GA method, the MA method is more feasible for PCR-RFLP SNP genotyping.		Yu-Huei Cheng;Ching-Ming Lai;Jiashen Teh;Che-Nan Kuo	2018	IEEE Access	10.1109/ACCESS.2018.2884189	genotyping;single-nucleotide polymorphism;snp;restriction fragment length polymorphism;distributed computing;snp genotyping;restriction enzyme;computer science;memetic algorithm;bioinformatics;polymerase chain reaction	Comp.	1.0019042559745857	-56.12458346818709	48271
2c34adfda14b9c3d8ad72efab2dab72df44b8171	set-relevance determines the impact of distractors on episodic memory retrieval		We investigated the interplay between stimulus-driven attention and memory retrieval with a novel interference paradigm that engaged both systems concurrently on each trial. Participants encoded a 45-min movie on Day 1 and, on Day 2, performed a temporal order judgment task during fMRI. Each retrieval trial comprised three images presented sequentially, and the task required participants to judge the temporal order of the first and the last images (“memory probes”) while ignoring the second image, which was task irrelevant (“attention distractor”). We manipulated the content relatedness and the temporal proximity between the distractor and the memory probes, as well as the temporal distance between two probes. Behaviorally, short temporal distances between the probes led to reduced retrieval performance. Distractors that at encoding were temporally close to the first probe image reduced these costs, specifically when the distractor was content unrelated to the memory probes. The imaging results associated the distractor probe temporal proximity with activation of the right ventral attention network. By contrast, the precuneus was activated for high-content relatedness between distractors and probes and in trials including a short distance between the two memory probes. The engagement of the right ventral attention network by specific types of distractors suggests a link between stimulus-driven attention control and episodic memory retrieval, whereas the activation pattern of the precuneus implicates this region in memory search within knowledge/content-based hierarchies.	distance;interference (communication);memory disorders;memory, episodic;programming paradigm;relevance;structure of precuneus;fmri	Sze Chai Kwok;Tim Shallice;Emiliano Macaluso	2014	Journal of Cognitive Neuroscience	10.1162/jocn_a_00601	psychology;cognitive psychology;communication;social psychology	Vision	16.070883415846307	-76.62383714165135	48366
0ba1bd76f2acad77d48efadd54d778fa5d3f9b3d	combining diffusion and hetesim features for accurate prediction of protein-lncrna interactions	lncrnas	Identifying the interactions between proteins and Long non-coding RNAs (lncRNAs) can provide valuable clues for understanding the mechanisms and physiological functions of lncRNAs. In this work, we propose a computational method, PLIPCOM, which can accurately detect protein-lncRNA interactions by integrating two groups of network features. Low dimensional diffusion characteristics and HeteSim features are combined to build the protein-lncRNA interaction predictor using the Gradient Tree Boosting (GTB) algorithm. In a cross-validation experiment on the benchmark data set, our PLIPCOM method substantially outperformed previous state-of-the-art approaches in predicting the interactions between proteins and lncRNAs.	algorithm;benchmark (computing);cross-validation (statistics);gradient boosting;interaction;kerrison predictor	Junqiang Wang;Yun Xiao;Zixiang Wang;Weihua Zhan;Lei Lei Deng	2017	2017 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)	10.1109/BIBM.2017.8217630	artificial intelligence;bioinformatics;machine learning;boosting (machine learning);computer science;genomics;heterogeneous network	Visualization	9.148147533679635	-55.08551434388642	48388
4e7e3b9e808136785b2716fef83ba0f67d5278d4	neural networks for molecular sequence classification	back propagation;associative memory;nucleic acid;database search;artificial neural network;feed forward;sequence analysis;ribosomal rna;neural network;singular value decomposition	A neural network classification method has been developed as an alternative approach to the search/organization problem of large molecular databases. Two artificial neural systems have been implemented on a Cray supercomputer for rapid protein/nucleic acid sequence classifications. The neural networks used are three-layered, feed-forward networks that employ back-propagation learning algorithm. The molecular sequences are encoded into neural input vectors by applying an n-gram hashing method or a SVD (singular value decomposition) method. Once trained with known sequences in the molecular databases, the neural system becomes an associative memory capable of classifying unknown sequences based on the class information embedded in its neural interconnections. The protein system, which classifies proteins into PIR (Protein Identification Resource) superfamilies, showed a 82% to a close to 100% sensitivity at a speed that is about an order of magnitude faster than other search methods. The pilot nucleic acid system, which classifies ribosomal RNA sequences according to phylogenetic groups, has achieved a 100% classification accuracy. The system could be used to reduce the database search time and help organize the molecular sequence databases. The tool is generally applicable to any databases that are organized according to family relationships.	algorithm;backpropagation;biological neural networks;cell nucleus;classification;content-addressable memory;databases;databases, molecular;embedded system;embedding;n-gram;neural network simulation;nucleic acids;phylogenetics;protein information resource;published database;rna;sequence database;singular value decomposition;software propagation;anatomical layer;gram;supercomputer	Cathy H. Wu;Michael W. Berry;Yuk-Shing Fung;Jerry McLarty	1993	Proceedings. International Conference on Intelligent Systems for Molecular Biology		nucleic acid;homology;database search engine;rna;ribosomal rna;biological classification;nucleic acid sequence;bioinformatics;artificial intelligence;backpropagation;machine learning;sequence analysis;time delay neural network;singular value decomposition;dna;feed forward;artificial neural network	ML	11.07929599798359	-53.73964810786135	48497
6fd4182abf9b3190ddc55485fde69de146ab6602	word learning in 6-month-olds: fast encoding–weak retention	tests;lexical semantics;memory testing;neurology;semantics;associative learning;diagnostic tests;developmental stages;vocabulary development;declarative memory;infants;brain structure;word learning;retention psychology;brain activation;brain hemisphere functions;memory	There has been general consensus that initial word learning during early infancy is a slow and time-consuming process that requires very frequent exposure, whereas later in development, infants are able to quickly learn a novel word for a novel meaning. From the perspective of memory maturation, this shift in behavioral development might represent a shift from slow procedural to fast declarative memory formation. Alternatively, it might be caused by the maturation of specific brain structures within the declarative memory system that may support lexical mapping from the very first. Here, we used the neurophysiological method of ERPs to watch the brain activity of 6-month-old infants, when repeatedly presented with object–word pairs in a cross-modal learning paradigm. We report first evidence that infants as young as 6 months are able to associate objects and words after only very few exposures. A memory test 1 day later showed that infants did not fully forget this newly acquired knowledge, although the ERP effects indicated it to be less stable than immediately after encoding. The combined results suggest that already at 6 months the encoding process of word learning is based on fast declarative memory formation, but limitations in the consolidation of declarative memory diminish the long lasting effect in lexical-semantic memory at that age.	anatomical maturation;erp;electroencephalography;lung consolidation;memory disorders;memory tester;microsoft word for mac;modal logic;programming paradigm;semiconductor consolidation	Manuela Friedrich;Angela D. Friederici	2011	Journal of Cognitive Neuroscience	10.1162/jocn_a_00002	psychology;cognitive psychology;lexical semantics;neurology;developmental psychology;developmental stage theories;semantics;linguistics;encoding specificity principle;declarative memory;memory;communication;diagnostic test;vocabulary development;implicit memory	ML	17.18379431998315	-78.28801853994628	48586
9e9cedf5205723723838c1f4ac0254bf27ec43f9	ipeap: integrating multiple omics and genetic data for pathway enrichment analysis		UNLABELLED A challenge in biodata analysis is to understand the underlying phenomena among many interactions in signaling pathways. Such study is formulated as the pathway enrichment analysis, which identifies relevant pathways functional enriched in high-throughput data. The question faced here is how to analyze different data types in a unified and integrative way by characterizing pathways that these data simultaneously reveal. To this end, we developed integrative Pathway Enrichment Analysis Platform, iPEAP, which handles transcriptomics, proteomics, metabolomics and GWAS data under a unified aggregation schema. iPEAP emphasizes on the ability to aggregate various pathway enrichment results generated in different high-throughput experiments, as well as the quantitative measurements of different ranking results, thus providing the first benchmark platform for integration, comparison and evaluation of multiple types of data and enrichment methods.   AVAILABILITY AND IMPLEMENTATION iPEAP is freely available at http://www.tongji.edu.cn/∼qiliu/ipeap.html.		Haoqi Sun;Haiping Wang;Ruixin Zhu;Kailin Tang;Qin Gong;Juan Cui;Zhi-Wei Cao;Qi Liu	2014	Bioinformatics	10.1093/bioinformatics/btt576	biology;bioinformatics;data science;data mining	Comp.	4.485683664548774	-57.05849918226724	48614
5597706c9b21aa19e76683eb5a506357f641a8bb	miscore: mismatch-based matrix similarity scores for dna motif detection	t technology general;digital repository;qa mathematics;information content;biological data;la trobe university research online;dna sequence	To detect or discover motifs in DNA sequences, two important concepts related to existing computational approaches are motif model and similarity score. One of motif models, represented by a position frequency matrix (PFM), has been widely employed to search for putative motifs. Detection and discovery of motifs can be done by comparing kmers with a motif model, or clustering kmers according to some criteria. In the past, information content based similarity scores have been widely used in searching tools. In this paper, we present a mismatchbased matrix similarity score (namely, MISCORE) for motif searching and discovering purpose. The proposed MISCORE can be biologically interpreted as an evolutionary metric for predicting a kmer as a motif member or not. Weighting factors, which are meaningful for biological data mining practice, are introduced in the MISCORE. The effectiveness of the MISCORE is investigated through exploring its separability, recognizability and robustness. Three well-known information contentbased matrix similarity scores are compared, and results show that our MISCORE works well.		Dianhui Wang;Nung Kion Lee	2008		10.1007/978-3-642-02490-0_59	dna sequencing;digital library;self-information;biological data;computer science;bioinformatics;data science;machine learning;data mining	AI	9.023060588338977	-52.90860064760178	48615
c3d3a21b60eb15dc9e1f42becc55219b84804db2	neural implementation of categorization in a motion discrimination task	rotation invariant connectivity;asymmetric shifted connectivity;correct rate;spiking network;context dependent categorization;motion direction;reaction time	Human being can categorize one object into different classes depending on the reference used, a cognitive capacity, i.e., context-dependent categorization, which is fundamental in our daily life. In the present study, we explore one possible neural mechanism underlying a motion discrimination task, in which the neural system needs to judge whether a motion direction embedded in a random dot kinematogram is clockwise or anticlockwise with respect to a reference direction that varies over time. We construct a spiking-neuron network model to implement this task. The model consists of three parts: (1) a working memory circuit, which holds the information of the reference direction; (2) two information extraction circuits, referred to as clockwise-preferred circuit and anticlockwise-preferred circuit, respectively, which extract either the clockwise or anticlockwise information about the test direction; and (3) a decision-making circuit, which reads out the category decision. At the core of the network is the assumption of an asymmetric offset and rotational invariance of the connectivity profile. Our model successfully implements the context-dependent categorization of motion direction where the reference varies over time. And it reproduces the experimental results that with higher similarity between the reference and test direction or lower coherence level of the random dot kinematogram, the performance gets worse (lower accuracy and longer reaction time).	categorization	L. T. Yu;Shu Wu;D. H. Wang	2016	Neurocomputing	10.1016/j.neucom.2016.08.038	mental chronometry;computer science;artificial intelligence;machine learning	Vision	16.96037036528672	-74.23003439164452	48624
07ea8297b6b7ed7ced8169375807de63c053391a	improved measures of phase-coupling between spikes and the local field potential	animals;models neurological;universiteitsbibliotheek;electroencephalography phase synchronization;nerve net;humans;neurons;electroencephalography;neural networks computer;action potentials	An important tool to study rhythmic neuronal synchronization is provided by relating spiking activity to the Local Field Potential (LFP). Two types of interdependent spike-LFP measures exist. The first approach is to directly quantify the consistency of single spike-LFP phases across spikes, referred to here as point-field phase synchronization measures. We show that conventional point-field phase synchronization measures are sensitive not only to the consistency of spike-LFP phases, but are also affected by statistical dependencies between spike-LFP phases, caused by e.g. non-Poissonian history-effects within spike trains such as bursting and refractoriness. To solve this problem, we develop a new pairwise measure that is not biased by the number of spikes and not affected by statistical dependencies between spike-LFP phases. The second approach is to quantify, similar to EEG-EEG coherence, the consistency of the relative phase between spike train and LFP signals across trials instead of across spikes, referred to here as spike train to field phase synchronization measures. We demonstrate an analytical relationship between point-field and spike train to field phase synchronization measures. Based on this relationship, we prove that the spike train to field pairwise phase consistency (PPC), a quantity closely related to the squared spike-field coherence, is a monotonically increasing function of the number of spikes per trial. This derived relationship is exact and analytic, and takes a linear form for weak phase-coupling. To solve this problem, we introduce a corrected version of the spike train to field PPC that is independent of the number of spikes per trial. Finally, we address the problem that dependencies between spike-LFP phase and the number of spikes per trial can cause spike-LFP phase synchronization measures to be biased by the number of trials. We show how to modify the developed point-field and spike train to field phase synchronization measures in order to make them unbiased by the number of trials.	electroencephalography phase desynchronization;interdependence;international conference on functional programming;least fixed point;neural oscillation;selaginella;spike count:nrat:pt:cerebral cortex:qn:eeg;the spike (1997);spike train	Martin Vinck;Francesco Paolo Battaglia;Thilo Womelsdorf;Cyriel M. A. Pennartz	2011		10.1007/s10827-011-0374-4	psychology;neuroscience;simulation;electroencephalography;computer science;machine learning;communication;action potential	ML	19.67162250528734	-75.00569601721737	48636
68984c73c75d993ceede36a4922ec3f7d8973eaa	optimality of human contour integration	models neurological;human performance;pattern recognition physiological;temporal dynamics;contour integration;human subjects;statistical properties;models statistical;algorithms;humans;neurons;perceptual masking;behavior;form perception;visual system;vision;computer simulation;sensory perception;psychophysics	For processing and segmenting visual scenes, the brain is required to combine a multitude of features and sensory channels. It is neither known if these complex tasks involve optimal integration of information, nor according to which objectives computations might be performed. Here, we investigate if optimal inference can explain contour integration in human subjects. We performed experiments where observers detected contours of curvilinearly aligned edge configurations embedded into randomly oriented distractors. The key feature of our framework is to use a generative process for creating the contours, for which it is possible to derive a class of ideal detection models. This allowed us to compare human detection for contours with different statistical properties to the corresponding ideal detection models for the same stimuli. We then subjected the detection models to realistic constraints and required them to reproduce human decisions for every stimulus as well as possible. By independently varying the four model parameters, we identify a single detection model which quantitatively captures all correlations of human decision behaviour for more than 2000 stimuli from 42 contour ensembles with greatly varying statistical properties. This model reveals specific interactions between edges closely matching independent findings from physiology and psychophysics. These interactions imply a statistics of contours for which edge stimuli are indeed optimally integrated by the visual system, with the objective of inferring the presence of contours in cluttered scenes. The recurrent algorithm of our model makes testable predictions about the temporal dynamics of neuronal populations engaged in contour integration, and it suggests a strong directionality of the underlying functional anatomy.	algorithm;alignment;anatomic structures;computation;contour line;dna integration;embedded system;embedding;experiment;greater than;inference;interaction;matching;neural ensemble;population;randomness;recurrent neural network;physiological aspects	Udo Ernst;Sunita Mandon;Nadja Schinkel-Bielefeld;Simon D. Neitzel;Andreas K. Kreiter;Klaus Pawelzik	2012		10.1371/journal.pcbi.1002520	computer simulation;vision;computer vision;neuroscience;visual system;form perception;computer science;machine learning;psychophysics;behavior	ML	19.525465914180803	-69.27116532840613	48679
5d4bcfefd91cd4b99b280fb8707a4fe2692e823c	e2d: a novel tool for annotating protein domains in expressed sequence tags	sequences databases pipelines hidden markov models protein engineering genomics bioinformatics libraries large scale systems assembly;biology computing;functional annotation;homology search;domain recognition;protein domains;protein domain annotation;genetics;domain recognition protein domain annotation expressed sequence tags functional genomics homology search domain profile search;proteins;functional genomics;proteins biology computing genetics;domain profile search;expressed sequence tag;expressed sequence tags	The vast number of expressed sequence tags (ESTs) in public databases provides an important resource for comparative and functional genomics. A variety of methods based on homology search or domain profile search have been developed to functionally annotate protein domains in ESTs. However, these methods either ignore potentially valuable information from the homologues beyond the top N hits, or they are extremely time consuming. We provide an efficient and novel tool, called E2D (EST to Domain), which functionally annotates anonymous ESTs by recognizing potential domains from the enlarged hit proteins. Comparison with InterProScan shows that E2D is more efficient and effective for domain recognition. Additionally, we achieve 87.5% agreement with existing GO function annotations in TIGR through domain-GO mapping, which demonstrates the efficacy of our approach	database;functional genomics;homology (biology)	Guo-Hsing Lee;Nai-Yu Chuang;Wen-Dar Lin;Chung-Der Hsiao;Hahn-Ming Lee;Jan-Ming Ho	2006	2006 IEEE Symposium on Computational Intelligence and Bioinformatics and Computational Biology	10.1109/CIBCB.2006.330967	biology;bioinformatics;data mining;genetics;expressed sequence tag	Comp.	1.5745846888834876	-57.296542172823884	48691
31bd2adde4f385df7523d1f559f9aa2809c66271	a base composition analysis of natural patterns for the preprocessing of metagenome sequences	dna bacterial;base composition;sequence analysis dna;metagenome;computational biology bioinformatics;cluster analysis;genome bacterial;algorithms;combinatorial libraries;base sequence;computer appl in life sciences;microarrays;bioinformatics	On the pretext that sequence reads and contigs often exhibit the same kinds of base usage that is also observed in the sequences from which they are derived, we offer a base composition analysis tool. Our tool uses these natural patterns to determine relatedness across sequence data. We introduce spectrum sets (sets of motifs) which are permutations of bacterial restriction sites and the base composition analysis framework to measure their proportional content in sequence data. We suggest that this framework will increase the efficiency during the pre-processing stages of metagenome sequencing and assembly projects. Our method is able to differentiate organisms and their reads or contigs. The framework shows how to successfully determine the relatedness between these reads or contigs by comparison of base composition. In particular, we show that two types of organismal-sequence data are fundamentally different by analyzing their spectrum set motif proportions (coverage). By the application of one of the four possible spectrum sets, encompassing all known restriction sites, we provide the evidence to claim that each set has a different ability to differentiate sequence data. Furthermore, we show that the spectrum set selection having relevance to one organism, but not to the others of the data set, will greatly improve performance of sequence differentiation even if the fragment size of the read, contig or sequence is not lengthy. We show the proof of concept of our method by its application to ten trials of two or three freshly selected sequence fragments (reads and contigs) for each experiment across the six organisms of our set. Here we describe a novel and computationally effective pre-processing step for metagenome sequencing and assembly tasks. Furthermore, our base composition method has applications in phylogeny where it can be used to infer evolutionary distances between organisms based on the notion that related organisms often have much conserved code.	base composition;base excess:scnc:pt:blda:qn:calculated;biopolymer sequencing;code coverage;distance;duplex sequencing;inference;metagenome;organism;patterns in nature;phylogenetic tree;preprocessor;pretext;reading (activity);relevance;sequence motif;whole genome sequencing	Oliver Bonham-Carter;Hesham H. Ali;Dhundy Bastola	2013		10.1186/1471-2105-14-S11-S5	biology;dna microarray;computer science;bioinformatics;cluster analysis;genetics;metagenomics	Comp.	1.8795580773395941	-56.247098165462525	48692
baf774efbcbd45d6826aaae4fe010802bc5e4186	comparative sequence analysis of the p53 response elements associated with apoptosis and cell cycle arrest	cell cycle arrest		sequence analysis	Feng Cui;Michael Sirotin;Victor B Zhurkin	2006			cancer research;sequence analysis;cell cycle checkpoint;apoptosis;biology	Logic	2.648468698002756	-63.68287960328558	48756
90d2fb54b6725411411361de3728e2c813a5ce3b	correlations modulate the non-monotonic response of a neuron with short-term plasticity	stochastic transmission;synchrony;second order statistics;neural response;short term plasticity	The impact of synchronous inputs onto a simple neuron model with synapses showing shortterm plasticity is studied. The synaptic model includes depression, stochastic release and facilitation. The mean and second-order statistics of the current are computed. The combination of synchrony and STP produces a non-monotonic behavior of the current variance , while the mean saturates monotonically. Provided that saturates under threshold, the output rate inherits the resonant behavior of , making the neuron respond maximally to a speci1c rate. Information about the input rate can be transmitted beyond the saturation of by means of . c © 2004 Elsevier B.V. All rights reserved.	biological neuron model;non-monotonic logic;synaptic package manager	Jaime de la Rocha;Rubén Moreno;Néstor Parga	2004	Neurocomputing	10.1016/j.neucom.2004.01.061	machine learning	ML	18.13150405780417	-71.3909282458491	48859
5830532234c35e5aa2f6ca28c4f5e5bd30ba5fea	comparative accuracy of methods for protein sequence similarity search	investigation method;evaluation performance;secuencia aminoacido;alignement sequence;proteine;performance evaluation;methode etude;sequence aminoacide;aminoacid sequence;protein sequence;estudio comparativo;evaluacion prestacion;alineacion secuencia;etude comparative;metodo estudio;homology;comparative study;proteina;sequence alignment;protein;homologia;similarity search;homologie	MOTIVATION Searching a protein sequence database for homologs is a powerful tool for discovering the structure and function of a sequence. Two new methods for searching sequence databases have recently been described: Probabilistic Smith-Waterman (PSW), which is based on Hidden Markov models for a single sequence using a standard scoring matrix, and a new version of BLAST (WU-BLAST2), which uses Sum statistics for gapped alignments.   RESULTS This paper compares and contrasts the effectiveness of these methods with three older methods (Smith-Waterman: SSEARCH, FASTA and BLASTP). The analysis indicates that the new methods are useful, and often offer improved accuracy. These tools are compared using a curated (by Bill Pearson) version of the annotated portion of PIR 39. Three different statistical criteria are utilized: equivalence number, minimum errors and the receiver operating characteristic. For complete-length protein query sequences from large families, PSW's accuracy is superior to that of the other methods, but its accuracy is poor when used with partial-length query sequences. False negatives are twice as common as false positives irrespective of the search methods if a family-specific threshold score that minimizes the total number of errors (i.e. the most favorable threshold score possible) is used. Thus, sensitivity, not selectivity, is the major problem. Among the analyzed methods using default parameters, the best accuracy was obtained from SSEARCH and PSW for complete-length proteins, and the two BLAST programs, plus SSEARCH, for partial-length proteins.	amino acid sequence;blast;baillie–psw primality test;chamaecyparis lawsoniana;databases;digital curation;fasta;hidden markov model;markov chain;pierre robin syndrome;position weight matrix;protein structure prediction;question (inquiry);receiver operating characteristic;score;selectivity (electronic);sequence alignment;sequence database;similarity search;smith–waterman algorithm;staphylococcal protein a;turing completeness	Pankaj Agarwal;David J. States	1998	Bioinformatics	10.1093/bioinformatics/14.1.40	biology;homology;bioinformatics;comparative research;protein sequencing;sequence alignment;mathematics;algorithm;statistics	Comp.	-2.282924465920651	-53.64701455580164	48867
d312cd63d05e1dd46e601837995b017b4c61e131	accelerating approximate subsequence search on large protein sequence databases	database indexing;dna;databases;bass tree;biology computing;sequences;sequence approximate match index method molecular biology approximate subsequence search large protein sequence index structure suffix tree dna sequences protein database bass tree;degradation;database management systems;protein sequence;dna sequences;approximate subsequence search;index structure;tree data structures;protein database;acceleration;indexing method;suffix tree;indexes;proteins;indexing;organizing;pattern matching;molecular biology;indexation;large protein sequence;approximate matching;search problems;search problems dna proteins database management systems biology computing pattern matching tree data structures database indexing;dna sequence;sequence approximate match index method;bioinformatics;acceleration protein sequence databases sequences indexes bioinformatics dna indexing organizing degradation	"""Bioinformatics has become an active research area in recent years. The amount of mapped sequences doubles every fourteen months. BLAST has been widely employed for retrieving sequences which has similar portion(s) to a given sequence. However, BLAST has to scan the entire database every time when a query is issued. This can be very time consuming especially when the database is large. In this paper, we study the problem on how to build a persistent index structure for protein sequences to support approximate match. The suffix tree has been proposed as a solution to index sequence database and has been deployed on organizing DNA sequences (Hunt et al. 2001). Unfortunately, it suffers from the problem of """"memory bottleneck"""" that prevents it from being applied efficiently to a large database. The performance even degrades further for protein database due to a larger fanout at each node. Here, we employ an indexing structure, called BASS-tree, to support approximate match in sublinear time on a large protein database. We call this indexing method as sequence approximate match (SAM) index method. The search of approximate matches can be properly directed to the portion in the database with a high potential of matching quickly. It has been demonstrated in our experiments that the potential performance improvement is in an order of magnitude over alternative methods such as the BLAST algorithm and the suffix tree."""	amino acid sequence;anatomic node;approximation algorithm;blast;basolateral sorting signal;bioinformatics;experiment;fan-out;fourteen;indexes;large;list of biological databases;matching;mental suffering;organizing (structure);peptide sequence;pierre robin syndrome;question (inquiry);sequence database;suffix tree;time complexity;von neumann architecture	Jiong Yang;Wei Wang;Yi Xia;Philip S. Yu	2002	Proceedings. IEEE Computer Society Bioinformatics Conference	10.1109/CSB.2002.1039343	database index;biology;dna sequencing;computer science;bioinformatics;theoretical computer science;data mining;genetics	DB	-2.3863746946824302	-52.39184265596342	48891
a4804203a2342c6837d0c6c7ae9f068922e8cfdf	prediction of infectious disease epidemics via weighted density ensembles		Accurate and reliable predictions of infectious disease dynamics can be valuable to public health organizations that plan interventions to decrease or prevent disease transmission. A great variety of models have been developed for this task, using different model structures, covariates, and targets for prediction. Experience has shown that the performance of these models varies; some tend to do better or worse in different seasons or at different points within a season. Ensemble methods combine multiple models to obtain a single prediction that leverages the strengths of each model. We considered a range of ensemble methods that each form a predictive density for a target of interest as a weighted sum of the predictive densities from component models. In the simplest case, equal weight is assigned to each component model; in the most complex case, the weights vary with the region, prediction target, week of the season when the predictions are made, a measure of component model uncertainty, and recent observations of disease incidence. We applied these methods to predict measures of influenza season timing and severity in the United States, both at the national and regional levels, using three component models. We trained the models on retrospective predictions from 14 seasons (1997/1998-2010/2011) and evaluated each model's prospective, out-of-sample performance in the five subsequent influenza seasons. In this test phase, the ensemble methods showed average performance that was similar to the best of the component models, but offered more consistent performance across seasons than the component models. Ensemble methods offer the potential to deliver more reliable predictions to public health decision makers.	best, worst and average case;communicable diseases;component-based software engineering;ensemble learning;experience;incidence matrix;legg-calve-perthes disease;personnameuse - assigned;prospective search;weight function;density;disease transmission	Evan L. Ray;Nicholas G. Reich	2018		10.1371/journal.pcbi.1005910	virology	ML	7.128645566766499	-73.85342124112877	48899
bddac0b3c6b0e705bda9af4ac8e886223123b93a	data mining system for biochemical analysis in experimental physiology	neural nets biochemistry biology computing chemistry computing data mining;biology computing;neural nets;chemistry computing;data mining;aspartate data mining system biochemical analysis experimental physiology adaptive resonance theory artificial neural network glutamate;artificial neural networks joints conferences electronic mail;glutamate;biochemistry;adaptive resonance theory;artificial neural network	We develop a data mining system to assist with the elucidation by graphical means of the biochemical changes in the brains of rodents. Manual analysis of such experiments is increasingly impractical because of the voluminous nature of the data that is generated, and the tedious nature of the analysis means that important information can be missed. For this purpose we are constructing an increasingly sophisticated data mining system which contains a number of pre-processing stages and classification via two steps of an adaptive resonance theory artificial neural network.In this paper we describe the system. The focus of our activity is the study of neurotransmitters: glutamate and aspartate and we present an example of how to utilize our data mining system for the automated classification of samples that are extracted from the brains of rodents. This methodology should prove equally valuable to other biochemical analysis problems in experimental physiology.	adaptive resonance theory;artificial neural network;data mining;experiment;graphical user interface;preprocessor	Junior Altamiranda;José Aguilar;Luis Hernández	2008	2008 IEEE International Joint Conference on Neural Networks (IEEE World Congress on Computational Intelligence)	10.1109/IJCNN.2008.4634282	computer science;bioinformatics;artificial intelligence;adaptive resonance theory;machine learning;glutamate receptor;artificial neural network	ML	3.737859625642552	-56.737290090544626	48901
f1f8b250348c00fadb7c14bd7bd9e6dc9b618a39	detecting chromosomal structural variation using jaccard distance and parallel architecture	parallel architecture	Understanding the nature of many diseases, including cancer, requires locating somatically acquired rearrangements corresponding to large-scale chromosomal aberrations. Computational methods to detect inter-chromosomal rearrangements based on next-generation sequencing platforms face the big challenge of accurately predicting the location of sites spanned by a typically small number of reads, while the entire sample contains hundreds of millions of reads. In this work, we propose a method called TDJD that identifies the location of interchromosomal breakpoints corresponding to a large scale structural variations, in particular translocations and insertions. To reduce the huge dimension of the search space, we split candidate reads that can be potential break points into windows, and represent the windows as a sequence of binary fingerprints. We then search for the location of the breakpoint in the reference genome using Jaccard distance. We use a combination of parallel computing, search using Jaccard distance to solve the exact nearest neighbor problem. The dimensionality reduction takes advantage of an SSE multi-thread architecture to achieve efficient search. We applied our algorithm to identify several reads with breakpoints, including those characterizing the PAX8-PPARγ rearrangement, a frequent modification occurring in follicular thyroid cancer. Our results show that we could identify the breakpoints much faster than the previous method. We also compared our results to several recently published methods, and found that our method is faster than all other compared methods with high accuracy.	algorithm;breakpoint;computation;dimensionality reduction;fingerprint;jd - java decompiler;jaccard index;ll parser;microsoft windows;nearest neighbor search;parallel computing;python;sensor;streaming simd extensions;tree rearrangement	Hamidreza Mohebbi;Amir Vajdi;Nurit Haspel;Dan A. Simovici	2017	2017 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)	10.1109/BIBM.2017.8217962	breakpoint;jaccard index;bioinformatics;computer science;structural variation;architecture;dimensionality reduction;reference genome;small number;k-nearest neighbors algorithm	Visualization	-1.715914733701483	-52.84828653149927	48933
c8abc87c6f265ea94490e8aa81668a17ca983d52	the cerebral basis of mapping nonsymbolic numerical quantities onto abstract symbols: an fmri training study	parietal cortex;prefrontal cortex;intraparietal sulcus;functional magnetic resonance images;individual learning;regression analysis	Although significant insights into the neural basis of numerical and mathematical processing have been made, the neural processes that enable abstract symbols to become numerical remain largely unexplored in humans. In the present study, adult participants were trained to associate novel symbols with nonsymbolic numerical magnitudes (arrays of dots). Functional magnetic resonance imaging was used to examine the neural correlates of numerical comparison versus recognition of the novel symbols after each of two training stages. A left-lateralized fronto-parietal network, including the intraparietal sulcus, the precuneus, and the dorsal prefrontal cortex, was more active during numerical comparison than during perceptual recognition. In contrast, a network including bilateral temporal–occipital regions was more active during recognition than comparison. A whole-brain three-way interaction revealed that those individuals who had higher scores on a postscan numerical task (measuring their understanding of the global numerical organization of the novel symbols) exhibited increasing segregation between the two tasks in the bilateral intraparietal sulci as a function of increased training. Furthermore, whole-brain regression analysis showed that activity in the left intraparietal sulcus was systematically related to the effect of numerical distance on accuracy. These data provide converging evidence that parietal and left prefrontal cortices are involved in learning to map numerical quantities onto visual symbols. Only the parietal cortex, however, appeared systematically related to the degree to which individuals learned to associate novel symbols with their numerical referents. We conclude that the left parietal cortex, in particular, may play a central role in imbuing visual symbols with numerical meaning.	bilateral filter;consciousness;convergence (action);groove;magnetic resonance imaging;mathematics;numerical analysis;occipital lobe;parietal lobe;prefrontal cortex;quantity;structure of intraparietal sulcus;structure of precuneus;dinoflagellate sulcus;fmri	Ian M. Lyons;Daniel Ansari	2009	Journal of Cognitive Neuroscience	10.1162/jocn.2009.21124	psychology;cognitive psychology;neuroscience;developmental psychology;posterior parietal cortex;communication;regression analysis	ML	18.071942902858428	-77.5856724531727	48945
57cecd076c31a0d220d3a29a483dcd54482b8092	an effective hierarchical model for the biomolecular covalent bond: an approach integrating artificial chemistry and an actual terrestrial life system	individual death;hierarchical structure;unicellular organism;genetics;hydrolysis;simulation experiment;programmed self decomposition model;individual death collective reutilizability bond energy programmed self decomposition model unicellular organism hydrolysis;collective reutilizability;bond energy;hierarchical model	Under the AChem paradigm and the programmed self-decomposition (PSD) model, we propose a hierarchical model for the biomolecular covalent bond (HBCB model). This model assumes that terrestrial organisms arrange their biomolecules in a hierarchical structure according to the energy strength of their covalent bonds. It also assumes that they have evolutionarily selected the PSD mechanism of turning biological polymers (BPs) into biological monomers (BMs) as an efficient biomolecular recycling strategy. We have examined the validity and effectiveness of the HBCB model by coordinating two complementary approaches: biological experiments using existent terrestrial life, and simulation experiments using an AChem system. Biological experiments have shown that terrestrial life possesses a PSD mechanism as an endergonic, genetically regulated process and that hydrolysis, which decomposes a BP into BMs, is one of the main processes of such a mechanism. In simulation experiments, we compared different virtual self-decomposition processes. The virtual species in which the self-decomposition process mainly involved covalent bond cleavage from a BP to BMs showed evolutionary superiority over other species in which the self-decomposition process involved cleavage from BP to classes lower than BM. These converging findings strongly support the existence of PSD and the validity and effectiveness of the HBCB model.	artificial chemistry;biological factors;biological system;class;convergence (action);covalent interaction;experiment;hierarchical database model;programming paradigm;recycling;simulation;terrestrial television;monomer;negative regulation of protein processing in phagocytic vesicle	Tsutomu Oohashi;Osamu Ueno;Tadao Maekawa;Norie Kawai;Emi Nishina;Manabu Honda	2009	Artificial Life	10.1162/artl.2009.15.1.15103	hydrolysis;bond energy;biology;artificial intelligence;ecology;genetics;hierarchical database model	Web+IR	7.597113198868184	-63.37964848940249	48946
8c7d304d1f104179180f8bee3b605eda2d375dd6	rna-seq gene and transcript expression analysis using the bioextract server and iplant collaborative	bioextract;high performance computing;rnaseq;cyberinfrastructure;workflow management system;ngs;escience;iplant collaborative	Background: The development of Next Generation Sequencing (NGS) technology provides great opportunities to study gene expression, gene spliced transcripts, post-transcriptional changes, and gene fusion mutations/SNPs. The large amount of data being generated from these approaches presents many challenges. For example, how can we manage and analyze these vast datasets in order to extract new knowledge.  Aims: This paper provides an integrated, adaptable, and scalable scenario to guide researchers through a complex, data analysis process using the iPlant Collaborative AGAVE RESTful API through the BioExtract Server. In 3 modules, we show how a High Performance Cluster (HPC) can be leveraged in a Workflow Management System (WMS) by following simple analytic steps.  Results: A workflow has been developed in the BioExtract Server to analyze RNA-Seq data. The running of this workflow on a 21.6GB dataset provides reliable gene and transcript expression results. The BioExtract Server's results compared to an existing manual workflow on the same dataset shows ≈800% improvement in execution time (from ≈18h to ≈2h10min). Additionally, there are several qualitative improvements such as; automation, reproducibility, sharability, and scalability. (Note: the performance was not compared to the workflow installed at Galaxy, https://usegalaxy.org/, due to extensive wait times on their public site.) Our workflow execution provides analysis results from input datasets and reveals a 0.05 fold discovery rate (FDR) showing that 342 genes, 228 isoforms, 270 TSS, 47 CDS and 23 promoters are significantly differentially expressed.  Conclusion: Having the ability to easily create and execute workflows leveraging the robust iPlant cyberinfrastructure to analyze NGS data represents one more steps in eScience initiative improvement. It improves, considerably, the ability of life science researchers to apply NGS tools. However, enhancements to this approach remains important as everyday improvements in HPC and WMS technology, techniques, and software continues. Our coming challenge will consist to follow that evolution in order to minimize the gap between researchers and these powerful resources.  Availability: Tools used here are freely available on referenced link. Additional data analysis from our workflow execution is available on demand. Our workflow is available on MyExperiment under creative commons (cc) license (http://www.myexperiment.org/workflows/3895.html?version=1).	communications satellite;cyberinfrastructure;e-science;iplant collaborative;management system;next-generation network;representational state transfer;run time (program lifecycle phase);scalability;server (computing);myexperiment	Etienne Z. Gnimpieba;Abalo Chango;Carol Lushbough	2014		10.1145/2649387.2660822	supercomputer;rna-seq;computer science;bioinformatics;data mining;world wide web;workflow management system	HPC	-1.7985305596150538	-56.00804002095106	48963
a4d6daa741dd46c20ddcc46cf08d7626dcbb2eb0	generalisation of structural knowledge in the hippocampal-entorhinal system		A central problem to understanding intelligence is the concept of generalisation. This allows previously learnt structure to be exploited to solve tasks in novel situations differing in their particularities. We take inspiration from neuroscience, specifically the hippocampal-entorhinal system known to be important for generalisation. We propose that to generalise structural knowledge, the representations of the structure of the world, i.e. how entities in the world relate to each other, need to be separated from representations of the entities themselves. We show, under these principles, artificial neural networks embedded with hierarchy and fast Hebbian memory, can learn the statistics of memories and generalise structural knowledge. Spatial neuronal representations mirroring those found in the brain emerge, suggesting spatial cognition is an instance of more general organising principles. We further unify many entorhinal cell types as basis functions for constructing transition graphs, and show these representations effectively utilise memories. We experimentally support model assumptions, showing a preserved relationship between entorhinal grid and hippocampal place cells across environments.	artificial neural network;basis function;cognition;disk mirroring;embedded system;entity;experiment;hebbian theory	James C. R. Whittington;Timothy H. Muller;Caswell Barry;Timothy Edward John Behrens	2018			computer science;grid;artificial intelligence;machine learning;artificial neural network;hippocampal formation;hebbian theory;hierarchy;generalization;mirroring	AI	19.41221513457984	-68.03097483258519	48965
126f84f0a4a0f648eefd86668c5d47a6bbe17dfe	complexity preserving increase of the capacity of bidirectional associative memories by dilation and translation	learning algorithm;kosko network;reseau kosko;dilatacion;algorithme apprentissage;bidirectional associative memories;translation;dilatation;connexion bidirectionnelle;contraccion;reseau neuronal;dilation;algoritmo aprendizaje;bidirectional associative memory;memoire associative bidirectionnelle;red neuronal;neural network;contraction;kosko type networks	In this paper, we show how to increase the capacity of Kosko-type bidirectional associative memories by introducing dilation and translation parameters in the pattern space. The essential point of this approach is that the increase of the capacity of the networks almost doesn't affect their complexity. The general idea of the proposed strategy is to tune the networks in such a way that they are better suited to store patterns which are highly correlated without touching their ability to recover easy-to-store information. A detailed example at the end of the paper shows how our approach works in practice.	bidirectional associative memory;complexity;dilation (morphology);genetic translation process;pathological dilatation;sed	Burkhard Lenze	1998	Neural networks : the official journal of the International Neural Network Society	10.1016/S0893-6080(98)00073-2	translation;computer science;artificial intelligence;machine learning;contraction;mathematics;bidirectional associative memory;dilation;artificial neural network;algorithm	ML	21.693188198719227	-70.2455618953132	48970
c196df8c479639395003747de5b3bc988d8d1222	curved dna without aa/tt dinucleotide step	dna;gel electrophoresis;oligodeoxyribonucleotides;nucleotides;mobility;electrophoresis polyacrylamide gel;secuencia repetida;sequence repetee;conformation;electroforesis gel;courbure;chief complaint;coude moleculaire;repetitive sequences nucleic acid;thymine nucleotides;conformacion;structure moleculaire;molecular bending;electrophorese gel;nucleic acid conformation;curvatura;curvature;molecular sequence data;pliegue molecular;base sequence;estructura molecular;adenine nucleotides;repeated sequence;molecular structure	The evidence is accumulating that dinucleotide steps other than AA/TT affect DNA flexure of AnTm (m + n greater than = 4) containing fragments. However, it is not clear whether macroscopic DNA flexure without AA/TT steps might occur. In this paper we demonstrate the anomaly in electrophoretic mobility of non AA/TT repetitive DNA sequences which is a function of sequence phasing. Therefore, our results show that PyPu (TA) and AG/CT steps, angulary separated by close to 180 degrees from Pu/Py (GC) and GG/CC steps, bend DNA, even in the absence of AnTm tracts.	amino acids;anomaly detection;dna binding site;dinucleoside phosphates;flexure;gadu-gadu;silver	I. Brukner;V. Jurukovski;M. Konstantinovic;A. Savic	1991	Nucleic acids research	10.1093/nar/19.13.3549	biology;biochemistry;molecular biology;nucleotide;repeated sequence;molecule;gel electrophoresis;curvature;mobile computing;genetics;dna	Comp.	4.570594778559846	-63.919473989839524	48978
a91b845e3cb9de6eec73cd4772c49ee2224d7554	the time course of visuospatial information in drawing from memory		A number of studies indicate that eye movements play an integral role in visuospatial memory during perceptualmotor tasks like making a sandwich or drawing a recently perceived scene from short-term memory. The present study analyzed spatial distributions of eye movements to test the decay of visuospatial memory and its effect on perceptual-motor task performance. Participants viewed images of natural scenes for 30 seconds each, and after each image was removed for either a 15 or 30 second delay, participants drew the image from memory. Results showed that eye movements during drawing became less like those during viewing after the longer delay compared with the shorter one. This decoupling of eye movements was also reflected in performance, in that drawings were nominally less similar to their corresponding images after the longer delay period.	coupling (computer programming);long short-term memory;spatial–temporal reasoning	Drew H. Abney;Bryan Kerster;Christopher T. Kello	2014			spatial memory;cognitive psychology;cognitive science;psychology;eye movement;perception	HCI	14.308027901141271	-75.97838231583135	48981
fb652eebdaaa19f981a72c2f368a5e1fc13c19a6	free energy profiles for unwrapping the outer superhelical turn of nucleosomal dna		The eukaryotic genome is packaged into a nucleus in the form of chromatin. The fundamental structural unit of chromatin is a protein-DNA complex, the nucleosome, where 146 or 147 base pairs of DNA wrap 1.75 times around a histone core. To function in cellular processes, however, nucleosomal DNA must be unwrapped. Although this unwrapping has been experimentally investigated, details of the process at an atomic level are not yet well understood. Here, we used molecular dynamics simulation with an enhanced sampling method to calculate the free energy profiles for unwrapping the outer superhelical turn of nucleosomal DNA. A free energy change of about 11.5 kcal/mol for the unwrapping agrees well with values obtained in single molecule experiments. This simulation revealed a variety of conformational states, indicating there are many potential paths to outer superhelicdal turn unwrapping, but the dominant path is likely asymmetric. At one end of the DNA, the first five bps unwrap, after which a second five bps unwrap at the same end with no increase in free energy. The unwrapping then starts at the other end of the DNA, where 10 bps are unwrapped. During further unwrapping of 15 bps, the unwrapping advances at one of the ends, after which the other end of the DNA unwraps to complete the unwrapping of the outer superhelical turn. These results provide insight into the construction, disruption, and repositioning of nucleosomes, which are continuously ongoing during cellular processes.	base pairing;benzalkonium chloride 1.3 mg/ml topical foam;cell nucleus;dna computing;duoxa1 gene;denial-of-service attack;experiment;histones;molecular dynamics;nucleosomes;popliteal pterygium syndrome, lethal type;sampling (signal processing);sampling - surgical action;simulation;staphylococcal protein a;free energy;kilocalorie	Hidetoshi Kono;Shun Sakuraba;Hisashi Ishida	2018		10.1371/journal.pcbi.1006024	crystallography;biology;bioinformatics;dna;nucleosome;base pair;histone;chromatin	Comp.	8.880956962703191	-63.45992338995565	48985
47ae9a6fa0da49fc128a709c9d1d45bb4797444d	path integration in 3d from visual motion cues: a human fmri study	settore bio 09 fisiologia	While neural correlates of path integration on a yaw plane have been studied extensively, much less is known about path integration in three-dimensions (3D). Here we used fMRI during virtual navigation within tunnels in pseudo-3D. We found that the same visual motion stimuli are encoded differently in the brain depending on whether they represent displacements within the yaw plane or within the pitch plane. The yaw plane is more represented in the hippocampus while the pitch plane is more represented in the angular gyrus (AG) and in the posterior inferior temporal gyrus (pITG), known to be involved in 3D space encoding. In addition, a region in pITG, located just above the previous one, showed two different patterns with multi-voxel analysis, separately coding for the pitch and yaw planes. These results suggest that information encoded within pITG about the yaw plane may be exchanged with the hippocampus, while information about the pitch plane may be exchanged with the AG.	angularjs;consciousness;dna integration;dimensions;lateral occipitotemporal gyrus;numerous;structure of angular gyrus;structure of inferior temporal gyrus;voxel;yaws;fmri	Iole Indovina;Vincenzo Maffei;Elisabetta Mazzarella;Valentina Sulpizio;Gaspare Galati;Francesco Lacquaniti	2016	NeuroImage	10.1016/j.neuroimage.2016.07.008	psychology;computer vision;speech recognition;communication	ML	18.22934713786499	-75.07689795913345	49031
10685b467241a877c6d93451bd00a57a70215729	tmfunction: database for functional residues in membrane proteins	dissociation constant;web interface;relational database;structure function relationship;internet;protein binding;amino acids;membrane protein;wild type;protein data bank;mutation;databases protein;membrane proteins	We have developed the database TMFunction, which is a collection of more than 2900 experimentally observed functional residues in membrane proteins. Each entry includes the numerical values for the parameters IC50 (measure of the effectiveness of a compound in inhibiting biological function), V(max) (maximal velocity of transport), relative activity of mutants with respect to wild-type protein, binding affinity, dissociation constant, etc., which are important for understanding the sequence-structure-function relationship of membrane proteins. In addition, we have provided information about name and source of the protein, Uniprot and Protein Data Bank codes, mutational and literature information. Furthermore, TMFunction is linked to related databases and other resources. We have set up a web interface with different search and display options so that users have the ability to get the data in several ways. TMFunction is freely available at http://tmbeta-genome.cbrc.jp/TMFunction/.	code;database;experiment;function (biology);greater than;inhibitory concentration 50;interface device component;maximal set;membrane proteins;numerical analysis;preparation;processor affinity;protein data bank;uniprot;user interface;velocity (software development);mutant	M. Michael Gromiha;Yukimitsu Yabuki;M. Xavier Suresh;A. Mary Thangakani;Makiko Suwa;Kazuhiko Fukui	2009		10.1093/nar/gkn672	biology;biochemistry;bioinformatics;membrane protein;genetics	Comp.	-0.6036632507938843	-60.411521861605095	49063
ff9454895d8bcdb5414af54975539c1b32cc0183	multi-omic approaches for liver cancer biomarker discovery	liver cancer;metabolites;biomarkers	Omic technologies offer the opportunity to characterize liver cancer at various molecular levels. In particular, characterizing the association of biomolecules such as metabolites and glycoproteins with liver cancer is a promising strategy to discover clinically relevant biomarkers. Metabolites are molecular fingerprints of what cells do at a particular point in time; they can reveal early signs of cancers when the chances for cure are highest. Also, the analysis of protein glycosylation is relevant to liver pathology because of the major influence of this organ on the homeostasis of blood glycoproteins. This talk will focus on the application of multi-omic approaches to identify biomarkers for early detection of liver cancer in patients with liver cirrhosis. Specifically, I will present transcriptomic, proteomic, glycomic/ glycoproteomic, and metabolomic (TPGM) studies we conducted by analysis of samples from HCC cases and cirrhotic controls using multiple omic platforms such as next generation sequencing, liquid chromatography-mass spectrometry (LC-MS), and gas chromatography-mass spectrometry (GC-MS). In addition to candidate biomarkers discovered by evaluating the changes in the levels of transcripts, proteins, glycans, and metabolites between HCC cases and cirrhotic controls, I will present network-based methods we developed for integrative analysis of multi-omic data to identify aberrant pathways/network activities and biomarkers for early detection of liver cancer.	fingerprint;glycomics;homeostasis;human-centered computing;list of omics topics in biology;metabolomics;next-generation network;proteomics	Habtom W. Resson	2016		10.1109/BIBM.2016.7822481	biology;bioinformatics;immunology	Comp.	6.058626877227939	-58.43888728782909	49069
d7546205b9e687580e47ab3e8d55a92e37ccc5d5	msdc-0160 and msdc-0602 binding with human mitochondrial pyruvate carrier (mpc) 1 and 2 heterodimer: pparγ activating and sparing tzds as therapeutics		The﻿mitochondrial﻿pyruvate﻿carrier﻿(MPC)﻿is﻿a﻿novel﻿target﻿for﻿therapeutic﻿drugs﻿to﻿treat﻿Alzheimer’s﻿ and﻿Parkinson’s﻿disease,﻿ diabetes﻿mellitus,﻿ and﻿non-alcoholic﻿ steatohepatitis﻿ (NASH).﻿Metabolic﻿ Solutions﻿Development﻿Company﻿(MSDC)﻿has﻿two﻿thiazolidinediones,﻿MSDC-0160﻿and﻿MSDC-0602,﻿ in﻿the﻿pipeline.﻿This﻿report﻿describes﻿results﻿for﻿a﻿MPC1/2﻿heterodimer﻿homology﻿model.﻿The﻿FASTA﻿ sequences﻿for﻿MPC1﻿and﻿MPC2﻿were﻿accessed﻿from﻿UniProt﻿and﻿submitted﻿to﻿RaptorX,﻿resulting﻿in﻿ best﻿candidate﻿monomeric﻿“protein﻿data﻿base”﻿files﻿for﻿each.﻿One﻿mutant﻿form﻿of﻿MPC1,﻿L36I,﻿was﻿ also﻿processed.﻿These﻿were﻿submitted﻿to﻿PyDock﻿to﻿generate﻿best﻿candidate﻿MPC1/2﻿heterodimer﻿ models﻿that﻿were﻿used﻿for﻿ligand﻿docking﻿analyses﻿with﻿AutoDock﻿Vina﻿and﻿“Rosetta﻿Online﻿Server﻿ that﻿Includes﻿Everyone”﻿(ROSIE).﻿Multiple﻿binding﻿sites﻿for﻿pyruvate﻿and﻿both﻿drugs﻿were﻿found﻿on﻿ both﻿MPC1﻿and﻿MPC2﻿subunits﻿with﻿drugs﻿having﻿nearly﻿double﻿the﻿affinity﻿in﻿each﻿case﻿except﻿the﻿ intermediate﻿and﻿open-in﻿states﻿for﻿the﻿L36I﻿mutant﻿transporter. KeywoRDS Protein Homology Modeling, Inhibitor Docking, L36I Mutant, Michael Addition, MPC1, MPC2, Protein Protein Docking, Pyruvate, Single Nucleotide Polymorphism, Thiohemiacetal, UK-5099, Wild Type	homology modeling;macromolecular docking	Clyde F. Phelix;Allen K. Bourdon;Jason L. Dugan;Greg Villareal;George Perry	2017	IJKDB	10.4018/IJKDB.2017070103	bioinformatics;msdc;pyruvate carrier;biology	Comp.	2.2516599953113	-64.30328704572455	49093
